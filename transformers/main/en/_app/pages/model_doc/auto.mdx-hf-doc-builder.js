import{S as Aga,i as Lga,s as yga,e as a,k as l,w as F,t as o,M as xga,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as $ga,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as M1t}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function kga($){let g,v,u,f,p,d,h,yo,rd,Ef,pt,td,ad,C9,Cf,Ve,He,nd,Zn,w9,es,os,A9,sd,rs,L9,ld,wf,Qa;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),yo=o(`, make sure its
`),rd=a("code"),Ef=o("model_type"),pt=o(" attribute is set to the same key you use when registering the config (here "),td=a("code"),ad=o('"new-model"'),C9=o(")."),Cf=l(),Ve=a("p"),He=o("Likewise, if your "),nd=a("code"),Zn=o("NewModel"),w9=o(" is a subclass of "),es=a("a"),os=o("PreTrainedModel"),A9=o(`, make sure its
`),sd=a("code"),rs=o("config_class"),L9=o(` attribute is set to the same class you use when registering the model (here
`),ld=a("code"),wf=o("NewModelConfig"),Qa=o(")."),this.h()},l(Je){g=n(Je,"P",{});var Ae=s(g);v=r(Ae,"If your "),u=n(Ae,"CODE",{});var yB=s(u);f=r(yB,"NewModelConfig"),yB.forEach(t),p=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var id=s(d);h=r(id,"PretrainedConfig"),id.forEach(t),yo=r(Ae,`, make sure its
`),rd=n(Ae,"CODE",{});var xB=s(rd);Ef=r(xB,"model_type"),xB.forEach(t),pt=r(Ae," attribute is set to the same key you use when registering the config (here "),td=n(Ae,"CODE",{});var $B=s(td);ad=r($B,'"new-model"'),$B.forEach(t),C9=r(Ae,")."),Ae.forEach(t),Cf=i(Je),Ve=n(Je,"P",{});var xo=s(Ve);He=r(xo,"Likewise, if your "),nd=n(xo,"CODE",{});var Wa=s(nd);Zn=r(Wa,"NewModel"),Wa.forEach(t),w9=r(xo," is a subclass of "),es=n(xo,"A",{href:!0});var kB=s(es);os=r(kB,"PreTrainedModel"),kB.forEach(t),A9=r(xo,`, make sure its
`),sd=n(xo,"CODE",{});var Af=s(sd);rs=r(Af,"config_class"),Af.forEach(t),L9=r(xo,` attribute is set to the same class you use when registering the model (here
`),ld=n(xo,"CODE",{});var SB=s(ld);wf=r(SB,"NewModelConfig"),SB.forEach(t),Qa=r(xo,")."),xo.forEach(t),this.h()},h(){c(es,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Je,Ae){b(Je,g,Ae),e(g,v),e(g,u),e(u,f),e(g,p),e(g,d),e(d,h),e(g,yo),e(g,rd),e(rd,Ef),e(g,pt),e(g,td),e(td,ad),e(g,C9),b(Je,Cf,Ae),b(Je,Ve,Ae),e(Ve,He),e(Ve,nd),e(nd,Zn),e(Ve,w9),e(Ve,es),e(es,os),e(Ve,A9),e(Ve,sd),e(sd,rs),e(Ve,L9),e(Ve,ld),e(ld,wf),e(Ve,Qa)},d(Je){Je&&t(g),Je&&t(Cf),Je&&t(Ve)}}}function Sga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Rga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Pga($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var yo=s(u);f=r(yo,"use_auth_token=True"),yo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function Bga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Iga($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var yo=s(u);f=r(yo,"use_auth_token=True"),yo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function Nga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function qga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function jga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Dga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Gga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Oga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Vga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Xga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function zga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Qga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Wga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Uga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Hga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Jga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Yga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Kga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Zga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function eha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function oha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function rha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function tha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function aha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function nha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function sha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function lha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function iha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function dha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function cha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function mha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function fha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function gha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function hha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function uha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function pha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _ha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function bha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function vha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Fha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Tha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Mha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Eha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Cha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function wha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Aha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Lha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function yha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function xha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $ha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function kha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Sha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Rha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Pha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Bha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Iha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Nha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function qha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function jha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Dha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Gha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Oha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Vha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Xha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function zha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Qha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Wha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Uha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Hha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Jha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Yha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Kha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Zha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function eua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function oua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function rua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function tua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function aua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function nua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function sua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function lua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function iua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function dua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function cua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function mua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function fua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function gua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function hua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function uua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function pua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _ua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function bua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function vua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Fua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Tua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Mua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Eua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Cua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function wua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Aua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Lua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function yua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function xua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $ua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function kua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Sua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Rua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Pua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Bua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Iua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Nua($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function qua($){let g,v,u,f,p,d,h,yo,rd,Ef,pt,td,ad,C9,Cf,Ve,He,nd,Zn,w9,es,os,A9,sd,rs,L9,ld,wf,Qa,Je,Ae,yB,id,xB,$B,xo,Wa,kB,Af,SB,Cro,UYe,dd,Lf,ade,y9,wro,nde,Aro,HYe,ts,Lro,sde,yro,xro,lde,$ro,kro,JYe,x9,YYe,RB,Sro,KYe,yf,ZYe,cd,xf,ide,$9,Rro,dde,Pro,eKe,$o,k9,Bro,S9,Iro,PB,Nro,qro,jro,R9,Dro,cde,Gro,Oro,Vro,Pr,P9,Xro,mde,zro,Qro,md,Wro,fde,Uro,Hro,gde,Jro,Yro,Kro,A,$f,hde,Zro,eto,BB,oto,rto,tto,kf,ude,ato,nto,IB,sto,lto,ito,Sf,pde,dto,cto,NB,mto,fto,gto,Rf,_de,hto,uto,qB,pto,_to,bto,Pf,bde,vto,Fto,jB,Tto,Mto,Eto,Bf,vde,Cto,wto,DB,Ato,Lto,yto,If,Fde,xto,$to,GB,kto,Sto,Rto,Nf,Tde,Pto,Bto,OB,Ito,Nto,qto,qf,Mde,jto,Dto,VB,Gto,Oto,Vto,jf,Ede,Xto,zto,XB,Qto,Wto,Uto,Df,Cde,Hto,Jto,zB,Yto,Kto,Zto,Gf,wde,eao,oao,QB,rao,tao,aao,Of,Ade,nao,sao,WB,lao,iao,dao,Vf,Lde,cao,mao,UB,fao,gao,hao,Xf,yde,uao,pao,HB,_ao,bao,vao,zf,xde,Fao,Tao,JB,Mao,Eao,Cao,Qf,$de,wao,Aao,YB,Lao,yao,xao,Wf,kde,$ao,kao,KB,Sao,Rao,Pao,Uf,Sde,Bao,Iao,ZB,Nao,qao,jao,Hf,Rde,Dao,Gao,eI,Oao,Vao,Xao,Jf,Pde,zao,Qao,oI,Wao,Uao,Hao,Yf,Bde,Jao,Yao,rI,Kao,Zao,eno,Kf,Ide,ono,rno,tI,tno,ano,nno,Zf,Nde,sno,lno,aI,ino,dno,cno,eg,qde,mno,fno,nI,gno,hno,uno,og,jde,pno,_no,sI,bno,vno,Fno,rg,Dde,Tno,Mno,lI,Eno,Cno,wno,tg,Gde,Ano,Lno,iI,yno,xno,$no,ag,Ode,kno,Sno,dI,Rno,Pno,Bno,ng,Vde,Ino,Nno,cI,qno,jno,Dno,sg,Xde,Gno,Ono,mI,Vno,Xno,zno,lg,zde,Qno,Wno,fI,Uno,Hno,Jno,ig,Qde,Yno,Kno,gI,Zno,eso,oso,dg,Wde,rso,tso,hI,aso,nso,sso,cg,Ude,lso,iso,uI,dso,cso,mso,mg,Hde,fso,gso,pI,hso,uso,pso,fg,Jde,_so,bso,_I,vso,Fso,Tso,gg,Yde,Mso,Eso,bI,Cso,wso,Aso,hg,Kde,Lso,yso,vI,xso,$so,kso,ug,Zde,Sso,Rso,FI,Pso,Bso,Iso,pg,ece,Nso,qso,TI,jso,Dso,Gso,_g,oce,Oso,Vso,MI,Xso,zso,Qso,bg,rce,Wso,Uso,EI,Hso,Jso,Yso,vg,tce,Kso,Zso,CI,elo,olo,rlo,Fg,ace,tlo,alo,wI,nlo,slo,llo,Tg,nce,ilo,dlo,AI,clo,mlo,flo,Mg,sce,glo,hlo,LI,ulo,plo,_lo,Eg,lce,blo,vlo,yI,Flo,Tlo,Mlo,Cg,ice,Elo,Clo,xI,wlo,Alo,Llo,wg,dce,ylo,xlo,$I,$lo,klo,Slo,Ag,cce,Rlo,Plo,kI,Blo,Ilo,Nlo,Lg,mce,qlo,jlo,SI,Dlo,Glo,Olo,yg,fce,Vlo,Xlo,RI,zlo,Qlo,Wlo,xg,gce,Ulo,Hlo,PI,Jlo,Ylo,Klo,$g,hce,Zlo,eio,BI,oio,rio,tio,kg,uce,aio,nio,II,sio,lio,iio,Sg,pce,dio,cio,NI,mio,fio,gio,Rg,_ce,hio,uio,qI,pio,_io,bio,Pg,bce,vio,Fio,jI,Tio,Mio,Eio,Bg,vce,Cio,wio,DI,Aio,Lio,yio,Ig,Fce,xio,$io,GI,kio,Sio,Rio,Ng,Tce,Pio,Bio,OI,Iio,Nio,qio,qg,Mce,jio,Dio,VI,Gio,Oio,Vio,jg,Ece,Xio,zio,XI,Qio,Wio,Uio,Dg,Cce,Hio,Jio,zI,Yio,Kio,Zio,Gg,wce,edo,odo,QI,rdo,tdo,ado,Og,Ace,ndo,sdo,WI,ldo,ido,ddo,Vg,Lce,cdo,mdo,UI,fdo,gdo,hdo,Xg,yce,udo,pdo,HI,_do,bdo,vdo,zg,xce,Fdo,Tdo,JI,Mdo,Edo,Cdo,Qg,$ce,wdo,Ado,YI,Ldo,ydo,xdo,Wg,kce,$do,kdo,KI,Sdo,Rdo,Pdo,Ug,Sce,Bdo,Ido,ZI,Ndo,qdo,jdo,Hg,Rce,Ddo,Gdo,eN,Odo,Vdo,Xdo,Jg,Pce,zdo,Qdo,oN,Wdo,Udo,Hdo,Yg,Bce,Jdo,Ydo,rN,Kdo,Zdo,eco,Kg,Ice,oco,rco,tN,tco,aco,nco,Zg,Nce,sco,lco,aN,ico,dco,cco,eh,qce,mco,fco,nN,gco,hco,uco,oh,jce,pco,_co,sN,bco,vco,Fco,rh,Dce,Tco,Mco,lN,Eco,Cco,wco,th,Gce,Aco,Lco,iN,yco,xco,$co,ah,Oce,kco,Sco,dN,Rco,Pco,Bco,nh,Vce,Ico,Nco,cN,qco,jco,Dco,sh,Xce,Gco,Oco,mN,Vco,Xco,zco,lh,zce,Qco,Wco,fN,Uco,Hco,Jco,ih,Qce,Yco,Kco,gN,Zco,emo,omo,dh,Wce,rmo,tmo,hN,amo,nmo,smo,ch,Uce,lmo,imo,uN,dmo,cmo,mmo,mh,Hce,fmo,gmo,pN,hmo,umo,pmo,fh,Jce,_mo,bmo,_N,vmo,Fmo,Tmo,gh,Yce,Mmo,Emo,bN,Cmo,wmo,Amo,hh,Kce,Lmo,ymo,vN,xmo,$mo,kmo,uh,Zce,Smo,Rmo,FN,Pmo,Bmo,Imo,ph,eme,Nmo,qmo,TN,jmo,Dmo,Gmo,_h,ome,Omo,Vmo,MN,Xmo,zmo,Qmo,bh,rme,Wmo,Umo,EN,Hmo,Jmo,Ymo,vh,tme,Kmo,Zmo,CN,efo,ofo,rfo,Fh,ame,tfo,afo,wN,nfo,sfo,lfo,Th,nme,ifo,dfo,AN,cfo,mfo,ffo,Mh,sme,gfo,hfo,LN,ufo,pfo,_fo,Eh,lme,bfo,vfo,yN,Ffo,Tfo,Mfo,Ch,ime,Efo,Cfo,xN,wfo,Afo,Lfo,wh,dme,yfo,xfo,$N,$fo,kfo,Sfo,Ah,cme,Rfo,Pfo,kN,Bfo,Ifo,Nfo,Lh,mme,qfo,jfo,SN,Dfo,Gfo,Ofo,yh,fme,Vfo,Xfo,RN,zfo,Qfo,Wfo,xh,gme,Ufo,Hfo,PN,Jfo,Yfo,Kfo,$h,hme,Zfo,ego,BN,ogo,rgo,tgo,kh,ume,ago,ngo,IN,sgo,lgo,igo,Sh,pme,dgo,cgo,NN,mgo,fgo,ggo,Rh,_me,hgo,ugo,qN,pgo,_go,bgo,Ph,bme,vgo,Fgo,jN,Tgo,Mgo,Ego,Bh,vme,Cgo,wgo,DN,Ago,Lgo,ygo,Ih,Fme,xgo,$go,GN,kgo,Sgo,Rgo,Nh,Tme,Pgo,Bgo,ON,Igo,Ngo,qgo,qh,Mme,jgo,Dgo,VN,Ggo,Ogo,Vgo,jh,Eme,Xgo,zgo,XN,Qgo,Wgo,Ugo,Dh,Cme,Hgo,Jgo,zN,Ygo,Kgo,Zgo,Gh,wme,eho,oho,QN,rho,tho,aho,Oh,Ame,nho,sho,WN,lho,iho,dho,Vh,Lme,cho,mho,UN,fho,gho,hho,Xh,yme,uho,pho,HN,_ho,bho,vho,zh,xme,Fho,Tho,JN,Mho,Eho,Cho,Qh,$me,who,Aho,YN,Lho,yho,xho,Wh,kme,$ho,kho,KN,Sho,Rho,Pho,Uh,Bho,Hh,B9,Iho,Sme,Nho,oKe,fd,Jh,Rme,I9,qho,Pme,jho,rKe,ko,N9,Dho,q9,Gho,ZN,Oho,Vho,Xho,j9,zho,Bme,Qho,Who,Uho,Br,D9,Hho,Ime,Jho,Yho,Ua,Kho,Nme,Zho,euo,qme,ouo,ruo,jme,tuo,auo,nuo,k,as,Dme,suo,luo,eq,iuo,duo,oq,cuo,muo,fuo,ns,Gme,guo,huo,rq,uuo,puo,tq,_uo,buo,vuo,ss,Ome,Fuo,Tuo,aq,Muo,Euo,nq,Cuo,wuo,Auo,Yh,Vme,Luo,yuo,sq,xuo,$uo,kuo,ls,Xme,Suo,Ruo,lq,Puo,Buo,iq,Iuo,Nuo,quo,Kh,zme,juo,Duo,dq,Guo,Ouo,Vuo,Zh,Qme,Xuo,zuo,cq,Quo,Wuo,Uuo,eu,Wme,Huo,Juo,mq,Yuo,Kuo,Zuo,is,Ume,epo,opo,fq,rpo,tpo,gq,apo,npo,spo,ds,Hme,lpo,ipo,hq,dpo,cpo,uq,mpo,fpo,gpo,cs,Jme,hpo,upo,pq,ppo,_po,_q,bpo,vpo,Fpo,ou,Yme,Tpo,Mpo,bq,Epo,Cpo,wpo,ru,Kme,Apo,Lpo,vq,ypo,xpo,$po,tu,Zme,kpo,Spo,Fq,Rpo,Ppo,Bpo,ms,efe,Ipo,Npo,Tq,qpo,jpo,Mq,Dpo,Gpo,Opo,au,ofe,Vpo,Xpo,Eq,zpo,Qpo,Wpo,fs,rfe,Upo,Hpo,Cq,Jpo,Ypo,wq,Kpo,Zpo,e_o,gs,tfe,o_o,r_o,Aq,t_o,a_o,Lq,n_o,s_o,l_o,hs,afe,i_o,d_o,yq,c_o,m_o,xq,f_o,g_o,h_o,us,nfe,u_o,p_o,$q,__o,b_o,kq,v_o,F_o,T_o,nu,sfe,M_o,E_o,Sq,C_o,w_o,A_o,ps,lfe,L_o,y_o,Rq,x_o,$_o,Pq,k_o,S_o,R_o,_s,ife,P_o,B_o,Bq,I_o,N_o,Iq,q_o,j_o,D_o,bs,dfe,G_o,O_o,Nq,V_o,X_o,qq,z_o,Q_o,W_o,vs,cfe,U_o,H_o,jq,J_o,Y_o,Dq,K_o,Z_o,ebo,Fs,mfe,obo,rbo,Gq,tbo,abo,Oq,nbo,sbo,lbo,Ts,ffe,ibo,dbo,Vq,cbo,mbo,Xq,fbo,gbo,hbo,Ms,gfe,ubo,pbo,zq,_bo,bbo,Qq,vbo,Fbo,Tbo,su,hfe,Mbo,Ebo,Wq,Cbo,wbo,Abo,Es,ufe,Lbo,ybo,Uq,xbo,$bo,Hq,kbo,Sbo,Rbo,lu,pfe,Pbo,Bbo,Jq,Ibo,Nbo,qbo,Cs,_fe,jbo,Dbo,Yq,Gbo,Obo,Kq,Vbo,Xbo,zbo,ws,bfe,Qbo,Wbo,Zq,Ubo,Hbo,ej,Jbo,Ybo,Kbo,As,vfe,Zbo,e2o,oj,o2o,r2o,rj,t2o,a2o,n2o,iu,Ffe,s2o,l2o,tj,i2o,d2o,c2o,Ls,Tfe,m2o,f2o,aj,g2o,h2o,nj,u2o,p2o,_2o,ys,Mfe,b2o,v2o,sj,F2o,T2o,lj,M2o,E2o,C2o,xs,Efe,w2o,A2o,ij,L2o,y2o,dj,x2o,$2o,k2o,du,Cfe,S2o,R2o,cj,P2o,B2o,I2o,$s,wfe,N2o,q2o,mj,j2o,D2o,fj,G2o,O2o,V2o,ks,Afe,X2o,z2o,gj,Q2o,W2o,hj,U2o,H2o,J2o,Ss,Lfe,Y2o,K2o,uj,Z2o,e1o,pj,o1o,r1o,t1o,Rs,yfe,a1o,n1o,_j,s1o,l1o,bj,i1o,d1o,c1o,Ps,xfe,m1o,f1o,vj,g1o,h1o,Fj,u1o,p1o,_1o,Bs,$fe,b1o,v1o,Tj,F1o,T1o,Mj,M1o,E1o,C1o,Is,kfe,w1o,A1o,Ej,L1o,y1o,Cj,x1o,$1o,k1o,Ns,Sfe,S1o,R1o,wj,P1o,B1o,Aj,I1o,N1o,q1o,cu,Rfe,j1o,D1o,Lj,G1o,O1o,V1o,qs,Pfe,X1o,z1o,yj,Q1o,W1o,xj,U1o,H1o,J1o,mu,Bfe,Y1o,K1o,$j,Z1o,evo,ovo,fu,Ife,rvo,tvo,kj,avo,nvo,svo,js,Nfe,lvo,ivo,Sj,dvo,cvo,Rj,mvo,fvo,gvo,Ds,qfe,hvo,uvo,Pj,pvo,_vo,Bj,bvo,vvo,Fvo,Gs,jfe,Tvo,Mvo,Ij,Evo,Cvo,Nj,wvo,Avo,Lvo,gu,Dfe,yvo,xvo,qj,$vo,kvo,Svo,Os,Gfe,Rvo,Pvo,jj,Bvo,Ivo,Dj,Nvo,qvo,jvo,Vs,Ofe,Dvo,Gvo,Gj,Ovo,Vvo,Oj,Xvo,zvo,Qvo,Xs,Vfe,Wvo,Uvo,Vj,Hvo,Jvo,Xj,Yvo,Kvo,Zvo,zs,Xfe,eFo,oFo,zj,rFo,tFo,Qj,aFo,nFo,sFo,Qs,zfe,lFo,iFo,Wj,dFo,cFo,Uj,mFo,fFo,gFo,Ws,Qfe,hFo,uFo,Hj,pFo,_Fo,Jj,bFo,vFo,FFo,Us,Wfe,TFo,MFo,Yj,EFo,CFo,Kj,wFo,AFo,LFo,Hs,Ufe,yFo,xFo,Zj,$Fo,kFo,eD,SFo,RFo,PFo,hu,Hfe,BFo,IFo,oD,NFo,qFo,jFo,Js,Jfe,DFo,GFo,rD,OFo,VFo,tD,XFo,zFo,QFo,Ys,Yfe,WFo,UFo,aD,HFo,JFo,nD,YFo,KFo,ZFo,uu,Kfe,eTo,oTo,sD,rTo,tTo,aTo,pu,Zfe,nTo,sTo,lD,lTo,iTo,dTo,_u,ege,cTo,mTo,iD,fTo,gTo,hTo,bu,oge,uTo,pTo,dD,_To,bTo,vTo,Ks,rge,FTo,TTo,cD,MTo,ETo,mD,CTo,wTo,ATo,vu,tge,LTo,yTo,fD,xTo,$To,kTo,Zs,age,STo,RTo,gD,PTo,BTo,hD,ITo,NTo,qTo,el,nge,jTo,DTo,uD,GTo,OTo,pD,VTo,XTo,zTo,ol,sge,QTo,WTo,_D,UTo,HTo,bD,JTo,YTo,KTo,rl,lge,ZTo,eMo,vD,oMo,rMo,FD,tMo,aMo,nMo,tl,ige,sMo,lMo,TD,iMo,dMo,MD,cMo,mMo,fMo,al,dge,gMo,hMo,ED,uMo,pMo,CD,_Mo,bMo,vMo,Fu,cge,FMo,TMo,wD,MMo,EMo,CMo,Tu,mge,wMo,AMo,AD,LMo,yMo,xMo,nl,fge,$Mo,kMo,LD,SMo,RMo,yD,PMo,BMo,IMo,sl,gge,NMo,qMo,xD,jMo,DMo,$D,GMo,OMo,VMo,ll,hge,XMo,zMo,kD,QMo,WMo,SD,UMo,HMo,JMo,Mu,uge,YMo,KMo,RD,ZMo,eEo,oEo,Eu,pge,rEo,tEo,PD,aEo,nEo,sEo,Cu,_ge,lEo,iEo,BD,dEo,cEo,mEo,il,bge,fEo,gEo,ID,hEo,uEo,ND,pEo,_Eo,bEo,dl,vge,vEo,FEo,qD,TEo,MEo,jD,EEo,CEo,wEo,wu,Fge,AEo,LEo,DD,yEo,xEo,$Eo,Au,Tge,kEo,SEo,GD,REo,PEo,BEo,Lu,Mge,IEo,NEo,OD,qEo,jEo,DEo,cl,Ege,GEo,OEo,VD,VEo,XEo,XD,zEo,QEo,WEo,ml,Cge,UEo,HEo,zD,JEo,YEo,QD,KEo,ZEo,e4o,yu,wge,o4o,r4o,WD,t4o,a4o,n4o,xu,Age,s4o,l4o,UD,i4o,d4o,c4o,fl,Lge,m4o,f4o,HD,g4o,h4o,JD,u4o,p4o,_4o,gl,yge,b4o,v4o,YD,F4o,T4o,KD,M4o,E4o,C4o,hl,xge,w4o,A4o,ZD,L4o,y4o,eG,x4o,$4o,k4o,ul,$ge,S4o,R4o,oG,P4o,B4o,rG,I4o,N4o,q4o,$u,j4o,ku,G9,D4o,kge,G4o,tKe,gd,Su,Sge,O9,O4o,Rge,V4o,aKe,So,V9,X4o,X9,z4o,tG,Q4o,W4o,U4o,z9,H4o,Pge,J4o,Y4o,K4o,Ye,Q9,Z4o,Bge,eCo,oCo,Ha,rCo,Ige,tCo,aCo,Nge,nCo,sCo,qge,lCo,iCo,dCo,Q,Ru,jge,cCo,mCo,aG,fCo,gCo,hCo,Pu,Dge,uCo,pCo,nG,_Co,bCo,vCo,Bu,Gge,FCo,TCo,sG,MCo,ECo,CCo,Iu,Oge,wCo,ACo,lG,LCo,yCo,xCo,Nu,Vge,$Co,kCo,iG,SCo,RCo,PCo,qu,Xge,BCo,ICo,dG,NCo,qCo,jCo,ju,zge,DCo,GCo,cG,OCo,VCo,XCo,Du,Qge,zCo,QCo,mG,WCo,UCo,HCo,Gu,Wge,JCo,YCo,fG,KCo,ZCo,e3o,Ou,Uge,o3o,r3o,gG,t3o,a3o,n3o,Vu,Hge,s3o,l3o,hG,i3o,d3o,c3o,Xu,Jge,m3o,f3o,uG,g3o,h3o,u3o,zu,Yge,p3o,_3o,pG,b3o,v3o,F3o,Qu,Kge,T3o,M3o,_G,E3o,C3o,w3o,Wu,Zge,A3o,L3o,bG,y3o,x3o,$3o,Uu,ehe,k3o,S3o,vG,R3o,P3o,B3o,Hu,ohe,I3o,N3o,FG,q3o,j3o,D3o,Ju,rhe,G3o,O3o,TG,V3o,X3o,z3o,Yu,the,Q3o,W3o,MG,U3o,H3o,J3o,Ku,ahe,Y3o,K3o,EG,Z3o,e5o,o5o,Zu,nhe,r5o,t5o,CG,a5o,n5o,s5o,ep,she,l5o,i5o,wG,d5o,c5o,m5o,op,lhe,f5o,g5o,AG,h5o,u5o,p5o,rp,ihe,_5o,b5o,LG,v5o,F5o,T5o,tp,dhe,M5o,E5o,yG,C5o,w5o,A5o,ap,che,L5o,y5o,xG,x5o,$5o,k5o,np,mhe,S5o,R5o,$G,P5o,B5o,I5o,sp,fhe,N5o,q5o,kG,j5o,D5o,G5o,lp,ghe,O5o,V5o,SG,X5o,z5o,Q5o,ip,hhe,W5o,U5o,RG,H5o,J5o,Y5o,dp,uhe,K5o,Z5o,PG,e0o,o0o,r0o,cp,phe,t0o,a0o,BG,n0o,s0o,l0o,mp,_he,i0o,d0o,IG,c0o,m0o,f0o,fp,bhe,g0o,h0o,NG,u0o,p0o,_0o,gp,vhe,b0o,v0o,qG,F0o,T0o,M0o,hp,Fhe,E0o,C0o,jG,w0o,A0o,L0o,up,The,y0o,x0o,DG,$0o,k0o,S0o,pp,Mhe,R0o,P0o,GG,B0o,I0o,N0o,_p,Ehe,q0o,j0o,OG,D0o,G0o,O0o,bp,Che,V0o,X0o,VG,z0o,Q0o,W0o,vp,U0o,Fp,H0o,Tp,W9,J0o,whe,Y0o,nKe,hd,Mp,Ahe,U9,K0o,Lhe,Z0o,sKe,Ro,H9,ewo,J9,owo,XG,rwo,two,awo,Y9,nwo,yhe,swo,lwo,iwo,Ke,K9,dwo,xhe,cwo,mwo,ud,fwo,$he,gwo,hwo,khe,uwo,pwo,_wo,ie,Ep,She,bwo,vwo,zG,Fwo,Two,Mwo,Cp,Rhe,Ewo,Cwo,QG,wwo,Awo,Lwo,wp,Phe,ywo,xwo,WG,$wo,kwo,Swo,Ap,Bhe,Rwo,Pwo,UG,Bwo,Iwo,Nwo,Lp,Ihe,qwo,jwo,HG,Dwo,Gwo,Owo,yp,Nhe,Vwo,Xwo,JG,zwo,Qwo,Wwo,xp,qhe,Uwo,Hwo,YG,Jwo,Ywo,Kwo,$p,jhe,Zwo,eAo,KG,oAo,rAo,tAo,kp,Dhe,aAo,nAo,ZG,sAo,lAo,iAo,Sp,Ghe,dAo,cAo,eO,mAo,fAo,gAo,Rp,Ohe,hAo,uAo,oO,pAo,_Ao,bAo,Pp,Vhe,vAo,FAo,rO,TAo,MAo,EAo,Bp,Xhe,CAo,wAo,tO,AAo,LAo,yAo,Ip,zhe,xAo,$Ao,aO,kAo,SAo,RAo,Np,Qhe,PAo,BAo,nO,IAo,NAo,qAo,qp,Whe,jAo,DAo,sO,GAo,OAo,VAo,jp,Uhe,XAo,zAo,lO,QAo,WAo,UAo,Dp,Hhe,HAo,JAo,iO,YAo,KAo,ZAo,Gp,Jhe,e6o,o6o,dO,r6o,t6o,a6o,Op,Yhe,n6o,s6o,cO,l6o,i6o,d6o,Vp,Khe,c6o,m6o,mO,f6o,g6o,h6o,Xp,u6o,zp,p6o,Qp,Z9,_6o,Zhe,b6o,lKe,pd,Wp,eue,ex,v6o,oue,F6o,iKe,Po,ox,T6o,_d,M6o,fO,E6o,C6o,gO,w6o,A6o,L6o,rx,y6o,rue,x6o,$6o,k6o,_t,tx,S6o,tue,R6o,P6o,bd,B6o,aue,I6o,N6o,hO,q6o,j6o,D6o,Up,G6o,Ze,ax,O6o,nue,V6o,X6o,Ja,z6o,sue,Q6o,W6o,lue,U6o,H6o,iue,J6o,Y6o,K6o,y,Hp,due,Z6o,e7o,uO,o7o,r7o,t7o,Jp,cue,a7o,n7o,pO,s7o,l7o,i7o,Yp,mue,d7o,c7o,_O,m7o,f7o,g7o,Kp,fue,h7o,u7o,bO,p7o,_7o,b7o,Zp,gue,v7o,F7o,vO,T7o,M7o,E7o,e_,hue,C7o,w7o,FO,A7o,L7o,y7o,o_,uue,x7o,$7o,TO,k7o,S7o,R7o,r_,pue,P7o,B7o,MO,I7o,N7o,q7o,t_,_ue,j7o,D7o,EO,G7o,O7o,V7o,a_,bue,X7o,z7o,CO,Q7o,W7o,U7o,n_,vue,H7o,J7o,wO,Y7o,K7o,Z7o,s_,Fue,eLo,oLo,AO,rLo,tLo,aLo,l_,Tue,nLo,sLo,LO,lLo,iLo,dLo,i_,Mue,cLo,mLo,yO,fLo,gLo,hLo,d_,Eue,uLo,pLo,xO,_Lo,bLo,vLo,c_,Cue,FLo,TLo,$O,MLo,ELo,CLo,m_,wue,wLo,ALo,kO,LLo,yLo,xLo,f_,Aue,$Lo,kLo,SO,SLo,RLo,PLo,g_,Lue,BLo,ILo,RO,NLo,qLo,jLo,h_,yue,DLo,GLo,PO,OLo,VLo,XLo,u_,xue,zLo,QLo,BO,WLo,ULo,HLo,p_,$ue,JLo,YLo,IO,KLo,ZLo,eyo,__,kue,oyo,ryo,NO,tyo,ayo,nyo,b_,Sue,syo,lyo,qO,iyo,dyo,cyo,v_,Rue,myo,fyo,jO,gyo,hyo,uyo,F_,Pue,pyo,_yo,DO,byo,vyo,Fyo,T_,Bue,Tyo,Myo,GO,Eyo,Cyo,wyo,M_,Iue,Ayo,Lyo,OO,yyo,xyo,$yo,E_,Nue,kyo,Syo,VO,Ryo,Pyo,Byo,C_,que,Iyo,Nyo,XO,qyo,jyo,Dyo,w_,jue,Gyo,Oyo,zO,Vyo,Xyo,zyo,A_,Due,Qyo,Wyo,QO,Uyo,Hyo,Jyo,L_,Gue,Yyo,Kyo,WO,Zyo,e8o,o8o,y_,Oue,r8o,t8o,UO,a8o,n8o,s8o,x_,Vue,l8o,i8o,HO,d8o,c8o,m8o,$_,Xue,f8o,g8o,JO,h8o,u8o,p8o,k_,zue,_8o,b8o,YO,v8o,F8o,T8o,pl,Que,M8o,E8o,KO,C8o,w8o,ZO,A8o,L8o,y8o,S_,Wue,x8o,$8o,eV,k8o,S8o,R8o,R_,Uue,P8o,B8o,oV,I8o,N8o,q8o,P_,Hue,j8o,D8o,rV,G8o,O8o,V8o,B_,Jue,X8o,z8o,tV,Q8o,W8o,U8o,I_,Yue,H8o,J8o,aV,Y8o,K8o,Z8o,N_,Kue,e9o,o9o,nV,r9o,t9o,a9o,q_,Zue,n9o,s9o,sV,l9o,i9o,d9o,j_,epe,c9o,m9o,lV,f9o,g9o,h9o,D_,ope,u9o,p9o,iV,_9o,b9o,v9o,G_,rpe,F9o,T9o,dV,M9o,E9o,C9o,O_,tpe,w9o,A9o,cV,L9o,y9o,x9o,V_,ape,$9o,k9o,mV,S9o,R9o,P9o,X_,npe,B9o,I9o,fV,N9o,q9o,j9o,z_,spe,D9o,G9o,gV,O9o,V9o,X9o,Q_,lpe,z9o,Q9o,hV,W9o,U9o,H9o,W_,ipe,J9o,Y9o,uV,K9o,Z9o,exo,U_,dpe,oxo,rxo,pV,txo,axo,nxo,H_,cpe,sxo,lxo,_V,ixo,dxo,cxo,J_,mpe,mxo,fxo,bV,gxo,hxo,uxo,Y_,fpe,pxo,_xo,vV,bxo,vxo,Fxo,K_,gpe,Txo,Mxo,FV,Exo,Cxo,wxo,Z_,hpe,Axo,Lxo,TV,yxo,xxo,$xo,eb,upe,kxo,Sxo,MV,Rxo,Pxo,Bxo,ob,ppe,Ixo,Nxo,EV,qxo,jxo,Dxo,rb,_pe,Gxo,Oxo,CV,Vxo,Xxo,zxo,tb,bpe,Qxo,Wxo,wV,Uxo,Hxo,Jxo,ab,vpe,Yxo,Kxo,AV,Zxo,e$o,o$o,nb,Fpe,r$o,t$o,LV,a$o,n$o,s$o,sb,Tpe,l$o,i$o,yV,d$o,c$o,m$o,lb,Mpe,f$o,g$o,xV,h$o,u$o,p$o,ib,Epe,_$o,b$o,$V,v$o,F$o,T$o,db,Cpe,M$o,E$o,kV,C$o,w$o,A$o,cb,wpe,L$o,y$o,SV,x$o,$$o,k$o,mb,Ape,S$o,R$o,RV,P$o,B$o,I$o,fb,Lpe,N$o,q$o,PV,j$o,D$o,G$o,gb,ype,O$o,V$o,BV,X$o,z$o,Q$o,hb,xpe,W$o,U$o,IV,H$o,J$o,Y$o,ub,$pe,K$o,Z$o,NV,eko,oko,rko,pb,kpe,tko,ako,qV,nko,sko,lko,_b,Spe,iko,dko,jV,cko,mko,fko,bb,Rpe,gko,hko,DV,uko,pko,_ko,vb,Ppe,bko,vko,GV,Fko,Tko,Mko,Fb,Bpe,Eko,Cko,OV,wko,Ako,Lko,Tb,Ipe,yko,xko,VV,$ko,kko,Sko,Mb,Npe,Rko,Pko,XV,Bko,Iko,Nko,Eb,qpe,qko,jko,zV,Dko,Gko,Oko,Cb,jpe,Vko,Xko,QV,zko,Qko,Wko,wb,Dpe,Uko,Hko,WV,Jko,Yko,Kko,Ab,Gpe,Zko,eSo,UV,oSo,rSo,tSo,Lb,Ope,aSo,nSo,HV,sSo,lSo,iSo,yb,Vpe,dSo,cSo,JV,mSo,fSo,gSo,xb,Xpe,hSo,uSo,YV,pSo,_So,bSo,$b,zpe,vSo,FSo,KV,TSo,MSo,ESo,kb,Qpe,CSo,wSo,ZV,ASo,LSo,ySo,Sb,Wpe,xSo,$So,eX,kSo,SSo,RSo,Rb,Upe,PSo,BSo,oX,ISo,NSo,qSo,Pb,Hpe,jSo,DSo,rX,GSo,OSo,VSo,Bb,Jpe,XSo,zSo,tX,QSo,WSo,USo,Ib,Ype,HSo,JSo,aX,YSo,KSo,ZSo,Nb,Kpe,eRo,oRo,nX,rRo,tRo,aRo,qb,Zpe,nRo,sRo,sX,lRo,iRo,dRo,jb,e_e,cRo,mRo,lX,fRo,gRo,hRo,Db,o_e,uRo,pRo,iX,_Ro,bRo,vRo,Gb,r_e,FRo,TRo,dX,MRo,ERo,CRo,Ob,t_e,wRo,ARo,cX,LRo,yRo,xRo,Vb,a_e,$Ro,kRo,mX,SRo,RRo,PRo,Xb,n_e,BRo,IRo,fX,NRo,qRo,jRo,zb,s_e,DRo,GRo,gX,ORo,VRo,XRo,Qb,l_e,zRo,QRo,hX,WRo,URo,HRo,Wb,i_e,JRo,YRo,uX,KRo,ZRo,ePo,Ub,d_e,oPo,rPo,pX,tPo,aPo,nPo,Hb,c_e,sPo,lPo,_X,iPo,dPo,cPo,Jb,m_e,mPo,fPo,bX,gPo,hPo,uPo,Yb,f_e,pPo,_Po,vX,bPo,vPo,FPo,Kb,g_e,TPo,MPo,FX,EPo,CPo,wPo,Zb,h_e,APo,LPo,TX,yPo,xPo,$Po,e2,u_e,kPo,SPo,MX,RPo,PPo,BPo,o2,p_e,IPo,NPo,EX,qPo,jPo,DPo,r2,__e,GPo,OPo,CX,VPo,XPo,zPo,t2,b_e,QPo,WPo,wX,UPo,HPo,JPo,a2,v_e,YPo,KPo,AX,ZPo,eBo,oBo,n2,F_e,rBo,tBo,LX,aBo,nBo,sBo,s2,lBo,T_e,iBo,dBo,M_e,cBo,mBo,l2,dKe,vd,i2,E_e,nx,fBo,C_e,gBo,cKe,Bo,sx,hBo,Fd,uBo,yX,pBo,_Bo,xX,bBo,vBo,FBo,lx,TBo,w_e,MBo,EBo,CBo,bt,ix,wBo,A_e,ABo,LBo,Td,yBo,L_e,xBo,$Bo,$X,kBo,SBo,RBo,d2,PBo,eo,dx,BBo,y_e,IBo,NBo,Ya,qBo,x_e,jBo,DBo,$_e,GBo,OBo,k_e,VBo,XBo,zBo,G,c2,S_e,QBo,WBo,kX,UBo,HBo,JBo,m2,R_e,YBo,KBo,SX,ZBo,eIo,oIo,f2,P_e,rIo,tIo,RX,aIo,nIo,sIo,g2,B_e,lIo,iIo,PX,dIo,cIo,mIo,h2,I_e,fIo,gIo,BX,hIo,uIo,pIo,u2,N_e,_Io,bIo,IX,vIo,FIo,TIo,p2,q_e,MIo,EIo,NX,CIo,wIo,AIo,_2,j_e,LIo,yIo,qX,xIo,$Io,kIo,b2,D_e,SIo,RIo,jX,PIo,BIo,IIo,v2,G_e,NIo,qIo,DX,jIo,DIo,GIo,F2,O_e,OIo,VIo,GX,XIo,zIo,QIo,T2,V_e,WIo,UIo,OX,HIo,JIo,YIo,M2,X_e,KIo,ZIo,VX,eNo,oNo,rNo,E2,z_e,tNo,aNo,XX,nNo,sNo,lNo,C2,Q_e,iNo,dNo,zX,cNo,mNo,fNo,w2,W_e,gNo,hNo,QX,uNo,pNo,_No,A2,U_e,bNo,vNo,WX,FNo,TNo,MNo,L2,H_e,ENo,CNo,UX,wNo,ANo,LNo,y2,J_e,yNo,xNo,HX,$No,kNo,SNo,x2,Y_e,RNo,PNo,JX,BNo,INo,NNo,$2,K_e,qNo,jNo,YX,DNo,GNo,ONo,k2,Z_e,VNo,XNo,KX,zNo,QNo,WNo,S2,ebe,UNo,HNo,ZX,JNo,YNo,KNo,R2,obe,ZNo,eqo,ez,oqo,rqo,tqo,P2,rbe,aqo,nqo,oz,sqo,lqo,iqo,B2,tbe,dqo,cqo,rz,mqo,fqo,gqo,I2,abe,hqo,uqo,tz,pqo,_qo,bqo,N2,nbe,vqo,Fqo,az,Tqo,Mqo,Eqo,q2,sbe,Cqo,wqo,nz,Aqo,Lqo,yqo,j2,lbe,xqo,$qo,sz,kqo,Sqo,Rqo,D2,ibe,Pqo,Bqo,lz,Iqo,Nqo,qqo,G2,dbe,jqo,Dqo,iz,Gqo,Oqo,Vqo,O2,cbe,Xqo,zqo,dz,Qqo,Wqo,Uqo,V2,mbe,Hqo,Jqo,cz,Yqo,Kqo,Zqo,X2,fbe,ejo,ojo,mz,rjo,tjo,ajo,z2,gbe,njo,sjo,fz,ljo,ijo,djo,Q2,hbe,cjo,mjo,gz,fjo,gjo,hjo,W2,ube,ujo,pjo,hz,_jo,bjo,vjo,U2,pbe,Fjo,Tjo,uz,Mjo,Ejo,Cjo,H2,_be,wjo,Ajo,pz,Ljo,yjo,xjo,J2,bbe,$jo,kjo,_z,Sjo,Rjo,Pjo,Y2,vbe,Bjo,Ijo,bz,Njo,qjo,jjo,K2,Fbe,Djo,Gjo,vz,Ojo,Vjo,Xjo,Z2,Tbe,zjo,Qjo,Fz,Wjo,Ujo,Hjo,e1,Mbe,Jjo,Yjo,Tz,Kjo,Zjo,eDo,o1,Ebe,oDo,rDo,Mz,tDo,aDo,nDo,r1,Cbe,sDo,lDo,Ez,iDo,dDo,cDo,t1,wbe,mDo,fDo,Cz,gDo,hDo,uDo,a1,pDo,Abe,_Do,bDo,Lbe,vDo,FDo,n1,mKe,Md,s1,ybe,cx,TDo,xbe,MDo,fKe,Io,mx,EDo,Ed,CDo,wz,wDo,ADo,Az,LDo,yDo,xDo,fx,$Do,$be,kDo,SDo,RDo,vt,gx,PDo,kbe,BDo,IDo,Cd,NDo,Sbe,qDo,jDo,Lz,DDo,GDo,ODo,l1,VDo,oo,hx,XDo,Rbe,zDo,QDo,Ka,WDo,Pbe,UDo,HDo,Bbe,JDo,YDo,Ibe,KDo,ZDo,eGo,z,i1,Nbe,oGo,rGo,yz,tGo,aGo,nGo,d1,qbe,sGo,lGo,xz,iGo,dGo,cGo,c1,jbe,mGo,fGo,$z,gGo,hGo,uGo,m1,Dbe,pGo,_Go,kz,bGo,vGo,FGo,f1,Gbe,TGo,MGo,Sz,EGo,CGo,wGo,g1,Obe,AGo,LGo,Rz,yGo,xGo,$Go,h1,Vbe,kGo,SGo,Pz,RGo,PGo,BGo,u1,Xbe,IGo,NGo,Bz,qGo,jGo,DGo,p1,zbe,GGo,OGo,Iz,VGo,XGo,zGo,_1,Qbe,QGo,WGo,Nz,UGo,HGo,JGo,b1,Wbe,YGo,KGo,qz,ZGo,eOo,oOo,v1,Ube,rOo,tOo,jz,aOo,nOo,sOo,F1,Hbe,lOo,iOo,Dz,dOo,cOo,mOo,T1,Jbe,fOo,gOo,Gz,hOo,uOo,pOo,M1,Ybe,_Oo,bOo,Oz,vOo,FOo,TOo,E1,Kbe,MOo,EOo,Vz,COo,wOo,AOo,C1,Zbe,LOo,yOo,Xz,xOo,$Oo,kOo,w1,e2e,SOo,ROo,zz,POo,BOo,IOo,A1,o2e,NOo,qOo,Qz,jOo,DOo,GOo,L1,r2e,OOo,VOo,Wz,XOo,zOo,QOo,y1,t2e,WOo,UOo,Uz,HOo,JOo,YOo,x1,a2e,KOo,ZOo,Hz,eVo,oVo,rVo,$1,n2e,tVo,aVo,Jz,nVo,sVo,lVo,k1,s2e,iVo,dVo,Yz,cVo,mVo,fVo,S1,l2e,gVo,hVo,Kz,uVo,pVo,_Vo,R1,i2e,bVo,vVo,Zz,FVo,TVo,MVo,P1,d2e,EVo,CVo,eQ,wVo,AVo,LVo,B1,c2e,yVo,xVo,oQ,$Vo,kVo,SVo,I1,m2e,RVo,PVo,rQ,BVo,IVo,NVo,N1,f2e,qVo,jVo,tQ,DVo,GVo,OVo,q1,g2e,VVo,XVo,aQ,zVo,QVo,WVo,j1,h2e,UVo,HVo,nQ,JVo,YVo,KVo,D1,u2e,ZVo,eXo,sQ,oXo,rXo,tXo,G1,p2e,aXo,nXo,lQ,sXo,lXo,iXo,O1,_2e,dXo,cXo,iQ,mXo,fXo,gXo,V1,b2e,hXo,uXo,dQ,pXo,_Xo,bXo,X1,v2e,vXo,FXo,cQ,TXo,MXo,EXo,z1,F2e,CXo,wXo,mQ,AXo,LXo,yXo,Q1,T2e,xXo,$Xo,fQ,kXo,SXo,RXo,W1,M2e,PXo,BXo,gQ,IXo,NXo,qXo,U1,E2e,jXo,DXo,hQ,GXo,OXo,VXo,H1,XXo,C2e,zXo,QXo,w2e,WXo,UXo,J1,gKe,wd,Y1,A2e,ux,HXo,L2e,JXo,hKe,No,px,YXo,Ad,KXo,uQ,ZXo,ezo,pQ,ozo,rzo,tzo,_x,azo,y2e,nzo,szo,lzo,Ft,bx,izo,x2e,dzo,czo,Ld,mzo,$2e,fzo,gzo,_Q,hzo,uzo,pzo,K1,_zo,ro,vx,bzo,k2e,vzo,Fzo,Za,Tzo,S2e,Mzo,Ezo,R2e,Czo,wzo,P2e,Azo,Lzo,yzo,U,Z1,B2e,xzo,$zo,bQ,kzo,Szo,Rzo,ev,I2e,Pzo,Bzo,vQ,Izo,Nzo,qzo,ov,N2e,jzo,Dzo,FQ,Gzo,Ozo,Vzo,rv,q2e,Xzo,zzo,TQ,Qzo,Wzo,Uzo,tv,j2e,Hzo,Jzo,MQ,Yzo,Kzo,Zzo,av,D2e,eQo,oQo,EQ,rQo,tQo,aQo,nv,G2e,nQo,sQo,CQ,lQo,iQo,dQo,sv,O2e,cQo,mQo,wQ,fQo,gQo,hQo,lv,V2e,uQo,pQo,AQ,_Qo,bQo,vQo,iv,X2e,FQo,TQo,LQ,MQo,EQo,CQo,dv,z2e,wQo,AQo,yQ,LQo,yQo,xQo,cv,Q2e,$Qo,kQo,xQ,SQo,RQo,PQo,mv,W2e,BQo,IQo,$Q,NQo,qQo,jQo,fv,U2e,DQo,GQo,kQ,OQo,VQo,XQo,gv,H2e,zQo,QQo,SQ,WQo,UQo,HQo,hv,J2e,JQo,YQo,RQ,KQo,ZQo,eWo,uv,Y2e,oWo,rWo,PQ,tWo,aWo,nWo,pv,K2e,sWo,lWo,BQ,iWo,dWo,cWo,_v,Z2e,mWo,fWo,IQ,gWo,hWo,uWo,bv,e1e,pWo,_Wo,NQ,bWo,vWo,FWo,vv,o1e,TWo,MWo,qQ,EWo,CWo,wWo,Fv,r1e,AWo,LWo,jQ,yWo,xWo,$Wo,Tv,t1e,kWo,SWo,DQ,RWo,PWo,BWo,Mv,a1e,IWo,NWo,GQ,qWo,jWo,DWo,Ev,n1e,GWo,OWo,OQ,VWo,XWo,zWo,Cv,s1e,QWo,WWo,VQ,UWo,HWo,JWo,wv,l1e,YWo,KWo,XQ,ZWo,eUo,oUo,Av,i1e,rUo,tUo,zQ,aUo,nUo,sUo,Lv,d1e,lUo,iUo,QQ,dUo,cUo,mUo,yv,c1e,fUo,gUo,WQ,hUo,uUo,pUo,xv,m1e,_Uo,bUo,UQ,vUo,FUo,TUo,$v,f1e,MUo,EUo,HQ,CUo,wUo,AUo,kv,g1e,LUo,yUo,JQ,xUo,$Uo,kUo,Sv,h1e,SUo,RUo,YQ,PUo,BUo,IUo,Rv,u1e,NUo,qUo,p1e,jUo,DUo,GUo,Pv,_1e,OUo,VUo,KQ,XUo,zUo,QUo,Bv,b1e,WUo,UUo,ZQ,HUo,JUo,YUo,Iv,v1e,KUo,ZUo,eW,eHo,oHo,rHo,Nv,F1e,tHo,aHo,oW,nHo,sHo,lHo,qv,iHo,T1e,dHo,cHo,M1e,mHo,fHo,jv,uKe,yd,Dv,E1e,Fx,gHo,C1e,hHo,pKe,qo,Tx,uHo,xd,pHo,rW,_Ho,bHo,tW,vHo,FHo,THo,Mx,MHo,w1e,EHo,CHo,wHo,Tt,Ex,AHo,A1e,LHo,yHo,$d,xHo,L1e,$Ho,kHo,aW,SHo,RHo,PHo,Gv,BHo,to,Cx,IHo,y1e,NHo,qHo,en,jHo,x1e,DHo,GHo,$1e,OHo,VHo,k1e,XHo,zHo,QHo,me,Ov,S1e,WHo,UHo,nW,HHo,JHo,YHo,Vv,R1e,KHo,ZHo,sW,eJo,oJo,rJo,Xv,P1e,tJo,aJo,lW,nJo,sJo,lJo,zv,B1e,iJo,dJo,iW,cJo,mJo,fJo,Qv,I1e,gJo,hJo,dW,uJo,pJo,_Jo,Wv,N1e,bJo,vJo,cW,FJo,TJo,MJo,Uv,q1e,EJo,CJo,mW,wJo,AJo,LJo,Hv,j1e,yJo,xJo,fW,$Jo,kJo,SJo,Jv,D1e,RJo,PJo,gW,BJo,IJo,NJo,Yv,G1e,qJo,jJo,hW,DJo,GJo,OJo,Kv,O1e,VJo,XJo,uW,zJo,QJo,WJo,Zv,V1e,UJo,HJo,pW,JJo,YJo,KJo,eF,X1e,ZJo,eYo,_W,oYo,rYo,tYo,oF,z1e,aYo,nYo,bW,sYo,lYo,iYo,rF,Q1e,dYo,cYo,vW,mYo,fYo,gYo,tF,W1e,hYo,uYo,FW,pYo,_Yo,bYo,aF,U1e,vYo,FYo,TW,TYo,MYo,EYo,nF,H1e,CYo,wYo,MW,AYo,LYo,yYo,sF,J1e,xYo,$Yo,EW,kYo,SYo,RYo,lF,Y1e,PYo,BYo,CW,IYo,NYo,qYo,iF,jYo,K1e,DYo,GYo,Z1e,OYo,VYo,dF,_Ke,kd,cF,eve,wx,XYo,ove,zYo,bKe,jo,Ax,QYo,Sd,WYo,wW,UYo,HYo,AW,JYo,YYo,KYo,Lx,ZYo,rve,eKo,oKo,rKo,Mt,yx,tKo,tve,aKo,nKo,Rd,sKo,ave,lKo,iKo,LW,dKo,cKo,mKo,mF,fKo,ao,xx,gKo,nve,hKo,uKo,on,pKo,sve,_Ko,bKo,lve,vKo,FKo,ive,TKo,MKo,EKo,q,fF,dve,CKo,wKo,yW,AKo,LKo,yKo,gF,cve,xKo,$Ko,xW,kKo,SKo,RKo,hF,mve,PKo,BKo,$W,IKo,NKo,qKo,uF,fve,jKo,DKo,kW,GKo,OKo,VKo,pF,gve,XKo,zKo,SW,QKo,WKo,UKo,_F,hve,HKo,JKo,RW,YKo,KKo,ZKo,bF,uve,eZo,oZo,PW,rZo,tZo,aZo,vF,pve,nZo,sZo,BW,lZo,iZo,dZo,FF,_ve,cZo,mZo,IW,fZo,gZo,hZo,TF,bve,uZo,pZo,NW,_Zo,bZo,vZo,MF,vve,FZo,TZo,qW,MZo,EZo,CZo,EF,Fve,wZo,AZo,jW,LZo,yZo,xZo,CF,Tve,$Zo,kZo,DW,SZo,RZo,PZo,wF,Mve,BZo,IZo,GW,NZo,qZo,jZo,AF,Eve,DZo,GZo,OW,OZo,VZo,XZo,LF,Cve,zZo,QZo,VW,WZo,UZo,HZo,yF,wve,JZo,YZo,XW,KZo,ZZo,eer,xF,Ave,oer,rer,zW,ter,aer,ner,$F,Lve,ser,ler,QW,ier,der,cer,kF,yve,mer,fer,WW,ger,her,uer,SF,xve,per,_er,UW,ber,ver,Fer,RF,$ve,Ter,Mer,HW,Eer,Cer,wer,PF,kve,Aer,Ler,JW,yer,xer,$er,BF,Sve,ker,Ser,YW,Rer,Per,Ber,IF,Rve,Ier,Ner,KW,qer,jer,Der,NF,Pve,Ger,Oer,ZW,Ver,Xer,zer,qF,Bve,Qer,Wer,eU,Uer,Her,Jer,jF,Ive,Yer,Ker,oU,Zer,eor,oor,DF,Nve,ror,tor,rU,aor,nor,sor,GF,qve,lor,ior,tU,dor,cor,mor,OF,jve,gor,hor,aU,uor,por,_or,VF,Dve,bor,vor,nU,For,Tor,Mor,XF,Gve,Eor,Cor,sU,wor,Aor,Lor,zF,Ove,yor,xor,lU,$or,kor,Sor,QF,Vve,Ror,Por,iU,Bor,Ior,Nor,WF,Xve,qor,jor,dU,Dor,Gor,Oor,UF,zve,Vor,Xor,cU,zor,Qor,Wor,HF,Qve,Uor,Hor,mU,Jor,Yor,Kor,JF,Wve,Zor,err,fU,orr,rrr,trr,YF,Uve,arr,nrr,gU,srr,lrr,irr,KF,Hve,drr,crr,hU,mrr,frr,grr,ZF,Jve,hrr,urr,uU,prr,_rr,brr,eT,Yve,vrr,Frr,pU,Trr,Mrr,Err,oT,Kve,Crr,wrr,_U,Arr,Lrr,yrr,rT,Zve,xrr,$rr,bU,krr,Srr,Rrr,tT,eFe,Prr,Brr,vU,Irr,Nrr,qrr,aT,oFe,jrr,Drr,FU,Grr,Orr,Vrr,nT,rFe,Xrr,zrr,TU,Qrr,Wrr,Urr,sT,tFe,Hrr,Jrr,MU,Yrr,Krr,Zrr,lT,aFe,etr,otr,EU,rtr,ttr,atr,iT,nFe,ntr,str,CU,ltr,itr,dtr,dT,sFe,ctr,mtr,wU,ftr,gtr,htr,cT,lFe,utr,ptr,AU,_tr,btr,vtr,mT,Ftr,iFe,Ttr,Mtr,dFe,Etr,Ctr,fT,vKe,Pd,gT,cFe,$x,wtr,mFe,Atr,FKe,Do,kx,Ltr,Bd,ytr,LU,xtr,$tr,yU,ktr,Str,Rtr,Sx,Ptr,fFe,Btr,Itr,Ntr,Et,Rx,qtr,gFe,jtr,Dtr,Id,Gtr,hFe,Otr,Vtr,xU,Xtr,ztr,Qtr,hT,Wtr,no,Px,Utr,uFe,Htr,Jtr,rn,Ytr,pFe,Ktr,Ztr,_Fe,ear,oar,bFe,rar,tar,aar,Z,uT,vFe,nar,sar,$U,lar,iar,dar,pT,FFe,car,mar,kU,far,gar,har,_T,TFe,uar,par,SU,_ar,bar,Far,bT,MFe,Tar,Mar,RU,Ear,Car,war,vT,EFe,Aar,Lar,PU,yar,xar,$ar,FT,CFe,kar,Sar,BU,Rar,Par,Bar,TT,wFe,Iar,Nar,IU,qar,jar,Dar,MT,AFe,Gar,Oar,NU,Var,Xar,zar,ET,LFe,Qar,War,qU,Uar,Har,Jar,CT,yFe,Yar,Kar,jU,Zar,enr,onr,wT,xFe,rnr,tnr,DU,anr,nnr,snr,AT,$Fe,lnr,inr,GU,dnr,cnr,mnr,LT,kFe,fnr,gnr,OU,hnr,unr,pnr,yT,SFe,_nr,bnr,VU,vnr,Fnr,Tnr,xT,RFe,Mnr,Enr,XU,Cnr,wnr,Anr,$T,PFe,Lnr,ynr,zU,xnr,$nr,knr,kT,BFe,Snr,Rnr,QU,Pnr,Bnr,Inr,ST,IFe,Nnr,qnr,WU,jnr,Dnr,Gnr,RT,NFe,Onr,Vnr,UU,Xnr,znr,Qnr,PT,qFe,Wnr,Unr,HU,Hnr,Jnr,Ynr,BT,jFe,Knr,Znr,JU,esr,osr,rsr,IT,DFe,tsr,asr,YU,nsr,ssr,lsr,NT,GFe,isr,dsr,KU,csr,msr,fsr,qT,OFe,gsr,hsr,ZU,usr,psr,_sr,jT,VFe,bsr,vsr,eH,Fsr,Tsr,Msr,DT,XFe,Esr,Csr,oH,wsr,Asr,Lsr,GT,zFe,ysr,xsr,rH,$sr,ksr,Ssr,OT,QFe,Rsr,Psr,tH,Bsr,Isr,Nsr,VT,WFe,qsr,jsr,aH,Dsr,Gsr,Osr,XT,UFe,Vsr,Xsr,nH,zsr,Qsr,Wsr,zT,HFe,Usr,Hsr,sH,Jsr,Ysr,Ksr,QT,JFe,Zsr,elr,lH,olr,rlr,tlr,WT,alr,YFe,nlr,slr,KFe,llr,ilr,UT,TKe,Nd,HT,ZFe,Bx,dlr,eTe,clr,MKe,Go,Ix,mlr,qd,flr,iH,glr,hlr,dH,ulr,plr,_lr,Nx,blr,oTe,vlr,Flr,Tlr,Ct,qx,Mlr,rTe,Elr,Clr,jd,wlr,tTe,Alr,Llr,cH,ylr,xlr,$lr,JT,klr,so,jx,Slr,aTe,Rlr,Plr,tn,Blr,nTe,Ilr,Nlr,sTe,qlr,jlr,lTe,Dlr,Glr,Olr,Ue,YT,iTe,Vlr,Xlr,mH,zlr,Qlr,Wlr,KT,dTe,Ulr,Hlr,fH,Jlr,Ylr,Klr,ZT,cTe,Zlr,eir,gH,oir,rir,tir,eM,mTe,air,nir,hH,sir,lir,iir,oM,fTe,dir,cir,uH,mir,fir,gir,rM,gTe,hir,uir,pH,pir,_ir,bir,tM,hTe,vir,Fir,_H,Tir,Mir,Eir,aM,Cir,uTe,wir,Air,pTe,Lir,yir,nM,EKe,Dd,sM,_Te,Dx,xir,bTe,$ir,CKe,Oo,Gx,kir,Gd,Sir,bH,Rir,Pir,vH,Bir,Iir,Nir,Ox,qir,vTe,jir,Dir,Gir,wt,Vx,Oir,FTe,Vir,Xir,Od,zir,TTe,Qir,Wir,FH,Uir,Hir,Jir,lM,Yir,lo,Xx,Kir,MTe,Zir,edr,an,odr,ETe,rdr,tdr,CTe,adr,ndr,wTe,sdr,ldr,idr,J,iM,ATe,ddr,cdr,TH,mdr,fdr,gdr,dM,LTe,hdr,udr,MH,pdr,_dr,bdr,cM,yTe,vdr,Fdr,EH,Tdr,Mdr,Edr,mM,xTe,Cdr,wdr,CH,Adr,Ldr,ydr,fM,$Te,xdr,$dr,wH,kdr,Sdr,Rdr,gM,kTe,Pdr,Bdr,AH,Idr,Ndr,qdr,hM,STe,jdr,Ddr,LH,Gdr,Odr,Vdr,uM,RTe,Xdr,zdr,yH,Qdr,Wdr,Udr,pM,PTe,Hdr,Jdr,xH,Ydr,Kdr,Zdr,_M,BTe,ecr,ocr,$H,rcr,tcr,acr,bM,ITe,ncr,scr,kH,lcr,icr,dcr,vM,NTe,ccr,mcr,SH,fcr,gcr,hcr,FM,qTe,ucr,pcr,RH,_cr,bcr,vcr,TM,jTe,Fcr,Tcr,PH,Mcr,Ecr,Ccr,MM,DTe,wcr,Acr,BH,Lcr,ycr,xcr,EM,GTe,$cr,kcr,IH,Scr,Rcr,Pcr,CM,OTe,Bcr,Icr,NH,Ncr,qcr,jcr,wM,VTe,Dcr,Gcr,qH,Ocr,Vcr,Xcr,AM,XTe,zcr,Qcr,jH,Wcr,Ucr,Hcr,LM,zTe,Jcr,Ycr,DH,Kcr,Zcr,emr,yM,QTe,omr,rmr,GH,tmr,amr,nmr,xM,WTe,smr,lmr,OH,imr,dmr,cmr,$M,UTe,mmr,fmr,VH,gmr,hmr,umr,kM,HTe,pmr,_mr,XH,bmr,vmr,Fmr,SM,JTe,Tmr,Mmr,zH,Emr,Cmr,wmr,RM,YTe,Amr,Lmr,QH,ymr,xmr,$mr,PM,KTe,kmr,Smr,WH,Rmr,Pmr,Bmr,BM,ZTe,Imr,Nmr,UH,qmr,jmr,Dmr,IM,eMe,Gmr,Omr,HH,Vmr,Xmr,zmr,NM,oMe,Qmr,Wmr,JH,Umr,Hmr,Jmr,qM,rMe,Ymr,Kmr,YH,Zmr,efr,ofr,jM,tMe,rfr,tfr,KH,afr,nfr,sfr,DM,aMe,lfr,ifr,ZH,dfr,cfr,mfr,GM,nMe,ffr,gfr,eJ,hfr,ufr,pfr,OM,sMe,_fr,bfr,oJ,vfr,Ffr,Tfr,VM,lMe,Mfr,Efr,rJ,Cfr,wfr,Afr,XM,iMe,Lfr,yfr,tJ,xfr,$fr,kfr,zM,dMe,Sfr,Rfr,aJ,Pfr,Bfr,Ifr,QM,Nfr,cMe,qfr,jfr,mMe,Dfr,Gfr,WM,wKe,Vd,UM,fMe,zx,Ofr,gMe,Vfr,AKe,Vo,Qx,Xfr,Xd,zfr,nJ,Qfr,Wfr,sJ,Ufr,Hfr,Jfr,Wx,Yfr,hMe,Kfr,Zfr,egr,At,Ux,ogr,uMe,rgr,tgr,zd,agr,pMe,ngr,sgr,lJ,lgr,igr,dgr,HM,cgr,io,Hx,mgr,_Me,fgr,ggr,nn,hgr,bMe,ugr,pgr,vMe,_gr,bgr,FMe,vgr,Fgr,Tgr,V,JM,TMe,Mgr,Egr,iJ,Cgr,wgr,Agr,YM,MMe,Lgr,ygr,dJ,xgr,$gr,kgr,KM,EMe,Sgr,Rgr,cJ,Pgr,Bgr,Igr,ZM,CMe,Ngr,qgr,mJ,jgr,Dgr,Ggr,eE,wMe,Ogr,Vgr,fJ,Xgr,zgr,Qgr,oE,AMe,Wgr,Ugr,gJ,Hgr,Jgr,Ygr,rE,LMe,Kgr,Zgr,hJ,ehr,ohr,rhr,tE,yMe,thr,ahr,uJ,nhr,shr,lhr,aE,xMe,ihr,dhr,pJ,chr,mhr,fhr,nE,$Me,ghr,hhr,_J,uhr,phr,_hr,sE,kMe,bhr,vhr,bJ,Fhr,Thr,Mhr,lE,SMe,Ehr,Chr,vJ,whr,Ahr,Lhr,iE,RMe,yhr,xhr,FJ,$hr,khr,Shr,dE,PMe,Rhr,Phr,TJ,Bhr,Ihr,Nhr,cE,BMe,qhr,jhr,MJ,Dhr,Ghr,Ohr,mE,IMe,Vhr,Xhr,EJ,zhr,Qhr,Whr,fE,NMe,Uhr,Hhr,CJ,Jhr,Yhr,Khr,gE,qMe,Zhr,eur,wJ,our,rur,tur,hE,jMe,aur,nur,AJ,sur,lur,iur,uE,DMe,dur,cur,LJ,mur,fur,gur,pE,GMe,hur,uur,yJ,pur,_ur,bur,_E,OMe,vur,Fur,xJ,Tur,Mur,Eur,bE,VMe,Cur,wur,$J,Aur,Lur,yur,vE,XMe,xur,$ur,kJ,kur,Sur,Rur,FE,zMe,Pur,Bur,SJ,Iur,Nur,qur,TE,QMe,jur,Dur,RJ,Gur,Our,Vur,ME,WMe,Xur,zur,PJ,Qur,Wur,Uur,EE,UMe,Hur,Jur,BJ,Yur,Kur,Zur,CE,HMe,epr,opr,IJ,rpr,tpr,apr,wE,JMe,npr,spr,NJ,lpr,ipr,dpr,AE,YMe,cpr,mpr,qJ,fpr,gpr,hpr,LE,KMe,upr,ppr,jJ,_pr,bpr,vpr,yE,ZMe,Fpr,Tpr,DJ,Mpr,Epr,Cpr,xE,eEe,wpr,Apr,GJ,Lpr,ypr,xpr,$E,oEe,$pr,kpr,OJ,Spr,Rpr,Ppr,kE,rEe,Bpr,Ipr,VJ,Npr,qpr,jpr,SE,tEe,Dpr,Gpr,XJ,Opr,Vpr,Xpr,RE,aEe,zpr,Qpr,zJ,Wpr,Upr,Hpr,PE,nEe,Jpr,Ypr,QJ,Kpr,Zpr,e_r,BE,sEe,o_r,r_r,WJ,t_r,a_r,n_r,IE,lEe,s_r,l_r,UJ,i_r,d_r,c_r,NE,iEe,m_r,f_r,HJ,g_r,h_r,u_r,qE,dEe,p_r,__r,JJ,b_r,v_r,F_r,jE,cEe,T_r,M_r,YJ,E_r,C_r,w_r,DE,A_r,mEe,L_r,y_r,fEe,x_r,$_r,GE,LKe,Qd,OE,gEe,Jx,k_r,hEe,S_r,yKe,Xo,Yx,R_r,Wd,P_r,KJ,B_r,I_r,ZJ,N_r,q_r,j_r,Kx,D_r,uEe,G_r,O_r,V_r,Lt,Zx,X_r,pEe,z_r,Q_r,Ud,W_r,_Ee,U_r,H_r,eY,J_r,Y_r,K_r,VE,Z_r,co,e$,ebr,bEe,obr,rbr,sn,tbr,vEe,abr,nbr,FEe,sbr,lbr,TEe,ibr,dbr,cbr,MEe,XE,EEe,mbr,fbr,oY,gbr,hbr,ubr,zE,pbr,CEe,_br,bbr,wEe,vbr,Fbr,QE,xKe,Hd,WE,AEe,o$,Tbr,LEe,Mbr,$Ke,zo,r$,Ebr,Jd,Cbr,rY,wbr,Abr,tY,Lbr,ybr,xbr,t$,$br,yEe,kbr,Sbr,Rbr,yt,a$,Pbr,xEe,Bbr,Ibr,Yd,Nbr,$Ee,qbr,jbr,aY,Dbr,Gbr,Obr,UE,Vbr,mo,n$,Xbr,kEe,zbr,Qbr,ln,Wbr,SEe,Ubr,Hbr,REe,Jbr,Ybr,PEe,Kbr,Zbr,e2r,Kd,HE,BEe,o2r,r2r,nY,t2r,a2r,n2r,JE,IEe,s2r,l2r,sY,i2r,d2r,c2r,YE,NEe,m2r,f2r,lY,g2r,h2r,u2r,KE,p2r,qEe,_2r,b2r,jEe,v2r,F2r,ZE,kKe,Zd,e4,DEe,s$,T2r,GEe,M2r,SKe,Qo,l$,E2r,ec,C2r,iY,w2r,A2r,dY,L2r,y2r,x2r,i$,$2r,OEe,k2r,S2r,R2r,xt,d$,P2r,VEe,B2r,I2r,oc,N2r,XEe,q2r,j2r,cY,D2r,G2r,O2r,o4,V2r,fo,c$,X2r,zEe,z2r,Q2r,dn,W2r,QEe,U2r,H2r,WEe,J2r,Y2r,UEe,K2r,Z2r,e1r,be,r4,HEe,o1r,r1r,mY,t1r,a1r,n1r,t4,JEe,s1r,l1r,fY,i1r,d1r,c1r,a4,YEe,m1r,f1r,gY,g1r,h1r,u1r,n4,KEe,p1r,_1r,hY,b1r,v1r,F1r,_l,ZEe,T1r,M1r,uY,E1r,C1r,pY,w1r,A1r,L1r,s4,e4e,y1r,x1r,_Y,$1r,k1r,S1r,bl,o4e,R1r,P1r,bY,B1r,I1r,vY,N1r,q1r,j1r,l4,r4e,D1r,G1r,FY,O1r,V1r,X1r,$t,t4e,z1r,Q1r,TY,W1r,U1r,MY,H1r,J1r,EY,Y1r,K1r,Z1r,i4,a4e,evr,ovr,CY,rvr,tvr,avr,d4,n4e,nvr,svr,wY,lvr,ivr,dvr,c4,s4e,cvr,mvr,AY,fvr,gvr,hvr,m4,l4e,uvr,pvr,LY,_vr,bvr,vvr,f4,i4e,Fvr,Tvr,yY,Mvr,Evr,Cvr,g4,d4e,wvr,Avr,xY,Lvr,yvr,xvr,h4,c4e,$vr,kvr,$Y,Svr,Rvr,Pvr,u4,m4e,Bvr,Ivr,kY,Nvr,qvr,jvr,p4,Dvr,f4e,Gvr,Ovr,g4e,Vvr,Xvr,_4,RKe,rc,b4,h4e,m$,zvr,u4e,Qvr,PKe,Wo,f$,Wvr,tc,Uvr,SY,Hvr,Jvr,RY,Yvr,Kvr,Zvr,g$,eFr,p4e,oFr,rFr,tFr,kt,h$,aFr,_4e,nFr,sFr,ac,lFr,b4e,iFr,dFr,PY,cFr,mFr,fFr,v4,gFr,go,u$,hFr,v4e,uFr,pFr,cn,_Fr,F4e,bFr,vFr,T4e,FFr,TFr,M4e,MFr,EFr,CFr,E4e,F4,C4e,wFr,AFr,BY,LFr,yFr,xFr,T4,$Fr,w4e,kFr,SFr,A4e,RFr,PFr,M4,BKe,nc,E4,L4e,p$,BFr,y4e,IFr,IKe,Uo,_$,NFr,sc,qFr,IY,jFr,DFr,NY,GFr,OFr,VFr,b$,XFr,x4e,zFr,QFr,WFr,St,v$,UFr,$4e,HFr,JFr,lc,YFr,k4e,KFr,ZFr,qY,eTr,oTr,rTr,C4,tTr,ho,F$,aTr,S4e,nTr,sTr,mn,lTr,R4e,iTr,dTr,P4e,cTr,mTr,B4e,fTr,gTr,hTr,I4e,w4,N4e,uTr,pTr,jY,_Tr,bTr,vTr,A4,FTr,q4e,TTr,MTr,j4e,ETr,CTr,L4,NKe,ic,y4,D4e,T$,wTr,G4e,ATr,qKe,Ho,M$,LTr,dc,yTr,DY,xTr,$Tr,GY,kTr,STr,RTr,E$,PTr,O4e,BTr,ITr,NTr,Rt,C$,qTr,V4e,jTr,DTr,cc,GTr,X4e,OTr,VTr,OY,XTr,zTr,QTr,x4,WTr,uo,w$,UTr,z4e,HTr,JTr,fn,YTr,Q4e,KTr,ZTr,W4e,eMr,oMr,U4e,rMr,tMr,aMr,H4e,$4,J4e,nMr,sMr,VY,lMr,iMr,dMr,k4,cMr,Y4e,mMr,fMr,K4e,gMr,hMr,S4,jKe,mc,R4,Z4e,A$,uMr,eCe,pMr,DKe,Jo,L$,_Mr,fc,bMr,XY,vMr,FMr,zY,TMr,MMr,EMr,y$,CMr,oCe,wMr,AMr,LMr,Pt,x$,yMr,rCe,xMr,$Mr,gc,kMr,tCe,SMr,RMr,QY,PMr,BMr,IMr,P4,NMr,po,$$,qMr,aCe,jMr,DMr,gn,GMr,nCe,OMr,VMr,sCe,XMr,zMr,lCe,QMr,WMr,UMr,Pe,B4,iCe,HMr,JMr,WY,YMr,KMr,ZMr,I4,dCe,eEr,oEr,UY,rEr,tEr,aEr,N4,cCe,nEr,sEr,HY,lEr,iEr,dEr,q4,mCe,cEr,mEr,JY,fEr,gEr,hEr,j4,fCe,uEr,pEr,YY,_Er,bEr,vEr,D4,gCe,FEr,TEr,KY,MEr,EEr,CEr,G4,hCe,wEr,AEr,ZY,LEr,yEr,xEr,O4,uCe,$Er,kEr,eK,SEr,REr,PEr,V4,pCe,BEr,IEr,oK,NEr,qEr,jEr,X4,DEr,_Ce,GEr,OEr,bCe,VEr,XEr,z4,GKe,hc,Q4,vCe,k$,zEr,FCe,QEr,OKe,Yo,S$,WEr,uc,UEr,rK,HEr,JEr,tK,YEr,KEr,ZEr,R$,e4r,TCe,o4r,r4r,t4r,Bt,P$,a4r,MCe,n4r,s4r,pc,l4r,ECe,i4r,d4r,aK,c4r,m4r,f4r,W4,g4r,_o,B$,h4r,CCe,u4r,p4r,hn,_4r,wCe,b4r,v4r,ACe,F4r,T4r,LCe,M4r,E4r,C4r,mt,U4,yCe,w4r,A4r,nK,L4r,y4r,x4r,H4,xCe,$4r,k4r,sK,S4r,R4r,P4r,J4,$Ce,B4r,I4r,lK,N4r,q4r,j4r,Y4,kCe,D4r,G4r,iK,O4r,V4r,X4r,K4,SCe,z4r,Q4r,dK,W4r,U4r,H4r,Z4,J4r,RCe,Y4r,K4r,PCe,Z4r,eCr,eC,VKe,_c,oC,BCe,I$,oCr,ICe,rCr,XKe,Ko,N$,tCr,bc,aCr,cK,nCr,sCr,mK,lCr,iCr,dCr,q$,cCr,NCe,mCr,fCr,gCr,It,j$,hCr,qCe,uCr,pCr,vc,_Cr,jCe,bCr,vCr,fK,FCr,TCr,MCr,rC,ECr,bo,D$,CCr,DCe,wCr,ACr,un,LCr,GCe,yCr,xCr,OCe,$Cr,kCr,VCe,SCr,RCr,PCr,Le,tC,XCe,BCr,ICr,gK,NCr,qCr,jCr,aC,zCe,DCr,GCr,hK,OCr,VCr,XCr,nC,QCe,zCr,QCr,uK,WCr,UCr,HCr,sC,WCe,JCr,YCr,pK,KCr,ZCr,e3r,lC,UCe,o3r,r3r,_K,t3r,a3r,n3r,iC,HCe,s3r,l3r,bK,i3r,d3r,c3r,dC,JCe,m3r,f3r,vK,g3r,h3r,u3r,cC,YCe,p3r,_3r,FK,b3r,v3r,F3r,mC,KCe,T3r,M3r,TK,E3r,C3r,w3r,fC,ZCe,A3r,L3r,MK,y3r,x3r,$3r,gC,k3r,e3e,S3r,R3r,o3e,P3r,B3r,hC,zKe,Fc,uC,r3e,G$,I3r,t3e,N3r,QKe,Zo,O$,q3r,Tc,j3r,EK,D3r,G3r,CK,O3r,V3r,X3r,V$,z3r,a3e,Q3r,W3r,U3r,Nt,X$,H3r,n3e,J3r,Y3r,Mc,K3r,s3e,Z3r,e5r,wK,o5r,r5r,t5r,pC,a5r,vo,z$,n5r,l3e,s5r,l5r,pn,i5r,i3e,d5r,c5r,d3e,m5r,f5r,c3e,g5r,h5r,u5r,Q$,_C,m3e,p5r,_5r,AK,b5r,v5r,F5r,bC,f3e,T5r,M5r,LK,E5r,C5r,w5r,vC,A5r,g3e,L5r,y5r,h3e,x5r,$5r,FC,WKe,Ec,TC,u3e,W$,k5r,p3e,S5r,UKe,er,U$,R5r,Cc,P5r,yK,B5r,I5r,xK,N5r,q5r,j5r,H$,D5r,_3e,G5r,O5r,V5r,qt,J$,X5r,b3e,z5r,Q5r,wc,W5r,v3e,U5r,H5r,$K,J5r,Y5r,K5r,MC,Z5r,Fo,Y$,e0r,F3e,o0r,r0r,_n,t0r,T3e,a0r,n0r,M3e,s0r,l0r,E3e,i0r,d0r,c0r,ft,EC,C3e,m0r,f0r,kK,g0r,h0r,u0r,CC,w3e,p0r,_0r,SK,b0r,v0r,F0r,wC,A3e,T0r,M0r,RK,E0r,C0r,w0r,AC,L3e,A0r,L0r,PK,y0r,x0r,$0r,LC,y3e,k0r,S0r,BK,R0r,P0r,B0r,yC,I0r,x3e,N0r,q0r,$3e,j0r,D0r,xC,HKe,Ac,$C,k3e,K$,G0r,S3e,O0r,JKe,or,Z$,V0r,Lc,X0r,IK,z0r,Q0r,NK,W0r,U0r,H0r,ek,J0r,R3e,Y0r,K0r,Z0r,jt,ok,ewr,P3e,owr,rwr,yc,twr,B3e,awr,nwr,qK,swr,lwr,iwr,kC,dwr,To,rk,cwr,I3e,mwr,fwr,bn,gwr,N3e,hwr,uwr,q3e,pwr,_wr,j3e,bwr,vwr,Fwr,vn,SC,D3e,Twr,Mwr,jK,Ewr,Cwr,wwr,RC,G3e,Awr,Lwr,DK,ywr,xwr,$wr,PC,O3e,kwr,Swr,GK,Rwr,Pwr,Bwr,BC,V3e,Iwr,Nwr,OK,qwr,jwr,Dwr,IC,Gwr,X3e,Owr,Vwr,z3e,Xwr,zwr,NC,YKe,xc,qC,Q3e,tk,Qwr,W3e,Wwr,KKe,rr,ak,Uwr,$c,Hwr,VK,Jwr,Ywr,XK,Kwr,Zwr,eAr,nk,oAr,U3e,rAr,tAr,aAr,Dt,sk,nAr,H3e,sAr,lAr,kc,iAr,J3e,dAr,cAr,zK,mAr,fAr,gAr,jC,hAr,Mo,lk,uAr,Y3e,pAr,_Ar,Fn,bAr,K3e,vAr,FAr,Z3e,TAr,MAr,e5e,EAr,CAr,wAr,Sc,DC,o5e,AAr,LAr,QK,yAr,xAr,$Ar,GC,r5e,kAr,SAr,WK,RAr,PAr,BAr,OC,t5e,IAr,NAr,UK,qAr,jAr,DAr,VC,GAr,a5e,OAr,VAr,n5e,XAr,zAr,XC,ZKe,Rc,zC,s5e,ik,QAr,l5e,WAr,eZe,tr,dk,UAr,Pc,HAr,HK,JAr,YAr,JK,KAr,ZAr,e6r,ck,o6r,i5e,r6r,t6r,a6r,Gt,mk,n6r,d5e,s6r,l6r,Bc,i6r,c5e,d6r,c6r,YK,m6r,f6r,g6r,QC,h6r,Eo,fk,u6r,m5e,p6r,_6r,Tn,b6r,f5e,v6r,F6r,g5e,T6r,M6r,h5e,E6r,C6r,w6r,u5e,WC,p5e,A6r,L6r,KK,y6r,x6r,$6r,UC,k6r,_5e,S6r,R6r,b5e,P6r,B6r,HC,oZe,Ic,JC,v5e,gk,I6r,F5e,N6r,rZe,ar,hk,q6r,Nc,j6r,ZK,D6r,G6r,eZ,O6r,V6r,X6r,uk,z6r,T5e,Q6r,W6r,U6r,Ot,pk,H6r,M5e,J6r,Y6r,qc,K6r,E5e,Z6r,e7r,oZ,o7r,r7r,t7r,YC,a7r,Co,_k,n7r,C5e,s7r,l7r,Mn,i7r,w5e,d7r,c7r,A5e,m7r,f7r,L5e,g7r,h7r,u7r,gt,KC,y5e,p7r,_7r,rZ,b7r,v7r,F7r,ZC,x5e,T7r,M7r,tZ,E7r,C7r,w7r,e3,$5e,A7r,L7r,aZ,y7r,x7r,$7r,o3,k5e,k7r,S7r,nZ,R7r,P7r,B7r,r3,S5e,I7r,N7r,sZ,q7r,j7r,D7r,t3,G7r,R5e,O7r,V7r,P5e,X7r,z7r,a3,tZe,jc,n3,B5e,bk,Q7r,I5e,W7r,aZe,nr,vk,U7r,Dc,H7r,lZ,J7r,Y7r,iZ,K7r,Z7r,eLr,Fk,oLr,N5e,rLr,tLr,aLr,Vt,Tk,nLr,q5e,sLr,lLr,Gc,iLr,j5e,dLr,cLr,dZ,mLr,fLr,gLr,s3,hLr,wo,Mk,uLr,D5e,pLr,_Lr,En,bLr,G5e,vLr,FLr,O5e,TLr,MLr,V5e,ELr,CLr,wLr,X5e,l3,z5e,ALr,LLr,cZ,yLr,xLr,$Lr,i3,kLr,Q5e,SLr,RLr,W5e,PLr,BLr,d3,nZe,Oc,c3,U5e,Ek,ILr,H5e,NLr,sZe,sr,Ck,qLr,Vc,jLr,mZ,DLr,GLr,fZ,OLr,VLr,XLr,wk,zLr,J5e,QLr,WLr,ULr,Xt,Ak,HLr,Y5e,JLr,YLr,Xc,KLr,K5e,ZLr,eyr,gZ,oyr,ryr,tyr,m3,ayr,Ir,Lk,nyr,Z5e,syr,lyr,Cn,iyr,e0e,dyr,cyr,o0e,myr,fyr,r0e,gyr,hyr,uyr,N,f3,t0e,pyr,_yr,hZ,byr,vyr,Fyr,g3,a0e,Tyr,Myr,uZ,Eyr,Cyr,wyr,h3,n0e,Ayr,Lyr,pZ,yyr,xyr,$yr,u3,s0e,kyr,Syr,_Z,Ryr,Pyr,Byr,p3,l0e,Iyr,Nyr,bZ,qyr,jyr,Dyr,_3,i0e,Gyr,Oyr,vZ,Vyr,Xyr,zyr,b3,d0e,Qyr,Wyr,FZ,Uyr,Hyr,Jyr,v3,c0e,Yyr,Kyr,TZ,Zyr,e8r,o8r,F3,m0e,r8r,t8r,MZ,a8r,n8r,s8r,T3,f0e,l8r,i8r,EZ,d8r,c8r,m8r,M3,g0e,f8r,g8r,CZ,h8r,u8r,p8r,E3,h0e,_8r,b8r,wZ,v8r,F8r,T8r,C3,u0e,M8r,E8r,AZ,C8r,w8r,A8r,w3,p0e,L8r,y8r,LZ,x8r,$8r,k8r,A3,_0e,S8r,R8r,yZ,P8r,B8r,I8r,L3,b0e,N8r,q8r,xZ,j8r,D8r,G8r,y3,v0e,O8r,V8r,$Z,X8r,z8r,Q8r,x3,F0e,W8r,U8r,kZ,H8r,J8r,Y8r,vl,T0e,K8r,Z8r,SZ,e9r,o9r,RZ,r9r,t9r,a9r,$3,M0e,n9r,s9r,PZ,l9r,i9r,d9r,k3,E0e,c9r,m9r,BZ,f9r,g9r,h9r,S3,C0e,u9r,p9r,IZ,_9r,b9r,v9r,R3,w0e,F9r,T9r,NZ,M9r,E9r,C9r,P3,A0e,w9r,A9r,qZ,L9r,y9r,x9r,B3,L0e,$9r,k9r,jZ,S9r,R9r,P9r,I3,y0e,B9r,I9r,DZ,N9r,q9r,j9r,N3,x0e,D9r,G9r,GZ,O9r,V9r,X9r,q3,$0e,z9r,Q9r,OZ,W9r,U9r,H9r,j3,k0e,J9r,Y9r,VZ,K9r,Z9r,exr,D3,S0e,oxr,rxr,XZ,txr,axr,nxr,G3,R0e,sxr,lxr,zZ,ixr,dxr,cxr,O3,P0e,mxr,fxr,QZ,gxr,hxr,uxr,V3,B0e,pxr,_xr,WZ,bxr,vxr,Fxr,X3,I0e,Txr,Mxr,UZ,Exr,Cxr,wxr,z3,N0e,Axr,Lxr,HZ,yxr,xxr,$xr,Q3,q0e,kxr,Sxr,JZ,Rxr,Pxr,Bxr,W3,j0e,Ixr,Nxr,YZ,qxr,jxr,Dxr,U3,D0e,Gxr,Oxr,KZ,Vxr,Xxr,zxr,H3,G0e,Qxr,Wxr,ZZ,Uxr,Hxr,Jxr,J3,O0e,Yxr,Kxr,eee,Zxr,e$r,o$r,Y3,V0e,r$r,t$r,oee,a$r,n$r,s$r,K3,X0e,l$r,i$r,ree,d$r,c$r,m$r,Z3,z0e,f$r,g$r,tee,h$r,u$r,p$r,e5,Q0e,_$r,b$r,aee,v$r,F$r,T$r,o5,W0e,M$r,E$r,nee,C$r,w$r,A$r,r5,U0e,L$r,y$r,see,x$r,$$r,k$r,t5,H0e,S$r,R$r,lee,P$r,B$r,I$r,a5,J0e,N$r,q$r,iee,j$r,D$r,G$r,n5,Y0e,O$r,V$r,dee,X$r,z$r,Q$r,s5,K0e,W$r,U$r,cee,H$r,J$r,Y$r,l5,Z0e,K$r,Z$r,mee,ekr,okr,rkr,i5,ewe,tkr,akr,fee,nkr,skr,lkr,d5,owe,ikr,dkr,gee,ckr,mkr,fkr,c5,rwe,gkr,hkr,hee,ukr,pkr,_kr,m5,lZe,zc,f5,twe,yk,bkr,awe,vkr,iZe,lr,xk,Fkr,Qc,Tkr,uee,Mkr,Ekr,pee,Ckr,wkr,Akr,$k,Lkr,nwe,ykr,xkr,$kr,zt,kk,kkr,swe,Skr,Rkr,Wc,Pkr,lwe,Bkr,Ikr,_ee,Nkr,qkr,jkr,g5,Dkr,Nr,Sk,Gkr,iwe,Okr,Vkr,wn,Xkr,dwe,zkr,Qkr,cwe,Wkr,Ukr,mwe,Hkr,Jkr,Ykr,se,h5,fwe,Kkr,Zkr,bee,eSr,oSr,rSr,u5,gwe,tSr,aSr,vee,nSr,sSr,lSr,p5,hwe,iSr,dSr,Fee,cSr,mSr,fSr,_5,uwe,gSr,hSr,Tee,uSr,pSr,_Sr,b5,pwe,bSr,vSr,Mee,FSr,TSr,MSr,v5,_we,ESr,CSr,Eee,wSr,ASr,LSr,F5,bwe,ySr,xSr,Cee,$Sr,kSr,SSr,T5,vwe,RSr,PSr,wee,BSr,ISr,NSr,M5,Fwe,qSr,jSr,Aee,DSr,GSr,OSr,E5,Twe,VSr,XSr,Lee,zSr,QSr,WSr,C5,Mwe,USr,HSr,yee,JSr,YSr,KSr,w5,Ewe,ZSr,eRr,xee,oRr,rRr,tRr,A5,Cwe,aRr,nRr,$ee,sRr,lRr,iRr,L5,wwe,dRr,cRr,kee,mRr,fRr,gRr,y5,Awe,hRr,uRr,See,pRr,_Rr,bRr,x5,Lwe,vRr,FRr,Ree,TRr,MRr,ERr,$5,ywe,CRr,wRr,Pee,ARr,LRr,yRr,k5,xwe,xRr,$Rr,Bee,kRr,SRr,RRr,S5,$we,PRr,BRr,Iee,IRr,NRr,qRr,R5,kwe,jRr,DRr,Nee,GRr,ORr,VRr,P5,Swe,XRr,zRr,qee,QRr,WRr,URr,B5,Rwe,HRr,JRr,jee,YRr,KRr,ZRr,I5,Pwe,ePr,oPr,Dee,rPr,tPr,aPr,N5,dZe,Uc,q5,Bwe,Rk,nPr,Iwe,sPr,cZe,ir,Pk,lPr,Hc,iPr,Gee,dPr,cPr,Oee,mPr,fPr,gPr,Bk,hPr,Nwe,uPr,pPr,_Pr,Qt,Ik,bPr,qwe,vPr,FPr,Jc,TPr,jwe,MPr,EPr,Vee,CPr,wPr,APr,j5,LPr,qr,Nk,yPr,Dwe,xPr,$Pr,An,kPr,Gwe,SPr,RPr,Owe,PPr,BPr,Vwe,IPr,NPr,qPr,Me,D5,Xwe,jPr,DPr,Xee,GPr,OPr,VPr,G5,zwe,XPr,zPr,zee,QPr,WPr,UPr,O5,Qwe,HPr,JPr,Qee,YPr,KPr,ZPr,V5,Wwe,eBr,oBr,Wee,rBr,tBr,aBr,X5,Uwe,nBr,sBr,Uee,lBr,iBr,dBr,z5,Hwe,cBr,mBr,Hee,fBr,gBr,hBr,Q5,Jwe,uBr,pBr,Jee,_Br,bBr,vBr,W5,Ywe,FBr,TBr,Yee,MBr,EBr,CBr,U5,Kwe,wBr,ABr,Kee,LBr,yBr,xBr,H5,Zwe,$Br,kBr,Zee,SBr,RBr,PBr,J5,eAe,BBr,IBr,eoe,NBr,qBr,jBr,Y5,oAe,DBr,GBr,ooe,OBr,VBr,XBr,K5,rAe,zBr,QBr,roe,WBr,UBr,HBr,Z5,tAe,JBr,YBr,toe,KBr,ZBr,eIr,e0,mZe,Yc,o0,aAe,qk,oIr,nAe,rIr,fZe,dr,jk,tIr,Kc,aIr,aoe,nIr,sIr,noe,lIr,iIr,dIr,Dk,cIr,sAe,mIr,fIr,gIr,Wt,Gk,hIr,lAe,uIr,pIr,Zc,_Ir,iAe,bIr,vIr,soe,FIr,TIr,MIr,r0,EIr,jr,Ok,CIr,dAe,wIr,AIr,Ln,LIr,cAe,yIr,xIr,mAe,$Ir,kIr,fAe,SIr,RIr,PIr,Be,t0,gAe,BIr,IIr,loe,NIr,qIr,jIr,a0,hAe,DIr,GIr,ioe,OIr,VIr,XIr,Fl,uAe,zIr,QIr,doe,WIr,UIr,coe,HIr,JIr,YIr,n0,pAe,KIr,ZIr,moe,eNr,oNr,rNr,s0,_Ae,tNr,aNr,foe,nNr,sNr,lNr,l0,bAe,iNr,dNr,goe,cNr,mNr,fNr,i0,vAe,gNr,hNr,hoe,uNr,pNr,_Nr,d0,FAe,bNr,vNr,uoe,FNr,TNr,MNr,c0,TAe,ENr,CNr,poe,wNr,ANr,LNr,m0,gZe,em,f0,MAe,Vk,yNr,EAe,xNr,hZe,cr,Xk,$Nr,om,kNr,_oe,SNr,RNr,boe,PNr,BNr,INr,zk,NNr,CAe,qNr,jNr,DNr,Ut,Qk,GNr,wAe,ONr,VNr,rm,XNr,AAe,zNr,QNr,voe,WNr,UNr,HNr,g0,JNr,Dr,Wk,YNr,LAe,KNr,ZNr,yn,eqr,yAe,oqr,rqr,xAe,tqr,aqr,$Ae,nqr,sqr,lqr,tm,h0,kAe,iqr,dqr,Foe,cqr,mqr,fqr,u0,SAe,gqr,hqr,Toe,uqr,pqr,_qr,p0,RAe,bqr,vqr,Moe,Fqr,Tqr,Mqr,_0,uZe,am,b0,PAe,Uk,Eqr,BAe,Cqr,pZe,mr,Hk,wqr,nm,Aqr,Eoe,Lqr,yqr,Coe,xqr,$qr,kqr,Jk,Sqr,IAe,Rqr,Pqr,Bqr,Ht,Yk,Iqr,NAe,Nqr,qqr,sm,jqr,qAe,Dqr,Gqr,woe,Oqr,Vqr,Xqr,v0,zqr,Gr,Kk,Qqr,jAe,Wqr,Uqr,xn,Hqr,DAe,Jqr,Yqr,GAe,Kqr,Zqr,OAe,ejr,ojr,rjr,fe,F0,VAe,tjr,ajr,Aoe,njr,sjr,ljr,T0,XAe,ijr,djr,Loe,cjr,mjr,fjr,M0,zAe,gjr,hjr,yoe,ujr,pjr,_jr,E0,QAe,bjr,vjr,xoe,Fjr,Tjr,Mjr,C0,WAe,Ejr,Cjr,$oe,wjr,Ajr,Ljr,w0,UAe,yjr,xjr,koe,$jr,kjr,Sjr,A0,HAe,Rjr,Pjr,Soe,Bjr,Ijr,Njr,L0,JAe,qjr,jjr,Roe,Djr,Gjr,Ojr,y0,YAe,Vjr,Xjr,Poe,zjr,Qjr,Wjr,x0,KAe,Ujr,Hjr,Boe,Jjr,Yjr,Kjr,$0,ZAe,Zjr,eDr,Ioe,oDr,rDr,tDr,k0,e6e,aDr,nDr,Noe,sDr,lDr,iDr,S0,o6e,dDr,cDr,qoe,mDr,fDr,gDr,R0,r6e,hDr,uDr,joe,pDr,_Dr,bDr,P0,t6e,vDr,FDr,Doe,TDr,MDr,EDr,B0,a6e,CDr,wDr,Goe,ADr,LDr,yDr,I0,n6e,xDr,$Dr,Ooe,kDr,SDr,RDr,N0,s6e,PDr,BDr,Voe,IDr,NDr,qDr,q0,l6e,jDr,DDr,Xoe,GDr,ODr,VDr,j0,i6e,XDr,zDr,zoe,QDr,WDr,UDr,D0,_Ze,lm,G0,d6e,Zk,HDr,c6e,JDr,bZe,fr,eS,YDr,im,KDr,Qoe,ZDr,eGr,Woe,oGr,rGr,tGr,oS,aGr,m6e,nGr,sGr,lGr,Jt,rS,iGr,f6e,dGr,cGr,dm,mGr,g6e,fGr,gGr,Uoe,hGr,uGr,pGr,O0,_Gr,Or,tS,bGr,h6e,vGr,FGr,$n,TGr,u6e,MGr,EGr,p6e,CGr,wGr,_6e,AGr,LGr,yGr,ye,V0,b6e,xGr,$Gr,Hoe,kGr,SGr,RGr,X0,v6e,PGr,BGr,Joe,IGr,NGr,qGr,z0,F6e,jGr,DGr,Yoe,GGr,OGr,VGr,Q0,T6e,XGr,zGr,Koe,QGr,WGr,UGr,W0,M6e,HGr,JGr,Zoe,YGr,KGr,ZGr,U0,E6e,eOr,oOr,ere,rOr,tOr,aOr,H0,C6e,nOr,sOr,ore,lOr,iOr,dOr,J0,w6e,cOr,mOr,rre,fOr,gOr,hOr,Y0,A6e,uOr,pOr,tre,_Or,bOr,vOr,K0,L6e,FOr,TOr,are,MOr,EOr,COr,Z0,vZe,cm,ew,y6e,aS,wOr,x6e,AOr,FZe,gr,nS,LOr,mm,yOr,nre,xOr,$Or,sre,kOr,SOr,ROr,sS,POr,$6e,BOr,IOr,NOr,Yt,lS,qOr,k6e,jOr,DOr,fm,GOr,S6e,OOr,VOr,lre,XOr,zOr,QOr,ow,WOr,Vr,iS,UOr,R6e,HOr,JOr,kn,YOr,P6e,KOr,ZOr,B6e,eVr,oVr,I6e,rVr,tVr,aVr,re,rw,N6e,nVr,sVr,ire,lVr,iVr,dVr,tw,q6e,cVr,mVr,dre,fVr,gVr,hVr,aw,j6e,uVr,pVr,cre,_Vr,bVr,vVr,nw,D6e,FVr,TVr,mre,MVr,EVr,CVr,sw,G6e,wVr,AVr,fre,LVr,yVr,xVr,lw,O6e,$Vr,kVr,gre,SVr,RVr,PVr,iw,V6e,BVr,IVr,hre,NVr,qVr,jVr,dw,X6e,DVr,GVr,ure,OVr,VVr,XVr,cw,z6e,zVr,QVr,pre,WVr,UVr,HVr,mw,Q6e,JVr,YVr,_re,KVr,ZVr,eXr,fw,W6e,oXr,rXr,bre,tXr,aXr,nXr,gw,U6e,sXr,lXr,vre,iXr,dXr,cXr,hw,H6e,mXr,fXr,Fre,gXr,hXr,uXr,uw,J6e,pXr,_Xr,Tre,bXr,vXr,FXr,pw,Y6e,TXr,MXr,Mre,EXr,CXr,wXr,_w,K6e,AXr,LXr,Ere,yXr,xXr,$Xr,bw,Z6e,kXr,SXr,Cre,RXr,PXr,BXr,vw,e7e,IXr,NXr,wre,qXr,jXr,DXr,Fw,o7e,GXr,OXr,Are,VXr,XXr,zXr,Tw,r7e,QXr,WXr,Lre,UXr,HXr,JXr,Mw,t7e,YXr,KXr,yre,ZXr,ezr,ozr,Ew,a7e,rzr,tzr,xre,azr,nzr,szr,Cw,n7e,lzr,izr,$re,dzr,czr,mzr,ww,s7e,fzr,gzr,kre,hzr,uzr,pzr,Aw,l7e,_zr,bzr,Sre,vzr,Fzr,Tzr,Lw,i7e,Mzr,Ezr,Rre,Czr,wzr,Azr,yw,d7e,Lzr,yzr,Pre,xzr,$zr,kzr,xw,TZe,gm,$w,c7e,dS,Szr,m7e,Rzr,MZe,hr,cS,Pzr,hm,Bzr,Bre,Izr,Nzr,Ire,qzr,jzr,Dzr,mS,Gzr,f7e,Ozr,Vzr,Xzr,Kt,fS,zzr,g7e,Qzr,Wzr,um,Uzr,h7e,Hzr,Jzr,Nre,Yzr,Kzr,Zzr,kw,eQr,Xr,gS,oQr,u7e,rQr,tQr,Sn,aQr,p7e,nQr,sQr,_7e,lQr,iQr,b7e,dQr,cQr,mQr,ve,Sw,v7e,fQr,gQr,qre,hQr,uQr,pQr,Rw,F7e,_Qr,bQr,jre,vQr,FQr,TQr,Pw,T7e,MQr,EQr,Dre,CQr,wQr,AQr,Bw,M7e,LQr,yQr,Gre,xQr,$Qr,kQr,Iw,E7e,SQr,RQr,Ore,PQr,BQr,IQr,Nw,C7e,NQr,qQr,Vre,jQr,DQr,GQr,qw,w7e,OQr,VQr,Xre,XQr,zQr,QQr,jw,A7e,WQr,UQr,zre,HQr,JQr,YQr,Dw,L7e,KQr,ZQr,Qre,eWr,oWr,rWr,Gw,y7e,tWr,aWr,Wre,nWr,sWr,lWr,Ow,x7e,iWr,dWr,Ure,cWr,mWr,fWr,Vw,$7e,gWr,hWr,Hre,uWr,pWr,_Wr,Xw,k7e,bWr,vWr,Jre,FWr,TWr,MWr,zw,S7e,EWr,CWr,Yre,wWr,AWr,LWr,Qw,R7e,yWr,xWr,Kre,$Wr,kWr,SWr,Ww,P7e,RWr,PWr,Zre,BWr,IWr,NWr,Uw,B7e,qWr,jWr,ete,DWr,GWr,OWr,Hw,EZe,pm,Jw,I7e,hS,VWr,N7e,XWr,CZe,ur,uS,zWr,_m,QWr,ote,WWr,UWr,rte,HWr,JWr,YWr,pS,KWr,q7e,ZWr,eUr,oUr,Zt,_S,rUr,j7e,tUr,aUr,bm,nUr,D7e,sUr,lUr,tte,iUr,dUr,cUr,Yw,mUr,zr,bS,fUr,G7e,gUr,hUr,Rn,uUr,O7e,pUr,_Ur,V7e,bUr,vUr,X7e,FUr,TUr,MUr,vS,Kw,z7e,EUr,CUr,ate,wUr,AUr,LUr,Zw,Q7e,yUr,xUr,nte,$Ur,kUr,SUr,eA,wZe,vm,oA,W7e,FS,RUr,U7e,PUr,AZe,pr,TS,BUr,Fm,IUr,ste,NUr,qUr,lte,jUr,DUr,GUr,MS,OUr,H7e,VUr,XUr,zUr,ea,ES,QUr,J7e,WUr,UUr,Tm,HUr,Y7e,JUr,YUr,ite,KUr,ZUr,eHr,rA,oHr,Qr,CS,rHr,K7e,tHr,aHr,Pn,nHr,Z7e,sHr,lHr,eLe,iHr,dHr,oLe,cHr,mHr,fHr,rLe,tA,tLe,gHr,hHr,dte,uHr,pHr,_Hr,aA,LZe,Mm,nA,aLe,wS,bHr,nLe,vHr,yZe,_r,AS,FHr,Em,THr,cte,MHr,EHr,mte,CHr,wHr,AHr,LS,LHr,sLe,yHr,xHr,$Hr,oa,yS,kHr,lLe,SHr,RHr,Cm,PHr,iLe,BHr,IHr,fte,NHr,qHr,jHr,sA,DHr,Wr,xS,GHr,dLe,OHr,VHr,Bn,XHr,cLe,zHr,QHr,mLe,WHr,UHr,fLe,HHr,JHr,YHr,gLe,lA,hLe,KHr,ZHr,gte,eJr,oJr,rJr,iA,xZe,wm,dA,uLe,$S,tJr,pLe,aJr,$Ze,br,kS,nJr,Am,sJr,hte,lJr,iJr,ute,dJr,cJr,mJr,SS,fJr,_Le,gJr,hJr,uJr,ra,RS,pJr,bLe,_Jr,bJr,Lm,vJr,vLe,FJr,TJr,pte,MJr,EJr,CJr,cA,wJr,Ur,PS,AJr,FLe,LJr,yJr,In,xJr,TLe,$Jr,kJr,MLe,SJr,RJr,ELe,PJr,BJr,IJr,de,mA,CLe,NJr,qJr,_te,jJr,DJr,GJr,fA,wLe,OJr,VJr,bte,XJr,zJr,QJr,gA,ALe,WJr,UJr,vte,HJr,JJr,YJr,hA,LLe,KJr,ZJr,Fte,eYr,oYr,rYr,uA,yLe,tYr,aYr,Tte,nYr,sYr,lYr,pA,xLe,iYr,dYr,Mte,cYr,mYr,fYr,_A,$Le,gYr,hYr,Ete,uYr,pYr,_Yr,bA,kLe,bYr,vYr,Cte,FYr,TYr,MYr,vA,SLe,EYr,CYr,wte,wYr,AYr,LYr,FA,RLe,yYr,xYr,Ate,$Yr,kYr,SYr,TA,PLe,RYr,PYr,Lte,BYr,IYr,NYr,MA,BLe,qYr,jYr,yte,DYr,GYr,OYr,EA,ILe,VYr,XYr,xte,zYr,QYr,WYr,CA,NLe,UYr,HYr,$te,JYr,YYr,KYr,wA,qLe,ZYr,eKr,kte,oKr,rKr,tKr,AA,jLe,aKr,nKr,Ste,sKr,lKr,iKr,LA,DLe,dKr,cKr,Rte,mKr,fKr,gKr,yA,GLe,hKr,uKr,Pte,pKr,_Kr,bKr,xA,OLe,vKr,FKr,Bte,TKr,MKr,EKr,$A,VLe,CKr,wKr,Ite,AKr,LKr,yKr,kA,XLe,xKr,$Kr,Nte,kKr,SKr,RKr,SA,kZe,ym,RA,zLe,BS,PKr,QLe,BKr,SZe,vr,IS,IKr,xm,NKr,qte,qKr,jKr,jte,DKr,GKr,OKr,NS,VKr,WLe,XKr,zKr,QKr,ta,qS,WKr,ULe,UKr,HKr,$m,JKr,HLe,YKr,KKr,Dte,ZKr,eZr,oZr,PA,rZr,Hr,jS,tZr,JLe,aZr,nZr,Nn,sZr,YLe,lZr,iZr,KLe,dZr,cZr,ZLe,mZr,fZr,gZr,ce,BA,eye,hZr,uZr,Gte,pZr,_Zr,bZr,IA,oye,vZr,FZr,Ote,TZr,MZr,EZr,NA,rye,CZr,wZr,Vte,AZr,LZr,yZr,qA,tye,xZr,$Zr,Xte,kZr,SZr,RZr,jA,aye,PZr,BZr,zte,IZr,NZr,qZr,DA,nye,jZr,DZr,Qte,GZr,OZr,VZr,GA,sye,XZr,zZr,Wte,QZr,WZr,UZr,OA,lye,HZr,JZr,Ute,YZr,KZr,ZZr,VA,iye,eet,oet,Hte,ret,tet,aet,XA,dye,net,set,Jte,iet,det,cet,zA,cye,met,fet,Yte,get,het,uet,QA,mye,pet,_et,Kte,bet,vet,Fet,WA,fye,Tet,Met,Zte,Eet,Cet,wet,UA,gye,Aet,Let,eae,yet,xet,$et,HA,hye,ket,Set,oae,Ret,Pet,Bet,JA,uye,Iet,Net,rae,qet,jet,Det,YA,pye,Get,Oet,tae,Vet,Xet,zet,KA,_ye,Qet,Wet,aae,Uet,Het,Jet,ZA,bye,Yet,Ket,nae,Zet,eot,oot,e6,vye,rot,tot,sae,aot,not,sot,o6,Fye,lot,iot,lae,dot,cot,mot,r6,RZe,km,t6,Tye,DS,fot,Mye,got,PZe,Fr,GS,hot,Sm,uot,iae,pot,_ot,dae,bot,vot,Fot,OS,Tot,Eye,Mot,Eot,Cot,aa,VS,wot,Cye,Aot,Lot,Rm,yot,wye,xot,$ot,cae,kot,Sot,Rot,a6,Pot,Jr,XS,Bot,Aye,Iot,Not,qn,qot,Lye,jot,Dot,yye,Got,Oot,xye,Vot,Xot,zot,$ye,n6,kye,Qot,Wot,mae,Uot,Hot,Jot,s6,BZe,Pm,l6,Sye,zS,Yot,Rye,Kot,IZe,Tr,QS,Zot,Bm,ert,fae,ort,rrt,gae,trt,art,nrt,WS,srt,Pye,lrt,irt,drt,na,US,crt,Bye,mrt,frt,Im,grt,Iye,hrt,urt,hae,prt,_rt,brt,i6,vrt,Yr,HS,Frt,Nye,Trt,Mrt,jn,Ert,qye,Crt,wrt,jye,Art,Lrt,Dye,yrt,xrt,$rt,Gye,d6,Oye,krt,Srt,uae,Rrt,Prt,Brt,c6,NZe,Nm,m6,Vye,JS,Irt,Xye,Nrt,qZe,Mr,YS,qrt,qm,jrt,pae,Drt,Grt,_ae,Ort,Vrt,Xrt,KS,zrt,zye,Qrt,Wrt,Urt,sa,ZS,Hrt,Qye,Jrt,Yrt,jm,Krt,Wye,Zrt,ett,bae,ott,rtt,ttt,f6,att,Kr,eR,ntt,Uye,stt,ltt,Dn,itt,Hye,dtt,ctt,Jye,mtt,ftt,Yye,gtt,htt,utt,te,g6,Kye,ptt,_tt,vae,btt,vtt,Ftt,h6,Zye,Ttt,Mtt,Fae,Ett,Ctt,wtt,u6,e8e,Att,Ltt,Tae,ytt,xtt,$tt,p6,o8e,ktt,Stt,Mae,Rtt,Ptt,Btt,_6,r8e,Itt,Ntt,Eae,qtt,jtt,Dtt,b6,t8e,Gtt,Ott,Cae,Vtt,Xtt,ztt,v6,a8e,Qtt,Wtt,wae,Utt,Htt,Jtt,F6,n8e,Ytt,Ktt,Aae,Ztt,eat,oat,T6,s8e,rat,tat,Lae,aat,nat,sat,M6,l8e,lat,iat,yae,dat,cat,mat,E6,i8e,fat,gat,xae,hat,uat,pat,C6,d8e,_at,bat,$ae,vat,Fat,Tat,w6,c8e,Mat,Eat,kae,Cat,wat,Aat,A6,m8e,Lat,yat,Sae,xat,$at,kat,L6,f8e,Sat,Rat,Rae,Pat,Bat,Iat,y6,g8e,Nat,qat,Pae,jat,Dat,Gat,x6,h8e,Oat,Vat,Bae,Xat,zat,Qat,$6,u8e,Wat,Uat,Iae,Hat,Jat,Yat,k6,p8e,Kat,Zat,Nae,ent,ont,rnt,S6,_8e,tnt,ant,qae,nnt,snt,lnt,R6,b8e,int,dnt,jae,cnt,mnt,fnt,P6,v8e,gnt,hnt,Dae,unt,pnt,_nt,B6,F8e,bnt,vnt,Gae,Fnt,Tnt,Mnt,I6,T8e,Ent,Cnt,Oae,wnt,Ant,Lnt,N6,M8e,ynt,xnt,Vae,$nt,knt,Snt,q6,E8e,Rnt,Pnt,Xae,Bnt,Int,Nnt,j6,C8e,qnt,jnt,zae,Dnt,Gnt,Ont,D6,jZe,Dm,G6,w8e,oR,Vnt,A8e,Xnt,DZe,Er,rR,znt,Gm,Qnt,Qae,Wnt,Unt,Wae,Hnt,Jnt,Ynt,tR,Knt,L8e,Znt,est,ost,la,aR,rst,y8e,tst,ast,Om,nst,x8e,sst,lst,Uae,ist,dst,cst,O6,mst,Zr,nR,fst,$8e,gst,hst,Gn,ust,k8e,pst,_st,S8e,bst,vst,R8e,Fst,Tst,Mst,xe,V6,P8e,Est,Cst,Hae,wst,Ast,Lst,X6,B8e,yst,xst,Jae,$st,kst,Sst,z6,I8e,Rst,Pst,Yae,Bst,Ist,Nst,Q6,N8e,qst,jst,Kae,Dst,Gst,Ost,W6,q8e,Vst,Xst,Zae,zst,Qst,Wst,U6,j8e,Ust,Hst,ene,Jst,Yst,Kst,H6,D8e,Zst,elt,one,olt,rlt,tlt,J6,G8e,alt,nlt,rne,slt,llt,ilt,Y6,O8e,dlt,clt,tne,mlt,flt,glt,K6,V8e,hlt,ult,ane,plt,_lt,blt,Z6,GZe,Vm,e7,X8e,sR,vlt,z8e,Flt,OZe,Cr,lR,Tlt,Xm,Mlt,nne,Elt,Clt,sne,wlt,Alt,Llt,iR,ylt,Q8e,xlt,$lt,klt,ia,dR,Slt,W8e,Rlt,Plt,zm,Blt,U8e,Ilt,Nlt,lne,qlt,jlt,Dlt,o7,Glt,et,cR,Olt,H8e,Vlt,Xlt,On,zlt,J8e,Qlt,Wlt,Y8e,Ult,Hlt,K8e,Jlt,Ylt,Klt,Ee,r7,Z8e,Zlt,eit,ine,oit,rit,tit,t7,e9e,ait,nit,dne,sit,lit,iit,a7,o9e,dit,cit,cne,mit,fit,git,n7,r9e,hit,uit,mne,pit,_it,bit,s7,t9e,vit,Fit,fne,Tit,Mit,Eit,l7,a9e,Cit,wit,gne,Ait,Lit,yit,i7,n9e,xit,$it,hne,kit,Sit,Rit,d7,s9e,Pit,Bit,une,Iit,Nit,qit,c7,l9e,jit,Dit,pne,Git,Oit,Vit,m7,i9e,Xit,zit,_ne,Qit,Wit,Uit,f7,d9e,Hit,Jit,bne,Yit,Kit,Zit,g7,c9e,edt,odt,vne,rdt,tdt,adt,h7,m9e,ndt,sdt,Fne,ldt,idt,ddt,u7,VZe,Qm,p7,f9e,mR,cdt,g9e,mdt,XZe,wr,fR,fdt,Wm,gdt,Tne,hdt,udt,Mne,pdt,_dt,bdt,gR,vdt,h9e,Fdt,Tdt,Mdt,da,hR,Edt,u9e,Cdt,wdt,Um,Adt,p9e,Ldt,ydt,Ene,xdt,$dt,kdt,_7,Sdt,ot,uR,Rdt,_9e,Pdt,Bdt,Vn,Idt,b9e,Ndt,qdt,v9e,jdt,Ddt,F9e,Gdt,Odt,Vdt,$e,b7,T9e,Xdt,zdt,Cne,Qdt,Wdt,Udt,v7,M9e,Hdt,Jdt,wne,Ydt,Kdt,Zdt,F7,E9e,ect,oct,Ane,rct,tct,act,T7,C9e,nct,sct,Lne,lct,ict,dct,M7,w9e,cct,mct,yne,fct,gct,hct,E7,A9e,uct,pct,xne,_ct,bct,vct,C7,L9e,Fct,Tct,$ne,Mct,Ect,Cct,w7,y9e,wct,Act,kne,Lct,yct,xct,A7,x9e,$ct,kct,Sne,Sct,Rct,Pct,L7,$9e,Bct,Ict,Rne,Nct,qct,jct,y7,zZe,Hm,x7,k9e,pR,Dct,S9e,Gct,QZe,Ar,_R,Oct,Jm,Vct,Pne,Xct,zct,Bne,Qct,Wct,Uct,bR,Hct,R9e,Jct,Yct,Kct,ca,vR,Zct,P9e,emt,omt,Ym,rmt,B9e,tmt,amt,Ine,nmt,smt,lmt,$7,imt,rt,FR,dmt,I9e,cmt,mmt,Xn,fmt,N9e,gmt,hmt,q9e,umt,pmt,j9e,_mt,bmt,vmt,ke,k7,D9e,Fmt,Tmt,Nne,Mmt,Emt,Cmt,S7,G9e,wmt,Amt,qne,Lmt,ymt,xmt,R7,O9e,$mt,kmt,jne,Smt,Rmt,Pmt,P7,V9e,Bmt,Imt,Dne,Nmt,qmt,jmt,B7,X9e,Dmt,Gmt,Gne,Omt,Vmt,Xmt,I7,z9e,zmt,Qmt,One,Wmt,Umt,Hmt,N7,Q9e,Jmt,Ymt,Vne,Kmt,Zmt,eft,q7,W9e,oft,rft,Xne,tft,aft,nft,j7,U9e,sft,lft,zne,ift,dft,cft,D7,H9e,mft,fft,Qne,gft,hft,uft,G7,WZe,Km,O7,J9e,TR,pft,Y9e,_ft,UZe,Lr,MR,bft,Zm,vft,Wne,Fft,Tft,Une,Mft,Eft,Cft,ER,wft,K9e,Aft,Lft,yft,ma,CR,xft,Z9e,$ft,kft,ef,Sft,exe,Rft,Pft,Hne,Bft,Ift,Nft,V7,qft,tt,wR,jft,oxe,Dft,Gft,zn,Oft,rxe,Vft,Xft,txe,zft,Qft,axe,Wft,Uft,Hft,Se,X7,nxe,Jft,Yft,Jne,Kft,Zft,egt,z7,sxe,ogt,rgt,Yne,tgt,agt,ngt,Q7,lxe,sgt,lgt,Kne,igt,dgt,cgt,W7,ixe,mgt,fgt,Zne,ggt,hgt,ugt,U7,dxe,pgt,_gt,ese,bgt,vgt,Fgt,H7,cxe,Tgt,Mgt,ose,Egt,Cgt,wgt,J7,mxe,Agt,Lgt,rse,ygt,xgt,$gt,Y7,fxe,kgt,Sgt,tse,Rgt,Pgt,Bgt,K7,gxe,Igt,Ngt,ase,qgt,jgt,Dgt,Z7,hxe,Ggt,Ogt,nse,Vgt,Xgt,zgt,eL,HZe,of,oL,uxe,AR,Qgt,pxe,Wgt,JZe,yr,LR,Ugt,rf,Hgt,sse,Jgt,Ygt,lse,Kgt,Zgt,eht,yR,oht,_xe,rht,tht,aht,fa,xR,nht,bxe,sht,lht,tf,iht,vxe,dht,cht,ise,mht,fht,ght,rL,hht,at,$R,uht,Fxe,pht,_ht,Qn,bht,Txe,vht,Fht,Mxe,Tht,Mht,Exe,Eht,Cht,wht,Re,tL,Cxe,Aht,Lht,dse,yht,xht,$ht,aL,wxe,kht,Sht,cse,Rht,Pht,Bht,nL,Axe,Iht,Nht,mse,qht,jht,Dht,sL,Lxe,Ght,Oht,fse,Vht,Xht,zht,lL,yxe,Qht,Wht,gse,Uht,Hht,Jht,iL,xxe,Yht,Kht,hse,Zht,eut,out,dL,$xe,rut,tut,use,aut,nut,sut,cL,kxe,lut,iut,pse,dut,cut,mut,mL,Sxe,fut,gut,_se,hut,uut,put,fL,Rxe,_ut,but,bse,vut,Fut,Tut,gL,YZe,af,hL,Pxe,kR,Mut,Bxe,Eut,KZe,xr,SR,Cut,nf,wut,vse,Aut,Lut,Fse,yut,xut,$ut,RR,kut,Ixe,Sut,Rut,Put,ga,PR,But,Nxe,Iut,Nut,sf,qut,qxe,jut,Dut,Tse,Gut,Out,Vut,uL,Xut,nt,BR,zut,jxe,Qut,Wut,Wn,Uut,Dxe,Hut,Jut,Gxe,Yut,Kut,Oxe,Zut,ept,opt,Xe,pL,Vxe,rpt,tpt,Mse,apt,npt,spt,_L,Xxe,lpt,ipt,Ese,dpt,cpt,mpt,bL,zxe,fpt,gpt,Cse,hpt,upt,ppt,vL,Qxe,_pt,bpt,wse,vpt,Fpt,Tpt,FL,Wxe,Mpt,Ept,Ase,Cpt,wpt,Apt,TL,Uxe,Lpt,ypt,Lse,xpt,$pt,kpt,ML,Hxe,Spt,Rpt,yse,Ppt,Bpt,Ipt,EL,Jxe,Npt,qpt,xse,jpt,Dpt,Gpt,CL,ZZe,lf,wL,Yxe,IR,Opt,Kxe,Vpt,eeo,$r,NR,Xpt,df,zpt,$se,Qpt,Wpt,kse,Upt,Hpt,Jpt,qR,Ypt,Zxe,Kpt,Zpt,e_t,ha,jR,o_t,e$e,r_t,t_t,cf,a_t,o$e,n_t,s_t,Sse,l_t,i_t,d_t,AL,c_t,st,DR,m_t,r$e,f_t,g_t,Un,h_t,t$e,u_t,p_t,a$e,__t,b_t,n$e,v_t,F_t,T_t,ze,LL,s$e,M_t,E_t,Rse,C_t,w_t,A_t,yL,l$e,L_t,y_t,Pse,x_t,$_t,k_t,xL,i$e,S_t,R_t,Bse,P_t,B_t,I_t,$L,d$e,N_t,q_t,Ise,j_t,D_t,G_t,kL,c$e,O_t,V_t,Nse,X_t,z_t,Q_t,SL,m$e,W_t,U_t,qse,H_t,J_t,Y_t,RL,f$e,K_t,Z_t,jse,ebt,obt,rbt,PL,g$e,tbt,abt,Dse,nbt,sbt,lbt,BL,oeo,mf,IL,h$e,GR,ibt,u$e,dbt,reo,kr,OR,cbt,ff,mbt,Gse,fbt,gbt,Ose,hbt,ubt,pbt,VR,_bt,p$e,bbt,vbt,Fbt,ua,XR,Tbt,_$e,Mbt,Ebt,gf,Cbt,b$e,wbt,Abt,Vse,Lbt,ybt,xbt,NL,$bt,lt,zR,kbt,v$e,Sbt,Rbt,Hn,Pbt,F$e,Bbt,Ibt,T$e,Nbt,qbt,M$e,jbt,Dbt,Gbt,E$e,qL,C$e,Obt,Vbt,Xse,Xbt,zbt,Qbt,jL,teo,hf,DL,w$e,QR,Wbt,A$e,Ubt,aeo,Sr,WR,Hbt,uf,Jbt,zse,Ybt,Kbt,Qse,Zbt,e2t,o2t,UR,r2t,L$e,t2t,a2t,n2t,pa,HR,s2t,y$e,l2t,i2t,pf,d2t,x$e,c2t,m2t,Wse,f2t,g2t,h2t,GL,u2t,it,JR,p2t,$$e,_2t,b2t,Jn,v2t,k$e,F2t,T2t,S$e,M2t,E2t,R$e,C2t,w2t,A2t,YR,OL,P$e,L2t,y2t,Use,x2t,$2t,k2t,VL,B$e,S2t,R2t,Hse,P2t,B2t,I2t,XL,neo,_f,zL,I$e,KR,N2t,N$e,q2t,seo,Rr,ZR,j2t,bf,D2t,Jse,G2t,O2t,Yse,V2t,X2t,z2t,eP,Q2t,q$e,W2t,U2t,H2t,_a,oP,J2t,j$e,Y2t,K2t,vf,Z2t,D$e,e1t,o1t,Kse,r1t,t1t,a1t,QL,n1t,dt,rP,s1t,G$e,l1t,i1t,Yn,d1t,O$e,c1t,m1t,V$e,f1t,g1t,X$e,h1t,u1t,p1t,z$e,WL,Q$e,_1t,b1t,Zse,v1t,F1t,T1t,UL,leo;return d=new oe({}),Qa=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),y9=new oe({}),x9=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),yf=new M1t({props:{warning:!0,$$slots:{default:[kga]},$$scope:{ctx:$}}}),$9=new oe({}),k9=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L638"}}),P9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L661"}}),Uh=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[Sga]},$$scope:{ctx:$}}}),B9=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L784"}}),I9=new oe({}),N9=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L426"}}),D9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L440"}}),$u=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[Rga]},$$scope:{ctx:$}}}),G9=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L641"}}),O9=new oe({}),V9=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L201"}}),Q9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L215"}}),vp=new M1t({props:{$$slots:{default:[Pga]},$$scope:{ctx:$}}}),Fp=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[Bga]},$$scope:{ctx:$}}}),W9=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L342"}}),U9=new oe({}),H9=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L94"}}),K9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L108"}}),Xp=new M1t({props:{$$slots:{default:[Iga]},$$scope:{ctx:$}}}),zp=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[Nga]},$$scope:{ctx:$}}}),Z9=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L275"}}),ex=new oe({}),ox=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L835"}}),tx=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Up=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[qga]},$$scope:{ctx:$}}}),ax=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),l2=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[jga]},$$scope:{ctx:$}}}),nx=new oe({}),sx=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L842"}}),ix=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),d2=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[Dga]},$$scope:{ctx:$}}}),dx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),n1=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Gga]},$$scope:{ctx:$}}}),cx=new oe({}),mx=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L857"}}),gx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),l1=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[Oga]},$$scope:{ctx:$}}}),hx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),J1=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Vga]},$$scope:{ctx:$}}}),ux=new oe({}),px=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L864"}}),bx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),K1=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[Xga]},$$scope:{ctx:$}}}),vx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),jv=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[zga]},$$scope:{ctx:$}}}),Fx=new oe({}),Tx=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L871"}}),Ex=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Gv=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Qga]},$$scope:{ctx:$}}}),Cx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),dF=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Wga]},$$scope:{ctx:$}}}),wx=new oe({}),Ax=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L880"}}),yx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),mF=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[Uga]},$$scope:{ctx:$}}}),xx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),fT=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Hga]},$$scope:{ctx:$}}}),$x=new oe({}),kx=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L936"}}),Rx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),hT=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[Jga]},$$scope:{ctx:$}}}),Px=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),UT=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Yga]},$$scope:{ctx:$}}}),Bx=new oe({}),Ix=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L943"}}),qx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),JT=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Kga]},$$scope:{ctx:$}}}),jx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),nM=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Zga]},$$scope:{ctx:$}}}),Dx=new oe({}),Gx=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L929"}}),Vx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),lM=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[eha]},$$scope:{ctx:$}}}),Xx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),WM=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[oha]},$$scope:{ctx:$}}}),zx=new oe({}),Qx=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L889"}}),Ux=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),HM=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[rha]},$$scope:{ctx:$}}}),Hx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),GE=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[tha]},$$scope:{ctx:$}}}),Jx=new oe({}),Yx=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L896"}}),Zx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),VE=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[aha]},$$scope:{ctx:$}}}),e$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),QE=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[nha]},$$scope:{ctx:$}}}),o$=new oe({}),r$=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L918"}}),a$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),UE=new B({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[sha]},$$scope:{ctx:$}}}),n$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ZE=new B({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[lha]},$$scope:{ctx:$}}}),s$=new oe({}),l$=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L952"}}),d$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),o4=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[iha]},$$scope:{ctx:$}}}),c$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_4=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[dha]},$$scope:{ctx:$}}}),m$=new oe({}),f$=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L991"}}),h$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),v4=new B({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[cha]},$$scope:{ctx:$}}}),u$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),M4=new B({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[mha]},$$scope:{ctx:$}}}),p$=new oe({}),_$=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L998"}}),v$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),C4=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[fha]},$$scope:{ctx:$}}}),F$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),L4=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[gha]},$$scope:{ctx:$}}}),T$=new oe({}),M$=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L907"}}),C$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),x4=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[hha]},$$scope:{ctx:$}}}),w$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),S4=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[uha]},$$scope:{ctx:$}}}),A$=new oe({}),L$=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1005"}}),x$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),P4=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[pha]},$$scope:{ctx:$}}}),$$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),z4=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[_ha]},$$scope:{ctx:$}}}),k$=new oe({}),S$=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1028"}}),P$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),W4=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[bha]},$$scope:{ctx:$}}}),B$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),eC=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[vha]},$$scope:{ctx:$}}}),I$=new oe({}),N$=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1012"}}),j$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),rC=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[Fha]},$$scope:{ctx:$}}}),D$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),hC=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[Tha]},$$scope:{ctx:$}}}),G$=new oe({}),O$=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1019"}}),X$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),pC=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Mha]},$$scope:{ctx:$}}}),z$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),FC=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Eha]},$$scope:{ctx:$}}}),W$=new oe({}),U$=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1037"}}),J$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),MC=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[Cha]},$$scope:{ctx:$}}}),Y$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),xC=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[wha]},$$scope:{ctx:$}}}),K$=new oe({}),Z$=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1044"}}),ok=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),kC=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[Aha]},$$scope:{ctx:$}}}),rk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),NC=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[Lha]},$$scope:{ctx:$}}}),tk=new oe({}),ak=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L984"}}),sk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),jC=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[yha]},$$scope:{ctx:$}}}),lk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),XC=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[xha]},$$scope:{ctx:$}}}),ik=new oe({}),dk=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L959"}}),mk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),QC=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[$ha]},$$scope:{ctx:$}}}),fk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),HC=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[kha]},$$scope:{ctx:$}}}),gk=new oe({}),hk=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L966"}}),pk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),YC=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[Sha]},$$scope:{ctx:$}}}),_k=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),a3=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[Rha]},$$scope:{ctx:$}}}),bk=new oe({}),vk=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L975"}}),Tk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),s3=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[Pha]},$$scope:{ctx:$}}}),Mk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),d3=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[Bha]},$$scope:{ctx:$}}}),Ek=new oe({}),Ck=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L433"}}),Ak=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),m3=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[Iha]},$$scope:{ctx:$}}}),Lk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),m5=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[Nha]},$$scope:{ctx:$}}}),yk=new oe({}),xk=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L440"}}),kk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),g5=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[qha]},$$scope:{ctx:$}}}),Sk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),N5=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[jha]},$$scope:{ctx:$}}}),Rk=new oe({}),Pk=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L455"}}),Ik=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),j5=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[Dha]},$$scope:{ctx:$}}}),Nk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),e0=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Gha]},$$scope:{ctx:$}}}),qk=new oe({}),jk=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L471"}}),Gk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),r0=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[Oha]},$$scope:{ctx:$}}}),Ok=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),m0=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Vha]},$$scope:{ctx:$}}}),Vk=new oe({}),Xk=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L480"}}),Qk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),g0=new B({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[Xha]},$$scope:{ctx:$}}}),Wk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_0=new B({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[zha]},$$scope:{ctx:$}}}),Uk=new oe({}),Hk=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L496"}}),Yk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),v0=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[Qha]},$$scope:{ctx:$}}}),Kk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),D0=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Wha]},$$scope:{ctx:$}}}),Zk=new oe({}),eS=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L503"}}),rS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),O0=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Uha]},$$scope:{ctx:$}}}),tS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Z0=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Hha]},$$scope:{ctx:$}}}),aS=new oe({}),nS=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L512"}}),lS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ow=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Jha]},$$scope:{ctx:$}}}),iS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),xw=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Yha]},$$scope:{ctx:$}}}),dS=new oe({}),cS=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L559"}}),fS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),kw=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Kha]},$$scope:{ctx:$}}}),gS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Hw=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Zha]},$$scope:{ctx:$}}}),hS=new oe({}),uS=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L566"}}),_S=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Yw=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[eua]},$$scope:{ctx:$}}}),bS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),eA=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[oua]},$$scope:{ctx:$}}}),FS=new oe({}),TS=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L539"}}),ES=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),rA=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[rua]},$$scope:{ctx:$}}}),CS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),aA=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[tua]},$$scope:{ctx:$}}}),wS=new oe({}),AS=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L528"}}),yS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),sA=new B({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[aua]},$$scope:{ctx:$}}}),xS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iA=new B({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[nua]},$$scope:{ctx:$}}}),$S=new oe({}),kS=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L550"}}),RS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),cA=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[sua]},$$scope:{ctx:$}}}),PS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),SA=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[lua]},$$scope:{ctx:$}}}),BS=new oe({}),IS=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L521"}}),qS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),PA=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[iua]},$$scope:{ctx:$}}}),jS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),r6=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[dua]},$$scope:{ctx:$}}}),DS=new oe({}),GS=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L489"}}),VS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),a6=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[cua]},$$scope:{ctx:$}}}),XS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),s6=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[mua]},$$scope:{ctx:$}}}),zS=new oe({}),QS=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L575"}}),US=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),i6=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[fua]},$$scope:{ctx:$}}}),HS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),c6=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[gua]},$$scope:{ctx:$}}}),JS=new oe({}),YS=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),ZS=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),f6=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[hua]},$$scope:{ctx:$}}}),eR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),D6=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[uua]},$$scope:{ctx:$}}}),oR=new oe({}),rR=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),aR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),O6=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[pua]},$$scope:{ctx:$}}}),nR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Z6=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[_ua]},$$scope:{ctx:$}}}),sR=new oe({}),lR=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),dR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),o7=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[bua]},$$scope:{ctx:$}}}),cR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),u7=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[vua]},$$scope:{ctx:$}}}),mR=new oe({}),fR=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),hR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),_7=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[Fua]},$$scope:{ctx:$}}}),uR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),y7=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Tua]},$$scope:{ctx:$}}}),pR=new oe({}),_R=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),vR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$7=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Mua]},$$scope:{ctx:$}}}),FR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),G7=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Eua]},$$scope:{ctx:$}}}),TR=new oe({}),MR=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),CR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),V7=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Cua]},$$scope:{ctx:$}}}),wR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),eL=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[wua]},$$scope:{ctx:$}}}),AR=new oe({}),LR=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),xR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),rL=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Aua]},$$scope:{ctx:$}}}),$R=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),gL=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Lua]},$$scope:{ctx:$}}}),kR=new oe({}),SR=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),PR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),uL=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[yua]},$$scope:{ctx:$}}}),BR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),CL=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[xua]},$$scope:{ctx:$}}}),IR=new oe({}),NR=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),jR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),AL=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[$ua]},$$scope:{ctx:$}}}),DR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),BL=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[kua]},$$scope:{ctx:$}}}),GR=new oe({}),OR=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),XR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),NL=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Sua]},$$scope:{ctx:$}}}),zR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),jL=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Rua]},$$scope:{ctx:$}}}),QR=new oe({}),WR=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),HR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),GL=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[Pua]},$$scope:{ctx:$}}}),JR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),XL=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Bua]},$$scope:{ctx:$}}}),KR=new oe({}),ZR=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),oP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),QL=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[Iua]},$$scope:{ctx:$}}}),rP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),UL=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Nua]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(d.$$.fragment),h=l(),yo=a("span"),rd=o("Auto Classes"),Ef=l(),pt=a("p"),td=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ad=a("code"),C9=o("from_pretrained()"),Cf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Ve=l(),He=a("p"),nd=o("Instantiating one of "),Zn=a("a"),w9=o("AutoConfig"),es=o(", "),os=a("a"),A9=o("AutoModel"),sd=o(`, and
`),rs=a("a"),L9=o("AutoTokenizer"),ld=o(" will directly create a class of the relevant architecture. For instance"),wf=l(),F(Qa.$$.fragment),Je=l(),Ae=a("p"),yB=o("will create a model that is an instance of "),id=a("a"),xB=o("BertModel"),$B=o("."),xo=l(),Wa=a("p"),kB=o("There is one class of "),Af=a("code"),SB=o("AutoModel"),Cro=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),UYe=l(),dd=a("h2"),Lf=a("a"),ade=a("span"),F(y9.$$.fragment),wro=l(),nde=a("span"),Aro=o("Extending the Auto Classes"),HYe=l(),ts=a("p"),Lro=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),sde=a("code"),yro=o("NewModel"),xro=o(", make sure you have a "),lde=a("code"),$ro=o("NewModelConfig"),kro=o(` then you can add those to the auto
classes like this:`),JYe=l(),F(x9.$$.fragment),YYe=l(),RB=a("p"),Sro=o("You will then be able to use the auto classes like you would usually do!"),KYe=l(),F(yf.$$.fragment),ZYe=l(),cd=a("h2"),xf=a("a"),ide=a("span"),F($9.$$.fragment),Rro=l(),dde=a("span"),Pro=o("AutoConfig"),eKe=l(),$o=a("div"),F(k9.$$.fragment),Bro=l(),S9=a("p"),Iro=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),PB=a("a"),Nro=o("from_pretrained()"),qro=o(" class method."),jro=l(),R9=a("p"),Dro=o("This class cannot be instantiated directly using "),cde=a("code"),Gro=o("__init__()"),Oro=o(" (throws an error)."),Vro=l(),Pr=a("div"),F(P9.$$.fragment),Xro=l(),mde=a("p"),zro=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),Qro=l(),md=a("p"),Wro=o("The configuration class to instantiate is selected based on the "),fde=a("code"),Uro=o("model_type"),Hro=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),gde=a("code"),Jro=o("pretrained_model_name_or_path"),Yro=o(":"),Kro=l(),A=a("ul"),$f=a("li"),hde=a("strong"),Zro=o("albert"),eto=o(" \u2014 "),BB=a("a"),oto=o("AlbertConfig"),rto=o(" (ALBERT model)"),tto=l(),kf=a("li"),ude=a("strong"),ato=o("bart"),nto=o(" \u2014 "),IB=a("a"),sto=o("BartConfig"),lto=o(" (BART model)"),ito=l(),Sf=a("li"),pde=a("strong"),dto=o("beit"),cto=o(" \u2014 "),NB=a("a"),mto=o("BeitConfig"),fto=o(" (BEiT model)"),gto=l(),Rf=a("li"),_de=a("strong"),hto=o("bert"),uto=o(" \u2014 "),qB=a("a"),pto=o("BertConfig"),_to=o(" (BERT model)"),bto=l(),Pf=a("li"),bde=a("strong"),vto=o("bert-generation"),Fto=o(" \u2014 "),jB=a("a"),Tto=o("BertGenerationConfig"),Mto=o(" (Bert Generation model)"),Eto=l(),Bf=a("li"),vde=a("strong"),Cto=o("big_bird"),wto=o(" \u2014 "),DB=a("a"),Ato=o("BigBirdConfig"),Lto=o(" (BigBird model)"),yto=l(),If=a("li"),Fde=a("strong"),xto=o("bigbird_pegasus"),$to=o(" \u2014 "),GB=a("a"),kto=o("BigBirdPegasusConfig"),Sto=o(" (BigBird-Pegasus model)"),Rto=l(),Nf=a("li"),Tde=a("strong"),Pto=o("blenderbot"),Bto=o(" \u2014 "),OB=a("a"),Ito=o("BlenderbotConfig"),Nto=o(" (Blenderbot model)"),qto=l(),qf=a("li"),Mde=a("strong"),jto=o("blenderbot-small"),Dto=o(" \u2014 "),VB=a("a"),Gto=o("BlenderbotSmallConfig"),Oto=o(" (BlenderbotSmall model)"),Vto=l(),jf=a("li"),Ede=a("strong"),Xto=o("bloom"),zto=o(" \u2014 "),XB=a("a"),Qto=o("BloomConfig"),Wto=o(" (BLOOM model)"),Uto=l(),Df=a("li"),Cde=a("strong"),Hto=o("camembert"),Jto=o(" \u2014 "),zB=a("a"),Yto=o("CamembertConfig"),Kto=o(" (CamemBERT model)"),Zto=l(),Gf=a("li"),wde=a("strong"),eao=o("canine"),oao=o(" \u2014 "),QB=a("a"),rao=o("CanineConfig"),tao=o(" (CANINE model)"),aao=l(),Of=a("li"),Ade=a("strong"),nao=o("clip"),sao=o(" \u2014 "),WB=a("a"),lao=o("CLIPConfig"),iao=o(" (CLIP model)"),dao=l(),Vf=a("li"),Lde=a("strong"),cao=o("codegen"),mao=o(" \u2014 "),UB=a("a"),fao=o("CodeGenConfig"),gao=o(" (CodeGen model)"),hao=l(),Xf=a("li"),yde=a("strong"),uao=o("convbert"),pao=o(" \u2014 "),HB=a("a"),_ao=o("ConvBertConfig"),bao=o(" (ConvBERT model)"),vao=l(),zf=a("li"),xde=a("strong"),Fao=o("convnext"),Tao=o(" \u2014 "),JB=a("a"),Mao=o("ConvNextConfig"),Eao=o(" (ConvNeXT model)"),Cao=l(),Qf=a("li"),$de=a("strong"),wao=o("ctrl"),Aao=o(" \u2014 "),YB=a("a"),Lao=o("CTRLConfig"),yao=o(" (CTRL model)"),xao=l(),Wf=a("li"),kde=a("strong"),$ao=o("cvt"),kao=o(" \u2014 "),KB=a("a"),Sao=o("CvtConfig"),Rao=o(" (CvT model)"),Pao=l(),Uf=a("li"),Sde=a("strong"),Bao=o("data2vec-audio"),Iao=o(" \u2014 "),ZB=a("a"),Nao=o("Data2VecAudioConfig"),qao=o(" (Data2VecAudio model)"),jao=l(),Hf=a("li"),Rde=a("strong"),Dao=o("data2vec-text"),Gao=o(" \u2014 "),eI=a("a"),Oao=o("Data2VecTextConfig"),Vao=o(" (Data2VecText model)"),Xao=l(),Jf=a("li"),Pde=a("strong"),zao=o("data2vec-vision"),Qao=o(" \u2014 "),oI=a("a"),Wao=o("Data2VecVisionConfig"),Uao=o(" (Data2VecVision model)"),Hao=l(),Yf=a("li"),Bde=a("strong"),Jao=o("deberta"),Yao=o(" \u2014 "),rI=a("a"),Kao=o("DebertaConfig"),Zao=o(" (DeBERTa model)"),eno=l(),Kf=a("li"),Ide=a("strong"),ono=o("deberta-v2"),rno=o(" \u2014 "),tI=a("a"),tno=o("DebertaV2Config"),ano=o(" (DeBERTa-v2 model)"),nno=l(),Zf=a("li"),Nde=a("strong"),sno=o("decision_transformer"),lno=o(" \u2014 "),aI=a("a"),ino=o("DecisionTransformerConfig"),dno=o(" (Decision Transformer model)"),cno=l(),eg=a("li"),qde=a("strong"),mno=o("deformable_detr"),fno=o(" \u2014 "),nI=a("a"),gno=o("DeformableDetrConfig"),hno=o(" (Deformable DETR model)"),uno=l(),og=a("li"),jde=a("strong"),pno=o("deit"),_no=o(" \u2014 "),sI=a("a"),bno=o("DeiTConfig"),vno=o(" (DeiT model)"),Fno=l(),rg=a("li"),Dde=a("strong"),Tno=o("detr"),Mno=o(" \u2014 "),lI=a("a"),Eno=o("DetrConfig"),Cno=o(" (DETR model)"),wno=l(),tg=a("li"),Gde=a("strong"),Ano=o("distilbert"),Lno=o(" \u2014 "),iI=a("a"),yno=o("DistilBertConfig"),xno=o(" (DistilBERT model)"),$no=l(),ag=a("li"),Ode=a("strong"),kno=o("donut-swin"),Sno=o(" \u2014 "),dI=a("a"),Rno=o("DonutSwinConfig"),Pno=o(" (DonutSwin model)"),Bno=l(),ng=a("li"),Vde=a("strong"),Ino=o("dpr"),Nno=o(" \u2014 "),cI=a("a"),qno=o("DPRConfig"),jno=o(" (DPR model)"),Dno=l(),sg=a("li"),Xde=a("strong"),Gno=o("dpt"),Ono=o(" \u2014 "),mI=a("a"),Vno=o("DPTConfig"),Xno=o(" (DPT model)"),zno=l(),lg=a("li"),zde=a("strong"),Qno=o("electra"),Wno=o(" \u2014 "),fI=a("a"),Uno=o("ElectraConfig"),Hno=o(" (ELECTRA model)"),Jno=l(),ig=a("li"),Qde=a("strong"),Yno=o("encoder-decoder"),Kno=o(" \u2014 "),gI=a("a"),Zno=o("EncoderDecoderConfig"),eso=o(" (Encoder decoder model)"),oso=l(),dg=a("li"),Wde=a("strong"),rso=o("ernie"),tso=o(" \u2014 "),hI=a("a"),aso=o("ErnieConfig"),nso=o(" (ERNIE model)"),sso=l(),cg=a("li"),Ude=a("strong"),lso=o("flaubert"),iso=o(" \u2014 "),uI=a("a"),dso=o("FlaubertConfig"),cso=o(" (FlauBERT model)"),mso=l(),mg=a("li"),Hde=a("strong"),fso=o("flava"),gso=o(" \u2014 "),pI=a("a"),hso=o("FlavaConfig"),uso=o(" (FLAVA model)"),pso=l(),fg=a("li"),Jde=a("strong"),_so=o("fnet"),bso=o(" \u2014 "),_I=a("a"),vso=o("FNetConfig"),Fso=o(" (FNet model)"),Tso=l(),gg=a("li"),Yde=a("strong"),Mso=o("fsmt"),Eso=o(" \u2014 "),bI=a("a"),Cso=o("FSMTConfig"),wso=o(" (FairSeq Machine-Translation model)"),Aso=l(),hg=a("li"),Kde=a("strong"),Lso=o("funnel"),yso=o(" \u2014 "),vI=a("a"),xso=o("FunnelConfig"),$so=o(" (Funnel Transformer model)"),kso=l(),ug=a("li"),Zde=a("strong"),Sso=o("glpn"),Rso=o(" \u2014 "),FI=a("a"),Pso=o("GLPNConfig"),Bso=o(" (GLPN model)"),Iso=l(),pg=a("li"),ece=a("strong"),Nso=o("gpt2"),qso=o(" \u2014 "),TI=a("a"),jso=o("GPT2Config"),Dso=o(" (OpenAI GPT-2 model)"),Gso=l(),_g=a("li"),oce=a("strong"),Oso=o("gpt_neo"),Vso=o(" \u2014 "),MI=a("a"),Xso=o("GPTNeoConfig"),zso=o(" (GPT Neo model)"),Qso=l(),bg=a("li"),rce=a("strong"),Wso=o("gpt_neox"),Uso=o(" \u2014 "),EI=a("a"),Hso=o("GPTNeoXConfig"),Jso=o(" (GPT NeoX model)"),Yso=l(),vg=a("li"),tce=a("strong"),Kso=o("gptj"),Zso=o(" \u2014 "),CI=a("a"),elo=o("GPTJConfig"),olo=o(" (GPT-J model)"),rlo=l(),Fg=a("li"),ace=a("strong"),tlo=o("groupvit"),alo=o(" \u2014 "),wI=a("a"),nlo=o("GroupViTConfig"),slo=o(" (GroupViT model)"),llo=l(),Tg=a("li"),nce=a("strong"),ilo=o("hubert"),dlo=o(" \u2014 "),AI=a("a"),clo=o("HubertConfig"),mlo=o(" (Hubert model)"),flo=l(),Mg=a("li"),sce=a("strong"),glo=o("ibert"),hlo=o(" \u2014 "),LI=a("a"),ulo=o("IBertConfig"),plo=o(" (I-BERT model)"),_lo=l(),Eg=a("li"),lce=a("strong"),blo=o("imagegpt"),vlo=o(" \u2014 "),yI=a("a"),Flo=o("ImageGPTConfig"),Tlo=o(" (ImageGPT model)"),Mlo=l(),Cg=a("li"),ice=a("strong"),Elo=o("layoutlm"),Clo=o(" \u2014 "),xI=a("a"),wlo=o("LayoutLMConfig"),Alo=o(" (LayoutLM model)"),Llo=l(),wg=a("li"),dce=a("strong"),ylo=o("layoutlmv2"),xlo=o(" \u2014 "),$I=a("a"),$lo=o("LayoutLMv2Config"),klo=o(" (LayoutLMv2 model)"),Slo=l(),Ag=a("li"),cce=a("strong"),Rlo=o("layoutlmv3"),Plo=o(" \u2014 "),kI=a("a"),Blo=o("LayoutLMv3Config"),Ilo=o(" (LayoutLMv3 model)"),Nlo=l(),Lg=a("li"),mce=a("strong"),qlo=o("led"),jlo=o(" \u2014 "),SI=a("a"),Dlo=o("LEDConfig"),Glo=o(" (LED model)"),Olo=l(),yg=a("li"),fce=a("strong"),Vlo=o("levit"),Xlo=o(" \u2014 "),RI=a("a"),zlo=o("LevitConfig"),Qlo=o(" (LeViT model)"),Wlo=l(),xg=a("li"),gce=a("strong"),Ulo=o("longformer"),Hlo=o(" \u2014 "),PI=a("a"),Jlo=o("LongformerConfig"),Ylo=o(" (Longformer model)"),Klo=l(),$g=a("li"),hce=a("strong"),Zlo=o("longt5"),eio=o(" \u2014 "),BI=a("a"),oio=o("LongT5Config"),rio=o(" (LongT5 model)"),tio=l(),kg=a("li"),uce=a("strong"),aio=o("luke"),nio=o(" \u2014 "),II=a("a"),sio=o("LukeConfig"),lio=o(" (LUKE model)"),iio=l(),Sg=a("li"),pce=a("strong"),dio=o("lxmert"),cio=o(" \u2014 "),NI=a("a"),mio=o("LxmertConfig"),fio=o(" (LXMERT model)"),gio=l(),Rg=a("li"),_ce=a("strong"),hio=o("m2m_100"),uio=o(" \u2014 "),qI=a("a"),pio=o("M2M100Config"),_io=o(" (M2M100 model)"),bio=l(),Pg=a("li"),bce=a("strong"),vio=o("marian"),Fio=o(" \u2014 "),jI=a("a"),Tio=o("MarianConfig"),Mio=o(" (Marian model)"),Eio=l(),Bg=a("li"),vce=a("strong"),Cio=o("maskformer"),wio=o(" \u2014 "),DI=a("a"),Aio=o("MaskFormerConfig"),Lio=o(" (MaskFormer model)"),yio=l(),Ig=a("li"),Fce=a("strong"),xio=o("mbart"),$io=o(" \u2014 "),GI=a("a"),kio=o("MBartConfig"),Sio=o(" (mBART model)"),Rio=l(),Ng=a("li"),Tce=a("strong"),Pio=o("mctct"),Bio=o(" \u2014 "),OI=a("a"),Iio=o("MCTCTConfig"),Nio=o(" (M-CTC-T model)"),qio=l(),qg=a("li"),Mce=a("strong"),jio=o("megatron-bert"),Dio=o(" \u2014 "),VI=a("a"),Gio=o("MegatronBertConfig"),Oio=o(" (Megatron-BERT model)"),Vio=l(),jg=a("li"),Ece=a("strong"),Xio=o("mobilebert"),zio=o(" \u2014 "),XI=a("a"),Qio=o("MobileBertConfig"),Wio=o(" (MobileBERT model)"),Uio=l(),Dg=a("li"),Cce=a("strong"),Hio=o("mobilevit"),Jio=o(" \u2014 "),zI=a("a"),Yio=o("MobileViTConfig"),Kio=o(" (MobileViT model)"),Zio=l(),Gg=a("li"),wce=a("strong"),edo=o("mpnet"),odo=o(" \u2014 "),QI=a("a"),rdo=o("MPNetConfig"),tdo=o(" (MPNet model)"),ado=l(),Og=a("li"),Ace=a("strong"),ndo=o("mt5"),sdo=o(" \u2014 "),WI=a("a"),ldo=o("MT5Config"),ido=o(" (MT5 model)"),ddo=l(),Vg=a("li"),Lce=a("strong"),cdo=o("mvp"),mdo=o(" \u2014 "),UI=a("a"),fdo=o("MvpConfig"),gdo=o(" (MVP model)"),hdo=l(),Xg=a("li"),yce=a("strong"),udo=o("nezha"),pdo=o(" \u2014 "),HI=a("a"),_do=o("NezhaConfig"),bdo=o(" (Nezha model)"),vdo=l(),zg=a("li"),xce=a("strong"),Fdo=o("nystromformer"),Tdo=o(" \u2014 "),JI=a("a"),Mdo=o("NystromformerConfig"),Edo=o(" (Nystr\xF6mformer model)"),Cdo=l(),Qg=a("li"),$ce=a("strong"),wdo=o("openai-gpt"),Ado=o(" \u2014 "),YI=a("a"),Ldo=o("OpenAIGPTConfig"),ydo=o(" (OpenAI GPT model)"),xdo=l(),Wg=a("li"),kce=a("strong"),$do=o("opt"),kdo=o(" \u2014 "),KI=a("a"),Sdo=o("OPTConfig"),Rdo=o(" (OPT model)"),Pdo=l(),Ug=a("li"),Sce=a("strong"),Bdo=o("owlvit"),Ido=o(" \u2014 "),ZI=a("a"),Ndo=o("OwlViTConfig"),qdo=o(" (OWL-ViT model)"),jdo=l(),Hg=a("li"),Rce=a("strong"),Ddo=o("pegasus"),Gdo=o(" \u2014 "),eN=a("a"),Odo=o("PegasusConfig"),Vdo=o(" (Pegasus model)"),Xdo=l(),Jg=a("li"),Pce=a("strong"),zdo=o("pegasus_x"),Qdo=o(" \u2014 "),oN=a("a"),Wdo=o("PegasusXConfig"),Udo=o(" (PEGASUS-X model)"),Hdo=l(),Yg=a("li"),Bce=a("strong"),Jdo=o("perceiver"),Ydo=o(" \u2014 "),rN=a("a"),Kdo=o("PerceiverConfig"),Zdo=o(" (Perceiver model)"),eco=l(),Kg=a("li"),Ice=a("strong"),oco=o("plbart"),rco=o(" \u2014 "),tN=a("a"),tco=o("PLBartConfig"),aco=o(" (PLBart model)"),nco=l(),Zg=a("li"),Nce=a("strong"),sco=o("poolformer"),lco=o(" \u2014 "),aN=a("a"),ico=o("PoolFormerConfig"),dco=o(" (PoolFormer model)"),cco=l(),eh=a("li"),qce=a("strong"),mco=o("prophetnet"),fco=o(" \u2014 "),nN=a("a"),gco=o("ProphetNetConfig"),hco=o(" (ProphetNet model)"),uco=l(),oh=a("li"),jce=a("strong"),pco=o("qdqbert"),_co=o(" \u2014 "),sN=a("a"),bco=o("QDQBertConfig"),vco=o(" (QDQBert model)"),Fco=l(),rh=a("li"),Dce=a("strong"),Tco=o("rag"),Mco=o(" \u2014 "),lN=a("a"),Eco=o("RagConfig"),Cco=o(" (RAG model)"),wco=l(),th=a("li"),Gce=a("strong"),Aco=o("realm"),Lco=o(" \u2014 "),iN=a("a"),yco=o("RealmConfig"),xco=o(" (REALM model)"),$co=l(),ah=a("li"),Oce=a("strong"),kco=o("reformer"),Sco=o(" \u2014 "),dN=a("a"),Rco=o("ReformerConfig"),Pco=o(" (Reformer model)"),Bco=l(),nh=a("li"),Vce=a("strong"),Ico=o("regnet"),Nco=o(" \u2014 "),cN=a("a"),qco=o("RegNetConfig"),jco=o(" (RegNet model)"),Dco=l(),sh=a("li"),Xce=a("strong"),Gco=o("rembert"),Oco=o(" \u2014 "),mN=a("a"),Vco=o("RemBertConfig"),Xco=o(" (RemBERT model)"),zco=l(),lh=a("li"),zce=a("strong"),Qco=o("resnet"),Wco=o(" \u2014 "),fN=a("a"),Uco=o("ResNetConfig"),Hco=o(" (ResNet model)"),Jco=l(),ih=a("li"),Qce=a("strong"),Yco=o("retribert"),Kco=o(" \u2014 "),gN=a("a"),Zco=o("RetriBertConfig"),emo=o(" (RetriBERT model)"),omo=l(),dh=a("li"),Wce=a("strong"),rmo=o("roberta"),tmo=o(" \u2014 "),hN=a("a"),amo=o("RobertaConfig"),nmo=o(" (RoBERTa model)"),smo=l(),ch=a("li"),Uce=a("strong"),lmo=o("roformer"),imo=o(" \u2014 "),uN=a("a"),dmo=o("RoFormerConfig"),cmo=o(" (RoFormer model)"),mmo=l(),mh=a("li"),Hce=a("strong"),fmo=o("segformer"),gmo=o(" \u2014 "),pN=a("a"),hmo=o("SegformerConfig"),umo=o(" (SegFormer model)"),pmo=l(),fh=a("li"),Jce=a("strong"),_mo=o("sew"),bmo=o(" \u2014 "),_N=a("a"),vmo=o("SEWConfig"),Fmo=o(" (SEW model)"),Tmo=l(),gh=a("li"),Yce=a("strong"),Mmo=o("sew-d"),Emo=o(" \u2014 "),bN=a("a"),Cmo=o("SEWDConfig"),wmo=o(" (SEW-D model)"),Amo=l(),hh=a("li"),Kce=a("strong"),Lmo=o("speech-encoder-decoder"),ymo=o(" \u2014 "),vN=a("a"),xmo=o("SpeechEncoderDecoderConfig"),$mo=o(" (Speech Encoder decoder model)"),kmo=l(),uh=a("li"),Zce=a("strong"),Smo=o("speech_to_text"),Rmo=o(" \u2014 "),FN=a("a"),Pmo=o("Speech2TextConfig"),Bmo=o(" (Speech2Text model)"),Imo=l(),ph=a("li"),eme=a("strong"),Nmo=o("speech_to_text_2"),qmo=o(" \u2014 "),TN=a("a"),jmo=o("Speech2Text2Config"),Dmo=o(" (Speech2Text2 model)"),Gmo=l(),_h=a("li"),ome=a("strong"),Omo=o("splinter"),Vmo=o(" \u2014 "),MN=a("a"),Xmo=o("SplinterConfig"),zmo=o(" (Splinter model)"),Qmo=l(),bh=a("li"),rme=a("strong"),Wmo=o("squeezebert"),Umo=o(" \u2014 "),EN=a("a"),Hmo=o("SqueezeBertConfig"),Jmo=o(" (SqueezeBERT model)"),Ymo=l(),vh=a("li"),tme=a("strong"),Kmo=o("swin"),Zmo=o(" \u2014 "),CN=a("a"),efo=o("SwinConfig"),ofo=o(" (Swin Transformer model)"),rfo=l(),Fh=a("li"),ame=a("strong"),tfo=o("swinv2"),afo=o(" \u2014 "),wN=a("a"),nfo=o("Swinv2Config"),sfo=o(" (Swin Transformer V2 model)"),lfo=l(),Th=a("li"),nme=a("strong"),ifo=o("t5"),dfo=o(" \u2014 "),AN=a("a"),cfo=o("T5Config"),mfo=o(" (T5 model)"),ffo=l(),Mh=a("li"),sme=a("strong"),gfo=o("tapas"),hfo=o(" \u2014 "),LN=a("a"),ufo=o("TapasConfig"),pfo=o(" (TAPAS model)"),_fo=l(),Eh=a("li"),lme=a("strong"),bfo=o("trajectory_transformer"),vfo=o(" \u2014 "),yN=a("a"),Ffo=o("TrajectoryTransformerConfig"),Tfo=o(" (Trajectory Transformer model)"),Mfo=l(),Ch=a("li"),ime=a("strong"),Efo=o("transfo-xl"),Cfo=o(" \u2014 "),xN=a("a"),wfo=o("TransfoXLConfig"),Afo=o(" (Transformer-XL model)"),Lfo=l(),wh=a("li"),dme=a("strong"),yfo=o("trocr"),xfo=o(" \u2014 "),$N=a("a"),$fo=o("TrOCRConfig"),kfo=o(" (TrOCR model)"),Sfo=l(),Ah=a("li"),cme=a("strong"),Rfo=o("unispeech"),Pfo=o(" \u2014 "),kN=a("a"),Bfo=o("UniSpeechConfig"),Ifo=o(" (UniSpeech model)"),Nfo=l(),Lh=a("li"),mme=a("strong"),qfo=o("unispeech-sat"),jfo=o(" \u2014 "),SN=a("a"),Dfo=o("UniSpeechSatConfig"),Gfo=o(" (UniSpeechSat model)"),Ofo=l(),yh=a("li"),fme=a("strong"),Vfo=o("van"),Xfo=o(" \u2014 "),RN=a("a"),zfo=o("VanConfig"),Qfo=o(" (VAN model)"),Wfo=l(),xh=a("li"),gme=a("strong"),Ufo=o("videomae"),Hfo=o(" \u2014 "),PN=a("a"),Jfo=o("VideoMAEConfig"),Yfo=o(" (VideoMAE model)"),Kfo=l(),$h=a("li"),hme=a("strong"),Zfo=o("vilt"),ego=o(" \u2014 "),BN=a("a"),ogo=o("ViltConfig"),rgo=o(" (ViLT model)"),tgo=l(),kh=a("li"),ume=a("strong"),ago=o("vision-encoder-decoder"),ngo=o(" \u2014 "),IN=a("a"),sgo=o("VisionEncoderDecoderConfig"),lgo=o(" (Vision Encoder decoder model)"),igo=l(),Sh=a("li"),pme=a("strong"),dgo=o("vision-text-dual-encoder"),cgo=o(" \u2014 "),NN=a("a"),mgo=o("VisionTextDualEncoderConfig"),fgo=o(" (VisionTextDualEncoder model)"),ggo=l(),Rh=a("li"),_me=a("strong"),hgo=o("visual_bert"),ugo=o(" \u2014 "),qN=a("a"),pgo=o("VisualBertConfig"),_go=o(" (VisualBERT model)"),bgo=l(),Ph=a("li"),bme=a("strong"),vgo=o("vit"),Fgo=o(" \u2014 "),jN=a("a"),Tgo=o("ViTConfig"),Mgo=o(" (ViT model)"),Ego=l(),Bh=a("li"),vme=a("strong"),Cgo=o("vit_mae"),wgo=o(" \u2014 "),DN=a("a"),Ago=o("ViTMAEConfig"),Lgo=o(" (ViTMAE model)"),ygo=l(),Ih=a("li"),Fme=a("strong"),xgo=o("wav2vec2"),$go=o(" \u2014 "),GN=a("a"),kgo=o("Wav2Vec2Config"),Sgo=o(" (Wav2Vec2 model)"),Rgo=l(),Nh=a("li"),Tme=a("strong"),Pgo=o("wav2vec2-conformer"),Bgo=o(" \u2014 "),ON=a("a"),Igo=o("Wav2Vec2ConformerConfig"),Ngo=o(" (Wav2Vec2-Conformer model)"),qgo=l(),qh=a("li"),Mme=a("strong"),jgo=o("wavlm"),Dgo=o(" \u2014 "),VN=a("a"),Ggo=o("WavLMConfig"),Ogo=o(" (WavLM model)"),Vgo=l(),jh=a("li"),Eme=a("strong"),Xgo=o("xclip"),zgo=o(" \u2014 "),XN=a("a"),Qgo=o("XCLIPConfig"),Wgo=o(" (X-CLIP model)"),Ugo=l(),Dh=a("li"),Cme=a("strong"),Hgo=o("xglm"),Jgo=o(" \u2014 "),zN=a("a"),Ygo=o("XGLMConfig"),Kgo=o(" (XGLM model)"),Zgo=l(),Gh=a("li"),wme=a("strong"),eho=o("xlm"),oho=o(" \u2014 "),QN=a("a"),rho=o("XLMConfig"),tho=o(" (XLM model)"),aho=l(),Oh=a("li"),Ame=a("strong"),nho=o("xlm-prophetnet"),sho=o(" \u2014 "),WN=a("a"),lho=o("XLMProphetNetConfig"),iho=o(" (XLM-ProphetNet model)"),dho=l(),Vh=a("li"),Lme=a("strong"),cho=o("xlm-roberta"),mho=o(" \u2014 "),UN=a("a"),fho=o("XLMRobertaConfig"),gho=o(" (XLM-RoBERTa model)"),hho=l(),Xh=a("li"),yme=a("strong"),uho=o("xlm-roberta-xl"),pho=o(" \u2014 "),HN=a("a"),_ho=o("XLMRobertaXLConfig"),bho=o(" (XLM-RoBERTa-XL model)"),vho=l(),zh=a("li"),xme=a("strong"),Fho=o("xlnet"),Tho=o(" \u2014 "),JN=a("a"),Mho=o("XLNetConfig"),Eho=o(" (XLNet model)"),Cho=l(),Qh=a("li"),$me=a("strong"),who=o("yolos"),Aho=o(" \u2014 "),YN=a("a"),Lho=o("YolosConfig"),yho=o(" (YOLOS model)"),xho=l(),Wh=a("li"),kme=a("strong"),$ho=o("yoso"),kho=o(" \u2014 "),KN=a("a"),Sho=o("YosoConfig"),Rho=o(" (YOSO model)"),Pho=l(),F(Uh.$$.fragment),Bho=l(),Hh=a("div"),F(B9.$$.fragment),Iho=l(),Sme=a("p"),Nho=o("Register a new configuration for this class."),oKe=l(),fd=a("h2"),Jh=a("a"),Rme=a("span"),F(I9.$$.fragment),qho=l(),Pme=a("span"),jho=o("AutoTokenizer"),rKe=l(),ko=a("div"),F(N9.$$.fragment),Dho=l(),q9=a("p"),Gho=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),ZN=a("a"),Oho=o("AutoTokenizer.from_pretrained()"),Vho=o(" class method."),Xho=l(),j9=a("p"),zho=o("This class cannot be instantiated directly using "),Bme=a("code"),Qho=o("__init__()"),Who=o(" (throws an error)."),Uho=l(),Br=a("div"),F(D9.$$.fragment),Hho=l(),Ime=a("p"),Jho=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Yho=l(),Ua=a("p"),Kho=o("The tokenizer class to instantiate is selected based on the "),Nme=a("code"),Zho=o("model_type"),euo=o(` property of the config object (either
passed as an argument or loaded from `),qme=a("code"),ouo=o("pretrained_model_name_or_path"),ruo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jme=a("code"),tuo=o("pretrained_model_name_or_path"),auo=o(":"),nuo=l(),k=a("ul"),as=a("li"),Dme=a("strong"),suo=o("albert"),luo=o(" \u2014 "),eq=a("a"),iuo=o("AlbertTokenizer"),duo=o(" or "),oq=a("a"),cuo=o("AlbertTokenizerFast"),muo=o(" (ALBERT model)"),fuo=l(),ns=a("li"),Gme=a("strong"),guo=o("bart"),huo=o(" \u2014 "),rq=a("a"),uuo=o("BartTokenizer"),puo=o(" or "),tq=a("a"),_uo=o("BartTokenizerFast"),buo=o(" (BART model)"),vuo=l(),ss=a("li"),Ome=a("strong"),Fuo=o("barthez"),Tuo=o(" \u2014 "),aq=a("a"),Muo=o("BarthezTokenizer"),Euo=o(" or "),nq=a("a"),Cuo=o("BarthezTokenizerFast"),wuo=o(" (BARThez model)"),Auo=l(),Yh=a("li"),Vme=a("strong"),Luo=o("bartpho"),yuo=o(" \u2014 "),sq=a("a"),xuo=o("BartphoTokenizer"),$uo=o(" (BARTpho model)"),kuo=l(),ls=a("li"),Xme=a("strong"),Suo=o("bert"),Ruo=o(" \u2014 "),lq=a("a"),Puo=o("BertTokenizer"),Buo=o(" or "),iq=a("a"),Iuo=o("BertTokenizerFast"),Nuo=o(" (BERT model)"),quo=l(),Kh=a("li"),zme=a("strong"),juo=o("bert-generation"),Duo=o(" \u2014 "),dq=a("a"),Guo=o("BertGenerationTokenizer"),Ouo=o(" (Bert Generation model)"),Vuo=l(),Zh=a("li"),Qme=a("strong"),Xuo=o("bert-japanese"),zuo=o(" \u2014 "),cq=a("a"),Quo=o("BertJapaneseTokenizer"),Wuo=o(" (BertJapanese model)"),Uuo=l(),eu=a("li"),Wme=a("strong"),Huo=o("bertweet"),Juo=o(" \u2014 "),mq=a("a"),Yuo=o("BertweetTokenizer"),Kuo=o(" (BERTweet model)"),Zuo=l(),is=a("li"),Ume=a("strong"),epo=o("big_bird"),opo=o(" \u2014 "),fq=a("a"),rpo=o("BigBirdTokenizer"),tpo=o(" or "),gq=a("a"),apo=o("BigBirdTokenizerFast"),npo=o(" (BigBird model)"),spo=l(),ds=a("li"),Hme=a("strong"),lpo=o("bigbird_pegasus"),ipo=o(" \u2014 "),hq=a("a"),dpo=o("PegasusTokenizer"),cpo=o(" or "),uq=a("a"),mpo=o("PegasusTokenizerFast"),fpo=o(" (BigBird-Pegasus model)"),gpo=l(),cs=a("li"),Jme=a("strong"),hpo=o("blenderbot"),upo=o(" \u2014 "),pq=a("a"),ppo=o("BlenderbotTokenizer"),_po=o(" or "),_q=a("a"),bpo=o("BlenderbotTokenizerFast"),vpo=o(" (Blenderbot model)"),Fpo=l(),ou=a("li"),Yme=a("strong"),Tpo=o("blenderbot-small"),Mpo=o(" \u2014 "),bq=a("a"),Epo=o("BlenderbotSmallTokenizer"),Cpo=o(" (BlenderbotSmall model)"),wpo=l(),ru=a("li"),Kme=a("strong"),Apo=o("bloom"),Lpo=o(" \u2014 "),vq=a("a"),ypo=o("BloomTokenizerFast"),xpo=o(" (BLOOM model)"),$po=l(),tu=a("li"),Zme=a("strong"),kpo=o("byt5"),Spo=o(" \u2014 "),Fq=a("a"),Rpo=o("ByT5Tokenizer"),Ppo=o(" (ByT5 model)"),Bpo=l(),ms=a("li"),efe=a("strong"),Ipo=o("camembert"),Npo=o(" \u2014 "),Tq=a("a"),qpo=o("CamembertTokenizer"),jpo=o(" or "),Mq=a("a"),Dpo=o("CamembertTokenizerFast"),Gpo=o(" (CamemBERT model)"),Opo=l(),au=a("li"),ofe=a("strong"),Vpo=o("canine"),Xpo=o(" \u2014 "),Eq=a("a"),zpo=o("CanineTokenizer"),Qpo=o(" (CANINE model)"),Wpo=l(),fs=a("li"),rfe=a("strong"),Upo=o("clip"),Hpo=o(" \u2014 "),Cq=a("a"),Jpo=o("CLIPTokenizer"),Ypo=o(" or "),wq=a("a"),Kpo=o("CLIPTokenizerFast"),Zpo=o(" (CLIP model)"),e_o=l(),gs=a("li"),tfe=a("strong"),o_o=o("codegen"),r_o=o(" \u2014 "),Aq=a("a"),t_o=o("CodeGenTokenizer"),a_o=o(" or "),Lq=a("a"),n_o=o("CodeGenTokenizerFast"),s_o=o(" (CodeGen model)"),l_o=l(),hs=a("li"),afe=a("strong"),i_o=o("convbert"),d_o=o(" \u2014 "),yq=a("a"),c_o=o("ConvBertTokenizer"),m_o=o(" or "),xq=a("a"),f_o=o("ConvBertTokenizerFast"),g_o=o(" (ConvBERT model)"),h_o=l(),us=a("li"),nfe=a("strong"),u_o=o("cpm"),p_o=o(" \u2014 "),$q=a("a"),__o=o("CpmTokenizer"),b_o=o(" or "),kq=a("a"),v_o=o("CpmTokenizerFast"),F_o=o(" (CPM model)"),T_o=l(),nu=a("li"),sfe=a("strong"),M_o=o("ctrl"),E_o=o(" \u2014 "),Sq=a("a"),C_o=o("CTRLTokenizer"),w_o=o(" (CTRL model)"),A_o=l(),ps=a("li"),lfe=a("strong"),L_o=o("data2vec-text"),y_o=o(" \u2014 "),Rq=a("a"),x_o=o("RobertaTokenizer"),$_o=o(" or "),Pq=a("a"),k_o=o("RobertaTokenizerFast"),S_o=o(" (Data2VecText model)"),R_o=l(),_s=a("li"),ife=a("strong"),P_o=o("deberta"),B_o=o(" \u2014 "),Bq=a("a"),I_o=o("DebertaTokenizer"),N_o=o(" or "),Iq=a("a"),q_o=o("DebertaTokenizerFast"),j_o=o(" (DeBERTa model)"),D_o=l(),bs=a("li"),dfe=a("strong"),G_o=o("deberta-v2"),O_o=o(" \u2014 "),Nq=a("a"),V_o=o("DebertaV2Tokenizer"),X_o=o(" or "),qq=a("a"),z_o=o("DebertaV2TokenizerFast"),Q_o=o(" (DeBERTa-v2 model)"),W_o=l(),vs=a("li"),cfe=a("strong"),U_o=o("distilbert"),H_o=o(" \u2014 "),jq=a("a"),J_o=o("DistilBertTokenizer"),Y_o=o(" or "),Dq=a("a"),K_o=o("DistilBertTokenizerFast"),Z_o=o(" (DistilBERT model)"),ebo=l(),Fs=a("li"),mfe=a("strong"),obo=o("dpr"),rbo=o(" \u2014 "),Gq=a("a"),tbo=o("DPRQuestionEncoderTokenizer"),abo=o(" or "),Oq=a("a"),nbo=o("DPRQuestionEncoderTokenizerFast"),sbo=o(" (DPR model)"),lbo=l(),Ts=a("li"),ffe=a("strong"),ibo=o("electra"),dbo=o(" \u2014 "),Vq=a("a"),cbo=o("ElectraTokenizer"),mbo=o(" or "),Xq=a("a"),fbo=o("ElectraTokenizerFast"),gbo=o(" (ELECTRA model)"),hbo=l(),Ms=a("li"),gfe=a("strong"),ubo=o("ernie"),pbo=o(" \u2014 "),zq=a("a"),_bo=o("BertTokenizer"),bbo=o(" or "),Qq=a("a"),vbo=o("BertTokenizerFast"),Fbo=o(" (ERNIE model)"),Tbo=l(),su=a("li"),hfe=a("strong"),Mbo=o("flaubert"),Ebo=o(" \u2014 "),Wq=a("a"),Cbo=o("FlaubertTokenizer"),wbo=o(" (FlauBERT model)"),Abo=l(),Es=a("li"),ufe=a("strong"),Lbo=o("fnet"),ybo=o(" \u2014 "),Uq=a("a"),xbo=o("FNetTokenizer"),$bo=o(" or "),Hq=a("a"),kbo=o("FNetTokenizerFast"),Sbo=o(" (FNet model)"),Rbo=l(),lu=a("li"),pfe=a("strong"),Pbo=o("fsmt"),Bbo=o(" \u2014 "),Jq=a("a"),Ibo=o("FSMTTokenizer"),Nbo=o(" (FairSeq Machine-Translation model)"),qbo=l(),Cs=a("li"),_fe=a("strong"),jbo=o("funnel"),Dbo=o(" \u2014 "),Yq=a("a"),Gbo=o("FunnelTokenizer"),Obo=o(" or "),Kq=a("a"),Vbo=o("FunnelTokenizerFast"),Xbo=o(" (Funnel Transformer model)"),zbo=l(),ws=a("li"),bfe=a("strong"),Qbo=o("gpt2"),Wbo=o(" \u2014 "),Zq=a("a"),Ubo=o("GPT2Tokenizer"),Hbo=o(" or "),ej=a("a"),Jbo=o("GPT2TokenizerFast"),Ybo=o(" (OpenAI GPT-2 model)"),Kbo=l(),As=a("li"),vfe=a("strong"),Zbo=o("gpt_neo"),e2o=o(" \u2014 "),oj=a("a"),o2o=o("GPT2Tokenizer"),r2o=o(" or "),rj=a("a"),t2o=o("GPT2TokenizerFast"),a2o=o(" (GPT Neo model)"),n2o=l(),iu=a("li"),Ffe=a("strong"),s2o=o("gpt_neox"),l2o=o(" \u2014 "),tj=a("a"),i2o=o("GPTNeoXTokenizerFast"),d2o=o(" (GPT NeoX model)"),c2o=l(),Ls=a("li"),Tfe=a("strong"),m2o=o("gptj"),f2o=o(" \u2014 "),aj=a("a"),g2o=o("GPT2Tokenizer"),h2o=o(" or "),nj=a("a"),u2o=o("GPT2TokenizerFast"),p2o=o(" (GPT-J model)"),_2o=l(),ys=a("li"),Mfe=a("strong"),b2o=o("groupvit"),v2o=o(" \u2014 "),sj=a("a"),F2o=o("CLIPTokenizer"),T2o=o(" or "),lj=a("a"),M2o=o("CLIPTokenizerFast"),E2o=o(" (GroupViT model)"),C2o=l(),xs=a("li"),Efe=a("strong"),w2o=o("herbert"),A2o=o(" \u2014 "),ij=a("a"),L2o=o("HerbertTokenizer"),y2o=o(" or "),dj=a("a"),x2o=o("HerbertTokenizerFast"),$2o=o(" (HerBERT model)"),k2o=l(),du=a("li"),Cfe=a("strong"),S2o=o("hubert"),R2o=o(" \u2014 "),cj=a("a"),P2o=o("Wav2Vec2CTCTokenizer"),B2o=o(" (Hubert model)"),I2o=l(),$s=a("li"),wfe=a("strong"),N2o=o("ibert"),q2o=o(" \u2014 "),mj=a("a"),j2o=o("RobertaTokenizer"),D2o=o(" or "),fj=a("a"),G2o=o("RobertaTokenizerFast"),O2o=o(" (I-BERT model)"),V2o=l(),ks=a("li"),Afe=a("strong"),X2o=o("layoutlm"),z2o=o(" \u2014 "),gj=a("a"),Q2o=o("LayoutLMTokenizer"),W2o=o(" or "),hj=a("a"),U2o=o("LayoutLMTokenizerFast"),H2o=o(" (LayoutLM model)"),J2o=l(),Ss=a("li"),Lfe=a("strong"),Y2o=o("layoutlmv2"),K2o=o(" \u2014 "),uj=a("a"),Z2o=o("LayoutLMv2Tokenizer"),e1o=o(" or "),pj=a("a"),o1o=o("LayoutLMv2TokenizerFast"),r1o=o(" (LayoutLMv2 model)"),t1o=l(),Rs=a("li"),yfe=a("strong"),a1o=o("layoutlmv3"),n1o=o(" \u2014 "),_j=a("a"),s1o=o("LayoutLMv3Tokenizer"),l1o=o(" or "),bj=a("a"),i1o=o("LayoutLMv3TokenizerFast"),d1o=o(" (LayoutLMv3 model)"),c1o=l(),Ps=a("li"),xfe=a("strong"),m1o=o("layoutxlm"),f1o=o(" \u2014 "),vj=a("a"),g1o=o("LayoutXLMTokenizer"),h1o=o(" or "),Fj=a("a"),u1o=o("LayoutXLMTokenizerFast"),p1o=o(" (LayoutXLM model)"),_1o=l(),Bs=a("li"),$fe=a("strong"),b1o=o("led"),v1o=o(" \u2014 "),Tj=a("a"),F1o=o("LEDTokenizer"),T1o=o(" or "),Mj=a("a"),M1o=o("LEDTokenizerFast"),E1o=o(" (LED model)"),C1o=l(),Is=a("li"),kfe=a("strong"),w1o=o("longformer"),A1o=o(" \u2014 "),Ej=a("a"),L1o=o("LongformerTokenizer"),y1o=o(" or "),Cj=a("a"),x1o=o("LongformerTokenizerFast"),$1o=o(" (Longformer model)"),k1o=l(),Ns=a("li"),Sfe=a("strong"),S1o=o("longt5"),R1o=o(" \u2014 "),wj=a("a"),P1o=o("T5Tokenizer"),B1o=o(" or "),Aj=a("a"),I1o=o("T5TokenizerFast"),N1o=o(" (LongT5 model)"),q1o=l(),cu=a("li"),Rfe=a("strong"),j1o=o("luke"),D1o=o(" \u2014 "),Lj=a("a"),G1o=o("LukeTokenizer"),O1o=o(" (LUKE model)"),V1o=l(),qs=a("li"),Pfe=a("strong"),X1o=o("lxmert"),z1o=o(" \u2014 "),yj=a("a"),Q1o=o("LxmertTokenizer"),W1o=o(" or "),xj=a("a"),U1o=o("LxmertTokenizerFast"),H1o=o(" (LXMERT model)"),J1o=l(),mu=a("li"),Bfe=a("strong"),Y1o=o("m2m_100"),K1o=o(" \u2014 "),$j=a("a"),Z1o=o("M2M100Tokenizer"),evo=o(" (M2M100 model)"),ovo=l(),fu=a("li"),Ife=a("strong"),rvo=o("marian"),tvo=o(" \u2014 "),kj=a("a"),avo=o("MarianTokenizer"),nvo=o(" (Marian model)"),svo=l(),js=a("li"),Nfe=a("strong"),lvo=o("mbart"),ivo=o(" \u2014 "),Sj=a("a"),dvo=o("MBartTokenizer"),cvo=o(" or "),Rj=a("a"),mvo=o("MBartTokenizerFast"),fvo=o(" (mBART model)"),gvo=l(),Ds=a("li"),qfe=a("strong"),hvo=o("mbart50"),uvo=o(" \u2014 "),Pj=a("a"),pvo=o("MBart50Tokenizer"),_vo=o(" or "),Bj=a("a"),bvo=o("MBart50TokenizerFast"),vvo=o(" (mBART-50 model)"),Fvo=l(),Gs=a("li"),jfe=a("strong"),Tvo=o("megatron-bert"),Mvo=o(" \u2014 "),Ij=a("a"),Evo=o("BertTokenizer"),Cvo=o(" or "),Nj=a("a"),wvo=o("BertTokenizerFast"),Avo=o(" (Megatron-BERT model)"),Lvo=l(),gu=a("li"),Dfe=a("strong"),yvo=o("mluke"),xvo=o(" \u2014 "),qj=a("a"),$vo=o("MLukeTokenizer"),kvo=o(" (mLUKE model)"),Svo=l(),Os=a("li"),Gfe=a("strong"),Rvo=o("mobilebert"),Pvo=o(" \u2014 "),jj=a("a"),Bvo=o("MobileBertTokenizer"),Ivo=o(" or "),Dj=a("a"),Nvo=o("MobileBertTokenizerFast"),qvo=o(" (MobileBERT model)"),jvo=l(),Vs=a("li"),Ofe=a("strong"),Dvo=o("mpnet"),Gvo=o(" \u2014 "),Gj=a("a"),Ovo=o("MPNetTokenizer"),Vvo=o(" or "),Oj=a("a"),Xvo=o("MPNetTokenizerFast"),zvo=o(" (MPNet model)"),Qvo=l(),Xs=a("li"),Vfe=a("strong"),Wvo=o("mt5"),Uvo=o(" \u2014 "),Vj=a("a"),Hvo=o("MT5Tokenizer"),Jvo=o(" or "),Xj=a("a"),Yvo=o("MT5TokenizerFast"),Kvo=o(" (MT5 model)"),Zvo=l(),zs=a("li"),Xfe=a("strong"),eFo=o("mvp"),oFo=o(" \u2014 "),zj=a("a"),rFo=o("MvpTokenizer"),tFo=o(" or "),Qj=a("a"),aFo=o("MvpTokenizerFast"),nFo=o(" (MVP model)"),sFo=l(),Qs=a("li"),zfe=a("strong"),lFo=o("nezha"),iFo=o(" \u2014 "),Wj=a("a"),dFo=o("BertTokenizer"),cFo=o(" or "),Uj=a("a"),mFo=o("BertTokenizerFast"),fFo=o(" (Nezha model)"),gFo=l(),Ws=a("li"),Qfe=a("strong"),hFo=o("nllb"),uFo=o(" \u2014 "),Hj=a("a"),pFo=o("NllbTokenizer"),_Fo=o(" or "),Jj=a("a"),bFo=o("NllbTokenizerFast"),vFo=o(" (NLLB model)"),FFo=l(),Us=a("li"),Wfe=a("strong"),TFo=o("nystromformer"),MFo=o(" \u2014 "),Yj=a("a"),EFo=o("AlbertTokenizer"),CFo=o(" or "),Kj=a("a"),wFo=o("AlbertTokenizerFast"),AFo=o(" (Nystr\xF6mformer model)"),LFo=l(),Hs=a("li"),Ufe=a("strong"),yFo=o("openai-gpt"),xFo=o(" \u2014 "),Zj=a("a"),$Fo=o("OpenAIGPTTokenizer"),kFo=o(" or "),eD=a("a"),SFo=o("OpenAIGPTTokenizerFast"),RFo=o(" (OpenAI GPT model)"),PFo=l(),hu=a("li"),Hfe=a("strong"),BFo=o("opt"),IFo=o(" \u2014 "),oD=a("a"),NFo=o("GPT2Tokenizer"),qFo=o(" (OPT model)"),jFo=l(),Js=a("li"),Jfe=a("strong"),DFo=o("owlvit"),GFo=o(" \u2014 "),rD=a("a"),OFo=o("CLIPTokenizer"),VFo=o(" or "),tD=a("a"),XFo=o("CLIPTokenizerFast"),zFo=o(" (OWL-ViT model)"),QFo=l(),Ys=a("li"),Yfe=a("strong"),WFo=o("pegasus"),UFo=o(" \u2014 "),aD=a("a"),HFo=o("PegasusTokenizer"),JFo=o(" or "),nD=a("a"),YFo=o("PegasusTokenizerFast"),KFo=o(" (Pegasus model)"),ZFo=l(),uu=a("li"),Kfe=a("strong"),eTo=o("perceiver"),oTo=o(" \u2014 "),sD=a("a"),rTo=o("PerceiverTokenizer"),tTo=o(" (Perceiver model)"),aTo=l(),pu=a("li"),Zfe=a("strong"),nTo=o("phobert"),sTo=o(" \u2014 "),lD=a("a"),lTo=o("PhobertTokenizer"),iTo=o(" (PhoBERT model)"),dTo=l(),_u=a("li"),ege=a("strong"),cTo=o("plbart"),mTo=o(" \u2014 "),iD=a("a"),fTo=o("PLBartTokenizer"),gTo=o(" (PLBart model)"),hTo=l(),bu=a("li"),oge=a("strong"),uTo=o("prophetnet"),pTo=o(" \u2014 "),dD=a("a"),_To=o("ProphetNetTokenizer"),bTo=o(" (ProphetNet model)"),vTo=l(),Ks=a("li"),rge=a("strong"),FTo=o("qdqbert"),TTo=o(" \u2014 "),cD=a("a"),MTo=o("BertTokenizer"),ETo=o(" or "),mD=a("a"),CTo=o("BertTokenizerFast"),wTo=o(" (QDQBert model)"),ATo=l(),vu=a("li"),tge=a("strong"),LTo=o("rag"),yTo=o(" \u2014 "),fD=a("a"),xTo=o("RagTokenizer"),$To=o(" (RAG model)"),kTo=l(),Zs=a("li"),age=a("strong"),STo=o("realm"),RTo=o(" \u2014 "),gD=a("a"),PTo=o("RealmTokenizer"),BTo=o(" or "),hD=a("a"),ITo=o("RealmTokenizerFast"),NTo=o(" (REALM model)"),qTo=l(),el=a("li"),nge=a("strong"),jTo=o("reformer"),DTo=o(" \u2014 "),uD=a("a"),GTo=o("ReformerTokenizer"),OTo=o(" or "),pD=a("a"),VTo=o("ReformerTokenizerFast"),XTo=o(" (Reformer model)"),zTo=l(),ol=a("li"),sge=a("strong"),QTo=o("rembert"),WTo=o(" \u2014 "),_D=a("a"),UTo=o("RemBertTokenizer"),HTo=o(" or "),bD=a("a"),JTo=o("RemBertTokenizerFast"),YTo=o(" (RemBERT model)"),KTo=l(),rl=a("li"),lge=a("strong"),ZTo=o("retribert"),eMo=o(" \u2014 "),vD=a("a"),oMo=o("RetriBertTokenizer"),rMo=o(" or "),FD=a("a"),tMo=o("RetriBertTokenizerFast"),aMo=o(" (RetriBERT model)"),nMo=l(),tl=a("li"),ige=a("strong"),sMo=o("roberta"),lMo=o(" \u2014 "),TD=a("a"),iMo=o("RobertaTokenizer"),dMo=o(" or "),MD=a("a"),cMo=o("RobertaTokenizerFast"),mMo=o(" (RoBERTa model)"),fMo=l(),al=a("li"),dge=a("strong"),gMo=o("roformer"),hMo=o(" \u2014 "),ED=a("a"),uMo=o("RoFormerTokenizer"),pMo=o(" or "),CD=a("a"),_Mo=o("RoFormerTokenizerFast"),bMo=o(" (RoFormer model)"),vMo=l(),Fu=a("li"),cge=a("strong"),FMo=o("speech_to_text"),TMo=o(" \u2014 "),wD=a("a"),MMo=o("Speech2TextTokenizer"),EMo=o(" (Speech2Text model)"),CMo=l(),Tu=a("li"),mge=a("strong"),wMo=o("speech_to_text_2"),AMo=o(" \u2014 "),AD=a("a"),LMo=o("Speech2Text2Tokenizer"),yMo=o(" (Speech2Text2 model)"),xMo=l(),nl=a("li"),fge=a("strong"),$Mo=o("splinter"),kMo=o(" \u2014 "),LD=a("a"),SMo=o("SplinterTokenizer"),RMo=o(" or "),yD=a("a"),PMo=o("SplinterTokenizerFast"),BMo=o(" (Splinter model)"),IMo=l(),sl=a("li"),gge=a("strong"),NMo=o("squeezebert"),qMo=o(" \u2014 "),xD=a("a"),jMo=o("SqueezeBertTokenizer"),DMo=o(" or "),$D=a("a"),GMo=o("SqueezeBertTokenizerFast"),OMo=o(" (SqueezeBERT model)"),VMo=l(),ll=a("li"),hge=a("strong"),XMo=o("t5"),zMo=o(" \u2014 "),kD=a("a"),QMo=o("T5Tokenizer"),WMo=o(" or "),SD=a("a"),UMo=o("T5TokenizerFast"),HMo=o(" (T5 model)"),JMo=l(),Mu=a("li"),uge=a("strong"),YMo=o("tapas"),KMo=o(" \u2014 "),RD=a("a"),ZMo=o("TapasTokenizer"),eEo=o(" (TAPAS model)"),oEo=l(),Eu=a("li"),pge=a("strong"),rEo=o("tapex"),tEo=o(" \u2014 "),PD=a("a"),aEo=o("TapexTokenizer"),nEo=o(" (TAPEX model)"),sEo=l(),Cu=a("li"),_ge=a("strong"),lEo=o("transfo-xl"),iEo=o(" \u2014 "),BD=a("a"),dEo=o("TransfoXLTokenizer"),cEo=o(" (Transformer-XL model)"),mEo=l(),il=a("li"),bge=a("strong"),fEo=o("vilt"),gEo=o(" \u2014 "),ID=a("a"),hEo=o("BertTokenizer"),uEo=o(" or "),ND=a("a"),pEo=o("BertTokenizerFast"),_Eo=o(" (ViLT model)"),bEo=l(),dl=a("li"),vge=a("strong"),vEo=o("visual_bert"),FEo=o(" \u2014 "),qD=a("a"),TEo=o("BertTokenizer"),MEo=o(" or "),jD=a("a"),EEo=o("BertTokenizerFast"),CEo=o(" (VisualBERT model)"),wEo=l(),wu=a("li"),Fge=a("strong"),AEo=o("wav2vec2"),LEo=o(" \u2014 "),DD=a("a"),yEo=o("Wav2Vec2CTCTokenizer"),xEo=o(" (Wav2Vec2 model)"),$Eo=l(),Au=a("li"),Tge=a("strong"),kEo=o("wav2vec2-conformer"),SEo=o(" \u2014 "),GD=a("a"),REo=o("Wav2Vec2CTCTokenizer"),PEo=o(" (Wav2Vec2-Conformer model)"),BEo=l(),Lu=a("li"),Mge=a("strong"),IEo=o("wav2vec2_phoneme"),NEo=o(" \u2014 "),OD=a("a"),qEo=o("Wav2Vec2PhonemeCTCTokenizer"),jEo=o(" (Wav2Vec2Phoneme model)"),DEo=l(),cl=a("li"),Ege=a("strong"),GEo=o("xclip"),OEo=o(" \u2014 "),VD=a("a"),VEo=o("CLIPTokenizer"),XEo=o(" or "),XD=a("a"),zEo=o("CLIPTokenizerFast"),QEo=o(" (X-CLIP model)"),WEo=l(),ml=a("li"),Cge=a("strong"),UEo=o("xglm"),HEo=o(" \u2014 "),zD=a("a"),JEo=o("XGLMTokenizer"),YEo=o(" or "),QD=a("a"),KEo=o("XGLMTokenizerFast"),ZEo=o(" (XGLM model)"),e4o=l(),yu=a("li"),wge=a("strong"),o4o=o("xlm"),r4o=o(" \u2014 "),WD=a("a"),t4o=o("XLMTokenizer"),a4o=o(" (XLM model)"),n4o=l(),xu=a("li"),Age=a("strong"),s4o=o("xlm-prophetnet"),l4o=o(" \u2014 "),UD=a("a"),i4o=o("XLMProphetNetTokenizer"),d4o=o(" (XLM-ProphetNet model)"),c4o=l(),fl=a("li"),Lge=a("strong"),m4o=o("xlm-roberta"),f4o=o(" \u2014 "),HD=a("a"),g4o=o("XLMRobertaTokenizer"),h4o=o(" or "),JD=a("a"),u4o=o("XLMRobertaTokenizerFast"),p4o=o(" (XLM-RoBERTa model)"),_4o=l(),gl=a("li"),yge=a("strong"),b4o=o("xlm-roberta-xl"),v4o=o(" \u2014 "),YD=a("a"),F4o=o("XLMRobertaTokenizer"),T4o=o(" or "),KD=a("a"),M4o=o("XLMRobertaTokenizerFast"),E4o=o(" (XLM-RoBERTa-XL model)"),C4o=l(),hl=a("li"),xge=a("strong"),w4o=o("xlnet"),A4o=o(" \u2014 "),ZD=a("a"),L4o=o("XLNetTokenizer"),y4o=o(" or "),eG=a("a"),x4o=o("XLNetTokenizerFast"),$4o=o(" (XLNet model)"),k4o=l(),ul=a("li"),$ge=a("strong"),S4o=o("yoso"),R4o=o(" \u2014 "),oG=a("a"),P4o=o("AlbertTokenizer"),B4o=o(" or "),rG=a("a"),I4o=o("AlbertTokenizerFast"),N4o=o(" (YOSO model)"),q4o=l(),F($u.$$.fragment),j4o=l(),ku=a("div"),F(G9.$$.fragment),D4o=l(),kge=a("p"),G4o=o("Register a new tokenizer in this mapping."),tKe=l(),gd=a("h2"),Su=a("a"),Sge=a("span"),F(O9.$$.fragment),O4o=l(),Rge=a("span"),V4o=o("AutoFeatureExtractor"),aKe=l(),So=a("div"),F(V9.$$.fragment),X4o=l(),X9=a("p"),z4o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),tG=a("a"),Q4o=o("AutoFeatureExtractor.from_pretrained()"),W4o=o(" class method."),U4o=l(),z9=a("p"),H4o=o("This class cannot be instantiated directly using "),Pge=a("code"),J4o=o("__init__()"),Y4o=o(" (throws an error)."),K4o=l(),Ye=a("div"),F(Q9.$$.fragment),Z4o=l(),Bge=a("p"),eCo=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),oCo=l(),Ha=a("p"),rCo=o("The feature extractor class to instantiate is selected based on the "),Ige=a("code"),tCo=o("model_type"),aCo=o(` property of the config object
(either passed as an argument or loaded from `),Nge=a("code"),nCo=o("pretrained_model_name_or_path"),sCo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),qge=a("code"),lCo=o("pretrained_model_name_or_path"),iCo=o(":"),dCo=l(),Q=a("ul"),Ru=a("li"),jge=a("strong"),cCo=o("beit"),mCo=o(" \u2014 "),aG=a("a"),fCo=o("BeitFeatureExtractor"),gCo=o(" (BEiT model)"),hCo=l(),Pu=a("li"),Dge=a("strong"),uCo=o("clip"),pCo=o(" \u2014 "),nG=a("a"),_Co=o("CLIPFeatureExtractor"),bCo=o(" (CLIP model)"),vCo=l(),Bu=a("li"),Gge=a("strong"),FCo=o("convnext"),TCo=o(" \u2014 "),sG=a("a"),MCo=o("ConvNextFeatureExtractor"),ECo=o(" (ConvNeXT model)"),CCo=l(),Iu=a("li"),Oge=a("strong"),wCo=o("cvt"),ACo=o(" \u2014 "),lG=a("a"),LCo=o("ConvNextFeatureExtractor"),yCo=o(" (CvT model)"),xCo=l(),Nu=a("li"),Vge=a("strong"),$Co=o("data2vec-audio"),kCo=o(" \u2014 "),iG=a("a"),SCo=o("Wav2Vec2FeatureExtractor"),RCo=o(" (Data2VecAudio model)"),PCo=l(),qu=a("li"),Xge=a("strong"),BCo=o("data2vec-vision"),ICo=o(" \u2014 "),dG=a("a"),NCo=o("BeitFeatureExtractor"),qCo=o(" (Data2VecVision model)"),jCo=l(),ju=a("li"),zge=a("strong"),DCo=o("deformable_detr"),GCo=o(" \u2014 "),cG=a("a"),OCo=o("DetrFeatureExtractor"),VCo=o(" (Deformable DETR model)"),XCo=l(),Du=a("li"),Qge=a("strong"),zCo=o("deit"),QCo=o(" \u2014 "),mG=a("a"),WCo=o("DeiTFeatureExtractor"),UCo=o(" (DeiT model)"),HCo=l(),Gu=a("li"),Wge=a("strong"),JCo=o("detr"),YCo=o(" \u2014 "),fG=a("a"),KCo=o("DetrFeatureExtractor"),ZCo=o(" (DETR model)"),e3o=l(),Ou=a("li"),Uge=a("strong"),o3o=o("donut"),r3o=o(" \u2014 "),gG=a("a"),t3o=o("DonutFeatureExtractor"),a3o=o(" (Donut model)"),n3o=l(),Vu=a("li"),Hge=a("strong"),s3o=o("dpt"),l3o=o(" \u2014 "),hG=a("a"),i3o=o("DPTFeatureExtractor"),d3o=o(" (DPT model)"),c3o=l(),Xu=a("li"),Jge=a("strong"),m3o=o("flava"),f3o=o(" \u2014 "),uG=a("a"),g3o=o("FlavaFeatureExtractor"),h3o=o(" (FLAVA model)"),u3o=l(),zu=a("li"),Yge=a("strong"),p3o=o("glpn"),_3o=o(" \u2014 "),pG=a("a"),b3o=o("GLPNFeatureExtractor"),v3o=o(" (GLPN model)"),F3o=l(),Qu=a("li"),Kge=a("strong"),T3o=o("groupvit"),M3o=o(" \u2014 "),_G=a("a"),E3o=o("CLIPFeatureExtractor"),C3o=o(" (GroupViT model)"),w3o=l(),Wu=a("li"),Zge=a("strong"),A3o=o("hubert"),L3o=o(" \u2014 "),bG=a("a"),y3o=o("Wav2Vec2FeatureExtractor"),x3o=o(" (Hubert model)"),$3o=l(),Uu=a("li"),ehe=a("strong"),k3o=o("imagegpt"),S3o=o(" \u2014 "),vG=a("a"),R3o=o("ImageGPTFeatureExtractor"),P3o=o(" (ImageGPT model)"),B3o=l(),Hu=a("li"),ohe=a("strong"),I3o=o("layoutlmv2"),N3o=o(" \u2014 "),FG=a("a"),q3o=o("LayoutLMv2FeatureExtractor"),j3o=o(" (LayoutLMv2 model)"),D3o=l(),Ju=a("li"),rhe=a("strong"),G3o=o("layoutlmv3"),O3o=o(" \u2014 "),TG=a("a"),V3o=o("LayoutLMv3FeatureExtractor"),X3o=o(" (LayoutLMv3 model)"),z3o=l(),Yu=a("li"),the=a("strong"),Q3o=o("levit"),W3o=o(" \u2014 "),MG=a("a"),U3o=o("LevitFeatureExtractor"),H3o=o(" (LeViT model)"),J3o=l(),Ku=a("li"),ahe=a("strong"),Y3o=o("maskformer"),K3o=o(" \u2014 "),EG=a("a"),Z3o=o("MaskFormerFeatureExtractor"),e5o=o(" (MaskFormer model)"),o5o=l(),Zu=a("li"),nhe=a("strong"),r5o=o("mctct"),t5o=o(" \u2014 "),CG=a("a"),a5o=o("MCTCTFeatureExtractor"),n5o=o(" (M-CTC-T model)"),s5o=l(),ep=a("li"),she=a("strong"),l5o=o("mobilevit"),i5o=o(" \u2014 "),wG=a("a"),d5o=o("MobileViTFeatureExtractor"),c5o=o(" (MobileViT model)"),m5o=l(),op=a("li"),lhe=a("strong"),f5o=o("owlvit"),g5o=o(" \u2014 "),AG=a("a"),h5o=o("OwlViTFeatureExtractor"),u5o=o(" (OWL-ViT model)"),p5o=l(),rp=a("li"),ihe=a("strong"),_5o=o("perceiver"),b5o=o(" \u2014 "),LG=a("a"),v5o=o("PerceiverFeatureExtractor"),F5o=o(" (Perceiver model)"),T5o=l(),tp=a("li"),dhe=a("strong"),M5o=o("poolformer"),E5o=o(" \u2014 "),yG=a("a"),C5o=o("PoolFormerFeatureExtractor"),w5o=o(" (PoolFormer model)"),A5o=l(),ap=a("li"),che=a("strong"),L5o=o("regnet"),y5o=o(" \u2014 "),xG=a("a"),x5o=o("ConvNextFeatureExtractor"),$5o=o(" (RegNet model)"),k5o=l(),np=a("li"),mhe=a("strong"),S5o=o("resnet"),R5o=o(" \u2014 "),$G=a("a"),P5o=o("ConvNextFeatureExtractor"),B5o=o(" (ResNet model)"),I5o=l(),sp=a("li"),fhe=a("strong"),N5o=o("segformer"),q5o=o(" \u2014 "),kG=a("a"),j5o=o("SegformerFeatureExtractor"),D5o=o(" (SegFormer model)"),G5o=l(),lp=a("li"),ghe=a("strong"),O5o=o("speech_to_text"),V5o=o(" \u2014 "),SG=a("a"),X5o=o("Speech2TextFeatureExtractor"),z5o=o(" (Speech2Text model)"),Q5o=l(),ip=a("li"),hhe=a("strong"),W5o=o("swin"),U5o=o(" \u2014 "),RG=a("a"),H5o=o("ViTFeatureExtractor"),J5o=o(" (Swin Transformer model)"),Y5o=l(),dp=a("li"),uhe=a("strong"),K5o=o("swinv2"),Z5o=o(" \u2014 "),PG=a("a"),e0o=o("ViTFeatureExtractor"),o0o=o(" (Swin Transformer V2 model)"),r0o=l(),cp=a("li"),phe=a("strong"),t0o=o("van"),a0o=o(" \u2014 "),BG=a("a"),n0o=o("ConvNextFeatureExtractor"),s0o=o(" (VAN model)"),l0o=l(),mp=a("li"),_he=a("strong"),i0o=o("videomae"),d0o=o(" \u2014 "),IG=a("a"),c0o=o("VideoMAEFeatureExtractor"),m0o=o(" (VideoMAE model)"),f0o=l(),fp=a("li"),bhe=a("strong"),g0o=o("vilt"),h0o=o(" \u2014 "),NG=a("a"),u0o=o("ViltFeatureExtractor"),p0o=o(" (ViLT model)"),_0o=l(),gp=a("li"),vhe=a("strong"),b0o=o("vit"),v0o=o(" \u2014 "),qG=a("a"),F0o=o("ViTFeatureExtractor"),T0o=o(" (ViT model)"),M0o=l(),hp=a("li"),Fhe=a("strong"),E0o=o("vit_mae"),C0o=o(" \u2014 "),jG=a("a"),w0o=o("ViTFeatureExtractor"),A0o=o(" (ViTMAE model)"),L0o=l(),up=a("li"),The=a("strong"),y0o=o("wav2vec2"),x0o=o(" \u2014 "),DG=a("a"),$0o=o("Wav2Vec2FeatureExtractor"),k0o=o(" (Wav2Vec2 model)"),S0o=l(),pp=a("li"),Mhe=a("strong"),R0o=o("wav2vec2-conformer"),P0o=o(" \u2014 "),GG=a("a"),B0o=o("Wav2Vec2FeatureExtractor"),I0o=o(" (Wav2Vec2-Conformer model)"),N0o=l(),_p=a("li"),Ehe=a("strong"),q0o=o("xclip"),j0o=o(" \u2014 "),OG=a("a"),D0o=o("CLIPFeatureExtractor"),G0o=o(" (X-CLIP model)"),O0o=l(),bp=a("li"),Che=a("strong"),V0o=o("yolos"),X0o=o(" \u2014 "),VG=a("a"),z0o=o("YolosFeatureExtractor"),Q0o=o(" (YOLOS model)"),W0o=l(),F(vp.$$.fragment),U0o=l(),F(Fp.$$.fragment),H0o=l(),Tp=a("div"),F(W9.$$.fragment),J0o=l(),whe=a("p"),Y0o=o("Register a new feature extractor for this class."),nKe=l(),hd=a("h2"),Mp=a("a"),Ahe=a("span"),F(U9.$$.fragment),K0o=l(),Lhe=a("span"),Z0o=o("AutoProcessor"),sKe=l(),Ro=a("div"),F(H9.$$.fragment),ewo=l(),J9=a("p"),owo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),XG=a("a"),rwo=o("AutoProcessor.from_pretrained()"),two=o(" class method."),awo=l(),Y9=a("p"),nwo=o("This class cannot be instantiated directly using "),yhe=a("code"),swo=o("__init__()"),lwo=o(" (throws an error)."),iwo=l(),Ke=a("div"),F(K9.$$.fragment),dwo=l(),xhe=a("p"),cwo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),mwo=l(),ud=a("p"),fwo=o("The processor class to instantiate is selected based on the "),$he=a("code"),gwo=o("model_type"),hwo=o(` property of the config object (either
passed as an argument or loaded from `),khe=a("code"),uwo=o("pretrained_model_name_or_path"),pwo=o(" if possible):"),_wo=l(),ie=a("ul"),Ep=a("li"),She=a("strong"),bwo=o("clip"),vwo=o(" \u2014 "),zG=a("a"),Fwo=o("CLIPProcessor"),Two=o(" (CLIP model)"),Mwo=l(),Cp=a("li"),Rhe=a("strong"),Ewo=o("donut"),Cwo=o(" \u2014 "),QG=a("a"),wwo=o("DonutProcessor"),Awo=o(" (Donut model)"),Lwo=l(),wp=a("li"),Phe=a("strong"),ywo=o("flava"),xwo=o(" \u2014 "),WG=a("a"),$wo=o("FlavaProcessor"),kwo=o(" (FLAVA model)"),Swo=l(),Ap=a("li"),Bhe=a("strong"),Rwo=o("groupvit"),Pwo=o(" \u2014 "),UG=a("a"),Bwo=o("CLIPProcessor"),Iwo=o(" (GroupViT model)"),Nwo=l(),Lp=a("li"),Ihe=a("strong"),qwo=o("layoutlmv2"),jwo=o(" \u2014 "),HG=a("a"),Dwo=o("LayoutLMv2Processor"),Gwo=o(" (LayoutLMv2 model)"),Owo=l(),yp=a("li"),Nhe=a("strong"),Vwo=o("layoutlmv3"),Xwo=o(" \u2014 "),JG=a("a"),zwo=o("LayoutLMv3Processor"),Qwo=o(" (LayoutLMv3 model)"),Wwo=l(),xp=a("li"),qhe=a("strong"),Uwo=o("layoutxlm"),Hwo=o(" \u2014 "),YG=a("a"),Jwo=o("LayoutXLMProcessor"),Ywo=o(" (LayoutXLM model)"),Kwo=l(),$p=a("li"),jhe=a("strong"),Zwo=o("owlvit"),eAo=o(" \u2014 "),KG=a("a"),oAo=o("OwlViTProcessor"),rAo=o(" (OWL-ViT model)"),tAo=l(),kp=a("li"),Dhe=a("strong"),aAo=o("sew"),nAo=o(" \u2014 "),ZG=a("a"),sAo=o("Wav2Vec2Processor"),lAo=o(" (SEW model)"),iAo=l(),Sp=a("li"),Ghe=a("strong"),dAo=o("sew-d"),cAo=o(" \u2014 "),eO=a("a"),mAo=o("Wav2Vec2Processor"),fAo=o(" (SEW-D model)"),gAo=l(),Rp=a("li"),Ohe=a("strong"),hAo=o("speech_to_text"),uAo=o(" \u2014 "),oO=a("a"),pAo=o("Speech2TextProcessor"),_Ao=o(" (Speech2Text model)"),bAo=l(),Pp=a("li"),Vhe=a("strong"),vAo=o("speech_to_text_2"),FAo=o(" \u2014 "),rO=a("a"),TAo=o("Speech2Text2Processor"),MAo=o(" (Speech2Text2 model)"),EAo=l(),Bp=a("li"),Xhe=a("strong"),CAo=o("trocr"),wAo=o(" \u2014 "),tO=a("a"),AAo=o("TrOCRProcessor"),LAo=o(" (TrOCR model)"),yAo=l(),Ip=a("li"),zhe=a("strong"),xAo=o("unispeech"),$Ao=o(" \u2014 "),aO=a("a"),kAo=o("Wav2Vec2Processor"),SAo=o(" (UniSpeech model)"),RAo=l(),Np=a("li"),Qhe=a("strong"),PAo=o("unispeech-sat"),BAo=o(" \u2014 "),nO=a("a"),IAo=o("Wav2Vec2Processor"),NAo=o(" (UniSpeechSat model)"),qAo=l(),qp=a("li"),Whe=a("strong"),jAo=o("vilt"),DAo=o(" \u2014 "),sO=a("a"),GAo=o("ViltProcessor"),OAo=o(" (ViLT model)"),VAo=l(),jp=a("li"),Uhe=a("strong"),XAo=o("vision-text-dual-encoder"),zAo=o(" \u2014 "),lO=a("a"),QAo=o("VisionTextDualEncoderProcessor"),WAo=o(" (VisionTextDualEncoder model)"),UAo=l(),Dp=a("li"),Hhe=a("strong"),HAo=o("wav2vec2"),JAo=o(" \u2014 "),iO=a("a"),YAo=o("Wav2Vec2Processor"),KAo=o(" (Wav2Vec2 model)"),ZAo=l(),Gp=a("li"),Jhe=a("strong"),e6o=o("wav2vec2-conformer"),o6o=o(" \u2014 "),dO=a("a"),r6o=o("Wav2Vec2Processor"),t6o=o(" (Wav2Vec2-Conformer model)"),a6o=l(),Op=a("li"),Yhe=a("strong"),n6o=o("wavlm"),s6o=o(" \u2014 "),cO=a("a"),l6o=o("Wav2Vec2Processor"),i6o=o(" (WavLM model)"),d6o=l(),Vp=a("li"),Khe=a("strong"),c6o=o("xclip"),m6o=o(" \u2014 "),mO=a("a"),f6o=o("CLIPProcessor"),g6o=o(" (X-CLIP model)"),h6o=l(),F(Xp.$$.fragment),u6o=l(),F(zp.$$.fragment),p6o=l(),Qp=a("div"),F(Z9.$$.fragment),_6o=l(),Zhe=a("p"),b6o=o("Register a new processor for this class."),lKe=l(),pd=a("h2"),Wp=a("a"),eue=a("span"),F(ex.$$.fragment),v6o=l(),oue=a("span"),F6o=o("AutoModel"),iKe=l(),Po=a("div"),F(ox.$$.fragment),T6o=l(),_d=a("p"),M6o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),fO=a("a"),E6o=o("from_pretrained()"),C6o=o(" class method or the "),gO=a("a"),w6o=o("from_config()"),A6o=o(` class
method.`),L6o=l(),rx=a("p"),y6o=o("This class cannot be instantiated directly using "),rue=a("code"),x6o=o("__init__()"),$6o=o(" (throws an error)."),k6o=l(),_t=a("div"),F(tx.$$.fragment),S6o=l(),tue=a("p"),R6o=o("Instantiates one of the base model classes of the library from a configuration."),P6o=l(),bd=a("p"),B6o=o(`Note:
Loading a model from its configuration file does `),aue=a("strong"),I6o=o("not"),N6o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hO=a("a"),q6o=o("from_pretrained()"),j6o=o(" to load the model weights."),D6o=l(),F(Up.$$.fragment),G6o=l(),Ze=a("div"),F(ax.$$.fragment),O6o=l(),nue=a("p"),V6o=o("Instantiate one of the base model classes of the library from a pretrained model."),X6o=l(),Ja=a("p"),z6o=o("The model class to instantiate is selected based on the "),sue=a("code"),Q6o=o("model_type"),W6o=o(` property of the config object (either
passed as an argument or loaded from `),lue=a("code"),U6o=o("pretrained_model_name_or_path"),H6o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iue=a("code"),J6o=o("pretrained_model_name_or_path"),Y6o=o(":"),K6o=l(),y=a("ul"),Hp=a("li"),due=a("strong"),Z6o=o("albert"),e7o=o(" \u2014 "),uO=a("a"),o7o=o("AlbertModel"),r7o=o(" (ALBERT model)"),t7o=l(),Jp=a("li"),cue=a("strong"),a7o=o("bart"),n7o=o(" \u2014 "),pO=a("a"),s7o=o("BartModel"),l7o=o(" (BART model)"),i7o=l(),Yp=a("li"),mue=a("strong"),d7o=o("beit"),c7o=o(" \u2014 "),_O=a("a"),m7o=o("BeitModel"),f7o=o(" (BEiT model)"),g7o=l(),Kp=a("li"),fue=a("strong"),h7o=o("bert"),u7o=o(" \u2014 "),bO=a("a"),p7o=o("BertModel"),_7o=o(" (BERT model)"),b7o=l(),Zp=a("li"),gue=a("strong"),v7o=o("bert-generation"),F7o=o(" \u2014 "),vO=a("a"),T7o=o("BertGenerationEncoder"),M7o=o(" (Bert Generation model)"),E7o=l(),e_=a("li"),hue=a("strong"),C7o=o("big_bird"),w7o=o(" \u2014 "),FO=a("a"),A7o=o("BigBirdModel"),L7o=o(" (BigBird model)"),y7o=l(),o_=a("li"),uue=a("strong"),x7o=o("bigbird_pegasus"),$7o=o(" \u2014 "),TO=a("a"),k7o=o("BigBirdPegasusModel"),S7o=o(" (BigBird-Pegasus model)"),R7o=l(),r_=a("li"),pue=a("strong"),P7o=o("blenderbot"),B7o=o(" \u2014 "),MO=a("a"),I7o=o("BlenderbotModel"),N7o=o(" (Blenderbot model)"),q7o=l(),t_=a("li"),_ue=a("strong"),j7o=o("blenderbot-small"),D7o=o(" \u2014 "),EO=a("a"),G7o=o("BlenderbotSmallModel"),O7o=o(" (BlenderbotSmall model)"),V7o=l(),a_=a("li"),bue=a("strong"),X7o=o("bloom"),z7o=o(" \u2014 "),CO=a("a"),Q7o=o("BloomModel"),W7o=o(" (BLOOM model)"),U7o=l(),n_=a("li"),vue=a("strong"),H7o=o("camembert"),J7o=o(" \u2014 "),wO=a("a"),Y7o=o("CamembertModel"),K7o=o(" (CamemBERT model)"),Z7o=l(),s_=a("li"),Fue=a("strong"),eLo=o("canine"),oLo=o(" \u2014 "),AO=a("a"),rLo=o("CanineModel"),tLo=o(" (CANINE model)"),aLo=l(),l_=a("li"),Tue=a("strong"),nLo=o("clip"),sLo=o(" \u2014 "),LO=a("a"),lLo=o("CLIPModel"),iLo=o(" (CLIP model)"),dLo=l(),i_=a("li"),Mue=a("strong"),cLo=o("codegen"),mLo=o(" \u2014 "),yO=a("a"),fLo=o("CodeGenModel"),gLo=o(" (CodeGen model)"),hLo=l(),d_=a("li"),Eue=a("strong"),uLo=o("convbert"),pLo=o(" \u2014 "),xO=a("a"),_Lo=o("ConvBertModel"),bLo=o(" (ConvBERT model)"),vLo=l(),c_=a("li"),Cue=a("strong"),FLo=o("convnext"),TLo=o(" \u2014 "),$O=a("a"),MLo=o("ConvNextModel"),ELo=o(" (ConvNeXT model)"),CLo=l(),m_=a("li"),wue=a("strong"),wLo=o("ctrl"),ALo=o(" \u2014 "),kO=a("a"),LLo=o("CTRLModel"),yLo=o(" (CTRL model)"),xLo=l(),f_=a("li"),Aue=a("strong"),$Lo=o("cvt"),kLo=o(" \u2014 "),SO=a("a"),SLo=o("CvtModel"),RLo=o(" (CvT model)"),PLo=l(),g_=a("li"),Lue=a("strong"),BLo=o("data2vec-audio"),ILo=o(" \u2014 "),RO=a("a"),NLo=o("Data2VecAudioModel"),qLo=o(" (Data2VecAudio model)"),jLo=l(),h_=a("li"),yue=a("strong"),DLo=o("data2vec-text"),GLo=o(" \u2014 "),PO=a("a"),OLo=o("Data2VecTextModel"),VLo=o(" (Data2VecText model)"),XLo=l(),u_=a("li"),xue=a("strong"),zLo=o("data2vec-vision"),QLo=o(" \u2014 "),BO=a("a"),WLo=o("Data2VecVisionModel"),ULo=o(" (Data2VecVision model)"),HLo=l(),p_=a("li"),$ue=a("strong"),JLo=o("deberta"),YLo=o(" \u2014 "),IO=a("a"),KLo=o("DebertaModel"),ZLo=o(" (DeBERTa model)"),eyo=l(),__=a("li"),kue=a("strong"),oyo=o("deberta-v2"),ryo=o(" \u2014 "),NO=a("a"),tyo=o("DebertaV2Model"),ayo=o(" (DeBERTa-v2 model)"),nyo=l(),b_=a("li"),Sue=a("strong"),syo=o("decision_transformer"),lyo=o(" \u2014 "),qO=a("a"),iyo=o("DecisionTransformerModel"),dyo=o(" (Decision Transformer model)"),cyo=l(),v_=a("li"),Rue=a("strong"),myo=o("deformable_detr"),fyo=o(" \u2014 "),jO=a("a"),gyo=o("DeformableDetrModel"),hyo=o(" (Deformable DETR model)"),uyo=l(),F_=a("li"),Pue=a("strong"),pyo=o("deit"),_yo=o(" \u2014 "),DO=a("a"),byo=o("DeiTModel"),vyo=o(" (DeiT model)"),Fyo=l(),T_=a("li"),Bue=a("strong"),Tyo=o("detr"),Myo=o(" \u2014 "),GO=a("a"),Eyo=o("DetrModel"),Cyo=o(" (DETR model)"),wyo=l(),M_=a("li"),Iue=a("strong"),Ayo=o("distilbert"),Lyo=o(" \u2014 "),OO=a("a"),yyo=o("DistilBertModel"),xyo=o(" (DistilBERT model)"),$yo=l(),E_=a("li"),Nue=a("strong"),kyo=o("donut-swin"),Syo=o(" \u2014 "),VO=a("a"),Ryo=o("DonutSwinModel"),Pyo=o(" (DonutSwin model)"),Byo=l(),C_=a("li"),que=a("strong"),Iyo=o("dpr"),Nyo=o(" \u2014 "),XO=a("a"),qyo=o("DPRQuestionEncoder"),jyo=o(" (DPR model)"),Dyo=l(),w_=a("li"),jue=a("strong"),Gyo=o("dpt"),Oyo=o(" \u2014 "),zO=a("a"),Vyo=o("DPTModel"),Xyo=o(" (DPT model)"),zyo=l(),A_=a("li"),Due=a("strong"),Qyo=o("electra"),Wyo=o(" \u2014 "),QO=a("a"),Uyo=o("ElectraModel"),Hyo=o(" (ELECTRA model)"),Jyo=l(),L_=a("li"),Gue=a("strong"),Yyo=o("ernie"),Kyo=o(" \u2014 "),WO=a("a"),Zyo=o("ErnieModel"),e8o=o(" (ERNIE model)"),o8o=l(),y_=a("li"),Oue=a("strong"),r8o=o("flaubert"),t8o=o(" \u2014 "),UO=a("a"),a8o=o("FlaubertModel"),n8o=o(" (FlauBERT model)"),s8o=l(),x_=a("li"),Vue=a("strong"),l8o=o("flava"),i8o=o(" \u2014 "),HO=a("a"),d8o=o("FlavaModel"),c8o=o(" (FLAVA model)"),m8o=l(),$_=a("li"),Xue=a("strong"),f8o=o("fnet"),g8o=o(" \u2014 "),JO=a("a"),h8o=o("FNetModel"),u8o=o(" (FNet model)"),p8o=l(),k_=a("li"),zue=a("strong"),_8o=o("fsmt"),b8o=o(" \u2014 "),YO=a("a"),v8o=o("FSMTModel"),F8o=o(" (FairSeq Machine-Translation model)"),T8o=l(),pl=a("li"),Que=a("strong"),M8o=o("funnel"),E8o=o(" \u2014 "),KO=a("a"),C8o=o("FunnelModel"),w8o=o(" or "),ZO=a("a"),A8o=o("FunnelBaseModel"),L8o=o(" (Funnel Transformer model)"),y8o=l(),S_=a("li"),Wue=a("strong"),x8o=o("glpn"),$8o=o(" \u2014 "),eV=a("a"),k8o=o("GLPNModel"),S8o=o(" (GLPN model)"),R8o=l(),R_=a("li"),Uue=a("strong"),P8o=o("gpt2"),B8o=o(" \u2014 "),oV=a("a"),I8o=o("GPT2Model"),N8o=o(" (OpenAI GPT-2 model)"),q8o=l(),P_=a("li"),Hue=a("strong"),j8o=o("gpt_neo"),D8o=o(" \u2014 "),rV=a("a"),G8o=o("GPTNeoModel"),O8o=o(" (GPT Neo model)"),V8o=l(),B_=a("li"),Jue=a("strong"),X8o=o("gpt_neox"),z8o=o(" \u2014 "),tV=a("a"),Q8o=o("GPTNeoXModel"),W8o=o(" (GPT NeoX model)"),U8o=l(),I_=a("li"),Yue=a("strong"),H8o=o("gptj"),J8o=o(" \u2014 "),aV=a("a"),Y8o=o("GPTJModel"),K8o=o(" (GPT-J model)"),Z8o=l(),N_=a("li"),Kue=a("strong"),e9o=o("groupvit"),o9o=o(" \u2014 "),nV=a("a"),r9o=o("GroupViTModel"),t9o=o(" (GroupViT model)"),a9o=l(),q_=a("li"),Zue=a("strong"),n9o=o("hubert"),s9o=o(" \u2014 "),sV=a("a"),l9o=o("HubertModel"),i9o=o(" (Hubert model)"),d9o=l(),j_=a("li"),epe=a("strong"),c9o=o("ibert"),m9o=o(" \u2014 "),lV=a("a"),f9o=o("IBertModel"),g9o=o(" (I-BERT model)"),h9o=l(),D_=a("li"),ope=a("strong"),u9o=o("imagegpt"),p9o=o(" \u2014 "),iV=a("a"),_9o=o("ImageGPTModel"),b9o=o(" (ImageGPT model)"),v9o=l(),G_=a("li"),rpe=a("strong"),F9o=o("layoutlm"),T9o=o(" \u2014 "),dV=a("a"),M9o=o("LayoutLMModel"),E9o=o(" (LayoutLM model)"),C9o=l(),O_=a("li"),tpe=a("strong"),w9o=o("layoutlmv2"),A9o=o(" \u2014 "),cV=a("a"),L9o=o("LayoutLMv2Model"),y9o=o(" (LayoutLMv2 model)"),x9o=l(),V_=a("li"),ape=a("strong"),$9o=o("layoutlmv3"),k9o=o(" \u2014 "),mV=a("a"),S9o=o("LayoutLMv3Model"),R9o=o(" (LayoutLMv3 model)"),P9o=l(),X_=a("li"),npe=a("strong"),B9o=o("led"),I9o=o(" \u2014 "),fV=a("a"),N9o=o("LEDModel"),q9o=o(" (LED model)"),j9o=l(),z_=a("li"),spe=a("strong"),D9o=o("levit"),G9o=o(" \u2014 "),gV=a("a"),O9o=o("LevitModel"),V9o=o(" (LeViT model)"),X9o=l(),Q_=a("li"),lpe=a("strong"),z9o=o("longformer"),Q9o=o(" \u2014 "),hV=a("a"),W9o=o("LongformerModel"),U9o=o(" (Longformer model)"),H9o=l(),W_=a("li"),ipe=a("strong"),J9o=o("longt5"),Y9o=o(" \u2014 "),uV=a("a"),K9o=o("LongT5Model"),Z9o=o(" (LongT5 model)"),exo=l(),U_=a("li"),dpe=a("strong"),oxo=o("luke"),rxo=o(" \u2014 "),pV=a("a"),txo=o("LukeModel"),axo=o(" (LUKE model)"),nxo=l(),H_=a("li"),cpe=a("strong"),sxo=o("lxmert"),lxo=o(" \u2014 "),_V=a("a"),ixo=o("LxmertModel"),dxo=o(" (LXMERT model)"),cxo=l(),J_=a("li"),mpe=a("strong"),mxo=o("m2m_100"),fxo=o(" \u2014 "),bV=a("a"),gxo=o("M2M100Model"),hxo=o(" (M2M100 model)"),uxo=l(),Y_=a("li"),fpe=a("strong"),pxo=o("marian"),_xo=o(" \u2014 "),vV=a("a"),bxo=o("MarianModel"),vxo=o(" (Marian model)"),Fxo=l(),K_=a("li"),gpe=a("strong"),Txo=o("maskformer"),Mxo=o(" \u2014 "),FV=a("a"),Exo=o("MaskFormerModel"),Cxo=o(" (MaskFormer model)"),wxo=l(),Z_=a("li"),hpe=a("strong"),Axo=o("mbart"),Lxo=o(" \u2014 "),TV=a("a"),yxo=o("MBartModel"),xxo=o(" (mBART model)"),$xo=l(),eb=a("li"),upe=a("strong"),kxo=o("mctct"),Sxo=o(" \u2014 "),MV=a("a"),Rxo=o("MCTCTModel"),Pxo=o(" (M-CTC-T model)"),Bxo=l(),ob=a("li"),ppe=a("strong"),Ixo=o("megatron-bert"),Nxo=o(" \u2014 "),EV=a("a"),qxo=o("MegatronBertModel"),jxo=o(" (Megatron-BERT model)"),Dxo=l(),rb=a("li"),_pe=a("strong"),Gxo=o("mobilebert"),Oxo=o(" \u2014 "),CV=a("a"),Vxo=o("MobileBertModel"),Xxo=o(" (MobileBERT model)"),zxo=l(),tb=a("li"),bpe=a("strong"),Qxo=o("mobilevit"),Wxo=o(" \u2014 "),wV=a("a"),Uxo=o("MobileViTModel"),Hxo=o(" (MobileViT model)"),Jxo=l(),ab=a("li"),vpe=a("strong"),Yxo=o("mpnet"),Kxo=o(" \u2014 "),AV=a("a"),Zxo=o("MPNetModel"),e$o=o(" (MPNet model)"),o$o=l(),nb=a("li"),Fpe=a("strong"),r$o=o("mt5"),t$o=o(" \u2014 "),LV=a("a"),a$o=o("MT5Model"),n$o=o(" (MT5 model)"),s$o=l(),sb=a("li"),Tpe=a("strong"),l$o=o("mvp"),i$o=o(" \u2014 "),yV=a("a"),d$o=o("MvpModel"),c$o=o(" (MVP model)"),m$o=l(),lb=a("li"),Mpe=a("strong"),f$o=o("nezha"),g$o=o(" \u2014 "),xV=a("a"),h$o=o("NezhaModel"),u$o=o(" (Nezha model)"),p$o=l(),ib=a("li"),Epe=a("strong"),_$o=o("nllb"),b$o=o(" \u2014 "),$V=a("a"),v$o=o("M2M100Model"),F$o=o(" (NLLB model)"),T$o=l(),db=a("li"),Cpe=a("strong"),M$o=o("nystromformer"),E$o=o(" \u2014 "),kV=a("a"),C$o=o("NystromformerModel"),w$o=o(" (Nystr\xF6mformer model)"),A$o=l(),cb=a("li"),wpe=a("strong"),L$o=o("openai-gpt"),y$o=o(" \u2014 "),SV=a("a"),x$o=o("OpenAIGPTModel"),$$o=o(" (OpenAI GPT model)"),k$o=l(),mb=a("li"),Ape=a("strong"),S$o=o("opt"),R$o=o(" \u2014 "),RV=a("a"),P$o=o("OPTModel"),B$o=o(" (OPT model)"),I$o=l(),fb=a("li"),Lpe=a("strong"),N$o=o("owlvit"),q$o=o(" \u2014 "),PV=a("a"),j$o=o("OwlViTModel"),D$o=o(" (OWL-ViT model)"),G$o=l(),gb=a("li"),ype=a("strong"),O$o=o("pegasus"),V$o=o(" \u2014 "),BV=a("a"),X$o=o("PegasusModel"),z$o=o(" (Pegasus model)"),Q$o=l(),hb=a("li"),xpe=a("strong"),W$o=o("pegasus_x"),U$o=o(" \u2014 "),IV=a("a"),H$o=o("PegasusXModel"),J$o=o(" (PEGASUS-X model)"),Y$o=l(),ub=a("li"),$pe=a("strong"),K$o=o("perceiver"),Z$o=o(" \u2014 "),NV=a("a"),eko=o("PerceiverModel"),oko=o(" (Perceiver model)"),rko=l(),pb=a("li"),kpe=a("strong"),tko=o("plbart"),ako=o(" \u2014 "),qV=a("a"),nko=o("PLBartModel"),sko=o(" (PLBart model)"),lko=l(),_b=a("li"),Spe=a("strong"),iko=o("poolformer"),dko=o(" \u2014 "),jV=a("a"),cko=o("PoolFormerModel"),mko=o(" (PoolFormer model)"),fko=l(),bb=a("li"),Rpe=a("strong"),gko=o("prophetnet"),hko=o(" \u2014 "),DV=a("a"),uko=o("ProphetNetModel"),pko=o(" (ProphetNet model)"),_ko=l(),vb=a("li"),Ppe=a("strong"),bko=o("qdqbert"),vko=o(" \u2014 "),GV=a("a"),Fko=o("QDQBertModel"),Tko=o(" (QDQBert model)"),Mko=l(),Fb=a("li"),Bpe=a("strong"),Eko=o("reformer"),Cko=o(" \u2014 "),OV=a("a"),wko=o("ReformerModel"),Ako=o(" (Reformer model)"),Lko=l(),Tb=a("li"),Ipe=a("strong"),yko=o("regnet"),xko=o(" \u2014 "),VV=a("a"),$ko=o("RegNetModel"),kko=o(" (RegNet model)"),Sko=l(),Mb=a("li"),Npe=a("strong"),Rko=o("rembert"),Pko=o(" \u2014 "),XV=a("a"),Bko=o("RemBertModel"),Iko=o(" (RemBERT model)"),Nko=l(),Eb=a("li"),qpe=a("strong"),qko=o("resnet"),jko=o(" \u2014 "),zV=a("a"),Dko=o("ResNetModel"),Gko=o(" (ResNet model)"),Oko=l(),Cb=a("li"),jpe=a("strong"),Vko=o("retribert"),Xko=o(" \u2014 "),QV=a("a"),zko=o("RetriBertModel"),Qko=o(" (RetriBERT model)"),Wko=l(),wb=a("li"),Dpe=a("strong"),Uko=o("roberta"),Hko=o(" \u2014 "),WV=a("a"),Jko=o("RobertaModel"),Yko=o(" (RoBERTa model)"),Kko=l(),Ab=a("li"),Gpe=a("strong"),Zko=o("roformer"),eSo=o(" \u2014 "),UV=a("a"),oSo=o("RoFormerModel"),rSo=o(" (RoFormer model)"),tSo=l(),Lb=a("li"),Ope=a("strong"),aSo=o("segformer"),nSo=o(" \u2014 "),HV=a("a"),sSo=o("SegformerModel"),lSo=o(" (SegFormer model)"),iSo=l(),yb=a("li"),Vpe=a("strong"),dSo=o("sew"),cSo=o(" \u2014 "),JV=a("a"),mSo=o("SEWModel"),fSo=o(" (SEW model)"),gSo=l(),xb=a("li"),Xpe=a("strong"),hSo=o("sew-d"),uSo=o(" \u2014 "),YV=a("a"),pSo=o("SEWDModel"),_So=o(" (SEW-D model)"),bSo=l(),$b=a("li"),zpe=a("strong"),vSo=o("speech_to_text"),FSo=o(" \u2014 "),KV=a("a"),TSo=o("Speech2TextModel"),MSo=o(" (Speech2Text model)"),ESo=l(),kb=a("li"),Qpe=a("strong"),CSo=o("splinter"),wSo=o(" \u2014 "),ZV=a("a"),ASo=o("SplinterModel"),LSo=o(" (Splinter model)"),ySo=l(),Sb=a("li"),Wpe=a("strong"),xSo=o("squeezebert"),$So=o(" \u2014 "),eX=a("a"),kSo=o("SqueezeBertModel"),SSo=o(" (SqueezeBERT model)"),RSo=l(),Rb=a("li"),Upe=a("strong"),PSo=o("swin"),BSo=o(" \u2014 "),oX=a("a"),ISo=o("SwinModel"),NSo=o(" (Swin Transformer model)"),qSo=l(),Pb=a("li"),Hpe=a("strong"),jSo=o("swinv2"),DSo=o(" \u2014 "),rX=a("a"),GSo=o("Swinv2Model"),OSo=o(" (Swin Transformer V2 model)"),VSo=l(),Bb=a("li"),Jpe=a("strong"),XSo=o("t5"),zSo=o(" \u2014 "),tX=a("a"),QSo=o("T5Model"),WSo=o(" (T5 model)"),USo=l(),Ib=a("li"),Ype=a("strong"),HSo=o("tapas"),JSo=o(" \u2014 "),aX=a("a"),YSo=o("TapasModel"),KSo=o(" (TAPAS model)"),ZSo=l(),Nb=a("li"),Kpe=a("strong"),eRo=o("trajectory_transformer"),oRo=o(" \u2014 "),nX=a("a"),rRo=o("TrajectoryTransformerModel"),tRo=o(" (Trajectory Transformer model)"),aRo=l(),qb=a("li"),Zpe=a("strong"),nRo=o("transfo-xl"),sRo=o(" \u2014 "),sX=a("a"),lRo=o("TransfoXLModel"),iRo=o(" (Transformer-XL model)"),dRo=l(),jb=a("li"),e_e=a("strong"),cRo=o("unispeech"),mRo=o(" \u2014 "),lX=a("a"),fRo=o("UniSpeechModel"),gRo=o(" (UniSpeech model)"),hRo=l(),Db=a("li"),o_e=a("strong"),uRo=o("unispeech-sat"),pRo=o(" \u2014 "),iX=a("a"),_Ro=o("UniSpeechSatModel"),bRo=o(" (UniSpeechSat model)"),vRo=l(),Gb=a("li"),r_e=a("strong"),FRo=o("van"),TRo=o(" \u2014 "),dX=a("a"),MRo=o("VanModel"),ERo=o(" (VAN model)"),CRo=l(),Ob=a("li"),t_e=a("strong"),wRo=o("videomae"),ARo=o(" \u2014 "),cX=a("a"),LRo=o("VideoMAEModel"),yRo=o(" (VideoMAE model)"),xRo=l(),Vb=a("li"),a_e=a("strong"),$Ro=o("vilt"),kRo=o(" \u2014 "),mX=a("a"),SRo=o("ViltModel"),RRo=o(" (ViLT model)"),PRo=l(),Xb=a("li"),n_e=a("strong"),BRo=o("vision-text-dual-encoder"),IRo=o(" \u2014 "),fX=a("a"),NRo=o("VisionTextDualEncoderModel"),qRo=o(" (VisionTextDualEncoder model)"),jRo=l(),zb=a("li"),s_e=a("strong"),DRo=o("visual_bert"),GRo=o(" \u2014 "),gX=a("a"),ORo=o("VisualBertModel"),VRo=o(" (VisualBERT model)"),XRo=l(),Qb=a("li"),l_e=a("strong"),zRo=o("vit"),QRo=o(" \u2014 "),hX=a("a"),WRo=o("ViTModel"),URo=o(" (ViT model)"),HRo=l(),Wb=a("li"),i_e=a("strong"),JRo=o("vit_mae"),YRo=o(" \u2014 "),uX=a("a"),KRo=o("ViTMAEModel"),ZRo=o(" (ViTMAE model)"),ePo=l(),Ub=a("li"),d_e=a("strong"),oPo=o("wav2vec2"),rPo=o(" \u2014 "),pX=a("a"),tPo=o("Wav2Vec2Model"),aPo=o(" (Wav2Vec2 model)"),nPo=l(),Hb=a("li"),c_e=a("strong"),sPo=o("wav2vec2-conformer"),lPo=o(" \u2014 "),_X=a("a"),iPo=o("Wav2Vec2ConformerModel"),dPo=o(" (Wav2Vec2-Conformer model)"),cPo=l(),Jb=a("li"),m_e=a("strong"),mPo=o("wavlm"),fPo=o(" \u2014 "),bX=a("a"),gPo=o("WavLMModel"),hPo=o(" (WavLM model)"),uPo=l(),Yb=a("li"),f_e=a("strong"),pPo=o("xclip"),_Po=o(" \u2014 "),vX=a("a"),bPo=o("XCLIPModel"),vPo=o(" (X-CLIP model)"),FPo=l(),Kb=a("li"),g_e=a("strong"),TPo=o("xglm"),MPo=o(" \u2014 "),FX=a("a"),EPo=o("XGLMModel"),CPo=o(" (XGLM model)"),wPo=l(),Zb=a("li"),h_e=a("strong"),APo=o("xlm"),LPo=o(" \u2014 "),TX=a("a"),yPo=o("XLMModel"),xPo=o(" (XLM model)"),$Po=l(),e2=a("li"),u_e=a("strong"),kPo=o("xlm-prophetnet"),SPo=o(" \u2014 "),MX=a("a"),RPo=o("XLMProphetNetModel"),PPo=o(" (XLM-ProphetNet model)"),BPo=l(),o2=a("li"),p_e=a("strong"),IPo=o("xlm-roberta"),NPo=o(" \u2014 "),EX=a("a"),qPo=o("XLMRobertaModel"),jPo=o(" (XLM-RoBERTa model)"),DPo=l(),r2=a("li"),__e=a("strong"),GPo=o("xlm-roberta-xl"),OPo=o(" \u2014 "),CX=a("a"),VPo=o("XLMRobertaXLModel"),XPo=o(" (XLM-RoBERTa-XL model)"),zPo=l(),t2=a("li"),b_e=a("strong"),QPo=o("xlnet"),WPo=o(" \u2014 "),wX=a("a"),UPo=o("XLNetModel"),HPo=o(" (XLNet model)"),JPo=l(),a2=a("li"),v_e=a("strong"),YPo=o("yolos"),KPo=o(" \u2014 "),AX=a("a"),ZPo=o("YolosModel"),eBo=o(" (YOLOS model)"),oBo=l(),n2=a("li"),F_e=a("strong"),rBo=o("yoso"),tBo=o(" \u2014 "),LX=a("a"),aBo=o("YosoModel"),nBo=o(" (YOSO model)"),sBo=l(),s2=a("p"),lBo=o("The model is set in evaluation mode by default using "),T_e=a("code"),iBo=o("model.eval()"),dBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),M_e=a("code"),cBo=o("model.train()"),mBo=l(),F(l2.$$.fragment),dKe=l(),vd=a("h2"),i2=a("a"),E_e=a("span"),F(nx.$$.fragment),fBo=l(),C_e=a("span"),gBo=o("AutoModelForPreTraining"),cKe=l(),Bo=a("div"),F(sx.$$.fragment),hBo=l(),Fd=a("p"),uBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),yX=a("a"),pBo=o("from_pretrained()"),_Bo=o(" class method or the "),xX=a("a"),bBo=o("from_config()"),vBo=o(` class
method.`),FBo=l(),lx=a("p"),TBo=o("This class cannot be instantiated directly using "),w_e=a("code"),MBo=o("__init__()"),EBo=o(" (throws an error)."),CBo=l(),bt=a("div"),F(ix.$$.fragment),wBo=l(),A_e=a("p"),ABo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),LBo=l(),Td=a("p"),yBo=o(`Note:
Loading a model from its configuration file does `),L_e=a("strong"),xBo=o("not"),$Bo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$X=a("a"),kBo=o("from_pretrained()"),SBo=o(" to load the model weights."),RBo=l(),F(d2.$$.fragment),PBo=l(),eo=a("div"),F(dx.$$.fragment),BBo=l(),y_e=a("p"),IBo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),NBo=l(),Ya=a("p"),qBo=o("The model class to instantiate is selected based on the "),x_e=a("code"),jBo=o("model_type"),DBo=o(` property of the config object (either
passed as an argument or loaded from `),$_e=a("code"),GBo=o("pretrained_model_name_or_path"),OBo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k_e=a("code"),VBo=o("pretrained_model_name_or_path"),XBo=o(":"),zBo=l(),G=a("ul"),c2=a("li"),S_e=a("strong"),QBo=o("albert"),WBo=o(" \u2014 "),kX=a("a"),UBo=o("AlbertForPreTraining"),HBo=o(" (ALBERT model)"),JBo=l(),m2=a("li"),R_e=a("strong"),YBo=o("bart"),KBo=o(" \u2014 "),SX=a("a"),ZBo=o("BartForConditionalGeneration"),eIo=o(" (BART model)"),oIo=l(),f2=a("li"),P_e=a("strong"),rIo=o("bert"),tIo=o(" \u2014 "),RX=a("a"),aIo=o("BertForPreTraining"),nIo=o(" (BERT model)"),sIo=l(),g2=a("li"),B_e=a("strong"),lIo=o("big_bird"),iIo=o(" \u2014 "),PX=a("a"),dIo=o("BigBirdForPreTraining"),cIo=o(" (BigBird model)"),mIo=l(),h2=a("li"),I_e=a("strong"),fIo=o("bloom"),gIo=o(" \u2014 "),BX=a("a"),hIo=o("BloomForCausalLM"),uIo=o(" (BLOOM model)"),pIo=l(),u2=a("li"),N_e=a("strong"),_Io=o("camembert"),bIo=o(" \u2014 "),IX=a("a"),vIo=o("CamembertForMaskedLM"),FIo=o(" (CamemBERT model)"),TIo=l(),p2=a("li"),q_e=a("strong"),MIo=o("ctrl"),EIo=o(" \u2014 "),NX=a("a"),CIo=o("CTRLLMHeadModel"),wIo=o(" (CTRL model)"),AIo=l(),_2=a("li"),j_e=a("strong"),LIo=o("data2vec-text"),yIo=o(" \u2014 "),qX=a("a"),xIo=o("Data2VecTextForMaskedLM"),$Io=o(" (Data2VecText model)"),kIo=l(),b2=a("li"),D_e=a("strong"),SIo=o("deberta"),RIo=o(" \u2014 "),jX=a("a"),PIo=o("DebertaForMaskedLM"),BIo=o(" (DeBERTa model)"),IIo=l(),v2=a("li"),G_e=a("strong"),NIo=o("deberta-v2"),qIo=o(" \u2014 "),DX=a("a"),jIo=o("DebertaV2ForMaskedLM"),DIo=o(" (DeBERTa-v2 model)"),GIo=l(),F2=a("li"),O_e=a("strong"),OIo=o("distilbert"),VIo=o(" \u2014 "),GX=a("a"),XIo=o("DistilBertForMaskedLM"),zIo=o(" (DistilBERT model)"),QIo=l(),T2=a("li"),V_e=a("strong"),WIo=o("electra"),UIo=o(" \u2014 "),OX=a("a"),HIo=o("ElectraForPreTraining"),JIo=o(" (ELECTRA model)"),YIo=l(),M2=a("li"),X_e=a("strong"),KIo=o("ernie"),ZIo=o(" \u2014 "),VX=a("a"),eNo=o("ErnieForPreTraining"),oNo=o(" (ERNIE model)"),rNo=l(),E2=a("li"),z_e=a("strong"),tNo=o("flaubert"),aNo=o(" \u2014 "),XX=a("a"),nNo=o("FlaubertWithLMHeadModel"),sNo=o(" (FlauBERT model)"),lNo=l(),C2=a("li"),Q_e=a("strong"),iNo=o("flava"),dNo=o(" \u2014 "),zX=a("a"),cNo=o("FlavaForPreTraining"),mNo=o(" (FLAVA model)"),fNo=l(),w2=a("li"),W_e=a("strong"),gNo=o("fnet"),hNo=o(" \u2014 "),QX=a("a"),uNo=o("FNetForPreTraining"),pNo=o(" (FNet model)"),_No=l(),A2=a("li"),U_e=a("strong"),bNo=o("fsmt"),vNo=o(" \u2014 "),WX=a("a"),FNo=o("FSMTForConditionalGeneration"),TNo=o(" (FairSeq Machine-Translation model)"),MNo=l(),L2=a("li"),H_e=a("strong"),ENo=o("funnel"),CNo=o(" \u2014 "),UX=a("a"),wNo=o("FunnelForPreTraining"),ANo=o(" (Funnel Transformer model)"),LNo=l(),y2=a("li"),J_e=a("strong"),yNo=o("gpt2"),xNo=o(" \u2014 "),HX=a("a"),$No=o("GPT2LMHeadModel"),kNo=o(" (OpenAI GPT-2 model)"),SNo=l(),x2=a("li"),Y_e=a("strong"),RNo=o("ibert"),PNo=o(" \u2014 "),JX=a("a"),BNo=o("IBertForMaskedLM"),INo=o(" (I-BERT model)"),NNo=l(),$2=a("li"),K_e=a("strong"),qNo=o("layoutlm"),jNo=o(" \u2014 "),YX=a("a"),DNo=o("LayoutLMForMaskedLM"),GNo=o(" (LayoutLM model)"),ONo=l(),k2=a("li"),Z_e=a("strong"),VNo=o("longformer"),XNo=o(" \u2014 "),KX=a("a"),zNo=o("LongformerForMaskedLM"),QNo=o(" (Longformer model)"),WNo=l(),S2=a("li"),ebe=a("strong"),UNo=o("luke"),HNo=o(" \u2014 "),ZX=a("a"),JNo=o("LukeForMaskedLM"),YNo=o(" (LUKE model)"),KNo=l(),R2=a("li"),obe=a("strong"),ZNo=o("lxmert"),eqo=o(" \u2014 "),ez=a("a"),oqo=o("LxmertForPreTraining"),rqo=o(" (LXMERT model)"),tqo=l(),P2=a("li"),rbe=a("strong"),aqo=o("megatron-bert"),nqo=o(" \u2014 "),oz=a("a"),sqo=o("MegatronBertForPreTraining"),lqo=o(" (Megatron-BERT model)"),iqo=l(),B2=a("li"),tbe=a("strong"),dqo=o("mobilebert"),cqo=o(" \u2014 "),rz=a("a"),mqo=o("MobileBertForPreTraining"),fqo=o(" (MobileBERT model)"),gqo=l(),I2=a("li"),abe=a("strong"),hqo=o("mpnet"),uqo=o(" \u2014 "),tz=a("a"),pqo=o("MPNetForMaskedLM"),_qo=o(" (MPNet model)"),bqo=l(),N2=a("li"),nbe=a("strong"),vqo=o("mvp"),Fqo=o(" \u2014 "),az=a("a"),Tqo=o("MvpForConditionalGeneration"),Mqo=o(" (MVP model)"),Eqo=l(),q2=a("li"),sbe=a("strong"),Cqo=o("nezha"),wqo=o(" \u2014 "),nz=a("a"),Aqo=o("NezhaForPreTraining"),Lqo=o(" (Nezha model)"),yqo=l(),j2=a("li"),lbe=a("strong"),xqo=o("openai-gpt"),$qo=o(" \u2014 "),sz=a("a"),kqo=o("OpenAIGPTLMHeadModel"),Sqo=o(" (OpenAI GPT model)"),Rqo=l(),D2=a("li"),ibe=a("strong"),Pqo=o("retribert"),Bqo=o(" \u2014 "),lz=a("a"),Iqo=o("RetriBertModel"),Nqo=o(" (RetriBERT model)"),qqo=l(),G2=a("li"),dbe=a("strong"),jqo=o("roberta"),Dqo=o(" \u2014 "),iz=a("a"),Gqo=o("RobertaForMaskedLM"),Oqo=o(" (RoBERTa model)"),Vqo=l(),O2=a("li"),cbe=a("strong"),Xqo=o("splinter"),zqo=o(" \u2014 "),dz=a("a"),Qqo=o("SplinterForPreTraining"),Wqo=o(" (Splinter model)"),Uqo=l(),V2=a("li"),mbe=a("strong"),Hqo=o("squeezebert"),Jqo=o(" \u2014 "),cz=a("a"),Yqo=o("SqueezeBertForMaskedLM"),Kqo=o(" (SqueezeBERT model)"),Zqo=l(),X2=a("li"),fbe=a("strong"),ejo=o("t5"),ojo=o(" \u2014 "),mz=a("a"),rjo=o("T5ForConditionalGeneration"),tjo=o(" (T5 model)"),ajo=l(),z2=a("li"),gbe=a("strong"),njo=o("tapas"),sjo=o(" \u2014 "),fz=a("a"),ljo=o("TapasForMaskedLM"),ijo=o(" (TAPAS model)"),djo=l(),Q2=a("li"),hbe=a("strong"),cjo=o("transfo-xl"),mjo=o(" \u2014 "),gz=a("a"),fjo=o("TransfoXLLMHeadModel"),gjo=o(" (Transformer-XL model)"),hjo=l(),W2=a("li"),ube=a("strong"),ujo=o("unispeech"),pjo=o(" \u2014 "),hz=a("a"),_jo=o("UniSpeechForPreTraining"),bjo=o(" (UniSpeech model)"),vjo=l(),U2=a("li"),pbe=a("strong"),Fjo=o("unispeech-sat"),Tjo=o(" \u2014 "),uz=a("a"),Mjo=o("UniSpeechSatForPreTraining"),Ejo=o(" (UniSpeechSat model)"),Cjo=l(),H2=a("li"),_be=a("strong"),wjo=o("videomae"),Ajo=o(" \u2014 "),pz=a("a"),Ljo=o("VideoMAEForPreTraining"),yjo=o(" (VideoMAE model)"),xjo=l(),J2=a("li"),bbe=a("strong"),$jo=o("visual_bert"),kjo=o(" \u2014 "),_z=a("a"),Sjo=o("VisualBertForPreTraining"),Rjo=o(" (VisualBERT model)"),Pjo=l(),Y2=a("li"),vbe=a("strong"),Bjo=o("vit_mae"),Ijo=o(" \u2014 "),bz=a("a"),Njo=o("ViTMAEForPreTraining"),qjo=o(" (ViTMAE model)"),jjo=l(),K2=a("li"),Fbe=a("strong"),Djo=o("wav2vec2"),Gjo=o(" \u2014 "),vz=a("a"),Ojo=o("Wav2Vec2ForPreTraining"),Vjo=o(" (Wav2Vec2 model)"),Xjo=l(),Z2=a("li"),Tbe=a("strong"),zjo=o("wav2vec2-conformer"),Qjo=o(" \u2014 "),Fz=a("a"),Wjo=o("Wav2Vec2ConformerForPreTraining"),Ujo=o(" (Wav2Vec2-Conformer model)"),Hjo=l(),e1=a("li"),Mbe=a("strong"),Jjo=o("xlm"),Yjo=o(" \u2014 "),Tz=a("a"),Kjo=o("XLMWithLMHeadModel"),Zjo=o(" (XLM model)"),eDo=l(),o1=a("li"),Ebe=a("strong"),oDo=o("xlm-roberta"),rDo=o(" \u2014 "),Mz=a("a"),tDo=o("XLMRobertaForMaskedLM"),aDo=o(" (XLM-RoBERTa model)"),nDo=l(),r1=a("li"),Cbe=a("strong"),sDo=o("xlm-roberta-xl"),lDo=o(" \u2014 "),Ez=a("a"),iDo=o("XLMRobertaXLForMaskedLM"),dDo=o(" (XLM-RoBERTa-XL model)"),cDo=l(),t1=a("li"),wbe=a("strong"),mDo=o("xlnet"),fDo=o(" \u2014 "),Cz=a("a"),gDo=o("XLNetLMHeadModel"),hDo=o(" (XLNet model)"),uDo=l(),a1=a("p"),pDo=o("The model is set in evaluation mode by default using "),Abe=a("code"),_Do=o("model.eval()"),bDo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lbe=a("code"),vDo=o("model.train()"),FDo=l(),F(n1.$$.fragment),mKe=l(),Md=a("h2"),s1=a("a"),ybe=a("span"),F(cx.$$.fragment),TDo=l(),xbe=a("span"),MDo=o("AutoModelForCausalLM"),fKe=l(),Io=a("div"),F(mx.$$.fragment),EDo=l(),Ed=a("p"),CDo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wz=a("a"),wDo=o("from_pretrained()"),ADo=o(" class method or the "),Az=a("a"),LDo=o("from_config()"),yDo=o(` class
method.`),xDo=l(),fx=a("p"),$Do=o("This class cannot be instantiated directly using "),$be=a("code"),kDo=o("__init__()"),SDo=o(" (throws an error)."),RDo=l(),vt=a("div"),F(gx.$$.fragment),PDo=l(),kbe=a("p"),BDo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),IDo=l(),Cd=a("p"),NDo=o(`Note:
Loading a model from its configuration file does `),Sbe=a("strong"),qDo=o("not"),jDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lz=a("a"),DDo=o("from_pretrained()"),GDo=o(" to load the model weights."),ODo=l(),F(l1.$$.fragment),VDo=l(),oo=a("div"),F(hx.$$.fragment),XDo=l(),Rbe=a("p"),zDo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),QDo=l(),Ka=a("p"),WDo=o("The model class to instantiate is selected based on the "),Pbe=a("code"),UDo=o("model_type"),HDo=o(` property of the config object (either
passed as an argument or loaded from `),Bbe=a("code"),JDo=o("pretrained_model_name_or_path"),YDo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ibe=a("code"),KDo=o("pretrained_model_name_or_path"),ZDo=o(":"),eGo=l(),z=a("ul"),i1=a("li"),Nbe=a("strong"),oGo=o("bart"),rGo=o(" \u2014 "),yz=a("a"),tGo=o("BartForCausalLM"),aGo=o(" (BART model)"),nGo=l(),d1=a("li"),qbe=a("strong"),sGo=o("bert"),lGo=o(" \u2014 "),xz=a("a"),iGo=o("BertLMHeadModel"),dGo=o(" (BERT model)"),cGo=l(),c1=a("li"),jbe=a("strong"),mGo=o("bert-generation"),fGo=o(" \u2014 "),$z=a("a"),gGo=o("BertGenerationDecoder"),hGo=o(" (Bert Generation model)"),uGo=l(),m1=a("li"),Dbe=a("strong"),pGo=o("big_bird"),_Go=o(" \u2014 "),kz=a("a"),bGo=o("BigBirdForCausalLM"),vGo=o(" (BigBird model)"),FGo=l(),f1=a("li"),Gbe=a("strong"),TGo=o("bigbird_pegasus"),MGo=o(" \u2014 "),Sz=a("a"),EGo=o("BigBirdPegasusForCausalLM"),CGo=o(" (BigBird-Pegasus model)"),wGo=l(),g1=a("li"),Obe=a("strong"),AGo=o("blenderbot"),LGo=o(" \u2014 "),Rz=a("a"),yGo=o("BlenderbotForCausalLM"),xGo=o(" (Blenderbot model)"),$Go=l(),h1=a("li"),Vbe=a("strong"),kGo=o("blenderbot-small"),SGo=o(" \u2014 "),Pz=a("a"),RGo=o("BlenderbotSmallForCausalLM"),PGo=o(" (BlenderbotSmall model)"),BGo=l(),u1=a("li"),Xbe=a("strong"),IGo=o("bloom"),NGo=o(" \u2014 "),Bz=a("a"),qGo=o("BloomForCausalLM"),jGo=o(" (BLOOM model)"),DGo=l(),p1=a("li"),zbe=a("strong"),GGo=o("camembert"),OGo=o(" \u2014 "),Iz=a("a"),VGo=o("CamembertForCausalLM"),XGo=o(" (CamemBERT model)"),zGo=l(),_1=a("li"),Qbe=a("strong"),QGo=o("codegen"),WGo=o(" \u2014 "),Nz=a("a"),UGo=o("CodeGenForCausalLM"),HGo=o(" (CodeGen model)"),JGo=l(),b1=a("li"),Wbe=a("strong"),YGo=o("ctrl"),KGo=o(" \u2014 "),qz=a("a"),ZGo=o("CTRLLMHeadModel"),eOo=o(" (CTRL model)"),oOo=l(),v1=a("li"),Ube=a("strong"),rOo=o("data2vec-text"),tOo=o(" \u2014 "),jz=a("a"),aOo=o("Data2VecTextForCausalLM"),nOo=o(" (Data2VecText model)"),sOo=l(),F1=a("li"),Hbe=a("strong"),lOo=o("electra"),iOo=o(" \u2014 "),Dz=a("a"),dOo=o("ElectraForCausalLM"),cOo=o(" (ELECTRA model)"),mOo=l(),T1=a("li"),Jbe=a("strong"),fOo=o("ernie"),gOo=o(" \u2014 "),Gz=a("a"),hOo=o("ErnieForCausalLM"),uOo=o(" (ERNIE model)"),pOo=l(),M1=a("li"),Ybe=a("strong"),_Oo=o("gpt2"),bOo=o(" \u2014 "),Oz=a("a"),vOo=o("GPT2LMHeadModel"),FOo=o(" (OpenAI GPT-2 model)"),TOo=l(),E1=a("li"),Kbe=a("strong"),MOo=o("gpt_neo"),EOo=o(" \u2014 "),Vz=a("a"),COo=o("GPTNeoForCausalLM"),wOo=o(" (GPT Neo model)"),AOo=l(),C1=a("li"),Zbe=a("strong"),LOo=o("gpt_neox"),yOo=o(" \u2014 "),Xz=a("a"),xOo=o("GPTNeoXForCausalLM"),$Oo=o(" (GPT NeoX model)"),kOo=l(),w1=a("li"),e2e=a("strong"),SOo=o("gptj"),ROo=o(" \u2014 "),zz=a("a"),POo=o("GPTJForCausalLM"),BOo=o(" (GPT-J model)"),IOo=l(),A1=a("li"),o2e=a("strong"),NOo=o("marian"),qOo=o(" \u2014 "),Qz=a("a"),jOo=o("MarianForCausalLM"),DOo=o(" (Marian model)"),GOo=l(),L1=a("li"),r2e=a("strong"),OOo=o("mbart"),VOo=o(" \u2014 "),Wz=a("a"),XOo=o("MBartForCausalLM"),zOo=o(" (mBART model)"),QOo=l(),y1=a("li"),t2e=a("strong"),WOo=o("megatron-bert"),UOo=o(" \u2014 "),Uz=a("a"),HOo=o("MegatronBertForCausalLM"),JOo=o(" (Megatron-BERT model)"),YOo=l(),x1=a("li"),a2e=a("strong"),KOo=o("mvp"),ZOo=o(" \u2014 "),Hz=a("a"),eVo=o("MvpForCausalLM"),oVo=o(" (MVP model)"),rVo=l(),$1=a("li"),n2e=a("strong"),tVo=o("openai-gpt"),aVo=o(" \u2014 "),Jz=a("a"),nVo=o("OpenAIGPTLMHeadModel"),sVo=o(" (OpenAI GPT model)"),lVo=l(),k1=a("li"),s2e=a("strong"),iVo=o("opt"),dVo=o(" \u2014 "),Yz=a("a"),cVo=o("OPTForCausalLM"),mVo=o(" (OPT model)"),fVo=l(),S1=a("li"),l2e=a("strong"),gVo=o("pegasus"),hVo=o(" \u2014 "),Kz=a("a"),uVo=o("PegasusForCausalLM"),pVo=o(" (Pegasus model)"),_Vo=l(),R1=a("li"),i2e=a("strong"),bVo=o("plbart"),vVo=o(" \u2014 "),Zz=a("a"),FVo=o("PLBartForCausalLM"),TVo=o(" (PLBart model)"),MVo=l(),P1=a("li"),d2e=a("strong"),EVo=o("prophetnet"),CVo=o(" \u2014 "),eQ=a("a"),wVo=o("ProphetNetForCausalLM"),AVo=o(" (ProphetNet model)"),LVo=l(),B1=a("li"),c2e=a("strong"),yVo=o("qdqbert"),xVo=o(" \u2014 "),oQ=a("a"),$Vo=o("QDQBertLMHeadModel"),kVo=o(" (QDQBert model)"),SVo=l(),I1=a("li"),m2e=a("strong"),RVo=o("reformer"),PVo=o(" \u2014 "),rQ=a("a"),BVo=o("ReformerModelWithLMHead"),IVo=o(" (Reformer model)"),NVo=l(),N1=a("li"),f2e=a("strong"),qVo=o("rembert"),jVo=o(" \u2014 "),tQ=a("a"),DVo=o("RemBertForCausalLM"),GVo=o(" (RemBERT model)"),OVo=l(),q1=a("li"),g2e=a("strong"),VVo=o("roberta"),XVo=o(" \u2014 "),aQ=a("a"),zVo=o("RobertaForCausalLM"),QVo=o(" (RoBERTa model)"),WVo=l(),j1=a("li"),h2e=a("strong"),UVo=o("roformer"),HVo=o(" \u2014 "),nQ=a("a"),JVo=o("RoFormerForCausalLM"),YVo=o(" (RoFormer model)"),KVo=l(),D1=a("li"),u2e=a("strong"),ZVo=o("speech_to_text_2"),eXo=o(" \u2014 "),sQ=a("a"),oXo=o("Speech2Text2ForCausalLM"),rXo=o(" (Speech2Text2 model)"),tXo=l(),G1=a("li"),p2e=a("strong"),aXo=o("transfo-xl"),nXo=o(" \u2014 "),lQ=a("a"),sXo=o("TransfoXLLMHeadModel"),lXo=o(" (Transformer-XL model)"),iXo=l(),O1=a("li"),_2e=a("strong"),dXo=o("trocr"),cXo=o(" \u2014 "),iQ=a("a"),mXo=o("TrOCRForCausalLM"),fXo=o(" (TrOCR model)"),gXo=l(),V1=a("li"),b2e=a("strong"),hXo=o("xglm"),uXo=o(" \u2014 "),dQ=a("a"),pXo=o("XGLMForCausalLM"),_Xo=o(" (XGLM model)"),bXo=l(),X1=a("li"),v2e=a("strong"),vXo=o("xlm"),FXo=o(" \u2014 "),cQ=a("a"),TXo=o("XLMWithLMHeadModel"),MXo=o(" (XLM model)"),EXo=l(),z1=a("li"),F2e=a("strong"),CXo=o("xlm-prophetnet"),wXo=o(" \u2014 "),mQ=a("a"),AXo=o("XLMProphetNetForCausalLM"),LXo=o(" (XLM-ProphetNet model)"),yXo=l(),Q1=a("li"),T2e=a("strong"),xXo=o("xlm-roberta"),$Xo=o(" \u2014 "),fQ=a("a"),kXo=o("XLMRobertaForCausalLM"),SXo=o(" (XLM-RoBERTa model)"),RXo=l(),W1=a("li"),M2e=a("strong"),PXo=o("xlm-roberta-xl"),BXo=o(" \u2014 "),gQ=a("a"),IXo=o("XLMRobertaXLForCausalLM"),NXo=o(" (XLM-RoBERTa-XL model)"),qXo=l(),U1=a("li"),E2e=a("strong"),jXo=o("xlnet"),DXo=o(" \u2014 "),hQ=a("a"),GXo=o("XLNetLMHeadModel"),OXo=o(" (XLNet model)"),VXo=l(),H1=a("p"),XXo=o("The model is set in evaluation mode by default using "),C2e=a("code"),zXo=o("model.eval()"),QXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w2e=a("code"),WXo=o("model.train()"),UXo=l(),F(J1.$$.fragment),gKe=l(),wd=a("h2"),Y1=a("a"),A2e=a("span"),F(ux.$$.fragment),HXo=l(),L2e=a("span"),JXo=o("AutoModelForMaskedLM"),hKe=l(),No=a("div"),F(px.$$.fragment),YXo=l(),Ad=a("p"),KXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),uQ=a("a"),ZXo=o("from_pretrained()"),ezo=o(" class method or the "),pQ=a("a"),ozo=o("from_config()"),rzo=o(` class
method.`),tzo=l(),_x=a("p"),azo=o("This class cannot be instantiated directly using "),y2e=a("code"),nzo=o("__init__()"),szo=o(" (throws an error)."),lzo=l(),Ft=a("div"),F(bx.$$.fragment),izo=l(),x2e=a("p"),dzo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),czo=l(),Ld=a("p"),mzo=o(`Note:
Loading a model from its configuration file does `),$2e=a("strong"),fzo=o("not"),gzo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_Q=a("a"),hzo=o("from_pretrained()"),uzo=o(" to load the model weights."),pzo=l(),F(K1.$$.fragment),_zo=l(),ro=a("div"),F(vx.$$.fragment),bzo=l(),k2e=a("p"),vzo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Fzo=l(),Za=a("p"),Tzo=o("The model class to instantiate is selected based on the "),S2e=a("code"),Mzo=o("model_type"),Ezo=o(` property of the config object (either
passed as an argument or loaded from `),R2e=a("code"),Czo=o("pretrained_model_name_or_path"),wzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P2e=a("code"),Azo=o("pretrained_model_name_or_path"),Lzo=o(":"),yzo=l(),U=a("ul"),Z1=a("li"),B2e=a("strong"),xzo=o("albert"),$zo=o(" \u2014 "),bQ=a("a"),kzo=o("AlbertForMaskedLM"),Szo=o(" (ALBERT model)"),Rzo=l(),ev=a("li"),I2e=a("strong"),Pzo=o("bart"),Bzo=o(" \u2014 "),vQ=a("a"),Izo=o("BartForConditionalGeneration"),Nzo=o(" (BART model)"),qzo=l(),ov=a("li"),N2e=a("strong"),jzo=o("bert"),Dzo=o(" \u2014 "),FQ=a("a"),Gzo=o("BertForMaskedLM"),Ozo=o(" (BERT model)"),Vzo=l(),rv=a("li"),q2e=a("strong"),Xzo=o("big_bird"),zzo=o(" \u2014 "),TQ=a("a"),Qzo=o("BigBirdForMaskedLM"),Wzo=o(" (BigBird model)"),Uzo=l(),tv=a("li"),j2e=a("strong"),Hzo=o("camembert"),Jzo=o(" \u2014 "),MQ=a("a"),Yzo=o("CamembertForMaskedLM"),Kzo=o(" (CamemBERT model)"),Zzo=l(),av=a("li"),D2e=a("strong"),eQo=o("convbert"),oQo=o(" \u2014 "),EQ=a("a"),rQo=o("ConvBertForMaskedLM"),tQo=o(" (ConvBERT model)"),aQo=l(),nv=a("li"),G2e=a("strong"),nQo=o("data2vec-text"),sQo=o(" \u2014 "),CQ=a("a"),lQo=o("Data2VecTextForMaskedLM"),iQo=o(" (Data2VecText model)"),dQo=l(),sv=a("li"),O2e=a("strong"),cQo=o("deberta"),mQo=o(" \u2014 "),wQ=a("a"),fQo=o("DebertaForMaskedLM"),gQo=o(" (DeBERTa model)"),hQo=l(),lv=a("li"),V2e=a("strong"),uQo=o("deberta-v2"),pQo=o(" \u2014 "),AQ=a("a"),_Qo=o("DebertaV2ForMaskedLM"),bQo=o(" (DeBERTa-v2 model)"),vQo=l(),iv=a("li"),X2e=a("strong"),FQo=o("distilbert"),TQo=o(" \u2014 "),LQ=a("a"),MQo=o("DistilBertForMaskedLM"),EQo=o(" (DistilBERT model)"),CQo=l(),dv=a("li"),z2e=a("strong"),wQo=o("electra"),AQo=o(" \u2014 "),yQ=a("a"),LQo=o("ElectraForMaskedLM"),yQo=o(" (ELECTRA model)"),xQo=l(),cv=a("li"),Q2e=a("strong"),$Qo=o("ernie"),kQo=o(" \u2014 "),xQ=a("a"),SQo=o("ErnieForMaskedLM"),RQo=o(" (ERNIE model)"),PQo=l(),mv=a("li"),W2e=a("strong"),BQo=o("flaubert"),IQo=o(" \u2014 "),$Q=a("a"),NQo=o("FlaubertWithLMHeadModel"),qQo=o(" (FlauBERT model)"),jQo=l(),fv=a("li"),U2e=a("strong"),DQo=o("fnet"),GQo=o(" \u2014 "),kQ=a("a"),OQo=o("FNetForMaskedLM"),VQo=o(" (FNet model)"),XQo=l(),gv=a("li"),H2e=a("strong"),zQo=o("funnel"),QQo=o(" \u2014 "),SQ=a("a"),WQo=o("FunnelForMaskedLM"),UQo=o(" (Funnel Transformer model)"),HQo=l(),hv=a("li"),J2e=a("strong"),JQo=o("ibert"),YQo=o(" \u2014 "),RQ=a("a"),KQo=o("IBertForMaskedLM"),ZQo=o(" (I-BERT model)"),eWo=l(),uv=a("li"),Y2e=a("strong"),oWo=o("layoutlm"),rWo=o(" \u2014 "),PQ=a("a"),tWo=o("LayoutLMForMaskedLM"),aWo=o(" (LayoutLM model)"),nWo=l(),pv=a("li"),K2e=a("strong"),sWo=o("longformer"),lWo=o(" \u2014 "),BQ=a("a"),iWo=o("LongformerForMaskedLM"),dWo=o(" (Longformer model)"),cWo=l(),_v=a("li"),Z2e=a("strong"),mWo=o("luke"),fWo=o(" \u2014 "),IQ=a("a"),gWo=o("LukeForMaskedLM"),hWo=o(" (LUKE model)"),uWo=l(),bv=a("li"),e1e=a("strong"),pWo=o("mbart"),_Wo=o(" \u2014 "),NQ=a("a"),bWo=o("MBartForConditionalGeneration"),vWo=o(" (mBART model)"),FWo=l(),vv=a("li"),o1e=a("strong"),TWo=o("megatron-bert"),MWo=o(" \u2014 "),qQ=a("a"),EWo=o("MegatronBertForMaskedLM"),CWo=o(" (Megatron-BERT model)"),wWo=l(),Fv=a("li"),r1e=a("strong"),AWo=o("mobilebert"),LWo=o(" \u2014 "),jQ=a("a"),yWo=o("MobileBertForMaskedLM"),xWo=o(" (MobileBERT model)"),$Wo=l(),Tv=a("li"),t1e=a("strong"),kWo=o("mpnet"),SWo=o(" \u2014 "),DQ=a("a"),RWo=o("MPNetForMaskedLM"),PWo=o(" (MPNet model)"),BWo=l(),Mv=a("li"),a1e=a("strong"),IWo=o("mvp"),NWo=o(" \u2014 "),GQ=a("a"),qWo=o("MvpForConditionalGeneration"),jWo=o(" (MVP model)"),DWo=l(),Ev=a("li"),n1e=a("strong"),GWo=o("nezha"),OWo=o(" \u2014 "),OQ=a("a"),VWo=o("NezhaForMaskedLM"),XWo=o(" (Nezha model)"),zWo=l(),Cv=a("li"),s1e=a("strong"),QWo=o("nystromformer"),WWo=o(" \u2014 "),VQ=a("a"),UWo=o("NystromformerForMaskedLM"),HWo=o(" (Nystr\xF6mformer model)"),JWo=l(),wv=a("li"),l1e=a("strong"),YWo=o("perceiver"),KWo=o(" \u2014 "),XQ=a("a"),ZWo=o("PerceiverForMaskedLM"),eUo=o(" (Perceiver model)"),oUo=l(),Av=a("li"),i1e=a("strong"),rUo=o("qdqbert"),tUo=o(" \u2014 "),zQ=a("a"),aUo=o("QDQBertForMaskedLM"),nUo=o(" (QDQBert model)"),sUo=l(),Lv=a("li"),d1e=a("strong"),lUo=o("reformer"),iUo=o(" \u2014 "),QQ=a("a"),dUo=o("ReformerForMaskedLM"),cUo=o(" (Reformer model)"),mUo=l(),yv=a("li"),c1e=a("strong"),fUo=o("rembert"),gUo=o(" \u2014 "),WQ=a("a"),hUo=o("RemBertForMaskedLM"),uUo=o(" (RemBERT model)"),pUo=l(),xv=a("li"),m1e=a("strong"),_Uo=o("roberta"),bUo=o(" \u2014 "),UQ=a("a"),vUo=o("RobertaForMaskedLM"),FUo=o(" (RoBERTa model)"),TUo=l(),$v=a("li"),f1e=a("strong"),MUo=o("roformer"),EUo=o(" \u2014 "),HQ=a("a"),CUo=o("RoFormerForMaskedLM"),wUo=o(" (RoFormer model)"),AUo=l(),kv=a("li"),g1e=a("strong"),LUo=o("squeezebert"),yUo=o(" \u2014 "),JQ=a("a"),xUo=o("SqueezeBertForMaskedLM"),$Uo=o(" (SqueezeBERT model)"),kUo=l(),Sv=a("li"),h1e=a("strong"),SUo=o("tapas"),RUo=o(" \u2014 "),YQ=a("a"),PUo=o("TapasForMaskedLM"),BUo=o(" (TAPAS model)"),IUo=l(),Rv=a("li"),u1e=a("strong"),NUo=o("wav2vec2"),qUo=o(" \u2014 "),p1e=a("code"),jUo=o("Wav2Vec2ForMaskedLM"),DUo=o(" (Wav2Vec2 model)"),GUo=l(),Pv=a("li"),_1e=a("strong"),OUo=o("xlm"),VUo=o(" \u2014 "),KQ=a("a"),XUo=o("XLMWithLMHeadModel"),zUo=o(" (XLM model)"),QUo=l(),Bv=a("li"),b1e=a("strong"),WUo=o("xlm-roberta"),UUo=o(" \u2014 "),ZQ=a("a"),HUo=o("XLMRobertaForMaskedLM"),JUo=o(" (XLM-RoBERTa model)"),YUo=l(),Iv=a("li"),v1e=a("strong"),KUo=o("xlm-roberta-xl"),ZUo=o(" \u2014 "),eW=a("a"),eHo=o("XLMRobertaXLForMaskedLM"),oHo=o(" (XLM-RoBERTa-XL model)"),rHo=l(),Nv=a("li"),F1e=a("strong"),tHo=o("yoso"),aHo=o(" \u2014 "),oW=a("a"),nHo=o("YosoForMaskedLM"),sHo=o(" (YOSO model)"),lHo=l(),qv=a("p"),iHo=o("The model is set in evaluation mode by default using "),T1e=a("code"),dHo=o("model.eval()"),cHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),M1e=a("code"),mHo=o("model.train()"),fHo=l(),F(jv.$$.fragment),uKe=l(),yd=a("h2"),Dv=a("a"),E1e=a("span"),F(Fx.$$.fragment),gHo=l(),C1e=a("span"),hHo=o("AutoModelForSeq2SeqLM"),pKe=l(),qo=a("div"),F(Tx.$$.fragment),uHo=l(),xd=a("p"),pHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),rW=a("a"),_Ho=o("from_pretrained()"),bHo=o(" class method or the "),tW=a("a"),vHo=o("from_config()"),FHo=o(` class
method.`),THo=l(),Mx=a("p"),MHo=o("This class cannot be instantiated directly using "),w1e=a("code"),EHo=o("__init__()"),CHo=o(" (throws an error)."),wHo=l(),Tt=a("div"),F(Ex.$$.fragment),AHo=l(),A1e=a("p"),LHo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),yHo=l(),$d=a("p"),xHo=o(`Note:
Loading a model from its configuration file does `),L1e=a("strong"),$Ho=o("not"),kHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aW=a("a"),SHo=o("from_pretrained()"),RHo=o(" to load the model weights."),PHo=l(),F(Gv.$$.fragment),BHo=l(),to=a("div"),F(Cx.$$.fragment),IHo=l(),y1e=a("p"),NHo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),qHo=l(),en=a("p"),jHo=o("The model class to instantiate is selected based on the "),x1e=a("code"),DHo=o("model_type"),GHo=o(` property of the config object (either
passed as an argument or loaded from `),$1e=a("code"),OHo=o("pretrained_model_name_or_path"),VHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k1e=a("code"),XHo=o("pretrained_model_name_or_path"),zHo=o(":"),QHo=l(),me=a("ul"),Ov=a("li"),S1e=a("strong"),WHo=o("bart"),UHo=o(" \u2014 "),nW=a("a"),HHo=o("BartForConditionalGeneration"),JHo=o(" (BART model)"),YHo=l(),Vv=a("li"),R1e=a("strong"),KHo=o("bigbird_pegasus"),ZHo=o(" \u2014 "),sW=a("a"),eJo=o("BigBirdPegasusForConditionalGeneration"),oJo=o(" (BigBird-Pegasus model)"),rJo=l(),Xv=a("li"),P1e=a("strong"),tJo=o("blenderbot"),aJo=o(" \u2014 "),lW=a("a"),nJo=o("BlenderbotForConditionalGeneration"),sJo=o(" (Blenderbot model)"),lJo=l(),zv=a("li"),B1e=a("strong"),iJo=o("blenderbot-small"),dJo=o(" \u2014 "),iW=a("a"),cJo=o("BlenderbotSmallForConditionalGeneration"),mJo=o(" (BlenderbotSmall model)"),fJo=l(),Qv=a("li"),I1e=a("strong"),gJo=o("encoder-decoder"),hJo=o(" \u2014 "),dW=a("a"),uJo=o("EncoderDecoderModel"),pJo=o(" (Encoder decoder model)"),_Jo=l(),Wv=a("li"),N1e=a("strong"),bJo=o("fsmt"),vJo=o(" \u2014 "),cW=a("a"),FJo=o("FSMTForConditionalGeneration"),TJo=o(" (FairSeq Machine-Translation model)"),MJo=l(),Uv=a("li"),q1e=a("strong"),EJo=o("led"),CJo=o(" \u2014 "),mW=a("a"),wJo=o("LEDForConditionalGeneration"),AJo=o(" (LED model)"),LJo=l(),Hv=a("li"),j1e=a("strong"),yJo=o("longt5"),xJo=o(" \u2014 "),fW=a("a"),$Jo=o("LongT5ForConditionalGeneration"),kJo=o(" (LongT5 model)"),SJo=l(),Jv=a("li"),D1e=a("strong"),RJo=o("m2m_100"),PJo=o(" \u2014 "),gW=a("a"),BJo=o("M2M100ForConditionalGeneration"),IJo=o(" (M2M100 model)"),NJo=l(),Yv=a("li"),G1e=a("strong"),qJo=o("marian"),jJo=o(" \u2014 "),hW=a("a"),DJo=o("MarianMTModel"),GJo=o(" (Marian model)"),OJo=l(),Kv=a("li"),O1e=a("strong"),VJo=o("mbart"),XJo=o(" \u2014 "),uW=a("a"),zJo=o("MBartForConditionalGeneration"),QJo=o(" (mBART model)"),WJo=l(),Zv=a("li"),V1e=a("strong"),UJo=o("mt5"),HJo=o(" \u2014 "),pW=a("a"),JJo=o("MT5ForConditionalGeneration"),YJo=o(" (MT5 model)"),KJo=l(),eF=a("li"),X1e=a("strong"),ZJo=o("mvp"),eYo=o(" \u2014 "),_W=a("a"),oYo=o("MvpForConditionalGeneration"),rYo=o(" (MVP model)"),tYo=l(),oF=a("li"),z1e=a("strong"),aYo=o("nllb"),nYo=o(" \u2014 "),bW=a("a"),sYo=o("M2M100ForConditionalGeneration"),lYo=o(" (NLLB model)"),iYo=l(),rF=a("li"),Q1e=a("strong"),dYo=o("pegasus"),cYo=o(" \u2014 "),vW=a("a"),mYo=o("PegasusForConditionalGeneration"),fYo=o(" (Pegasus model)"),gYo=l(),tF=a("li"),W1e=a("strong"),hYo=o("pegasus_x"),uYo=o(" \u2014 "),FW=a("a"),pYo=o("PegasusXForConditionalGeneration"),_Yo=o(" (PEGASUS-X model)"),bYo=l(),aF=a("li"),U1e=a("strong"),vYo=o("plbart"),FYo=o(" \u2014 "),TW=a("a"),TYo=o("PLBartForConditionalGeneration"),MYo=o(" (PLBart model)"),EYo=l(),nF=a("li"),H1e=a("strong"),CYo=o("prophetnet"),wYo=o(" \u2014 "),MW=a("a"),AYo=o("ProphetNetForConditionalGeneration"),LYo=o(" (ProphetNet model)"),yYo=l(),sF=a("li"),J1e=a("strong"),xYo=o("t5"),$Yo=o(" \u2014 "),EW=a("a"),kYo=o("T5ForConditionalGeneration"),SYo=o(" (T5 model)"),RYo=l(),lF=a("li"),Y1e=a("strong"),PYo=o("xlm-prophetnet"),BYo=o(" \u2014 "),CW=a("a"),IYo=o("XLMProphetNetForConditionalGeneration"),NYo=o(" (XLM-ProphetNet model)"),qYo=l(),iF=a("p"),jYo=o("The model is set in evaluation mode by default using "),K1e=a("code"),DYo=o("model.eval()"),GYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z1e=a("code"),OYo=o("model.train()"),VYo=l(),F(dF.$$.fragment),_Ke=l(),kd=a("h2"),cF=a("a"),eve=a("span"),F(wx.$$.fragment),XYo=l(),ove=a("span"),zYo=o("AutoModelForSequenceClassification"),bKe=l(),jo=a("div"),F(Ax.$$.fragment),QYo=l(),Sd=a("p"),WYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),wW=a("a"),UYo=o("from_pretrained()"),HYo=o(" class method or the "),AW=a("a"),JYo=o("from_config()"),YYo=o(` class
method.`),KYo=l(),Lx=a("p"),ZYo=o("This class cannot be instantiated directly using "),rve=a("code"),eKo=o("__init__()"),oKo=o(" (throws an error)."),rKo=l(),Mt=a("div"),F(yx.$$.fragment),tKo=l(),tve=a("p"),aKo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),nKo=l(),Rd=a("p"),sKo=o(`Note:
Loading a model from its configuration file does `),ave=a("strong"),lKo=o("not"),iKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LW=a("a"),dKo=o("from_pretrained()"),cKo=o(" to load the model weights."),mKo=l(),F(mF.$$.fragment),fKo=l(),ao=a("div"),F(xx.$$.fragment),gKo=l(),nve=a("p"),hKo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),uKo=l(),on=a("p"),pKo=o("The model class to instantiate is selected based on the "),sve=a("code"),_Ko=o("model_type"),bKo=o(` property of the config object (either
passed as an argument or loaded from `),lve=a("code"),vKo=o("pretrained_model_name_or_path"),FKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ive=a("code"),TKo=o("pretrained_model_name_or_path"),MKo=o(":"),EKo=l(),q=a("ul"),fF=a("li"),dve=a("strong"),CKo=o("albert"),wKo=o(" \u2014 "),yW=a("a"),AKo=o("AlbertForSequenceClassification"),LKo=o(" (ALBERT model)"),yKo=l(),gF=a("li"),cve=a("strong"),xKo=o("bart"),$Ko=o(" \u2014 "),xW=a("a"),kKo=o("BartForSequenceClassification"),SKo=o(" (BART model)"),RKo=l(),hF=a("li"),mve=a("strong"),PKo=o("bert"),BKo=o(" \u2014 "),$W=a("a"),IKo=o("BertForSequenceClassification"),NKo=o(" (BERT model)"),qKo=l(),uF=a("li"),fve=a("strong"),jKo=o("big_bird"),DKo=o(" \u2014 "),kW=a("a"),GKo=o("BigBirdForSequenceClassification"),OKo=o(" (BigBird model)"),VKo=l(),pF=a("li"),gve=a("strong"),XKo=o("bigbird_pegasus"),zKo=o(" \u2014 "),SW=a("a"),QKo=o("BigBirdPegasusForSequenceClassification"),WKo=o(" (BigBird-Pegasus model)"),UKo=l(),_F=a("li"),hve=a("strong"),HKo=o("bloom"),JKo=o(" \u2014 "),RW=a("a"),YKo=o("BloomForSequenceClassification"),KKo=o(" (BLOOM model)"),ZKo=l(),bF=a("li"),uve=a("strong"),eZo=o("camembert"),oZo=o(" \u2014 "),PW=a("a"),rZo=o("CamembertForSequenceClassification"),tZo=o(" (CamemBERT model)"),aZo=l(),vF=a("li"),pve=a("strong"),nZo=o("canine"),sZo=o(" \u2014 "),BW=a("a"),lZo=o("CanineForSequenceClassification"),iZo=o(" (CANINE model)"),dZo=l(),FF=a("li"),_ve=a("strong"),cZo=o("convbert"),mZo=o(" \u2014 "),IW=a("a"),fZo=o("ConvBertForSequenceClassification"),gZo=o(" (ConvBERT model)"),hZo=l(),TF=a("li"),bve=a("strong"),uZo=o("ctrl"),pZo=o(" \u2014 "),NW=a("a"),_Zo=o("CTRLForSequenceClassification"),bZo=o(" (CTRL model)"),vZo=l(),MF=a("li"),vve=a("strong"),FZo=o("data2vec-text"),TZo=o(" \u2014 "),qW=a("a"),MZo=o("Data2VecTextForSequenceClassification"),EZo=o(" (Data2VecText model)"),CZo=l(),EF=a("li"),Fve=a("strong"),wZo=o("deberta"),AZo=o(" \u2014 "),jW=a("a"),LZo=o("DebertaForSequenceClassification"),yZo=o(" (DeBERTa model)"),xZo=l(),CF=a("li"),Tve=a("strong"),$Zo=o("deberta-v2"),kZo=o(" \u2014 "),DW=a("a"),SZo=o("DebertaV2ForSequenceClassification"),RZo=o(" (DeBERTa-v2 model)"),PZo=l(),wF=a("li"),Mve=a("strong"),BZo=o("distilbert"),IZo=o(" \u2014 "),GW=a("a"),NZo=o("DistilBertForSequenceClassification"),qZo=o(" (DistilBERT model)"),jZo=l(),AF=a("li"),Eve=a("strong"),DZo=o("electra"),GZo=o(" \u2014 "),OW=a("a"),OZo=o("ElectraForSequenceClassification"),VZo=o(" (ELECTRA model)"),XZo=l(),LF=a("li"),Cve=a("strong"),zZo=o("ernie"),QZo=o(" \u2014 "),VW=a("a"),WZo=o("ErnieForSequenceClassification"),UZo=o(" (ERNIE model)"),HZo=l(),yF=a("li"),wve=a("strong"),JZo=o("flaubert"),YZo=o(" \u2014 "),XW=a("a"),KZo=o("FlaubertForSequenceClassification"),ZZo=o(" (FlauBERT model)"),eer=l(),xF=a("li"),Ave=a("strong"),oer=o("fnet"),rer=o(" \u2014 "),zW=a("a"),ter=o("FNetForSequenceClassification"),aer=o(" (FNet model)"),ner=l(),$F=a("li"),Lve=a("strong"),ser=o("funnel"),ler=o(" \u2014 "),QW=a("a"),ier=o("FunnelForSequenceClassification"),der=o(" (Funnel Transformer model)"),cer=l(),kF=a("li"),yve=a("strong"),mer=o("gpt2"),fer=o(" \u2014 "),WW=a("a"),ger=o("GPT2ForSequenceClassification"),her=o(" (OpenAI GPT-2 model)"),uer=l(),SF=a("li"),xve=a("strong"),per=o("gpt_neo"),_er=o(" \u2014 "),UW=a("a"),ber=o("GPTNeoForSequenceClassification"),ver=o(" (GPT Neo model)"),Fer=l(),RF=a("li"),$ve=a("strong"),Ter=o("gptj"),Mer=o(" \u2014 "),HW=a("a"),Eer=o("GPTJForSequenceClassification"),Cer=o(" (GPT-J model)"),wer=l(),PF=a("li"),kve=a("strong"),Aer=o("ibert"),Ler=o(" \u2014 "),JW=a("a"),yer=o("IBertForSequenceClassification"),xer=o(" (I-BERT model)"),$er=l(),BF=a("li"),Sve=a("strong"),ker=o("layoutlm"),Ser=o(" \u2014 "),YW=a("a"),Rer=o("LayoutLMForSequenceClassification"),Per=o(" (LayoutLM model)"),Ber=l(),IF=a("li"),Rve=a("strong"),Ier=o("layoutlmv2"),Ner=o(" \u2014 "),KW=a("a"),qer=o("LayoutLMv2ForSequenceClassification"),jer=o(" (LayoutLMv2 model)"),Der=l(),NF=a("li"),Pve=a("strong"),Ger=o("layoutlmv3"),Oer=o(" \u2014 "),ZW=a("a"),Ver=o("LayoutLMv3ForSequenceClassification"),Xer=o(" (LayoutLMv3 model)"),zer=l(),qF=a("li"),Bve=a("strong"),Qer=o("led"),Wer=o(" \u2014 "),eU=a("a"),Uer=o("LEDForSequenceClassification"),Her=o(" (LED model)"),Jer=l(),jF=a("li"),Ive=a("strong"),Yer=o("longformer"),Ker=o(" \u2014 "),oU=a("a"),Zer=o("LongformerForSequenceClassification"),eor=o(" (Longformer model)"),oor=l(),DF=a("li"),Nve=a("strong"),ror=o("luke"),tor=o(" \u2014 "),rU=a("a"),aor=o("LukeForSequenceClassification"),nor=o(" (LUKE model)"),sor=l(),GF=a("li"),qve=a("strong"),lor=o("mbart"),ior=o(" \u2014 "),tU=a("a"),dor=o("MBartForSequenceClassification"),cor=o(" (mBART model)"),mor=l(),OF=a("li"),jve=a("strong"),gor=o("megatron-bert"),hor=o(" \u2014 "),aU=a("a"),uor=o("MegatronBertForSequenceClassification"),por=o(" (Megatron-BERT model)"),_or=l(),VF=a("li"),Dve=a("strong"),bor=o("mobilebert"),vor=o(" \u2014 "),nU=a("a"),For=o("MobileBertForSequenceClassification"),Tor=o(" (MobileBERT model)"),Mor=l(),XF=a("li"),Gve=a("strong"),Eor=o("mpnet"),Cor=o(" \u2014 "),sU=a("a"),wor=o("MPNetForSequenceClassification"),Aor=o(" (MPNet model)"),Lor=l(),zF=a("li"),Ove=a("strong"),yor=o("mvp"),xor=o(" \u2014 "),lU=a("a"),$or=o("MvpForSequenceClassification"),kor=o(" (MVP model)"),Sor=l(),QF=a("li"),Vve=a("strong"),Ror=o("nezha"),Por=o(" \u2014 "),iU=a("a"),Bor=o("NezhaForSequenceClassification"),Ior=o(" (Nezha model)"),Nor=l(),WF=a("li"),Xve=a("strong"),qor=o("nystromformer"),jor=o(" \u2014 "),dU=a("a"),Dor=o("NystromformerForSequenceClassification"),Gor=o(" (Nystr\xF6mformer model)"),Oor=l(),UF=a("li"),zve=a("strong"),Vor=o("openai-gpt"),Xor=o(" \u2014 "),cU=a("a"),zor=o("OpenAIGPTForSequenceClassification"),Qor=o(" (OpenAI GPT model)"),Wor=l(),HF=a("li"),Qve=a("strong"),Uor=o("opt"),Hor=o(" \u2014 "),mU=a("a"),Jor=o("OPTForSequenceClassification"),Yor=o(" (OPT model)"),Kor=l(),JF=a("li"),Wve=a("strong"),Zor=o("perceiver"),err=o(" \u2014 "),fU=a("a"),orr=o("PerceiverForSequenceClassification"),rrr=o(" (Perceiver model)"),trr=l(),YF=a("li"),Uve=a("strong"),arr=o("plbart"),nrr=o(" \u2014 "),gU=a("a"),srr=o("PLBartForSequenceClassification"),lrr=o(" (PLBart model)"),irr=l(),KF=a("li"),Hve=a("strong"),drr=o("qdqbert"),crr=o(" \u2014 "),hU=a("a"),mrr=o("QDQBertForSequenceClassification"),frr=o(" (QDQBert model)"),grr=l(),ZF=a("li"),Jve=a("strong"),hrr=o("reformer"),urr=o(" \u2014 "),uU=a("a"),prr=o("ReformerForSequenceClassification"),_rr=o(" (Reformer model)"),brr=l(),eT=a("li"),Yve=a("strong"),vrr=o("rembert"),Frr=o(" \u2014 "),pU=a("a"),Trr=o("RemBertForSequenceClassification"),Mrr=o(" (RemBERT model)"),Err=l(),oT=a("li"),Kve=a("strong"),Crr=o("roberta"),wrr=o(" \u2014 "),_U=a("a"),Arr=o("RobertaForSequenceClassification"),Lrr=o(" (RoBERTa model)"),yrr=l(),rT=a("li"),Zve=a("strong"),xrr=o("roformer"),$rr=o(" \u2014 "),bU=a("a"),krr=o("RoFormerForSequenceClassification"),Srr=o(" (RoFormer model)"),Rrr=l(),tT=a("li"),eFe=a("strong"),Prr=o("squeezebert"),Brr=o(" \u2014 "),vU=a("a"),Irr=o("SqueezeBertForSequenceClassification"),Nrr=o(" (SqueezeBERT model)"),qrr=l(),aT=a("li"),oFe=a("strong"),jrr=o("tapas"),Drr=o(" \u2014 "),FU=a("a"),Grr=o("TapasForSequenceClassification"),Orr=o(" (TAPAS model)"),Vrr=l(),nT=a("li"),rFe=a("strong"),Xrr=o("transfo-xl"),zrr=o(" \u2014 "),TU=a("a"),Qrr=o("TransfoXLForSequenceClassification"),Wrr=o(" (Transformer-XL model)"),Urr=l(),sT=a("li"),tFe=a("strong"),Hrr=o("xlm"),Jrr=o(" \u2014 "),MU=a("a"),Yrr=o("XLMForSequenceClassification"),Krr=o(" (XLM model)"),Zrr=l(),lT=a("li"),aFe=a("strong"),etr=o("xlm-roberta"),otr=o(" \u2014 "),EU=a("a"),rtr=o("XLMRobertaForSequenceClassification"),ttr=o(" (XLM-RoBERTa model)"),atr=l(),iT=a("li"),nFe=a("strong"),ntr=o("xlm-roberta-xl"),str=o(" \u2014 "),CU=a("a"),ltr=o("XLMRobertaXLForSequenceClassification"),itr=o(" (XLM-RoBERTa-XL model)"),dtr=l(),dT=a("li"),sFe=a("strong"),ctr=o("xlnet"),mtr=o(" \u2014 "),wU=a("a"),ftr=o("XLNetForSequenceClassification"),gtr=o(" (XLNet model)"),htr=l(),cT=a("li"),lFe=a("strong"),utr=o("yoso"),ptr=o(" \u2014 "),AU=a("a"),_tr=o("YosoForSequenceClassification"),btr=o(" (YOSO model)"),vtr=l(),mT=a("p"),Ftr=o("The model is set in evaluation mode by default using "),iFe=a("code"),Ttr=o("model.eval()"),Mtr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dFe=a("code"),Etr=o("model.train()"),Ctr=l(),F(fT.$$.fragment),vKe=l(),Pd=a("h2"),gT=a("a"),cFe=a("span"),F($x.$$.fragment),wtr=l(),mFe=a("span"),Atr=o("AutoModelForMultipleChoice"),FKe=l(),Do=a("div"),F(kx.$$.fragment),Ltr=l(),Bd=a("p"),ytr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),LU=a("a"),xtr=o("from_pretrained()"),$tr=o(" class method or the "),yU=a("a"),ktr=o("from_config()"),Str=o(` class
method.`),Rtr=l(),Sx=a("p"),Ptr=o("This class cannot be instantiated directly using "),fFe=a("code"),Btr=o("__init__()"),Itr=o(" (throws an error)."),Ntr=l(),Et=a("div"),F(Rx.$$.fragment),qtr=l(),gFe=a("p"),jtr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Dtr=l(),Id=a("p"),Gtr=o(`Note:
Loading a model from its configuration file does `),hFe=a("strong"),Otr=o("not"),Vtr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xU=a("a"),Xtr=o("from_pretrained()"),ztr=o(" to load the model weights."),Qtr=l(),F(hT.$$.fragment),Wtr=l(),no=a("div"),F(Px.$$.fragment),Utr=l(),uFe=a("p"),Htr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Jtr=l(),rn=a("p"),Ytr=o("The model class to instantiate is selected based on the "),pFe=a("code"),Ktr=o("model_type"),Ztr=o(` property of the config object (either
passed as an argument or loaded from `),_Fe=a("code"),ear=o("pretrained_model_name_or_path"),oar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bFe=a("code"),rar=o("pretrained_model_name_or_path"),tar=o(":"),aar=l(),Z=a("ul"),uT=a("li"),vFe=a("strong"),nar=o("albert"),sar=o(" \u2014 "),$U=a("a"),lar=o("AlbertForMultipleChoice"),iar=o(" (ALBERT model)"),dar=l(),pT=a("li"),FFe=a("strong"),car=o("bert"),mar=o(" \u2014 "),kU=a("a"),far=o("BertForMultipleChoice"),gar=o(" (BERT model)"),har=l(),_T=a("li"),TFe=a("strong"),uar=o("big_bird"),par=o(" \u2014 "),SU=a("a"),_ar=o("BigBirdForMultipleChoice"),bar=o(" (BigBird model)"),Far=l(),bT=a("li"),MFe=a("strong"),Tar=o("camembert"),Mar=o(" \u2014 "),RU=a("a"),Ear=o("CamembertForMultipleChoice"),Car=o(" (CamemBERT model)"),war=l(),vT=a("li"),EFe=a("strong"),Aar=o("canine"),Lar=o(" \u2014 "),PU=a("a"),yar=o("CanineForMultipleChoice"),xar=o(" (CANINE model)"),$ar=l(),FT=a("li"),CFe=a("strong"),kar=o("convbert"),Sar=o(" \u2014 "),BU=a("a"),Rar=o("ConvBertForMultipleChoice"),Par=o(" (ConvBERT model)"),Bar=l(),TT=a("li"),wFe=a("strong"),Iar=o("data2vec-text"),Nar=o(" \u2014 "),IU=a("a"),qar=o("Data2VecTextForMultipleChoice"),jar=o(" (Data2VecText model)"),Dar=l(),MT=a("li"),AFe=a("strong"),Gar=o("deberta-v2"),Oar=o(" \u2014 "),NU=a("a"),Var=o("DebertaV2ForMultipleChoice"),Xar=o(" (DeBERTa-v2 model)"),zar=l(),ET=a("li"),LFe=a("strong"),Qar=o("distilbert"),War=o(" \u2014 "),qU=a("a"),Uar=o("DistilBertForMultipleChoice"),Har=o(" (DistilBERT model)"),Jar=l(),CT=a("li"),yFe=a("strong"),Yar=o("electra"),Kar=o(" \u2014 "),jU=a("a"),Zar=o("ElectraForMultipleChoice"),enr=o(" (ELECTRA model)"),onr=l(),wT=a("li"),xFe=a("strong"),rnr=o("ernie"),tnr=o(" \u2014 "),DU=a("a"),anr=o("ErnieForMultipleChoice"),nnr=o(" (ERNIE model)"),snr=l(),AT=a("li"),$Fe=a("strong"),lnr=o("flaubert"),inr=o(" \u2014 "),GU=a("a"),dnr=o("FlaubertForMultipleChoice"),cnr=o(" (FlauBERT model)"),mnr=l(),LT=a("li"),kFe=a("strong"),fnr=o("fnet"),gnr=o(" \u2014 "),OU=a("a"),hnr=o("FNetForMultipleChoice"),unr=o(" (FNet model)"),pnr=l(),yT=a("li"),SFe=a("strong"),_nr=o("funnel"),bnr=o(" \u2014 "),VU=a("a"),vnr=o("FunnelForMultipleChoice"),Fnr=o(" (Funnel Transformer model)"),Tnr=l(),xT=a("li"),RFe=a("strong"),Mnr=o("ibert"),Enr=o(" \u2014 "),XU=a("a"),Cnr=o("IBertForMultipleChoice"),wnr=o(" (I-BERT model)"),Anr=l(),$T=a("li"),PFe=a("strong"),Lnr=o("longformer"),ynr=o(" \u2014 "),zU=a("a"),xnr=o("LongformerForMultipleChoice"),$nr=o(" (Longformer model)"),knr=l(),kT=a("li"),BFe=a("strong"),Snr=o("luke"),Rnr=o(" \u2014 "),QU=a("a"),Pnr=o("LukeForMultipleChoice"),Bnr=o(" (LUKE model)"),Inr=l(),ST=a("li"),IFe=a("strong"),Nnr=o("megatron-bert"),qnr=o(" \u2014 "),WU=a("a"),jnr=o("MegatronBertForMultipleChoice"),Dnr=o(" (Megatron-BERT model)"),Gnr=l(),RT=a("li"),NFe=a("strong"),Onr=o("mobilebert"),Vnr=o(" \u2014 "),UU=a("a"),Xnr=o("MobileBertForMultipleChoice"),znr=o(" (MobileBERT model)"),Qnr=l(),PT=a("li"),qFe=a("strong"),Wnr=o("mpnet"),Unr=o(" \u2014 "),HU=a("a"),Hnr=o("MPNetForMultipleChoice"),Jnr=o(" (MPNet model)"),Ynr=l(),BT=a("li"),jFe=a("strong"),Knr=o("nezha"),Znr=o(" \u2014 "),JU=a("a"),esr=o("NezhaForMultipleChoice"),osr=o(" (Nezha model)"),rsr=l(),IT=a("li"),DFe=a("strong"),tsr=o("nystromformer"),asr=o(" \u2014 "),YU=a("a"),nsr=o("NystromformerForMultipleChoice"),ssr=o(" (Nystr\xF6mformer model)"),lsr=l(),NT=a("li"),GFe=a("strong"),isr=o("qdqbert"),dsr=o(" \u2014 "),KU=a("a"),csr=o("QDQBertForMultipleChoice"),msr=o(" (QDQBert model)"),fsr=l(),qT=a("li"),OFe=a("strong"),gsr=o("rembert"),hsr=o(" \u2014 "),ZU=a("a"),usr=o("RemBertForMultipleChoice"),psr=o(" (RemBERT model)"),_sr=l(),jT=a("li"),VFe=a("strong"),bsr=o("roberta"),vsr=o(" \u2014 "),eH=a("a"),Fsr=o("RobertaForMultipleChoice"),Tsr=o(" (RoBERTa model)"),Msr=l(),DT=a("li"),XFe=a("strong"),Esr=o("roformer"),Csr=o(" \u2014 "),oH=a("a"),wsr=o("RoFormerForMultipleChoice"),Asr=o(" (RoFormer model)"),Lsr=l(),GT=a("li"),zFe=a("strong"),ysr=o("squeezebert"),xsr=o(" \u2014 "),rH=a("a"),$sr=o("SqueezeBertForMultipleChoice"),ksr=o(" (SqueezeBERT model)"),Ssr=l(),OT=a("li"),QFe=a("strong"),Rsr=o("xlm"),Psr=o(" \u2014 "),tH=a("a"),Bsr=o("XLMForMultipleChoice"),Isr=o(" (XLM model)"),Nsr=l(),VT=a("li"),WFe=a("strong"),qsr=o("xlm-roberta"),jsr=o(" \u2014 "),aH=a("a"),Dsr=o("XLMRobertaForMultipleChoice"),Gsr=o(" (XLM-RoBERTa model)"),Osr=l(),XT=a("li"),UFe=a("strong"),Vsr=o("xlm-roberta-xl"),Xsr=o(" \u2014 "),nH=a("a"),zsr=o("XLMRobertaXLForMultipleChoice"),Qsr=o(" (XLM-RoBERTa-XL model)"),Wsr=l(),zT=a("li"),HFe=a("strong"),Usr=o("xlnet"),Hsr=o(" \u2014 "),sH=a("a"),Jsr=o("XLNetForMultipleChoice"),Ysr=o(" (XLNet model)"),Ksr=l(),QT=a("li"),JFe=a("strong"),Zsr=o("yoso"),elr=o(" \u2014 "),lH=a("a"),olr=o("YosoForMultipleChoice"),rlr=o(" (YOSO model)"),tlr=l(),WT=a("p"),alr=o("The model is set in evaluation mode by default using "),YFe=a("code"),nlr=o("model.eval()"),slr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),KFe=a("code"),llr=o("model.train()"),ilr=l(),F(UT.$$.fragment),TKe=l(),Nd=a("h2"),HT=a("a"),ZFe=a("span"),F(Bx.$$.fragment),dlr=l(),eTe=a("span"),clr=o("AutoModelForNextSentencePrediction"),MKe=l(),Go=a("div"),F(Ix.$$.fragment),mlr=l(),qd=a("p"),flr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),iH=a("a"),glr=o("from_pretrained()"),hlr=o(" class method or the "),dH=a("a"),ulr=o("from_config()"),plr=o(` class
method.`),_lr=l(),Nx=a("p"),blr=o("This class cannot be instantiated directly using "),oTe=a("code"),vlr=o("__init__()"),Flr=o(" (throws an error)."),Tlr=l(),Ct=a("div"),F(qx.$$.fragment),Mlr=l(),rTe=a("p"),Elr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Clr=l(),jd=a("p"),wlr=o(`Note:
Loading a model from its configuration file does `),tTe=a("strong"),Alr=o("not"),Llr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cH=a("a"),ylr=o("from_pretrained()"),xlr=o(" to load the model weights."),$lr=l(),F(JT.$$.fragment),klr=l(),so=a("div"),F(jx.$$.fragment),Slr=l(),aTe=a("p"),Rlr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Plr=l(),tn=a("p"),Blr=o("The model class to instantiate is selected based on the "),nTe=a("code"),Ilr=o("model_type"),Nlr=o(` property of the config object (either
passed as an argument or loaded from `),sTe=a("code"),qlr=o("pretrained_model_name_or_path"),jlr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lTe=a("code"),Dlr=o("pretrained_model_name_or_path"),Glr=o(":"),Olr=l(),Ue=a("ul"),YT=a("li"),iTe=a("strong"),Vlr=o("bert"),Xlr=o(" \u2014 "),mH=a("a"),zlr=o("BertForNextSentencePrediction"),Qlr=o(" (BERT model)"),Wlr=l(),KT=a("li"),dTe=a("strong"),Ulr=o("ernie"),Hlr=o(" \u2014 "),fH=a("a"),Jlr=o("ErnieForNextSentencePrediction"),Ylr=o(" (ERNIE model)"),Klr=l(),ZT=a("li"),cTe=a("strong"),Zlr=o("fnet"),eir=o(" \u2014 "),gH=a("a"),oir=o("FNetForNextSentencePrediction"),rir=o(" (FNet model)"),tir=l(),eM=a("li"),mTe=a("strong"),air=o("megatron-bert"),nir=o(" \u2014 "),hH=a("a"),sir=o("MegatronBertForNextSentencePrediction"),lir=o(" (Megatron-BERT model)"),iir=l(),oM=a("li"),fTe=a("strong"),dir=o("mobilebert"),cir=o(" \u2014 "),uH=a("a"),mir=o("MobileBertForNextSentencePrediction"),fir=o(" (MobileBERT model)"),gir=l(),rM=a("li"),gTe=a("strong"),hir=o("nezha"),uir=o(" \u2014 "),pH=a("a"),pir=o("NezhaForNextSentencePrediction"),_ir=o(" (Nezha model)"),bir=l(),tM=a("li"),hTe=a("strong"),vir=o("qdqbert"),Fir=o(" \u2014 "),_H=a("a"),Tir=o("QDQBertForNextSentencePrediction"),Mir=o(" (QDQBert model)"),Eir=l(),aM=a("p"),Cir=o("The model is set in evaluation mode by default using "),uTe=a("code"),wir=o("model.eval()"),Air=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pTe=a("code"),Lir=o("model.train()"),yir=l(),F(nM.$$.fragment),EKe=l(),Dd=a("h2"),sM=a("a"),_Te=a("span"),F(Dx.$$.fragment),xir=l(),bTe=a("span"),$ir=o("AutoModelForTokenClassification"),CKe=l(),Oo=a("div"),F(Gx.$$.fragment),kir=l(),Gd=a("p"),Sir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),bH=a("a"),Rir=o("from_pretrained()"),Pir=o(" class method or the "),vH=a("a"),Bir=o("from_config()"),Iir=o(` class
method.`),Nir=l(),Ox=a("p"),qir=o("This class cannot be instantiated directly using "),vTe=a("code"),jir=o("__init__()"),Dir=o(" (throws an error)."),Gir=l(),wt=a("div"),F(Vx.$$.fragment),Oir=l(),FTe=a("p"),Vir=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Xir=l(),Od=a("p"),zir=o(`Note:
Loading a model from its configuration file does `),TTe=a("strong"),Qir=o("not"),Wir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FH=a("a"),Uir=o("from_pretrained()"),Hir=o(" to load the model weights."),Jir=l(),F(lM.$$.fragment),Yir=l(),lo=a("div"),F(Xx.$$.fragment),Kir=l(),MTe=a("p"),Zir=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),edr=l(),an=a("p"),odr=o("The model class to instantiate is selected based on the "),ETe=a("code"),rdr=o("model_type"),tdr=o(` property of the config object (either
passed as an argument or loaded from `),CTe=a("code"),adr=o("pretrained_model_name_or_path"),ndr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wTe=a("code"),sdr=o("pretrained_model_name_or_path"),ldr=o(":"),idr=l(),J=a("ul"),iM=a("li"),ATe=a("strong"),ddr=o("albert"),cdr=o(" \u2014 "),TH=a("a"),mdr=o("AlbertForTokenClassification"),fdr=o(" (ALBERT model)"),gdr=l(),dM=a("li"),LTe=a("strong"),hdr=o("bert"),udr=o(" \u2014 "),MH=a("a"),pdr=o("BertForTokenClassification"),_dr=o(" (BERT model)"),bdr=l(),cM=a("li"),yTe=a("strong"),vdr=o("big_bird"),Fdr=o(" \u2014 "),EH=a("a"),Tdr=o("BigBirdForTokenClassification"),Mdr=o(" (BigBird model)"),Edr=l(),mM=a("li"),xTe=a("strong"),Cdr=o("bloom"),wdr=o(" \u2014 "),CH=a("a"),Adr=o("BloomForTokenClassification"),Ldr=o(" (BLOOM model)"),ydr=l(),fM=a("li"),$Te=a("strong"),xdr=o("camembert"),$dr=o(" \u2014 "),wH=a("a"),kdr=o("CamembertForTokenClassification"),Sdr=o(" (CamemBERT model)"),Rdr=l(),gM=a("li"),kTe=a("strong"),Pdr=o("canine"),Bdr=o(" \u2014 "),AH=a("a"),Idr=o("CanineForTokenClassification"),Ndr=o(" (CANINE model)"),qdr=l(),hM=a("li"),STe=a("strong"),jdr=o("convbert"),Ddr=o(" \u2014 "),LH=a("a"),Gdr=o("ConvBertForTokenClassification"),Odr=o(" (ConvBERT model)"),Vdr=l(),uM=a("li"),RTe=a("strong"),Xdr=o("data2vec-text"),zdr=o(" \u2014 "),yH=a("a"),Qdr=o("Data2VecTextForTokenClassification"),Wdr=o(" (Data2VecText model)"),Udr=l(),pM=a("li"),PTe=a("strong"),Hdr=o("deberta"),Jdr=o(" \u2014 "),xH=a("a"),Ydr=o("DebertaForTokenClassification"),Kdr=o(" (DeBERTa model)"),Zdr=l(),_M=a("li"),BTe=a("strong"),ecr=o("deberta-v2"),ocr=o(" \u2014 "),$H=a("a"),rcr=o("DebertaV2ForTokenClassification"),tcr=o(" (DeBERTa-v2 model)"),acr=l(),bM=a("li"),ITe=a("strong"),ncr=o("distilbert"),scr=o(" \u2014 "),kH=a("a"),lcr=o("DistilBertForTokenClassification"),icr=o(" (DistilBERT model)"),dcr=l(),vM=a("li"),NTe=a("strong"),ccr=o("electra"),mcr=o(" \u2014 "),SH=a("a"),fcr=o("ElectraForTokenClassification"),gcr=o(" (ELECTRA model)"),hcr=l(),FM=a("li"),qTe=a("strong"),ucr=o("ernie"),pcr=o(" \u2014 "),RH=a("a"),_cr=o("ErnieForTokenClassification"),bcr=o(" (ERNIE model)"),vcr=l(),TM=a("li"),jTe=a("strong"),Fcr=o("flaubert"),Tcr=o(" \u2014 "),PH=a("a"),Mcr=o("FlaubertForTokenClassification"),Ecr=o(" (FlauBERT model)"),Ccr=l(),MM=a("li"),DTe=a("strong"),wcr=o("fnet"),Acr=o(" \u2014 "),BH=a("a"),Lcr=o("FNetForTokenClassification"),ycr=o(" (FNet model)"),xcr=l(),EM=a("li"),GTe=a("strong"),$cr=o("funnel"),kcr=o(" \u2014 "),IH=a("a"),Scr=o("FunnelForTokenClassification"),Rcr=o(" (Funnel Transformer model)"),Pcr=l(),CM=a("li"),OTe=a("strong"),Bcr=o("gpt2"),Icr=o(" \u2014 "),NH=a("a"),Ncr=o("GPT2ForTokenClassification"),qcr=o(" (OpenAI GPT-2 model)"),jcr=l(),wM=a("li"),VTe=a("strong"),Dcr=o("ibert"),Gcr=o(" \u2014 "),qH=a("a"),Ocr=o("IBertForTokenClassification"),Vcr=o(" (I-BERT model)"),Xcr=l(),AM=a("li"),XTe=a("strong"),zcr=o("layoutlm"),Qcr=o(" \u2014 "),jH=a("a"),Wcr=o("LayoutLMForTokenClassification"),Ucr=o(" (LayoutLM model)"),Hcr=l(),LM=a("li"),zTe=a("strong"),Jcr=o("layoutlmv2"),Ycr=o(" \u2014 "),DH=a("a"),Kcr=o("LayoutLMv2ForTokenClassification"),Zcr=o(" (LayoutLMv2 model)"),emr=l(),yM=a("li"),QTe=a("strong"),omr=o("layoutlmv3"),rmr=o(" \u2014 "),GH=a("a"),tmr=o("LayoutLMv3ForTokenClassification"),amr=o(" (LayoutLMv3 model)"),nmr=l(),xM=a("li"),WTe=a("strong"),smr=o("longformer"),lmr=o(" \u2014 "),OH=a("a"),imr=o("LongformerForTokenClassification"),dmr=o(" (Longformer model)"),cmr=l(),$M=a("li"),UTe=a("strong"),mmr=o("luke"),fmr=o(" \u2014 "),VH=a("a"),gmr=o("LukeForTokenClassification"),hmr=o(" (LUKE model)"),umr=l(),kM=a("li"),HTe=a("strong"),pmr=o("megatron-bert"),_mr=o(" \u2014 "),XH=a("a"),bmr=o("MegatronBertForTokenClassification"),vmr=o(" (Megatron-BERT model)"),Fmr=l(),SM=a("li"),JTe=a("strong"),Tmr=o("mobilebert"),Mmr=o(" \u2014 "),zH=a("a"),Emr=o("MobileBertForTokenClassification"),Cmr=o(" (MobileBERT model)"),wmr=l(),RM=a("li"),YTe=a("strong"),Amr=o("mpnet"),Lmr=o(" \u2014 "),QH=a("a"),ymr=o("MPNetForTokenClassification"),xmr=o(" (MPNet model)"),$mr=l(),PM=a("li"),KTe=a("strong"),kmr=o("nezha"),Smr=o(" \u2014 "),WH=a("a"),Rmr=o("NezhaForTokenClassification"),Pmr=o(" (Nezha model)"),Bmr=l(),BM=a("li"),ZTe=a("strong"),Imr=o("nystromformer"),Nmr=o(" \u2014 "),UH=a("a"),qmr=o("NystromformerForTokenClassification"),jmr=o(" (Nystr\xF6mformer model)"),Dmr=l(),IM=a("li"),eMe=a("strong"),Gmr=o("qdqbert"),Omr=o(" \u2014 "),HH=a("a"),Vmr=o("QDQBertForTokenClassification"),Xmr=o(" (QDQBert model)"),zmr=l(),NM=a("li"),oMe=a("strong"),Qmr=o("rembert"),Wmr=o(" \u2014 "),JH=a("a"),Umr=o("RemBertForTokenClassification"),Hmr=o(" (RemBERT model)"),Jmr=l(),qM=a("li"),rMe=a("strong"),Ymr=o("roberta"),Kmr=o(" \u2014 "),YH=a("a"),Zmr=o("RobertaForTokenClassification"),efr=o(" (RoBERTa model)"),ofr=l(),jM=a("li"),tMe=a("strong"),rfr=o("roformer"),tfr=o(" \u2014 "),KH=a("a"),afr=o("RoFormerForTokenClassification"),nfr=o(" (RoFormer model)"),sfr=l(),DM=a("li"),aMe=a("strong"),lfr=o("squeezebert"),ifr=o(" \u2014 "),ZH=a("a"),dfr=o("SqueezeBertForTokenClassification"),cfr=o(" (SqueezeBERT model)"),mfr=l(),GM=a("li"),nMe=a("strong"),ffr=o("xlm"),gfr=o(" \u2014 "),eJ=a("a"),hfr=o("XLMForTokenClassification"),ufr=o(" (XLM model)"),pfr=l(),OM=a("li"),sMe=a("strong"),_fr=o("xlm-roberta"),bfr=o(" \u2014 "),oJ=a("a"),vfr=o("XLMRobertaForTokenClassification"),Ffr=o(" (XLM-RoBERTa model)"),Tfr=l(),VM=a("li"),lMe=a("strong"),Mfr=o("xlm-roberta-xl"),Efr=o(" \u2014 "),rJ=a("a"),Cfr=o("XLMRobertaXLForTokenClassification"),wfr=o(" (XLM-RoBERTa-XL model)"),Afr=l(),XM=a("li"),iMe=a("strong"),Lfr=o("xlnet"),yfr=o(" \u2014 "),tJ=a("a"),xfr=o("XLNetForTokenClassification"),$fr=o(" (XLNet model)"),kfr=l(),zM=a("li"),dMe=a("strong"),Sfr=o("yoso"),Rfr=o(" \u2014 "),aJ=a("a"),Pfr=o("YosoForTokenClassification"),Bfr=o(" (YOSO model)"),Ifr=l(),QM=a("p"),Nfr=o("The model is set in evaluation mode by default using "),cMe=a("code"),qfr=o("model.eval()"),jfr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mMe=a("code"),Dfr=o("model.train()"),Gfr=l(),F(WM.$$.fragment),wKe=l(),Vd=a("h2"),UM=a("a"),fMe=a("span"),F(zx.$$.fragment),Ofr=l(),gMe=a("span"),Vfr=o("AutoModelForQuestionAnswering"),AKe=l(),Vo=a("div"),F(Qx.$$.fragment),Xfr=l(),Xd=a("p"),zfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),nJ=a("a"),Qfr=o("from_pretrained()"),Wfr=o(" class method or the "),sJ=a("a"),Ufr=o("from_config()"),Hfr=o(` class
method.`),Jfr=l(),Wx=a("p"),Yfr=o("This class cannot be instantiated directly using "),hMe=a("code"),Kfr=o("__init__()"),Zfr=o(" (throws an error)."),egr=l(),At=a("div"),F(Ux.$$.fragment),ogr=l(),uMe=a("p"),rgr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),tgr=l(),zd=a("p"),agr=o(`Note:
Loading a model from its configuration file does `),pMe=a("strong"),ngr=o("not"),sgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lJ=a("a"),lgr=o("from_pretrained()"),igr=o(" to load the model weights."),dgr=l(),F(HM.$$.fragment),cgr=l(),io=a("div"),F(Hx.$$.fragment),mgr=l(),_Me=a("p"),fgr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),ggr=l(),nn=a("p"),hgr=o("The model class to instantiate is selected based on the "),bMe=a("code"),ugr=o("model_type"),pgr=o(` property of the config object (either
passed as an argument or loaded from `),vMe=a("code"),_gr=o("pretrained_model_name_or_path"),bgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FMe=a("code"),vgr=o("pretrained_model_name_or_path"),Fgr=o(":"),Tgr=l(),V=a("ul"),JM=a("li"),TMe=a("strong"),Mgr=o("albert"),Egr=o(" \u2014 "),iJ=a("a"),Cgr=o("AlbertForQuestionAnswering"),wgr=o(" (ALBERT model)"),Agr=l(),YM=a("li"),MMe=a("strong"),Lgr=o("bart"),ygr=o(" \u2014 "),dJ=a("a"),xgr=o("BartForQuestionAnswering"),$gr=o(" (BART model)"),kgr=l(),KM=a("li"),EMe=a("strong"),Sgr=o("bert"),Rgr=o(" \u2014 "),cJ=a("a"),Pgr=o("BertForQuestionAnswering"),Bgr=o(" (BERT model)"),Igr=l(),ZM=a("li"),CMe=a("strong"),Ngr=o("big_bird"),qgr=o(" \u2014 "),mJ=a("a"),jgr=o("BigBirdForQuestionAnswering"),Dgr=o(" (BigBird model)"),Ggr=l(),eE=a("li"),wMe=a("strong"),Ogr=o("bigbird_pegasus"),Vgr=o(" \u2014 "),fJ=a("a"),Xgr=o("BigBirdPegasusForQuestionAnswering"),zgr=o(" (BigBird-Pegasus model)"),Qgr=l(),oE=a("li"),AMe=a("strong"),Wgr=o("camembert"),Ugr=o(" \u2014 "),gJ=a("a"),Hgr=o("CamembertForQuestionAnswering"),Jgr=o(" (CamemBERT model)"),Ygr=l(),rE=a("li"),LMe=a("strong"),Kgr=o("canine"),Zgr=o(" \u2014 "),hJ=a("a"),ehr=o("CanineForQuestionAnswering"),ohr=o(" (CANINE model)"),rhr=l(),tE=a("li"),yMe=a("strong"),thr=o("convbert"),ahr=o(" \u2014 "),uJ=a("a"),nhr=o("ConvBertForQuestionAnswering"),shr=o(" (ConvBERT model)"),lhr=l(),aE=a("li"),xMe=a("strong"),ihr=o("data2vec-text"),dhr=o(" \u2014 "),pJ=a("a"),chr=o("Data2VecTextForQuestionAnswering"),mhr=o(" (Data2VecText model)"),fhr=l(),nE=a("li"),$Me=a("strong"),ghr=o("deberta"),hhr=o(" \u2014 "),_J=a("a"),uhr=o("DebertaForQuestionAnswering"),phr=o(" (DeBERTa model)"),_hr=l(),sE=a("li"),kMe=a("strong"),bhr=o("deberta-v2"),vhr=o(" \u2014 "),bJ=a("a"),Fhr=o("DebertaV2ForQuestionAnswering"),Thr=o(" (DeBERTa-v2 model)"),Mhr=l(),lE=a("li"),SMe=a("strong"),Ehr=o("distilbert"),Chr=o(" \u2014 "),vJ=a("a"),whr=o("DistilBertForQuestionAnswering"),Ahr=o(" (DistilBERT model)"),Lhr=l(),iE=a("li"),RMe=a("strong"),yhr=o("electra"),xhr=o(" \u2014 "),FJ=a("a"),$hr=o("ElectraForQuestionAnswering"),khr=o(" (ELECTRA model)"),Shr=l(),dE=a("li"),PMe=a("strong"),Rhr=o("ernie"),Phr=o(" \u2014 "),TJ=a("a"),Bhr=o("ErnieForQuestionAnswering"),Ihr=o(" (ERNIE model)"),Nhr=l(),cE=a("li"),BMe=a("strong"),qhr=o("flaubert"),jhr=o(" \u2014 "),MJ=a("a"),Dhr=o("FlaubertForQuestionAnsweringSimple"),Ghr=o(" (FlauBERT model)"),Ohr=l(),mE=a("li"),IMe=a("strong"),Vhr=o("fnet"),Xhr=o(" \u2014 "),EJ=a("a"),zhr=o("FNetForQuestionAnswering"),Qhr=o(" (FNet model)"),Whr=l(),fE=a("li"),NMe=a("strong"),Uhr=o("funnel"),Hhr=o(" \u2014 "),CJ=a("a"),Jhr=o("FunnelForQuestionAnswering"),Yhr=o(" (Funnel Transformer model)"),Khr=l(),gE=a("li"),qMe=a("strong"),Zhr=o("gptj"),eur=o(" \u2014 "),wJ=a("a"),our=o("GPTJForQuestionAnswering"),rur=o(" (GPT-J model)"),tur=l(),hE=a("li"),jMe=a("strong"),aur=o("ibert"),nur=o(" \u2014 "),AJ=a("a"),sur=o("IBertForQuestionAnswering"),lur=o(" (I-BERT model)"),iur=l(),uE=a("li"),DMe=a("strong"),dur=o("layoutlmv2"),cur=o(" \u2014 "),LJ=a("a"),mur=o("LayoutLMv2ForQuestionAnswering"),fur=o(" (LayoutLMv2 model)"),gur=l(),pE=a("li"),GMe=a("strong"),hur=o("layoutlmv3"),uur=o(" \u2014 "),yJ=a("a"),pur=o("LayoutLMv3ForQuestionAnswering"),_ur=o(" (LayoutLMv3 model)"),bur=l(),_E=a("li"),OMe=a("strong"),vur=o("led"),Fur=o(" \u2014 "),xJ=a("a"),Tur=o("LEDForQuestionAnswering"),Mur=o(" (LED model)"),Eur=l(),bE=a("li"),VMe=a("strong"),Cur=o("longformer"),wur=o(" \u2014 "),$J=a("a"),Aur=o("LongformerForQuestionAnswering"),Lur=o(" (Longformer model)"),yur=l(),vE=a("li"),XMe=a("strong"),xur=o("luke"),$ur=o(" \u2014 "),kJ=a("a"),kur=o("LukeForQuestionAnswering"),Sur=o(" (LUKE model)"),Rur=l(),FE=a("li"),zMe=a("strong"),Pur=o("lxmert"),Bur=o(" \u2014 "),SJ=a("a"),Iur=o("LxmertForQuestionAnswering"),Nur=o(" (LXMERT model)"),qur=l(),TE=a("li"),QMe=a("strong"),jur=o("mbart"),Dur=o(" \u2014 "),RJ=a("a"),Gur=o("MBartForQuestionAnswering"),Our=o(" (mBART model)"),Vur=l(),ME=a("li"),WMe=a("strong"),Xur=o("megatron-bert"),zur=o(" \u2014 "),PJ=a("a"),Qur=o("MegatronBertForQuestionAnswering"),Wur=o(" (Megatron-BERT model)"),Uur=l(),EE=a("li"),UMe=a("strong"),Hur=o("mobilebert"),Jur=o(" \u2014 "),BJ=a("a"),Yur=o("MobileBertForQuestionAnswering"),Kur=o(" (MobileBERT model)"),Zur=l(),CE=a("li"),HMe=a("strong"),epr=o("mpnet"),opr=o(" \u2014 "),IJ=a("a"),rpr=o("MPNetForQuestionAnswering"),tpr=o(" (MPNet model)"),apr=l(),wE=a("li"),JMe=a("strong"),npr=o("mvp"),spr=o(" \u2014 "),NJ=a("a"),lpr=o("MvpForQuestionAnswering"),ipr=o(" (MVP model)"),dpr=l(),AE=a("li"),YMe=a("strong"),cpr=o("nezha"),mpr=o(" \u2014 "),qJ=a("a"),fpr=o("NezhaForQuestionAnswering"),gpr=o(" (Nezha model)"),hpr=l(),LE=a("li"),KMe=a("strong"),upr=o("nystromformer"),ppr=o(" \u2014 "),jJ=a("a"),_pr=o("NystromformerForQuestionAnswering"),bpr=o(" (Nystr\xF6mformer model)"),vpr=l(),yE=a("li"),ZMe=a("strong"),Fpr=o("qdqbert"),Tpr=o(" \u2014 "),DJ=a("a"),Mpr=o("QDQBertForQuestionAnswering"),Epr=o(" (QDQBert model)"),Cpr=l(),xE=a("li"),eEe=a("strong"),wpr=o("reformer"),Apr=o(" \u2014 "),GJ=a("a"),Lpr=o("ReformerForQuestionAnswering"),ypr=o(" (Reformer model)"),xpr=l(),$E=a("li"),oEe=a("strong"),$pr=o("rembert"),kpr=o(" \u2014 "),OJ=a("a"),Spr=o("RemBertForQuestionAnswering"),Rpr=o(" (RemBERT model)"),Ppr=l(),kE=a("li"),rEe=a("strong"),Bpr=o("roberta"),Ipr=o(" \u2014 "),VJ=a("a"),Npr=o("RobertaForQuestionAnswering"),qpr=o(" (RoBERTa model)"),jpr=l(),SE=a("li"),tEe=a("strong"),Dpr=o("roformer"),Gpr=o(" \u2014 "),XJ=a("a"),Opr=o("RoFormerForQuestionAnswering"),Vpr=o(" (RoFormer model)"),Xpr=l(),RE=a("li"),aEe=a("strong"),zpr=o("splinter"),Qpr=o(" \u2014 "),zJ=a("a"),Wpr=o("SplinterForQuestionAnswering"),Upr=o(" (Splinter model)"),Hpr=l(),PE=a("li"),nEe=a("strong"),Jpr=o("squeezebert"),Ypr=o(" \u2014 "),QJ=a("a"),Kpr=o("SqueezeBertForQuestionAnswering"),Zpr=o(" (SqueezeBERT model)"),e_r=l(),BE=a("li"),sEe=a("strong"),o_r=o("xlm"),r_r=o(" \u2014 "),WJ=a("a"),t_r=o("XLMForQuestionAnsweringSimple"),a_r=o(" (XLM model)"),n_r=l(),IE=a("li"),lEe=a("strong"),s_r=o("xlm-roberta"),l_r=o(" \u2014 "),UJ=a("a"),i_r=o("XLMRobertaForQuestionAnswering"),d_r=o(" (XLM-RoBERTa model)"),c_r=l(),NE=a("li"),iEe=a("strong"),m_r=o("xlm-roberta-xl"),f_r=o(" \u2014 "),HJ=a("a"),g_r=o("XLMRobertaXLForQuestionAnswering"),h_r=o(" (XLM-RoBERTa-XL model)"),u_r=l(),qE=a("li"),dEe=a("strong"),p_r=o("xlnet"),__r=o(" \u2014 "),JJ=a("a"),b_r=o("XLNetForQuestionAnsweringSimple"),v_r=o(" (XLNet model)"),F_r=l(),jE=a("li"),cEe=a("strong"),T_r=o("yoso"),M_r=o(" \u2014 "),YJ=a("a"),E_r=o("YosoForQuestionAnswering"),C_r=o(" (YOSO model)"),w_r=l(),DE=a("p"),A_r=o("The model is set in evaluation mode by default using "),mEe=a("code"),L_r=o("model.eval()"),y_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fEe=a("code"),x_r=o("model.train()"),$_r=l(),F(GE.$$.fragment),LKe=l(),Qd=a("h2"),OE=a("a"),gEe=a("span"),F(Jx.$$.fragment),k_r=l(),hEe=a("span"),S_r=o("AutoModelForTableQuestionAnswering"),yKe=l(),Xo=a("div"),F(Yx.$$.fragment),R_r=l(),Wd=a("p"),P_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),KJ=a("a"),B_r=o("from_pretrained()"),I_r=o(" class method or the "),ZJ=a("a"),N_r=o("from_config()"),q_r=o(` class
method.`),j_r=l(),Kx=a("p"),D_r=o("This class cannot be instantiated directly using "),uEe=a("code"),G_r=o("__init__()"),O_r=o(" (throws an error)."),V_r=l(),Lt=a("div"),F(Zx.$$.fragment),X_r=l(),pEe=a("p"),z_r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Q_r=l(),Ud=a("p"),W_r=o(`Note:
Loading a model from its configuration file does `),_Ee=a("strong"),U_r=o("not"),H_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eY=a("a"),J_r=o("from_pretrained()"),Y_r=o(" to load the model weights."),K_r=l(),F(VE.$$.fragment),Z_r=l(),co=a("div"),F(e$.$$.fragment),ebr=l(),bEe=a("p"),obr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),rbr=l(),sn=a("p"),tbr=o("The model class to instantiate is selected based on the "),vEe=a("code"),abr=o("model_type"),nbr=o(` property of the config object (either
passed as an argument or loaded from `),FEe=a("code"),sbr=o("pretrained_model_name_or_path"),lbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TEe=a("code"),ibr=o("pretrained_model_name_or_path"),dbr=o(":"),cbr=l(),MEe=a("ul"),XE=a("li"),EEe=a("strong"),mbr=o("tapas"),fbr=o(" \u2014 "),oY=a("a"),gbr=o("TapasForQuestionAnswering"),hbr=o(" (TAPAS model)"),ubr=l(),zE=a("p"),pbr=o("The model is set in evaluation mode by default using "),CEe=a("code"),_br=o("model.eval()"),bbr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wEe=a("code"),vbr=o("model.train()"),Fbr=l(),F(QE.$$.fragment),xKe=l(),Hd=a("h2"),WE=a("a"),AEe=a("span"),F(o$.$$.fragment),Tbr=l(),LEe=a("span"),Mbr=o("AutoModelForDocumentQuestionAnswering"),$Ke=l(),zo=a("div"),F(r$.$$.fragment),Ebr=l(),Jd=a("p"),Cbr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),rY=a("a"),wbr=o("from_pretrained()"),Abr=o(" class method or the "),tY=a("a"),Lbr=o("from_config()"),ybr=o(` class
method.`),xbr=l(),t$=a("p"),$br=o("This class cannot be instantiated directly using "),yEe=a("code"),kbr=o("__init__()"),Sbr=o(" (throws an error)."),Rbr=l(),yt=a("div"),F(a$.$$.fragment),Pbr=l(),xEe=a("p"),Bbr=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Ibr=l(),Yd=a("p"),Nbr=o(`Note:
Loading a model from its configuration file does `),$Ee=a("strong"),qbr=o("not"),jbr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aY=a("a"),Dbr=o("from_pretrained()"),Gbr=o(" to load the model weights."),Obr=l(),F(UE.$$.fragment),Vbr=l(),mo=a("div"),F(n$.$$.fragment),Xbr=l(),kEe=a("p"),zbr=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Qbr=l(),ln=a("p"),Wbr=o("The model class to instantiate is selected based on the "),SEe=a("code"),Ubr=o("model_type"),Hbr=o(` property of the config object (either
passed as an argument or loaded from `),REe=a("code"),Jbr=o("pretrained_model_name_or_path"),Ybr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PEe=a("code"),Kbr=o("pretrained_model_name_or_path"),Zbr=o(":"),e2r=l(),Kd=a("ul"),HE=a("li"),BEe=a("strong"),o2r=o("layoutlm"),r2r=o(" \u2014 "),nY=a("a"),t2r=o("LayoutLMForQuestionAnswering"),a2r=o(" (LayoutLM model)"),n2r=l(),JE=a("li"),IEe=a("strong"),s2r=o("layoutlmv2"),l2r=o(" \u2014 "),sY=a("a"),i2r=o("LayoutLMv2ForQuestionAnswering"),d2r=o(" (LayoutLMv2 model)"),c2r=l(),YE=a("li"),NEe=a("strong"),m2r=o("layoutlmv3"),f2r=o(" \u2014 "),lY=a("a"),g2r=o("LayoutLMv3ForQuestionAnswering"),h2r=o(" (LayoutLMv3 model)"),u2r=l(),KE=a("p"),p2r=o("The model is set in evaluation mode by default using "),qEe=a("code"),_2r=o("model.eval()"),b2r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),jEe=a("code"),v2r=o("model.train()"),F2r=l(),F(ZE.$$.fragment),kKe=l(),Zd=a("h2"),e4=a("a"),DEe=a("span"),F(s$.$$.fragment),T2r=l(),GEe=a("span"),M2r=o("AutoModelForImageClassification"),SKe=l(),Qo=a("div"),F(l$.$$.fragment),E2r=l(),ec=a("p"),C2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),iY=a("a"),w2r=o("from_pretrained()"),A2r=o(" class method or the "),dY=a("a"),L2r=o("from_config()"),y2r=o(` class
method.`),x2r=l(),i$=a("p"),$2r=o("This class cannot be instantiated directly using "),OEe=a("code"),k2r=o("__init__()"),S2r=o(" (throws an error)."),R2r=l(),xt=a("div"),F(d$.$$.fragment),P2r=l(),VEe=a("p"),B2r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),I2r=l(),oc=a("p"),N2r=o(`Note:
Loading a model from its configuration file does `),XEe=a("strong"),q2r=o("not"),j2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cY=a("a"),D2r=o("from_pretrained()"),G2r=o(" to load the model weights."),O2r=l(),F(o4.$$.fragment),V2r=l(),fo=a("div"),F(c$.$$.fragment),X2r=l(),zEe=a("p"),z2r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Q2r=l(),dn=a("p"),W2r=o("The model class to instantiate is selected based on the "),QEe=a("code"),U2r=o("model_type"),H2r=o(` property of the config object (either
passed as an argument or loaded from `),WEe=a("code"),J2r=o("pretrained_model_name_or_path"),Y2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),UEe=a("code"),K2r=o("pretrained_model_name_or_path"),Z2r=o(":"),e1r=l(),be=a("ul"),r4=a("li"),HEe=a("strong"),o1r=o("beit"),r1r=o(" \u2014 "),mY=a("a"),t1r=o("BeitForImageClassification"),a1r=o(" (BEiT model)"),n1r=l(),t4=a("li"),JEe=a("strong"),s1r=o("convnext"),l1r=o(" \u2014 "),fY=a("a"),i1r=o("ConvNextForImageClassification"),d1r=o(" (ConvNeXT model)"),c1r=l(),a4=a("li"),YEe=a("strong"),m1r=o("cvt"),f1r=o(" \u2014 "),gY=a("a"),g1r=o("CvtForImageClassification"),h1r=o(" (CvT model)"),u1r=l(),n4=a("li"),KEe=a("strong"),p1r=o("data2vec-vision"),_1r=o(" \u2014 "),hY=a("a"),b1r=o("Data2VecVisionForImageClassification"),v1r=o(" (Data2VecVision model)"),F1r=l(),_l=a("li"),ZEe=a("strong"),T1r=o("deit"),M1r=o(" \u2014 "),uY=a("a"),E1r=o("DeiTForImageClassification"),C1r=o(" or "),pY=a("a"),w1r=o("DeiTForImageClassificationWithTeacher"),A1r=o(" (DeiT model)"),L1r=l(),s4=a("li"),e4e=a("strong"),y1r=o("imagegpt"),x1r=o(" \u2014 "),_Y=a("a"),$1r=o("ImageGPTForImageClassification"),k1r=o(" (ImageGPT model)"),S1r=l(),bl=a("li"),o4e=a("strong"),R1r=o("levit"),P1r=o(" \u2014 "),bY=a("a"),B1r=o("LevitForImageClassification"),I1r=o(" or "),vY=a("a"),N1r=o("LevitForImageClassificationWithTeacher"),q1r=o(" (LeViT model)"),j1r=l(),l4=a("li"),r4e=a("strong"),D1r=o("mobilevit"),G1r=o(" \u2014 "),FY=a("a"),O1r=o("MobileViTForImageClassification"),V1r=o(" (MobileViT model)"),X1r=l(),$t=a("li"),t4e=a("strong"),z1r=o("perceiver"),Q1r=o(" \u2014 "),TY=a("a"),W1r=o("PerceiverForImageClassificationLearned"),U1r=o(" or "),MY=a("a"),H1r=o("PerceiverForImageClassificationFourier"),J1r=o(" or "),EY=a("a"),Y1r=o("PerceiverForImageClassificationConvProcessing"),K1r=o(" (Perceiver model)"),Z1r=l(),i4=a("li"),a4e=a("strong"),evr=o("poolformer"),ovr=o(" \u2014 "),CY=a("a"),rvr=o("PoolFormerForImageClassification"),tvr=o(" (PoolFormer model)"),avr=l(),d4=a("li"),n4e=a("strong"),nvr=o("regnet"),svr=o(" \u2014 "),wY=a("a"),lvr=o("RegNetForImageClassification"),ivr=o(" (RegNet model)"),dvr=l(),c4=a("li"),s4e=a("strong"),cvr=o("resnet"),mvr=o(" \u2014 "),AY=a("a"),fvr=o("ResNetForImageClassification"),gvr=o(" (ResNet model)"),hvr=l(),m4=a("li"),l4e=a("strong"),uvr=o("segformer"),pvr=o(" \u2014 "),LY=a("a"),_vr=o("SegformerForImageClassification"),bvr=o(" (SegFormer model)"),vvr=l(),f4=a("li"),i4e=a("strong"),Fvr=o("swin"),Tvr=o(" \u2014 "),yY=a("a"),Mvr=o("SwinForImageClassification"),Evr=o(" (Swin Transformer model)"),Cvr=l(),g4=a("li"),d4e=a("strong"),wvr=o("swinv2"),Avr=o(" \u2014 "),xY=a("a"),Lvr=o("Swinv2ForImageClassification"),yvr=o(" (Swin Transformer V2 model)"),xvr=l(),h4=a("li"),c4e=a("strong"),$vr=o("van"),kvr=o(" \u2014 "),$Y=a("a"),Svr=o("VanForImageClassification"),Rvr=o(" (VAN model)"),Pvr=l(),u4=a("li"),m4e=a("strong"),Bvr=o("vit"),Ivr=o(" \u2014 "),kY=a("a"),Nvr=o("ViTForImageClassification"),qvr=o(" (ViT model)"),jvr=l(),p4=a("p"),Dvr=o("The model is set in evaluation mode by default using "),f4e=a("code"),Gvr=o("model.eval()"),Ovr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),g4e=a("code"),Vvr=o("model.train()"),Xvr=l(),F(_4.$$.fragment),RKe=l(),rc=a("h2"),b4=a("a"),h4e=a("span"),F(m$.$$.fragment),zvr=l(),u4e=a("span"),Qvr=o("AutoModelForVideoClassification"),PKe=l(),Wo=a("div"),F(f$.$$.fragment),Wvr=l(),tc=a("p"),Uvr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),SY=a("a"),Hvr=o("from_pretrained()"),Jvr=o(" class method or the "),RY=a("a"),Yvr=o("from_config()"),Kvr=o(` class
method.`),Zvr=l(),g$=a("p"),eFr=o("This class cannot be instantiated directly using "),p4e=a("code"),oFr=o("__init__()"),rFr=o(" (throws an error)."),tFr=l(),kt=a("div"),F(h$.$$.fragment),aFr=l(),_4e=a("p"),nFr=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),sFr=l(),ac=a("p"),lFr=o(`Note:
Loading a model from its configuration file does `),b4e=a("strong"),iFr=o("not"),dFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),PY=a("a"),cFr=o("from_pretrained()"),mFr=o(" to load the model weights."),fFr=l(),F(v4.$$.fragment),gFr=l(),go=a("div"),F(u$.$$.fragment),hFr=l(),v4e=a("p"),uFr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),pFr=l(),cn=a("p"),_Fr=o("The model class to instantiate is selected based on the "),F4e=a("code"),bFr=o("model_type"),vFr=o(` property of the config object (either
passed as an argument or loaded from `),T4e=a("code"),FFr=o("pretrained_model_name_or_path"),TFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M4e=a("code"),MFr=o("pretrained_model_name_or_path"),EFr=o(":"),CFr=l(),E4e=a("ul"),F4=a("li"),C4e=a("strong"),wFr=o("videomae"),AFr=o(" \u2014 "),BY=a("a"),LFr=o("VideoMAEForVideoClassification"),yFr=o(" (VideoMAE model)"),xFr=l(),T4=a("p"),$Fr=o("The model is set in evaluation mode by default using "),w4e=a("code"),kFr=o("model.eval()"),SFr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),A4e=a("code"),RFr=o("model.train()"),PFr=l(),F(M4.$$.fragment),BKe=l(),nc=a("h2"),E4=a("a"),L4e=a("span"),F(p$.$$.fragment),BFr=l(),y4e=a("span"),IFr=o("AutoModelForVision2Seq"),IKe=l(),Uo=a("div"),F(_$.$$.fragment),NFr=l(),sc=a("p"),qFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),IY=a("a"),jFr=o("from_pretrained()"),DFr=o(" class method or the "),NY=a("a"),GFr=o("from_config()"),OFr=o(` class
method.`),VFr=l(),b$=a("p"),XFr=o("This class cannot be instantiated directly using "),x4e=a("code"),zFr=o("__init__()"),QFr=o(" (throws an error)."),WFr=l(),St=a("div"),F(v$.$$.fragment),UFr=l(),$4e=a("p"),HFr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),JFr=l(),lc=a("p"),YFr=o(`Note:
Loading a model from its configuration file does `),k4e=a("strong"),KFr=o("not"),ZFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qY=a("a"),eTr=o("from_pretrained()"),oTr=o(" to load the model weights."),rTr=l(),F(C4.$$.fragment),tTr=l(),ho=a("div"),F(F$.$$.fragment),aTr=l(),S4e=a("p"),nTr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),sTr=l(),mn=a("p"),lTr=o("The model class to instantiate is selected based on the "),R4e=a("code"),iTr=o("model_type"),dTr=o(` property of the config object (either
passed as an argument or loaded from `),P4e=a("code"),cTr=o("pretrained_model_name_or_path"),mTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B4e=a("code"),fTr=o("pretrained_model_name_or_path"),gTr=o(":"),hTr=l(),I4e=a("ul"),w4=a("li"),N4e=a("strong"),uTr=o("vision-encoder-decoder"),pTr=o(" \u2014 "),jY=a("a"),_Tr=o("VisionEncoderDecoderModel"),bTr=o(" (Vision Encoder decoder model)"),vTr=l(),A4=a("p"),FTr=o("The model is set in evaluation mode by default using "),q4e=a("code"),TTr=o("model.eval()"),MTr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j4e=a("code"),ETr=o("model.train()"),CTr=l(),F(L4.$$.fragment),NKe=l(),ic=a("h2"),y4=a("a"),D4e=a("span"),F(T$.$$.fragment),wTr=l(),G4e=a("span"),ATr=o("AutoModelForVisualQuestionAnswering"),qKe=l(),Ho=a("div"),F(M$.$$.fragment),LTr=l(),dc=a("p"),yTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),DY=a("a"),xTr=o("from_pretrained()"),$Tr=o(" class method or the "),GY=a("a"),kTr=o("from_config()"),STr=o(` class
method.`),RTr=l(),E$=a("p"),PTr=o("This class cannot be instantiated directly using "),O4e=a("code"),BTr=o("__init__()"),ITr=o(" (throws an error)."),NTr=l(),Rt=a("div"),F(C$.$$.fragment),qTr=l(),V4e=a("p"),jTr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),DTr=l(),cc=a("p"),GTr=o(`Note:
Loading a model from its configuration file does `),X4e=a("strong"),OTr=o("not"),VTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OY=a("a"),XTr=o("from_pretrained()"),zTr=o(" to load the model weights."),QTr=l(),F(x4.$$.fragment),WTr=l(),uo=a("div"),F(w$.$$.fragment),UTr=l(),z4e=a("p"),HTr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),JTr=l(),fn=a("p"),YTr=o("The model class to instantiate is selected based on the "),Q4e=a("code"),KTr=o("model_type"),ZTr=o(` property of the config object (either
passed as an argument or loaded from `),W4e=a("code"),eMr=o("pretrained_model_name_or_path"),oMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U4e=a("code"),rMr=o("pretrained_model_name_or_path"),tMr=o(":"),aMr=l(),H4e=a("ul"),$4=a("li"),J4e=a("strong"),nMr=o("vilt"),sMr=o(" \u2014 "),VY=a("a"),lMr=o("ViltForQuestionAnswering"),iMr=o(" (ViLT model)"),dMr=l(),k4=a("p"),cMr=o("The model is set in evaluation mode by default using "),Y4e=a("code"),mMr=o("model.eval()"),fMr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),K4e=a("code"),gMr=o("model.train()"),hMr=l(),F(S4.$$.fragment),jKe=l(),mc=a("h2"),R4=a("a"),Z4e=a("span"),F(A$.$$.fragment),uMr=l(),eCe=a("span"),pMr=o("AutoModelForAudioClassification"),DKe=l(),Jo=a("div"),F(L$.$$.fragment),_Mr=l(),fc=a("p"),bMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),XY=a("a"),vMr=o("from_pretrained()"),FMr=o(" class method or the "),zY=a("a"),TMr=o("from_config()"),MMr=o(` class
method.`),EMr=l(),y$=a("p"),CMr=o("This class cannot be instantiated directly using "),oCe=a("code"),wMr=o("__init__()"),AMr=o(" (throws an error)."),LMr=l(),Pt=a("div"),F(x$.$$.fragment),yMr=l(),rCe=a("p"),xMr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),$Mr=l(),gc=a("p"),kMr=o(`Note:
Loading a model from its configuration file does `),tCe=a("strong"),SMr=o("not"),RMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QY=a("a"),PMr=o("from_pretrained()"),BMr=o(" to load the model weights."),IMr=l(),F(P4.$$.fragment),NMr=l(),po=a("div"),F($$.$$.fragment),qMr=l(),aCe=a("p"),jMr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),DMr=l(),gn=a("p"),GMr=o("The model class to instantiate is selected based on the "),nCe=a("code"),OMr=o("model_type"),VMr=o(` property of the config object (either
passed as an argument or loaded from `),sCe=a("code"),XMr=o("pretrained_model_name_or_path"),zMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lCe=a("code"),QMr=o("pretrained_model_name_or_path"),WMr=o(":"),UMr=l(),Pe=a("ul"),B4=a("li"),iCe=a("strong"),HMr=o("data2vec-audio"),JMr=o(" \u2014 "),WY=a("a"),YMr=o("Data2VecAudioForSequenceClassification"),KMr=o(" (Data2VecAudio model)"),ZMr=l(),I4=a("li"),dCe=a("strong"),eEr=o("hubert"),oEr=o(" \u2014 "),UY=a("a"),rEr=o("HubertForSequenceClassification"),tEr=o(" (Hubert model)"),aEr=l(),N4=a("li"),cCe=a("strong"),nEr=o("sew"),sEr=o(" \u2014 "),HY=a("a"),lEr=o("SEWForSequenceClassification"),iEr=o(" (SEW model)"),dEr=l(),q4=a("li"),mCe=a("strong"),cEr=o("sew-d"),mEr=o(" \u2014 "),JY=a("a"),fEr=o("SEWDForSequenceClassification"),gEr=o(" (SEW-D model)"),hEr=l(),j4=a("li"),fCe=a("strong"),uEr=o("unispeech"),pEr=o(" \u2014 "),YY=a("a"),_Er=o("UniSpeechForSequenceClassification"),bEr=o(" (UniSpeech model)"),vEr=l(),D4=a("li"),gCe=a("strong"),FEr=o("unispeech-sat"),TEr=o(" \u2014 "),KY=a("a"),MEr=o("UniSpeechSatForSequenceClassification"),EEr=o(" (UniSpeechSat model)"),CEr=l(),G4=a("li"),hCe=a("strong"),wEr=o("wav2vec2"),AEr=o(" \u2014 "),ZY=a("a"),LEr=o("Wav2Vec2ForSequenceClassification"),yEr=o(" (Wav2Vec2 model)"),xEr=l(),O4=a("li"),uCe=a("strong"),$Er=o("wav2vec2-conformer"),kEr=o(" \u2014 "),eK=a("a"),SEr=o("Wav2Vec2ConformerForSequenceClassification"),REr=o(" (Wav2Vec2-Conformer model)"),PEr=l(),V4=a("li"),pCe=a("strong"),BEr=o("wavlm"),IEr=o(" \u2014 "),oK=a("a"),NEr=o("WavLMForSequenceClassification"),qEr=o(" (WavLM model)"),jEr=l(),X4=a("p"),DEr=o("The model is set in evaluation mode by default using "),_Ce=a("code"),GEr=o("model.eval()"),OEr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bCe=a("code"),VEr=o("model.train()"),XEr=l(),F(z4.$$.fragment),GKe=l(),hc=a("h2"),Q4=a("a"),vCe=a("span"),F(k$.$$.fragment),zEr=l(),FCe=a("span"),QEr=o("AutoModelForAudioFrameClassification"),OKe=l(),Yo=a("div"),F(S$.$$.fragment),WEr=l(),uc=a("p"),UEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),rK=a("a"),HEr=o("from_pretrained()"),JEr=o(" class method or the "),tK=a("a"),YEr=o("from_config()"),KEr=o(` class
method.`),ZEr=l(),R$=a("p"),e4r=o("This class cannot be instantiated directly using "),TCe=a("code"),o4r=o("__init__()"),r4r=o(" (throws an error)."),t4r=l(),Bt=a("div"),F(P$.$$.fragment),a4r=l(),MCe=a("p"),n4r=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),s4r=l(),pc=a("p"),l4r=o(`Note:
Loading a model from its configuration file does `),ECe=a("strong"),i4r=o("not"),d4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aK=a("a"),c4r=o("from_pretrained()"),m4r=o(" to load the model weights."),f4r=l(),F(W4.$$.fragment),g4r=l(),_o=a("div"),F(B$.$$.fragment),h4r=l(),CCe=a("p"),u4r=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),p4r=l(),hn=a("p"),_4r=o("The model class to instantiate is selected based on the "),wCe=a("code"),b4r=o("model_type"),v4r=o(` property of the config object (either
passed as an argument or loaded from `),ACe=a("code"),F4r=o("pretrained_model_name_or_path"),T4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LCe=a("code"),M4r=o("pretrained_model_name_or_path"),E4r=o(":"),C4r=l(),mt=a("ul"),U4=a("li"),yCe=a("strong"),w4r=o("data2vec-audio"),A4r=o(" \u2014 "),nK=a("a"),L4r=o("Data2VecAudioForAudioFrameClassification"),y4r=o(" (Data2VecAudio model)"),x4r=l(),H4=a("li"),xCe=a("strong"),$4r=o("unispeech-sat"),k4r=o(" \u2014 "),sK=a("a"),S4r=o("UniSpeechSatForAudioFrameClassification"),R4r=o(" (UniSpeechSat model)"),P4r=l(),J4=a("li"),$Ce=a("strong"),B4r=o("wav2vec2"),I4r=o(" \u2014 "),lK=a("a"),N4r=o("Wav2Vec2ForAudioFrameClassification"),q4r=o(" (Wav2Vec2 model)"),j4r=l(),Y4=a("li"),kCe=a("strong"),D4r=o("wav2vec2-conformer"),G4r=o(" \u2014 "),iK=a("a"),O4r=o("Wav2Vec2ConformerForAudioFrameClassification"),V4r=o(" (Wav2Vec2-Conformer model)"),X4r=l(),K4=a("li"),SCe=a("strong"),z4r=o("wavlm"),Q4r=o(" \u2014 "),dK=a("a"),W4r=o("WavLMForAudioFrameClassification"),U4r=o(" (WavLM model)"),H4r=l(),Z4=a("p"),J4r=o("The model is set in evaluation mode by default using "),RCe=a("code"),Y4r=o("model.eval()"),K4r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),PCe=a("code"),Z4r=o("model.train()"),eCr=l(),F(eC.$$.fragment),VKe=l(),_c=a("h2"),oC=a("a"),BCe=a("span"),F(I$.$$.fragment),oCr=l(),ICe=a("span"),rCr=o("AutoModelForCTC"),XKe=l(),Ko=a("div"),F(N$.$$.fragment),tCr=l(),bc=a("p"),aCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),cK=a("a"),nCr=o("from_pretrained()"),sCr=o(" class method or the "),mK=a("a"),lCr=o("from_config()"),iCr=o(` class
method.`),dCr=l(),q$=a("p"),cCr=o("This class cannot be instantiated directly using "),NCe=a("code"),mCr=o("__init__()"),fCr=o(" (throws an error)."),gCr=l(),It=a("div"),F(j$.$$.fragment),hCr=l(),qCe=a("p"),uCr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),pCr=l(),vc=a("p"),_Cr=o(`Note:
Loading a model from its configuration file does `),jCe=a("strong"),bCr=o("not"),vCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fK=a("a"),FCr=o("from_pretrained()"),TCr=o(" to load the model weights."),MCr=l(),F(rC.$$.fragment),ECr=l(),bo=a("div"),F(D$.$$.fragment),CCr=l(),DCe=a("p"),wCr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),ACr=l(),un=a("p"),LCr=o("The model class to instantiate is selected based on the "),GCe=a("code"),yCr=o("model_type"),xCr=o(` property of the config object (either
passed as an argument or loaded from `),OCe=a("code"),$Cr=o("pretrained_model_name_or_path"),kCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VCe=a("code"),SCr=o("pretrained_model_name_or_path"),RCr=o(":"),PCr=l(),Le=a("ul"),tC=a("li"),XCe=a("strong"),BCr=o("data2vec-audio"),ICr=o(" \u2014 "),gK=a("a"),NCr=o("Data2VecAudioForCTC"),qCr=o(" (Data2VecAudio model)"),jCr=l(),aC=a("li"),zCe=a("strong"),DCr=o("hubert"),GCr=o(" \u2014 "),hK=a("a"),OCr=o("HubertForCTC"),VCr=o(" (Hubert model)"),XCr=l(),nC=a("li"),QCe=a("strong"),zCr=o("mctct"),QCr=o(" \u2014 "),uK=a("a"),WCr=o("MCTCTForCTC"),UCr=o(" (M-CTC-T model)"),HCr=l(),sC=a("li"),WCe=a("strong"),JCr=o("sew"),YCr=o(" \u2014 "),pK=a("a"),KCr=o("SEWForCTC"),ZCr=o(" (SEW model)"),e3r=l(),lC=a("li"),UCe=a("strong"),o3r=o("sew-d"),r3r=o(" \u2014 "),_K=a("a"),t3r=o("SEWDForCTC"),a3r=o(" (SEW-D model)"),n3r=l(),iC=a("li"),HCe=a("strong"),s3r=o("unispeech"),l3r=o(" \u2014 "),bK=a("a"),i3r=o("UniSpeechForCTC"),d3r=o(" (UniSpeech model)"),c3r=l(),dC=a("li"),JCe=a("strong"),m3r=o("unispeech-sat"),f3r=o(" \u2014 "),vK=a("a"),g3r=o("UniSpeechSatForCTC"),h3r=o(" (UniSpeechSat model)"),u3r=l(),cC=a("li"),YCe=a("strong"),p3r=o("wav2vec2"),_3r=o(" \u2014 "),FK=a("a"),b3r=o("Wav2Vec2ForCTC"),v3r=o(" (Wav2Vec2 model)"),F3r=l(),mC=a("li"),KCe=a("strong"),T3r=o("wav2vec2-conformer"),M3r=o(" \u2014 "),TK=a("a"),E3r=o("Wav2Vec2ConformerForCTC"),C3r=o(" (Wav2Vec2-Conformer model)"),w3r=l(),fC=a("li"),ZCe=a("strong"),A3r=o("wavlm"),L3r=o(" \u2014 "),MK=a("a"),y3r=o("WavLMForCTC"),x3r=o(" (WavLM model)"),$3r=l(),gC=a("p"),k3r=o("The model is set in evaluation mode by default using "),e3e=a("code"),S3r=o("model.eval()"),R3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o3e=a("code"),P3r=o("model.train()"),B3r=l(),F(hC.$$.fragment),zKe=l(),Fc=a("h2"),uC=a("a"),r3e=a("span"),F(G$.$$.fragment),I3r=l(),t3e=a("span"),N3r=o("AutoModelForSpeechSeq2Seq"),QKe=l(),Zo=a("div"),F(O$.$$.fragment),q3r=l(),Tc=a("p"),j3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),EK=a("a"),D3r=o("from_pretrained()"),G3r=o(" class method or the "),CK=a("a"),O3r=o("from_config()"),V3r=o(` class
method.`),X3r=l(),V$=a("p"),z3r=o("This class cannot be instantiated directly using "),a3e=a("code"),Q3r=o("__init__()"),W3r=o(" (throws an error)."),U3r=l(),Nt=a("div"),F(X$.$$.fragment),H3r=l(),n3e=a("p"),J3r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Y3r=l(),Mc=a("p"),K3r=o(`Note:
Loading a model from its configuration file does `),s3e=a("strong"),Z3r=o("not"),e5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wK=a("a"),o5r=o("from_pretrained()"),r5r=o(" to load the model weights."),t5r=l(),F(pC.$$.fragment),a5r=l(),vo=a("div"),F(z$.$$.fragment),n5r=l(),l3e=a("p"),s5r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),l5r=l(),pn=a("p"),i5r=o("The model class to instantiate is selected based on the "),i3e=a("code"),d5r=o("model_type"),c5r=o(` property of the config object (either
passed as an argument or loaded from `),d3e=a("code"),m5r=o("pretrained_model_name_or_path"),f5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c3e=a("code"),g5r=o("pretrained_model_name_or_path"),h5r=o(":"),u5r=l(),Q$=a("ul"),_C=a("li"),m3e=a("strong"),p5r=o("speech-encoder-decoder"),_5r=o(" \u2014 "),AK=a("a"),b5r=o("SpeechEncoderDecoderModel"),v5r=o(" (Speech Encoder decoder model)"),F5r=l(),bC=a("li"),f3e=a("strong"),T5r=o("speech_to_text"),M5r=o(" \u2014 "),LK=a("a"),E5r=o("Speech2TextForConditionalGeneration"),C5r=o(" (Speech2Text model)"),w5r=l(),vC=a("p"),A5r=o("The model is set in evaluation mode by default using "),g3e=a("code"),L5r=o("model.eval()"),y5r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h3e=a("code"),x5r=o("model.train()"),$5r=l(),F(FC.$$.fragment),WKe=l(),Ec=a("h2"),TC=a("a"),u3e=a("span"),F(W$.$$.fragment),k5r=l(),p3e=a("span"),S5r=o("AutoModelForAudioXVector"),UKe=l(),er=a("div"),F(U$.$$.fragment),R5r=l(),Cc=a("p"),P5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),yK=a("a"),B5r=o("from_pretrained()"),I5r=o(" class method or the "),xK=a("a"),N5r=o("from_config()"),q5r=o(` class
method.`),j5r=l(),H$=a("p"),D5r=o("This class cannot be instantiated directly using "),_3e=a("code"),G5r=o("__init__()"),O5r=o(" (throws an error)."),V5r=l(),qt=a("div"),F(J$.$$.fragment),X5r=l(),b3e=a("p"),z5r=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Q5r=l(),wc=a("p"),W5r=o(`Note:
Loading a model from its configuration file does `),v3e=a("strong"),U5r=o("not"),H5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$K=a("a"),J5r=o("from_pretrained()"),Y5r=o(" to load the model weights."),K5r=l(),F(MC.$$.fragment),Z5r=l(),Fo=a("div"),F(Y$.$$.fragment),e0r=l(),F3e=a("p"),o0r=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),r0r=l(),_n=a("p"),t0r=o("The model class to instantiate is selected based on the "),T3e=a("code"),a0r=o("model_type"),n0r=o(` property of the config object (either
passed as an argument or loaded from `),M3e=a("code"),s0r=o("pretrained_model_name_or_path"),l0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E3e=a("code"),i0r=o("pretrained_model_name_or_path"),d0r=o(":"),c0r=l(),ft=a("ul"),EC=a("li"),C3e=a("strong"),m0r=o("data2vec-audio"),f0r=o(" \u2014 "),kK=a("a"),g0r=o("Data2VecAudioForXVector"),h0r=o(" (Data2VecAudio model)"),u0r=l(),CC=a("li"),w3e=a("strong"),p0r=o("unispeech-sat"),_0r=o(" \u2014 "),SK=a("a"),b0r=o("UniSpeechSatForXVector"),v0r=o(" (UniSpeechSat model)"),F0r=l(),wC=a("li"),A3e=a("strong"),T0r=o("wav2vec2"),M0r=o(" \u2014 "),RK=a("a"),E0r=o("Wav2Vec2ForXVector"),C0r=o(" (Wav2Vec2 model)"),w0r=l(),AC=a("li"),L3e=a("strong"),A0r=o("wav2vec2-conformer"),L0r=o(" \u2014 "),PK=a("a"),y0r=o("Wav2Vec2ConformerForXVector"),x0r=o(" (Wav2Vec2-Conformer model)"),$0r=l(),LC=a("li"),y3e=a("strong"),k0r=o("wavlm"),S0r=o(" \u2014 "),BK=a("a"),R0r=o("WavLMForXVector"),P0r=o(" (WavLM model)"),B0r=l(),yC=a("p"),I0r=o("The model is set in evaluation mode by default using "),x3e=a("code"),N0r=o("model.eval()"),q0r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$3e=a("code"),j0r=o("model.train()"),D0r=l(),F(xC.$$.fragment),HKe=l(),Ac=a("h2"),$C=a("a"),k3e=a("span"),F(K$.$$.fragment),G0r=l(),S3e=a("span"),O0r=o("AutoModelForMaskedImageModeling"),JKe=l(),or=a("div"),F(Z$.$$.fragment),V0r=l(),Lc=a("p"),X0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),IK=a("a"),z0r=o("from_pretrained()"),Q0r=o(" class method or the "),NK=a("a"),W0r=o("from_config()"),U0r=o(` class
method.`),H0r=l(),ek=a("p"),J0r=o("This class cannot be instantiated directly using "),R3e=a("code"),Y0r=o("__init__()"),K0r=o(" (throws an error)."),Z0r=l(),jt=a("div"),F(ok.$$.fragment),ewr=l(),P3e=a("p"),owr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),rwr=l(),yc=a("p"),twr=o(`Note:
Loading a model from its configuration file does `),B3e=a("strong"),awr=o("not"),nwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qK=a("a"),swr=o("from_pretrained()"),lwr=o(" to load the model weights."),iwr=l(),F(kC.$$.fragment),dwr=l(),To=a("div"),F(rk.$$.fragment),cwr=l(),I3e=a("p"),mwr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),fwr=l(),bn=a("p"),gwr=o("The model class to instantiate is selected based on the "),N3e=a("code"),hwr=o("model_type"),uwr=o(` property of the config object (either
passed as an argument or loaded from `),q3e=a("code"),pwr=o("pretrained_model_name_or_path"),_wr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j3e=a("code"),bwr=o("pretrained_model_name_or_path"),vwr=o(":"),Fwr=l(),vn=a("ul"),SC=a("li"),D3e=a("strong"),Twr=o("deit"),Mwr=o(" \u2014 "),jK=a("a"),Ewr=o("DeiTForMaskedImageModeling"),Cwr=o(" (DeiT model)"),wwr=l(),RC=a("li"),G3e=a("strong"),Awr=o("swin"),Lwr=o(" \u2014 "),DK=a("a"),ywr=o("SwinForMaskedImageModeling"),xwr=o(" (Swin Transformer model)"),$wr=l(),PC=a("li"),O3e=a("strong"),kwr=o("swinv2"),Swr=o(" \u2014 "),GK=a("a"),Rwr=o("Swinv2ForMaskedImageModeling"),Pwr=o(" (Swin Transformer V2 model)"),Bwr=l(),BC=a("li"),V3e=a("strong"),Iwr=o("vit"),Nwr=o(" \u2014 "),OK=a("a"),qwr=o("ViTForMaskedImageModeling"),jwr=o(" (ViT model)"),Dwr=l(),IC=a("p"),Gwr=o("The model is set in evaluation mode by default using "),X3e=a("code"),Owr=o("model.eval()"),Vwr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z3e=a("code"),Xwr=o("model.train()"),zwr=l(),F(NC.$$.fragment),YKe=l(),xc=a("h2"),qC=a("a"),Q3e=a("span"),F(tk.$$.fragment),Qwr=l(),W3e=a("span"),Wwr=o("AutoModelForObjectDetection"),KKe=l(),rr=a("div"),F(ak.$$.fragment),Uwr=l(),$c=a("p"),Hwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),VK=a("a"),Jwr=o("from_pretrained()"),Ywr=o(" class method or the "),XK=a("a"),Kwr=o("from_config()"),Zwr=o(` class
method.`),eAr=l(),nk=a("p"),oAr=o("This class cannot be instantiated directly using "),U3e=a("code"),rAr=o("__init__()"),tAr=o(" (throws an error)."),aAr=l(),Dt=a("div"),F(sk.$$.fragment),nAr=l(),H3e=a("p"),sAr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),lAr=l(),kc=a("p"),iAr=o(`Note:
Loading a model from its configuration file does `),J3e=a("strong"),dAr=o("not"),cAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zK=a("a"),mAr=o("from_pretrained()"),fAr=o(" to load the model weights."),gAr=l(),F(jC.$$.fragment),hAr=l(),Mo=a("div"),F(lk.$$.fragment),uAr=l(),Y3e=a("p"),pAr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),_Ar=l(),Fn=a("p"),bAr=o("The model class to instantiate is selected based on the "),K3e=a("code"),vAr=o("model_type"),FAr=o(` property of the config object (either
passed as an argument or loaded from `),Z3e=a("code"),TAr=o("pretrained_model_name_or_path"),MAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e5e=a("code"),EAr=o("pretrained_model_name_or_path"),CAr=o(":"),wAr=l(),Sc=a("ul"),DC=a("li"),o5e=a("strong"),AAr=o("deformable_detr"),LAr=o(" \u2014 "),QK=a("a"),yAr=o("DeformableDetrForObjectDetection"),xAr=o(" (Deformable DETR model)"),$Ar=l(),GC=a("li"),r5e=a("strong"),kAr=o("detr"),SAr=o(" \u2014 "),WK=a("a"),RAr=o("DetrForObjectDetection"),PAr=o(" (DETR model)"),BAr=l(),OC=a("li"),t5e=a("strong"),IAr=o("yolos"),NAr=o(" \u2014 "),UK=a("a"),qAr=o("YolosForObjectDetection"),jAr=o(" (YOLOS model)"),DAr=l(),VC=a("p"),GAr=o("The model is set in evaluation mode by default using "),a5e=a("code"),OAr=o("model.eval()"),VAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n5e=a("code"),XAr=o("model.train()"),zAr=l(),F(XC.$$.fragment),ZKe=l(),Rc=a("h2"),zC=a("a"),s5e=a("span"),F(ik.$$.fragment),QAr=l(),l5e=a("span"),WAr=o("AutoModelForImageSegmentation"),eZe=l(),tr=a("div"),F(dk.$$.fragment),UAr=l(),Pc=a("p"),HAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),HK=a("a"),JAr=o("from_pretrained()"),YAr=o(" class method or the "),JK=a("a"),KAr=o("from_config()"),ZAr=o(` class
method.`),e6r=l(),ck=a("p"),o6r=o("This class cannot be instantiated directly using "),i5e=a("code"),r6r=o("__init__()"),t6r=o(" (throws an error)."),a6r=l(),Gt=a("div"),F(mk.$$.fragment),n6r=l(),d5e=a("p"),s6r=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),l6r=l(),Bc=a("p"),i6r=o(`Note:
Loading a model from its configuration file does `),c5e=a("strong"),d6r=o("not"),c6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YK=a("a"),m6r=o("from_pretrained()"),f6r=o(" to load the model weights."),g6r=l(),F(QC.$$.fragment),h6r=l(),Eo=a("div"),F(fk.$$.fragment),u6r=l(),m5e=a("p"),p6r=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),_6r=l(),Tn=a("p"),b6r=o("The model class to instantiate is selected based on the "),f5e=a("code"),v6r=o("model_type"),F6r=o(` property of the config object (either
passed as an argument or loaded from `),g5e=a("code"),T6r=o("pretrained_model_name_or_path"),M6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h5e=a("code"),E6r=o("pretrained_model_name_or_path"),C6r=o(":"),w6r=l(),u5e=a("ul"),WC=a("li"),p5e=a("strong"),A6r=o("detr"),L6r=o(" \u2014 "),KK=a("a"),y6r=o("DetrForSegmentation"),x6r=o(" (DETR model)"),$6r=l(),UC=a("p"),k6r=o("The model is set in evaluation mode by default using "),_5e=a("code"),S6r=o("model.eval()"),R6r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b5e=a("code"),P6r=o("model.train()"),B6r=l(),F(HC.$$.fragment),oZe=l(),Ic=a("h2"),JC=a("a"),v5e=a("span"),F(gk.$$.fragment),I6r=l(),F5e=a("span"),N6r=o("AutoModelForSemanticSegmentation"),rZe=l(),ar=a("div"),F(hk.$$.fragment),q6r=l(),Nc=a("p"),j6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),ZK=a("a"),D6r=o("from_pretrained()"),G6r=o(" class method or the "),eZ=a("a"),O6r=o("from_config()"),V6r=o(` class
method.`),X6r=l(),uk=a("p"),z6r=o("This class cannot be instantiated directly using "),T5e=a("code"),Q6r=o("__init__()"),W6r=o(" (throws an error)."),U6r=l(),Ot=a("div"),F(pk.$$.fragment),H6r=l(),M5e=a("p"),J6r=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Y6r=l(),qc=a("p"),K6r=o(`Note:
Loading a model from its configuration file does `),E5e=a("strong"),Z6r=o("not"),e7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oZ=a("a"),o7r=o("from_pretrained()"),r7r=o(" to load the model weights."),t7r=l(),F(YC.$$.fragment),a7r=l(),Co=a("div"),F(_k.$$.fragment),n7r=l(),C5e=a("p"),s7r=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),l7r=l(),Mn=a("p"),i7r=o("The model class to instantiate is selected based on the "),w5e=a("code"),d7r=o("model_type"),c7r=o(` property of the config object (either
passed as an argument or loaded from `),A5e=a("code"),m7r=o("pretrained_model_name_or_path"),f7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L5e=a("code"),g7r=o("pretrained_model_name_or_path"),h7r=o(":"),u7r=l(),gt=a("ul"),KC=a("li"),y5e=a("strong"),p7r=o("beit"),_7r=o(" \u2014 "),rZ=a("a"),b7r=o("BeitForSemanticSegmentation"),v7r=o(" (BEiT model)"),F7r=l(),ZC=a("li"),x5e=a("strong"),T7r=o("data2vec-vision"),M7r=o(" \u2014 "),tZ=a("a"),E7r=o("Data2VecVisionForSemanticSegmentation"),C7r=o(" (Data2VecVision model)"),w7r=l(),e3=a("li"),$5e=a("strong"),A7r=o("dpt"),L7r=o(" \u2014 "),aZ=a("a"),y7r=o("DPTForSemanticSegmentation"),x7r=o(" (DPT model)"),$7r=l(),o3=a("li"),k5e=a("strong"),k7r=o("mobilevit"),S7r=o(" \u2014 "),nZ=a("a"),R7r=o("MobileViTForSemanticSegmentation"),P7r=o(" (MobileViT model)"),B7r=l(),r3=a("li"),S5e=a("strong"),I7r=o("segformer"),N7r=o(" \u2014 "),sZ=a("a"),q7r=o("SegformerForSemanticSegmentation"),j7r=o(" (SegFormer model)"),D7r=l(),t3=a("p"),G7r=o("The model is set in evaluation mode by default using "),R5e=a("code"),O7r=o("model.eval()"),V7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P5e=a("code"),X7r=o("model.train()"),z7r=l(),F(a3.$$.fragment),tZe=l(),jc=a("h2"),n3=a("a"),B5e=a("span"),F(bk.$$.fragment),Q7r=l(),I5e=a("span"),W7r=o("AutoModelForInstanceSegmentation"),aZe=l(),nr=a("div"),F(vk.$$.fragment),U7r=l(),Dc=a("p"),H7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),lZ=a("a"),J7r=o("from_pretrained()"),Y7r=o(" class method or the "),iZ=a("a"),K7r=o("from_config()"),Z7r=o(` class
method.`),eLr=l(),Fk=a("p"),oLr=o("This class cannot be instantiated directly using "),N5e=a("code"),rLr=o("__init__()"),tLr=o(" (throws an error)."),aLr=l(),Vt=a("div"),F(Tk.$$.fragment),nLr=l(),q5e=a("p"),sLr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),lLr=l(),Gc=a("p"),iLr=o(`Note:
Loading a model from its configuration file does `),j5e=a("strong"),dLr=o("not"),cLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dZ=a("a"),mLr=o("from_pretrained()"),fLr=o(" to load the model weights."),gLr=l(),F(s3.$$.fragment),hLr=l(),wo=a("div"),F(Mk.$$.fragment),uLr=l(),D5e=a("p"),pLr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),_Lr=l(),En=a("p"),bLr=o("The model class to instantiate is selected based on the "),G5e=a("code"),vLr=o("model_type"),FLr=o(` property of the config object (either
passed as an argument or loaded from `),O5e=a("code"),TLr=o("pretrained_model_name_or_path"),MLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V5e=a("code"),ELr=o("pretrained_model_name_or_path"),CLr=o(":"),wLr=l(),X5e=a("ul"),l3=a("li"),z5e=a("strong"),ALr=o("maskformer"),LLr=o(" \u2014 "),cZ=a("a"),yLr=o("MaskFormerForInstanceSegmentation"),xLr=o(" (MaskFormer model)"),$Lr=l(),i3=a("p"),kLr=o("The model is set in evaluation mode by default using "),Q5e=a("code"),SLr=o("model.eval()"),RLr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W5e=a("code"),PLr=o("model.train()"),BLr=l(),F(d3.$$.fragment),nZe=l(),Oc=a("h2"),c3=a("a"),U5e=a("span"),F(Ek.$$.fragment),ILr=l(),H5e=a("span"),NLr=o("TFAutoModel"),sZe=l(),sr=a("div"),F(Ck.$$.fragment),qLr=l(),Vc=a("p"),jLr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),mZ=a("a"),DLr=o("from_pretrained()"),GLr=o(" class method or the "),fZ=a("a"),OLr=o("from_config()"),VLr=o(` class
method.`),XLr=l(),wk=a("p"),zLr=o("This class cannot be instantiated directly using "),J5e=a("code"),QLr=o("__init__()"),WLr=o(" (throws an error)."),ULr=l(),Xt=a("div"),F(Ak.$$.fragment),HLr=l(),Y5e=a("p"),JLr=o("Instantiates one of the base model classes of the library from a configuration."),YLr=l(),Xc=a("p"),KLr=o(`Note:
Loading a model from its configuration file does `),K5e=a("strong"),ZLr=o("not"),eyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gZ=a("a"),oyr=o("from_pretrained()"),ryr=o(" to load the model weights."),tyr=l(),F(m3.$$.fragment),ayr=l(),Ir=a("div"),F(Lk.$$.fragment),nyr=l(),Z5e=a("p"),syr=o("Instantiate one of the base model classes of the library from a pretrained model."),lyr=l(),Cn=a("p"),iyr=o("The model class to instantiate is selected based on the "),e0e=a("code"),dyr=o("model_type"),cyr=o(` property of the config object (either
passed as an argument or loaded from `),o0e=a("code"),myr=o("pretrained_model_name_or_path"),fyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r0e=a("code"),gyr=o("pretrained_model_name_or_path"),hyr=o(":"),uyr=l(),N=a("ul"),f3=a("li"),t0e=a("strong"),pyr=o("albert"),_yr=o(" \u2014 "),hZ=a("a"),byr=o("TFAlbertModel"),vyr=o(" (ALBERT model)"),Fyr=l(),g3=a("li"),a0e=a("strong"),Tyr=o("bart"),Myr=o(" \u2014 "),uZ=a("a"),Eyr=o("TFBartModel"),Cyr=o(" (BART model)"),wyr=l(),h3=a("li"),n0e=a("strong"),Ayr=o("bert"),Lyr=o(" \u2014 "),pZ=a("a"),yyr=o("TFBertModel"),xyr=o(" (BERT model)"),$yr=l(),u3=a("li"),s0e=a("strong"),kyr=o("blenderbot"),Syr=o(" \u2014 "),_Z=a("a"),Ryr=o("TFBlenderbotModel"),Pyr=o(" (Blenderbot model)"),Byr=l(),p3=a("li"),l0e=a("strong"),Iyr=o("blenderbot-small"),Nyr=o(" \u2014 "),bZ=a("a"),qyr=o("TFBlenderbotSmallModel"),jyr=o(" (BlenderbotSmall model)"),Dyr=l(),_3=a("li"),i0e=a("strong"),Gyr=o("camembert"),Oyr=o(" \u2014 "),vZ=a("a"),Vyr=o("TFCamembertModel"),Xyr=o(" (CamemBERT model)"),zyr=l(),b3=a("li"),d0e=a("strong"),Qyr=o("clip"),Wyr=o(" \u2014 "),FZ=a("a"),Uyr=o("TFCLIPModel"),Hyr=o(" (CLIP model)"),Jyr=l(),v3=a("li"),c0e=a("strong"),Yyr=o("convbert"),Kyr=o(" \u2014 "),TZ=a("a"),Zyr=o("TFConvBertModel"),e8r=o(" (ConvBERT model)"),o8r=l(),F3=a("li"),m0e=a("strong"),r8r=o("convnext"),t8r=o(" \u2014 "),MZ=a("a"),a8r=o("TFConvNextModel"),n8r=o(" (ConvNeXT model)"),s8r=l(),T3=a("li"),f0e=a("strong"),l8r=o("ctrl"),i8r=o(" \u2014 "),EZ=a("a"),d8r=o("TFCTRLModel"),c8r=o(" (CTRL model)"),m8r=l(),M3=a("li"),g0e=a("strong"),f8r=o("data2vec-vision"),g8r=o(" \u2014 "),CZ=a("a"),h8r=o("TFData2VecVisionModel"),u8r=o(" (Data2VecVision model)"),p8r=l(),E3=a("li"),h0e=a("strong"),_8r=o("deberta"),b8r=o(" \u2014 "),wZ=a("a"),v8r=o("TFDebertaModel"),F8r=o(" (DeBERTa model)"),T8r=l(),C3=a("li"),u0e=a("strong"),M8r=o("deberta-v2"),E8r=o(" \u2014 "),AZ=a("a"),C8r=o("TFDebertaV2Model"),w8r=o(" (DeBERTa-v2 model)"),A8r=l(),w3=a("li"),p0e=a("strong"),L8r=o("deit"),y8r=o(" \u2014 "),LZ=a("a"),x8r=o("TFDeiTModel"),$8r=o(" (DeiT model)"),k8r=l(),A3=a("li"),_0e=a("strong"),S8r=o("distilbert"),R8r=o(" \u2014 "),yZ=a("a"),P8r=o("TFDistilBertModel"),B8r=o(" (DistilBERT model)"),I8r=l(),L3=a("li"),b0e=a("strong"),N8r=o("dpr"),q8r=o(" \u2014 "),xZ=a("a"),j8r=o("TFDPRQuestionEncoder"),D8r=o(" (DPR model)"),G8r=l(),y3=a("li"),v0e=a("strong"),O8r=o("electra"),V8r=o(" \u2014 "),$Z=a("a"),X8r=o("TFElectraModel"),z8r=o(" (ELECTRA model)"),Q8r=l(),x3=a("li"),F0e=a("strong"),W8r=o("flaubert"),U8r=o(" \u2014 "),kZ=a("a"),H8r=o("TFFlaubertModel"),J8r=o(" (FlauBERT model)"),Y8r=l(),vl=a("li"),T0e=a("strong"),K8r=o("funnel"),Z8r=o(" \u2014 "),SZ=a("a"),e9r=o("TFFunnelModel"),o9r=o(" or "),RZ=a("a"),r9r=o("TFFunnelBaseModel"),t9r=o(" (Funnel Transformer model)"),a9r=l(),$3=a("li"),M0e=a("strong"),n9r=o("gpt2"),s9r=o(" \u2014 "),PZ=a("a"),l9r=o("TFGPT2Model"),i9r=o(" (OpenAI GPT-2 model)"),d9r=l(),k3=a("li"),E0e=a("strong"),c9r=o("gptj"),m9r=o(" \u2014 "),BZ=a("a"),f9r=o("TFGPTJModel"),g9r=o(" (GPT-J model)"),h9r=l(),S3=a("li"),C0e=a("strong"),u9r=o("hubert"),p9r=o(" \u2014 "),IZ=a("a"),_9r=o("TFHubertModel"),b9r=o(" (Hubert model)"),v9r=l(),R3=a("li"),w0e=a("strong"),F9r=o("layoutlm"),T9r=o(" \u2014 "),NZ=a("a"),M9r=o("TFLayoutLMModel"),E9r=o(" (LayoutLM model)"),C9r=l(),P3=a("li"),A0e=a("strong"),w9r=o("layoutlmv3"),A9r=o(" \u2014 "),qZ=a("a"),L9r=o("TFLayoutLMv3Model"),y9r=o(" (LayoutLMv3 model)"),x9r=l(),B3=a("li"),L0e=a("strong"),$9r=o("led"),k9r=o(" \u2014 "),jZ=a("a"),S9r=o("TFLEDModel"),R9r=o(" (LED model)"),P9r=l(),I3=a("li"),y0e=a("strong"),B9r=o("longformer"),I9r=o(" \u2014 "),DZ=a("a"),N9r=o("TFLongformerModel"),q9r=o(" (Longformer model)"),j9r=l(),N3=a("li"),x0e=a("strong"),D9r=o("lxmert"),G9r=o(" \u2014 "),GZ=a("a"),O9r=o("TFLxmertModel"),V9r=o(" (LXMERT model)"),X9r=l(),q3=a("li"),$0e=a("strong"),z9r=o("marian"),Q9r=o(" \u2014 "),OZ=a("a"),W9r=o("TFMarianModel"),U9r=o(" (Marian model)"),H9r=l(),j3=a("li"),k0e=a("strong"),J9r=o("mbart"),Y9r=o(" \u2014 "),VZ=a("a"),K9r=o("TFMBartModel"),Z9r=o(" (mBART model)"),exr=l(),D3=a("li"),S0e=a("strong"),oxr=o("mobilebert"),rxr=o(" \u2014 "),XZ=a("a"),txr=o("TFMobileBertModel"),axr=o(" (MobileBERT model)"),nxr=l(),G3=a("li"),R0e=a("strong"),sxr=o("mobilevit"),lxr=o(" \u2014 "),zZ=a("a"),ixr=o("TFMobileViTModel"),dxr=o(" (MobileViT model)"),cxr=l(),O3=a("li"),P0e=a("strong"),mxr=o("mpnet"),fxr=o(" \u2014 "),QZ=a("a"),gxr=o("TFMPNetModel"),hxr=o(" (MPNet model)"),uxr=l(),V3=a("li"),B0e=a("strong"),pxr=o("mt5"),_xr=o(" \u2014 "),WZ=a("a"),bxr=o("TFMT5Model"),vxr=o(" (MT5 model)"),Fxr=l(),X3=a("li"),I0e=a("strong"),Txr=o("openai-gpt"),Mxr=o(" \u2014 "),UZ=a("a"),Exr=o("TFOpenAIGPTModel"),Cxr=o(" (OpenAI GPT model)"),wxr=l(),z3=a("li"),N0e=a("strong"),Axr=o("opt"),Lxr=o(" \u2014 "),HZ=a("a"),yxr=o("TFOPTModel"),xxr=o(" (OPT model)"),$xr=l(),Q3=a("li"),q0e=a("strong"),kxr=o("pegasus"),Sxr=o(" \u2014 "),JZ=a("a"),Rxr=o("TFPegasusModel"),Pxr=o(" (Pegasus model)"),Bxr=l(),W3=a("li"),j0e=a("strong"),Ixr=o("regnet"),Nxr=o(" \u2014 "),YZ=a("a"),qxr=o("TFRegNetModel"),jxr=o(" (RegNet model)"),Dxr=l(),U3=a("li"),D0e=a("strong"),Gxr=o("rembert"),Oxr=o(" \u2014 "),KZ=a("a"),Vxr=o("TFRemBertModel"),Xxr=o(" (RemBERT model)"),zxr=l(),H3=a("li"),G0e=a("strong"),Qxr=o("resnet"),Wxr=o(" \u2014 "),ZZ=a("a"),Uxr=o("TFResNetModel"),Hxr=o(" (ResNet model)"),Jxr=l(),J3=a("li"),O0e=a("strong"),Yxr=o("roberta"),Kxr=o(" \u2014 "),eee=a("a"),Zxr=o("TFRobertaModel"),e$r=o(" (RoBERTa model)"),o$r=l(),Y3=a("li"),V0e=a("strong"),r$r=o("roformer"),t$r=o(" \u2014 "),oee=a("a"),a$r=o("TFRoFormerModel"),n$r=o(" (RoFormer model)"),s$r=l(),K3=a("li"),X0e=a("strong"),l$r=o("segformer"),i$r=o(" \u2014 "),ree=a("a"),d$r=o("TFSegformerModel"),c$r=o(" (SegFormer model)"),m$r=l(),Z3=a("li"),z0e=a("strong"),f$r=o("speech_to_text"),g$r=o(" \u2014 "),tee=a("a"),h$r=o("TFSpeech2TextModel"),u$r=o(" (Speech2Text model)"),p$r=l(),e5=a("li"),Q0e=a("strong"),_$r=o("swin"),b$r=o(" \u2014 "),aee=a("a"),v$r=o("TFSwinModel"),F$r=o(" (Swin Transformer model)"),T$r=l(),o5=a("li"),W0e=a("strong"),M$r=o("t5"),E$r=o(" \u2014 "),nee=a("a"),C$r=o("TFT5Model"),w$r=o(" (T5 model)"),A$r=l(),r5=a("li"),U0e=a("strong"),L$r=o("tapas"),y$r=o(" \u2014 "),see=a("a"),x$r=o("TFTapasModel"),$$r=o(" (TAPAS model)"),k$r=l(),t5=a("li"),H0e=a("strong"),S$r=o("transfo-xl"),R$r=o(" \u2014 "),lee=a("a"),P$r=o("TFTransfoXLModel"),B$r=o(" (Transformer-XL model)"),I$r=l(),a5=a("li"),J0e=a("strong"),N$r=o("vit"),q$r=o(" \u2014 "),iee=a("a"),j$r=o("TFViTModel"),D$r=o(" (ViT model)"),G$r=l(),n5=a("li"),Y0e=a("strong"),O$r=o("vit_mae"),V$r=o(" \u2014 "),dee=a("a"),X$r=o("TFViTMAEModel"),z$r=o(" (ViTMAE model)"),Q$r=l(),s5=a("li"),K0e=a("strong"),W$r=o("wav2vec2"),U$r=o(" \u2014 "),cee=a("a"),H$r=o("TFWav2Vec2Model"),J$r=o(" (Wav2Vec2 model)"),Y$r=l(),l5=a("li"),Z0e=a("strong"),K$r=o("xglm"),Z$r=o(" \u2014 "),mee=a("a"),ekr=o("TFXGLMModel"),okr=o(" (XGLM model)"),rkr=l(),i5=a("li"),ewe=a("strong"),tkr=o("xlm"),akr=o(" \u2014 "),fee=a("a"),nkr=o("TFXLMModel"),skr=o(" (XLM model)"),lkr=l(),d5=a("li"),owe=a("strong"),ikr=o("xlm-roberta"),dkr=o(" \u2014 "),gee=a("a"),ckr=o("TFXLMRobertaModel"),mkr=o(" (XLM-RoBERTa model)"),fkr=l(),c5=a("li"),rwe=a("strong"),gkr=o("xlnet"),hkr=o(" \u2014 "),hee=a("a"),ukr=o("TFXLNetModel"),pkr=o(" (XLNet model)"),_kr=l(),F(m5.$$.fragment),lZe=l(),zc=a("h2"),f5=a("a"),twe=a("span"),F(yk.$$.fragment),bkr=l(),awe=a("span"),vkr=o("TFAutoModelForPreTraining"),iZe=l(),lr=a("div"),F(xk.$$.fragment),Fkr=l(),Qc=a("p"),Tkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),uee=a("a"),Mkr=o("from_pretrained()"),Ekr=o(" class method or the "),pee=a("a"),Ckr=o("from_config()"),wkr=o(` class
method.`),Akr=l(),$k=a("p"),Lkr=o("This class cannot be instantiated directly using "),nwe=a("code"),ykr=o("__init__()"),xkr=o(" (throws an error)."),$kr=l(),zt=a("div"),F(kk.$$.fragment),kkr=l(),swe=a("p"),Skr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Rkr=l(),Wc=a("p"),Pkr=o(`Note:
Loading a model from its configuration file does `),lwe=a("strong"),Bkr=o("not"),Ikr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_ee=a("a"),Nkr=o("from_pretrained()"),qkr=o(" to load the model weights."),jkr=l(),F(g5.$$.fragment),Dkr=l(),Nr=a("div"),F(Sk.$$.fragment),Gkr=l(),iwe=a("p"),Okr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Vkr=l(),wn=a("p"),Xkr=o("The model class to instantiate is selected based on the "),dwe=a("code"),zkr=o("model_type"),Qkr=o(` property of the config object (either
passed as an argument or loaded from `),cwe=a("code"),Wkr=o("pretrained_model_name_or_path"),Ukr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mwe=a("code"),Hkr=o("pretrained_model_name_or_path"),Jkr=o(":"),Ykr=l(),se=a("ul"),h5=a("li"),fwe=a("strong"),Kkr=o("albert"),Zkr=o(" \u2014 "),bee=a("a"),eSr=o("TFAlbertForPreTraining"),oSr=o(" (ALBERT model)"),rSr=l(),u5=a("li"),gwe=a("strong"),tSr=o("bart"),aSr=o(" \u2014 "),vee=a("a"),nSr=o("TFBartForConditionalGeneration"),sSr=o(" (BART model)"),lSr=l(),p5=a("li"),hwe=a("strong"),iSr=o("bert"),dSr=o(" \u2014 "),Fee=a("a"),cSr=o("TFBertForPreTraining"),mSr=o(" (BERT model)"),fSr=l(),_5=a("li"),uwe=a("strong"),gSr=o("camembert"),hSr=o(" \u2014 "),Tee=a("a"),uSr=o("TFCamembertForMaskedLM"),pSr=o(" (CamemBERT model)"),_Sr=l(),b5=a("li"),pwe=a("strong"),bSr=o("ctrl"),vSr=o(" \u2014 "),Mee=a("a"),FSr=o("TFCTRLLMHeadModel"),TSr=o(" (CTRL model)"),MSr=l(),v5=a("li"),_we=a("strong"),ESr=o("distilbert"),CSr=o(" \u2014 "),Eee=a("a"),wSr=o("TFDistilBertForMaskedLM"),ASr=o(" (DistilBERT model)"),LSr=l(),F5=a("li"),bwe=a("strong"),ySr=o("electra"),xSr=o(" \u2014 "),Cee=a("a"),$Sr=o("TFElectraForPreTraining"),kSr=o(" (ELECTRA model)"),SSr=l(),T5=a("li"),vwe=a("strong"),RSr=o("flaubert"),PSr=o(" \u2014 "),wee=a("a"),BSr=o("TFFlaubertWithLMHeadModel"),ISr=o(" (FlauBERT model)"),NSr=l(),M5=a("li"),Fwe=a("strong"),qSr=o("funnel"),jSr=o(" \u2014 "),Aee=a("a"),DSr=o("TFFunnelForPreTraining"),GSr=o(" (Funnel Transformer model)"),OSr=l(),E5=a("li"),Twe=a("strong"),VSr=o("gpt2"),XSr=o(" \u2014 "),Lee=a("a"),zSr=o("TFGPT2LMHeadModel"),QSr=o(" (OpenAI GPT-2 model)"),WSr=l(),C5=a("li"),Mwe=a("strong"),USr=o("layoutlm"),HSr=o(" \u2014 "),yee=a("a"),JSr=o("TFLayoutLMForMaskedLM"),YSr=o(" (LayoutLM model)"),KSr=l(),w5=a("li"),Ewe=a("strong"),ZSr=o("lxmert"),eRr=o(" \u2014 "),xee=a("a"),oRr=o("TFLxmertForPreTraining"),rRr=o(" (LXMERT model)"),tRr=l(),A5=a("li"),Cwe=a("strong"),aRr=o("mobilebert"),nRr=o(" \u2014 "),$ee=a("a"),sRr=o("TFMobileBertForPreTraining"),lRr=o(" (MobileBERT model)"),iRr=l(),L5=a("li"),wwe=a("strong"),dRr=o("mpnet"),cRr=o(" \u2014 "),kee=a("a"),mRr=o("TFMPNetForMaskedLM"),fRr=o(" (MPNet model)"),gRr=l(),y5=a("li"),Awe=a("strong"),hRr=o("openai-gpt"),uRr=o(" \u2014 "),See=a("a"),pRr=o("TFOpenAIGPTLMHeadModel"),_Rr=o(" (OpenAI GPT model)"),bRr=l(),x5=a("li"),Lwe=a("strong"),vRr=o("roberta"),FRr=o(" \u2014 "),Ree=a("a"),TRr=o("TFRobertaForMaskedLM"),MRr=o(" (RoBERTa model)"),ERr=l(),$5=a("li"),ywe=a("strong"),CRr=o("t5"),wRr=o(" \u2014 "),Pee=a("a"),ARr=o("TFT5ForConditionalGeneration"),LRr=o(" (T5 model)"),yRr=l(),k5=a("li"),xwe=a("strong"),xRr=o("tapas"),$Rr=o(" \u2014 "),Bee=a("a"),kRr=o("TFTapasForMaskedLM"),SRr=o(" (TAPAS model)"),RRr=l(),S5=a("li"),$we=a("strong"),PRr=o("transfo-xl"),BRr=o(" \u2014 "),Iee=a("a"),IRr=o("TFTransfoXLLMHeadModel"),NRr=o(" (Transformer-XL model)"),qRr=l(),R5=a("li"),kwe=a("strong"),jRr=o("vit_mae"),DRr=o(" \u2014 "),Nee=a("a"),GRr=o("TFViTMAEForPreTraining"),ORr=o(" (ViTMAE model)"),VRr=l(),P5=a("li"),Swe=a("strong"),XRr=o("xlm"),zRr=o(" \u2014 "),qee=a("a"),QRr=o("TFXLMWithLMHeadModel"),WRr=o(" (XLM model)"),URr=l(),B5=a("li"),Rwe=a("strong"),HRr=o("xlm-roberta"),JRr=o(" \u2014 "),jee=a("a"),YRr=o("TFXLMRobertaForMaskedLM"),KRr=o(" (XLM-RoBERTa model)"),ZRr=l(),I5=a("li"),Pwe=a("strong"),ePr=o("xlnet"),oPr=o(" \u2014 "),Dee=a("a"),rPr=o("TFXLNetLMHeadModel"),tPr=o(" (XLNet model)"),aPr=l(),F(N5.$$.fragment),dZe=l(),Uc=a("h2"),q5=a("a"),Bwe=a("span"),F(Rk.$$.fragment),nPr=l(),Iwe=a("span"),sPr=o("TFAutoModelForCausalLM"),cZe=l(),ir=a("div"),F(Pk.$$.fragment),lPr=l(),Hc=a("p"),iPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Gee=a("a"),dPr=o("from_pretrained()"),cPr=o(" class method or the "),Oee=a("a"),mPr=o("from_config()"),fPr=o(` class
method.`),gPr=l(),Bk=a("p"),hPr=o("This class cannot be instantiated directly using "),Nwe=a("code"),uPr=o("__init__()"),pPr=o(" (throws an error)."),_Pr=l(),Qt=a("div"),F(Ik.$$.fragment),bPr=l(),qwe=a("p"),vPr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),FPr=l(),Jc=a("p"),TPr=o(`Note:
Loading a model from its configuration file does `),jwe=a("strong"),MPr=o("not"),EPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vee=a("a"),CPr=o("from_pretrained()"),wPr=o(" to load the model weights."),APr=l(),F(j5.$$.fragment),LPr=l(),qr=a("div"),F(Nk.$$.fragment),yPr=l(),Dwe=a("p"),xPr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),$Pr=l(),An=a("p"),kPr=o("The model class to instantiate is selected based on the "),Gwe=a("code"),SPr=o("model_type"),RPr=o(` property of the config object (either
passed as an argument or loaded from `),Owe=a("code"),PPr=o("pretrained_model_name_or_path"),BPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vwe=a("code"),IPr=o("pretrained_model_name_or_path"),NPr=o(":"),qPr=l(),Me=a("ul"),D5=a("li"),Xwe=a("strong"),jPr=o("bert"),DPr=o(" \u2014 "),Xee=a("a"),GPr=o("TFBertLMHeadModel"),OPr=o(" (BERT model)"),VPr=l(),G5=a("li"),zwe=a("strong"),XPr=o("camembert"),zPr=o(" \u2014 "),zee=a("a"),QPr=o("TFCamembertForCausalLM"),WPr=o(" (CamemBERT model)"),UPr=l(),O5=a("li"),Qwe=a("strong"),HPr=o("ctrl"),JPr=o(" \u2014 "),Qee=a("a"),YPr=o("TFCTRLLMHeadModel"),KPr=o(" (CTRL model)"),ZPr=l(),V5=a("li"),Wwe=a("strong"),eBr=o("gpt2"),oBr=o(" \u2014 "),Wee=a("a"),rBr=o("TFGPT2LMHeadModel"),tBr=o(" (OpenAI GPT-2 model)"),aBr=l(),X5=a("li"),Uwe=a("strong"),nBr=o("gptj"),sBr=o(" \u2014 "),Uee=a("a"),lBr=o("TFGPTJForCausalLM"),iBr=o(" (GPT-J model)"),dBr=l(),z5=a("li"),Hwe=a("strong"),cBr=o("openai-gpt"),mBr=o(" \u2014 "),Hee=a("a"),fBr=o("TFOpenAIGPTLMHeadModel"),gBr=o(" (OpenAI GPT model)"),hBr=l(),Q5=a("li"),Jwe=a("strong"),uBr=o("opt"),pBr=o(" \u2014 "),Jee=a("a"),_Br=o("TFOPTForCausalLM"),bBr=o(" (OPT model)"),vBr=l(),W5=a("li"),Ywe=a("strong"),FBr=o("rembert"),TBr=o(" \u2014 "),Yee=a("a"),MBr=o("TFRemBertForCausalLM"),EBr=o(" (RemBERT model)"),CBr=l(),U5=a("li"),Kwe=a("strong"),wBr=o("roberta"),ABr=o(" \u2014 "),Kee=a("a"),LBr=o("TFRobertaForCausalLM"),yBr=o(" (RoBERTa model)"),xBr=l(),H5=a("li"),Zwe=a("strong"),$Br=o("roformer"),kBr=o(" \u2014 "),Zee=a("a"),SBr=o("TFRoFormerForCausalLM"),RBr=o(" (RoFormer model)"),PBr=l(),J5=a("li"),eAe=a("strong"),BBr=o("transfo-xl"),IBr=o(" \u2014 "),eoe=a("a"),NBr=o("TFTransfoXLLMHeadModel"),qBr=o(" (Transformer-XL model)"),jBr=l(),Y5=a("li"),oAe=a("strong"),DBr=o("xglm"),GBr=o(" \u2014 "),ooe=a("a"),OBr=o("TFXGLMForCausalLM"),VBr=o(" (XGLM model)"),XBr=l(),K5=a("li"),rAe=a("strong"),zBr=o("xlm"),QBr=o(" \u2014 "),roe=a("a"),WBr=o("TFXLMWithLMHeadModel"),UBr=o(" (XLM model)"),HBr=l(),Z5=a("li"),tAe=a("strong"),JBr=o("xlnet"),YBr=o(" \u2014 "),toe=a("a"),KBr=o("TFXLNetLMHeadModel"),ZBr=o(" (XLNet model)"),eIr=l(),F(e0.$$.fragment),mZe=l(),Yc=a("h2"),o0=a("a"),aAe=a("span"),F(qk.$$.fragment),oIr=l(),nAe=a("span"),rIr=o("TFAutoModelForImageClassification"),fZe=l(),dr=a("div"),F(jk.$$.fragment),tIr=l(),Kc=a("p"),aIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),aoe=a("a"),nIr=o("from_pretrained()"),sIr=o(" class method or the "),noe=a("a"),lIr=o("from_config()"),iIr=o(` class
method.`),dIr=l(),Dk=a("p"),cIr=o("This class cannot be instantiated directly using "),sAe=a("code"),mIr=o("__init__()"),fIr=o(" (throws an error)."),gIr=l(),Wt=a("div"),F(Gk.$$.fragment),hIr=l(),lAe=a("p"),uIr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),pIr=l(),Zc=a("p"),_Ir=o(`Note:
Loading a model from its configuration file does `),iAe=a("strong"),bIr=o("not"),vIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),soe=a("a"),FIr=o("from_pretrained()"),TIr=o(" to load the model weights."),MIr=l(),F(r0.$$.fragment),EIr=l(),jr=a("div"),F(Ok.$$.fragment),CIr=l(),dAe=a("p"),wIr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),AIr=l(),Ln=a("p"),LIr=o("The model class to instantiate is selected based on the "),cAe=a("code"),yIr=o("model_type"),xIr=o(` property of the config object (either
passed as an argument or loaded from `),mAe=a("code"),$Ir=o("pretrained_model_name_or_path"),kIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fAe=a("code"),SIr=o("pretrained_model_name_or_path"),RIr=o(":"),PIr=l(),Be=a("ul"),t0=a("li"),gAe=a("strong"),BIr=o("convnext"),IIr=o(" \u2014 "),loe=a("a"),NIr=o("TFConvNextForImageClassification"),qIr=o(" (ConvNeXT model)"),jIr=l(),a0=a("li"),hAe=a("strong"),DIr=o("data2vec-vision"),GIr=o(" \u2014 "),ioe=a("a"),OIr=o("TFData2VecVisionForImageClassification"),VIr=o(" (Data2VecVision model)"),XIr=l(),Fl=a("li"),uAe=a("strong"),zIr=o("deit"),QIr=o(" \u2014 "),doe=a("a"),WIr=o("TFDeiTForImageClassification"),UIr=o(" or "),coe=a("a"),HIr=o("TFDeiTForImageClassificationWithTeacher"),JIr=o(" (DeiT model)"),YIr=l(),n0=a("li"),pAe=a("strong"),KIr=o("mobilevit"),ZIr=o(" \u2014 "),moe=a("a"),eNr=o("TFMobileViTForImageClassification"),oNr=o(" (MobileViT model)"),rNr=l(),s0=a("li"),_Ae=a("strong"),tNr=o("regnet"),aNr=o(" \u2014 "),foe=a("a"),nNr=o("TFRegNetForImageClassification"),sNr=o(" (RegNet model)"),lNr=l(),l0=a("li"),bAe=a("strong"),iNr=o("resnet"),dNr=o(" \u2014 "),goe=a("a"),cNr=o("TFResNetForImageClassification"),mNr=o(" (ResNet model)"),fNr=l(),i0=a("li"),vAe=a("strong"),gNr=o("segformer"),hNr=o(" \u2014 "),hoe=a("a"),uNr=o("TFSegformerForImageClassification"),pNr=o(" (SegFormer model)"),_Nr=l(),d0=a("li"),FAe=a("strong"),bNr=o("swin"),vNr=o(" \u2014 "),uoe=a("a"),FNr=o("TFSwinForImageClassification"),TNr=o(" (Swin Transformer model)"),MNr=l(),c0=a("li"),TAe=a("strong"),ENr=o("vit"),CNr=o(" \u2014 "),poe=a("a"),wNr=o("TFViTForImageClassification"),ANr=o(" (ViT model)"),LNr=l(),F(m0.$$.fragment),gZe=l(),em=a("h2"),f0=a("a"),MAe=a("span"),F(Vk.$$.fragment),yNr=l(),EAe=a("span"),xNr=o("TFAutoModelForSemanticSegmentation"),hZe=l(),cr=a("div"),F(Xk.$$.fragment),$Nr=l(),om=a("p"),kNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),_oe=a("a"),SNr=o("from_pretrained()"),RNr=o(" class method or the "),boe=a("a"),PNr=o("from_config()"),BNr=o(` class
method.`),INr=l(),zk=a("p"),NNr=o("This class cannot be instantiated directly using "),CAe=a("code"),qNr=o("__init__()"),jNr=o(" (throws an error)."),DNr=l(),Ut=a("div"),F(Qk.$$.fragment),GNr=l(),wAe=a("p"),ONr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),VNr=l(),rm=a("p"),XNr=o(`Note:
Loading a model from its configuration file does `),AAe=a("strong"),zNr=o("not"),QNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),voe=a("a"),WNr=o("from_pretrained()"),UNr=o(" to load the model weights."),HNr=l(),F(g0.$$.fragment),JNr=l(),Dr=a("div"),F(Wk.$$.fragment),YNr=l(),LAe=a("p"),KNr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),ZNr=l(),yn=a("p"),eqr=o("The model class to instantiate is selected based on the "),yAe=a("code"),oqr=o("model_type"),rqr=o(` property of the config object (either
passed as an argument or loaded from `),xAe=a("code"),tqr=o("pretrained_model_name_or_path"),aqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ae=a("code"),nqr=o("pretrained_model_name_or_path"),sqr=o(":"),lqr=l(),tm=a("ul"),h0=a("li"),kAe=a("strong"),iqr=o("data2vec-vision"),dqr=o(" \u2014 "),Foe=a("a"),cqr=o("TFData2VecVisionForSemanticSegmentation"),mqr=o(" (Data2VecVision model)"),fqr=l(),u0=a("li"),SAe=a("strong"),gqr=o("mobilevit"),hqr=o(" \u2014 "),Toe=a("a"),uqr=o("TFMobileViTForSemanticSegmentation"),pqr=o(" (MobileViT model)"),_qr=l(),p0=a("li"),RAe=a("strong"),bqr=o("segformer"),vqr=o(" \u2014 "),Moe=a("a"),Fqr=o("TFSegformerForSemanticSegmentation"),Tqr=o(" (SegFormer model)"),Mqr=l(),F(_0.$$.fragment),uZe=l(),am=a("h2"),b0=a("a"),PAe=a("span"),F(Uk.$$.fragment),Eqr=l(),BAe=a("span"),Cqr=o("TFAutoModelForMaskedLM"),pZe=l(),mr=a("div"),F(Hk.$$.fragment),wqr=l(),nm=a("p"),Aqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Eoe=a("a"),Lqr=o("from_pretrained()"),yqr=o(" class method or the "),Coe=a("a"),xqr=o("from_config()"),$qr=o(` class
method.`),kqr=l(),Jk=a("p"),Sqr=o("This class cannot be instantiated directly using "),IAe=a("code"),Rqr=o("__init__()"),Pqr=o(" (throws an error)."),Bqr=l(),Ht=a("div"),F(Yk.$$.fragment),Iqr=l(),NAe=a("p"),Nqr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),qqr=l(),sm=a("p"),jqr=o(`Note:
Loading a model from its configuration file does `),qAe=a("strong"),Dqr=o("not"),Gqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),woe=a("a"),Oqr=o("from_pretrained()"),Vqr=o(" to load the model weights."),Xqr=l(),F(v0.$$.fragment),zqr=l(),Gr=a("div"),F(Kk.$$.fragment),Qqr=l(),jAe=a("p"),Wqr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Uqr=l(),xn=a("p"),Hqr=o("The model class to instantiate is selected based on the "),DAe=a("code"),Jqr=o("model_type"),Yqr=o(` property of the config object (either
passed as an argument or loaded from `),GAe=a("code"),Kqr=o("pretrained_model_name_or_path"),Zqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),OAe=a("code"),ejr=o("pretrained_model_name_or_path"),ojr=o(":"),rjr=l(),fe=a("ul"),F0=a("li"),VAe=a("strong"),tjr=o("albert"),ajr=o(" \u2014 "),Aoe=a("a"),njr=o("TFAlbertForMaskedLM"),sjr=o(" (ALBERT model)"),ljr=l(),T0=a("li"),XAe=a("strong"),ijr=o("bert"),djr=o(" \u2014 "),Loe=a("a"),cjr=o("TFBertForMaskedLM"),mjr=o(" (BERT model)"),fjr=l(),M0=a("li"),zAe=a("strong"),gjr=o("camembert"),hjr=o(" \u2014 "),yoe=a("a"),ujr=o("TFCamembertForMaskedLM"),pjr=o(" (CamemBERT model)"),_jr=l(),E0=a("li"),QAe=a("strong"),bjr=o("convbert"),vjr=o(" \u2014 "),xoe=a("a"),Fjr=o("TFConvBertForMaskedLM"),Tjr=o(" (ConvBERT model)"),Mjr=l(),C0=a("li"),WAe=a("strong"),Ejr=o("deberta"),Cjr=o(" \u2014 "),$oe=a("a"),wjr=o("TFDebertaForMaskedLM"),Ajr=o(" (DeBERTa model)"),Ljr=l(),w0=a("li"),UAe=a("strong"),yjr=o("deberta-v2"),xjr=o(" \u2014 "),koe=a("a"),$jr=o("TFDebertaV2ForMaskedLM"),kjr=o(" (DeBERTa-v2 model)"),Sjr=l(),A0=a("li"),HAe=a("strong"),Rjr=o("distilbert"),Pjr=o(" \u2014 "),Soe=a("a"),Bjr=o("TFDistilBertForMaskedLM"),Ijr=o(" (DistilBERT model)"),Njr=l(),L0=a("li"),JAe=a("strong"),qjr=o("electra"),jjr=o(" \u2014 "),Roe=a("a"),Djr=o("TFElectraForMaskedLM"),Gjr=o(" (ELECTRA model)"),Ojr=l(),y0=a("li"),YAe=a("strong"),Vjr=o("flaubert"),Xjr=o(" \u2014 "),Poe=a("a"),zjr=o("TFFlaubertWithLMHeadModel"),Qjr=o(" (FlauBERT model)"),Wjr=l(),x0=a("li"),KAe=a("strong"),Ujr=o("funnel"),Hjr=o(" \u2014 "),Boe=a("a"),Jjr=o("TFFunnelForMaskedLM"),Yjr=o(" (Funnel Transformer model)"),Kjr=l(),$0=a("li"),ZAe=a("strong"),Zjr=o("layoutlm"),eDr=o(" \u2014 "),Ioe=a("a"),oDr=o("TFLayoutLMForMaskedLM"),rDr=o(" (LayoutLM model)"),tDr=l(),k0=a("li"),e6e=a("strong"),aDr=o("longformer"),nDr=o(" \u2014 "),Noe=a("a"),sDr=o("TFLongformerForMaskedLM"),lDr=o(" (Longformer model)"),iDr=l(),S0=a("li"),o6e=a("strong"),dDr=o("mobilebert"),cDr=o(" \u2014 "),qoe=a("a"),mDr=o("TFMobileBertForMaskedLM"),fDr=o(" (MobileBERT model)"),gDr=l(),R0=a("li"),r6e=a("strong"),hDr=o("mpnet"),uDr=o(" \u2014 "),joe=a("a"),pDr=o("TFMPNetForMaskedLM"),_Dr=o(" (MPNet model)"),bDr=l(),P0=a("li"),t6e=a("strong"),vDr=o("rembert"),FDr=o(" \u2014 "),Doe=a("a"),TDr=o("TFRemBertForMaskedLM"),MDr=o(" (RemBERT model)"),EDr=l(),B0=a("li"),a6e=a("strong"),CDr=o("roberta"),wDr=o(" \u2014 "),Goe=a("a"),ADr=o("TFRobertaForMaskedLM"),LDr=o(" (RoBERTa model)"),yDr=l(),I0=a("li"),n6e=a("strong"),xDr=o("roformer"),$Dr=o(" \u2014 "),Ooe=a("a"),kDr=o("TFRoFormerForMaskedLM"),SDr=o(" (RoFormer model)"),RDr=l(),N0=a("li"),s6e=a("strong"),PDr=o("tapas"),BDr=o(" \u2014 "),Voe=a("a"),IDr=o("TFTapasForMaskedLM"),NDr=o(" (TAPAS model)"),qDr=l(),q0=a("li"),l6e=a("strong"),jDr=o("xlm"),DDr=o(" \u2014 "),Xoe=a("a"),GDr=o("TFXLMWithLMHeadModel"),ODr=o(" (XLM model)"),VDr=l(),j0=a("li"),i6e=a("strong"),XDr=o("xlm-roberta"),zDr=o(" \u2014 "),zoe=a("a"),QDr=o("TFXLMRobertaForMaskedLM"),WDr=o(" (XLM-RoBERTa model)"),UDr=l(),F(D0.$$.fragment),_Ze=l(),lm=a("h2"),G0=a("a"),d6e=a("span"),F(Zk.$$.fragment),HDr=l(),c6e=a("span"),JDr=o("TFAutoModelForSeq2SeqLM"),bZe=l(),fr=a("div"),F(eS.$$.fragment),YDr=l(),im=a("p"),KDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Qoe=a("a"),ZDr=o("from_pretrained()"),eGr=o(" class method or the "),Woe=a("a"),oGr=o("from_config()"),rGr=o(` class
method.`),tGr=l(),oS=a("p"),aGr=o("This class cannot be instantiated directly using "),m6e=a("code"),nGr=o("__init__()"),sGr=o(" (throws an error)."),lGr=l(),Jt=a("div"),F(rS.$$.fragment),iGr=l(),f6e=a("p"),dGr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),cGr=l(),dm=a("p"),mGr=o(`Note:
Loading a model from its configuration file does `),g6e=a("strong"),fGr=o("not"),gGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Uoe=a("a"),hGr=o("from_pretrained()"),uGr=o(" to load the model weights."),pGr=l(),F(O0.$$.fragment),_Gr=l(),Or=a("div"),F(tS.$$.fragment),bGr=l(),h6e=a("p"),vGr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),FGr=l(),$n=a("p"),TGr=o("The model class to instantiate is selected based on the "),u6e=a("code"),MGr=o("model_type"),EGr=o(` property of the config object (either
passed as an argument or loaded from `),p6e=a("code"),CGr=o("pretrained_model_name_or_path"),wGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_6e=a("code"),AGr=o("pretrained_model_name_or_path"),LGr=o(":"),yGr=l(),ye=a("ul"),V0=a("li"),b6e=a("strong"),xGr=o("bart"),$Gr=o(" \u2014 "),Hoe=a("a"),kGr=o("TFBartForConditionalGeneration"),SGr=o(" (BART model)"),RGr=l(),X0=a("li"),v6e=a("strong"),PGr=o("blenderbot"),BGr=o(" \u2014 "),Joe=a("a"),IGr=o("TFBlenderbotForConditionalGeneration"),NGr=o(" (Blenderbot model)"),qGr=l(),z0=a("li"),F6e=a("strong"),jGr=o("blenderbot-small"),DGr=o(" \u2014 "),Yoe=a("a"),GGr=o("TFBlenderbotSmallForConditionalGeneration"),OGr=o(" (BlenderbotSmall model)"),VGr=l(),Q0=a("li"),T6e=a("strong"),XGr=o("encoder-decoder"),zGr=o(" \u2014 "),Koe=a("a"),QGr=o("TFEncoderDecoderModel"),WGr=o(" (Encoder decoder model)"),UGr=l(),W0=a("li"),M6e=a("strong"),HGr=o("led"),JGr=o(" \u2014 "),Zoe=a("a"),YGr=o("TFLEDForConditionalGeneration"),KGr=o(" (LED model)"),ZGr=l(),U0=a("li"),E6e=a("strong"),eOr=o("marian"),oOr=o(" \u2014 "),ere=a("a"),rOr=o("TFMarianMTModel"),tOr=o(" (Marian model)"),aOr=l(),H0=a("li"),C6e=a("strong"),nOr=o("mbart"),sOr=o(" \u2014 "),ore=a("a"),lOr=o("TFMBartForConditionalGeneration"),iOr=o(" (mBART model)"),dOr=l(),J0=a("li"),w6e=a("strong"),cOr=o("mt5"),mOr=o(" \u2014 "),rre=a("a"),fOr=o("TFMT5ForConditionalGeneration"),gOr=o(" (MT5 model)"),hOr=l(),Y0=a("li"),A6e=a("strong"),uOr=o("pegasus"),pOr=o(" \u2014 "),tre=a("a"),_Or=o("TFPegasusForConditionalGeneration"),bOr=o(" (Pegasus model)"),vOr=l(),K0=a("li"),L6e=a("strong"),FOr=o("t5"),TOr=o(" \u2014 "),are=a("a"),MOr=o("TFT5ForConditionalGeneration"),EOr=o(" (T5 model)"),COr=l(),F(Z0.$$.fragment),vZe=l(),cm=a("h2"),ew=a("a"),y6e=a("span"),F(aS.$$.fragment),wOr=l(),x6e=a("span"),AOr=o("TFAutoModelForSequenceClassification"),FZe=l(),gr=a("div"),F(nS.$$.fragment),LOr=l(),mm=a("p"),yOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),nre=a("a"),xOr=o("from_pretrained()"),$Or=o(" class method or the "),sre=a("a"),kOr=o("from_config()"),SOr=o(` class
method.`),ROr=l(),sS=a("p"),POr=o("This class cannot be instantiated directly using "),$6e=a("code"),BOr=o("__init__()"),IOr=o(" (throws an error)."),NOr=l(),Yt=a("div"),F(lS.$$.fragment),qOr=l(),k6e=a("p"),jOr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),DOr=l(),fm=a("p"),GOr=o(`Note:
Loading a model from its configuration file does `),S6e=a("strong"),OOr=o("not"),VOr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lre=a("a"),XOr=o("from_pretrained()"),zOr=o(" to load the model weights."),QOr=l(),F(ow.$$.fragment),WOr=l(),Vr=a("div"),F(iS.$$.fragment),UOr=l(),R6e=a("p"),HOr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),JOr=l(),kn=a("p"),YOr=o("The model class to instantiate is selected based on the "),P6e=a("code"),KOr=o("model_type"),ZOr=o(` property of the config object (either
passed as an argument or loaded from `),B6e=a("code"),eVr=o("pretrained_model_name_or_path"),oVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I6e=a("code"),rVr=o("pretrained_model_name_or_path"),tVr=o(":"),aVr=l(),re=a("ul"),rw=a("li"),N6e=a("strong"),nVr=o("albert"),sVr=o(" \u2014 "),ire=a("a"),lVr=o("TFAlbertForSequenceClassification"),iVr=o(" (ALBERT model)"),dVr=l(),tw=a("li"),q6e=a("strong"),cVr=o("bert"),mVr=o(" \u2014 "),dre=a("a"),fVr=o("TFBertForSequenceClassification"),gVr=o(" (BERT model)"),hVr=l(),aw=a("li"),j6e=a("strong"),uVr=o("camembert"),pVr=o(" \u2014 "),cre=a("a"),_Vr=o("TFCamembertForSequenceClassification"),bVr=o(" (CamemBERT model)"),vVr=l(),nw=a("li"),D6e=a("strong"),FVr=o("convbert"),TVr=o(" \u2014 "),mre=a("a"),MVr=o("TFConvBertForSequenceClassification"),EVr=o(" (ConvBERT model)"),CVr=l(),sw=a("li"),G6e=a("strong"),wVr=o("ctrl"),AVr=o(" \u2014 "),fre=a("a"),LVr=o("TFCTRLForSequenceClassification"),yVr=o(" (CTRL model)"),xVr=l(),lw=a("li"),O6e=a("strong"),$Vr=o("deberta"),kVr=o(" \u2014 "),gre=a("a"),SVr=o("TFDebertaForSequenceClassification"),RVr=o(" (DeBERTa model)"),PVr=l(),iw=a("li"),V6e=a("strong"),BVr=o("deberta-v2"),IVr=o(" \u2014 "),hre=a("a"),NVr=o("TFDebertaV2ForSequenceClassification"),qVr=o(" (DeBERTa-v2 model)"),jVr=l(),dw=a("li"),X6e=a("strong"),DVr=o("distilbert"),GVr=o(" \u2014 "),ure=a("a"),OVr=o("TFDistilBertForSequenceClassification"),VVr=o(" (DistilBERT model)"),XVr=l(),cw=a("li"),z6e=a("strong"),zVr=o("electra"),QVr=o(" \u2014 "),pre=a("a"),WVr=o("TFElectraForSequenceClassification"),UVr=o(" (ELECTRA model)"),HVr=l(),mw=a("li"),Q6e=a("strong"),JVr=o("flaubert"),YVr=o(" \u2014 "),_re=a("a"),KVr=o("TFFlaubertForSequenceClassification"),ZVr=o(" (FlauBERT model)"),eXr=l(),fw=a("li"),W6e=a("strong"),oXr=o("funnel"),rXr=o(" \u2014 "),bre=a("a"),tXr=o("TFFunnelForSequenceClassification"),aXr=o(" (Funnel Transformer model)"),nXr=l(),gw=a("li"),U6e=a("strong"),sXr=o("gpt2"),lXr=o(" \u2014 "),vre=a("a"),iXr=o("TFGPT2ForSequenceClassification"),dXr=o(" (OpenAI GPT-2 model)"),cXr=l(),hw=a("li"),H6e=a("strong"),mXr=o("gptj"),fXr=o(" \u2014 "),Fre=a("a"),gXr=o("TFGPTJForSequenceClassification"),hXr=o(" (GPT-J model)"),uXr=l(),uw=a("li"),J6e=a("strong"),pXr=o("layoutlm"),_Xr=o(" \u2014 "),Tre=a("a"),bXr=o("TFLayoutLMForSequenceClassification"),vXr=o(" (LayoutLM model)"),FXr=l(),pw=a("li"),Y6e=a("strong"),TXr=o("layoutlmv3"),MXr=o(" \u2014 "),Mre=a("a"),EXr=o("TFLayoutLMv3ForSequenceClassification"),CXr=o(" (LayoutLMv3 model)"),wXr=l(),_w=a("li"),K6e=a("strong"),AXr=o("longformer"),LXr=o(" \u2014 "),Ere=a("a"),yXr=o("TFLongformerForSequenceClassification"),xXr=o(" (Longformer model)"),$Xr=l(),bw=a("li"),Z6e=a("strong"),kXr=o("mobilebert"),SXr=o(" \u2014 "),Cre=a("a"),RXr=o("TFMobileBertForSequenceClassification"),PXr=o(" (MobileBERT model)"),BXr=l(),vw=a("li"),e7e=a("strong"),IXr=o("mpnet"),NXr=o(" \u2014 "),wre=a("a"),qXr=o("TFMPNetForSequenceClassification"),jXr=o(" (MPNet model)"),DXr=l(),Fw=a("li"),o7e=a("strong"),GXr=o("openai-gpt"),OXr=o(" \u2014 "),Are=a("a"),VXr=o("TFOpenAIGPTForSequenceClassification"),XXr=o(" (OpenAI GPT model)"),zXr=l(),Tw=a("li"),r7e=a("strong"),QXr=o("rembert"),WXr=o(" \u2014 "),Lre=a("a"),UXr=o("TFRemBertForSequenceClassification"),HXr=o(" (RemBERT model)"),JXr=l(),Mw=a("li"),t7e=a("strong"),YXr=o("roberta"),KXr=o(" \u2014 "),yre=a("a"),ZXr=o("TFRobertaForSequenceClassification"),ezr=o(" (RoBERTa model)"),ozr=l(),Ew=a("li"),a7e=a("strong"),rzr=o("roformer"),tzr=o(" \u2014 "),xre=a("a"),azr=o("TFRoFormerForSequenceClassification"),nzr=o(" (RoFormer model)"),szr=l(),Cw=a("li"),n7e=a("strong"),lzr=o("tapas"),izr=o(" \u2014 "),$re=a("a"),dzr=o("TFTapasForSequenceClassification"),czr=o(" (TAPAS model)"),mzr=l(),ww=a("li"),s7e=a("strong"),fzr=o("transfo-xl"),gzr=o(" \u2014 "),kre=a("a"),hzr=o("TFTransfoXLForSequenceClassification"),uzr=o(" (Transformer-XL model)"),pzr=l(),Aw=a("li"),l7e=a("strong"),_zr=o("xlm"),bzr=o(" \u2014 "),Sre=a("a"),vzr=o("TFXLMForSequenceClassification"),Fzr=o(" (XLM model)"),Tzr=l(),Lw=a("li"),i7e=a("strong"),Mzr=o("xlm-roberta"),Ezr=o(" \u2014 "),Rre=a("a"),Czr=o("TFXLMRobertaForSequenceClassification"),wzr=o(" (XLM-RoBERTa model)"),Azr=l(),yw=a("li"),d7e=a("strong"),Lzr=o("xlnet"),yzr=o(" \u2014 "),Pre=a("a"),xzr=o("TFXLNetForSequenceClassification"),$zr=o(" (XLNet model)"),kzr=l(),F(xw.$$.fragment),TZe=l(),gm=a("h2"),$w=a("a"),c7e=a("span"),F(dS.$$.fragment),Szr=l(),m7e=a("span"),Rzr=o("TFAutoModelForMultipleChoice"),MZe=l(),hr=a("div"),F(cS.$$.fragment),Pzr=l(),hm=a("p"),Bzr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Bre=a("a"),Izr=o("from_pretrained()"),Nzr=o(" class method or the "),Ire=a("a"),qzr=o("from_config()"),jzr=o(` class
method.`),Dzr=l(),mS=a("p"),Gzr=o("This class cannot be instantiated directly using "),f7e=a("code"),Ozr=o("__init__()"),Vzr=o(" (throws an error)."),Xzr=l(),Kt=a("div"),F(fS.$$.fragment),zzr=l(),g7e=a("p"),Qzr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Wzr=l(),um=a("p"),Uzr=o(`Note:
Loading a model from its configuration file does `),h7e=a("strong"),Hzr=o("not"),Jzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nre=a("a"),Yzr=o("from_pretrained()"),Kzr=o(" to load the model weights."),Zzr=l(),F(kw.$$.fragment),eQr=l(),Xr=a("div"),F(gS.$$.fragment),oQr=l(),u7e=a("p"),rQr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),tQr=l(),Sn=a("p"),aQr=o("The model class to instantiate is selected based on the "),p7e=a("code"),nQr=o("model_type"),sQr=o(` property of the config object (either
passed as an argument or loaded from `),_7e=a("code"),lQr=o("pretrained_model_name_or_path"),iQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b7e=a("code"),dQr=o("pretrained_model_name_or_path"),cQr=o(":"),mQr=l(),ve=a("ul"),Sw=a("li"),v7e=a("strong"),fQr=o("albert"),gQr=o(" \u2014 "),qre=a("a"),hQr=o("TFAlbertForMultipleChoice"),uQr=o(" (ALBERT model)"),pQr=l(),Rw=a("li"),F7e=a("strong"),_Qr=o("bert"),bQr=o(" \u2014 "),jre=a("a"),vQr=o("TFBertForMultipleChoice"),FQr=o(" (BERT model)"),TQr=l(),Pw=a("li"),T7e=a("strong"),MQr=o("camembert"),EQr=o(" \u2014 "),Dre=a("a"),CQr=o("TFCamembertForMultipleChoice"),wQr=o(" (CamemBERT model)"),AQr=l(),Bw=a("li"),M7e=a("strong"),LQr=o("convbert"),yQr=o(" \u2014 "),Gre=a("a"),xQr=o("TFConvBertForMultipleChoice"),$Qr=o(" (ConvBERT model)"),kQr=l(),Iw=a("li"),E7e=a("strong"),SQr=o("distilbert"),RQr=o(" \u2014 "),Ore=a("a"),PQr=o("TFDistilBertForMultipleChoice"),BQr=o(" (DistilBERT model)"),IQr=l(),Nw=a("li"),C7e=a("strong"),NQr=o("electra"),qQr=o(" \u2014 "),Vre=a("a"),jQr=o("TFElectraForMultipleChoice"),DQr=o(" (ELECTRA model)"),GQr=l(),qw=a("li"),w7e=a("strong"),OQr=o("flaubert"),VQr=o(" \u2014 "),Xre=a("a"),XQr=o("TFFlaubertForMultipleChoice"),zQr=o(" (FlauBERT model)"),QQr=l(),jw=a("li"),A7e=a("strong"),WQr=o("funnel"),UQr=o(" \u2014 "),zre=a("a"),HQr=o("TFFunnelForMultipleChoice"),JQr=o(" (Funnel Transformer model)"),YQr=l(),Dw=a("li"),L7e=a("strong"),KQr=o("longformer"),ZQr=o(" \u2014 "),Qre=a("a"),eWr=o("TFLongformerForMultipleChoice"),oWr=o(" (Longformer model)"),rWr=l(),Gw=a("li"),y7e=a("strong"),tWr=o("mobilebert"),aWr=o(" \u2014 "),Wre=a("a"),nWr=o("TFMobileBertForMultipleChoice"),sWr=o(" (MobileBERT model)"),lWr=l(),Ow=a("li"),x7e=a("strong"),iWr=o("mpnet"),dWr=o(" \u2014 "),Ure=a("a"),cWr=o("TFMPNetForMultipleChoice"),mWr=o(" (MPNet model)"),fWr=l(),Vw=a("li"),$7e=a("strong"),gWr=o("rembert"),hWr=o(" \u2014 "),Hre=a("a"),uWr=o("TFRemBertForMultipleChoice"),pWr=o(" (RemBERT model)"),_Wr=l(),Xw=a("li"),k7e=a("strong"),bWr=o("roberta"),vWr=o(" \u2014 "),Jre=a("a"),FWr=o("TFRobertaForMultipleChoice"),TWr=o(" (RoBERTa model)"),MWr=l(),zw=a("li"),S7e=a("strong"),EWr=o("roformer"),CWr=o(" \u2014 "),Yre=a("a"),wWr=o("TFRoFormerForMultipleChoice"),AWr=o(" (RoFormer model)"),LWr=l(),Qw=a("li"),R7e=a("strong"),yWr=o("xlm"),xWr=o(" \u2014 "),Kre=a("a"),$Wr=o("TFXLMForMultipleChoice"),kWr=o(" (XLM model)"),SWr=l(),Ww=a("li"),P7e=a("strong"),RWr=o("xlm-roberta"),PWr=o(" \u2014 "),Zre=a("a"),BWr=o("TFXLMRobertaForMultipleChoice"),IWr=o(" (XLM-RoBERTa model)"),NWr=l(),Uw=a("li"),B7e=a("strong"),qWr=o("xlnet"),jWr=o(" \u2014 "),ete=a("a"),DWr=o("TFXLNetForMultipleChoice"),GWr=o(" (XLNet model)"),OWr=l(),F(Hw.$$.fragment),EZe=l(),pm=a("h2"),Jw=a("a"),I7e=a("span"),F(hS.$$.fragment),VWr=l(),N7e=a("span"),XWr=o("TFAutoModelForNextSentencePrediction"),CZe=l(),ur=a("div"),F(uS.$$.fragment),zWr=l(),_m=a("p"),QWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),ote=a("a"),WWr=o("from_pretrained()"),UWr=o(" class method or the "),rte=a("a"),HWr=o("from_config()"),JWr=o(` class
method.`),YWr=l(),pS=a("p"),KWr=o("This class cannot be instantiated directly using "),q7e=a("code"),ZWr=o("__init__()"),eUr=o(" (throws an error)."),oUr=l(),Zt=a("div"),F(_S.$$.fragment),rUr=l(),j7e=a("p"),tUr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),aUr=l(),bm=a("p"),nUr=o(`Note:
Loading a model from its configuration file does `),D7e=a("strong"),sUr=o("not"),lUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tte=a("a"),iUr=o("from_pretrained()"),dUr=o(" to load the model weights."),cUr=l(),F(Yw.$$.fragment),mUr=l(),zr=a("div"),F(bS.$$.fragment),fUr=l(),G7e=a("p"),gUr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),hUr=l(),Rn=a("p"),uUr=o("The model class to instantiate is selected based on the "),O7e=a("code"),pUr=o("model_type"),_Ur=o(` property of the config object (either
passed as an argument or loaded from `),V7e=a("code"),bUr=o("pretrained_model_name_or_path"),vUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X7e=a("code"),FUr=o("pretrained_model_name_or_path"),TUr=o(":"),MUr=l(),vS=a("ul"),Kw=a("li"),z7e=a("strong"),EUr=o("bert"),CUr=o(" \u2014 "),ate=a("a"),wUr=o("TFBertForNextSentencePrediction"),AUr=o(" (BERT model)"),LUr=l(),Zw=a("li"),Q7e=a("strong"),yUr=o("mobilebert"),xUr=o(" \u2014 "),nte=a("a"),$Ur=o("TFMobileBertForNextSentencePrediction"),kUr=o(" (MobileBERT model)"),SUr=l(),F(eA.$$.fragment),wZe=l(),vm=a("h2"),oA=a("a"),W7e=a("span"),F(FS.$$.fragment),RUr=l(),U7e=a("span"),PUr=o("TFAutoModelForTableQuestionAnswering"),AZe=l(),pr=a("div"),F(TS.$$.fragment),BUr=l(),Fm=a("p"),IUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),ste=a("a"),NUr=o("from_pretrained()"),qUr=o(" class method or the "),lte=a("a"),jUr=o("from_config()"),DUr=o(` class
method.`),GUr=l(),MS=a("p"),OUr=o("This class cannot be instantiated directly using "),H7e=a("code"),VUr=o("__init__()"),XUr=o(" (throws an error)."),zUr=l(),ea=a("div"),F(ES.$$.fragment),QUr=l(),J7e=a("p"),WUr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),UUr=l(),Tm=a("p"),HUr=o(`Note:
Loading a model from its configuration file does `),Y7e=a("strong"),JUr=o("not"),YUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ite=a("a"),KUr=o("from_pretrained()"),ZUr=o(" to load the model weights."),eHr=l(),F(rA.$$.fragment),oHr=l(),Qr=a("div"),F(CS.$$.fragment),rHr=l(),K7e=a("p"),tHr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),aHr=l(),Pn=a("p"),nHr=o("The model class to instantiate is selected based on the "),Z7e=a("code"),sHr=o("model_type"),lHr=o(` property of the config object (either
passed as an argument or loaded from `),eLe=a("code"),iHr=o("pretrained_model_name_or_path"),dHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oLe=a("code"),cHr=o("pretrained_model_name_or_path"),mHr=o(":"),fHr=l(),rLe=a("ul"),tA=a("li"),tLe=a("strong"),gHr=o("tapas"),hHr=o(" \u2014 "),dte=a("a"),uHr=o("TFTapasForQuestionAnswering"),pHr=o(" (TAPAS model)"),_Hr=l(),F(aA.$$.fragment),LZe=l(),Mm=a("h2"),nA=a("a"),aLe=a("span"),F(wS.$$.fragment),bHr=l(),nLe=a("span"),vHr=o("TFAutoModelForDocumentQuestionAnswering"),yZe=l(),_r=a("div"),F(AS.$$.fragment),FHr=l(),Em=a("p"),THr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),cte=a("a"),MHr=o("from_pretrained()"),EHr=o(" class method or the "),mte=a("a"),CHr=o("from_config()"),wHr=o(` class
method.`),AHr=l(),LS=a("p"),LHr=o("This class cannot be instantiated directly using "),sLe=a("code"),yHr=o("__init__()"),xHr=o(" (throws an error)."),$Hr=l(),oa=a("div"),F(yS.$$.fragment),kHr=l(),lLe=a("p"),SHr=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),RHr=l(),Cm=a("p"),PHr=o(`Note:
Loading a model from its configuration file does `),iLe=a("strong"),BHr=o("not"),IHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fte=a("a"),NHr=o("from_pretrained()"),qHr=o(" to load the model weights."),jHr=l(),F(sA.$$.fragment),DHr=l(),Wr=a("div"),F(xS.$$.fragment),GHr=l(),dLe=a("p"),OHr=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),VHr=l(),Bn=a("p"),XHr=o("The model class to instantiate is selected based on the "),cLe=a("code"),zHr=o("model_type"),QHr=o(` property of the config object (either
passed as an argument or loaded from `),mLe=a("code"),WHr=o("pretrained_model_name_or_path"),UHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fLe=a("code"),HHr=o("pretrained_model_name_or_path"),JHr=o(":"),YHr=l(),gLe=a("ul"),lA=a("li"),hLe=a("strong"),KHr=o("layoutlm"),ZHr=o(" \u2014 "),gte=a("a"),eJr=o("TFLayoutLMForQuestionAnswering"),oJr=o(" (LayoutLM model)"),rJr=l(),F(iA.$$.fragment),xZe=l(),wm=a("h2"),dA=a("a"),uLe=a("span"),F($S.$$.fragment),tJr=l(),pLe=a("span"),aJr=o("TFAutoModelForTokenClassification"),$Ze=l(),br=a("div"),F(kS.$$.fragment),nJr=l(),Am=a("p"),sJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),hte=a("a"),lJr=o("from_pretrained()"),iJr=o(" class method or the "),ute=a("a"),dJr=o("from_config()"),cJr=o(` class
method.`),mJr=l(),SS=a("p"),fJr=o("This class cannot be instantiated directly using "),_Le=a("code"),gJr=o("__init__()"),hJr=o(" (throws an error)."),uJr=l(),ra=a("div"),F(RS.$$.fragment),pJr=l(),bLe=a("p"),_Jr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),bJr=l(),Lm=a("p"),vJr=o(`Note:
Loading a model from its configuration file does `),vLe=a("strong"),FJr=o("not"),TJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pte=a("a"),MJr=o("from_pretrained()"),EJr=o(" to load the model weights."),CJr=l(),F(cA.$$.fragment),wJr=l(),Ur=a("div"),F(PS.$$.fragment),AJr=l(),FLe=a("p"),LJr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),yJr=l(),In=a("p"),xJr=o("The model class to instantiate is selected based on the "),TLe=a("code"),$Jr=o("model_type"),kJr=o(` property of the config object (either
passed as an argument or loaded from `),MLe=a("code"),SJr=o("pretrained_model_name_or_path"),RJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ELe=a("code"),PJr=o("pretrained_model_name_or_path"),BJr=o(":"),IJr=l(),de=a("ul"),mA=a("li"),CLe=a("strong"),NJr=o("albert"),qJr=o(" \u2014 "),_te=a("a"),jJr=o("TFAlbertForTokenClassification"),DJr=o(" (ALBERT model)"),GJr=l(),fA=a("li"),wLe=a("strong"),OJr=o("bert"),VJr=o(" \u2014 "),bte=a("a"),XJr=o("TFBertForTokenClassification"),zJr=o(" (BERT model)"),QJr=l(),gA=a("li"),ALe=a("strong"),WJr=o("camembert"),UJr=o(" \u2014 "),vte=a("a"),HJr=o("TFCamembertForTokenClassification"),JJr=o(" (CamemBERT model)"),YJr=l(),hA=a("li"),LLe=a("strong"),KJr=o("convbert"),ZJr=o(" \u2014 "),Fte=a("a"),eYr=o("TFConvBertForTokenClassification"),oYr=o(" (ConvBERT model)"),rYr=l(),uA=a("li"),yLe=a("strong"),tYr=o("deberta"),aYr=o(" \u2014 "),Tte=a("a"),nYr=o("TFDebertaForTokenClassification"),sYr=o(" (DeBERTa model)"),lYr=l(),pA=a("li"),xLe=a("strong"),iYr=o("deberta-v2"),dYr=o(" \u2014 "),Mte=a("a"),cYr=o("TFDebertaV2ForTokenClassification"),mYr=o(" (DeBERTa-v2 model)"),fYr=l(),_A=a("li"),$Le=a("strong"),gYr=o("distilbert"),hYr=o(" \u2014 "),Ete=a("a"),uYr=o("TFDistilBertForTokenClassification"),pYr=o(" (DistilBERT model)"),_Yr=l(),bA=a("li"),kLe=a("strong"),bYr=o("electra"),vYr=o(" \u2014 "),Cte=a("a"),FYr=o("TFElectraForTokenClassification"),TYr=o(" (ELECTRA model)"),MYr=l(),vA=a("li"),SLe=a("strong"),EYr=o("flaubert"),CYr=o(" \u2014 "),wte=a("a"),wYr=o("TFFlaubertForTokenClassification"),AYr=o(" (FlauBERT model)"),LYr=l(),FA=a("li"),RLe=a("strong"),yYr=o("funnel"),xYr=o(" \u2014 "),Ate=a("a"),$Yr=o("TFFunnelForTokenClassification"),kYr=o(" (Funnel Transformer model)"),SYr=l(),TA=a("li"),PLe=a("strong"),RYr=o("layoutlm"),PYr=o(" \u2014 "),Lte=a("a"),BYr=o("TFLayoutLMForTokenClassification"),IYr=o(" (LayoutLM model)"),NYr=l(),MA=a("li"),BLe=a("strong"),qYr=o("layoutlmv3"),jYr=o(" \u2014 "),yte=a("a"),DYr=o("TFLayoutLMv3ForTokenClassification"),GYr=o(" (LayoutLMv3 model)"),OYr=l(),EA=a("li"),ILe=a("strong"),VYr=o("longformer"),XYr=o(" \u2014 "),xte=a("a"),zYr=o("TFLongformerForTokenClassification"),QYr=o(" (Longformer model)"),WYr=l(),CA=a("li"),NLe=a("strong"),UYr=o("mobilebert"),HYr=o(" \u2014 "),$te=a("a"),JYr=o("TFMobileBertForTokenClassification"),YYr=o(" (MobileBERT model)"),KYr=l(),wA=a("li"),qLe=a("strong"),ZYr=o("mpnet"),eKr=o(" \u2014 "),kte=a("a"),oKr=o("TFMPNetForTokenClassification"),rKr=o(" (MPNet model)"),tKr=l(),AA=a("li"),jLe=a("strong"),aKr=o("rembert"),nKr=o(" \u2014 "),Ste=a("a"),sKr=o("TFRemBertForTokenClassification"),lKr=o(" (RemBERT model)"),iKr=l(),LA=a("li"),DLe=a("strong"),dKr=o("roberta"),cKr=o(" \u2014 "),Rte=a("a"),mKr=o("TFRobertaForTokenClassification"),fKr=o(" (RoBERTa model)"),gKr=l(),yA=a("li"),GLe=a("strong"),hKr=o("roformer"),uKr=o(" \u2014 "),Pte=a("a"),pKr=o("TFRoFormerForTokenClassification"),_Kr=o(" (RoFormer model)"),bKr=l(),xA=a("li"),OLe=a("strong"),vKr=o("xlm"),FKr=o(" \u2014 "),Bte=a("a"),TKr=o("TFXLMForTokenClassification"),MKr=o(" (XLM model)"),EKr=l(),$A=a("li"),VLe=a("strong"),CKr=o("xlm-roberta"),wKr=o(" \u2014 "),Ite=a("a"),AKr=o("TFXLMRobertaForTokenClassification"),LKr=o(" (XLM-RoBERTa model)"),yKr=l(),kA=a("li"),XLe=a("strong"),xKr=o("xlnet"),$Kr=o(" \u2014 "),Nte=a("a"),kKr=o("TFXLNetForTokenClassification"),SKr=o(" (XLNet model)"),RKr=l(),F(SA.$$.fragment),kZe=l(),ym=a("h2"),RA=a("a"),zLe=a("span"),F(BS.$$.fragment),PKr=l(),QLe=a("span"),BKr=o("TFAutoModelForQuestionAnswering"),SZe=l(),vr=a("div"),F(IS.$$.fragment),IKr=l(),xm=a("p"),NKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),qte=a("a"),qKr=o("from_pretrained()"),jKr=o(" class method or the "),jte=a("a"),DKr=o("from_config()"),GKr=o(` class
method.`),OKr=l(),NS=a("p"),VKr=o("This class cannot be instantiated directly using "),WLe=a("code"),XKr=o("__init__()"),zKr=o(" (throws an error)."),QKr=l(),ta=a("div"),F(qS.$$.fragment),WKr=l(),ULe=a("p"),UKr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),HKr=l(),$m=a("p"),JKr=o(`Note:
Loading a model from its configuration file does `),HLe=a("strong"),YKr=o("not"),KKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Dte=a("a"),ZKr=o("from_pretrained()"),eZr=o(" to load the model weights."),oZr=l(),F(PA.$$.fragment),rZr=l(),Hr=a("div"),F(jS.$$.fragment),tZr=l(),JLe=a("p"),aZr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),nZr=l(),Nn=a("p"),sZr=o("The model class to instantiate is selected based on the "),YLe=a("code"),lZr=o("model_type"),iZr=o(` property of the config object (either
passed as an argument or loaded from `),KLe=a("code"),dZr=o("pretrained_model_name_or_path"),cZr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZLe=a("code"),mZr=o("pretrained_model_name_or_path"),fZr=o(":"),gZr=l(),ce=a("ul"),BA=a("li"),eye=a("strong"),hZr=o("albert"),uZr=o(" \u2014 "),Gte=a("a"),pZr=o("TFAlbertForQuestionAnswering"),_Zr=o(" (ALBERT model)"),bZr=l(),IA=a("li"),oye=a("strong"),vZr=o("bert"),FZr=o(" \u2014 "),Ote=a("a"),TZr=o("TFBertForQuestionAnswering"),MZr=o(" (BERT model)"),EZr=l(),NA=a("li"),rye=a("strong"),CZr=o("camembert"),wZr=o(" \u2014 "),Vte=a("a"),AZr=o("TFCamembertForQuestionAnswering"),LZr=o(" (CamemBERT model)"),yZr=l(),qA=a("li"),tye=a("strong"),xZr=o("convbert"),$Zr=o(" \u2014 "),Xte=a("a"),kZr=o("TFConvBertForQuestionAnswering"),SZr=o(" (ConvBERT model)"),RZr=l(),jA=a("li"),aye=a("strong"),PZr=o("deberta"),BZr=o(" \u2014 "),zte=a("a"),IZr=o("TFDebertaForQuestionAnswering"),NZr=o(" (DeBERTa model)"),qZr=l(),DA=a("li"),nye=a("strong"),jZr=o("deberta-v2"),DZr=o(" \u2014 "),Qte=a("a"),GZr=o("TFDebertaV2ForQuestionAnswering"),OZr=o(" (DeBERTa-v2 model)"),VZr=l(),GA=a("li"),sye=a("strong"),XZr=o("distilbert"),zZr=o(" \u2014 "),Wte=a("a"),QZr=o("TFDistilBertForQuestionAnswering"),WZr=o(" (DistilBERT model)"),UZr=l(),OA=a("li"),lye=a("strong"),HZr=o("electra"),JZr=o(" \u2014 "),Ute=a("a"),YZr=o("TFElectraForQuestionAnswering"),KZr=o(" (ELECTRA model)"),ZZr=l(),VA=a("li"),iye=a("strong"),eet=o("flaubert"),oet=o(" \u2014 "),Hte=a("a"),ret=o("TFFlaubertForQuestionAnsweringSimple"),tet=o(" (FlauBERT model)"),aet=l(),XA=a("li"),dye=a("strong"),net=o("funnel"),set=o(" \u2014 "),Jte=a("a"),iet=o("TFFunnelForQuestionAnswering"),det=o(" (Funnel Transformer model)"),cet=l(),zA=a("li"),cye=a("strong"),met=o("gptj"),fet=o(" \u2014 "),Yte=a("a"),get=o("TFGPTJForQuestionAnswering"),het=o(" (GPT-J model)"),uet=l(),QA=a("li"),mye=a("strong"),pet=o("layoutlmv3"),_et=o(" \u2014 "),Kte=a("a"),bet=o("TFLayoutLMv3ForQuestionAnswering"),vet=o(" (LayoutLMv3 model)"),Fet=l(),WA=a("li"),fye=a("strong"),Tet=o("longformer"),Met=o(" \u2014 "),Zte=a("a"),Eet=o("TFLongformerForQuestionAnswering"),Cet=o(" (Longformer model)"),wet=l(),UA=a("li"),gye=a("strong"),Aet=o("mobilebert"),Let=o(" \u2014 "),eae=a("a"),yet=o("TFMobileBertForQuestionAnswering"),xet=o(" (MobileBERT model)"),$et=l(),HA=a("li"),hye=a("strong"),ket=o("mpnet"),Set=o(" \u2014 "),oae=a("a"),Ret=o("TFMPNetForQuestionAnswering"),Pet=o(" (MPNet model)"),Bet=l(),JA=a("li"),uye=a("strong"),Iet=o("rembert"),Net=o(" \u2014 "),rae=a("a"),qet=o("TFRemBertForQuestionAnswering"),jet=o(" (RemBERT model)"),Det=l(),YA=a("li"),pye=a("strong"),Get=o("roberta"),Oet=o(" \u2014 "),tae=a("a"),Vet=o("TFRobertaForQuestionAnswering"),Xet=o(" (RoBERTa model)"),zet=l(),KA=a("li"),_ye=a("strong"),Qet=o("roformer"),Wet=o(" \u2014 "),aae=a("a"),Uet=o("TFRoFormerForQuestionAnswering"),Het=o(" (RoFormer model)"),Jet=l(),ZA=a("li"),bye=a("strong"),Yet=o("xlm"),Ket=o(" \u2014 "),nae=a("a"),Zet=o("TFXLMForQuestionAnsweringSimple"),eot=o(" (XLM model)"),oot=l(),e6=a("li"),vye=a("strong"),rot=o("xlm-roberta"),tot=o(" \u2014 "),sae=a("a"),aot=o("TFXLMRobertaForQuestionAnswering"),not=o(" (XLM-RoBERTa model)"),sot=l(),o6=a("li"),Fye=a("strong"),lot=o("xlnet"),iot=o(" \u2014 "),lae=a("a"),dot=o("TFXLNetForQuestionAnsweringSimple"),cot=o(" (XLNet model)"),mot=l(),F(r6.$$.fragment),RZe=l(),km=a("h2"),t6=a("a"),Tye=a("span"),F(DS.$$.fragment),fot=l(),Mye=a("span"),got=o("TFAutoModelForVision2Seq"),PZe=l(),Fr=a("div"),F(GS.$$.fragment),hot=l(),Sm=a("p"),uot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),iae=a("a"),pot=o("from_pretrained()"),_ot=o(" class method or the "),dae=a("a"),bot=o("from_config()"),vot=o(` class
method.`),Fot=l(),OS=a("p"),Tot=o("This class cannot be instantiated directly using "),Eye=a("code"),Mot=o("__init__()"),Eot=o(" (throws an error)."),Cot=l(),aa=a("div"),F(VS.$$.fragment),wot=l(),Cye=a("p"),Aot=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Lot=l(),Rm=a("p"),yot=o(`Note:
Loading a model from its configuration file does `),wye=a("strong"),xot=o("not"),$ot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cae=a("a"),kot=o("from_pretrained()"),Sot=o(" to load the model weights."),Rot=l(),F(a6.$$.fragment),Pot=l(),Jr=a("div"),F(XS.$$.fragment),Bot=l(),Aye=a("p"),Iot=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Not=l(),qn=a("p"),qot=o("The model class to instantiate is selected based on the "),Lye=a("code"),jot=o("model_type"),Dot=o(` property of the config object (either
passed as an argument or loaded from `),yye=a("code"),Got=o("pretrained_model_name_or_path"),Oot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xye=a("code"),Vot=o("pretrained_model_name_or_path"),Xot=o(":"),zot=l(),$ye=a("ul"),n6=a("li"),kye=a("strong"),Qot=o("vision-encoder-decoder"),Wot=o(" \u2014 "),mae=a("a"),Uot=o("TFVisionEncoderDecoderModel"),Hot=o(" (Vision Encoder decoder model)"),Jot=l(),F(s6.$$.fragment),BZe=l(),Pm=a("h2"),l6=a("a"),Sye=a("span"),F(zS.$$.fragment),Yot=l(),Rye=a("span"),Kot=o("TFAutoModelForSpeechSeq2Seq"),IZe=l(),Tr=a("div"),F(QS.$$.fragment),Zot=l(),Bm=a("p"),ert=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),fae=a("a"),ort=o("from_pretrained()"),rrt=o(" class method or the "),gae=a("a"),trt=o("from_config()"),art=o(` class
method.`),nrt=l(),WS=a("p"),srt=o("This class cannot be instantiated directly using "),Pye=a("code"),lrt=o("__init__()"),irt=o(" (throws an error)."),drt=l(),na=a("div"),F(US.$$.fragment),crt=l(),Bye=a("p"),mrt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),frt=l(),Im=a("p"),grt=o(`Note:
Loading a model from its configuration file does `),Iye=a("strong"),hrt=o("not"),urt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hae=a("a"),prt=o("from_pretrained()"),_rt=o(" to load the model weights."),brt=l(),F(i6.$$.fragment),vrt=l(),Yr=a("div"),F(HS.$$.fragment),Frt=l(),Nye=a("p"),Trt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Mrt=l(),jn=a("p"),Ert=o("The model class to instantiate is selected based on the "),qye=a("code"),Crt=o("model_type"),wrt=o(` property of the config object (either
passed as an argument or loaded from `),jye=a("code"),Art=o("pretrained_model_name_or_path"),Lrt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dye=a("code"),yrt=o("pretrained_model_name_or_path"),xrt=o(":"),$rt=l(),Gye=a("ul"),d6=a("li"),Oye=a("strong"),krt=o("speech_to_text"),Srt=o(" \u2014 "),uae=a("a"),Rrt=o("TFSpeech2TextForConditionalGeneration"),Prt=o(" (Speech2Text model)"),Brt=l(),F(c6.$$.fragment),NZe=l(),Nm=a("h2"),m6=a("a"),Vye=a("span"),F(JS.$$.fragment),Irt=l(),Xye=a("span"),Nrt=o("FlaxAutoModel"),qZe=l(),Mr=a("div"),F(YS.$$.fragment),qrt=l(),qm=a("p"),jrt=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),pae=a("a"),Drt=o("from_pretrained()"),Grt=o(" class method or the "),_ae=a("a"),Ort=o("from_config()"),Vrt=o(` class
method.`),Xrt=l(),KS=a("p"),zrt=o("This class cannot be instantiated directly using "),zye=a("code"),Qrt=o("__init__()"),Wrt=o(" (throws an error)."),Urt=l(),sa=a("div"),F(ZS.$$.fragment),Hrt=l(),Qye=a("p"),Jrt=o("Instantiates one of the base model classes of the library from a configuration."),Yrt=l(),jm=a("p"),Krt=o(`Note:
Loading a model from its configuration file does `),Wye=a("strong"),Zrt=o("not"),ett=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bae=a("a"),ott=o("from_pretrained()"),rtt=o(" to load the model weights."),ttt=l(),F(f6.$$.fragment),att=l(),Kr=a("div"),F(eR.$$.fragment),ntt=l(),Uye=a("p"),stt=o("Instantiate one of the base model classes of the library from a pretrained model."),ltt=l(),Dn=a("p"),itt=o("The model class to instantiate is selected based on the "),Hye=a("code"),dtt=o("model_type"),ctt=o(` property of the config object (either
passed as an argument or loaded from `),Jye=a("code"),mtt=o("pretrained_model_name_or_path"),ftt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yye=a("code"),gtt=o("pretrained_model_name_or_path"),htt=o(":"),utt=l(),te=a("ul"),g6=a("li"),Kye=a("strong"),ptt=o("albert"),_tt=o(" \u2014 "),vae=a("a"),btt=o("FlaxAlbertModel"),vtt=o(" (ALBERT model)"),Ftt=l(),h6=a("li"),Zye=a("strong"),Ttt=o("bart"),Mtt=o(" \u2014 "),Fae=a("a"),Ett=o("FlaxBartModel"),Ctt=o(" (BART model)"),wtt=l(),u6=a("li"),e8e=a("strong"),Att=o("beit"),Ltt=o(" \u2014 "),Tae=a("a"),ytt=o("FlaxBeitModel"),xtt=o(" (BEiT model)"),$tt=l(),p6=a("li"),o8e=a("strong"),ktt=o("bert"),Stt=o(" \u2014 "),Mae=a("a"),Rtt=o("FlaxBertModel"),Ptt=o(" (BERT model)"),Btt=l(),_6=a("li"),r8e=a("strong"),Itt=o("big_bird"),Ntt=o(" \u2014 "),Eae=a("a"),qtt=o("FlaxBigBirdModel"),jtt=o(" (BigBird model)"),Dtt=l(),b6=a("li"),t8e=a("strong"),Gtt=o("blenderbot"),Ott=o(" \u2014 "),Cae=a("a"),Vtt=o("FlaxBlenderbotModel"),Xtt=o(" (Blenderbot model)"),ztt=l(),v6=a("li"),a8e=a("strong"),Qtt=o("blenderbot-small"),Wtt=o(" \u2014 "),wae=a("a"),Utt=o("FlaxBlenderbotSmallModel"),Htt=o(" (BlenderbotSmall model)"),Jtt=l(),F6=a("li"),n8e=a("strong"),Ytt=o("clip"),Ktt=o(" \u2014 "),Aae=a("a"),Ztt=o("FlaxCLIPModel"),eat=o(" (CLIP model)"),oat=l(),T6=a("li"),s8e=a("strong"),rat=o("distilbert"),tat=o(" \u2014 "),Lae=a("a"),aat=o("FlaxDistilBertModel"),nat=o(" (DistilBERT model)"),sat=l(),M6=a("li"),l8e=a("strong"),lat=o("electra"),iat=o(" \u2014 "),yae=a("a"),dat=o("FlaxElectraModel"),cat=o(" (ELECTRA model)"),mat=l(),E6=a("li"),i8e=a("strong"),fat=o("gpt2"),gat=o(" \u2014 "),xae=a("a"),hat=o("FlaxGPT2Model"),uat=o(" (OpenAI GPT-2 model)"),pat=l(),C6=a("li"),d8e=a("strong"),_at=o("gpt_neo"),bat=o(" \u2014 "),$ae=a("a"),vat=o("FlaxGPTNeoModel"),Fat=o(" (GPT Neo model)"),Tat=l(),w6=a("li"),c8e=a("strong"),Mat=o("gptj"),Eat=o(" \u2014 "),kae=a("a"),Cat=o("FlaxGPTJModel"),wat=o(" (GPT-J model)"),Aat=l(),A6=a("li"),m8e=a("strong"),Lat=o("longt5"),yat=o(" \u2014 "),Sae=a("a"),xat=o("FlaxLongT5Model"),$at=o(" (LongT5 model)"),kat=l(),L6=a("li"),f8e=a("strong"),Sat=o("marian"),Rat=o(" \u2014 "),Rae=a("a"),Pat=o("FlaxMarianModel"),Bat=o(" (Marian model)"),Iat=l(),y6=a("li"),g8e=a("strong"),Nat=o("mbart"),qat=o(" \u2014 "),Pae=a("a"),jat=o("FlaxMBartModel"),Dat=o(" (mBART model)"),Gat=l(),x6=a("li"),h8e=a("strong"),Oat=o("mt5"),Vat=o(" \u2014 "),Bae=a("a"),Xat=o("FlaxMT5Model"),zat=o(" (MT5 model)"),Qat=l(),$6=a("li"),u8e=a("strong"),Wat=o("opt"),Uat=o(" \u2014 "),Iae=a("a"),Hat=o("FlaxOPTModel"),Jat=o(" (OPT model)"),Yat=l(),k6=a("li"),p8e=a("strong"),Kat=o("pegasus"),Zat=o(" \u2014 "),Nae=a("a"),ent=o("FlaxPegasusModel"),ont=o(" (Pegasus model)"),rnt=l(),S6=a("li"),_8e=a("strong"),tnt=o("roberta"),ant=o(" \u2014 "),qae=a("a"),nnt=o("FlaxRobertaModel"),snt=o(" (RoBERTa model)"),lnt=l(),R6=a("li"),b8e=a("strong"),int=o("roformer"),dnt=o(" \u2014 "),jae=a("a"),cnt=o("FlaxRoFormerModel"),mnt=o(" (RoFormer model)"),fnt=l(),P6=a("li"),v8e=a("strong"),gnt=o("t5"),hnt=o(" \u2014 "),Dae=a("a"),unt=o("FlaxT5Model"),pnt=o(" (T5 model)"),_nt=l(),B6=a("li"),F8e=a("strong"),bnt=o("vision-text-dual-encoder"),vnt=o(" \u2014 "),Gae=a("a"),Fnt=o("FlaxVisionTextDualEncoderModel"),Tnt=o(" (VisionTextDualEncoder model)"),Mnt=l(),I6=a("li"),T8e=a("strong"),Ent=o("vit"),Cnt=o(" \u2014 "),Oae=a("a"),wnt=o("FlaxViTModel"),Ant=o(" (ViT model)"),Lnt=l(),N6=a("li"),M8e=a("strong"),ynt=o("wav2vec2"),xnt=o(" \u2014 "),Vae=a("a"),$nt=o("FlaxWav2Vec2Model"),knt=o(" (Wav2Vec2 model)"),Snt=l(),q6=a("li"),E8e=a("strong"),Rnt=o("xglm"),Pnt=o(" \u2014 "),Xae=a("a"),Bnt=o("FlaxXGLMModel"),Int=o(" (XGLM model)"),Nnt=l(),j6=a("li"),C8e=a("strong"),qnt=o("xlm-roberta"),jnt=o(" \u2014 "),zae=a("a"),Dnt=o("FlaxXLMRobertaModel"),Gnt=o(" (XLM-RoBERTa model)"),Ont=l(),F(D6.$$.fragment),jZe=l(),Dm=a("h2"),G6=a("a"),w8e=a("span"),F(oR.$$.fragment),Vnt=l(),A8e=a("span"),Xnt=o("FlaxAutoModelForCausalLM"),DZe=l(),Er=a("div"),F(rR.$$.fragment),znt=l(),Gm=a("p"),Qnt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Qae=a("a"),Wnt=o("from_pretrained()"),Unt=o(" class method or the "),Wae=a("a"),Hnt=o("from_config()"),Jnt=o(` class
method.`),Ynt=l(),tR=a("p"),Knt=o("This class cannot be instantiated directly using "),L8e=a("code"),Znt=o("__init__()"),est=o(" (throws an error)."),ost=l(),la=a("div"),F(aR.$$.fragment),rst=l(),y8e=a("p"),tst=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ast=l(),Om=a("p"),nst=o(`Note:
Loading a model from its configuration file does `),x8e=a("strong"),sst=o("not"),lst=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Uae=a("a"),ist=o("from_pretrained()"),dst=o(" to load the model weights."),cst=l(),F(O6.$$.fragment),mst=l(),Zr=a("div"),F(nR.$$.fragment),fst=l(),$8e=a("p"),gst=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),hst=l(),Gn=a("p"),ust=o("The model class to instantiate is selected based on the "),k8e=a("code"),pst=o("model_type"),_st=o(` property of the config object (either
passed as an argument or loaded from `),S8e=a("code"),bst=o("pretrained_model_name_or_path"),vst=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R8e=a("code"),Fst=o("pretrained_model_name_or_path"),Tst=o(":"),Mst=l(),xe=a("ul"),V6=a("li"),P8e=a("strong"),Est=o("bart"),Cst=o(" \u2014 "),Hae=a("a"),wst=o("FlaxBartForCausalLM"),Ast=o(" (BART model)"),Lst=l(),X6=a("li"),B8e=a("strong"),yst=o("bert"),xst=o(" \u2014 "),Jae=a("a"),$st=o("FlaxBertForCausalLM"),kst=o(" (BERT model)"),Sst=l(),z6=a("li"),I8e=a("strong"),Rst=o("big_bird"),Pst=o(" \u2014 "),Yae=a("a"),Bst=o("FlaxBigBirdForCausalLM"),Ist=o(" (BigBird model)"),Nst=l(),Q6=a("li"),N8e=a("strong"),qst=o("electra"),jst=o(" \u2014 "),Kae=a("a"),Dst=o("FlaxElectraForCausalLM"),Gst=o(" (ELECTRA model)"),Ost=l(),W6=a("li"),q8e=a("strong"),Vst=o("gpt2"),Xst=o(" \u2014 "),Zae=a("a"),zst=o("FlaxGPT2LMHeadModel"),Qst=o(" (OpenAI GPT-2 model)"),Wst=l(),U6=a("li"),j8e=a("strong"),Ust=o("gpt_neo"),Hst=o(" \u2014 "),ene=a("a"),Jst=o("FlaxGPTNeoForCausalLM"),Yst=o(" (GPT Neo model)"),Kst=l(),H6=a("li"),D8e=a("strong"),Zst=o("gptj"),elt=o(" \u2014 "),one=a("a"),olt=o("FlaxGPTJForCausalLM"),rlt=o(" (GPT-J model)"),tlt=l(),J6=a("li"),G8e=a("strong"),alt=o("opt"),nlt=o(" \u2014 "),rne=a("a"),slt=o("FlaxOPTForCausalLM"),llt=o(" (OPT model)"),ilt=l(),Y6=a("li"),O8e=a("strong"),dlt=o("roberta"),clt=o(" \u2014 "),tne=a("a"),mlt=o("FlaxRobertaForCausalLM"),flt=o(" (RoBERTa model)"),glt=l(),K6=a("li"),V8e=a("strong"),hlt=o("xglm"),ult=o(" \u2014 "),ane=a("a"),plt=o("FlaxXGLMForCausalLM"),_lt=o(" (XGLM model)"),blt=l(),F(Z6.$$.fragment),GZe=l(),Vm=a("h2"),e7=a("a"),X8e=a("span"),F(sR.$$.fragment),vlt=l(),z8e=a("span"),Flt=o("FlaxAutoModelForPreTraining"),OZe=l(),Cr=a("div"),F(lR.$$.fragment),Tlt=l(),Xm=a("p"),Mlt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),nne=a("a"),Elt=o("from_pretrained()"),Clt=o(" class method or the "),sne=a("a"),wlt=o("from_config()"),Alt=o(` class
method.`),Llt=l(),iR=a("p"),ylt=o("This class cannot be instantiated directly using "),Q8e=a("code"),xlt=o("__init__()"),$lt=o(" (throws an error)."),klt=l(),ia=a("div"),F(dR.$$.fragment),Slt=l(),W8e=a("p"),Rlt=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Plt=l(),zm=a("p"),Blt=o(`Note:
Loading a model from its configuration file does `),U8e=a("strong"),Ilt=o("not"),Nlt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lne=a("a"),qlt=o("from_pretrained()"),jlt=o(" to load the model weights."),Dlt=l(),F(o7.$$.fragment),Glt=l(),et=a("div"),F(cR.$$.fragment),Olt=l(),H8e=a("p"),Vlt=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Xlt=l(),On=a("p"),zlt=o("The model class to instantiate is selected based on the "),J8e=a("code"),Qlt=o("model_type"),Wlt=o(` property of the config object (either
passed as an argument or loaded from `),Y8e=a("code"),Ult=o("pretrained_model_name_or_path"),Hlt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K8e=a("code"),Jlt=o("pretrained_model_name_or_path"),Ylt=o(":"),Klt=l(),Ee=a("ul"),r7=a("li"),Z8e=a("strong"),Zlt=o("albert"),eit=o(" \u2014 "),ine=a("a"),oit=o("FlaxAlbertForPreTraining"),rit=o(" (ALBERT model)"),tit=l(),t7=a("li"),e9e=a("strong"),ait=o("bart"),nit=o(" \u2014 "),dne=a("a"),sit=o("FlaxBartForConditionalGeneration"),lit=o(" (BART model)"),iit=l(),a7=a("li"),o9e=a("strong"),dit=o("bert"),cit=o(" \u2014 "),cne=a("a"),mit=o("FlaxBertForPreTraining"),fit=o(" (BERT model)"),git=l(),n7=a("li"),r9e=a("strong"),hit=o("big_bird"),uit=o(" \u2014 "),mne=a("a"),pit=o("FlaxBigBirdForPreTraining"),_it=o(" (BigBird model)"),bit=l(),s7=a("li"),t9e=a("strong"),vit=o("electra"),Fit=o(" \u2014 "),fne=a("a"),Tit=o("FlaxElectraForPreTraining"),Mit=o(" (ELECTRA model)"),Eit=l(),l7=a("li"),a9e=a("strong"),Cit=o("longt5"),wit=o(" \u2014 "),gne=a("a"),Ait=o("FlaxLongT5ForConditionalGeneration"),Lit=o(" (LongT5 model)"),yit=l(),i7=a("li"),n9e=a("strong"),xit=o("mbart"),$it=o(" \u2014 "),hne=a("a"),kit=o("FlaxMBartForConditionalGeneration"),Sit=o(" (mBART model)"),Rit=l(),d7=a("li"),s9e=a("strong"),Pit=o("mt5"),Bit=o(" \u2014 "),une=a("a"),Iit=o("FlaxMT5ForConditionalGeneration"),Nit=o(" (MT5 model)"),qit=l(),c7=a("li"),l9e=a("strong"),jit=o("roberta"),Dit=o(" \u2014 "),pne=a("a"),Git=o("FlaxRobertaForMaskedLM"),Oit=o(" (RoBERTa model)"),Vit=l(),m7=a("li"),i9e=a("strong"),Xit=o("roformer"),zit=o(" \u2014 "),_ne=a("a"),Qit=o("FlaxRoFormerForMaskedLM"),Wit=o(" (RoFormer model)"),Uit=l(),f7=a("li"),d9e=a("strong"),Hit=o("t5"),Jit=o(" \u2014 "),bne=a("a"),Yit=o("FlaxT5ForConditionalGeneration"),Kit=o(" (T5 model)"),Zit=l(),g7=a("li"),c9e=a("strong"),edt=o("wav2vec2"),odt=o(" \u2014 "),vne=a("a"),rdt=o("FlaxWav2Vec2ForPreTraining"),tdt=o(" (Wav2Vec2 model)"),adt=l(),h7=a("li"),m9e=a("strong"),ndt=o("xlm-roberta"),sdt=o(" \u2014 "),Fne=a("a"),ldt=o("FlaxXLMRobertaForMaskedLM"),idt=o(" (XLM-RoBERTa model)"),ddt=l(),F(u7.$$.fragment),VZe=l(),Qm=a("h2"),p7=a("a"),f9e=a("span"),F(mR.$$.fragment),cdt=l(),g9e=a("span"),mdt=o("FlaxAutoModelForMaskedLM"),XZe=l(),wr=a("div"),F(fR.$$.fragment),fdt=l(),Wm=a("p"),gdt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Tne=a("a"),hdt=o("from_pretrained()"),udt=o(" class method or the "),Mne=a("a"),pdt=o("from_config()"),_dt=o(` class
method.`),bdt=l(),gR=a("p"),vdt=o("This class cannot be instantiated directly using "),h9e=a("code"),Fdt=o("__init__()"),Tdt=o(" (throws an error)."),Mdt=l(),da=a("div"),F(hR.$$.fragment),Edt=l(),u9e=a("p"),Cdt=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),wdt=l(),Um=a("p"),Adt=o(`Note:
Loading a model from its configuration file does `),p9e=a("strong"),Ldt=o("not"),ydt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ene=a("a"),xdt=o("from_pretrained()"),$dt=o(" to load the model weights."),kdt=l(),F(_7.$$.fragment),Sdt=l(),ot=a("div"),F(uR.$$.fragment),Rdt=l(),_9e=a("p"),Pdt=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Bdt=l(),Vn=a("p"),Idt=o("The model class to instantiate is selected based on the "),b9e=a("code"),Ndt=o("model_type"),qdt=o(` property of the config object (either
passed as an argument or loaded from `),v9e=a("code"),jdt=o("pretrained_model_name_or_path"),Ddt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F9e=a("code"),Gdt=o("pretrained_model_name_or_path"),Odt=o(":"),Vdt=l(),$e=a("ul"),b7=a("li"),T9e=a("strong"),Xdt=o("albert"),zdt=o(" \u2014 "),Cne=a("a"),Qdt=o("FlaxAlbertForMaskedLM"),Wdt=o(" (ALBERT model)"),Udt=l(),v7=a("li"),M9e=a("strong"),Hdt=o("bart"),Jdt=o(" \u2014 "),wne=a("a"),Ydt=o("FlaxBartForConditionalGeneration"),Kdt=o(" (BART model)"),Zdt=l(),F7=a("li"),E9e=a("strong"),ect=o("bert"),oct=o(" \u2014 "),Ane=a("a"),rct=o("FlaxBertForMaskedLM"),tct=o(" (BERT model)"),act=l(),T7=a("li"),C9e=a("strong"),nct=o("big_bird"),sct=o(" \u2014 "),Lne=a("a"),lct=o("FlaxBigBirdForMaskedLM"),ict=o(" (BigBird model)"),dct=l(),M7=a("li"),w9e=a("strong"),cct=o("distilbert"),mct=o(" \u2014 "),yne=a("a"),fct=o("FlaxDistilBertForMaskedLM"),gct=o(" (DistilBERT model)"),hct=l(),E7=a("li"),A9e=a("strong"),uct=o("electra"),pct=o(" \u2014 "),xne=a("a"),_ct=o("FlaxElectraForMaskedLM"),bct=o(" (ELECTRA model)"),vct=l(),C7=a("li"),L9e=a("strong"),Fct=o("mbart"),Tct=o(" \u2014 "),$ne=a("a"),Mct=o("FlaxMBartForConditionalGeneration"),Ect=o(" (mBART model)"),Cct=l(),w7=a("li"),y9e=a("strong"),wct=o("roberta"),Act=o(" \u2014 "),kne=a("a"),Lct=o("FlaxRobertaForMaskedLM"),yct=o(" (RoBERTa model)"),xct=l(),A7=a("li"),x9e=a("strong"),$ct=o("roformer"),kct=o(" \u2014 "),Sne=a("a"),Sct=o("FlaxRoFormerForMaskedLM"),Rct=o(" (RoFormer model)"),Pct=l(),L7=a("li"),$9e=a("strong"),Bct=o("xlm-roberta"),Ict=o(" \u2014 "),Rne=a("a"),Nct=o("FlaxXLMRobertaForMaskedLM"),qct=o(" (XLM-RoBERTa model)"),jct=l(),F(y7.$$.fragment),zZe=l(),Hm=a("h2"),x7=a("a"),k9e=a("span"),F(pR.$$.fragment),Dct=l(),S9e=a("span"),Gct=o("FlaxAutoModelForSeq2SeqLM"),QZe=l(),Ar=a("div"),F(_R.$$.fragment),Oct=l(),Jm=a("p"),Vct=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Pne=a("a"),Xct=o("from_pretrained()"),zct=o(" class method or the "),Bne=a("a"),Qct=o("from_config()"),Wct=o(` class
method.`),Uct=l(),bR=a("p"),Hct=o("This class cannot be instantiated directly using "),R9e=a("code"),Jct=o("__init__()"),Yct=o(" (throws an error)."),Kct=l(),ca=a("div"),F(vR.$$.fragment),Zct=l(),P9e=a("p"),emt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),omt=l(),Ym=a("p"),rmt=o(`Note:
Loading a model from its configuration file does `),B9e=a("strong"),tmt=o("not"),amt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ine=a("a"),nmt=o("from_pretrained()"),smt=o(" to load the model weights."),lmt=l(),F($7.$$.fragment),imt=l(),rt=a("div"),F(FR.$$.fragment),dmt=l(),I9e=a("p"),cmt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),mmt=l(),Xn=a("p"),fmt=o("The model class to instantiate is selected based on the "),N9e=a("code"),gmt=o("model_type"),hmt=o(` property of the config object (either
passed as an argument or loaded from `),q9e=a("code"),umt=o("pretrained_model_name_or_path"),pmt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j9e=a("code"),_mt=o("pretrained_model_name_or_path"),bmt=o(":"),vmt=l(),ke=a("ul"),k7=a("li"),D9e=a("strong"),Fmt=o("bart"),Tmt=o(" \u2014 "),Nne=a("a"),Mmt=o("FlaxBartForConditionalGeneration"),Emt=o(" (BART model)"),Cmt=l(),S7=a("li"),G9e=a("strong"),wmt=o("blenderbot"),Amt=o(" \u2014 "),qne=a("a"),Lmt=o("FlaxBlenderbotForConditionalGeneration"),ymt=o(" (Blenderbot model)"),xmt=l(),R7=a("li"),O9e=a("strong"),$mt=o("blenderbot-small"),kmt=o(" \u2014 "),jne=a("a"),Smt=o("FlaxBlenderbotSmallForConditionalGeneration"),Rmt=o(" (BlenderbotSmall model)"),Pmt=l(),P7=a("li"),V9e=a("strong"),Bmt=o("encoder-decoder"),Imt=o(" \u2014 "),Dne=a("a"),Nmt=o("FlaxEncoderDecoderModel"),qmt=o(" (Encoder decoder model)"),jmt=l(),B7=a("li"),X9e=a("strong"),Dmt=o("longt5"),Gmt=o(" \u2014 "),Gne=a("a"),Omt=o("FlaxLongT5ForConditionalGeneration"),Vmt=o(" (LongT5 model)"),Xmt=l(),I7=a("li"),z9e=a("strong"),zmt=o("marian"),Qmt=o(" \u2014 "),One=a("a"),Wmt=o("FlaxMarianMTModel"),Umt=o(" (Marian model)"),Hmt=l(),N7=a("li"),Q9e=a("strong"),Jmt=o("mbart"),Ymt=o(" \u2014 "),Vne=a("a"),Kmt=o("FlaxMBartForConditionalGeneration"),Zmt=o(" (mBART model)"),eft=l(),q7=a("li"),W9e=a("strong"),oft=o("mt5"),rft=o(" \u2014 "),Xne=a("a"),tft=o("FlaxMT5ForConditionalGeneration"),aft=o(" (MT5 model)"),nft=l(),j7=a("li"),U9e=a("strong"),sft=o("pegasus"),lft=o(" \u2014 "),zne=a("a"),ift=o("FlaxPegasusForConditionalGeneration"),dft=o(" (Pegasus model)"),cft=l(),D7=a("li"),H9e=a("strong"),mft=o("t5"),fft=o(" \u2014 "),Qne=a("a"),gft=o("FlaxT5ForConditionalGeneration"),hft=o(" (T5 model)"),uft=l(),F(G7.$$.fragment),WZe=l(),Km=a("h2"),O7=a("a"),J9e=a("span"),F(TR.$$.fragment),pft=l(),Y9e=a("span"),_ft=o("FlaxAutoModelForSequenceClassification"),UZe=l(),Lr=a("div"),F(MR.$$.fragment),bft=l(),Zm=a("p"),vft=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Wne=a("a"),Fft=o("from_pretrained()"),Tft=o(" class method or the "),Une=a("a"),Mft=o("from_config()"),Eft=o(` class
method.`),Cft=l(),ER=a("p"),wft=o("This class cannot be instantiated directly using "),K9e=a("code"),Aft=o("__init__()"),Lft=o(" (throws an error)."),yft=l(),ma=a("div"),F(CR.$$.fragment),xft=l(),Z9e=a("p"),$ft=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),kft=l(),ef=a("p"),Sft=o(`Note:
Loading a model from its configuration file does `),exe=a("strong"),Rft=o("not"),Pft=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Hne=a("a"),Bft=o("from_pretrained()"),Ift=o(" to load the model weights."),Nft=l(),F(V7.$$.fragment),qft=l(),tt=a("div"),F(wR.$$.fragment),jft=l(),oxe=a("p"),Dft=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Gft=l(),zn=a("p"),Oft=o("The model class to instantiate is selected based on the "),rxe=a("code"),Vft=o("model_type"),Xft=o(` property of the config object (either
passed as an argument or loaded from `),txe=a("code"),zft=o("pretrained_model_name_or_path"),Qft=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),axe=a("code"),Wft=o("pretrained_model_name_or_path"),Uft=o(":"),Hft=l(),Se=a("ul"),X7=a("li"),nxe=a("strong"),Jft=o("albert"),Yft=o(" \u2014 "),Jne=a("a"),Kft=o("FlaxAlbertForSequenceClassification"),Zft=o(" (ALBERT model)"),egt=l(),z7=a("li"),sxe=a("strong"),ogt=o("bart"),rgt=o(" \u2014 "),Yne=a("a"),tgt=o("FlaxBartForSequenceClassification"),agt=o(" (BART model)"),ngt=l(),Q7=a("li"),lxe=a("strong"),sgt=o("bert"),lgt=o(" \u2014 "),Kne=a("a"),igt=o("FlaxBertForSequenceClassification"),dgt=o(" (BERT model)"),cgt=l(),W7=a("li"),ixe=a("strong"),mgt=o("big_bird"),fgt=o(" \u2014 "),Zne=a("a"),ggt=o("FlaxBigBirdForSequenceClassification"),hgt=o(" (BigBird model)"),ugt=l(),U7=a("li"),dxe=a("strong"),pgt=o("distilbert"),_gt=o(" \u2014 "),ese=a("a"),bgt=o("FlaxDistilBertForSequenceClassification"),vgt=o(" (DistilBERT model)"),Fgt=l(),H7=a("li"),cxe=a("strong"),Tgt=o("electra"),Mgt=o(" \u2014 "),ose=a("a"),Egt=o("FlaxElectraForSequenceClassification"),Cgt=o(" (ELECTRA model)"),wgt=l(),J7=a("li"),mxe=a("strong"),Agt=o("mbart"),Lgt=o(" \u2014 "),rse=a("a"),ygt=o("FlaxMBartForSequenceClassification"),xgt=o(" (mBART model)"),$gt=l(),Y7=a("li"),fxe=a("strong"),kgt=o("roberta"),Sgt=o(" \u2014 "),tse=a("a"),Rgt=o("FlaxRobertaForSequenceClassification"),Pgt=o(" (RoBERTa model)"),Bgt=l(),K7=a("li"),gxe=a("strong"),Igt=o("roformer"),Ngt=o(" \u2014 "),ase=a("a"),qgt=o("FlaxRoFormerForSequenceClassification"),jgt=o(" (RoFormer model)"),Dgt=l(),Z7=a("li"),hxe=a("strong"),Ggt=o("xlm-roberta"),Ogt=o(" \u2014 "),nse=a("a"),Vgt=o("FlaxXLMRobertaForSequenceClassification"),Xgt=o(" (XLM-RoBERTa model)"),zgt=l(),F(eL.$$.fragment),HZe=l(),of=a("h2"),oL=a("a"),uxe=a("span"),F(AR.$$.fragment),Qgt=l(),pxe=a("span"),Wgt=o("FlaxAutoModelForQuestionAnswering"),JZe=l(),yr=a("div"),F(LR.$$.fragment),Ugt=l(),rf=a("p"),Hgt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),sse=a("a"),Jgt=o("from_pretrained()"),Ygt=o(" class method or the "),lse=a("a"),Kgt=o("from_config()"),Zgt=o(` class
method.`),eht=l(),yR=a("p"),oht=o("This class cannot be instantiated directly using "),_xe=a("code"),rht=o("__init__()"),tht=o(" (throws an error)."),aht=l(),fa=a("div"),F(xR.$$.fragment),nht=l(),bxe=a("p"),sht=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),lht=l(),tf=a("p"),iht=o(`Note:
Loading a model from its configuration file does `),vxe=a("strong"),dht=o("not"),cht=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ise=a("a"),mht=o("from_pretrained()"),fht=o(" to load the model weights."),ght=l(),F(rL.$$.fragment),hht=l(),at=a("div"),F($R.$$.fragment),uht=l(),Fxe=a("p"),pht=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),_ht=l(),Qn=a("p"),bht=o("The model class to instantiate is selected based on the "),Txe=a("code"),vht=o("model_type"),Fht=o(` property of the config object (either
passed as an argument or loaded from `),Mxe=a("code"),Tht=o("pretrained_model_name_or_path"),Mht=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Exe=a("code"),Eht=o("pretrained_model_name_or_path"),Cht=o(":"),wht=l(),Re=a("ul"),tL=a("li"),Cxe=a("strong"),Aht=o("albert"),Lht=o(" \u2014 "),dse=a("a"),yht=o("FlaxAlbertForQuestionAnswering"),xht=o(" (ALBERT model)"),$ht=l(),aL=a("li"),wxe=a("strong"),kht=o("bart"),Sht=o(" \u2014 "),cse=a("a"),Rht=o("FlaxBartForQuestionAnswering"),Pht=o(" (BART model)"),Bht=l(),nL=a("li"),Axe=a("strong"),Iht=o("bert"),Nht=o(" \u2014 "),mse=a("a"),qht=o("FlaxBertForQuestionAnswering"),jht=o(" (BERT model)"),Dht=l(),sL=a("li"),Lxe=a("strong"),Ght=o("big_bird"),Oht=o(" \u2014 "),fse=a("a"),Vht=o("FlaxBigBirdForQuestionAnswering"),Xht=o(" (BigBird model)"),zht=l(),lL=a("li"),yxe=a("strong"),Qht=o("distilbert"),Wht=o(" \u2014 "),gse=a("a"),Uht=o("FlaxDistilBertForQuestionAnswering"),Hht=o(" (DistilBERT model)"),Jht=l(),iL=a("li"),xxe=a("strong"),Yht=o("electra"),Kht=o(" \u2014 "),hse=a("a"),Zht=o("FlaxElectraForQuestionAnswering"),eut=o(" (ELECTRA model)"),out=l(),dL=a("li"),$xe=a("strong"),rut=o("mbart"),tut=o(" \u2014 "),use=a("a"),aut=o("FlaxMBartForQuestionAnswering"),nut=o(" (mBART model)"),sut=l(),cL=a("li"),kxe=a("strong"),lut=o("roberta"),iut=o(" \u2014 "),pse=a("a"),dut=o("FlaxRobertaForQuestionAnswering"),cut=o(" (RoBERTa model)"),mut=l(),mL=a("li"),Sxe=a("strong"),fut=o("roformer"),gut=o(" \u2014 "),_se=a("a"),hut=o("FlaxRoFormerForQuestionAnswering"),uut=o(" (RoFormer model)"),put=l(),fL=a("li"),Rxe=a("strong"),_ut=o("xlm-roberta"),but=o(" \u2014 "),bse=a("a"),vut=o("FlaxXLMRobertaForQuestionAnswering"),Fut=o(" (XLM-RoBERTa model)"),Tut=l(),F(gL.$$.fragment),YZe=l(),af=a("h2"),hL=a("a"),Pxe=a("span"),F(kR.$$.fragment),Mut=l(),Bxe=a("span"),Eut=o("FlaxAutoModelForTokenClassification"),KZe=l(),xr=a("div"),F(SR.$$.fragment),Cut=l(),nf=a("p"),wut=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),vse=a("a"),Aut=o("from_pretrained()"),Lut=o(" class method or the "),Fse=a("a"),yut=o("from_config()"),xut=o(` class
method.`),$ut=l(),RR=a("p"),kut=o("This class cannot be instantiated directly using "),Ixe=a("code"),Sut=o("__init__()"),Rut=o(" (throws an error)."),Put=l(),ga=a("div"),F(PR.$$.fragment),But=l(),Nxe=a("p"),Iut=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Nut=l(),sf=a("p"),qut=o(`Note:
Loading a model from its configuration file does `),qxe=a("strong"),jut=o("not"),Dut=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tse=a("a"),Gut=o("from_pretrained()"),Out=o(" to load the model weights."),Vut=l(),F(uL.$$.fragment),Xut=l(),nt=a("div"),F(BR.$$.fragment),zut=l(),jxe=a("p"),Qut=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Wut=l(),Wn=a("p"),Uut=o("The model class to instantiate is selected based on the "),Dxe=a("code"),Hut=o("model_type"),Jut=o(` property of the config object (either
passed as an argument or loaded from `),Gxe=a("code"),Yut=o("pretrained_model_name_or_path"),Kut=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Oxe=a("code"),Zut=o("pretrained_model_name_or_path"),ept=o(":"),opt=l(),Xe=a("ul"),pL=a("li"),Vxe=a("strong"),rpt=o("albert"),tpt=o(" \u2014 "),Mse=a("a"),apt=o("FlaxAlbertForTokenClassification"),npt=o(" (ALBERT model)"),spt=l(),_L=a("li"),Xxe=a("strong"),lpt=o("bert"),ipt=o(" \u2014 "),Ese=a("a"),dpt=o("FlaxBertForTokenClassification"),cpt=o(" (BERT model)"),mpt=l(),bL=a("li"),zxe=a("strong"),fpt=o("big_bird"),gpt=o(" \u2014 "),Cse=a("a"),hpt=o("FlaxBigBirdForTokenClassification"),upt=o(" (BigBird model)"),ppt=l(),vL=a("li"),Qxe=a("strong"),_pt=o("distilbert"),bpt=o(" \u2014 "),wse=a("a"),vpt=o("FlaxDistilBertForTokenClassification"),Fpt=o(" (DistilBERT model)"),Tpt=l(),FL=a("li"),Wxe=a("strong"),Mpt=o("electra"),Ept=o(" \u2014 "),Ase=a("a"),Cpt=o("FlaxElectraForTokenClassification"),wpt=o(" (ELECTRA model)"),Apt=l(),TL=a("li"),Uxe=a("strong"),Lpt=o("roberta"),ypt=o(" \u2014 "),Lse=a("a"),xpt=o("FlaxRobertaForTokenClassification"),$pt=o(" (RoBERTa model)"),kpt=l(),ML=a("li"),Hxe=a("strong"),Spt=o("roformer"),Rpt=o(" \u2014 "),yse=a("a"),Ppt=o("FlaxRoFormerForTokenClassification"),Bpt=o(" (RoFormer model)"),Ipt=l(),EL=a("li"),Jxe=a("strong"),Npt=o("xlm-roberta"),qpt=o(" \u2014 "),xse=a("a"),jpt=o("FlaxXLMRobertaForTokenClassification"),Dpt=o(" (XLM-RoBERTa model)"),Gpt=l(),F(CL.$$.fragment),ZZe=l(),lf=a("h2"),wL=a("a"),Yxe=a("span"),F(IR.$$.fragment),Opt=l(),Kxe=a("span"),Vpt=o("FlaxAutoModelForMultipleChoice"),eeo=l(),$r=a("div"),F(NR.$$.fragment),Xpt=l(),df=a("p"),zpt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),$se=a("a"),Qpt=o("from_pretrained()"),Wpt=o(" class method or the "),kse=a("a"),Upt=o("from_config()"),Hpt=o(` class
method.`),Jpt=l(),qR=a("p"),Ypt=o("This class cannot be instantiated directly using "),Zxe=a("code"),Kpt=o("__init__()"),Zpt=o(" (throws an error)."),e_t=l(),ha=a("div"),F(jR.$$.fragment),o_t=l(),e$e=a("p"),r_t=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),t_t=l(),cf=a("p"),a_t=o(`Note:
Loading a model from its configuration file does `),o$e=a("strong"),n_t=o("not"),s_t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Sse=a("a"),l_t=o("from_pretrained()"),i_t=o(" to load the model weights."),d_t=l(),F(AL.$$.fragment),c_t=l(),st=a("div"),F(DR.$$.fragment),m_t=l(),r$e=a("p"),f_t=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),g_t=l(),Un=a("p"),h_t=o("The model class to instantiate is selected based on the "),t$e=a("code"),u_t=o("model_type"),p_t=o(` property of the config object (either
passed as an argument or loaded from `),a$e=a("code"),__t=o("pretrained_model_name_or_path"),b_t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n$e=a("code"),v_t=o("pretrained_model_name_or_path"),F_t=o(":"),T_t=l(),ze=a("ul"),LL=a("li"),s$e=a("strong"),M_t=o("albert"),E_t=o(" \u2014 "),Rse=a("a"),C_t=o("FlaxAlbertForMultipleChoice"),w_t=o(" (ALBERT model)"),A_t=l(),yL=a("li"),l$e=a("strong"),L_t=o("bert"),y_t=o(" \u2014 "),Pse=a("a"),x_t=o("FlaxBertForMultipleChoice"),$_t=o(" (BERT model)"),k_t=l(),xL=a("li"),i$e=a("strong"),S_t=o("big_bird"),R_t=o(" \u2014 "),Bse=a("a"),P_t=o("FlaxBigBirdForMultipleChoice"),B_t=o(" (BigBird model)"),I_t=l(),$L=a("li"),d$e=a("strong"),N_t=o("distilbert"),q_t=o(" \u2014 "),Ise=a("a"),j_t=o("FlaxDistilBertForMultipleChoice"),D_t=o(" (DistilBERT model)"),G_t=l(),kL=a("li"),c$e=a("strong"),O_t=o("electra"),V_t=o(" \u2014 "),Nse=a("a"),X_t=o("FlaxElectraForMultipleChoice"),z_t=o(" (ELECTRA model)"),Q_t=l(),SL=a("li"),m$e=a("strong"),W_t=o("roberta"),U_t=o(" \u2014 "),qse=a("a"),H_t=o("FlaxRobertaForMultipleChoice"),J_t=o(" (RoBERTa model)"),Y_t=l(),RL=a("li"),f$e=a("strong"),K_t=o("roformer"),Z_t=o(" \u2014 "),jse=a("a"),ebt=o("FlaxRoFormerForMultipleChoice"),obt=o(" (RoFormer model)"),rbt=l(),PL=a("li"),g$e=a("strong"),tbt=o("xlm-roberta"),abt=o(" \u2014 "),Dse=a("a"),nbt=o("FlaxXLMRobertaForMultipleChoice"),sbt=o(" (XLM-RoBERTa model)"),lbt=l(),F(BL.$$.fragment),oeo=l(),mf=a("h2"),IL=a("a"),h$e=a("span"),F(GR.$$.fragment),ibt=l(),u$e=a("span"),dbt=o("FlaxAutoModelForNextSentencePrediction"),reo=l(),kr=a("div"),F(OR.$$.fragment),cbt=l(),ff=a("p"),mbt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Gse=a("a"),fbt=o("from_pretrained()"),gbt=o(" class method or the "),Ose=a("a"),hbt=o("from_config()"),ubt=o(` class
method.`),pbt=l(),VR=a("p"),_bt=o("This class cannot be instantiated directly using "),p$e=a("code"),bbt=o("__init__()"),vbt=o(" (throws an error)."),Fbt=l(),ua=a("div"),F(XR.$$.fragment),Tbt=l(),_$e=a("p"),Mbt=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Ebt=l(),gf=a("p"),Cbt=o(`Note:
Loading a model from its configuration file does `),b$e=a("strong"),wbt=o("not"),Abt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vse=a("a"),Lbt=o("from_pretrained()"),ybt=o(" to load the model weights."),xbt=l(),F(NL.$$.fragment),$bt=l(),lt=a("div"),F(zR.$$.fragment),kbt=l(),v$e=a("p"),Sbt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Rbt=l(),Hn=a("p"),Pbt=o("The model class to instantiate is selected based on the "),F$e=a("code"),Bbt=o("model_type"),Ibt=o(` property of the config object (either
passed as an argument or loaded from `),T$e=a("code"),Nbt=o("pretrained_model_name_or_path"),qbt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M$e=a("code"),jbt=o("pretrained_model_name_or_path"),Dbt=o(":"),Gbt=l(),E$e=a("ul"),qL=a("li"),C$e=a("strong"),Obt=o("bert"),Vbt=o(" \u2014 "),Xse=a("a"),Xbt=o("FlaxBertForNextSentencePrediction"),zbt=o(" (BERT model)"),Qbt=l(),F(jL.$$.fragment),teo=l(),hf=a("h2"),DL=a("a"),w$e=a("span"),F(QR.$$.fragment),Wbt=l(),A$e=a("span"),Ubt=o("FlaxAutoModelForImageClassification"),aeo=l(),Sr=a("div"),F(WR.$$.fragment),Hbt=l(),uf=a("p"),Jbt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),zse=a("a"),Ybt=o("from_pretrained()"),Kbt=o(" class method or the "),Qse=a("a"),Zbt=o("from_config()"),e2t=o(` class
method.`),o2t=l(),UR=a("p"),r2t=o("This class cannot be instantiated directly using "),L$e=a("code"),t2t=o("__init__()"),a2t=o(" (throws an error)."),n2t=l(),pa=a("div"),F(HR.$$.fragment),s2t=l(),y$e=a("p"),l2t=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),i2t=l(),pf=a("p"),d2t=o(`Note:
Loading a model from its configuration file does `),x$e=a("strong"),c2t=o("not"),m2t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Wse=a("a"),f2t=o("from_pretrained()"),g2t=o(" to load the model weights."),h2t=l(),F(GL.$$.fragment),u2t=l(),it=a("div"),F(JR.$$.fragment),p2t=l(),$$e=a("p"),_2t=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),b2t=l(),Jn=a("p"),v2t=o("The model class to instantiate is selected based on the "),k$e=a("code"),F2t=o("model_type"),T2t=o(` property of the config object (either
passed as an argument or loaded from `),S$e=a("code"),M2t=o("pretrained_model_name_or_path"),E2t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R$e=a("code"),C2t=o("pretrained_model_name_or_path"),w2t=o(":"),A2t=l(),YR=a("ul"),OL=a("li"),P$e=a("strong"),L2t=o("beit"),y2t=o(" \u2014 "),Use=a("a"),x2t=o("FlaxBeitForImageClassification"),$2t=o(" (BEiT model)"),k2t=l(),VL=a("li"),B$e=a("strong"),S2t=o("vit"),R2t=o(" \u2014 "),Hse=a("a"),P2t=o("FlaxViTForImageClassification"),B2t=o(" (ViT model)"),I2t=l(),F(XL.$$.fragment),neo=l(),_f=a("h2"),zL=a("a"),I$e=a("span"),F(KR.$$.fragment),N2t=l(),N$e=a("span"),q2t=o("FlaxAutoModelForVision2Seq"),seo=l(),Rr=a("div"),F(ZR.$$.fragment),j2t=l(),bf=a("p"),D2t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Jse=a("a"),G2t=o("from_pretrained()"),O2t=o(" class method or the "),Yse=a("a"),V2t=o("from_config()"),X2t=o(` class
method.`),z2t=l(),eP=a("p"),Q2t=o("This class cannot be instantiated directly using "),q$e=a("code"),W2t=o("__init__()"),U2t=o(" (throws an error)."),H2t=l(),_a=a("div"),F(oP.$$.fragment),J2t=l(),j$e=a("p"),Y2t=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),K2t=l(),vf=a("p"),Z2t=o(`Note:
Loading a model from its configuration file does `),D$e=a("strong"),e1t=o("not"),o1t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kse=a("a"),r1t=o("from_pretrained()"),t1t=o(" to load the model weights."),a1t=l(),F(QL.$$.fragment),n1t=l(),dt=a("div"),F(rP.$$.fragment),s1t=l(),G$e=a("p"),l1t=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),i1t=l(),Yn=a("p"),d1t=o("The model class to instantiate is selected based on the "),O$e=a("code"),c1t=o("model_type"),m1t=o(` property of the config object (either
passed as an argument or loaded from `),V$e=a("code"),f1t=o("pretrained_model_name_or_path"),g1t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X$e=a("code"),h1t=o("pretrained_model_name_or_path"),u1t=o(":"),p1t=l(),z$e=a("ul"),WL=a("li"),Q$e=a("strong"),_1t=o("vision-encoder-decoder"),b1t=o(" \u2014 "),Zse=a("a"),v1t=o("FlaxVisionEncoderDecoderModel"),F1t=o(" (Vision Encoder decoder model)"),T1t=l(),F(UL.$$.fragment),this.h()},l(m){const _=xga('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(m),u=n(m,"H1",{class:!0});var tP=s(u);f=n(tP,"A",{id:!0,class:!0,href:!0});var W$e=s(f);p=n(W$e,"SPAN",{});var U$e=s(p);T(d.$$.fragment,U$e),U$e.forEach(t),W$e.forEach(t),h=i(tP),yo=n(tP,"SPAN",{});var H$e=s(yo);rd=r(H$e,"Auto Classes"),H$e.forEach(t),tP.forEach(t),Ef=i(m),pt=n(m,"P",{});var aP=s(pt);td=r(aP,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ad=n(aP,"CODE",{});var J$e=s(ad);C9=r(J$e,"from_pretrained()"),J$e.forEach(t),Cf=r(aP,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),aP.forEach(t),Ve=i(m),He=n(m,"P",{});var Kn=s(He);nd=r(Kn,"Instantiating one of "),Zn=n(Kn,"A",{href:!0});var Y$e=s(Zn);w9=r(Y$e,"AutoConfig"),Y$e.forEach(t),es=r(Kn,", "),os=n(Kn,"A",{href:!0});var K$e=s(os);A9=r(K$e,"AutoModel"),K$e.forEach(t),sd=r(Kn,`, and
`),rs=n(Kn,"A",{href:!0});var Z$e=s(rs);L9=r(Z$e,"AutoTokenizer"),Z$e.forEach(t),ld=r(Kn," will directly create a class of the relevant architecture. For instance"),Kn.forEach(t),wf=i(m),T(Qa.$$.fragment,m),Je=i(m),Ae=n(m,"P",{});var nP=s(Ae);yB=r(nP,"will create a model that is an instance of "),id=n(nP,"A",{href:!0});var eke=s(id);xB=r(eke,"BertModel"),eke.forEach(t),$B=r(nP,"."),nP.forEach(t),xo=i(m),Wa=n(m,"P",{});var sP=s(Wa);kB=r(sP,"There is one class of "),Af=n(sP,"CODE",{});var oke=s(Af);SB=r(oke,"AutoModel"),oke.forEach(t),Cro=r(sP," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),sP.forEach(t),UYe=i(m),dd=n(m,"H2",{class:!0});var lP=s(dd);Lf=n(lP,"A",{id:!0,class:!0,href:!0});var rke=s(Lf);ade=n(rke,"SPAN",{});var tke=s(ade);T(y9.$$.fragment,tke),tke.forEach(t),rke.forEach(t),wro=i(lP),nde=n(lP,"SPAN",{});var ake=s(nde);Aro=r(ake,"Extending the Auto Classes"),ake.forEach(t),lP.forEach(t),HYe=i(m),ts=n(m,"P",{});var Ff=s(ts);Lro=r(Ff,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),sde=n(Ff,"CODE",{});var nke=s(sde);yro=r(nke,"NewModel"),nke.forEach(t),xro=r(Ff,", make sure you have a "),lde=n(Ff,"CODE",{});var ske=s(lde);$ro=r(ske,"NewModelConfig"),ske.forEach(t),kro=r(Ff,` then you can add those to the auto
classes like this:`),Ff.forEach(t),JYe=i(m),T(x9.$$.fragment,m),YYe=i(m),RB=n(m,"P",{});var lke=s(RB);Sro=r(lke,"You will then be able to use the auto classes like you would usually do!"),lke.forEach(t),KYe=i(m),T(yf.$$.fragment,m),ZYe=i(m),cd=n(m,"H2",{class:!0});var iP=s(cd);xf=n(iP,"A",{id:!0,class:!0,href:!0});var ike=s(xf);ide=n(ike,"SPAN",{});var dke=s(ide);T($9.$$.fragment,dke),dke.forEach(t),ike.forEach(t),Rro=i(iP),dde=n(iP,"SPAN",{});var cke=s(dde);Pro=r(cke,"AutoConfig"),cke.forEach(t),iP.forEach(t),eKe=i(m),$o=n(m,"DIV",{class:!0});var ht=s($o);T(k9.$$.fragment,ht),Bro=i(ht),S9=n(ht,"P",{});var dP=s(S9);Iro=r(dP,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),PB=n(dP,"A",{href:!0});var mke=s(PB);Nro=r(mke,"from_pretrained()"),mke.forEach(t),qro=r(dP," class method."),dP.forEach(t),jro=i(ht),R9=n(ht,"P",{});var cP=s(R9);Dro=r(cP,"This class cannot be instantiated directly using "),cde=n(cP,"CODE",{});var fke=s(cde);Gro=r(fke,"__init__()"),fke.forEach(t),Oro=r(cP," (throws an error)."),cP.forEach(t),Vro=i(ht),Pr=n(ht,"DIV",{class:!0});var ut=s(Pr);T(P9.$$.fragment,ut),Xro=i(ut),mde=n(ut,"P",{});var gke=s(mde);zro=r(gke,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),gke.forEach(t),Qro=i(ut),md=n(ut,"P",{});var Tf=s(md);Wro=r(Tf,"The configuration class to instantiate is selected based on the "),fde=n(Tf,"CODE",{});var hke=s(fde);Uro=r(hke,"model_type"),hke.forEach(t),Hro=r(Tf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),gde=n(Tf,"CODE",{});var uke=s(gde);Jro=r(uke,"pretrained_model_name_or_path"),uke.forEach(t),Yro=r(Tf,":"),Tf.forEach(t),Kro=i(ut),A=n(ut,"UL",{});var L=s(A);$f=n(L,"LI",{});var HL=s($f);hde=n(HL,"STRONG",{});var pke=s(hde);Zro=r(pke,"albert"),pke.forEach(t),eto=r(HL," \u2014 "),BB=n(HL,"A",{href:!0});var _ke=s(BB);oto=r(_ke,"AlbertConfig"),_ke.forEach(t),rto=r(HL," (ALBERT model)"),HL.forEach(t),tto=i(L),kf=n(L,"LI",{});var JL=s(kf);ude=n(JL,"STRONG",{});var bke=s(ude);ato=r(bke,"bart"),bke.forEach(t),nto=r(JL," \u2014 "),IB=n(JL,"A",{href:!0});var vke=s(IB);sto=r(vke,"BartConfig"),vke.forEach(t),lto=r(JL," (BART model)"),JL.forEach(t),ito=i(L),Sf=n(L,"LI",{});var YL=s(Sf);pde=n(YL,"STRONG",{});var Fke=s(pde);dto=r(Fke,"beit"),Fke.forEach(t),cto=r(YL," \u2014 "),NB=n(YL,"A",{href:!0});var Tke=s(NB);mto=r(Tke,"BeitConfig"),Tke.forEach(t),fto=r(YL," (BEiT model)"),YL.forEach(t),gto=i(L),Rf=n(L,"LI",{});var KL=s(Rf);_de=n(KL,"STRONG",{});var Mke=s(_de);hto=r(Mke,"bert"),Mke.forEach(t),uto=r(KL," \u2014 "),qB=n(KL,"A",{href:!0});var Eke=s(qB);pto=r(Eke,"BertConfig"),Eke.forEach(t),_to=r(KL," (BERT model)"),KL.forEach(t),bto=i(L),Pf=n(L,"LI",{});var ZL=s(Pf);bde=n(ZL,"STRONG",{});var Cke=s(bde);vto=r(Cke,"bert-generation"),Cke.forEach(t),Fto=r(ZL," \u2014 "),jB=n(ZL,"A",{href:!0});var wke=s(jB);Tto=r(wke,"BertGenerationConfig"),wke.forEach(t),Mto=r(ZL," (Bert Generation model)"),ZL.forEach(t),Eto=i(L),Bf=n(L,"LI",{});var ey=s(Bf);vde=n(ey,"STRONG",{});var Ake=s(vde);Cto=r(Ake,"big_bird"),Ake.forEach(t),wto=r(ey," \u2014 "),DB=n(ey,"A",{href:!0});var Lke=s(DB);Ato=r(Lke,"BigBirdConfig"),Lke.forEach(t),Lto=r(ey," (BigBird model)"),ey.forEach(t),yto=i(L),If=n(L,"LI",{});var oy=s(If);Fde=n(oy,"STRONG",{});var yke=s(Fde);xto=r(yke,"bigbird_pegasus"),yke.forEach(t),$to=r(oy," \u2014 "),GB=n(oy,"A",{href:!0});var xke=s(GB);kto=r(xke,"BigBirdPegasusConfig"),xke.forEach(t),Sto=r(oy," (BigBird-Pegasus model)"),oy.forEach(t),Rto=i(L),Nf=n(L,"LI",{});var ry=s(Nf);Tde=n(ry,"STRONG",{});var $ke=s(Tde);Pto=r($ke,"blenderbot"),$ke.forEach(t),Bto=r(ry," \u2014 "),OB=n(ry,"A",{href:!0});var kke=s(OB);Ito=r(kke,"BlenderbotConfig"),kke.forEach(t),Nto=r(ry," (Blenderbot model)"),ry.forEach(t),qto=i(L),qf=n(L,"LI",{});var ty=s(qf);Mde=n(ty,"STRONG",{});var Ske=s(Mde);jto=r(Ske,"blenderbot-small"),Ske.forEach(t),Dto=r(ty," \u2014 "),VB=n(ty,"A",{href:!0});var Rke=s(VB);Gto=r(Rke,"BlenderbotSmallConfig"),Rke.forEach(t),Oto=r(ty," (BlenderbotSmall model)"),ty.forEach(t),Vto=i(L),jf=n(L,"LI",{});var ay=s(jf);Ede=n(ay,"STRONG",{});var Pke=s(Ede);Xto=r(Pke,"bloom"),Pke.forEach(t),zto=r(ay," \u2014 "),XB=n(ay,"A",{href:!0});var Bke=s(XB);Qto=r(Bke,"BloomConfig"),Bke.forEach(t),Wto=r(ay," (BLOOM model)"),ay.forEach(t),Uto=i(L),Df=n(L,"LI",{});var ny=s(Df);Cde=n(ny,"STRONG",{});var Ike=s(Cde);Hto=r(Ike,"camembert"),Ike.forEach(t),Jto=r(ny," \u2014 "),zB=n(ny,"A",{href:!0});var Nke=s(zB);Yto=r(Nke,"CamembertConfig"),Nke.forEach(t),Kto=r(ny," (CamemBERT model)"),ny.forEach(t),Zto=i(L),Gf=n(L,"LI",{});var sy=s(Gf);wde=n(sy,"STRONG",{});var qke=s(wde);eao=r(qke,"canine"),qke.forEach(t),oao=r(sy," \u2014 "),QB=n(sy,"A",{href:!0});var jke=s(QB);rao=r(jke,"CanineConfig"),jke.forEach(t),tao=r(sy," (CANINE model)"),sy.forEach(t),aao=i(L),Of=n(L,"LI",{});var ly=s(Of);Ade=n(ly,"STRONG",{});var Dke=s(Ade);nao=r(Dke,"clip"),Dke.forEach(t),sao=r(ly," \u2014 "),WB=n(ly,"A",{href:!0});var Gke=s(WB);lao=r(Gke,"CLIPConfig"),Gke.forEach(t),iao=r(ly," (CLIP model)"),ly.forEach(t),dao=i(L),Vf=n(L,"LI",{});var iy=s(Vf);Lde=n(iy,"STRONG",{});var Oke=s(Lde);cao=r(Oke,"codegen"),Oke.forEach(t),mao=r(iy," \u2014 "),UB=n(iy,"A",{href:!0});var Vke=s(UB);fao=r(Vke,"CodeGenConfig"),Vke.forEach(t),gao=r(iy," (CodeGen model)"),iy.forEach(t),hao=i(L),Xf=n(L,"LI",{});var dy=s(Xf);yde=n(dy,"STRONG",{});var Xke=s(yde);uao=r(Xke,"convbert"),Xke.forEach(t),pao=r(dy," \u2014 "),HB=n(dy,"A",{href:!0});var zke=s(HB);_ao=r(zke,"ConvBertConfig"),zke.forEach(t),bao=r(dy," (ConvBERT model)"),dy.forEach(t),vao=i(L),zf=n(L,"LI",{});var cy=s(zf);xde=n(cy,"STRONG",{});var Qke=s(xde);Fao=r(Qke,"convnext"),Qke.forEach(t),Tao=r(cy," \u2014 "),JB=n(cy,"A",{href:!0});var Wke=s(JB);Mao=r(Wke,"ConvNextConfig"),Wke.forEach(t),Eao=r(cy," (ConvNeXT model)"),cy.forEach(t),Cao=i(L),Qf=n(L,"LI",{});var my=s(Qf);$de=n(my,"STRONG",{});var Uke=s($de);wao=r(Uke,"ctrl"),Uke.forEach(t),Aao=r(my," \u2014 "),YB=n(my,"A",{href:!0});var Hke=s(YB);Lao=r(Hke,"CTRLConfig"),Hke.forEach(t),yao=r(my," (CTRL model)"),my.forEach(t),xao=i(L),Wf=n(L,"LI",{});var fy=s(Wf);kde=n(fy,"STRONG",{});var Jke=s(kde);$ao=r(Jke,"cvt"),Jke.forEach(t),kao=r(fy," \u2014 "),KB=n(fy,"A",{href:!0});var Yke=s(KB);Sao=r(Yke,"CvtConfig"),Yke.forEach(t),Rao=r(fy," (CvT model)"),fy.forEach(t),Pao=i(L),Uf=n(L,"LI",{});var gy=s(Uf);Sde=n(gy,"STRONG",{});var Kke=s(Sde);Bao=r(Kke,"data2vec-audio"),Kke.forEach(t),Iao=r(gy," \u2014 "),ZB=n(gy,"A",{href:!0});var Zke=s(ZB);Nao=r(Zke,"Data2VecAudioConfig"),Zke.forEach(t),qao=r(gy," (Data2VecAudio model)"),gy.forEach(t),jao=i(L),Hf=n(L,"LI",{});var hy=s(Hf);Rde=n(hy,"STRONG",{});var eSe=s(Rde);Dao=r(eSe,"data2vec-text"),eSe.forEach(t),Gao=r(hy," \u2014 "),eI=n(hy,"A",{href:!0});var oSe=s(eI);Oao=r(oSe,"Data2VecTextConfig"),oSe.forEach(t),Vao=r(hy," (Data2VecText model)"),hy.forEach(t),Xao=i(L),Jf=n(L,"LI",{});var uy=s(Jf);Pde=n(uy,"STRONG",{});var rSe=s(Pde);zao=r(rSe,"data2vec-vision"),rSe.forEach(t),Qao=r(uy," \u2014 "),oI=n(uy,"A",{href:!0});var tSe=s(oI);Wao=r(tSe,"Data2VecVisionConfig"),tSe.forEach(t),Uao=r(uy," (Data2VecVision model)"),uy.forEach(t),Hao=i(L),Yf=n(L,"LI",{});var py=s(Yf);Bde=n(py,"STRONG",{});var aSe=s(Bde);Jao=r(aSe,"deberta"),aSe.forEach(t),Yao=r(py," \u2014 "),rI=n(py,"A",{href:!0});var nSe=s(rI);Kao=r(nSe,"DebertaConfig"),nSe.forEach(t),Zao=r(py," (DeBERTa model)"),py.forEach(t),eno=i(L),Kf=n(L,"LI",{});var _y=s(Kf);Ide=n(_y,"STRONG",{});var sSe=s(Ide);ono=r(sSe,"deberta-v2"),sSe.forEach(t),rno=r(_y," \u2014 "),tI=n(_y,"A",{href:!0});var lSe=s(tI);tno=r(lSe,"DebertaV2Config"),lSe.forEach(t),ano=r(_y," (DeBERTa-v2 model)"),_y.forEach(t),nno=i(L),Zf=n(L,"LI",{});var by=s(Zf);Nde=n(by,"STRONG",{});var iSe=s(Nde);sno=r(iSe,"decision_transformer"),iSe.forEach(t),lno=r(by," \u2014 "),aI=n(by,"A",{href:!0});var dSe=s(aI);ino=r(dSe,"DecisionTransformerConfig"),dSe.forEach(t),dno=r(by," (Decision Transformer model)"),by.forEach(t),cno=i(L),eg=n(L,"LI",{});var vy=s(eg);qde=n(vy,"STRONG",{});var cSe=s(qde);mno=r(cSe,"deformable_detr"),cSe.forEach(t),fno=r(vy," \u2014 "),nI=n(vy,"A",{href:!0});var mSe=s(nI);gno=r(mSe,"DeformableDetrConfig"),mSe.forEach(t),hno=r(vy," (Deformable DETR model)"),vy.forEach(t),uno=i(L),og=n(L,"LI",{});var Fy=s(og);jde=n(Fy,"STRONG",{});var fSe=s(jde);pno=r(fSe,"deit"),fSe.forEach(t),_no=r(Fy," \u2014 "),sI=n(Fy,"A",{href:!0});var gSe=s(sI);bno=r(gSe,"DeiTConfig"),gSe.forEach(t),vno=r(Fy," (DeiT model)"),Fy.forEach(t),Fno=i(L),rg=n(L,"LI",{});var hSe=s(rg);Dde=n(hSe,"STRONG",{});var E1t=s(Dde);Tno=r(E1t,"detr"),E1t.forEach(t),Mno=r(hSe," \u2014 "),lI=n(hSe,"A",{href:!0});var C1t=s(lI);Eno=r(C1t,"DetrConfig"),C1t.forEach(t),Cno=r(hSe," (DETR model)"),hSe.forEach(t),wno=i(L),tg=n(L,"LI",{});var uSe=s(tg);Gde=n(uSe,"STRONG",{});var w1t=s(Gde);Ano=r(w1t,"distilbert"),w1t.forEach(t),Lno=r(uSe," \u2014 "),iI=n(uSe,"A",{href:!0});var A1t=s(iI);yno=r(A1t,"DistilBertConfig"),A1t.forEach(t),xno=r(uSe," (DistilBERT model)"),uSe.forEach(t),$no=i(L),ag=n(L,"LI",{});var pSe=s(ag);Ode=n(pSe,"STRONG",{});var L1t=s(Ode);kno=r(L1t,"donut-swin"),L1t.forEach(t),Sno=r(pSe," \u2014 "),dI=n(pSe,"A",{href:!0});var y1t=s(dI);Rno=r(y1t,"DonutSwinConfig"),y1t.forEach(t),Pno=r(pSe," (DonutSwin model)"),pSe.forEach(t),Bno=i(L),ng=n(L,"LI",{});var _Se=s(ng);Vde=n(_Se,"STRONG",{});var x1t=s(Vde);Ino=r(x1t,"dpr"),x1t.forEach(t),Nno=r(_Se," \u2014 "),cI=n(_Se,"A",{href:!0});var $1t=s(cI);qno=r($1t,"DPRConfig"),$1t.forEach(t),jno=r(_Se," (DPR model)"),_Se.forEach(t),Dno=i(L),sg=n(L,"LI",{});var bSe=s(sg);Xde=n(bSe,"STRONG",{});var k1t=s(Xde);Gno=r(k1t,"dpt"),k1t.forEach(t),Ono=r(bSe," \u2014 "),mI=n(bSe,"A",{href:!0});var S1t=s(mI);Vno=r(S1t,"DPTConfig"),S1t.forEach(t),Xno=r(bSe," (DPT model)"),bSe.forEach(t),zno=i(L),lg=n(L,"LI",{});var vSe=s(lg);zde=n(vSe,"STRONG",{});var R1t=s(zde);Qno=r(R1t,"electra"),R1t.forEach(t),Wno=r(vSe," \u2014 "),fI=n(vSe,"A",{href:!0});var P1t=s(fI);Uno=r(P1t,"ElectraConfig"),P1t.forEach(t),Hno=r(vSe," (ELECTRA model)"),vSe.forEach(t),Jno=i(L),ig=n(L,"LI",{});var FSe=s(ig);Qde=n(FSe,"STRONG",{});var B1t=s(Qde);Yno=r(B1t,"encoder-decoder"),B1t.forEach(t),Kno=r(FSe," \u2014 "),gI=n(FSe,"A",{href:!0});var I1t=s(gI);Zno=r(I1t,"EncoderDecoderConfig"),I1t.forEach(t),eso=r(FSe," (Encoder decoder model)"),FSe.forEach(t),oso=i(L),dg=n(L,"LI",{});var TSe=s(dg);Wde=n(TSe,"STRONG",{});var N1t=s(Wde);rso=r(N1t,"ernie"),N1t.forEach(t),tso=r(TSe," \u2014 "),hI=n(TSe,"A",{href:!0});var q1t=s(hI);aso=r(q1t,"ErnieConfig"),q1t.forEach(t),nso=r(TSe," (ERNIE model)"),TSe.forEach(t),sso=i(L),cg=n(L,"LI",{});var MSe=s(cg);Ude=n(MSe,"STRONG",{});var j1t=s(Ude);lso=r(j1t,"flaubert"),j1t.forEach(t),iso=r(MSe," \u2014 "),uI=n(MSe,"A",{href:!0});var D1t=s(uI);dso=r(D1t,"FlaubertConfig"),D1t.forEach(t),cso=r(MSe," (FlauBERT model)"),MSe.forEach(t),mso=i(L),mg=n(L,"LI",{});var ESe=s(mg);Hde=n(ESe,"STRONG",{});var G1t=s(Hde);fso=r(G1t,"flava"),G1t.forEach(t),gso=r(ESe," \u2014 "),pI=n(ESe,"A",{href:!0});var O1t=s(pI);hso=r(O1t,"FlavaConfig"),O1t.forEach(t),uso=r(ESe," (FLAVA model)"),ESe.forEach(t),pso=i(L),fg=n(L,"LI",{});var CSe=s(fg);Jde=n(CSe,"STRONG",{});var V1t=s(Jde);_so=r(V1t,"fnet"),V1t.forEach(t),bso=r(CSe," \u2014 "),_I=n(CSe,"A",{href:!0});var X1t=s(_I);vso=r(X1t,"FNetConfig"),X1t.forEach(t),Fso=r(CSe," (FNet model)"),CSe.forEach(t),Tso=i(L),gg=n(L,"LI",{});var wSe=s(gg);Yde=n(wSe,"STRONG",{});var z1t=s(Yde);Mso=r(z1t,"fsmt"),z1t.forEach(t),Eso=r(wSe," \u2014 "),bI=n(wSe,"A",{href:!0});var Q1t=s(bI);Cso=r(Q1t,"FSMTConfig"),Q1t.forEach(t),wso=r(wSe," (FairSeq Machine-Translation model)"),wSe.forEach(t),Aso=i(L),hg=n(L,"LI",{});var ASe=s(hg);Kde=n(ASe,"STRONG",{});var W1t=s(Kde);Lso=r(W1t,"funnel"),W1t.forEach(t),yso=r(ASe," \u2014 "),vI=n(ASe,"A",{href:!0});var U1t=s(vI);xso=r(U1t,"FunnelConfig"),U1t.forEach(t),$so=r(ASe," (Funnel Transformer model)"),ASe.forEach(t),kso=i(L),ug=n(L,"LI",{});var LSe=s(ug);Zde=n(LSe,"STRONG",{});var H1t=s(Zde);Sso=r(H1t,"glpn"),H1t.forEach(t),Rso=r(LSe," \u2014 "),FI=n(LSe,"A",{href:!0});var J1t=s(FI);Pso=r(J1t,"GLPNConfig"),J1t.forEach(t),Bso=r(LSe," (GLPN model)"),LSe.forEach(t),Iso=i(L),pg=n(L,"LI",{});var ySe=s(pg);ece=n(ySe,"STRONG",{});var Y1t=s(ece);Nso=r(Y1t,"gpt2"),Y1t.forEach(t),qso=r(ySe," \u2014 "),TI=n(ySe,"A",{href:!0});var K1t=s(TI);jso=r(K1t,"GPT2Config"),K1t.forEach(t),Dso=r(ySe," (OpenAI GPT-2 model)"),ySe.forEach(t),Gso=i(L),_g=n(L,"LI",{});var xSe=s(_g);oce=n(xSe,"STRONG",{});var Z1t=s(oce);Oso=r(Z1t,"gpt_neo"),Z1t.forEach(t),Vso=r(xSe," \u2014 "),MI=n(xSe,"A",{href:!0});var evt=s(MI);Xso=r(evt,"GPTNeoConfig"),evt.forEach(t),zso=r(xSe," (GPT Neo model)"),xSe.forEach(t),Qso=i(L),bg=n(L,"LI",{});var $Se=s(bg);rce=n($Se,"STRONG",{});var ovt=s(rce);Wso=r(ovt,"gpt_neox"),ovt.forEach(t),Uso=r($Se," \u2014 "),EI=n($Se,"A",{href:!0});var rvt=s(EI);Hso=r(rvt,"GPTNeoXConfig"),rvt.forEach(t),Jso=r($Se," (GPT NeoX model)"),$Se.forEach(t),Yso=i(L),vg=n(L,"LI",{});var kSe=s(vg);tce=n(kSe,"STRONG",{});var tvt=s(tce);Kso=r(tvt,"gptj"),tvt.forEach(t),Zso=r(kSe," \u2014 "),CI=n(kSe,"A",{href:!0});var avt=s(CI);elo=r(avt,"GPTJConfig"),avt.forEach(t),olo=r(kSe," (GPT-J model)"),kSe.forEach(t),rlo=i(L),Fg=n(L,"LI",{});var SSe=s(Fg);ace=n(SSe,"STRONG",{});var nvt=s(ace);tlo=r(nvt,"groupvit"),nvt.forEach(t),alo=r(SSe," \u2014 "),wI=n(SSe,"A",{href:!0});var svt=s(wI);nlo=r(svt,"GroupViTConfig"),svt.forEach(t),slo=r(SSe," (GroupViT model)"),SSe.forEach(t),llo=i(L),Tg=n(L,"LI",{});var RSe=s(Tg);nce=n(RSe,"STRONG",{});var lvt=s(nce);ilo=r(lvt,"hubert"),lvt.forEach(t),dlo=r(RSe," \u2014 "),AI=n(RSe,"A",{href:!0});var ivt=s(AI);clo=r(ivt,"HubertConfig"),ivt.forEach(t),mlo=r(RSe," (Hubert model)"),RSe.forEach(t),flo=i(L),Mg=n(L,"LI",{});var PSe=s(Mg);sce=n(PSe,"STRONG",{});var dvt=s(sce);glo=r(dvt,"ibert"),dvt.forEach(t),hlo=r(PSe," \u2014 "),LI=n(PSe,"A",{href:!0});var cvt=s(LI);ulo=r(cvt,"IBertConfig"),cvt.forEach(t),plo=r(PSe," (I-BERT model)"),PSe.forEach(t),_lo=i(L),Eg=n(L,"LI",{});var BSe=s(Eg);lce=n(BSe,"STRONG",{});var mvt=s(lce);blo=r(mvt,"imagegpt"),mvt.forEach(t),vlo=r(BSe," \u2014 "),yI=n(BSe,"A",{href:!0});var fvt=s(yI);Flo=r(fvt,"ImageGPTConfig"),fvt.forEach(t),Tlo=r(BSe," (ImageGPT model)"),BSe.forEach(t),Mlo=i(L),Cg=n(L,"LI",{});var ISe=s(Cg);ice=n(ISe,"STRONG",{});var gvt=s(ice);Elo=r(gvt,"layoutlm"),gvt.forEach(t),Clo=r(ISe," \u2014 "),xI=n(ISe,"A",{href:!0});var hvt=s(xI);wlo=r(hvt,"LayoutLMConfig"),hvt.forEach(t),Alo=r(ISe," (LayoutLM model)"),ISe.forEach(t),Llo=i(L),wg=n(L,"LI",{});var NSe=s(wg);dce=n(NSe,"STRONG",{});var uvt=s(dce);ylo=r(uvt,"layoutlmv2"),uvt.forEach(t),xlo=r(NSe," \u2014 "),$I=n(NSe,"A",{href:!0});var pvt=s($I);$lo=r(pvt,"LayoutLMv2Config"),pvt.forEach(t),klo=r(NSe," (LayoutLMv2 model)"),NSe.forEach(t),Slo=i(L),Ag=n(L,"LI",{});var qSe=s(Ag);cce=n(qSe,"STRONG",{});var _vt=s(cce);Rlo=r(_vt,"layoutlmv3"),_vt.forEach(t),Plo=r(qSe," \u2014 "),kI=n(qSe,"A",{href:!0});var bvt=s(kI);Blo=r(bvt,"LayoutLMv3Config"),bvt.forEach(t),Ilo=r(qSe," (LayoutLMv3 model)"),qSe.forEach(t),Nlo=i(L),Lg=n(L,"LI",{});var jSe=s(Lg);mce=n(jSe,"STRONG",{});var vvt=s(mce);qlo=r(vvt,"led"),vvt.forEach(t),jlo=r(jSe," \u2014 "),SI=n(jSe,"A",{href:!0});var Fvt=s(SI);Dlo=r(Fvt,"LEDConfig"),Fvt.forEach(t),Glo=r(jSe," (LED model)"),jSe.forEach(t),Olo=i(L),yg=n(L,"LI",{});var DSe=s(yg);fce=n(DSe,"STRONG",{});var Tvt=s(fce);Vlo=r(Tvt,"levit"),Tvt.forEach(t),Xlo=r(DSe," \u2014 "),RI=n(DSe,"A",{href:!0});var Mvt=s(RI);zlo=r(Mvt,"LevitConfig"),Mvt.forEach(t),Qlo=r(DSe," (LeViT model)"),DSe.forEach(t),Wlo=i(L),xg=n(L,"LI",{});var GSe=s(xg);gce=n(GSe,"STRONG",{});var Evt=s(gce);Ulo=r(Evt,"longformer"),Evt.forEach(t),Hlo=r(GSe," \u2014 "),PI=n(GSe,"A",{href:!0});var Cvt=s(PI);Jlo=r(Cvt,"LongformerConfig"),Cvt.forEach(t),Ylo=r(GSe," (Longformer model)"),GSe.forEach(t),Klo=i(L),$g=n(L,"LI",{});var OSe=s($g);hce=n(OSe,"STRONG",{});var wvt=s(hce);Zlo=r(wvt,"longt5"),wvt.forEach(t),eio=r(OSe," \u2014 "),BI=n(OSe,"A",{href:!0});var Avt=s(BI);oio=r(Avt,"LongT5Config"),Avt.forEach(t),rio=r(OSe," (LongT5 model)"),OSe.forEach(t),tio=i(L),kg=n(L,"LI",{});var VSe=s(kg);uce=n(VSe,"STRONG",{});var Lvt=s(uce);aio=r(Lvt,"luke"),Lvt.forEach(t),nio=r(VSe," \u2014 "),II=n(VSe,"A",{href:!0});var yvt=s(II);sio=r(yvt,"LukeConfig"),yvt.forEach(t),lio=r(VSe," (LUKE model)"),VSe.forEach(t),iio=i(L),Sg=n(L,"LI",{});var XSe=s(Sg);pce=n(XSe,"STRONG",{});var xvt=s(pce);dio=r(xvt,"lxmert"),xvt.forEach(t),cio=r(XSe," \u2014 "),NI=n(XSe,"A",{href:!0});var $vt=s(NI);mio=r($vt,"LxmertConfig"),$vt.forEach(t),fio=r(XSe," (LXMERT model)"),XSe.forEach(t),gio=i(L),Rg=n(L,"LI",{});var zSe=s(Rg);_ce=n(zSe,"STRONG",{});var kvt=s(_ce);hio=r(kvt,"m2m_100"),kvt.forEach(t),uio=r(zSe," \u2014 "),qI=n(zSe,"A",{href:!0});var Svt=s(qI);pio=r(Svt,"M2M100Config"),Svt.forEach(t),_io=r(zSe," (M2M100 model)"),zSe.forEach(t),bio=i(L),Pg=n(L,"LI",{});var QSe=s(Pg);bce=n(QSe,"STRONG",{});var Rvt=s(bce);vio=r(Rvt,"marian"),Rvt.forEach(t),Fio=r(QSe," \u2014 "),jI=n(QSe,"A",{href:!0});var Pvt=s(jI);Tio=r(Pvt,"MarianConfig"),Pvt.forEach(t),Mio=r(QSe," (Marian model)"),QSe.forEach(t),Eio=i(L),Bg=n(L,"LI",{});var WSe=s(Bg);vce=n(WSe,"STRONG",{});var Bvt=s(vce);Cio=r(Bvt,"maskformer"),Bvt.forEach(t),wio=r(WSe," \u2014 "),DI=n(WSe,"A",{href:!0});var Ivt=s(DI);Aio=r(Ivt,"MaskFormerConfig"),Ivt.forEach(t),Lio=r(WSe," (MaskFormer model)"),WSe.forEach(t),yio=i(L),Ig=n(L,"LI",{});var USe=s(Ig);Fce=n(USe,"STRONG",{});var Nvt=s(Fce);xio=r(Nvt,"mbart"),Nvt.forEach(t),$io=r(USe," \u2014 "),GI=n(USe,"A",{href:!0});var qvt=s(GI);kio=r(qvt,"MBartConfig"),qvt.forEach(t),Sio=r(USe," (mBART model)"),USe.forEach(t),Rio=i(L),Ng=n(L,"LI",{});var HSe=s(Ng);Tce=n(HSe,"STRONG",{});var jvt=s(Tce);Pio=r(jvt,"mctct"),jvt.forEach(t),Bio=r(HSe," \u2014 "),OI=n(HSe,"A",{href:!0});var Dvt=s(OI);Iio=r(Dvt,"MCTCTConfig"),Dvt.forEach(t),Nio=r(HSe," (M-CTC-T model)"),HSe.forEach(t),qio=i(L),qg=n(L,"LI",{});var JSe=s(qg);Mce=n(JSe,"STRONG",{});var Gvt=s(Mce);jio=r(Gvt,"megatron-bert"),Gvt.forEach(t),Dio=r(JSe," \u2014 "),VI=n(JSe,"A",{href:!0});var Ovt=s(VI);Gio=r(Ovt,"MegatronBertConfig"),Ovt.forEach(t),Oio=r(JSe," (Megatron-BERT model)"),JSe.forEach(t),Vio=i(L),jg=n(L,"LI",{});var YSe=s(jg);Ece=n(YSe,"STRONG",{});var Vvt=s(Ece);Xio=r(Vvt,"mobilebert"),Vvt.forEach(t),zio=r(YSe," \u2014 "),XI=n(YSe,"A",{href:!0});var Xvt=s(XI);Qio=r(Xvt,"MobileBertConfig"),Xvt.forEach(t),Wio=r(YSe," (MobileBERT model)"),YSe.forEach(t),Uio=i(L),Dg=n(L,"LI",{});var KSe=s(Dg);Cce=n(KSe,"STRONG",{});var zvt=s(Cce);Hio=r(zvt,"mobilevit"),zvt.forEach(t),Jio=r(KSe," \u2014 "),zI=n(KSe,"A",{href:!0});var Qvt=s(zI);Yio=r(Qvt,"MobileViTConfig"),Qvt.forEach(t),Kio=r(KSe," (MobileViT model)"),KSe.forEach(t),Zio=i(L),Gg=n(L,"LI",{});var ZSe=s(Gg);wce=n(ZSe,"STRONG",{});var Wvt=s(wce);edo=r(Wvt,"mpnet"),Wvt.forEach(t),odo=r(ZSe," \u2014 "),QI=n(ZSe,"A",{href:!0});var Uvt=s(QI);rdo=r(Uvt,"MPNetConfig"),Uvt.forEach(t),tdo=r(ZSe," (MPNet model)"),ZSe.forEach(t),ado=i(L),Og=n(L,"LI",{});var eRe=s(Og);Ace=n(eRe,"STRONG",{});var Hvt=s(Ace);ndo=r(Hvt,"mt5"),Hvt.forEach(t),sdo=r(eRe," \u2014 "),WI=n(eRe,"A",{href:!0});var Jvt=s(WI);ldo=r(Jvt,"MT5Config"),Jvt.forEach(t),ido=r(eRe," (MT5 model)"),eRe.forEach(t),ddo=i(L),Vg=n(L,"LI",{});var oRe=s(Vg);Lce=n(oRe,"STRONG",{});var Yvt=s(Lce);cdo=r(Yvt,"mvp"),Yvt.forEach(t),mdo=r(oRe," \u2014 "),UI=n(oRe,"A",{href:!0});var Kvt=s(UI);fdo=r(Kvt,"MvpConfig"),Kvt.forEach(t),gdo=r(oRe," (MVP model)"),oRe.forEach(t),hdo=i(L),Xg=n(L,"LI",{});var rRe=s(Xg);yce=n(rRe,"STRONG",{});var Zvt=s(yce);udo=r(Zvt,"nezha"),Zvt.forEach(t),pdo=r(rRe," \u2014 "),HI=n(rRe,"A",{href:!0});var eFt=s(HI);_do=r(eFt,"NezhaConfig"),eFt.forEach(t),bdo=r(rRe," (Nezha model)"),rRe.forEach(t),vdo=i(L),zg=n(L,"LI",{});var tRe=s(zg);xce=n(tRe,"STRONG",{});var oFt=s(xce);Fdo=r(oFt,"nystromformer"),oFt.forEach(t),Tdo=r(tRe," \u2014 "),JI=n(tRe,"A",{href:!0});var rFt=s(JI);Mdo=r(rFt,"NystromformerConfig"),rFt.forEach(t),Edo=r(tRe," (Nystr\xF6mformer model)"),tRe.forEach(t),Cdo=i(L),Qg=n(L,"LI",{});var aRe=s(Qg);$ce=n(aRe,"STRONG",{});var tFt=s($ce);wdo=r(tFt,"openai-gpt"),tFt.forEach(t),Ado=r(aRe," \u2014 "),YI=n(aRe,"A",{href:!0});var aFt=s(YI);Ldo=r(aFt,"OpenAIGPTConfig"),aFt.forEach(t),ydo=r(aRe," (OpenAI GPT model)"),aRe.forEach(t),xdo=i(L),Wg=n(L,"LI",{});var nRe=s(Wg);kce=n(nRe,"STRONG",{});var nFt=s(kce);$do=r(nFt,"opt"),nFt.forEach(t),kdo=r(nRe," \u2014 "),KI=n(nRe,"A",{href:!0});var sFt=s(KI);Sdo=r(sFt,"OPTConfig"),sFt.forEach(t),Rdo=r(nRe," (OPT model)"),nRe.forEach(t),Pdo=i(L),Ug=n(L,"LI",{});var sRe=s(Ug);Sce=n(sRe,"STRONG",{});var lFt=s(Sce);Bdo=r(lFt,"owlvit"),lFt.forEach(t),Ido=r(sRe," \u2014 "),ZI=n(sRe,"A",{href:!0});var iFt=s(ZI);Ndo=r(iFt,"OwlViTConfig"),iFt.forEach(t),qdo=r(sRe," (OWL-ViT model)"),sRe.forEach(t),jdo=i(L),Hg=n(L,"LI",{});var lRe=s(Hg);Rce=n(lRe,"STRONG",{});var dFt=s(Rce);Ddo=r(dFt,"pegasus"),dFt.forEach(t),Gdo=r(lRe," \u2014 "),eN=n(lRe,"A",{href:!0});var cFt=s(eN);Odo=r(cFt,"PegasusConfig"),cFt.forEach(t),Vdo=r(lRe," (Pegasus model)"),lRe.forEach(t),Xdo=i(L),Jg=n(L,"LI",{});var iRe=s(Jg);Pce=n(iRe,"STRONG",{});var mFt=s(Pce);zdo=r(mFt,"pegasus_x"),mFt.forEach(t),Qdo=r(iRe," \u2014 "),oN=n(iRe,"A",{href:!0});var fFt=s(oN);Wdo=r(fFt,"PegasusXConfig"),fFt.forEach(t),Udo=r(iRe," (PEGASUS-X model)"),iRe.forEach(t),Hdo=i(L),Yg=n(L,"LI",{});var dRe=s(Yg);Bce=n(dRe,"STRONG",{});var gFt=s(Bce);Jdo=r(gFt,"perceiver"),gFt.forEach(t),Ydo=r(dRe," \u2014 "),rN=n(dRe,"A",{href:!0});var hFt=s(rN);Kdo=r(hFt,"PerceiverConfig"),hFt.forEach(t),Zdo=r(dRe," (Perceiver model)"),dRe.forEach(t),eco=i(L),Kg=n(L,"LI",{});var cRe=s(Kg);Ice=n(cRe,"STRONG",{});var uFt=s(Ice);oco=r(uFt,"plbart"),uFt.forEach(t),rco=r(cRe," \u2014 "),tN=n(cRe,"A",{href:!0});var pFt=s(tN);tco=r(pFt,"PLBartConfig"),pFt.forEach(t),aco=r(cRe," (PLBart model)"),cRe.forEach(t),nco=i(L),Zg=n(L,"LI",{});var mRe=s(Zg);Nce=n(mRe,"STRONG",{});var _Ft=s(Nce);sco=r(_Ft,"poolformer"),_Ft.forEach(t),lco=r(mRe," \u2014 "),aN=n(mRe,"A",{href:!0});var bFt=s(aN);ico=r(bFt,"PoolFormerConfig"),bFt.forEach(t),dco=r(mRe," (PoolFormer model)"),mRe.forEach(t),cco=i(L),eh=n(L,"LI",{});var fRe=s(eh);qce=n(fRe,"STRONG",{});var vFt=s(qce);mco=r(vFt,"prophetnet"),vFt.forEach(t),fco=r(fRe," \u2014 "),nN=n(fRe,"A",{href:!0});var FFt=s(nN);gco=r(FFt,"ProphetNetConfig"),FFt.forEach(t),hco=r(fRe," (ProphetNet model)"),fRe.forEach(t),uco=i(L),oh=n(L,"LI",{});var gRe=s(oh);jce=n(gRe,"STRONG",{});var TFt=s(jce);pco=r(TFt,"qdqbert"),TFt.forEach(t),_co=r(gRe," \u2014 "),sN=n(gRe,"A",{href:!0});var MFt=s(sN);bco=r(MFt,"QDQBertConfig"),MFt.forEach(t),vco=r(gRe," (QDQBert model)"),gRe.forEach(t),Fco=i(L),rh=n(L,"LI",{});var hRe=s(rh);Dce=n(hRe,"STRONG",{});var EFt=s(Dce);Tco=r(EFt,"rag"),EFt.forEach(t),Mco=r(hRe," \u2014 "),lN=n(hRe,"A",{href:!0});var CFt=s(lN);Eco=r(CFt,"RagConfig"),CFt.forEach(t),Cco=r(hRe," (RAG model)"),hRe.forEach(t),wco=i(L),th=n(L,"LI",{});var uRe=s(th);Gce=n(uRe,"STRONG",{});var wFt=s(Gce);Aco=r(wFt,"realm"),wFt.forEach(t),Lco=r(uRe," \u2014 "),iN=n(uRe,"A",{href:!0});var AFt=s(iN);yco=r(AFt,"RealmConfig"),AFt.forEach(t),xco=r(uRe," (REALM model)"),uRe.forEach(t),$co=i(L),ah=n(L,"LI",{});var pRe=s(ah);Oce=n(pRe,"STRONG",{});var LFt=s(Oce);kco=r(LFt,"reformer"),LFt.forEach(t),Sco=r(pRe," \u2014 "),dN=n(pRe,"A",{href:!0});var yFt=s(dN);Rco=r(yFt,"ReformerConfig"),yFt.forEach(t),Pco=r(pRe," (Reformer model)"),pRe.forEach(t),Bco=i(L),nh=n(L,"LI",{});var _Re=s(nh);Vce=n(_Re,"STRONG",{});var xFt=s(Vce);Ico=r(xFt,"regnet"),xFt.forEach(t),Nco=r(_Re," \u2014 "),cN=n(_Re,"A",{href:!0});var $Ft=s(cN);qco=r($Ft,"RegNetConfig"),$Ft.forEach(t),jco=r(_Re," (RegNet model)"),_Re.forEach(t),Dco=i(L),sh=n(L,"LI",{});var bRe=s(sh);Xce=n(bRe,"STRONG",{});var kFt=s(Xce);Gco=r(kFt,"rembert"),kFt.forEach(t),Oco=r(bRe," \u2014 "),mN=n(bRe,"A",{href:!0});var SFt=s(mN);Vco=r(SFt,"RemBertConfig"),SFt.forEach(t),Xco=r(bRe," (RemBERT model)"),bRe.forEach(t),zco=i(L),lh=n(L,"LI",{});var vRe=s(lh);zce=n(vRe,"STRONG",{});var RFt=s(zce);Qco=r(RFt,"resnet"),RFt.forEach(t),Wco=r(vRe," \u2014 "),fN=n(vRe,"A",{href:!0});var PFt=s(fN);Uco=r(PFt,"ResNetConfig"),PFt.forEach(t),Hco=r(vRe," (ResNet model)"),vRe.forEach(t),Jco=i(L),ih=n(L,"LI",{});var FRe=s(ih);Qce=n(FRe,"STRONG",{});var BFt=s(Qce);Yco=r(BFt,"retribert"),BFt.forEach(t),Kco=r(FRe," \u2014 "),gN=n(FRe,"A",{href:!0});var IFt=s(gN);Zco=r(IFt,"RetriBertConfig"),IFt.forEach(t),emo=r(FRe," (RetriBERT model)"),FRe.forEach(t),omo=i(L),dh=n(L,"LI",{});var TRe=s(dh);Wce=n(TRe,"STRONG",{});var NFt=s(Wce);rmo=r(NFt,"roberta"),NFt.forEach(t),tmo=r(TRe," \u2014 "),hN=n(TRe,"A",{href:!0});var qFt=s(hN);amo=r(qFt,"RobertaConfig"),qFt.forEach(t),nmo=r(TRe," (RoBERTa model)"),TRe.forEach(t),smo=i(L),ch=n(L,"LI",{});var MRe=s(ch);Uce=n(MRe,"STRONG",{});var jFt=s(Uce);lmo=r(jFt,"roformer"),jFt.forEach(t),imo=r(MRe," \u2014 "),uN=n(MRe,"A",{href:!0});var DFt=s(uN);dmo=r(DFt,"RoFormerConfig"),DFt.forEach(t),cmo=r(MRe," (RoFormer model)"),MRe.forEach(t),mmo=i(L),mh=n(L,"LI",{});var ERe=s(mh);Hce=n(ERe,"STRONG",{});var GFt=s(Hce);fmo=r(GFt,"segformer"),GFt.forEach(t),gmo=r(ERe," \u2014 "),pN=n(ERe,"A",{href:!0});var OFt=s(pN);hmo=r(OFt,"SegformerConfig"),OFt.forEach(t),umo=r(ERe," (SegFormer model)"),ERe.forEach(t),pmo=i(L),fh=n(L,"LI",{});var CRe=s(fh);Jce=n(CRe,"STRONG",{});var VFt=s(Jce);_mo=r(VFt,"sew"),VFt.forEach(t),bmo=r(CRe," \u2014 "),_N=n(CRe,"A",{href:!0});var XFt=s(_N);vmo=r(XFt,"SEWConfig"),XFt.forEach(t),Fmo=r(CRe," (SEW model)"),CRe.forEach(t),Tmo=i(L),gh=n(L,"LI",{});var wRe=s(gh);Yce=n(wRe,"STRONG",{});var zFt=s(Yce);Mmo=r(zFt,"sew-d"),zFt.forEach(t),Emo=r(wRe," \u2014 "),bN=n(wRe,"A",{href:!0});var QFt=s(bN);Cmo=r(QFt,"SEWDConfig"),QFt.forEach(t),wmo=r(wRe," (SEW-D model)"),wRe.forEach(t),Amo=i(L),hh=n(L,"LI",{});var ARe=s(hh);Kce=n(ARe,"STRONG",{});var WFt=s(Kce);Lmo=r(WFt,"speech-encoder-decoder"),WFt.forEach(t),ymo=r(ARe," \u2014 "),vN=n(ARe,"A",{href:!0});var UFt=s(vN);xmo=r(UFt,"SpeechEncoderDecoderConfig"),UFt.forEach(t),$mo=r(ARe," (Speech Encoder decoder model)"),ARe.forEach(t),kmo=i(L),uh=n(L,"LI",{});var LRe=s(uh);Zce=n(LRe,"STRONG",{});var HFt=s(Zce);Smo=r(HFt,"speech_to_text"),HFt.forEach(t),Rmo=r(LRe," \u2014 "),FN=n(LRe,"A",{href:!0});var JFt=s(FN);Pmo=r(JFt,"Speech2TextConfig"),JFt.forEach(t),Bmo=r(LRe," (Speech2Text model)"),LRe.forEach(t),Imo=i(L),ph=n(L,"LI",{});var yRe=s(ph);eme=n(yRe,"STRONG",{});var YFt=s(eme);Nmo=r(YFt,"speech_to_text_2"),YFt.forEach(t),qmo=r(yRe," \u2014 "),TN=n(yRe,"A",{href:!0});var KFt=s(TN);jmo=r(KFt,"Speech2Text2Config"),KFt.forEach(t),Dmo=r(yRe," (Speech2Text2 model)"),yRe.forEach(t),Gmo=i(L),_h=n(L,"LI",{});var xRe=s(_h);ome=n(xRe,"STRONG",{});var ZFt=s(ome);Omo=r(ZFt,"splinter"),ZFt.forEach(t),Vmo=r(xRe," \u2014 "),MN=n(xRe,"A",{href:!0});var eTt=s(MN);Xmo=r(eTt,"SplinterConfig"),eTt.forEach(t),zmo=r(xRe," (Splinter model)"),xRe.forEach(t),Qmo=i(L),bh=n(L,"LI",{});var $Re=s(bh);rme=n($Re,"STRONG",{});var oTt=s(rme);Wmo=r(oTt,"squeezebert"),oTt.forEach(t),Umo=r($Re," \u2014 "),EN=n($Re,"A",{href:!0});var rTt=s(EN);Hmo=r(rTt,"SqueezeBertConfig"),rTt.forEach(t),Jmo=r($Re," (SqueezeBERT model)"),$Re.forEach(t),Ymo=i(L),vh=n(L,"LI",{});var kRe=s(vh);tme=n(kRe,"STRONG",{});var tTt=s(tme);Kmo=r(tTt,"swin"),tTt.forEach(t),Zmo=r(kRe," \u2014 "),CN=n(kRe,"A",{href:!0});var aTt=s(CN);efo=r(aTt,"SwinConfig"),aTt.forEach(t),ofo=r(kRe," (Swin Transformer model)"),kRe.forEach(t),rfo=i(L),Fh=n(L,"LI",{});var SRe=s(Fh);ame=n(SRe,"STRONG",{});var nTt=s(ame);tfo=r(nTt,"swinv2"),nTt.forEach(t),afo=r(SRe," \u2014 "),wN=n(SRe,"A",{href:!0});var sTt=s(wN);nfo=r(sTt,"Swinv2Config"),sTt.forEach(t),sfo=r(SRe," (Swin Transformer V2 model)"),SRe.forEach(t),lfo=i(L),Th=n(L,"LI",{});var RRe=s(Th);nme=n(RRe,"STRONG",{});var lTt=s(nme);ifo=r(lTt,"t5"),lTt.forEach(t),dfo=r(RRe," \u2014 "),AN=n(RRe,"A",{href:!0});var iTt=s(AN);cfo=r(iTt,"T5Config"),iTt.forEach(t),mfo=r(RRe," (T5 model)"),RRe.forEach(t),ffo=i(L),Mh=n(L,"LI",{});var PRe=s(Mh);sme=n(PRe,"STRONG",{});var dTt=s(sme);gfo=r(dTt,"tapas"),dTt.forEach(t),hfo=r(PRe," \u2014 "),LN=n(PRe,"A",{href:!0});var cTt=s(LN);ufo=r(cTt,"TapasConfig"),cTt.forEach(t),pfo=r(PRe," (TAPAS model)"),PRe.forEach(t),_fo=i(L),Eh=n(L,"LI",{});var BRe=s(Eh);lme=n(BRe,"STRONG",{});var mTt=s(lme);bfo=r(mTt,"trajectory_transformer"),mTt.forEach(t),vfo=r(BRe," \u2014 "),yN=n(BRe,"A",{href:!0});var fTt=s(yN);Ffo=r(fTt,"TrajectoryTransformerConfig"),fTt.forEach(t),Tfo=r(BRe," (Trajectory Transformer model)"),BRe.forEach(t),Mfo=i(L),Ch=n(L,"LI",{});var IRe=s(Ch);ime=n(IRe,"STRONG",{});var gTt=s(ime);Efo=r(gTt,"transfo-xl"),gTt.forEach(t),Cfo=r(IRe," \u2014 "),xN=n(IRe,"A",{href:!0});var hTt=s(xN);wfo=r(hTt,"TransfoXLConfig"),hTt.forEach(t),Afo=r(IRe," (Transformer-XL model)"),IRe.forEach(t),Lfo=i(L),wh=n(L,"LI",{});var NRe=s(wh);dme=n(NRe,"STRONG",{});var uTt=s(dme);yfo=r(uTt,"trocr"),uTt.forEach(t),xfo=r(NRe," \u2014 "),$N=n(NRe,"A",{href:!0});var pTt=s($N);$fo=r(pTt,"TrOCRConfig"),pTt.forEach(t),kfo=r(NRe," (TrOCR model)"),NRe.forEach(t),Sfo=i(L),Ah=n(L,"LI",{});var qRe=s(Ah);cme=n(qRe,"STRONG",{});var _Tt=s(cme);Rfo=r(_Tt,"unispeech"),_Tt.forEach(t),Pfo=r(qRe," \u2014 "),kN=n(qRe,"A",{href:!0});var bTt=s(kN);Bfo=r(bTt,"UniSpeechConfig"),bTt.forEach(t),Ifo=r(qRe," (UniSpeech model)"),qRe.forEach(t),Nfo=i(L),Lh=n(L,"LI",{});var jRe=s(Lh);mme=n(jRe,"STRONG",{});var vTt=s(mme);qfo=r(vTt,"unispeech-sat"),vTt.forEach(t),jfo=r(jRe," \u2014 "),SN=n(jRe,"A",{href:!0});var FTt=s(SN);Dfo=r(FTt,"UniSpeechSatConfig"),FTt.forEach(t),Gfo=r(jRe," (UniSpeechSat model)"),jRe.forEach(t),Ofo=i(L),yh=n(L,"LI",{});var DRe=s(yh);fme=n(DRe,"STRONG",{});var TTt=s(fme);Vfo=r(TTt,"van"),TTt.forEach(t),Xfo=r(DRe," \u2014 "),RN=n(DRe,"A",{href:!0});var MTt=s(RN);zfo=r(MTt,"VanConfig"),MTt.forEach(t),Qfo=r(DRe," (VAN model)"),DRe.forEach(t),Wfo=i(L),xh=n(L,"LI",{});var GRe=s(xh);gme=n(GRe,"STRONG",{});var ETt=s(gme);Ufo=r(ETt,"videomae"),ETt.forEach(t),Hfo=r(GRe," \u2014 "),PN=n(GRe,"A",{href:!0});var CTt=s(PN);Jfo=r(CTt,"VideoMAEConfig"),CTt.forEach(t),Yfo=r(GRe," (VideoMAE model)"),GRe.forEach(t),Kfo=i(L),$h=n(L,"LI",{});var ORe=s($h);hme=n(ORe,"STRONG",{});var wTt=s(hme);Zfo=r(wTt,"vilt"),wTt.forEach(t),ego=r(ORe," \u2014 "),BN=n(ORe,"A",{href:!0});var ATt=s(BN);ogo=r(ATt,"ViltConfig"),ATt.forEach(t),rgo=r(ORe," (ViLT model)"),ORe.forEach(t),tgo=i(L),kh=n(L,"LI",{});var VRe=s(kh);ume=n(VRe,"STRONG",{});var LTt=s(ume);ago=r(LTt,"vision-encoder-decoder"),LTt.forEach(t),ngo=r(VRe," \u2014 "),IN=n(VRe,"A",{href:!0});var yTt=s(IN);sgo=r(yTt,"VisionEncoderDecoderConfig"),yTt.forEach(t),lgo=r(VRe," (Vision Encoder decoder model)"),VRe.forEach(t),igo=i(L),Sh=n(L,"LI",{});var XRe=s(Sh);pme=n(XRe,"STRONG",{});var xTt=s(pme);dgo=r(xTt,"vision-text-dual-encoder"),xTt.forEach(t),cgo=r(XRe," \u2014 "),NN=n(XRe,"A",{href:!0});var $Tt=s(NN);mgo=r($Tt,"VisionTextDualEncoderConfig"),$Tt.forEach(t),fgo=r(XRe," (VisionTextDualEncoder model)"),XRe.forEach(t),ggo=i(L),Rh=n(L,"LI",{});var zRe=s(Rh);_me=n(zRe,"STRONG",{});var kTt=s(_me);hgo=r(kTt,"visual_bert"),kTt.forEach(t),ugo=r(zRe," \u2014 "),qN=n(zRe,"A",{href:!0});var STt=s(qN);pgo=r(STt,"VisualBertConfig"),STt.forEach(t),_go=r(zRe," (VisualBERT model)"),zRe.forEach(t),bgo=i(L),Ph=n(L,"LI",{});var QRe=s(Ph);bme=n(QRe,"STRONG",{});var RTt=s(bme);vgo=r(RTt,"vit"),RTt.forEach(t),Fgo=r(QRe," \u2014 "),jN=n(QRe,"A",{href:!0});var PTt=s(jN);Tgo=r(PTt,"ViTConfig"),PTt.forEach(t),Mgo=r(QRe," (ViT model)"),QRe.forEach(t),Ego=i(L),Bh=n(L,"LI",{});var WRe=s(Bh);vme=n(WRe,"STRONG",{});var BTt=s(vme);Cgo=r(BTt,"vit_mae"),BTt.forEach(t),wgo=r(WRe," \u2014 "),DN=n(WRe,"A",{href:!0});var ITt=s(DN);Ago=r(ITt,"ViTMAEConfig"),ITt.forEach(t),Lgo=r(WRe," (ViTMAE model)"),WRe.forEach(t),ygo=i(L),Ih=n(L,"LI",{});var URe=s(Ih);Fme=n(URe,"STRONG",{});var NTt=s(Fme);xgo=r(NTt,"wav2vec2"),NTt.forEach(t),$go=r(URe," \u2014 "),GN=n(URe,"A",{href:!0});var qTt=s(GN);kgo=r(qTt,"Wav2Vec2Config"),qTt.forEach(t),Sgo=r(URe," (Wav2Vec2 model)"),URe.forEach(t),Rgo=i(L),Nh=n(L,"LI",{});var HRe=s(Nh);Tme=n(HRe,"STRONG",{});var jTt=s(Tme);Pgo=r(jTt,"wav2vec2-conformer"),jTt.forEach(t),Bgo=r(HRe," \u2014 "),ON=n(HRe,"A",{href:!0});var DTt=s(ON);Igo=r(DTt,"Wav2Vec2ConformerConfig"),DTt.forEach(t),Ngo=r(HRe," (Wav2Vec2-Conformer model)"),HRe.forEach(t),qgo=i(L),qh=n(L,"LI",{});var JRe=s(qh);Mme=n(JRe,"STRONG",{});var GTt=s(Mme);jgo=r(GTt,"wavlm"),GTt.forEach(t),Dgo=r(JRe," \u2014 "),VN=n(JRe,"A",{href:!0});var OTt=s(VN);Ggo=r(OTt,"WavLMConfig"),OTt.forEach(t),Ogo=r(JRe," (WavLM model)"),JRe.forEach(t),Vgo=i(L),jh=n(L,"LI",{});var YRe=s(jh);Eme=n(YRe,"STRONG",{});var VTt=s(Eme);Xgo=r(VTt,"xclip"),VTt.forEach(t),zgo=r(YRe," \u2014 "),XN=n(YRe,"A",{href:!0});var XTt=s(XN);Qgo=r(XTt,"XCLIPConfig"),XTt.forEach(t),Wgo=r(YRe," (X-CLIP model)"),YRe.forEach(t),Ugo=i(L),Dh=n(L,"LI",{});var KRe=s(Dh);Cme=n(KRe,"STRONG",{});var zTt=s(Cme);Hgo=r(zTt,"xglm"),zTt.forEach(t),Jgo=r(KRe," \u2014 "),zN=n(KRe,"A",{href:!0});var QTt=s(zN);Ygo=r(QTt,"XGLMConfig"),QTt.forEach(t),Kgo=r(KRe," (XGLM model)"),KRe.forEach(t),Zgo=i(L),Gh=n(L,"LI",{});var ZRe=s(Gh);wme=n(ZRe,"STRONG",{});var WTt=s(wme);eho=r(WTt,"xlm"),WTt.forEach(t),oho=r(ZRe," \u2014 "),QN=n(ZRe,"A",{href:!0});var UTt=s(QN);rho=r(UTt,"XLMConfig"),UTt.forEach(t),tho=r(ZRe," (XLM model)"),ZRe.forEach(t),aho=i(L),Oh=n(L,"LI",{});var ePe=s(Oh);Ame=n(ePe,"STRONG",{});var HTt=s(Ame);nho=r(HTt,"xlm-prophetnet"),HTt.forEach(t),sho=r(ePe," \u2014 "),WN=n(ePe,"A",{href:!0});var JTt=s(WN);lho=r(JTt,"XLMProphetNetConfig"),JTt.forEach(t),iho=r(ePe," (XLM-ProphetNet model)"),ePe.forEach(t),dho=i(L),Vh=n(L,"LI",{});var oPe=s(Vh);Lme=n(oPe,"STRONG",{});var YTt=s(Lme);cho=r(YTt,"xlm-roberta"),YTt.forEach(t),mho=r(oPe," \u2014 "),UN=n(oPe,"A",{href:!0});var KTt=s(UN);fho=r(KTt,"XLMRobertaConfig"),KTt.forEach(t),gho=r(oPe," (XLM-RoBERTa model)"),oPe.forEach(t),hho=i(L),Xh=n(L,"LI",{});var rPe=s(Xh);yme=n(rPe,"STRONG",{});var ZTt=s(yme);uho=r(ZTt,"xlm-roberta-xl"),ZTt.forEach(t),pho=r(rPe," \u2014 "),HN=n(rPe,"A",{href:!0});var eMt=s(HN);_ho=r(eMt,"XLMRobertaXLConfig"),eMt.forEach(t),bho=r(rPe," (XLM-RoBERTa-XL model)"),rPe.forEach(t),vho=i(L),zh=n(L,"LI",{});var tPe=s(zh);xme=n(tPe,"STRONG",{});var oMt=s(xme);Fho=r(oMt,"xlnet"),oMt.forEach(t),Tho=r(tPe," \u2014 "),JN=n(tPe,"A",{href:!0});var rMt=s(JN);Mho=r(rMt,"XLNetConfig"),rMt.forEach(t),Eho=r(tPe," (XLNet model)"),tPe.forEach(t),Cho=i(L),Qh=n(L,"LI",{});var aPe=s(Qh);$me=n(aPe,"STRONG",{});var tMt=s($me);who=r(tMt,"yolos"),tMt.forEach(t),Aho=r(aPe," \u2014 "),YN=n(aPe,"A",{href:!0});var aMt=s(YN);Lho=r(aMt,"YolosConfig"),aMt.forEach(t),yho=r(aPe," (YOLOS model)"),aPe.forEach(t),xho=i(L),Wh=n(L,"LI",{});var nPe=s(Wh);kme=n(nPe,"STRONG",{});var nMt=s(kme);$ho=r(nMt,"yoso"),nMt.forEach(t),kho=r(nPe," \u2014 "),KN=n(nPe,"A",{href:!0});var sMt=s(KN);Sho=r(sMt,"YosoConfig"),sMt.forEach(t),Rho=r(nPe," (YOSO model)"),nPe.forEach(t),L.forEach(t),Pho=i(ut),T(Uh.$$.fragment,ut),ut.forEach(t),Bho=i(ht),Hh=n(ht,"DIV",{class:!0});var ieo=s(Hh);T(B9.$$.fragment,ieo),Iho=i(ieo),Sme=n(ieo,"P",{});var lMt=s(Sme);Nho=r(lMt,"Register a new configuration for this class."),lMt.forEach(t),ieo.forEach(t),ht.forEach(t),oKe=i(m),fd=n(m,"H2",{class:!0});var deo=s(fd);Jh=n(deo,"A",{id:!0,class:!0,href:!0});var iMt=s(Jh);Rme=n(iMt,"SPAN",{});var dMt=s(Rme);T(I9.$$.fragment,dMt),dMt.forEach(t),iMt.forEach(t),qho=i(deo),Pme=n(deo,"SPAN",{});var cMt=s(Pme);jho=r(cMt,"AutoTokenizer"),cMt.forEach(t),deo.forEach(t),rKe=i(m),ko=n(m,"DIV",{class:!0});var Tl=s(ko);T(N9.$$.fragment,Tl),Dho=i(Tl),q9=n(Tl,"P",{});var ceo=s(q9);Gho=r(ceo,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),ZN=n(ceo,"A",{href:!0});var mMt=s(ZN);Oho=r(mMt,"AutoTokenizer.from_pretrained()"),mMt.forEach(t),Vho=r(ceo," class method."),ceo.forEach(t),Xho=i(Tl),j9=n(Tl,"P",{});var meo=s(j9);zho=r(meo,"This class cannot be instantiated directly using "),Bme=n(meo,"CODE",{});var fMt=s(Bme);Qho=r(fMt,"__init__()"),fMt.forEach(t),Who=r(meo," (throws an error)."),meo.forEach(t),Uho=i(Tl),Br=n(Tl,"DIV",{class:!0});var Ml=s(Br);T(D9.$$.fragment,Ml),Hho=i(Ml),Ime=n(Ml,"P",{});var gMt=s(Ime);Jho=r(gMt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),gMt.forEach(t),Yho=i(Ml),Ua=n(Ml,"P",{});var Ty=s(Ua);Kho=r(Ty,"The tokenizer class to instantiate is selected based on the "),Nme=n(Ty,"CODE",{});var hMt=s(Nme);Zho=r(hMt,"model_type"),hMt.forEach(t),euo=r(Ty,` property of the config object (either
passed as an argument or loaded from `),qme=n(Ty,"CODE",{});var uMt=s(qme);ouo=r(uMt,"pretrained_model_name_or_path"),uMt.forEach(t),ruo=r(Ty,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jme=n(Ty,"CODE",{});var pMt=s(jme);tuo=r(pMt,"pretrained_model_name_or_path"),pMt.forEach(t),auo=r(Ty,":"),Ty.forEach(t),nuo=i(Ml),k=n(Ml,"UL",{});var S=s(k);as=n(S,"LI",{});var mP=s(as);Dme=n(mP,"STRONG",{});var _Mt=s(Dme);suo=r(_Mt,"albert"),_Mt.forEach(t),luo=r(mP," \u2014 "),eq=n(mP,"A",{href:!0});var bMt=s(eq);iuo=r(bMt,"AlbertTokenizer"),bMt.forEach(t),duo=r(mP," or "),oq=n(mP,"A",{href:!0});var vMt=s(oq);cuo=r(vMt,"AlbertTokenizerFast"),vMt.forEach(t),muo=r(mP," (ALBERT model)"),mP.forEach(t),fuo=i(S),ns=n(S,"LI",{});var fP=s(ns);Gme=n(fP,"STRONG",{});var FMt=s(Gme);guo=r(FMt,"bart"),FMt.forEach(t),huo=r(fP," \u2014 "),rq=n(fP,"A",{href:!0});var TMt=s(rq);uuo=r(TMt,"BartTokenizer"),TMt.forEach(t),puo=r(fP," or "),tq=n(fP,"A",{href:!0});var MMt=s(tq);_uo=r(MMt,"BartTokenizerFast"),MMt.forEach(t),buo=r(fP," (BART model)"),fP.forEach(t),vuo=i(S),ss=n(S,"LI",{});var gP=s(ss);Ome=n(gP,"STRONG",{});var EMt=s(Ome);Fuo=r(EMt,"barthez"),EMt.forEach(t),Tuo=r(gP," \u2014 "),aq=n(gP,"A",{href:!0});var CMt=s(aq);Muo=r(CMt,"BarthezTokenizer"),CMt.forEach(t),Euo=r(gP," or "),nq=n(gP,"A",{href:!0});var wMt=s(nq);Cuo=r(wMt,"BarthezTokenizerFast"),wMt.forEach(t),wuo=r(gP," (BARThez model)"),gP.forEach(t),Auo=i(S),Yh=n(S,"LI",{});var sPe=s(Yh);Vme=n(sPe,"STRONG",{});var AMt=s(Vme);Luo=r(AMt,"bartpho"),AMt.forEach(t),yuo=r(sPe," \u2014 "),sq=n(sPe,"A",{href:!0});var LMt=s(sq);xuo=r(LMt,"BartphoTokenizer"),LMt.forEach(t),$uo=r(sPe," (BARTpho model)"),sPe.forEach(t),kuo=i(S),ls=n(S,"LI",{});var hP=s(ls);Xme=n(hP,"STRONG",{});var yMt=s(Xme);Suo=r(yMt,"bert"),yMt.forEach(t),Ruo=r(hP," \u2014 "),lq=n(hP,"A",{href:!0});var xMt=s(lq);Puo=r(xMt,"BertTokenizer"),xMt.forEach(t),Buo=r(hP," or "),iq=n(hP,"A",{href:!0});var $Mt=s(iq);Iuo=r($Mt,"BertTokenizerFast"),$Mt.forEach(t),Nuo=r(hP," (BERT model)"),hP.forEach(t),quo=i(S),Kh=n(S,"LI",{});var lPe=s(Kh);zme=n(lPe,"STRONG",{});var kMt=s(zme);juo=r(kMt,"bert-generation"),kMt.forEach(t),Duo=r(lPe," \u2014 "),dq=n(lPe,"A",{href:!0});var SMt=s(dq);Guo=r(SMt,"BertGenerationTokenizer"),SMt.forEach(t),Ouo=r(lPe," (Bert Generation model)"),lPe.forEach(t),Vuo=i(S),Zh=n(S,"LI",{});var iPe=s(Zh);Qme=n(iPe,"STRONG",{});var RMt=s(Qme);Xuo=r(RMt,"bert-japanese"),RMt.forEach(t),zuo=r(iPe," \u2014 "),cq=n(iPe,"A",{href:!0});var PMt=s(cq);Quo=r(PMt,"BertJapaneseTokenizer"),PMt.forEach(t),Wuo=r(iPe," (BertJapanese model)"),iPe.forEach(t),Uuo=i(S),eu=n(S,"LI",{});var dPe=s(eu);Wme=n(dPe,"STRONG",{});var BMt=s(Wme);Huo=r(BMt,"bertweet"),BMt.forEach(t),Juo=r(dPe," \u2014 "),mq=n(dPe,"A",{href:!0});var IMt=s(mq);Yuo=r(IMt,"BertweetTokenizer"),IMt.forEach(t),Kuo=r(dPe," (BERTweet model)"),dPe.forEach(t),Zuo=i(S),is=n(S,"LI",{});var uP=s(is);Ume=n(uP,"STRONG",{});var NMt=s(Ume);epo=r(NMt,"big_bird"),NMt.forEach(t),opo=r(uP," \u2014 "),fq=n(uP,"A",{href:!0});var qMt=s(fq);rpo=r(qMt,"BigBirdTokenizer"),qMt.forEach(t),tpo=r(uP," or "),gq=n(uP,"A",{href:!0});var jMt=s(gq);apo=r(jMt,"BigBirdTokenizerFast"),jMt.forEach(t),npo=r(uP," (BigBird model)"),uP.forEach(t),spo=i(S),ds=n(S,"LI",{});var pP=s(ds);Hme=n(pP,"STRONG",{});var DMt=s(Hme);lpo=r(DMt,"bigbird_pegasus"),DMt.forEach(t),ipo=r(pP," \u2014 "),hq=n(pP,"A",{href:!0});var GMt=s(hq);dpo=r(GMt,"PegasusTokenizer"),GMt.forEach(t),cpo=r(pP," or "),uq=n(pP,"A",{href:!0});var OMt=s(uq);mpo=r(OMt,"PegasusTokenizerFast"),OMt.forEach(t),fpo=r(pP," (BigBird-Pegasus model)"),pP.forEach(t),gpo=i(S),cs=n(S,"LI",{});var _P=s(cs);Jme=n(_P,"STRONG",{});var VMt=s(Jme);hpo=r(VMt,"blenderbot"),VMt.forEach(t),upo=r(_P," \u2014 "),pq=n(_P,"A",{href:!0});var XMt=s(pq);ppo=r(XMt,"BlenderbotTokenizer"),XMt.forEach(t),_po=r(_P," or "),_q=n(_P,"A",{href:!0});var zMt=s(_q);bpo=r(zMt,"BlenderbotTokenizerFast"),zMt.forEach(t),vpo=r(_P," (Blenderbot model)"),_P.forEach(t),Fpo=i(S),ou=n(S,"LI",{});var cPe=s(ou);Yme=n(cPe,"STRONG",{});var QMt=s(Yme);Tpo=r(QMt,"blenderbot-small"),QMt.forEach(t),Mpo=r(cPe," \u2014 "),bq=n(cPe,"A",{href:!0});var WMt=s(bq);Epo=r(WMt,"BlenderbotSmallTokenizer"),WMt.forEach(t),Cpo=r(cPe," (BlenderbotSmall model)"),cPe.forEach(t),wpo=i(S),ru=n(S,"LI",{});var mPe=s(ru);Kme=n(mPe,"STRONG",{});var UMt=s(Kme);Apo=r(UMt,"bloom"),UMt.forEach(t),Lpo=r(mPe," \u2014 "),vq=n(mPe,"A",{href:!0});var HMt=s(vq);ypo=r(HMt,"BloomTokenizerFast"),HMt.forEach(t),xpo=r(mPe," (BLOOM model)"),mPe.forEach(t),$po=i(S),tu=n(S,"LI",{});var fPe=s(tu);Zme=n(fPe,"STRONG",{});var JMt=s(Zme);kpo=r(JMt,"byt5"),JMt.forEach(t),Spo=r(fPe," \u2014 "),Fq=n(fPe,"A",{href:!0});var YMt=s(Fq);Rpo=r(YMt,"ByT5Tokenizer"),YMt.forEach(t),Ppo=r(fPe," (ByT5 model)"),fPe.forEach(t),Bpo=i(S),ms=n(S,"LI",{});var bP=s(ms);efe=n(bP,"STRONG",{});var KMt=s(efe);Ipo=r(KMt,"camembert"),KMt.forEach(t),Npo=r(bP," \u2014 "),Tq=n(bP,"A",{href:!0});var ZMt=s(Tq);qpo=r(ZMt,"CamembertTokenizer"),ZMt.forEach(t),jpo=r(bP," or "),Mq=n(bP,"A",{href:!0});var eEt=s(Mq);Dpo=r(eEt,"CamembertTokenizerFast"),eEt.forEach(t),Gpo=r(bP," (CamemBERT model)"),bP.forEach(t),Opo=i(S),au=n(S,"LI",{});var gPe=s(au);ofe=n(gPe,"STRONG",{});var oEt=s(ofe);Vpo=r(oEt,"canine"),oEt.forEach(t),Xpo=r(gPe," \u2014 "),Eq=n(gPe,"A",{href:!0});var rEt=s(Eq);zpo=r(rEt,"CanineTokenizer"),rEt.forEach(t),Qpo=r(gPe," (CANINE model)"),gPe.forEach(t),Wpo=i(S),fs=n(S,"LI",{});var vP=s(fs);rfe=n(vP,"STRONG",{});var tEt=s(rfe);Upo=r(tEt,"clip"),tEt.forEach(t),Hpo=r(vP," \u2014 "),Cq=n(vP,"A",{href:!0});var aEt=s(Cq);Jpo=r(aEt,"CLIPTokenizer"),aEt.forEach(t),Ypo=r(vP," or "),wq=n(vP,"A",{href:!0});var nEt=s(wq);Kpo=r(nEt,"CLIPTokenizerFast"),nEt.forEach(t),Zpo=r(vP," (CLIP model)"),vP.forEach(t),e_o=i(S),gs=n(S,"LI",{});var FP=s(gs);tfe=n(FP,"STRONG",{});var sEt=s(tfe);o_o=r(sEt,"codegen"),sEt.forEach(t),r_o=r(FP," \u2014 "),Aq=n(FP,"A",{href:!0});var lEt=s(Aq);t_o=r(lEt,"CodeGenTokenizer"),lEt.forEach(t),a_o=r(FP," or "),Lq=n(FP,"A",{href:!0});var iEt=s(Lq);n_o=r(iEt,"CodeGenTokenizerFast"),iEt.forEach(t),s_o=r(FP," (CodeGen model)"),FP.forEach(t),l_o=i(S),hs=n(S,"LI",{});var TP=s(hs);afe=n(TP,"STRONG",{});var dEt=s(afe);i_o=r(dEt,"convbert"),dEt.forEach(t),d_o=r(TP," \u2014 "),yq=n(TP,"A",{href:!0});var cEt=s(yq);c_o=r(cEt,"ConvBertTokenizer"),cEt.forEach(t),m_o=r(TP," or "),xq=n(TP,"A",{href:!0});var mEt=s(xq);f_o=r(mEt,"ConvBertTokenizerFast"),mEt.forEach(t),g_o=r(TP," (ConvBERT model)"),TP.forEach(t),h_o=i(S),us=n(S,"LI",{});var MP=s(us);nfe=n(MP,"STRONG",{});var fEt=s(nfe);u_o=r(fEt,"cpm"),fEt.forEach(t),p_o=r(MP," \u2014 "),$q=n(MP,"A",{href:!0});var gEt=s($q);__o=r(gEt,"CpmTokenizer"),gEt.forEach(t),b_o=r(MP," or "),kq=n(MP,"A",{href:!0});var hEt=s(kq);v_o=r(hEt,"CpmTokenizerFast"),hEt.forEach(t),F_o=r(MP," (CPM model)"),MP.forEach(t),T_o=i(S),nu=n(S,"LI",{});var hPe=s(nu);sfe=n(hPe,"STRONG",{});var uEt=s(sfe);M_o=r(uEt,"ctrl"),uEt.forEach(t),E_o=r(hPe," \u2014 "),Sq=n(hPe,"A",{href:!0});var pEt=s(Sq);C_o=r(pEt,"CTRLTokenizer"),pEt.forEach(t),w_o=r(hPe," (CTRL model)"),hPe.forEach(t),A_o=i(S),ps=n(S,"LI",{});var EP=s(ps);lfe=n(EP,"STRONG",{});var _Et=s(lfe);L_o=r(_Et,"data2vec-text"),_Et.forEach(t),y_o=r(EP," \u2014 "),Rq=n(EP,"A",{href:!0});var bEt=s(Rq);x_o=r(bEt,"RobertaTokenizer"),bEt.forEach(t),$_o=r(EP," or "),Pq=n(EP,"A",{href:!0});var vEt=s(Pq);k_o=r(vEt,"RobertaTokenizerFast"),vEt.forEach(t),S_o=r(EP," (Data2VecText model)"),EP.forEach(t),R_o=i(S),_s=n(S,"LI",{});var CP=s(_s);ife=n(CP,"STRONG",{});var FEt=s(ife);P_o=r(FEt,"deberta"),FEt.forEach(t),B_o=r(CP," \u2014 "),Bq=n(CP,"A",{href:!0});var TEt=s(Bq);I_o=r(TEt,"DebertaTokenizer"),TEt.forEach(t),N_o=r(CP," or "),Iq=n(CP,"A",{href:!0});var MEt=s(Iq);q_o=r(MEt,"DebertaTokenizerFast"),MEt.forEach(t),j_o=r(CP," (DeBERTa model)"),CP.forEach(t),D_o=i(S),bs=n(S,"LI",{});var wP=s(bs);dfe=n(wP,"STRONG",{});var EEt=s(dfe);G_o=r(EEt,"deberta-v2"),EEt.forEach(t),O_o=r(wP," \u2014 "),Nq=n(wP,"A",{href:!0});var CEt=s(Nq);V_o=r(CEt,"DebertaV2Tokenizer"),CEt.forEach(t),X_o=r(wP," or "),qq=n(wP,"A",{href:!0});var wEt=s(qq);z_o=r(wEt,"DebertaV2TokenizerFast"),wEt.forEach(t),Q_o=r(wP," (DeBERTa-v2 model)"),wP.forEach(t),W_o=i(S),vs=n(S,"LI",{});var AP=s(vs);cfe=n(AP,"STRONG",{});var AEt=s(cfe);U_o=r(AEt,"distilbert"),AEt.forEach(t),H_o=r(AP," \u2014 "),jq=n(AP,"A",{href:!0});var LEt=s(jq);J_o=r(LEt,"DistilBertTokenizer"),LEt.forEach(t),Y_o=r(AP," or "),Dq=n(AP,"A",{href:!0});var yEt=s(Dq);K_o=r(yEt,"DistilBertTokenizerFast"),yEt.forEach(t),Z_o=r(AP," (DistilBERT model)"),AP.forEach(t),ebo=i(S),Fs=n(S,"LI",{});var LP=s(Fs);mfe=n(LP,"STRONG",{});var xEt=s(mfe);obo=r(xEt,"dpr"),xEt.forEach(t),rbo=r(LP," \u2014 "),Gq=n(LP,"A",{href:!0});var $Et=s(Gq);tbo=r($Et,"DPRQuestionEncoderTokenizer"),$Et.forEach(t),abo=r(LP," or "),Oq=n(LP,"A",{href:!0});var kEt=s(Oq);nbo=r(kEt,"DPRQuestionEncoderTokenizerFast"),kEt.forEach(t),sbo=r(LP," (DPR model)"),LP.forEach(t),lbo=i(S),Ts=n(S,"LI",{});var yP=s(Ts);ffe=n(yP,"STRONG",{});var SEt=s(ffe);ibo=r(SEt,"electra"),SEt.forEach(t),dbo=r(yP," \u2014 "),Vq=n(yP,"A",{href:!0});var REt=s(Vq);cbo=r(REt,"ElectraTokenizer"),REt.forEach(t),mbo=r(yP," or "),Xq=n(yP,"A",{href:!0});var PEt=s(Xq);fbo=r(PEt,"ElectraTokenizerFast"),PEt.forEach(t),gbo=r(yP," (ELECTRA model)"),yP.forEach(t),hbo=i(S),Ms=n(S,"LI",{});var xP=s(Ms);gfe=n(xP,"STRONG",{});var BEt=s(gfe);ubo=r(BEt,"ernie"),BEt.forEach(t),pbo=r(xP," \u2014 "),zq=n(xP,"A",{href:!0});var IEt=s(zq);_bo=r(IEt,"BertTokenizer"),IEt.forEach(t),bbo=r(xP," or "),Qq=n(xP,"A",{href:!0});var NEt=s(Qq);vbo=r(NEt,"BertTokenizerFast"),NEt.forEach(t),Fbo=r(xP," (ERNIE model)"),xP.forEach(t),Tbo=i(S),su=n(S,"LI",{});var uPe=s(su);hfe=n(uPe,"STRONG",{});var qEt=s(hfe);Mbo=r(qEt,"flaubert"),qEt.forEach(t),Ebo=r(uPe," \u2014 "),Wq=n(uPe,"A",{href:!0});var jEt=s(Wq);Cbo=r(jEt,"FlaubertTokenizer"),jEt.forEach(t),wbo=r(uPe," (FlauBERT model)"),uPe.forEach(t),Abo=i(S),Es=n(S,"LI",{});var $P=s(Es);ufe=n($P,"STRONG",{});var DEt=s(ufe);Lbo=r(DEt,"fnet"),DEt.forEach(t),ybo=r($P," \u2014 "),Uq=n($P,"A",{href:!0});var GEt=s(Uq);xbo=r(GEt,"FNetTokenizer"),GEt.forEach(t),$bo=r($P," or "),Hq=n($P,"A",{href:!0});var OEt=s(Hq);kbo=r(OEt,"FNetTokenizerFast"),OEt.forEach(t),Sbo=r($P," (FNet model)"),$P.forEach(t),Rbo=i(S),lu=n(S,"LI",{});var pPe=s(lu);pfe=n(pPe,"STRONG",{});var VEt=s(pfe);Pbo=r(VEt,"fsmt"),VEt.forEach(t),Bbo=r(pPe," \u2014 "),Jq=n(pPe,"A",{href:!0});var XEt=s(Jq);Ibo=r(XEt,"FSMTTokenizer"),XEt.forEach(t),Nbo=r(pPe," (FairSeq Machine-Translation model)"),pPe.forEach(t),qbo=i(S),Cs=n(S,"LI",{});var kP=s(Cs);_fe=n(kP,"STRONG",{});var zEt=s(_fe);jbo=r(zEt,"funnel"),zEt.forEach(t),Dbo=r(kP," \u2014 "),Yq=n(kP,"A",{href:!0});var QEt=s(Yq);Gbo=r(QEt,"FunnelTokenizer"),QEt.forEach(t),Obo=r(kP," or "),Kq=n(kP,"A",{href:!0});var WEt=s(Kq);Vbo=r(WEt,"FunnelTokenizerFast"),WEt.forEach(t),Xbo=r(kP," (Funnel Transformer model)"),kP.forEach(t),zbo=i(S),ws=n(S,"LI",{});var SP=s(ws);bfe=n(SP,"STRONG",{});var UEt=s(bfe);Qbo=r(UEt,"gpt2"),UEt.forEach(t),Wbo=r(SP," \u2014 "),Zq=n(SP,"A",{href:!0});var HEt=s(Zq);Ubo=r(HEt,"GPT2Tokenizer"),HEt.forEach(t),Hbo=r(SP," or "),ej=n(SP,"A",{href:!0});var JEt=s(ej);Jbo=r(JEt,"GPT2TokenizerFast"),JEt.forEach(t),Ybo=r(SP," (OpenAI GPT-2 model)"),SP.forEach(t),Kbo=i(S),As=n(S,"LI",{});var RP=s(As);vfe=n(RP,"STRONG",{});var YEt=s(vfe);Zbo=r(YEt,"gpt_neo"),YEt.forEach(t),e2o=r(RP," \u2014 "),oj=n(RP,"A",{href:!0});var KEt=s(oj);o2o=r(KEt,"GPT2Tokenizer"),KEt.forEach(t),r2o=r(RP," or "),rj=n(RP,"A",{href:!0});var ZEt=s(rj);t2o=r(ZEt,"GPT2TokenizerFast"),ZEt.forEach(t),a2o=r(RP," (GPT Neo model)"),RP.forEach(t),n2o=i(S),iu=n(S,"LI",{});var _Pe=s(iu);Ffe=n(_Pe,"STRONG",{});var e4t=s(Ffe);s2o=r(e4t,"gpt_neox"),e4t.forEach(t),l2o=r(_Pe," \u2014 "),tj=n(_Pe,"A",{href:!0});var o4t=s(tj);i2o=r(o4t,"GPTNeoXTokenizerFast"),o4t.forEach(t),d2o=r(_Pe," (GPT NeoX model)"),_Pe.forEach(t),c2o=i(S),Ls=n(S,"LI",{});var PP=s(Ls);Tfe=n(PP,"STRONG",{});var r4t=s(Tfe);m2o=r(r4t,"gptj"),r4t.forEach(t),f2o=r(PP," \u2014 "),aj=n(PP,"A",{href:!0});var t4t=s(aj);g2o=r(t4t,"GPT2Tokenizer"),t4t.forEach(t),h2o=r(PP," or "),nj=n(PP,"A",{href:!0});var a4t=s(nj);u2o=r(a4t,"GPT2TokenizerFast"),a4t.forEach(t),p2o=r(PP," (GPT-J model)"),PP.forEach(t),_2o=i(S),ys=n(S,"LI",{});var BP=s(ys);Mfe=n(BP,"STRONG",{});var n4t=s(Mfe);b2o=r(n4t,"groupvit"),n4t.forEach(t),v2o=r(BP," \u2014 "),sj=n(BP,"A",{href:!0});var s4t=s(sj);F2o=r(s4t,"CLIPTokenizer"),s4t.forEach(t),T2o=r(BP," or "),lj=n(BP,"A",{href:!0});var l4t=s(lj);M2o=r(l4t,"CLIPTokenizerFast"),l4t.forEach(t),E2o=r(BP," (GroupViT model)"),BP.forEach(t),C2o=i(S),xs=n(S,"LI",{});var IP=s(xs);Efe=n(IP,"STRONG",{});var i4t=s(Efe);w2o=r(i4t,"herbert"),i4t.forEach(t),A2o=r(IP," \u2014 "),ij=n(IP,"A",{href:!0});var d4t=s(ij);L2o=r(d4t,"HerbertTokenizer"),d4t.forEach(t),y2o=r(IP," or "),dj=n(IP,"A",{href:!0});var c4t=s(dj);x2o=r(c4t,"HerbertTokenizerFast"),c4t.forEach(t),$2o=r(IP," (HerBERT model)"),IP.forEach(t),k2o=i(S),du=n(S,"LI",{});var bPe=s(du);Cfe=n(bPe,"STRONG",{});var m4t=s(Cfe);S2o=r(m4t,"hubert"),m4t.forEach(t),R2o=r(bPe," \u2014 "),cj=n(bPe,"A",{href:!0});var f4t=s(cj);P2o=r(f4t,"Wav2Vec2CTCTokenizer"),f4t.forEach(t),B2o=r(bPe," (Hubert model)"),bPe.forEach(t),I2o=i(S),$s=n(S,"LI",{});var NP=s($s);wfe=n(NP,"STRONG",{});var g4t=s(wfe);N2o=r(g4t,"ibert"),g4t.forEach(t),q2o=r(NP," \u2014 "),mj=n(NP,"A",{href:!0});var h4t=s(mj);j2o=r(h4t,"RobertaTokenizer"),h4t.forEach(t),D2o=r(NP," or "),fj=n(NP,"A",{href:!0});var u4t=s(fj);G2o=r(u4t,"RobertaTokenizerFast"),u4t.forEach(t),O2o=r(NP," (I-BERT model)"),NP.forEach(t),V2o=i(S),ks=n(S,"LI",{});var qP=s(ks);Afe=n(qP,"STRONG",{});var p4t=s(Afe);X2o=r(p4t,"layoutlm"),p4t.forEach(t),z2o=r(qP," \u2014 "),gj=n(qP,"A",{href:!0});var _4t=s(gj);Q2o=r(_4t,"LayoutLMTokenizer"),_4t.forEach(t),W2o=r(qP," or "),hj=n(qP,"A",{href:!0});var b4t=s(hj);U2o=r(b4t,"LayoutLMTokenizerFast"),b4t.forEach(t),H2o=r(qP," (LayoutLM model)"),qP.forEach(t),J2o=i(S),Ss=n(S,"LI",{});var jP=s(Ss);Lfe=n(jP,"STRONG",{});var v4t=s(Lfe);Y2o=r(v4t,"layoutlmv2"),v4t.forEach(t),K2o=r(jP," \u2014 "),uj=n(jP,"A",{href:!0});var F4t=s(uj);Z2o=r(F4t,"LayoutLMv2Tokenizer"),F4t.forEach(t),e1o=r(jP," or "),pj=n(jP,"A",{href:!0});var T4t=s(pj);o1o=r(T4t,"LayoutLMv2TokenizerFast"),T4t.forEach(t),r1o=r(jP," (LayoutLMv2 model)"),jP.forEach(t),t1o=i(S),Rs=n(S,"LI",{});var DP=s(Rs);yfe=n(DP,"STRONG",{});var M4t=s(yfe);a1o=r(M4t,"layoutlmv3"),M4t.forEach(t),n1o=r(DP," \u2014 "),_j=n(DP,"A",{href:!0});var E4t=s(_j);s1o=r(E4t,"LayoutLMv3Tokenizer"),E4t.forEach(t),l1o=r(DP," or "),bj=n(DP,"A",{href:!0});var C4t=s(bj);i1o=r(C4t,"LayoutLMv3TokenizerFast"),C4t.forEach(t),d1o=r(DP," (LayoutLMv3 model)"),DP.forEach(t),c1o=i(S),Ps=n(S,"LI",{});var GP=s(Ps);xfe=n(GP,"STRONG",{});var w4t=s(xfe);m1o=r(w4t,"layoutxlm"),w4t.forEach(t),f1o=r(GP," \u2014 "),vj=n(GP,"A",{href:!0});var A4t=s(vj);g1o=r(A4t,"LayoutXLMTokenizer"),A4t.forEach(t),h1o=r(GP," or "),Fj=n(GP,"A",{href:!0});var L4t=s(Fj);u1o=r(L4t,"LayoutXLMTokenizerFast"),L4t.forEach(t),p1o=r(GP," (LayoutXLM model)"),GP.forEach(t),_1o=i(S),Bs=n(S,"LI",{});var OP=s(Bs);$fe=n(OP,"STRONG",{});var y4t=s($fe);b1o=r(y4t,"led"),y4t.forEach(t),v1o=r(OP," \u2014 "),Tj=n(OP,"A",{href:!0});var x4t=s(Tj);F1o=r(x4t,"LEDTokenizer"),x4t.forEach(t),T1o=r(OP," or "),Mj=n(OP,"A",{href:!0});var $4t=s(Mj);M1o=r($4t,"LEDTokenizerFast"),$4t.forEach(t),E1o=r(OP," (LED model)"),OP.forEach(t),C1o=i(S),Is=n(S,"LI",{});var VP=s(Is);kfe=n(VP,"STRONG",{});var k4t=s(kfe);w1o=r(k4t,"longformer"),k4t.forEach(t),A1o=r(VP," \u2014 "),Ej=n(VP,"A",{href:!0});var S4t=s(Ej);L1o=r(S4t,"LongformerTokenizer"),S4t.forEach(t),y1o=r(VP," or "),Cj=n(VP,"A",{href:!0});var R4t=s(Cj);x1o=r(R4t,"LongformerTokenizerFast"),R4t.forEach(t),$1o=r(VP," (Longformer model)"),VP.forEach(t),k1o=i(S),Ns=n(S,"LI",{});var XP=s(Ns);Sfe=n(XP,"STRONG",{});var P4t=s(Sfe);S1o=r(P4t,"longt5"),P4t.forEach(t),R1o=r(XP," \u2014 "),wj=n(XP,"A",{href:!0});var B4t=s(wj);P1o=r(B4t,"T5Tokenizer"),B4t.forEach(t),B1o=r(XP," or "),Aj=n(XP,"A",{href:!0});var I4t=s(Aj);I1o=r(I4t,"T5TokenizerFast"),I4t.forEach(t),N1o=r(XP," (LongT5 model)"),XP.forEach(t),q1o=i(S),cu=n(S,"LI",{});var vPe=s(cu);Rfe=n(vPe,"STRONG",{});var N4t=s(Rfe);j1o=r(N4t,"luke"),N4t.forEach(t),D1o=r(vPe," \u2014 "),Lj=n(vPe,"A",{href:!0});var q4t=s(Lj);G1o=r(q4t,"LukeTokenizer"),q4t.forEach(t),O1o=r(vPe," (LUKE model)"),vPe.forEach(t),V1o=i(S),qs=n(S,"LI",{});var zP=s(qs);Pfe=n(zP,"STRONG",{});var j4t=s(Pfe);X1o=r(j4t,"lxmert"),j4t.forEach(t),z1o=r(zP," \u2014 "),yj=n(zP,"A",{href:!0});var D4t=s(yj);Q1o=r(D4t,"LxmertTokenizer"),D4t.forEach(t),W1o=r(zP," or "),xj=n(zP,"A",{href:!0});var G4t=s(xj);U1o=r(G4t,"LxmertTokenizerFast"),G4t.forEach(t),H1o=r(zP," (LXMERT model)"),zP.forEach(t),J1o=i(S),mu=n(S,"LI",{});var FPe=s(mu);Bfe=n(FPe,"STRONG",{});var O4t=s(Bfe);Y1o=r(O4t,"m2m_100"),O4t.forEach(t),K1o=r(FPe," \u2014 "),$j=n(FPe,"A",{href:!0});var V4t=s($j);Z1o=r(V4t,"M2M100Tokenizer"),V4t.forEach(t),evo=r(FPe," (M2M100 model)"),FPe.forEach(t),ovo=i(S),fu=n(S,"LI",{});var TPe=s(fu);Ife=n(TPe,"STRONG",{});var X4t=s(Ife);rvo=r(X4t,"marian"),X4t.forEach(t),tvo=r(TPe," \u2014 "),kj=n(TPe,"A",{href:!0});var z4t=s(kj);avo=r(z4t,"MarianTokenizer"),z4t.forEach(t),nvo=r(TPe," (Marian model)"),TPe.forEach(t),svo=i(S),js=n(S,"LI",{});var QP=s(js);Nfe=n(QP,"STRONG",{});var Q4t=s(Nfe);lvo=r(Q4t,"mbart"),Q4t.forEach(t),ivo=r(QP," \u2014 "),Sj=n(QP,"A",{href:!0});var W4t=s(Sj);dvo=r(W4t,"MBartTokenizer"),W4t.forEach(t),cvo=r(QP," or "),Rj=n(QP,"A",{href:!0});var U4t=s(Rj);mvo=r(U4t,"MBartTokenizerFast"),U4t.forEach(t),fvo=r(QP," (mBART model)"),QP.forEach(t),gvo=i(S),Ds=n(S,"LI",{});var WP=s(Ds);qfe=n(WP,"STRONG",{});var H4t=s(qfe);hvo=r(H4t,"mbart50"),H4t.forEach(t),uvo=r(WP," \u2014 "),Pj=n(WP,"A",{href:!0});var J4t=s(Pj);pvo=r(J4t,"MBart50Tokenizer"),J4t.forEach(t),_vo=r(WP," or "),Bj=n(WP,"A",{href:!0});var Y4t=s(Bj);bvo=r(Y4t,"MBart50TokenizerFast"),Y4t.forEach(t),vvo=r(WP," (mBART-50 model)"),WP.forEach(t),Fvo=i(S),Gs=n(S,"LI",{});var UP=s(Gs);jfe=n(UP,"STRONG",{});var K4t=s(jfe);Tvo=r(K4t,"megatron-bert"),K4t.forEach(t),Mvo=r(UP," \u2014 "),Ij=n(UP,"A",{href:!0});var Z4t=s(Ij);Evo=r(Z4t,"BertTokenizer"),Z4t.forEach(t),Cvo=r(UP," or "),Nj=n(UP,"A",{href:!0});var eCt=s(Nj);wvo=r(eCt,"BertTokenizerFast"),eCt.forEach(t),Avo=r(UP," (Megatron-BERT model)"),UP.forEach(t),Lvo=i(S),gu=n(S,"LI",{});var MPe=s(gu);Dfe=n(MPe,"STRONG",{});var oCt=s(Dfe);yvo=r(oCt,"mluke"),oCt.forEach(t),xvo=r(MPe," \u2014 "),qj=n(MPe,"A",{href:!0});var rCt=s(qj);$vo=r(rCt,"MLukeTokenizer"),rCt.forEach(t),kvo=r(MPe," (mLUKE model)"),MPe.forEach(t),Svo=i(S),Os=n(S,"LI",{});var HP=s(Os);Gfe=n(HP,"STRONG",{});var tCt=s(Gfe);Rvo=r(tCt,"mobilebert"),tCt.forEach(t),Pvo=r(HP," \u2014 "),jj=n(HP,"A",{href:!0});var aCt=s(jj);Bvo=r(aCt,"MobileBertTokenizer"),aCt.forEach(t),Ivo=r(HP," or "),Dj=n(HP,"A",{href:!0});var nCt=s(Dj);Nvo=r(nCt,"MobileBertTokenizerFast"),nCt.forEach(t),qvo=r(HP," (MobileBERT model)"),HP.forEach(t),jvo=i(S),Vs=n(S,"LI",{});var JP=s(Vs);Ofe=n(JP,"STRONG",{});var sCt=s(Ofe);Dvo=r(sCt,"mpnet"),sCt.forEach(t),Gvo=r(JP," \u2014 "),Gj=n(JP,"A",{href:!0});var lCt=s(Gj);Ovo=r(lCt,"MPNetTokenizer"),lCt.forEach(t),Vvo=r(JP," or "),Oj=n(JP,"A",{href:!0});var iCt=s(Oj);Xvo=r(iCt,"MPNetTokenizerFast"),iCt.forEach(t),zvo=r(JP," (MPNet model)"),JP.forEach(t),Qvo=i(S),Xs=n(S,"LI",{});var YP=s(Xs);Vfe=n(YP,"STRONG",{});var dCt=s(Vfe);Wvo=r(dCt,"mt5"),dCt.forEach(t),Uvo=r(YP," \u2014 "),Vj=n(YP,"A",{href:!0});var cCt=s(Vj);Hvo=r(cCt,"MT5Tokenizer"),cCt.forEach(t),Jvo=r(YP," or "),Xj=n(YP,"A",{href:!0});var mCt=s(Xj);Yvo=r(mCt,"MT5TokenizerFast"),mCt.forEach(t),Kvo=r(YP," (MT5 model)"),YP.forEach(t),Zvo=i(S),zs=n(S,"LI",{});var KP=s(zs);Xfe=n(KP,"STRONG",{});var fCt=s(Xfe);eFo=r(fCt,"mvp"),fCt.forEach(t),oFo=r(KP," \u2014 "),zj=n(KP,"A",{href:!0});var gCt=s(zj);rFo=r(gCt,"MvpTokenizer"),gCt.forEach(t),tFo=r(KP," or "),Qj=n(KP,"A",{href:!0});var hCt=s(Qj);aFo=r(hCt,"MvpTokenizerFast"),hCt.forEach(t),nFo=r(KP," (MVP model)"),KP.forEach(t),sFo=i(S),Qs=n(S,"LI",{});var ZP=s(Qs);zfe=n(ZP,"STRONG",{});var uCt=s(zfe);lFo=r(uCt,"nezha"),uCt.forEach(t),iFo=r(ZP," \u2014 "),Wj=n(ZP,"A",{href:!0});var pCt=s(Wj);dFo=r(pCt,"BertTokenizer"),pCt.forEach(t),cFo=r(ZP," or "),Uj=n(ZP,"A",{href:!0});var _Ct=s(Uj);mFo=r(_Ct,"BertTokenizerFast"),_Ct.forEach(t),fFo=r(ZP," (Nezha model)"),ZP.forEach(t),gFo=i(S),Ws=n(S,"LI",{});var eB=s(Ws);Qfe=n(eB,"STRONG",{});var bCt=s(Qfe);hFo=r(bCt,"nllb"),bCt.forEach(t),uFo=r(eB," \u2014 "),Hj=n(eB,"A",{href:!0});var vCt=s(Hj);pFo=r(vCt,"NllbTokenizer"),vCt.forEach(t),_Fo=r(eB," or "),Jj=n(eB,"A",{href:!0});var FCt=s(Jj);bFo=r(FCt,"NllbTokenizerFast"),FCt.forEach(t),vFo=r(eB," (NLLB model)"),eB.forEach(t),FFo=i(S),Us=n(S,"LI",{});var oB=s(Us);Wfe=n(oB,"STRONG",{});var TCt=s(Wfe);TFo=r(TCt,"nystromformer"),TCt.forEach(t),MFo=r(oB," \u2014 "),Yj=n(oB,"A",{href:!0});var MCt=s(Yj);EFo=r(MCt,"AlbertTokenizer"),MCt.forEach(t),CFo=r(oB," or "),Kj=n(oB,"A",{href:!0});var ECt=s(Kj);wFo=r(ECt,"AlbertTokenizerFast"),ECt.forEach(t),AFo=r(oB," (Nystr\xF6mformer model)"),oB.forEach(t),LFo=i(S),Hs=n(S,"LI",{});var rB=s(Hs);Ufe=n(rB,"STRONG",{});var CCt=s(Ufe);yFo=r(CCt,"openai-gpt"),CCt.forEach(t),xFo=r(rB," \u2014 "),Zj=n(rB,"A",{href:!0});var wCt=s(Zj);$Fo=r(wCt,"OpenAIGPTTokenizer"),wCt.forEach(t),kFo=r(rB," or "),eD=n(rB,"A",{href:!0});var ACt=s(eD);SFo=r(ACt,"OpenAIGPTTokenizerFast"),ACt.forEach(t),RFo=r(rB," (OpenAI GPT model)"),rB.forEach(t),PFo=i(S),hu=n(S,"LI",{});var EPe=s(hu);Hfe=n(EPe,"STRONG",{});var LCt=s(Hfe);BFo=r(LCt,"opt"),LCt.forEach(t),IFo=r(EPe," \u2014 "),oD=n(EPe,"A",{href:!0});var yCt=s(oD);NFo=r(yCt,"GPT2Tokenizer"),yCt.forEach(t),qFo=r(EPe," (OPT model)"),EPe.forEach(t),jFo=i(S),Js=n(S,"LI",{});var tB=s(Js);Jfe=n(tB,"STRONG",{});var xCt=s(Jfe);DFo=r(xCt,"owlvit"),xCt.forEach(t),GFo=r(tB," \u2014 "),rD=n(tB,"A",{href:!0});var $Ct=s(rD);OFo=r($Ct,"CLIPTokenizer"),$Ct.forEach(t),VFo=r(tB," or "),tD=n(tB,"A",{href:!0});var kCt=s(tD);XFo=r(kCt,"CLIPTokenizerFast"),kCt.forEach(t),zFo=r(tB," (OWL-ViT model)"),tB.forEach(t),QFo=i(S),Ys=n(S,"LI",{});var aB=s(Ys);Yfe=n(aB,"STRONG",{});var SCt=s(Yfe);WFo=r(SCt,"pegasus"),SCt.forEach(t),UFo=r(aB," \u2014 "),aD=n(aB,"A",{href:!0});var RCt=s(aD);HFo=r(RCt,"PegasusTokenizer"),RCt.forEach(t),JFo=r(aB," or "),nD=n(aB,"A",{href:!0});var PCt=s(nD);YFo=r(PCt,"PegasusTokenizerFast"),PCt.forEach(t),KFo=r(aB," (Pegasus model)"),aB.forEach(t),ZFo=i(S),uu=n(S,"LI",{});var CPe=s(uu);Kfe=n(CPe,"STRONG",{});var BCt=s(Kfe);eTo=r(BCt,"perceiver"),BCt.forEach(t),oTo=r(CPe," \u2014 "),sD=n(CPe,"A",{href:!0});var ICt=s(sD);rTo=r(ICt,"PerceiverTokenizer"),ICt.forEach(t),tTo=r(CPe," (Perceiver model)"),CPe.forEach(t),aTo=i(S),pu=n(S,"LI",{});var wPe=s(pu);Zfe=n(wPe,"STRONG",{});var NCt=s(Zfe);nTo=r(NCt,"phobert"),NCt.forEach(t),sTo=r(wPe," \u2014 "),lD=n(wPe,"A",{href:!0});var qCt=s(lD);lTo=r(qCt,"PhobertTokenizer"),qCt.forEach(t),iTo=r(wPe," (PhoBERT model)"),wPe.forEach(t),dTo=i(S),_u=n(S,"LI",{});var APe=s(_u);ege=n(APe,"STRONG",{});var jCt=s(ege);cTo=r(jCt,"plbart"),jCt.forEach(t),mTo=r(APe," \u2014 "),iD=n(APe,"A",{href:!0});var DCt=s(iD);fTo=r(DCt,"PLBartTokenizer"),DCt.forEach(t),gTo=r(APe," (PLBart model)"),APe.forEach(t),hTo=i(S),bu=n(S,"LI",{});var LPe=s(bu);oge=n(LPe,"STRONG",{});var GCt=s(oge);uTo=r(GCt,"prophetnet"),GCt.forEach(t),pTo=r(LPe," \u2014 "),dD=n(LPe,"A",{href:!0});var OCt=s(dD);_To=r(OCt,"ProphetNetTokenizer"),OCt.forEach(t),bTo=r(LPe," (ProphetNet model)"),LPe.forEach(t),vTo=i(S),Ks=n(S,"LI",{});var nB=s(Ks);rge=n(nB,"STRONG",{});var VCt=s(rge);FTo=r(VCt,"qdqbert"),VCt.forEach(t),TTo=r(nB," \u2014 "),cD=n(nB,"A",{href:!0});var XCt=s(cD);MTo=r(XCt,"BertTokenizer"),XCt.forEach(t),ETo=r(nB," or "),mD=n(nB,"A",{href:!0});var zCt=s(mD);CTo=r(zCt,"BertTokenizerFast"),zCt.forEach(t),wTo=r(nB," (QDQBert model)"),nB.forEach(t),ATo=i(S),vu=n(S,"LI",{});var yPe=s(vu);tge=n(yPe,"STRONG",{});var QCt=s(tge);LTo=r(QCt,"rag"),QCt.forEach(t),yTo=r(yPe," \u2014 "),fD=n(yPe,"A",{href:!0});var WCt=s(fD);xTo=r(WCt,"RagTokenizer"),WCt.forEach(t),$To=r(yPe," (RAG model)"),yPe.forEach(t),kTo=i(S),Zs=n(S,"LI",{});var sB=s(Zs);age=n(sB,"STRONG",{});var UCt=s(age);STo=r(UCt,"realm"),UCt.forEach(t),RTo=r(sB," \u2014 "),gD=n(sB,"A",{href:!0});var HCt=s(gD);PTo=r(HCt,"RealmTokenizer"),HCt.forEach(t),BTo=r(sB," or "),hD=n(sB,"A",{href:!0});var JCt=s(hD);ITo=r(JCt,"RealmTokenizerFast"),JCt.forEach(t),NTo=r(sB," (REALM model)"),sB.forEach(t),qTo=i(S),el=n(S,"LI",{});var lB=s(el);nge=n(lB,"STRONG",{});var YCt=s(nge);jTo=r(YCt,"reformer"),YCt.forEach(t),DTo=r(lB," \u2014 "),uD=n(lB,"A",{href:!0});var KCt=s(uD);GTo=r(KCt,"ReformerTokenizer"),KCt.forEach(t),OTo=r(lB," or "),pD=n(lB,"A",{href:!0});var ZCt=s(pD);VTo=r(ZCt,"ReformerTokenizerFast"),ZCt.forEach(t),XTo=r(lB," (Reformer model)"),lB.forEach(t),zTo=i(S),ol=n(S,"LI",{});var iB=s(ol);sge=n(iB,"STRONG",{});var e3t=s(sge);QTo=r(e3t,"rembert"),e3t.forEach(t),WTo=r(iB," \u2014 "),_D=n(iB,"A",{href:!0});var o3t=s(_D);UTo=r(o3t,"RemBertTokenizer"),o3t.forEach(t),HTo=r(iB," or "),bD=n(iB,"A",{href:!0});var r3t=s(bD);JTo=r(r3t,"RemBertTokenizerFast"),r3t.forEach(t),YTo=r(iB," (RemBERT model)"),iB.forEach(t),KTo=i(S),rl=n(S,"LI",{});var dB=s(rl);lge=n(dB,"STRONG",{});var t3t=s(lge);ZTo=r(t3t,"retribert"),t3t.forEach(t),eMo=r(dB," \u2014 "),vD=n(dB,"A",{href:!0});var a3t=s(vD);oMo=r(a3t,"RetriBertTokenizer"),a3t.forEach(t),rMo=r(dB," or "),FD=n(dB,"A",{href:!0});var n3t=s(FD);tMo=r(n3t,"RetriBertTokenizerFast"),n3t.forEach(t),aMo=r(dB," (RetriBERT model)"),dB.forEach(t),nMo=i(S),tl=n(S,"LI",{});var cB=s(tl);ige=n(cB,"STRONG",{});var s3t=s(ige);sMo=r(s3t,"roberta"),s3t.forEach(t),lMo=r(cB," \u2014 "),TD=n(cB,"A",{href:!0});var l3t=s(TD);iMo=r(l3t,"RobertaTokenizer"),l3t.forEach(t),dMo=r(cB," or "),MD=n(cB,"A",{href:!0});var i3t=s(MD);cMo=r(i3t,"RobertaTokenizerFast"),i3t.forEach(t),mMo=r(cB," (RoBERTa model)"),cB.forEach(t),fMo=i(S),al=n(S,"LI",{});var mB=s(al);dge=n(mB,"STRONG",{});var d3t=s(dge);gMo=r(d3t,"roformer"),d3t.forEach(t),hMo=r(mB," \u2014 "),ED=n(mB,"A",{href:!0});var c3t=s(ED);uMo=r(c3t,"RoFormerTokenizer"),c3t.forEach(t),pMo=r(mB," or "),CD=n(mB,"A",{href:!0});var m3t=s(CD);_Mo=r(m3t,"RoFormerTokenizerFast"),m3t.forEach(t),bMo=r(mB," (RoFormer model)"),mB.forEach(t),vMo=i(S),Fu=n(S,"LI",{});var xPe=s(Fu);cge=n(xPe,"STRONG",{});var f3t=s(cge);FMo=r(f3t,"speech_to_text"),f3t.forEach(t),TMo=r(xPe," \u2014 "),wD=n(xPe,"A",{href:!0});var g3t=s(wD);MMo=r(g3t,"Speech2TextTokenizer"),g3t.forEach(t),EMo=r(xPe," (Speech2Text model)"),xPe.forEach(t),CMo=i(S),Tu=n(S,"LI",{});var $Pe=s(Tu);mge=n($Pe,"STRONG",{});var h3t=s(mge);wMo=r(h3t,"speech_to_text_2"),h3t.forEach(t),AMo=r($Pe," \u2014 "),AD=n($Pe,"A",{href:!0});var u3t=s(AD);LMo=r(u3t,"Speech2Text2Tokenizer"),u3t.forEach(t),yMo=r($Pe," (Speech2Text2 model)"),$Pe.forEach(t),xMo=i(S),nl=n(S,"LI",{});var fB=s(nl);fge=n(fB,"STRONG",{});var p3t=s(fge);$Mo=r(p3t,"splinter"),p3t.forEach(t),kMo=r(fB," \u2014 "),LD=n(fB,"A",{href:!0});var _3t=s(LD);SMo=r(_3t,"SplinterTokenizer"),_3t.forEach(t),RMo=r(fB," or "),yD=n(fB,"A",{href:!0});var b3t=s(yD);PMo=r(b3t,"SplinterTokenizerFast"),b3t.forEach(t),BMo=r(fB," (Splinter model)"),fB.forEach(t),IMo=i(S),sl=n(S,"LI",{});var gB=s(sl);gge=n(gB,"STRONG",{});var v3t=s(gge);NMo=r(v3t,"squeezebert"),v3t.forEach(t),qMo=r(gB," \u2014 "),xD=n(gB,"A",{href:!0});var F3t=s(xD);jMo=r(F3t,"SqueezeBertTokenizer"),F3t.forEach(t),DMo=r(gB," or "),$D=n(gB,"A",{href:!0});var T3t=s($D);GMo=r(T3t,"SqueezeBertTokenizerFast"),T3t.forEach(t),OMo=r(gB," (SqueezeBERT model)"),gB.forEach(t),VMo=i(S),ll=n(S,"LI",{});var hB=s(ll);hge=n(hB,"STRONG",{});var M3t=s(hge);XMo=r(M3t,"t5"),M3t.forEach(t),zMo=r(hB," \u2014 "),kD=n(hB,"A",{href:!0});var E3t=s(kD);QMo=r(E3t,"T5Tokenizer"),E3t.forEach(t),WMo=r(hB," or "),SD=n(hB,"A",{href:!0});var C3t=s(SD);UMo=r(C3t,"T5TokenizerFast"),C3t.forEach(t),HMo=r(hB," (T5 model)"),hB.forEach(t),JMo=i(S),Mu=n(S,"LI",{});var kPe=s(Mu);uge=n(kPe,"STRONG",{});var w3t=s(uge);YMo=r(w3t,"tapas"),w3t.forEach(t),KMo=r(kPe," \u2014 "),RD=n(kPe,"A",{href:!0});var A3t=s(RD);ZMo=r(A3t,"TapasTokenizer"),A3t.forEach(t),eEo=r(kPe," (TAPAS model)"),kPe.forEach(t),oEo=i(S),Eu=n(S,"LI",{});var SPe=s(Eu);pge=n(SPe,"STRONG",{});var L3t=s(pge);rEo=r(L3t,"tapex"),L3t.forEach(t),tEo=r(SPe," \u2014 "),PD=n(SPe,"A",{href:!0});var y3t=s(PD);aEo=r(y3t,"TapexTokenizer"),y3t.forEach(t),nEo=r(SPe," (TAPEX model)"),SPe.forEach(t),sEo=i(S),Cu=n(S,"LI",{});var RPe=s(Cu);_ge=n(RPe,"STRONG",{});var x3t=s(_ge);lEo=r(x3t,"transfo-xl"),x3t.forEach(t),iEo=r(RPe," \u2014 "),BD=n(RPe,"A",{href:!0});var $3t=s(BD);dEo=r($3t,"TransfoXLTokenizer"),$3t.forEach(t),cEo=r(RPe," (Transformer-XL model)"),RPe.forEach(t),mEo=i(S),il=n(S,"LI",{});var uB=s(il);bge=n(uB,"STRONG",{});var k3t=s(bge);fEo=r(k3t,"vilt"),k3t.forEach(t),gEo=r(uB," \u2014 "),ID=n(uB,"A",{href:!0});var S3t=s(ID);hEo=r(S3t,"BertTokenizer"),S3t.forEach(t),uEo=r(uB," or "),ND=n(uB,"A",{href:!0});var R3t=s(ND);pEo=r(R3t,"BertTokenizerFast"),R3t.forEach(t),_Eo=r(uB," (ViLT model)"),uB.forEach(t),bEo=i(S),dl=n(S,"LI",{});var pB=s(dl);vge=n(pB,"STRONG",{});var P3t=s(vge);vEo=r(P3t,"visual_bert"),P3t.forEach(t),FEo=r(pB," \u2014 "),qD=n(pB,"A",{href:!0});var B3t=s(qD);TEo=r(B3t,"BertTokenizer"),B3t.forEach(t),MEo=r(pB," or "),jD=n(pB,"A",{href:!0});var I3t=s(jD);EEo=r(I3t,"BertTokenizerFast"),I3t.forEach(t),CEo=r(pB," (VisualBERT model)"),pB.forEach(t),wEo=i(S),wu=n(S,"LI",{});var PPe=s(wu);Fge=n(PPe,"STRONG",{});var N3t=s(Fge);AEo=r(N3t,"wav2vec2"),N3t.forEach(t),LEo=r(PPe," \u2014 "),DD=n(PPe,"A",{href:!0});var q3t=s(DD);yEo=r(q3t,"Wav2Vec2CTCTokenizer"),q3t.forEach(t),xEo=r(PPe," (Wav2Vec2 model)"),PPe.forEach(t),$Eo=i(S),Au=n(S,"LI",{});var BPe=s(Au);Tge=n(BPe,"STRONG",{});var j3t=s(Tge);kEo=r(j3t,"wav2vec2-conformer"),j3t.forEach(t),SEo=r(BPe," \u2014 "),GD=n(BPe,"A",{href:!0});var D3t=s(GD);REo=r(D3t,"Wav2Vec2CTCTokenizer"),D3t.forEach(t),PEo=r(BPe," (Wav2Vec2-Conformer model)"),BPe.forEach(t),BEo=i(S),Lu=n(S,"LI",{});var IPe=s(Lu);Mge=n(IPe,"STRONG",{});var G3t=s(Mge);IEo=r(G3t,"wav2vec2_phoneme"),G3t.forEach(t),NEo=r(IPe," \u2014 "),OD=n(IPe,"A",{href:!0});var O3t=s(OD);qEo=r(O3t,"Wav2Vec2PhonemeCTCTokenizer"),O3t.forEach(t),jEo=r(IPe," (Wav2Vec2Phoneme model)"),IPe.forEach(t),DEo=i(S),cl=n(S,"LI",{});var _B=s(cl);Ege=n(_B,"STRONG",{});var V3t=s(Ege);GEo=r(V3t,"xclip"),V3t.forEach(t),OEo=r(_B," \u2014 "),VD=n(_B,"A",{href:!0});var X3t=s(VD);VEo=r(X3t,"CLIPTokenizer"),X3t.forEach(t),XEo=r(_B," or "),XD=n(_B,"A",{href:!0});var z3t=s(XD);zEo=r(z3t,"CLIPTokenizerFast"),z3t.forEach(t),QEo=r(_B," (X-CLIP model)"),_B.forEach(t),WEo=i(S),ml=n(S,"LI",{});var bB=s(ml);Cge=n(bB,"STRONG",{});var Q3t=s(Cge);UEo=r(Q3t,"xglm"),Q3t.forEach(t),HEo=r(bB," \u2014 "),zD=n(bB,"A",{href:!0});var W3t=s(zD);JEo=r(W3t,"XGLMTokenizer"),W3t.forEach(t),YEo=r(bB," or "),QD=n(bB,"A",{href:!0});var U3t=s(QD);KEo=r(U3t,"XGLMTokenizerFast"),U3t.forEach(t),ZEo=r(bB," (XGLM model)"),bB.forEach(t),e4o=i(S),yu=n(S,"LI",{});var NPe=s(yu);wge=n(NPe,"STRONG",{});var H3t=s(wge);o4o=r(H3t,"xlm"),H3t.forEach(t),r4o=r(NPe," \u2014 "),WD=n(NPe,"A",{href:!0});var J3t=s(WD);t4o=r(J3t,"XLMTokenizer"),J3t.forEach(t),a4o=r(NPe," (XLM model)"),NPe.forEach(t),n4o=i(S),xu=n(S,"LI",{});var qPe=s(xu);Age=n(qPe,"STRONG",{});var Y3t=s(Age);s4o=r(Y3t,"xlm-prophetnet"),Y3t.forEach(t),l4o=r(qPe," \u2014 "),UD=n(qPe,"A",{href:!0});var K3t=s(UD);i4o=r(K3t,"XLMProphetNetTokenizer"),K3t.forEach(t),d4o=r(qPe," (XLM-ProphetNet model)"),qPe.forEach(t),c4o=i(S),fl=n(S,"LI",{});var vB=s(fl);Lge=n(vB,"STRONG",{});var Z3t=s(Lge);m4o=r(Z3t,"xlm-roberta"),Z3t.forEach(t),f4o=r(vB," \u2014 "),HD=n(vB,"A",{href:!0});var e5t=s(HD);g4o=r(e5t,"XLMRobertaTokenizer"),e5t.forEach(t),h4o=r(vB," or "),JD=n(vB,"A",{href:!0});var o5t=s(JD);u4o=r(o5t,"XLMRobertaTokenizerFast"),o5t.forEach(t),p4o=r(vB," (XLM-RoBERTa model)"),vB.forEach(t),_4o=i(S),gl=n(S,"LI",{});var FB=s(gl);yge=n(FB,"STRONG",{});var r5t=s(yge);b4o=r(r5t,"xlm-roberta-xl"),r5t.forEach(t),v4o=r(FB," \u2014 "),YD=n(FB,"A",{href:!0});var t5t=s(YD);F4o=r(t5t,"XLMRobertaTokenizer"),t5t.forEach(t),T4o=r(FB," or "),KD=n(FB,"A",{href:!0});var a5t=s(KD);M4o=r(a5t,"XLMRobertaTokenizerFast"),a5t.forEach(t),E4o=r(FB," (XLM-RoBERTa-XL model)"),FB.forEach(t),C4o=i(S),hl=n(S,"LI",{});var TB=s(hl);xge=n(TB,"STRONG",{});var n5t=s(xge);w4o=r(n5t,"xlnet"),n5t.forEach(t),A4o=r(TB," \u2014 "),ZD=n(TB,"A",{href:!0});var s5t=s(ZD);L4o=r(s5t,"XLNetTokenizer"),s5t.forEach(t),y4o=r(TB," or "),eG=n(TB,"A",{href:!0});var l5t=s(eG);x4o=r(l5t,"XLNetTokenizerFast"),l5t.forEach(t),$4o=r(TB," (XLNet model)"),TB.forEach(t),k4o=i(S),ul=n(S,"LI",{});var MB=s(ul);$ge=n(MB,"STRONG",{});var i5t=s($ge);S4o=r(i5t,"yoso"),i5t.forEach(t),R4o=r(MB," \u2014 "),oG=n(MB,"A",{href:!0});var d5t=s(oG);P4o=r(d5t,"AlbertTokenizer"),d5t.forEach(t),B4o=r(MB," or "),rG=n(MB,"A",{href:!0});var c5t=s(rG);I4o=r(c5t,"AlbertTokenizerFast"),c5t.forEach(t),N4o=r(MB," (YOSO model)"),MB.forEach(t),S.forEach(t),q4o=i(Ml),T($u.$$.fragment,Ml),Ml.forEach(t),j4o=i(Tl),ku=n(Tl,"DIV",{class:!0});var feo=s(ku);T(G9.$$.fragment,feo),D4o=i(feo),kge=n(feo,"P",{});var m5t=s(kge);G4o=r(m5t,"Register a new tokenizer in this mapping."),m5t.forEach(t),feo.forEach(t),Tl.forEach(t),tKe=i(m),gd=n(m,"H2",{class:!0});var geo=s(gd);Su=n(geo,"A",{id:!0,class:!0,href:!0});var f5t=s(Su);Sge=n(f5t,"SPAN",{});var g5t=s(Sge);T(O9.$$.fragment,g5t),g5t.forEach(t),f5t.forEach(t),O4o=i(geo),Rge=n(geo,"SPAN",{});var h5t=s(Rge);V4o=r(h5t,"AutoFeatureExtractor"),h5t.forEach(t),geo.forEach(t),aKe=i(m),So=n(m,"DIV",{class:!0});var El=s(So);T(V9.$$.fragment,El),X4o=i(El),X9=n(El,"P",{});var heo=s(X9);z4o=r(heo,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),tG=n(heo,"A",{href:!0});var u5t=s(tG);Q4o=r(u5t,"AutoFeatureExtractor.from_pretrained()"),u5t.forEach(t),W4o=r(heo," class method."),heo.forEach(t),U4o=i(El),z9=n(El,"P",{});var ueo=s(z9);H4o=r(ueo,"This class cannot be instantiated directly using "),Pge=n(ueo,"CODE",{});var p5t=s(Pge);J4o=r(p5t,"__init__()"),p5t.forEach(t),Y4o=r(ueo," (throws an error)."),ueo.forEach(t),K4o=i(El),Ye=n(El,"DIV",{class:!0});var ba=s(Ye);T(Q9.$$.fragment,ba),Z4o=i(ba),Bge=n(ba,"P",{});var _5t=s(Bge);eCo=r(_5t,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),_5t.forEach(t),oCo=i(ba),Ha=n(ba,"P",{});var My=s(Ha);rCo=r(My,"The feature extractor class to instantiate is selected based on the "),Ige=n(My,"CODE",{});var b5t=s(Ige);tCo=r(b5t,"model_type"),b5t.forEach(t),aCo=r(My,` property of the config object
(either passed as an argument or loaded from `),Nge=n(My,"CODE",{});var v5t=s(Nge);nCo=r(v5t,"pretrained_model_name_or_path"),v5t.forEach(t),sCo=r(My,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),qge=n(My,"CODE",{});var F5t=s(qge);lCo=r(F5t,"pretrained_model_name_or_path"),F5t.forEach(t),iCo=r(My,":"),My.forEach(t),dCo=i(ba),Q=n(ba,"UL",{});var H=s(Q);Ru=n(H,"LI",{});var jPe=s(Ru);jge=n(jPe,"STRONG",{});var T5t=s(jge);cCo=r(T5t,"beit"),T5t.forEach(t),mCo=r(jPe," \u2014 "),aG=n(jPe,"A",{href:!0});var M5t=s(aG);fCo=r(M5t,"BeitFeatureExtractor"),M5t.forEach(t),gCo=r(jPe," (BEiT model)"),jPe.forEach(t),hCo=i(H),Pu=n(H,"LI",{});var DPe=s(Pu);Dge=n(DPe,"STRONG",{});var E5t=s(Dge);uCo=r(E5t,"clip"),E5t.forEach(t),pCo=r(DPe," \u2014 "),nG=n(DPe,"A",{href:!0});var C5t=s(nG);_Co=r(C5t,"CLIPFeatureExtractor"),C5t.forEach(t),bCo=r(DPe," (CLIP model)"),DPe.forEach(t),vCo=i(H),Bu=n(H,"LI",{});var GPe=s(Bu);Gge=n(GPe,"STRONG",{});var w5t=s(Gge);FCo=r(w5t,"convnext"),w5t.forEach(t),TCo=r(GPe," \u2014 "),sG=n(GPe,"A",{href:!0});var A5t=s(sG);MCo=r(A5t,"ConvNextFeatureExtractor"),A5t.forEach(t),ECo=r(GPe," (ConvNeXT model)"),GPe.forEach(t),CCo=i(H),Iu=n(H,"LI",{});var OPe=s(Iu);Oge=n(OPe,"STRONG",{});var L5t=s(Oge);wCo=r(L5t,"cvt"),L5t.forEach(t),ACo=r(OPe," \u2014 "),lG=n(OPe,"A",{href:!0});var y5t=s(lG);LCo=r(y5t,"ConvNextFeatureExtractor"),y5t.forEach(t),yCo=r(OPe," (CvT model)"),OPe.forEach(t),xCo=i(H),Nu=n(H,"LI",{});var VPe=s(Nu);Vge=n(VPe,"STRONG",{});var x5t=s(Vge);$Co=r(x5t,"data2vec-audio"),x5t.forEach(t),kCo=r(VPe," \u2014 "),iG=n(VPe,"A",{href:!0});var $5t=s(iG);SCo=r($5t,"Wav2Vec2FeatureExtractor"),$5t.forEach(t),RCo=r(VPe," (Data2VecAudio model)"),VPe.forEach(t),PCo=i(H),qu=n(H,"LI",{});var XPe=s(qu);Xge=n(XPe,"STRONG",{});var k5t=s(Xge);BCo=r(k5t,"data2vec-vision"),k5t.forEach(t),ICo=r(XPe," \u2014 "),dG=n(XPe,"A",{href:!0});var S5t=s(dG);NCo=r(S5t,"BeitFeatureExtractor"),S5t.forEach(t),qCo=r(XPe," (Data2VecVision model)"),XPe.forEach(t),jCo=i(H),ju=n(H,"LI",{});var zPe=s(ju);zge=n(zPe,"STRONG",{});var R5t=s(zge);DCo=r(R5t,"deformable_detr"),R5t.forEach(t),GCo=r(zPe," \u2014 "),cG=n(zPe,"A",{href:!0});var P5t=s(cG);OCo=r(P5t,"DetrFeatureExtractor"),P5t.forEach(t),VCo=r(zPe," (Deformable DETR model)"),zPe.forEach(t),XCo=i(H),Du=n(H,"LI",{});var QPe=s(Du);Qge=n(QPe,"STRONG",{});var B5t=s(Qge);zCo=r(B5t,"deit"),B5t.forEach(t),QCo=r(QPe," \u2014 "),mG=n(QPe,"A",{href:!0});var I5t=s(mG);WCo=r(I5t,"DeiTFeatureExtractor"),I5t.forEach(t),UCo=r(QPe," (DeiT model)"),QPe.forEach(t),HCo=i(H),Gu=n(H,"LI",{});var WPe=s(Gu);Wge=n(WPe,"STRONG",{});var N5t=s(Wge);JCo=r(N5t,"detr"),N5t.forEach(t),YCo=r(WPe," \u2014 "),fG=n(WPe,"A",{href:!0});var q5t=s(fG);KCo=r(q5t,"DetrFeatureExtractor"),q5t.forEach(t),ZCo=r(WPe," (DETR model)"),WPe.forEach(t),e3o=i(H),Ou=n(H,"LI",{});var UPe=s(Ou);Uge=n(UPe,"STRONG",{});var j5t=s(Uge);o3o=r(j5t,"donut"),j5t.forEach(t),r3o=r(UPe," \u2014 "),gG=n(UPe,"A",{href:!0});var D5t=s(gG);t3o=r(D5t,"DonutFeatureExtractor"),D5t.forEach(t),a3o=r(UPe," (Donut model)"),UPe.forEach(t),n3o=i(H),Vu=n(H,"LI",{});var HPe=s(Vu);Hge=n(HPe,"STRONG",{});var G5t=s(Hge);s3o=r(G5t,"dpt"),G5t.forEach(t),l3o=r(HPe," \u2014 "),hG=n(HPe,"A",{href:!0});var O5t=s(hG);i3o=r(O5t,"DPTFeatureExtractor"),O5t.forEach(t),d3o=r(HPe," (DPT model)"),HPe.forEach(t),c3o=i(H),Xu=n(H,"LI",{});var JPe=s(Xu);Jge=n(JPe,"STRONG",{});var V5t=s(Jge);m3o=r(V5t,"flava"),V5t.forEach(t),f3o=r(JPe," \u2014 "),uG=n(JPe,"A",{href:!0});var X5t=s(uG);g3o=r(X5t,"FlavaFeatureExtractor"),X5t.forEach(t),h3o=r(JPe," (FLAVA model)"),JPe.forEach(t),u3o=i(H),zu=n(H,"LI",{});var YPe=s(zu);Yge=n(YPe,"STRONG",{});var z5t=s(Yge);p3o=r(z5t,"glpn"),z5t.forEach(t),_3o=r(YPe," \u2014 "),pG=n(YPe,"A",{href:!0});var Q5t=s(pG);b3o=r(Q5t,"GLPNFeatureExtractor"),Q5t.forEach(t),v3o=r(YPe," (GLPN model)"),YPe.forEach(t),F3o=i(H),Qu=n(H,"LI",{});var KPe=s(Qu);Kge=n(KPe,"STRONG",{});var W5t=s(Kge);T3o=r(W5t,"groupvit"),W5t.forEach(t),M3o=r(KPe," \u2014 "),_G=n(KPe,"A",{href:!0});var U5t=s(_G);E3o=r(U5t,"CLIPFeatureExtractor"),U5t.forEach(t),C3o=r(KPe," (GroupViT model)"),KPe.forEach(t),w3o=i(H),Wu=n(H,"LI",{});var ZPe=s(Wu);Zge=n(ZPe,"STRONG",{});var H5t=s(Zge);A3o=r(H5t,"hubert"),H5t.forEach(t),L3o=r(ZPe," \u2014 "),bG=n(ZPe,"A",{href:!0});var J5t=s(bG);y3o=r(J5t,"Wav2Vec2FeatureExtractor"),J5t.forEach(t),x3o=r(ZPe," (Hubert model)"),ZPe.forEach(t),$3o=i(H),Uu=n(H,"LI",{});var eBe=s(Uu);ehe=n(eBe,"STRONG",{});var Y5t=s(ehe);k3o=r(Y5t,"imagegpt"),Y5t.forEach(t),S3o=r(eBe," \u2014 "),vG=n(eBe,"A",{href:!0});var K5t=s(vG);R3o=r(K5t,"ImageGPTFeatureExtractor"),K5t.forEach(t),P3o=r(eBe," (ImageGPT model)"),eBe.forEach(t),B3o=i(H),Hu=n(H,"LI",{});var oBe=s(Hu);ohe=n(oBe,"STRONG",{});var Z5t=s(ohe);I3o=r(Z5t,"layoutlmv2"),Z5t.forEach(t),N3o=r(oBe," \u2014 "),FG=n(oBe,"A",{href:!0});var e0t=s(FG);q3o=r(e0t,"LayoutLMv2FeatureExtractor"),e0t.forEach(t),j3o=r(oBe," (LayoutLMv2 model)"),oBe.forEach(t),D3o=i(H),Ju=n(H,"LI",{});var rBe=s(Ju);rhe=n(rBe,"STRONG",{});var o0t=s(rhe);G3o=r(o0t,"layoutlmv3"),o0t.forEach(t),O3o=r(rBe," \u2014 "),TG=n(rBe,"A",{href:!0});var r0t=s(TG);V3o=r(r0t,"LayoutLMv3FeatureExtractor"),r0t.forEach(t),X3o=r(rBe," (LayoutLMv3 model)"),rBe.forEach(t),z3o=i(H),Yu=n(H,"LI",{});var tBe=s(Yu);the=n(tBe,"STRONG",{});var t0t=s(the);Q3o=r(t0t,"levit"),t0t.forEach(t),W3o=r(tBe," \u2014 "),MG=n(tBe,"A",{href:!0});var a0t=s(MG);U3o=r(a0t,"LevitFeatureExtractor"),a0t.forEach(t),H3o=r(tBe," (LeViT model)"),tBe.forEach(t),J3o=i(H),Ku=n(H,"LI",{});var aBe=s(Ku);ahe=n(aBe,"STRONG",{});var n0t=s(ahe);Y3o=r(n0t,"maskformer"),n0t.forEach(t),K3o=r(aBe," \u2014 "),EG=n(aBe,"A",{href:!0});var s0t=s(EG);Z3o=r(s0t,"MaskFormerFeatureExtractor"),s0t.forEach(t),e5o=r(aBe," (MaskFormer model)"),aBe.forEach(t),o5o=i(H),Zu=n(H,"LI",{});var nBe=s(Zu);nhe=n(nBe,"STRONG",{});var l0t=s(nhe);r5o=r(l0t,"mctct"),l0t.forEach(t),t5o=r(nBe," \u2014 "),CG=n(nBe,"A",{href:!0});var i0t=s(CG);a5o=r(i0t,"MCTCTFeatureExtractor"),i0t.forEach(t),n5o=r(nBe," (M-CTC-T model)"),nBe.forEach(t),s5o=i(H),ep=n(H,"LI",{});var sBe=s(ep);she=n(sBe,"STRONG",{});var d0t=s(she);l5o=r(d0t,"mobilevit"),d0t.forEach(t),i5o=r(sBe," \u2014 "),wG=n(sBe,"A",{href:!0});var c0t=s(wG);d5o=r(c0t,"MobileViTFeatureExtractor"),c0t.forEach(t),c5o=r(sBe," (MobileViT model)"),sBe.forEach(t),m5o=i(H),op=n(H,"LI",{});var lBe=s(op);lhe=n(lBe,"STRONG",{});var m0t=s(lhe);f5o=r(m0t,"owlvit"),m0t.forEach(t),g5o=r(lBe," \u2014 "),AG=n(lBe,"A",{href:!0});var f0t=s(AG);h5o=r(f0t,"OwlViTFeatureExtractor"),f0t.forEach(t),u5o=r(lBe," (OWL-ViT model)"),lBe.forEach(t),p5o=i(H),rp=n(H,"LI",{});var iBe=s(rp);ihe=n(iBe,"STRONG",{});var g0t=s(ihe);_5o=r(g0t,"perceiver"),g0t.forEach(t),b5o=r(iBe," \u2014 "),LG=n(iBe,"A",{href:!0});var h0t=s(LG);v5o=r(h0t,"PerceiverFeatureExtractor"),h0t.forEach(t),F5o=r(iBe," (Perceiver model)"),iBe.forEach(t),T5o=i(H),tp=n(H,"LI",{});var dBe=s(tp);dhe=n(dBe,"STRONG",{});var u0t=s(dhe);M5o=r(u0t,"poolformer"),u0t.forEach(t),E5o=r(dBe," \u2014 "),yG=n(dBe,"A",{href:!0});var p0t=s(yG);C5o=r(p0t,"PoolFormerFeatureExtractor"),p0t.forEach(t),w5o=r(dBe," (PoolFormer model)"),dBe.forEach(t),A5o=i(H),ap=n(H,"LI",{});var cBe=s(ap);che=n(cBe,"STRONG",{});var _0t=s(che);L5o=r(_0t,"regnet"),_0t.forEach(t),y5o=r(cBe," \u2014 "),xG=n(cBe,"A",{href:!0});var b0t=s(xG);x5o=r(b0t,"ConvNextFeatureExtractor"),b0t.forEach(t),$5o=r(cBe," (RegNet model)"),cBe.forEach(t),k5o=i(H),np=n(H,"LI",{});var mBe=s(np);mhe=n(mBe,"STRONG",{});var v0t=s(mhe);S5o=r(v0t,"resnet"),v0t.forEach(t),R5o=r(mBe," \u2014 "),$G=n(mBe,"A",{href:!0});var F0t=s($G);P5o=r(F0t,"ConvNextFeatureExtractor"),F0t.forEach(t),B5o=r(mBe," (ResNet model)"),mBe.forEach(t),I5o=i(H),sp=n(H,"LI",{});var fBe=s(sp);fhe=n(fBe,"STRONG",{});var T0t=s(fhe);N5o=r(T0t,"segformer"),T0t.forEach(t),q5o=r(fBe," \u2014 "),kG=n(fBe,"A",{href:!0});var M0t=s(kG);j5o=r(M0t,"SegformerFeatureExtractor"),M0t.forEach(t),D5o=r(fBe," (SegFormer model)"),fBe.forEach(t),G5o=i(H),lp=n(H,"LI",{});var gBe=s(lp);ghe=n(gBe,"STRONG",{});var E0t=s(ghe);O5o=r(E0t,"speech_to_text"),E0t.forEach(t),V5o=r(gBe," \u2014 "),SG=n(gBe,"A",{href:!0});var C0t=s(SG);X5o=r(C0t,"Speech2TextFeatureExtractor"),C0t.forEach(t),z5o=r(gBe," (Speech2Text model)"),gBe.forEach(t),Q5o=i(H),ip=n(H,"LI",{});var hBe=s(ip);hhe=n(hBe,"STRONG",{});var w0t=s(hhe);W5o=r(w0t,"swin"),w0t.forEach(t),U5o=r(hBe," \u2014 "),RG=n(hBe,"A",{href:!0});var A0t=s(RG);H5o=r(A0t,"ViTFeatureExtractor"),A0t.forEach(t),J5o=r(hBe," (Swin Transformer model)"),hBe.forEach(t),Y5o=i(H),dp=n(H,"LI",{});var uBe=s(dp);uhe=n(uBe,"STRONG",{});var L0t=s(uhe);K5o=r(L0t,"swinv2"),L0t.forEach(t),Z5o=r(uBe," \u2014 "),PG=n(uBe,"A",{href:!0});var y0t=s(PG);e0o=r(y0t,"ViTFeatureExtractor"),y0t.forEach(t),o0o=r(uBe," (Swin Transformer V2 model)"),uBe.forEach(t),r0o=i(H),cp=n(H,"LI",{});var pBe=s(cp);phe=n(pBe,"STRONG",{});var x0t=s(phe);t0o=r(x0t,"van"),x0t.forEach(t),a0o=r(pBe," \u2014 "),BG=n(pBe,"A",{href:!0});var $0t=s(BG);n0o=r($0t,"ConvNextFeatureExtractor"),$0t.forEach(t),s0o=r(pBe," (VAN model)"),pBe.forEach(t),l0o=i(H),mp=n(H,"LI",{});var _Be=s(mp);_he=n(_Be,"STRONG",{});var k0t=s(_he);i0o=r(k0t,"videomae"),k0t.forEach(t),d0o=r(_Be," \u2014 "),IG=n(_Be,"A",{href:!0});var S0t=s(IG);c0o=r(S0t,"VideoMAEFeatureExtractor"),S0t.forEach(t),m0o=r(_Be," (VideoMAE model)"),_Be.forEach(t),f0o=i(H),fp=n(H,"LI",{});var bBe=s(fp);bhe=n(bBe,"STRONG",{});var R0t=s(bhe);g0o=r(R0t,"vilt"),R0t.forEach(t),h0o=r(bBe," \u2014 "),NG=n(bBe,"A",{href:!0});var P0t=s(NG);u0o=r(P0t,"ViltFeatureExtractor"),P0t.forEach(t),p0o=r(bBe," (ViLT model)"),bBe.forEach(t),_0o=i(H),gp=n(H,"LI",{});var vBe=s(gp);vhe=n(vBe,"STRONG",{});var B0t=s(vhe);b0o=r(B0t,"vit"),B0t.forEach(t),v0o=r(vBe," \u2014 "),qG=n(vBe,"A",{href:!0});var I0t=s(qG);F0o=r(I0t,"ViTFeatureExtractor"),I0t.forEach(t),T0o=r(vBe," (ViT model)"),vBe.forEach(t),M0o=i(H),hp=n(H,"LI",{});var FBe=s(hp);Fhe=n(FBe,"STRONG",{});var N0t=s(Fhe);E0o=r(N0t,"vit_mae"),N0t.forEach(t),C0o=r(FBe," \u2014 "),jG=n(FBe,"A",{href:!0});var q0t=s(jG);w0o=r(q0t,"ViTFeatureExtractor"),q0t.forEach(t),A0o=r(FBe," (ViTMAE model)"),FBe.forEach(t),L0o=i(H),up=n(H,"LI",{});var TBe=s(up);The=n(TBe,"STRONG",{});var j0t=s(The);y0o=r(j0t,"wav2vec2"),j0t.forEach(t),x0o=r(TBe," \u2014 "),DG=n(TBe,"A",{href:!0});var D0t=s(DG);$0o=r(D0t,"Wav2Vec2FeatureExtractor"),D0t.forEach(t),k0o=r(TBe," (Wav2Vec2 model)"),TBe.forEach(t),S0o=i(H),pp=n(H,"LI",{});var MBe=s(pp);Mhe=n(MBe,"STRONG",{});var G0t=s(Mhe);R0o=r(G0t,"wav2vec2-conformer"),G0t.forEach(t),P0o=r(MBe," \u2014 "),GG=n(MBe,"A",{href:!0});var O0t=s(GG);B0o=r(O0t,"Wav2Vec2FeatureExtractor"),O0t.forEach(t),I0o=r(MBe," (Wav2Vec2-Conformer model)"),MBe.forEach(t),N0o=i(H),_p=n(H,"LI",{});var EBe=s(_p);Ehe=n(EBe,"STRONG",{});var V0t=s(Ehe);q0o=r(V0t,"xclip"),V0t.forEach(t),j0o=r(EBe," \u2014 "),OG=n(EBe,"A",{href:!0});var X0t=s(OG);D0o=r(X0t,"CLIPFeatureExtractor"),X0t.forEach(t),G0o=r(EBe," (X-CLIP model)"),EBe.forEach(t),O0o=i(H),bp=n(H,"LI",{});var CBe=s(bp);Che=n(CBe,"STRONG",{});var z0t=s(Che);V0o=r(z0t,"yolos"),z0t.forEach(t),X0o=r(CBe," \u2014 "),VG=n(CBe,"A",{href:!0});var Q0t=s(VG);z0o=r(Q0t,"YolosFeatureExtractor"),Q0t.forEach(t),Q0o=r(CBe," (YOLOS model)"),CBe.forEach(t),H.forEach(t),W0o=i(ba),T(vp.$$.fragment,ba),U0o=i(ba),T(Fp.$$.fragment,ba),ba.forEach(t),H0o=i(El),Tp=n(El,"DIV",{class:!0});var peo=s(Tp);T(W9.$$.fragment,peo),J0o=i(peo),whe=n(peo,"P",{});var W0t=s(whe);Y0o=r(W0t,"Register a new feature extractor for this class."),W0t.forEach(t),peo.forEach(t),El.forEach(t),nKe=i(m),hd=n(m,"H2",{class:!0});var _eo=s(hd);Mp=n(_eo,"A",{id:!0,class:!0,href:!0});var U0t=s(Mp);Ahe=n(U0t,"SPAN",{});var H0t=s(Ahe);T(U9.$$.fragment,H0t),H0t.forEach(t),U0t.forEach(t),K0o=i(_eo),Lhe=n(_eo,"SPAN",{});var J0t=s(Lhe);Z0o=r(J0t,"AutoProcessor"),J0t.forEach(t),_eo.forEach(t),sKe=i(m),Ro=n(m,"DIV",{class:!0});var Cl=s(Ro);T(H9.$$.fragment,Cl),ewo=i(Cl),J9=n(Cl,"P",{});var beo=s(J9);owo=r(beo,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),XG=n(beo,"A",{href:!0});var Y0t=s(XG);rwo=r(Y0t,"AutoProcessor.from_pretrained()"),Y0t.forEach(t),two=r(beo," class method."),beo.forEach(t),awo=i(Cl),Y9=n(Cl,"P",{});var veo=s(Y9);nwo=r(veo,"This class cannot be instantiated directly using "),yhe=n(veo,"CODE",{});var K0t=s(yhe);swo=r(K0t,"__init__()"),K0t.forEach(t),lwo=r(veo," (throws an error)."),veo.forEach(t),iwo=i(Cl),Ke=n(Cl,"DIV",{class:!0});var va=s(Ke);T(K9.$$.fragment,va),dwo=i(va),xhe=n(va,"P",{});var Z0t=s(xhe);cwo=r(Z0t,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),Z0t.forEach(t),mwo=i(va),ud=n(va,"P",{});var ele=s(ud);fwo=r(ele,"The processor class to instantiate is selected based on the "),$he=n(ele,"CODE",{});var ewt=s($he);gwo=r(ewt,"model_type"),ewt.forEach(t),hwo=r(ele,` property of the config object (either
passed as an argument or loaded from `),khe=n(ele,"CODE",{});var owt=s(khe);uwo=r(owt,"pretrained_model_name_or_path"),owt.forEach(t),pwo=r(ele," if possible):"),ele.forEach(t),_wo=i(va),ie=n(va,"UL",{});var ge=s(ie);Ep=n(ge,"LI",{});var wBe=s(Ep);She=n(wBe,"STRONG",{});var rwt=s(She);bwo=r(rwt,"clip"),rwt.forEach(t),vwo=r(wBe," \u2014 "),zG=n(wBe,"A",{href:!0});var twt=s(zG);Fwo=r(twt,"CLIPProcessor"),twt.forEach(t),Two=r(wBe," (CLIP model)"),wBe.forEach(t),Mwo=i(ge),Cp=n(ge,"LI",{});var ABe=s(Cp);Rhe=n(ABe,"STRONG",{});var awt=s(Rhe);Ewo=r(awt,"donut"),awt.forEach(t),Cwo=r(ABe," \u2014 "),QG=n(ABe,"A",{href:!0});var nwt=s(QG);wwo=r(nwt,"DonutProcessor"),nwt.forEach(t),Awo=r(ABe," (Donut model)"),ABe.forEach(t),Lwo=i(ge),wp=n(ge,"LI",{});var LBe=s(wp);Phe=n(LBe,"STRONG",{});var swt=s(Phe);ywo=r(swt,"flava"),swt.forEach(t),xwo=r(LBe," \u2014 "),WG=n(LBe,"A",{href:!0});var lwt=s(WG);$wo=r(lwt,"FlavaProcessor"),lwt.forEach(t),kwo=r(LBe," (FLAVA model)"),LBe.forEach(t),Swo=i(ge),Ap=n(ge,"LI",{});var yBe=s(Ap);Bhe=n(yBe,"STRONG",{});var iwt=s(Bhe);Rwo=r(iwt,"groupvit"),iwt.forEach(t),Pwo=r(yBe," \u2014 "),UG=n(yBe,"A",{href:!0});var dwt=s(UG);Bwo=r(dwt,"CLIPProcessor"),dwt.forEach(t),Iwo=r(yBe," (GroupViT model)"),yBe.forEach(t),Nwo=i(ge),Lp=n(ge,"LI",{});var xBe=s(Lp);Ihe=n(xBe,"STRONG",{});var cwt=s(Ihe);qwo=r(cwt,"layoutlmv2"),cwt.forEach(t),jwo=r(xBe," \u2014 "),HG=n(xBe,"A",{href:!0});var mwt=s(HG);Dwo=r(mwt,"LayoutLMv2Processor"),mwt.forEach(t),Gwo=r(xBe," (LayoutLMv2 model)"),xBe.forEach(t),Owo=i(ge),yp=n(ge,"LI",{});var $Be=s(yp);Nhe=n($Be,"STRONG",{});var fwt=s(Nhe);Vwo=r(fwt,"layoutlmv3"),fwt.forEach(t),Xwo=r($Be," \u2014 "),JG=n($Be,"A",{href:!0});var gwt=s(JG);zwo=r(gwt,"LayoutLMv3Processor"),gwt.forEach(t),Qwo=r($Be," (LayoutLMv3 model)"),$Be.forEach(t),Wwo=i(ge),xp=n(ge,"LI",{});var kBe=s(xp);qhe=n(kBe,"STRONG",{});var hwt=s(qhe);Uwo=r(hwt,"layoutxlm"),hwt.forEach(t),Hwo=r(kBe," \u2014 "),YG=n(kBe,"A",{href:!0});var uwt=s(YG);Jwo=r(uwt,"LayoutXLMProcessor"),uwt.forEach(t),Ywo=r(kBe," (LayoutXLM model)"),kBe.forEach(t),Kwo=i(ge),$p=n(ge,"LI",{});var SBe=s($p);jhe=n(SBe,"STRONG",{});var pwt=s(jhe);Zwo=r(pwt,"owlvit"),pwt.forEach(t),eAo=r(SBe," \u2014 "),KG=n(SBe,"A",{href:!0});var _wt=s(KG);oAo=r(_wt,"OwlViTProcessor"),_wt.forEach(t),rAo=r(SBe," (OWL-ViT model)"),SBe.forEach(t),tAo=i(ge),kp=n(ge,"LI",{});var RBe=s(kp);Dhe=n(RBe,"STRONG",{});var bwt=s(Dhe);aAo=r(bwt,"sew"),bwt.forEach(t),nAo=r(RBe," \u2014 "),ZG=n(RBe,"A",{href:!0});var vwt=s(ZG);sAo=r(vwt,"Wav2Vec2Processor"),vwt.forEach(t),lAo=r(RBe," (SEW model)"),RBe.forEach(t),iAo=i(ge),Sp=n(ge,"LI",{});var PBe=s(Sp);Ghe=n(PBe,"STRONG",{});var Fwt=s(Ghe);dAo=r(Fwt,"sew-d"),Fwt.forEach(t),cAo=r(PBe," \u2014 "),eO=n(PBe,"A",{href:!0});var Twt=s(eO);mAo=r(Twt,"Wav2Vec2Processor"),Twt.forEach(t),fAo=r(PBe," (SEW-D model)"),PBe.forEach(t),gAo=i(ge),Rp=n(ge,"LI",{});var BBe=s(Rp);Ohe=n(BBe,"STRONG",{});var Mwt=s(Ohe);hAo=r(Mwt,"speech_to_text"),Mwt.forEach(t),uAo=r(BBe," \u2014 "),oO=n(BBe,"A",{href:!0});var Ewt=s(oO);pAo=r(Ewt,"Speech2TextProcessor"),Ewt.forEach(t),_Ao=r(BBe," (Speech2Text model)"),BBe.forEach(t),bAo=i(ge),Pp=n(ge,"LI",{});var IBe=s(Pp);Vhe=n(IBe,"STRONG",{});var Cwt=s(Vhe);vAo=r(Cwt,"speech_to_text_2"),Cwt.forEach(t),FAo=r(IBe," \u2014 "),rO=n(IBe,"A",{href:!0});var wwt=s(rO);TAo=r(wwt,"Speech2Text2Processor"),wwt.forEach(t),MAo=r(IBe," (Speech2Text2 model)"),IBe.forEach(t),EAo=i(ge),Bp=n(ge,"LI",{});var NBe=s(Bp);Xhe=n(NBe,"STRONG",{});var Awt=s(Xhe);CAo=r(Awt,"trocr"),Awt.forEach(t),wAo=r(NBe," \u2014 "),tO=n(NBe,"A",{href:!0});var Lwt=s(tO);AAo=r(Lwt,"TrOCRProcessor"),Lwt.forEach(t),LAo=r(NBe," (TrOCR model)"),NBe.forEach(t),yAo=i(ge),Ip=n(ge,"LI",{});var qBe=s(Ip);zhe=n(qBe,"STRONG",{});var ywt=s(zhe);xAo=r(ywt,"unispeech"),ywt.forEach(t),$Ao=r(qBe," \u2014 "),aO=n(qBe,"A",{href:!0});var xwt=s(aO);kAo=r(xwt,"Wav2Vec2Processor"),xwt.forEach(t),SAo=r(qBe," (UniSpeech model)"),qBe.forEach(t),RAo=i(ge),Np=n(ge,"LI",{});var jBe=s(Np);Qhe=n(jBe,"STRONG",{});var $wt=s(Qhe);PAo=r($wt,"unispeech-sat"),$wt.forEach(t),BAo=r(jBe," \u2014 "),nO=n(jBe,"A",{href:!0});var kwt=s(nO);IAo=r(kwt,"Wav2Vec2Processor"),kwt.forEach(t),NAo=r(jBe," (UniSpeechSat model)"),jBe.forEach(t),qAo=i(ge),qp=n(ge,"LI",{});var DBe=s(qp);Whe=n(DBe,"STRONG",{});var Swt=s(Whe);jAo=r(Swt,"vilt"),Swt.forEach(t),DAo=r(DBe," \u2014 "),sO=n(DBe,"A",{href:!0});var Rwt=s(sO);GAo=r(Rwt,"ViltProcessor"),Rwt.forEach(t),OAo=r(DBe," (ViLT model)"),DBe.forEach(t),VAo=i(ge),jp=n(ge,"LI",{});var GBe=s(jp);Uhe=n(GBe,"STRONG",{});var Pwt=s(Uhe);XAo=r(Pwt,"vision-text-dual-encoder"),Pwt.forEach(t),zAo=r(GBe," \u2014 "),lO=n(GBe,"A",{href:!0});var Bwt=s(lO);QAo=r(Bwt,"VisionTextDualEncoderProcessor"),Bwt.forEach(t),WAo=r(GBe," (VisionTextDualEncoder model)"),GBe.forEach(t),UAo=i(ge),Dp=n(ge,"LI",{});var OBe=s(Dp);Hhe=n(OBe,"STRONG",{});var Iwt=s(Hhe);HAo=r(Iwt,"wav2vec2"),Iwt.forEach(t),JAo=r(OBe," \u2014 "),iO=n(OBe,"A",{href:!0});var Nwt=s(iO);YAo=r(Nwt,"Wav2Vec2Processor"),Nwt.forEach(t),KAo=r(OBe," (Wav2Vec2 model)"),OBe.forEach(t),ZAo=i(ge),Gp=n(ge,"LI",{});var VBe=s(Gp);Jhe=n(VBe,"STRONG",{});var qwt=s(Jhe);e6o=r(qwt,"wav2vec2-conformer"),qwt.forEach(t),o6o=r(VBe," \u2014 "),dO=n(VBe,"A",{href:!0});var jwt=s(dO);r6o=r(jwt,"Wav2Vec2Processor"),jwt.forEach(t),t6o=r(VBe," (Wav2Vec2-Conformer model)"),VBe.forEach(t),a6o=i(ge),Op=n(ge,"LI",{});var XBe=s(Op);Yhe=n(XBe,"STRONG",{});var Dwt=s(Yhe);n6o=r(Dwt,"wavlm"),Dwt.forEach(t),s6o=r(XBe," \u2014 "),cO=n(XBe,"A",{href:!0});var Gwt=s(cO);l6o=r(Gwt,"Wav2Vec2Processor"),Gwt.forEach(t),i6o=r(XBe," (WavLM model)"),XBe.forEach(t),d6o=i(ge),Vp=n(ge,"LI",{});var zBe=s(Vp);Khe=n(zBe,"STRONG",{});var Owt=s(Khe);c6o=r(Owt,"xclip"),Owt.forEach(t),m6o=r(zBe," \u2014 "),mO=n(zBe,"A",{href:!0});var Vwt=s(mO);f6o=r(Vwt,"CLIPProcessor"),Vwt.forEach(t),g6o=r(zBe," (X-CLIP model)"),zBe.forEach(t),ge.forEach(t),h6o=i(va),T(Xp.$$.fragment,va),u6o=i(va),T(zp.$$.fragment,va),va.forEach(t),p6o=i(Cl),Qp=n(Cl,"DIV",{class:!0});var Feo=s(Qp);T(Z9.$$.fragment,Feo),_6o=i(Feo),Zhe=n(Feo,"P",{});var Xwt=s(Zhe);b6o=r(Xwt,"Register a new processor for this class."),Xwt.forEach(t),Feo.forEach(t),Cl.forEach(t),lKe=i(m),pd=n(m,"H2",{class:!0});var Teo=s(pd);Wp=n(Teo,"A",{id:!0,class:!0,href:!0});var zwt=s(Wp);eue=n(zwt,"SPAN",{});var Qwt=s(eue);T(ex.$$.fragment,Qwt),Qwt.forEach(t),zwt.forEach(t),v6o=i(Teo),oue=n(Teo,"SPAN",{});var Wwt=s(oue);F6o=r(Wwt,"AutoModel"),Wwt.forEach(t),Teo.forEach(t),iKe=i(m),Po=n(m,"DIV",{class:!0});var wl=s(Po);T(ox.$$.fragment,wl),T6o=i(wl),_d=n(wl,"P",{});var ole=s(_d);M6o=r(ole,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),fO=n(ole,"A",{href:!0});var Uwt=s(fO);E6o=r(Uwt,"from_pretrained()"),Uwt.forEach(t),C6o=r(ole," class method or the "),gO=n(ole,"A",{href:!0});var Hwt=s(gO);w6o=r(Hwt,"from_config()"),Hwt.forEach(t),A6o=r(ole,` class
method.`),ole.forEach(t),L6o=i(wl),rx=n(wl,"P",{});var Meo=s(rx);y6o=r(Meo,"This class cannot be instantiated directly using "),rue=n(Meo,"CODE",{});var Jwt=s(rue);x6o=r(Jwt,"__init__()"),Jwt.forEach(t),$6o=r(Meo," (throws an error)."),Meo.forEach(t),k6o=i(wl),_t=n(wl,"DIV",{class:!0});var Ey=s(_t);T(tx.$$.fragment,Ey),S6o=i(Ey),tue=n(Ey,"P",{});var Ywt=s(tue);R6o=r(Ywt,"Instantiates one of the base model classes of the library from a configuration."),Ywt.forEach(t),P6o=i(Ey),bd=n(Ey,"P",{});var rle=s(bd);B6o=r(rle,`Note:
Loading a model from its configuration file does `),aue=n(rle,"STRONG",{});var Kwt=s(aue);I6o=r(Kwt,"not"),Kwt.forEach(t),N6o=r(rle,` load the model weights. It only affects the
model\u2019s configuration. Use `),hO=n(rle,"A",{href:!0});var Zwt=s(hO);q6o=r(Zwt,"from_pretrained()"),Zwt.forEach(t),j6o=r(rle," to load the model weights."),rle.forEach(t),D6o=i(Ey),T(Up.$$.fragment,Ey),Ey.forEach(t),G6o=i(wl),Ze=n(wl,"DIV",{class:!0});var Fa=s(Ze);T(ax.$$.fragment,Fa),O6o=i(Fa),nue=n(Fa,"P",{});var eAt=s(nue);V6o=r(eAt,"Instantiate one of the base model classes of the library from a pretrained model."),eAt.forEach(t),X6o=i(Fa),Ja=n(Fa,"P",{});var Cy=s(Ja);z6o=r(Cy,"The model class to instantiate is selected based on the "),sue=n(Cy,"CODE",{});var oAt=s(sue);Q6o=r(oAt,"model_type"),oAt.forEach(t),W6o=r(Cy,` property of the config object (either
passed as an argument or loaded from `),lue=n(Cy,"CODE",{});var rAt=s(lue);U6o=r(rAt,"pretrained_model_name_or_path"),rAt.forEach(t),H6o=r(Cy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iue=n(Cy,"CODE",{});var tAt=s(iue);J6o=r(tAt,"pretrained_model_name_or_path"),tAt.forEach(t),Y6o=r(Cy,":"),Cy.forEach(t),K6o=i(Fa),y=n(Fa,"UL",{});var x=s(y);Hp=n(x,"LI",{});var QBe=s(Hp);due=n(QBe,"STRONG",{});var aAt=s(due);Z6o=r(aAt,"albert"),aAt.forEach(t),e7o=r(QBe," \u2014 "),uO=n(QBe,"A",{href:!0});var nAt=s(uO);o7o=r(nAt,"AlbertModel"),nAt.forEach(t),r7o=r(QBe," (ALBERT model)"),QBe.forEach(t),t7o=i(x),Jp=n(x,"LI",{});var WBe=s(Jp);cue=n(WBe,"STRONG",{});var sAt=s(cue);a7o=r(sAt,"bart"),sAt.forEach(t),n7o=r(WBe," \u2014 "),pO=n(WBe,"A",{href:!0});var lAt=s(pO);s7o=r(lAt,"BartModel"),lAt.forEach(t),l7o=r(WBe," (BART model)"),WBe.forEach(t),i7o=i(x),Yp=n(x,"LI",{});var UBe=s(Yp);mue=n(UBe,"STRONG",{});var iAt=s(mue);d7o=r(iAt,"beit"),iAt.forEach(t),c7o=r(UBe," \u2014 "),_O=n(UBe,"A",{href:!0});var dAt=s(_O);m7o=r(dAt,"BeitModel"),dAt.forEach(t),f7o=r(UBe," (BEiT model)"),UBe.forEach(t),g7o=i(x),Kp=n(x,"LI",{});var HBe=s(Kp);fue=n(HBe,"STRONG",{});var cAt=s(fue);h7o=r(cAt,"bert"),cAt.forEach(t),u7o=r(HBe," \u2014 "),bO=n(HBe,"A",{href:!0});var mAt=s(bO);p7o=r(mAt,"BertModel"),mAt.forEach(t),_7o=r(HBe," (BERT model)"),HBe.forEach(t),b7o=i(x),Zp=n(x,"LI",{});var JBe=s(Zp);gue=n(JBe,"STRONG",{});var fAt=s(gue);v7o=r(fAt,"bert-generation"),fAt.forEach(t),F7o=r(JBe," \u2014 "),vO=n(JBe,"A",{href:!0});var gAt=s(vO);T7o=r(gAt,"BertGenerationEncoder"),gAt.forEach(t),M7o=r(JBe," (Bert Generation model)"),JBe.forEach(t),E7o=i(x),e_=n(x,"LI",{});var YBe=s(e_);hue=n(YBe,"STRONG",{});var hAt=s(hue);C7o=r(hAt,"big_bird"),hAt.forEach(t),w7o=r(YBe," \u2014 "),FO=n(YBe,"A",{href:!0});var uAt=s(FO);A7o=r(uAt,"BigBirdModel"),uAt.forEach(t),L7o=r(YBe," (BigBird model)"),YBe.forEach(t),y7o=i(x),o_=n(x,"LI",{});var KBe=s(o_);uue=n(KBe,"STRONG",{});var pAt=s(uue);x7o=r(pAt,"bigbird_pegasus"),pAt.forEach(t),$7o=r(KBe," \u2014 "),TO=n(KBe,"A",{href:!0});var _At=s(TO);k7o=r(_At,"BigBirdPegasusModel"),_At.forEach(t),S7o=r(KBe," (BigBird-Pegasus model)"),KBe.forEach(t),R7o=i(x),r_=n(x,"LI",{});var ZBe=s(r_);pue=n(ZBe,"STRONG",{});var bAt=s(pue);P7o=r(bAt,"blenderbot"),bAt.forEach(t),B7o=r(ZBe," \u2014 "),MO=n(ZBe,"A",{href:!0});var vAt=s(MO);I7o=r(vAt,"BlenderbotModel"),vAt.forEach(t),N7o=r(ZBe," (Blenderbot model)"),ZBe.forEach(t),q7o=i(x),t_=n(x,"LI",{});var eIe=s(t_);_ue=n(eIe,"STRONG",{});var FAt=s(_ue);j7o=r(FAt,"blenderbot-small"),FAt.forEach(t),D7o=r(eIe," \u2014 "),EO=n(eIe,"A",{href:!0});var TAt=s(EO);G7o=r(TAt,"BlenderbotSmallModel"),TAt.forEach(t),O7o=r(eIe," (BlenderbotSmall model)"),eIe.forEach(t),V7o=i(x),a_=n(x,"LI",{});var oIe=s(a_);bue=n(oIe,"STRONG",{});var MAt=s(bue);X7o=r(MAt,"bloom"),MAt.forEach(t),z7o=r(oIe," \u2014 "),CO=n(oIe,"A",{href:!0});var EAt=s(CO);Q7o=r(EAt,"BloomModel"),EAt.forEach(t),W7o=r(oIe," (BLOOM model)"),oIe.forEach(t),U7o=i(x),n_=n(x,"LI",{});var rIe=s(n_);vue=n(rIe,"STRONG",{});var CAt=s(vue);H7o=r(CAt,"camembert"),CAt.forEach(t),J7o=r(rIe," \u2014 "),wO=n(rIe,"A",{href:!0});var wAt=s(wO);Y7o=r(wAt,"CamembertModel"),wAt.forEach(t),K7o=r(rIe," (CamemBERT model)"),rIe.forEach(t),Z7o=i(x),s_=n(x,"LI",{});var tIe=s(s_);Fue=n(tIe,"STRONG",{});var AAt=s(Fue);eLo=r(AAt,"canine"),AAt.forEach(t),oLo=r(tIe," \u2014 "),AO=n(tIe,"A",{href:!0});var LAt=s(AO);rLo=r(LAt,"CanineModel"),LAt.forEach(t),tLo=r(tIe," (CANINE model)"),tIe.forEach(t),aLo=i(x),l_=n(x,"LI",{});var aIe=s(l_);Tue=n(aIe,"STRONG",{});var yAt=s(Tue);nLo=r(yAt,"clip"),yAt.forEach(t),sLo=r(aIe," \u2014 "),LO=n(aIe,"A",{href:!0});var xAt=s(LO);lLo=r(xAt,"CLIPModel"),xAt.forEach(t),iLo=r(aIe," (CLIP model)"),aIe.forEach(t),dLo=i(x),i_=n(x,"LI",{});var nIe=s(i_);Mue=n(nIe,"STRONG",{});var $At=s(Mue);cLo=r($At,"codegen"),$At.forEach(t),mLo=r(nIe," \u2014 "),yO=n(nIe,"A",{href:!0});var kAt=s(yO);fLo=r(kAt,"CodeGenModel"),kAt.forEach(t),gLo=r(nIe," (CodeGen model)"),nIe.forEach(t),hLo=i(x),d_=n(x,"LI",{});var sIe=s(d_);Eue=n(sIe,"STRONG",{});var SAt=s(Eue);uLo=r(SAt,"convbert"),SAt.forEach(t),pLo=r(sIe," \u2014 "),xO=n(sIe,"A",{href:!0});var RAt=s(xO);_Lo=r(RAt,"ConvBertModel"),RAt.forEach(t),bLo=r(sIe," (ConvBERT model)"),sIe.forEach(t),vLo=i(x),c_=n(x,"LI",{});var lIe=s(c_);Cue=n(lIe,"STRONG",{});var PAt=s(Cue);FLo=r(PAt,"convnext"),PAt.forEach(t),TLo=r(lIe," \u2014 "),$O=n(lIe,"A",{href:!0});var BAt=s($O);MLo=r(BAt,"ConvNextModel"),BAt.forEach(t),ELo=r(lIe," (ConvNeXT model)"),lIe.forEach(t),CLo=i(x),m_=n(x,"LI",{});var iIe=s(m_);wue=n(iIe,"STRONG",{});var IAt=s(wue);wLo=r(IAt,"ctrl"),IAt.forEach(t),ALo=r(iIe," \u2014 "),kO=n(iIe,"A",{href:!0});var NAt=s(kO);LLo=r(NAt,"CTRLModel"),NAt.forEach(t),yLo=r(iIe," (CTRL model)"),iIe.forEach(t),xLo=i(x),f_=n(x,"LI",{});var dIe=s(f_);Aue=n(dIe,"STRONG",{});var qAt=s(Aue);$Lo=r(qAt,"cvt"),qAt.forEach(t),kLo=r(dIe," \u2014 "),SO=n(dIe,"A",{href:!0});var jAt=s(SO);SLo=r(jAt,"CvtModel"),jAt.forEach(t),RLo=r(dIe," (CvT model)"),dIe.forEach(t),PLo=i(x),g_=n(x,"LI",{});var cIe=s(g_);Lue=n(cIe,"STRONG",{});var DAt=s(Lue);BLo=r(DAt,"data2vec-audio"),DAt.forEach(t),ILo=r(cIe," \u2014 "),RO=n(cIe,"A",{href:!0});var GAt=s(RO);NLo=r(GAt,"Data2VecAudioModel"),GAt.forEach(t),qLo=r(cIe," (Data2VecAudio model)"),cIe.forEach(t),jLo=i(x),h_=n(x,"LI",{});var mIe=s(h_);yue=n(mIe,"STRONG",{});var OAt=s(yue);DLo=r(OAt,"data2vec-text"),OAt.forEach(t),GLo=r(mIe," \u2014 "),PO=n(mIe,"A",{href:!0});var VAt=s(PO);OLo=r(VAt,"Data2VecTextModel"),VAt.forEach(t),VLo=r(mIe," (Data2VecText model)"),mIe.forEach(t),XLo=i(x),u_=n(x,"LI",{});var fIe=s(u_);xue=n(fIe,"STRONG",{});var XAt=s(xue);zLo=r(XAt,"data2vec-vision"),XAt.forEach(t),QLo=r(fIe," \u2014 "),BO=n(fIe,"A",{href:!0});var zAt=s(BO);WLo=r(zAt,"Data2VecVisionModel"),zAt.forEach(t),ULo=r(fIe," (Data2VecVision model)"),fIe.forEach(t),HLo=i(x),p_=n(x,"LI",{});var gIe=s(p_);$ue=n(gIe,"STRONG",{});var QAt=s($ue);JLo=r(QAt,"deberta"),QAt.forEach(t),YLo=r(gIe," \u2014 "),IO=n(gIe,"A",{href:!0});var WAt=s(IO);KLo=r(WAt,"DebertaModel"),WAt.forEach(t),ZLo=r(gIe," (DeBERTa model)"),gIe.forEach(t),eyo=i(x),__=n(x,"LI",{});var hIe=s(__);kue=n(hIe,"STRONG",{});var UAt=s(kue);oyo=r(UAt,"deberta-v2"),UAt.forEach(t),ryo=r(hIe," \u2014 "),NO=n(hIe,"A",{href:!0});var HAt=s(NO);tyo=r(HAt,"DebertaV2Model"),HAt.forEach(t),ayo=r(hIe," (DeBERTa-v2 model)"),hIe.forEach(t),nyo=i(x),b_=n(x,"LI",{});var uIe=s(b_);Sue=n(uIe,"STRONG",{});var JAt=s(Sue);syo=r(JAt,"decision_transformer"),JAt.forEach(t),lyo=r(uIe," \u2014 "),qO=n(uIe,"A",{href:!0});var YAt=s(qO);iyo=r(YAt,"DecisionTransformerModel"),YAt.forEach(t),dyo=r(uIe," (Decision Transformer model)"),uIe.forEach(t),cyo=i(x),v_=n(x,"LI",{});var pIe=s(v_);Rue=n(pIe,"STRONG",{});var KAt=s(Rue);myo=r(KAt,"deformable_detr"),KAt.forEach(t),fyo=r(pIe," \u2014 "),jO=n(pIe,"A",{href:!0});var ZAt=s(jO);gyo=r(ZAt,"DeformableDetrModel"),ZAt.forEach(t),hyo=r(pIe," (Deformable DETR model)"),pIe.forEach(t),uyo=i(x),F_=n(x,"LI",{});var _Ie=s(F_);Pue=n(_Ie,"STRONG",{});var e6t=s(Pue);pyo=r(e6t,"deit"),e6t.forEach(t),_yo=r(_Ie," \u2014 "),DO=n(_Ie,"A",{href:!0});var o6t=s(DO);byo=r(o6t,"DeiTModel"),o6t.forEach(t),vyo=r(_Ie," (DeiT model)"),_Ie.forEach(t),Fyo=i(x),T_=n(x,"LI",{});var bIe=s(T_);Bue=n(bIe,"STRONG",{});var r6t=s(Bue);Tyo=r(r6t,"detr"),r6t.forEach(t),Myo=r(bIe," \u2014 "),GO=n(bIe,"A",{href:!0});var t6t=s(GO);Eyo=r(t6t,"DetrModel"),t6t.forEach(t),Cyo=r(bIe," (DETR model)"),bIe.forEach(t),wyo=i(x),M_=n(x,"LI",{});var vIe=s(M_);Iue=n(vIe,"STRONG",{});var a6t=s(Iue);Ayo=r(a6t,"distilbert"),a6t.forEach(t),Lyo=r(vIe," \u2014 "),OO=n(vIe,"A",{href:!0});var n6t=s(OO);yyo=r(n6t,"DistilBertModel"),n6t.forEach(t),xyo=r(vIe," (DistilBERT model)"),vIe.forEach(t),$yo=i(x),E_=n(x,"LI",{});var FIe=s(E_);Nue=n(FIe,"STRONG",{});var s6t=s(Nue);kyo=r(s6t,"donut-swin"),s6t.forEach(t),Syo=r(FIe," \u2014 "),VO=n(FIe,"A",{href:!0});var l6t=s(VO);Ryo=r(l6t,"DonutSwinModel"),l6t.forEach(t),Pyo=r(FIe," (DonutSwin model)"),FIe.forEach(t),Byo=i(x),C_=n(x,"LI",{});var TIe=s(C_);que=n(TIe,"STRONG",{});var i6t=s(que);Iyo=r(i6t,"dpr"),i6t.forEach(t),Nyo=r(TIe," \u2014 "),XO=n(TIe,"A",{href:!0});var d6t=s(XO);qyo=r(d6t,"DPRQuestionEncoder"),d6t.forEach(t),jyo=r(TIe," (DPR model)"),TIe.forEach(t),Dyo=i(x),w_=n(x,"LI",{});var MIe=s(w_);jue=n(MIe,"STRONG",{});var c6t=s(jue);Gyo=r(c6t,"dpt"),c6t.forEach(t),Oyo=r(MIe," \u2014 "),zO=n(MIe,"A",{href:!0});var m6t=s(zO);Vyo=r(m6t,"DPTModel"),m6t.forEach(t),Xyo=r(MIe," (DPT model)"),MIe.forEach(t),zyo=i(x),A_=n(x,"LI",{});var EIe=s(A_);Due=n(EIe,"STRONG",{});var f6t=s(Due);Qyo=r(f6t,"electra"),f6t.forEach(t),Wyo=r(EIe," \u2014 "),QO=n(EIe,"A",{href:!0});var g6t=s(QO);Uyo=r(g6t,"ElectraModel"),g6t.forEach(t),Hyo=r(EIe," (ELECTRA model)"),EIe.forEach(t),Jyo=i(x),L_=n(x,"LI",{});var CIe=s(L_);Gue=n(CIe,"STRONG",{});var h6t=s(Gue);Yyo=r(h6t,"ernie"),h6t.forEach(t),Kyo=r(CIe," \u2014 "),WO=n(CIe,"A",{href:!0});var u6t=s(WO);Zyo=r(u6t,"ErnieModel"),u6t.forEach(t),e8o=r(CIe," (ERNIE model)"),CIe.forEach(t),o8o=i(x),y_=n(x,"LI",{});var wIe=s(y_);Oue=n(wIe,"STRONG",{});var p6t=s(Oue);r8o=r(p6t,"flaubert"),p6t.forEach(t),t8o=r(wIe," \u2014 "),UO=n(wIe,"A",{href:!0});var _6t=s(UO);a8o=r(_6t,"FlaubertModel"),_6t.forEach(t),n8o=r(wIe," (FlauBERT model)"),wIe.forEach(t),s8o=i(x),x_=n(x,"LI",{});var AIe=s(x_);Vue=n(AIe,"STRONG",{});var b6t=s(Vue);l8o=r(b6t,"flava"),b6t.forEach(t),i8o=r(AIe," \u2014 "),HO=n(AIe,"A",{href:!0});var v6t=s(HO);d8o=r(v6t,"FlavaModel"),v6t.forEach(t),c8o=r(AIe," (FLAVA model)"),AIe.forEach(t),m8o=i(x),$_=n(x,"LI",{});var LIe=s($_);Xue=n(LIe,"STRONG",{});var F6t=s(Xue);f8o=r(F6t,"fnet"),F6t.forEach(t),g8o=r(LIe," \u2014 "),JO=n(LIe,"A",{href:!0});var T6t=s(JO);h8o=r(T6t,"FNetModel"),T6t.forEach(t),u8o=r(LIe," (FNet model)"),LIe.forEach(t),p8o=i(x),k_=n(x,"LI",{});var yIe=s(k_);zue=n(yIe,"STRONG",{});var M6t=s(zue);_8o=r(M6t,"fsmt"),M6t.forEach(t),b8o=r(yIe," \u2014 "),YO=n(yIe,"A",{href:!0});var E6t=s(YO);v8o=r(E6t,"FSMTModel"),E6t.forEach(t),F8o=r(yIe," (FairSeq Machine-Translation model)"),yIe.forEach(t),T8o=i(x),pl=n(x,"LI",{});var EB=s(pl);Que=n(EB,"STRONG",{});var C6t=s(Que);M8o=r(C6t,"funnel"),C6t.forEach(t),E8o=r(EB," \u2014 "),KO=n(EB,"A",{href:!0});var w6t=s(KO);C8o=r(w6t,"FunnelModel"),w6t.forEach(t),w8o=r(EB," or "),ZO=n(EB,"A",{href:!0});var A6t=s(ZO);A8o=r(A6t,"FunnelBaseModel"),A6t.forEach(t),L8o=r(EB," (Funnel Transformer model)"),EB.forEach(t),y8o=i(x),S_=n(x,"LI",{});var xIe=s(S_);Wue=n(xIe,"STRONG",{});var L6t=s(Wue);x8o=r(L6t,"glpn"),L6t.forEach(t),$8o=r(xIe," \u2014 "),eV=n(xIe,"A",{href:!0});var y6t=s(eV);k8o=r(y6t,"GLPNModel"),y6t.forEach(t),S8o=r(xIe," (GLPN model)"),xIe.forEach(t),R8o=i(x),R_=n(x,"LI",{});var $Ie=s(R_);Uue=n($Ie,"STRONG",{});var x6t=s(Uue);P8o=r(x6t,"gpt2"),x6t.forEach(t),B8o=r($Ie," \u2014 "),oV=n($Ie,"A",{href:!0});var $6t=s(oV);I8o=r($6t,"GPT2Model"),$6t.forEach(t),N8o=r($Ie," (OpenAI GPT-2 model)"),$Ie.forEach(t),q8o=i(x),P_=n(x,"LI",{});var kIe=s(P_);Hue=n(kIe,"STRONG",{});var k6t=s(Hue);j8o=r(k6t,"gpt_neo"),k6t.forEach(t),D8o=r(kIe," \u2014 "),rV=n(kIe,"A",{href:!0});var S6t=s(rV);G8o=r(S6t,"GPTNeoModel"),S6t.forEach(t),O8o=r(kIe," (GPT Neo model)"),kIe.forEach(t),V8o=i(x),B_=n(x,"LI",{});var SIe=s(B_);Jue=n(SIe,"STRONG",{});var R6t=s(Jue);X8o=r(R6t,"gpt_neox"),R6t.forEach(t),z8o=r(SIe," \u2014 "),tV=n(SIe,"A",{href:!0});var P6t=s(tV);Q8o=r(P6t,"GPTNeoXModel"),P6t.forEach(t),W8o=r(SIe," (GPT NeoX model)"),SIe.forEach(t),U8o=i(x),I_=n(x,"LI",{});var RIe=s(I_);Yue=n(RIe,"STRONG",{});var B6t=s(Yue);H8o=r(B6t,"gptj"),B6t.forEach(t),J8o=r(RIe," \u2014 "),aV=n(RIe,"A",{href:!0});var I6t=s(aV);Y8o=r(I6t,"GPTJModel"),I6t.forEach(t),K8o=r(RIe," (GPT-J model)"),RIe.forEach(t),Z8o=i(x),N_=n(x,"LI",{});var PIe=s(N_);Kue=n(PIe,"STRONG",{});var N6t=s(Kue);e9o=r(N6t,"groupvit"),N6t.forEach(t),o9o=r(PIe," \u2014 "),nV=n(PIe,"A",{href:!0});var q6t=s(nV);r9o=r(q6t,"GroupViTModel"),q6t.forEach(t),t9o=r(PIe," (GroupViT model)"),PIe.forEach(t),a9o=i(x),q_=n(x,"LI",{});var BIe=s(q_);Zue=n(BIe,"STRONG",{});var j6t=s(Zue);n9o=r(j6t,"hubert"),j6t.forEach(t),s9o=r(BIe," \u2014 "),sV=n(BIe,"A",{href:!0});var D6t=s(sV);l9o=r(D6t,"HubertModel"),D6t.forEach(t),i9o=r(BIe," (Hubert model)"),BIe.forEach(t),d9o=i(x),j_=n(x,"LI",{});var IIe=s(j_);epe=n(IIe,"STRONG",{});var G6t=s(epe);c9o=r(G6t,"ibert"),G6t.forEach(t),m9o=r(IIe," \u2014 "),lV=n(IIe,"A",{href:!0});var O6t=s(lV);f9o=r(O6t,"IBertModel"),O6t.forEach(t),g9o=r(IIe," (I-BERT model)"),IIe.forEach(t),h9o=i(x),D_=n(x,"LI",{});var NIe=s(D_);ope=n(NIe,"STRONG",{});var V6t=s(ope);u9o=r(V6t,"imagegpt"),V6t.forEach(t),p9o=r(NIe," \u2014 "),iV=n(NIe,"A",{href:!0});var X6t=s(iV);_9o=r(X6t,"ImageGPTModel"),X6t.forEach(t),b9o=r(NIe," (ImageGPT model)"),NIe.forEach(t),v9o=i(x),G_=n(x,"LI",{});var qIe=s(G_);rpe=n(qIe,"STRONG",{});var z6t=s(rpe);F9o=r(z6t,"layoutlm"),z6t.forEach(t),T9o=r(qIe," \u2014 "),dV=n(qIe,"A",{href:!0});var Q6t=s(dV);M9o=r(Q6t,"LayoutLMModel"),Q6t.forEach(t),E9o=r(qIe," (LayoutLM model)"),qIe.forEach(t),C9o=i(x),O_=n(x,"LI",{});var jIe=s(O_);tpe=n(jIe,"STRONG",{});var W6t=s(tpe);w9o=r(W6t,"layoutlmv2"),W6t.forEach(t),A9o=r(jIe," \u2014 "),cV=n(jIe,"A",{href:!0});var U6t=s(cV);L9o=r(U6t,"LayoutLMv2Model"),U6t.forEach(t),y9o=r(jIe," (LayoutLMv2 model)"),jIe.forEach(t),x9o=i(x),V_=n(x,"LI",{});var DIe=s(V_);ape=n(DIe,"STRONG",{});var H6t=s(ape);$9o=r(H6t,"layoutlmv3"),H6t.forEach(t),k9o=r(DIe," \u2014 "),mV=n(DIe,"A",{href:!0});var J6t=s(mV);S9o=r(J6t,"LayoutLMv3Model"),J6t.forEach(t),R9o=r(DIe," (LayoutLMv3 model)"),DIe.forEach(t),P9o=i(x),X_=n(x,"LI",{});var GIe=s(X_);npe=n(GIe,"STRONG",{});var Y6t=s(npe);B9o=r(Y6t,"led"),Y6t.forEach(t),I9o=r(GIe," \u2014 "),fV=n(GIe,"A",{href:!0});var K6t=s(fV);N9o=r(K6t,"LEDModel"),K6t.forEach(t),q9o=r(GIe," (LED model)"),GIe.forEach(t),j9o=i(x),z_=n(x,"LI",{});var OIe=s(z_);spe=n(OIe,"STRONG",{});var Z6t=s(spe);D9o=r(Z6t,"levit"),Z6t.forEach(t),G9o=r(OIe," \u2014 "),gV=n(OIe,"A",{href:!0});var e7t=s(gV);O9o=r(e7t,"LevitModel"),e7t.forEach(t),V9o=r(OIe," (LeViT model)"),OIe.forEach(t),X9o=i(x),Q_=n(x,"LI",{});var VIe=s(Q_);lpe=n(VIe,"STRONG",{});var o7t=s(lpe);z9o=r(o7t,"longformer"),o7t.forEach(t),Q9o=r(VIe," \u2014 "),hV=n(VIe,"A",{href:!0});var r7t=s(hV);W9o=r(r7t,"LongformerModel"),r7t.forEach(t),U9o=r(VIe," (Longformer model)"),VIe.forEach(t),H9o=i(x),W_=n(x,"LI",{});var XIe=s(W_);ipe=n(XIe,"STRONG",{});var t7t=s(ipe);J9o=r(t7t,"longt5"),t7t.forEach(t),Y9o=r(XIe," \u2014 "),uV=n(XIe,"A",{href:!0});var a7t=s(uV);K9o=r(a7t,"LongT5Model"),a7t.forEach(t),Z9o=r(XIe," (LongT5 model)"),XIe.forEach(t),exo=i(x),U_=n(x,"LI",{});var zIe=s(U_);dpe=n(zIe,"STRONG",{});var n7t=s(dpe);oxo=r(n7t,"luke"),n7t.forEach(t),rxo=r(zIe," \u2014 "),pV=n(zIe,"A",{href:!0});var s7t=s(pV);txo=r(s7t,"LukeModel"),s7t.forEach(t),axo=r(zIe," (LUKE model)"),zIe.forEach(t),nxo=i(x),H_=n(x,"LI",{});var QIe=s(H_);cpe=n(QIe,"STRONG",{});var l7t=s(cpe);sxo=r(l7t,"lxmert"),l7t.forEach(t),lxo=r(QIe," \u2014 "),_V=n(QIe,"A",{href:!0});var i7t=s(_V);ixo=r(i7t,"LxmertModel"),i7t.forEach(t),dxo=r(QIe," (LXMERT model)"),QIe.forEach(t),cxo=i(x),J_=n(x,"LI",{});var WIe=s(J_);mpe=n(WIe,"STRONG",{});var d7t=s(mpe);mxo=r(d7t,"m2m_100"),d7t.forEach(t),fxo=r(WIe," \u2014 "),bV=n(WIe,"A",{href:!0});var c7t=s(bV);gxo=r(c7t,"M2M100Model"),c7t.forEach(t),hxo=r(WIe," (M2M100 model)"),WIe.forEach(t),uxo=i(x),Y_=n(x,"LI",{});var UIe=s(Y_);fpe=n(UIe,"STRONG",{});var m7t=s(fpe);pxo=r(m7t,"marian"),m7t.forEach(t),_xo=r(UIe," \u2014 "),vV=n(UIe,"A",{href:!0});var f7t=s(vV);bxo=r(f7t,"MarianModel"),f7t.forEach(t),vxo=r(UIe," (Marian model)"),UIe.forEach(t),Fxo=i(x),K_=n(x,"LI",{});var HIe=s(K_);gpe=n(HIe,"STRONG",{});var g7t=s(gpe);Txo=r(g7t,"maskformer"),g7t.forEach(t),Mxo=r(HIe," \u2014 "),FV=n(HIe,"A",{href:!0});var h7t=s(FV);Exo=r(h7t,"MaskFormerModel"),h7t.forEach(t),Cxo=r(HIe," (MaskFormer model)"),HIe.forEach(t),wxo=i(x),Z_=n(x,"LI",{});var JIe=s(Z_);hpe=n(JIe,"STRONG",{});var u7t=s(hpe);Axo=r(u7t,"mbart"),u7t.forEach(t),Lxo=r(JIe," \u2014 "),TV=n(JIe,"A",{href:!0});var p7t=s(TV);yxo=r(p7t,"MBartModel"),p7t.forEach(t),xxo=r(JIe," (mBART model)"),JIe.forEach(t),$xo=i(x),eb=n(x,"LI",{});var YIe=s(eb);upe=n(YIe,"STRONG",{});var _7t=s(upe);kxo=r(_7t,"mctct"),_7t.forEach(t),Sxo=r(YIe," \u2014 "),MV=n(YIe,"A",{href:!0});var b7t=s(MV);Rxo=r(b7t,"MCTCTModel"),b7t.forEach(t),Pxo=r(YIe," (M-CTC-T model)"),YIe.forEach(t),Bxo=i(x),ob=n(x,"LI",{});var KIe=s(ob);ppe=n(KIe,"STRONG",{});var v7t=s(ppe);Ixo=r(v7t,"megatron-bert"),v7t.forEach(t),Nxo=r(KIe," \u2014 "),EV=n(KIe,"A",{href:!0});var F7t=s(EV);qxo=r(F7t,"MegatronBertModel"),F7t.forEach(t),jxo=r(KIe," (Megatron-BERT model)"),KIe.forEach(t),Dxo=i(x),rb=n(x,"LI",{});var ZIe=s(rb);_pe=n(ZIe,"STRONG",{});var T7t=s(_pe);Gxo=r(T7t,"mobilebert"),T7t.forEach(t),Oxo=r(ZIe," \u2014 "),CV=n(ZIe,"A",{href:!0});var M7t=s(CV);Vxo=r(M7t,"MobileBertModel"),M7t.forEach(t),Xxo=r(ZIe," (MobileBERT model)"),ZIe.forEach(t),zxo=i(x),tb=n(x,"LI",{});var eNe=s(tb);bpe=n(eNe,"STRONG",{});var E7t=s(bpe);Qxo=r(E7t,"mobilevit"),E7t.forEach(t),Wxo=r(eNe," \u2014 "),wV=n(eNe,"A",{href:!0});var C7t=s(wV);Uxo=r(C7t,"MobileViTModel"),C7t.forEach(t),Hxo=r(eNe," (MobileViT model)"),eNe.forEach(t),Jxo=i(x),ab=n(x,"LI",{});var oNe=s(ab);vpe=n(oNe,"STRONG",{});var w7t=s(vpe);Yxo=r(w7t,"mpnet"),w7t.forEach(t),Kxo=r(oNe," \u2014 "),AV=n(oNe,"A",{href:!0});var A7t=s(AV);Zxo=r(A7t,"MPNetModel"),A7t.forEach(t),e$o=r(oNe," (MPNet model)"),oNe.forEach(t),o$o=i(x),nb=n(x,"LI",{});var rNe=s(nb);Fpe=n(rNe,"STRONG",{});var L7t=s(Fpe);r$o=r(L7t,"mt5"),L7t.forEach(t),t$o=r(rNe," \u2014 "),LV=n(rNe,"A",{href:!0});var y7t=s(LV);a$o=r(y7t,"MT5Model"),y7t.forEach(t),n$o=r(rNe," (MT5 model)"),rNe.forEach(t),s$o=i(x),sb=n(x,"LI",{});var tNe=s(sb);Tpe=n(tNe,"STRONG",{});var x7t=s(Tpe);l$o=r(x7t,"mvp"),x7t.forEach(t),i$o=r(tNe," \u2014 "),yV=n(tNe,"A",{href:!0});var $7t=s(yV);d$o=r($7t,"MvpModel"),$7t.forEach(t),c$o=r(tNe," (MVP model)"),tNe.forEach(t),m$o=i(x),lb=n(x,"LI",{});var aNe=s(lb);Mpe=n(aNe,"STRONG",{});var k7t=s(Mpe);f$o=r(k7t,"nezha"),k7t.forEach(t),g$o=r(aNe," \u2014 "),xV=n(aNe,"A",{href:!0});var S7t=s(xV);h$o=r(S7t,"NezhaModel"),S7t.forEach(t),u$o=r(aNe," (Nezha model)"),aNe.forEach(t),p$o=i(x),ib=n(x,"LI",{});var nNe=s(ib);Epe=n(nNe,"STRONG",{});var R7t=s(Epe);_$o=r(R7t,"nllb"),R7t.forEach(t),b$o=r(nNe," \u2014 "),$V=n(nNe,"A",{href:!0});var P7t=s($V);v$o=r(P7t,"M2M100Model"),P7t.forEach(t),F$o=r(nNe," (NLLB model)"),nNe.forEach(t),T$o=i(x),db=n(x,"LI",{});var sNe=s(db);Cpe=n(sNe,"STRONG",{});var B7t=s(Cpe);M$o=r(B7t,"nystromformer"),B7t.forEach(t),E$o=r(sNe," \u2014 "),kV=n(sNe,"A",{href:!0});var I7t=s(kV);C$o=r(I7t,"NystromformerModel"),I7t.forEach(t),w$o=r(sNe," (Nystr\xF6mformer model)"),sNe.forEach(t),A$o=i(x),cb=n(x,"LI",{});var lNe=s(cb);wpe=n(lNe,"STRONG",{});var N7t=s(wpe);L$o=r(N7t,"openai-gpt"),N7t.forEach(t),y$o=r(lNe," \u2014 "),SV=n(lNe,"A",{href:!0});var q7t=s(SV);x$o=r(q7t,"OpenAIGPTModel"),q7t.forEach(t),$$o=r(lNe," (OpenAI GPT model)"),lNe.forEach(t),k$o=i(x),mb=n(x,"LI",{});var iNe=s(mb);Ape=n(iNe,"STRONG",{});var j7t=s(Ape);S$o=r(j7t,"opt"),j7t.forEach(t),R$o=r(iNe," \u2014 "),RV=n(iNe,"A",{href:!0});var D7t=s(RV);P$o=r(D7t,"OPTModel"),D7t.forEach(t),B$o=r(iNe," (OPT model)"),iNe.forEach(t),I$o=i(x),fb=n(x,"LI",{});var dNe=s(fb);Lpe=n(dNe,"STRONG",{});var G7t=s(Lpe);N$o=r(G7t,"owlvit"),G7t.forEach(t),q$o=r(dNe," \u2014 "),PV=n(dNe,"A",{href:!0});var O7t=s(PV);j$o=r(O7t,"OwlViTModel"),O7t.forEach(t),D$o=r(dNe," (OWL-ViT model)"),dNe.forEach(t),G$o=i(x),gb=n(x,"LI",{});var cNe=s(gb);ype=n(cNe,"STRONG",{});var V7t=s(ype);O$o=r(V7t,"pegasus"),V7t.forEach(t),V$o=r(cNe," \u2014 "),BV=n(cNe,"A",{href:!0});var X7t=s(BV);X$o=r(X7t,"PegasusModel"),X7t.forEach(t),z$o=r(cNe," (Pegasus model)"),cNe.forEach(t),Q$o=i(x),hb=n(x,"LI",{});var mNe=s(hb);xpe=n(mNe,"STRONG",{});var z7t=s(xpe);W$o=r(z7t,"pegasus_x"),z7t.forEach(t),U$o=r(mNe," \u2014 "),IV=n(mNe,"A",{href:!0});var Q7t=s(IV);H$o=r(Q7t,"PegasusXModel"),Q7t.forEach(t),J$o=r(mNe," (PEGASUS-X model)"),mNe.forEach(t),Y$o=i(x),ub=n(x,"LI",{});var fNe=s(ub);$pe=n(fNe,"STRONG",{});var W7t=s($pe);K$o=r(W7t,"perceiver"),W7t.forEach(t),Z$o=r(fNe," \u2014 "),NV=n(fNe,"A",{href:!0});var U7t=s(NV);eko=r(U7t,"PerceiverModel"),U7t.forEach(t),oko=r(fNe," (Perceiver model)"),fNe.forEach(t),rko=i(x),pb=n(x,"LI",{});var gNe=s(pb);kpe=n(gNe,"STRONG",{});var H7t=s(kpe);tko=r(H7t,"plbart"),H7t.forEach(t),ako=r(gNe," \u2014 "),qV=n(gNe,"A",{href:!0});var J7t=s(qV);nko=r(J7t,"PLBartModel"),J7t.forEach(t),sko=r(gNe," (PLBart model)"),gNe.forEach(t),lko=i(x),_b=n(x,"LI",{});var hNe=s(_b);Spe=n(hNe,"STRONG",{});var Y7t=s(Spe);iko=r(Y7t,"poolformer"),Y7t.forEach(t),dko=r(hNe," \u2014 "),jV=n(hNe,"A",{href:!0});var K7t=s(jV);cko=r(K7t,"PoolFormerModel"),K7t.forEach(t),mko=r(hNe," (PoolFormer model)"),hNe.forEach(t),fko=i(x),bb=n(x,"LI",{});var uNe=s(bb);Rpe=n(uNe,"STRONG",{});var Z7t=s(Rpe);gko=r(Z7t,"prophetnet"),Z7t.forEach(t),hko=r(uNe," \u2014 "),DV=n(uNe,"A",{href:!0});var eLt=s(DV);uko=r(eLt,"ProphetNetModel"),eLt.forEach(t),pko=r(uNe," (ProphetNet model)"),uNe.forEach(t),_ko=i(x),vb=n(x,"LI",{});var pNe=s(vb);Ppe=n(pNe,"STRONG",{});var oLt=s(Ppe);bko=r(oLt,"qdqbert"),oLt.forEach(t),vko=r(pNe," \u2014 "),GV=n(pNe,"A",{href:!0});var rLt=s(GV);Fko=r(rLt,"QDQBertModel"),rLt.forEach(t),Tko=r(pNe," (QDQBert model)"),pNe.forEach(t),Mko=i(x),Fb=n(x,"LI",{});var _Ne=s(Fb);Bpe=n(_Ne,"STRONG",{});var tLt=s(Bpe);Eko=r(tLt,"reformer"),tLt.forEach(t),Cko=r(_Ne," \u2014 "),OV=n(_Ne,"A",{href:!0});var aLt=s(OV);wko=r(aLt,"ReformerModel"),aLt.forEach(t),Ako=r(_Ne," (Reformer model)"),_Ne.forEach(t),Lko=i(x),Tb=n(x,"LI",{});var bNe=s(Tb);Ipe=n(bNe,"STRONG",{});var nLt=s(Ipe);yko=r(nLt,"regnet"),nLt.forEach(t),xko=r(bNe," \u2014 "),VV=n(bNe,"A",{href:!0});var sLt=s(VV);$ko=r(sLt,"RegNetModel"),sLt.forEach(t),kko=r(bNe," (RegNet model)"),bNe.forEach(t),Sko=i(x),Mb=n(x,"LI",{});var vNe=s(Mb);Npe=n(vNe,"STRONG",{});var lLt=s(Npe);Rko=r(lLt,"rembert"),lLt.forEach(t),Pko=r(vNe," \u2014 "),XV=n(vNe,"A",{href:!0});var iLt=s(XV);Bko=r(iLt,"RemBertModel"),iLt.forEach(t),Iko=r(vNe," (RemBERT model)"),vNe.forEach(t),Nko=i(x),Eb=n(x,"LI",{});var FNe=s(Eb);qpe=n(FNe,"STRONG",{});var dLt=s(qpe);qko=r(dLt,"resnet"),dLt.forEach(t),jko=r(FNe," \u2014 "),zV=n(FNe,"A",{href:!0});var cLt=s(zV);Dko=r(cLt,"ResNetModel"),cLt.forEach(t),Gko=r(FNe," (ResNet model)"),FNe.forEach(t),Oko=i(x),Cb=n(x,"LI",{});var TNe=s(Cb);jpe=n(TNe,"STRONG",{});var mLt=s(jpe);Vko=r(mLt,"retribert"),mLt.forEach(t),Xko=r(TNe," \u2014 "),QV=n(TNe,"A",{href:!0});var fLt=s(QV);zko=r(fLt,"RetriBertModel"),fLt.forEach(t),Qko=r(TNe," (RetriBERT model)"),TNe.forEach(t),Wko=i(x),wb=n(x,"LI",{});var MNe=s(wb);Dpe=n(MNe,"STRONG",{});var gLt=s(Dpe);Uko=r(gLt,"roberta"),gLt.forEach(t),Hko=r(MNe," \u2014 "),WV=n(MNe,"A",{href:!0});var hLt=s(WV);Jko=r(hLt,"RobertaModel"),hLt.forEach(t),Yko=r(MNe," (RoBERTa model)"),MNe.forEach(t),Kko=i(x),Ab=n(x,"LI",{});var ENe=s(Ab);Gpe=n(ENe,"STRONG",{});var uLt=s(Gpe);Zko=r(uLt,"roformer"),uLt.forEach(t),eSo=r(ENe," \u2014 "),UV=n(ENe,"A",{href:!0});var pLt=s(UV);oSo=r(pLt,"RoFormerModel"),pLt.forEach(t),rSo=r(ENe," (RoFormer model)"),ENe.forEach(t),tSo=i(x),Lb=n(x,"LI",{});var CNe=s(Lb);Ope=n(CNe,"STRONG",{});var _Lt=s(Ope);aSo=r(_Lt,"segformer"),_Lt.forEach(t),nSo=r(CNe," \u2014 "),HV=n(CNe,"A",{href:!0});var bLt=s(HV);sSo=r(bLt,"SegformerModel"),bLt.forEach(t),lSo=r(CNe," (SegFormer model)"),CNe.forEach(t),iSo=i(x),yb=n(x,"LI",{});var wNe=s(yb);Vpe=n(wNe,"STRONG",{});var vLt=s(Vpe);dSo=r(vLt,"sew"),vLt.forEach(t),cSo=r(wNe," \u2014 "),JV=n(wNe,"A",{href:!0});var FLt=s(JV);mSo=r(FLt,"SEWModel"),FLt.forEach(t),fSo=r(wNe," (SEW model)"),wNe.forEach(t),gSo=i(x),xb=n(x,"LI",{});var ANe=s(xb);Xpe=n(ANe,"STRONG",{});var TLt=s(Xpe);hSo=r(TLt,"sew-d"),TLt.forEach(t),uSo=r(ANe," \u2014 "),YV=n(ANe,"A",{href:!0});var MLt=s(YV);pSo=r(MLt,"SEWDModel"),MLt.forEach(t),_So=r(ANe," (SEW-D model)"),ANe.forEach(t),bSo=i(x),$b=n(x,"LI",{});var LNe=s($b);zpe=n(LNe,"STRONG",{});var ELt=s(zpe);vSo=r(ELt,"speech_to_text"),ELt.forEach(t),FSo=r(LNe," \u2014 "),KV=n(LNe,"A",{href:!0});var CLt=s(KV);TSo=r(CLt,"Speech2TextModel"),CLt.forEach(t),MSo=r(LNe," (Speech2Text model)"),LNe.forEach(t),ESo=i(x),kb=n(x,"LI",{});var yNe=s(kb);Qpe=n(yNe,"STRONG",{});var wLt=s(Qpe);CSo=r(wLt,"splinter"),wLt.forEach(t),wSo=r(yNe," \u2014 "),ZV=n(yNe,"A",{href:!0});var ALt=s(ZV);ASo=r(ALt,"SplinterModel"),ALt.forEach(t),LSo=r(yNe," (Splinter model)"),yNe.forEach(t),ySo=i(x),Sb=n(x,"LI",{});var xNe=s(Sb);Wpe=n(xNe,"STRONG",{});var LLt=s(Wpe);xSo=r(LLt,"squeezebert"),LLt.forEach(t),$So=r(xNe," \u2014 "),eX=n(xNe,"A",{href:!0});var yLt=s(eX);kSo=r(yLt,"SqueezeBertModel"),yLt.forEach(t),SSo=r(xNe," (SqueezeBERT model)"),xNe.forEach(t),RSo=i(x),Rb=n(x,"LI",{});var $Ne=s(Rb);Upe=n($Ne,"STRONG",{});var xLt=s(Upe);PSo=r(xLt,"swin"),xLt.forEach(t),BSo=r($Ne," \u2014 "),oX=n($Ne,"A",{href:!0});var $Lt=s(oX);ISo=r($Lt,"SwinModel"),$Lt.forEach(t),NSo=r($Ne," (Swin Transformer model)"),$Ne.forEach(t),qSo=i(x),Pb=n(x,"LI",{});var kNe=s(Pb);Hpe=n(kNe,"STRONG",{});var kLt=s(Hpe);jSo=r(kLt,"swinv2"),kLt.forEach(t),DSo=r(kNe," \u2014 "),rX=n(kNe,"A",{href:!0});var SLt=s(rX);GSo=r(SLt,"Swinv2Model"),SLt.forEach(t),OSo=r(kNe," (Swin Transformer V2 model)"),kNe.forEach(t),VSo=i(x),Bb=n(x,"LI",{});var SNe=s(Bb);Jpe=n(SNe,"STRONG",{});var RLt=s(Jpe);XSo=r(RLt,"t5"),RLt.forEach(t),zSo=r(SNe," \u2014 "),tX=n(SNe,"A",{href:!0});var PLt=s(tX);QSo=r(PLt,"T5Model"),PLt.forEach(t),WSo=r(SNe," (T5 model)"),SNe.forEach(t),USo=i(x),Ib=n(x,"LI",{});var RNe=s(Ib);Ype=n(RNe,"STRONG",{});var BLt=s(Ype);HSo=r(BLt,"tapas"),BLt.forEach(t),JSo=r(RNe," \u2014 "),aX=n(RNe,"A",{href:!0});var ILt=s(aX);YSo=r(ILt,"TapasModel"),ILt.forEach(t),KSo=r(RNe," (TAPAS model)"),RNe.forEach(t),ZSo=i(x),Nb=n(x,"LI",{});var PNe=s(Nb);Kpe=n(PNe,"STRONG",{});var NLt=s(Kpe);eRo=r(NLt,"trajectory_transformer"),NLt.forEach(t),oRo=r(PNe," \u2014 "),nX=n(PNe,"A",{href:!0});var qLt=s(nX);rRo=r(qLt,"TrajectoryTransformerModel"),qLt.forEach(t),tRo=r(PNe," (Trajectory Transformer model)"),PNe.forEach(t),aRo=i(x),qb=n(x,"LI",{});var BNe=s(qb);Zpe=n(BNe,"STRONG",{});var jLt=s(Zpe);nRo=r(jLt,"transfo-xl"),jLt.forEach(t),sRo=r(BNe," \u2014 "),sX=n(BNe,"A",{href:!0});var DLt=s(sX);lRo=r(DLt,"TransfoXLModel"),DLt.forEach(t),iRo=r(BNe," (Transformer-XL model)"),BNe.forEach(t),dRo=i(x),jb=n(x,"LI",{});var INe=s(jb);e_e=n(INe,"STRONG",{});var GLt=s(e_e);cRo=r(GLt,"unispeech"),GLt.forEach(t),mRo=r(INe," \u2014 "),lX=n(INe,"A",{href:!0});var OLt=s(lX);fRo=r(OLt,"UniSpeechModel"),OLt.forEach(t),gRo=r(INe," (UniSpeech model)"),INe.forEach(t),hRo=i(x),Db=n(x,"LI",{});var NNe=s(Db);o_e=n(NNe,"STRONG",{});var VLt=s(o_e);uRo=r(VLt,"unispeech-sat"),VLt.forEach(t),pRo=r(NNe," \u2014 "),iX=n(NNe,"A",{href:!0});var XLt=s(iX);_Ro=r(XLt,"UniSpeechSatModel"),XLt.forEach(t),bRo=r(NNe," (UniSpeechSat model)"),NNe.forEach(t),vRo=i(x),Gb=n(x,"LI",{});var qNe=s(Gb);r_e=n(qNe,"STRONG",{});var zLt=s(r_e);FRo=r(zLt,"van"),zLt.forEach(t),TRo=r(qNe," \u2014 "),dX=n(qNe,"A",{href:!0});var QLt=s(dX);MRo=r(QLt,"VanModel"),QLt.forEach(t),ERo=r(qNe," (VAN model)"),qNe.forEach(t),CRo=i(x),Ob=n(x,"LI",{});var jNe=s(Ob);t_e=n(jNe,"STRONG",{});var WLt=s(t_e);wRo=r(WLt,"videomae"),WLt.forEach(t),ARo=r(jNe," \u2014 "),cX=n(jNe,"A",{href:!0});var ULt=s(cX);LRo=r(ULt,"VideoMAEModel"),ULt.forEach(t),yRo=r(jNe," (VideoMAE model)"),jNe.forEach(t),xRo=i(x),Vb=n(x,"LI",{});var DNe=s(Vb);a_e=n(DNe,"STRONG",{});var HLt=s(a_e);$Ro=r(HLt,"vilt"),HLt.forEach(t),kRo=r(DNe," \u2014 "),mX=n(DNe,"A",{href:!0});var JLt=s(mX);SRo=r(JLt,"ViltModel"),JLt.forEach(t),RRo=r(DNe," (ViLT model)"),DNe.forEach(t),PRo=i(x),Xb=n(x,"LI",{});var GNe=s(Xb);n_e=n(GNe,"STRONG",{});var YLt=s(n_e);BRo=r(YLt,"vision-text-dual-encoder"),YLt.forEach(t),IRo=r(GNe," \u2014 "),fX=n(GNe,"A",{href:!0});var KLt=s(fX);NRo=r(KLt,"VisionTextDualEncoderModel"),KLt.forEach(t),qRo=r(GNe," (VisionTextDualEncoder model)"),GNe.forEach(t),jRo=i(x),zb=n(x,"LI",{});var ONe=s(zb);s_e=n(ONe,"STRONG",{});var ZLt=s(s_e);DRo=r(ZLt,"visual_bert"),ZLt.forEach(t),GRo=r(ONe," \u2014 "),gX=n(ONe,"A",{href:!0});var eyt=s(gX);ORo=r(eyt,"VisualBertModel"),eyt.forEach(t),VRo=r(ONe," (VisualBERT model)"),ONe.forEach(t),XRo=i(x),Qb=n(x,"LI",{});var VNe=s(Qb);l_e=n(VNe,"STRONG",{});var oyt=s(l_e);zRo=r(oyt,"vit"),oyt.forEach(t),QRo=r(VNe," \u2014 "),hX=n(VNe,"A",{href:!0});var ryt=s(hX);WRo=r(ryt,"ViTModel"),ryt.forEach(t),URo=r(VNe," (ViT model)"),VNe.forEach(t),HRo=i(x),Wb=n(x,"LI",{});var XNe=s(Wb);i_e=n(XNe,"STRONG",{});var tyt=s(i_e);JRo=r(tyt,"vit_mae"),tyt.forEach(t),YRo=r(XNe," \u2014 "),uX=n(XNe,"A",{href:!0});var ayt=s(uX);KRo=r(ayt,"ViTMAEModel"),ayt.forEach(t),ZRo=r(XNe," (ViTMAE model)"),XNe.forEach(t),ePo=i(x),Ub=n(x,"LI",{});var zNe=s(Ub);d_e=n(zNe,"STRONG",{});var nyt=s(d_e);oPo=r(nyt,"wav2vec2"),nyt.forEach(t),rPo=r(zNe," \u2014 "),pX=n(zNe,"A",{href:!0});var syt=s(pX);tPo=r(syt,"Wav2Vec2Model"),syt.forEach(t),aPo=r(zNe," (Wav2Vec2 model)"),zNe.forEach(t),nPo=i(x),Hb=n(x,"LI",{});var QNe=s(Hb);c_e=n(QNe,"STRONG",{});var lyt=s(c_e);sPo=r(lyt,"wav2vec2-conformer"),lyt.forEach(t),lPo=r(QNe," \u2014 "),_X=n(QNe,"A",{href:!0});var iyt=s(_X);iPo=r(iyt,"Wav2Vec2ConformerModel"),iyt.forEach(t),dPo=r(QNe," (Wav2Vec2-Conformer model)"),QNe.forEach(t),cPo=i(x),Jb=n(x,"LI",{});var WNe=s(Jb);m_e=n(WNe,"STRONG",{});var dyt=s(m_e);mPo=r(dyt,"wavlm"),dyt.forEach(t),fPo=r(WNe," \u2014 "),bX=n(WNe,"A",{href:!0});var cyt=s(bX);gPo=r(cyt,"WavLMModel"),cyt.forEach(t),hPo=r(WNe," (WavLM model)"),WNe.forEach(t),uPo=i(x),Yb=n(x,"LI",{});var UNe=s(Yb);f_e=n(UNe,"STRONG",{});var myt=s(f_e);pPo=r(myt,"xclip"),myt.forEach(t),_Po=r(UNe," \u2014 "),vX=n(UNe,"A",{href:!0});var fyt=s(vX);bPo=r(fyt,"XCLIPModel"),fyt.forEach(t),vPo=r(UNe," (X-CLIP model)"),UNe.forEach(t),FPo=i(x),Kb=n(x,"LI",{});var HNe=s(Kb);g_e=n(HNe,"STRONG",{});var gyt=s(g_e);TPo=r(gyt,"xglm"),gyt.forEach(t),MPo=r(HNe," \u2014 "),FX=n(HNe,"A",{href:!0});var hyt=s(FX);EPo=r(hyt,"XGLMModel"),hyt.forEach(t),CPo=r(HNe," (XGLM model)"),HNe.forEach(t),wPo=i(x),Zb=n(x,"LI",{});var JNe=s(Zb);h_e=n(JNe,"STRONG",{});var uyt=s(h_e);APo=r(uyt,"xlm"),uyt.forEach(t),LPo=r(JNe," \u2014 "),TX=n(JNe,"A",{href:!0});var pyt=s(TX);yPo=r(pyt,"XLMModel"),pyt.forEach(t),xPo=r(JNe," (XLM model)"),JNe.forEach(t),$Po=i(x),e2=n(x,"LI",{});var YNe=s(e2);u_e=n(YNe,"STRONG",{});var _yt=s(u_e);kPo=r(_yt,"xlm-prophetnet"),_yt.forEach(t),SPo=r(YNe," \u2014 "),MX=n(YNe,"A",{href:!0});var byt=s(MX);RPo=r(byt,"XLMProphetNetModel"),byt.forEach(t),PPo=r(YNe," (XLM-ProphetNet model)"),YNe.forEach(t),BPo=i(x),o2=n(x,"LI",{});var KNe=s(o2);p_e=n(KNe,"STRONG",{});var vyt=s(p_e);IPo=r(vyt,"xlm-roberta"),vyt.forEach(t),NPo=r(KNe," \u2014 "),EX=n(KNe,"A",{href:!0});var Fyt=s(EX);qPo=r(Fyt,"XLMRobertaModel"),Fyt.forEach(t),jPo=r(KNe," (XLM-RoBERTa model)"),KNe.forEach(t),DPo=i(x),r2=n(x,"LI",{});var ZNe=s(r2);__e=n(ZNe,"STRONG",{});var Tyt=s(__e);GPo=r(Tyt,"xlm-roberta-xl"),Tyt.forEach(t),OPo=r(ZNe," \u2014 "),CX=n(ZNe,"A",{href:!0});var Myt=s(CX);VPo=r(Myt,"XLMRobertaXLModel"),Myt.forEach(t),XPo=r(ZNe," (XLM-RoBERTa-XL model)"),ZNe.forEach(t),zPo=i(x),t2=n(x,"LI",{});var eqe=s(t2);b_e=n(eqe,"STRONG",{});var Eyt=s(b_e);QPo=r(Eyt,"xlnet"),Eyt.forEach(t),WPo=r(eqe," \u2014 "),wX=n(eqe,"A",{href:!0});var Cyt=s(wX);UPo=r(Cyt,"XLNetModel"),Cyt.forEach(t),HPo=r(eqe," (XLNet model)"),eqe.forEach(t),JPo=i(x),a2=n(x,"LI",{});var oqe=s(a2);v_e=n(oqe,"STRONG",{});var wyt=s(v_e);YPo=r(wyt,"yolos"),wyt.forEach(t),KPo=r(oqe," \u2014 "),AX=n(oqe,"A",{href:!0});var Ayt=s(AX);ZPo=r(Ayt,"YolosModel"),Ayt.forEach(t),eBo=r(oqe," (YOLOS model)"),oqe.forEach(t),oBo=i(x),n2=n(x,"LI",{});var rqe=s(n2);F_e=n(rqe,"STRONG",{});var Lyt=s(F_e);rBo=r(Lyt,"yoso"),Lyt.forEach(t),tBo=r(rqe," \u2014 "),LX=n(rqe,"A",{href:!0});var yyt=s(LX);aBo=r(yyt,"YosoModel"),yyt.forEach(t),nBo=r(rqe," (YOSO model)"),rqe.forEach(t),x.forEach(t),sBo=i(Fa),s2=n(Fa,"P",{});var tqe=s(s2);lBo=r(tqe,"The model is set in evaluation mode by default using "),T_e=n(tqe,"CODE",{});var xyt=s(T_e);iBo=r(xyt,"model.eval()"),xyt.forEach(t),dBo=r(tqe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),M_e=n(tqe,"CODE",{});var $yt=s(M_e);cBo=r($yt,"model.train()"),$yt.forEach(t),tqe.forEach(t),mBo=i(Fa),T(l2.$$.fragment,Fa),Fa.forEach(t),wl.forEach(t),dKe=i(m),vd=n(m,"H2",{class:!0});var Eeo=s(vd);i2=n(Eeo,"A",{id:!0,class:!0,href:!0});var kyt=s(i2);E_e=n(kyt,"SPAN",{});var Syt=s(E_e);T(nx.$$.fragment,Syt),Syt.forEach(t),kyt.forEach(t),fBo=i(Eeo),C_e=n(Eeo,"SPAN",{});var Ryt=s(C_e);gBo=r(Ryt,"AutoModelForPreTraining"),Ryt.forEach(t),Eeo.forEach(t),cKe=i(m),Bo=n(m,"DIV",{class:!0});var Al=s(Bo);T(sx.$$.fragment,Al),hBo=i(Al),Fd=n(Al,"P",{});var tle=s(Fd);uBo=r(tle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),yX=n(tle,"A",{href:!0});var Pyt=s(yX);pBo=r(Pyt,"from_pretrained()"),Pyt.forEach(t),_Bo=r(tle," class method or the "),xX=n(tle,"A",{href:!0});var Byt=s(xX);bBo=r(Byt,"from_config()"),Byt.forEach(t),vBo=r(tle,` class
method.`),tle.forEach(t),FBo=i(Al),lx=n(Al,"P",{});var Ceo=s(lx);TBo=r(Ceo,"This class cannot be instantiated directly using "),w_e=n(Ceo,"CODE",{});var Iyt=s(w_e);MBo=r(Iyt,"__init__()"),Iyt.forEach(t),EBo=r(Ceo," (throws an error)."),Ceo.forEach(t),CBo=i(Al),bt=n(Al,"DIV",{class:!0});var wy=s(bt);T(ix.$$.fragment,wy),wBo=i(wy),A_e=n(wy,"P",{});var Nyt=s(A_e);ABo=r(Nyt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Nyt.forEach(t),LBo=i(wy),Td=n(wy,"P",{});var ale=s(Td);yBo=r(ale,`Note:
Loading a model from its configuration file does `),L_e=n(ale,"STRONG",{});var qyt=s(L_e);xBo=r(qyt,"not"),qyt.forEach(t),$Bo=r(ale,` load the model weights. It only affects the
model\u2019s configuration. Use `),$X=n(ale,"A",{href:!0});var jyt=s($X);kBo=r(jyt,"from_pretrained()"),jyt.forEach(t),SBo=r(ale," to load the model weights."),ale.forEach(t),RBo=i(wy),T(d2.$$.fragment,wy),wy.forEach(t),PBo=i(Al),eo=n(Al,"DIV",{class:!0});var Ta=s(eo);T(dx.$$.fragment,Ta),BBo=i(Ta),y_e=n(Ta,"P",{});var Dyt=s(y_e);IBo=r(Dyt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Dyt.forEach(t),NBo=i(Ta),Ya=n(Ta,"P",{});var Ay=s(Ya);qBo=r(Ay,"The model class to instantiate is selected based on the "),x_e=n(Ay,"CODE",{});var Gyt=s(x_e);jBo=r(Gyt,"model_type"),Gyt.forEach(t),DBo=r(Ay,` property of the config object (either
passed as an argument or loaded from `),$_e=n(Ay,"CODE",{});var Oyt=s($_e);GBo=r(Oyt,"pretrained_model_name_or_path"),Oyt.forEach(t),OBo=r(Ay,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k_e=n(Ay,"CODE",{});var Vyt=s(k_e);VBo=r(Vyt,"pretrained_model_name_or_path"),Vyt.forEach(t),XBo=r(Ay,":"),Ay.forEach(t),zBo=i(Ta),G=n(Ta,"UL",{});var O=s(G);c2=n(O,"LI",{});var aqe=s(c2);S_e=n(aqe,"STRONG",{});var Xyt=s(S_e);QBo=r(Xyt,"albert"),Xyt.forEach(t),WBo=r(aqe," \u2014 "),kX=n(aqe,"A",{href:!0});var zyt=s(kX);UBo=r(zyt,"AlbertForPreTraining"),zyt.forEach(t),HBo=r(aqe," (ALBERT model)"),aqe.forEach(t),JBo=i(O),m2=n(O,"LI",{});var nqe=s(m2);R_e=n(nqe,"STRONG",{});var Qyt=s(R_e);YBo=r(Qyt,"bart"),Qyt.forEach(t),KBo=r(nqe," \u2014 "),SX=n(nqe,"A",{href:!0});var Wyt=s(SX);ZBo=r(Wyt,"BartForConditionalGeneration"),Wyt.forEach(t),eIo=r(nqe," (BART model)"),nqe.forEach(t),oIo=i(O),f2=n(O,"LI",{});var sqe=s(f2);P_e=n(sqe,"STRONG",{});var Uyt=s(P_e);rIo=r(Uyt,"bert"),Uyt.forEach(t),tIo=r(sqe," \u2014 "),RX=n(sqe,"A",{href:!0});var Hyt=s(RX);aIo=r(Hyt,"BertForPreTraining"),Hyt.forEach(t),nIo=r(sqe," (BERT model)"),sqe.forEach(t),sIo=i(O),g2=n(O,"LI",{});var lqe=s(g2);B_e=n(lqe,"STRONG",{});var Jyt=s(B_e);lIo=r(Jyt,"big_bird"),Jyt.forEach(t),iIo=r(lqe," \u2014 "),PX=n(lqe,"A",{href:!0});var Yyt=s(PX);dIo=r(Yyt,"BigBirdForPreTraining"),Yyt.forEach(t),cIo=r(lqe," (BigBird model)"),lqe.forEach(t),mIo=i(O),h2=n(O,"LI",{});var iqe=s(h2);I_e=n(iqe,"STRONG",{});var Kyt=s(I_e);fIo=r(Kyt,"bloom"),Kyt.forEach(t),gIo=r(iqe," \u2014 "),BX=n(iqe,"A",{href:!0});var Zyt=s(BX);hIo=r(Zyt,"BloomForCausalLM"),Zyt.forEach(t),uIo=r(iqe," (BLOOM model)"),iqe.forEach(t),pIo=i(O),u2=n(O,"LI",{});var dqe=s(u2);N_e=n(dqe,"STRONG",{});var e8t=s(N_e);_Io=r(e8t,"camembert"),e8t.forEach(t),bIo=r(dqe," \u2014 "),IX=n(dqe,"A",{href:!0});var o8t=s(IX);vIo=r(o8t,"CamembertForMaskedLM"),o8t.forEach(t),FIo=r(dqe," (CamemBERT model)"),dqe.forEach(t),TIo=i(O),p2=n(O,"LI",{});var cqe=s(p2);q_e=n(cqe,"STRONG",{});var r8t=s(q_e);MIo=r(r8t,"ctrl"),r8t.forEach(t),EIo=r(cqe," \u2014 "),NX=n(cqe,"A",{href:!0});var t8t=s(NX);CIo=r(t8t,"CTRLLMHeadModel"),t8t.forEach(t),wIo=r(cqe," (CTRL model)"),cqe.forEach(t),AIo=i(O),_2=n(O,"LI",{});var mqe=s(_2);j_e=n(mqe,"STRONG",{});var a8t=s(j_e);LIo=r(a8t,"data2vec-text"),a8t.forEach(t),yIo=r(mqe," \u2014 "),qX=n(mqe,"A",{href:!0});var n8t=s(qX);xIo=r(n8t,"Data2VecTextForMaskedLM"),n8t.forEach(t),$Io=r(mqe," (Data2VecText model)"),mqe.forEach(t),kIo=i(O),b2=n(O,"LI",{});var fqe=s(b2);D_e=n(fqe,"STRONG",{});var s8t=s(D_e);SIo=r(s8t,"deberta"),s8t.forEach(t),RIo=r(fqe," \u2014 "),jX=n(fqe,"A",{href:!0});var l8t=s(jX);PIo=r(l8t,"DebertaForMaskedLM"),l8t.forEach(t),BIo=r(fqe," (DeBERTa model)"),fqe.forEach(t),IIo=i(O),v2=n(O,"LI",{});var gqe=s(v2);G_e=n(gqe,"STRONG",{});var i8t=s(G_e);NIo=r(i8t,"deberta-v2"),i8t.forEach(t),qIo=r(gqe," \u2014 "),DX=n(gqe,"A",{href:!0});var d8t=s(DX);jIo=r(d8t,"DebertaV2ForMaskedLM"),d8t.forEach(t),DIo=r(gqe," (DeBERTa-v2 model)"),gqe.forEach(t),GIo=i(O),F2=n(O,"LI",{});var hqe=s(F2);O_e=n(hqe,"STRONG",{});var c8t=s(O_e);OIo=r(c8t,"distilbert"),c8t.forEach(t),VIo=r(hqe," \u2014 "),GX=n(hqe,"A",{href:!0});var m8t=s(GX);XIo=r(m8t,"DistilBertForMaskedLM"),m8t.forEach(t),zIo=r(hqe," (DistilBERT model)"),hqe.forEach(t),QIo=i(O),T2=n(O,"LI",{});var uqe=s(T2);V_e=n(uqe,"STRONG",{});var f8t=s(V_e);WIo=r(f8t,"electra"),f8t.forEach(t),UIo=r(uqe," \u2014 "),OX=n(uqe,"A",{href:!0});var g8t=s(OX);HIo=r(g8t,"ElectraForPreTraining"),g8t.forEach(t),JIo=r(uqe," (ELECTRA model)"),uqe.forEach(t),YIo=i(O),M2=n(O,"LI",{});var pqe=s(M2);X_e=n(pqe,"STRONG",{});var h8t=s(X_e);KIo=r(h8t,"ernie"),h8t.forEach(t),ZIo=r(pqe," \u2014 "),VX=n(pqe,"A",{href:!0});var u8t=s(VX);eNo=r(u8t,"ErnieForPreTraining"),u8t.forEach(t),oNo=r(pqe," (ERNIE model)"),pqe.forEach(t),rNo=i(O),E2=n(O,"LI",{});var _qe=s(E2);z_e=n(_qe,"STRONG",{});var p8t=s(z_e);tNo=r(p8t,"flaubert"),p8t.forEach(t),aNo=r(_qe," \u2014 "),XX=n(_qe,"A",{href:!0});var _8t=s(XX);nNo=r(_8t,"FlaubertWithLMHeadModel"),_8t.forEach(t),sNo=r(_qe," (FlauBERT model)"),_qe.forEach(t),lNo=i(O),C2=n(O,"LI",{});var bqe=s(C2);Q_e=n(bqe,"STRONG",{});var b8t=s(Q_e);iNo=r(b8t,"flava"),b8t.forEach(t),dNo=r(bqe," \u2014 "),zX=n(bqe,"A",{href:!0});var v8t=s(zX);cNo=r(v8t,"FlavaForPreTraining"),v8t.forEach(t),mNo=r(bqe," (FLAVA model)"),bqe.forEach(t),fNo=i(O),w2=n(O,"LI",{});var vqe=s(w2);W_e=n(vqe,"STRONG",{});var F8t=s(W_e);gNo=r(F8t,"fnet"),F8t.forEach(t),hNo=r(vqe," \u2014 "),QX=n(vqe,"A",{href:!0});var T8t=s(QX);uNo=r(T8t,"FNetForPreTraining"),T8t.forEach(t),pNo=r(vqe," (FNet model)"),vqe.forEach(t),_No=i(O),A2=n(O,"LI",{});var Fqe=s(A2);U_e=n(Fqe,"STRONG",{});var M8t=s(U_e);bNo=r(M8t,"fsmt"),M8t.forEach(t),vNo=r(Fqe," \u2014 "),WX=n(Fqe,"A",{href:!0});var E8t=s(WX);FNo=r(E8t,"FSMTForConditionalGeneration"),E8t.forEach(t),TNo=r(Fqe," (FairSeq Machine-Translation model)"),Fqe.forEach(t),MNo=i(O),L2=n(O,"LI",{});var Tqe=s(L2);H_e=n(Tqe,"STRONG",{});var C8t=s(H_e);ENo=r(C8t,"funnel"),C8t.forEach(t),CNo=r(Tqe," \u2014 "),UX=n(Tqe,"A",{href:!0});var w8t=s(UX);wNo=r(w8t,"FunnelForPreTraining"),w8t.forEach(t),ANo=r(Tqe," (Funnel Transformer model)"),Tqe.forEach(t),LNo=i(O),y2=n(O,"LI",{});var Mqe=s(y2);J_e=n(Mqe,"STRONG",{});var A8t=s(J_e);yNo=r(A8t,"gpt2"),A8t.forEach(t),xNo=r(Mqe," \u2014 "),HX=n(Mqe,"A",{href:!0});var L8t=s(HX);$No=r(L8t,"GPT2LMHeadModel"),L8t.forEach(t),kNo=r(Mqe," (OpenAI GPT-2 model)"),Mqe.forEach(t),SNo=i(O),x2=n(O,"LI",{});var Eqe=s(x2);Y_e=n(Eqe,"STRONG",{});var y8t=s(Y_e);RNo=r(y8t,"ibert"),y8t.forEach(t),PNo=r(Eqe," \u2014 "),JX=n(Eqe,"A",{href:!0});var x8t=s(JX);BNo=r(x8t,"IBertForMaskedLM"),x8t.forEach(t),INo=r(Eqe," (I-BERT model)"),Eqe.forEach(t),NNo=i(O),$2=n(O,"LI",{});var Cqe=s($2);K_e=n(Cqe,"STRONG",{});var $8t=s(K_e);qNo=r($8t,"layoutlm"),$8t.forEach(t),jNo=r(Cqe," \u2014 "),YX=n(Cqe,"A",{href:!0});var k8t=s(YX);DNo=r(k8t,"LayoutLMForMaskedLM"),k8t.forEach(t),GNo=r(Cqe," (LayoutLM model)"),Cqe.forEach(t),ONo=i(O),k2=n(O,"LI",{});var wqe=s(k2);Z_e=n(wqe,"STRONG",{});var S8t=s(Z_e);VNo=r(S8t,"longformer"),S8t.forEach(t),XNo=r(wqe," \u2014 "),KX=n(wqe,"A",{href:!0});var R8t=s(KX);zNo=r(R8t,"LongformerForMaskedLM"),R8t.forEach(t),QNo=r(wqe," (Longformer model)"),wqe.forEach(t),WNo=i(O),S2=n(O,"LI",{});var Aqe=s(S2);ebe=n(Aqe,"STRONG",{});var P8t=s(ebe);UNo=r(P8t,"luke"),P8t.forEach(t),HNo=r(Aqe," \u2014 "),ZX=n(Aqe,"A",{href:!0});var B8t=s(ZX);JNo=r(B8t,"LukeForMaskedLM"),B8t.forEach(t),YNo=r(Aqe," (LUKE model)"),Aqe.forEach(t),KNo=i(O),R2=n(O,"LI",{});var Lqe=s(R2);obe=n(Lqe,"STRONG",{});var I8t=s(obe);ZNo=r(I8t,"lxmert"),I8t.forEach(t),eqo=r(Lqe," \u2014 "),ez=n(Lqe,"A",{href:!0});var N8t=s(ez);oqo=r(N8t,"LxmertForPreTraining"),N8t.forEach(t),rqo=r(Lqe," (LXMERT model)"),Lqe.forEach(t),tqo=i(O),P2=n(O,"LI",{});var yqe=s(P2);rbe=n(yqe,"STRONG",{});var q8t=s(rbe);aqo=r(q8t,"megatron-bert"),q8t.forEach(t),nqo=r(yqe," \u2014 "),oz=n(yqe,"A",{href:!0});var j8t=s(oz);sqo=r(j8t,"MegatronBertForPreTraining"),j8t.forEach(t),lqo=r(yqe," (Megatron-BERT model)"),yqe.forEach(t),iqo=i(O),B2=n(O,"LI",{});var xqe=s(B2);tbe=n(xqe,"STRONG",{});var D8t=s(tbe);dqo=r(D8t,"mobilebert"),D8t.forEach(t),cqo=r(xqe," \u2014 "),rz=n(xqe,"A",{href:!0});var G8t=s(rz);mqo=r(G8t,"MobileBertForPreTraining"),G8t.forEach(t),fqo=r(xqe," (MobileBERT model)"),xqe.forEach(t),gqo=i(O),I2=n(O,"LI",{});var $qe=s(I2);abe=n($qe,"STRONG",{});var O8t=s(abe);hqo=r(O8t,"mpnet"),O8t.forEach(t),uqo=r($qe," \u2014 "),tz=n($qe,"A",{href:!0});var V8t=s(tz);pqo=r(V8t,"MPNetForMaskedLM"),V8t.forEach(t),_qo=r($qe," (MPNet model)"),$qe.forEach(t),bqo=i(O),N2=n(O,"LI",{});var kqe=s(N2);nbe=n(kqe,"STRONG",{});var X8t=s(nbe);vqo=r(X8t,"mvp"),X8t.forEach(t),Fqo=r(kqe," \u2014 "),az=n(kqe,"A",{href:!0});var z8t=s(az);Tqo=r(z8t,"MvpForConditionalGeneration"),z8t.forEach(t),Mqo=r(kqe," (MVP model)"),kqe.forEach(t),Eqo=i(O),q2=n(O,"LI",{});var Sqe=s(q2);sbe=n(Sqe,"STRONG",{});var Q8t=s(sbe);Cqo=r(Q8t,"nezha"),Q8t.forEach(t),wqo=r(Sqe," \u2014 "),nz=n(Sqe,"A",{href:!0});var W8t=s(nz);Aqo=r(W8t,"NezhaForPreTraining"),W8t.forEach(t),Lqo=r(Sqe," (Nezha model)"),Sqe.forEach(t),yqo=i(O),j2=n(O,"LI",{});var Rqe=s(j2);lbe=n(Rqe,"STRONG",{});var U8t=s(lbe);xqo=r(U8t,"openai-gpt"),U8t.forEach(t),$qo=r(Rqe," \u2014 "),sz=n(Rqe,"A",{href:!0});var H8t=s(sz);kqo=r(H8t,"OpenAIGPTLMHeadModel"),H8t.forEach(t),Sqo=r(Rqe," (OpenAI GPT model)"),Rqe.forEach(t),Rqo=i(O),D2=n(O,"LI",{});var Pqe=s(D2);ibe=n(Pqe,"STRONG",{});var J8t=s(ibe);Pqo=r(J8t,"retribert"),J8t.forEach(t),Bqo=r(Pqe," \u2014 "),lz=n(Pqe,"A",{href:!0});var Y8t=s(lz);Iqo=r(Y8t,"RetriBertModel"),Y8t.forEach(t),Nqo=r(Pqe," (RetriBERT model)"),Pqe.forEach(t),qqo=i(O),G2=n(O,"LI",{});var Bqe=s(G2);dbe=n(Bqe,"STRONG",{});var K8t=s(dbe);jqo=r(K8t,"roberta"),K8t.forEach(t),Dqo=r(Bqe," \u2014 "),iz=n(Bqe,"A",{href:!0});var Z8t=s(iz);Gqo=r(Z8t,"RobertaForMaskedLM"),Z8t.forEach(t),Oqo=r(Bqe," (RoBERTa model)"),Bqe.forEach(t),Vqo=i(O),O2=n(O,"LI",{});var Iqe=s(O2);cbe=n(Iqe,"STRONG",{});var e9t=s(cbe);Xqo=r(e9t,"splinter"),e9t.forEach(t),zqo=r(Iqe," \u2014 "),dz=n(Iqe,"A",{href:!0});var o9t=s(dz);Qqo=r(o9t,"SplinterForPreTraining"),o9t.forEach(t),Wqo=r(Iqe," (Splinter model)"),Iqe.forEach(t),Uqo=i(O),V2=n(O,"LI",{});var Nqe=s(V2);mbe=n(Nqe,"STRONG",{});var r9t=s(mbe);Hqo=r(r9t,"squeezebert"),r9t.forEach(t),Jqo=r(Nqe," \u2014 "),cz=n(Nqe,"A",{href:!0});var t9t=s(cz);Yqo=r(t9t,"SqueezeBertForMaskedLM"),t9t.forEach(t),Kqo=r(Nqe," (SqueezeBERT model)"),Nqe.forEach(t),Zqo=i(O),X2=n(O,"LI",{});var qqe=s(X2);fbe=n(qqe,"STRONG",{});var a9t=s(fbe);ejo=r(a9t,"t5"),a9t.forEach(t),ojo=r(qqe," \u2014 "),mz=n(qqe,"A",{href:!0});var n9t=s(mz);rjo=r(n9t,"T5ForConditionalGeneration"),n9t.forEach(t),tjo=r(qqe," (T5 model)"),qqe.forEach(t),ajo=i(O),z2=n(O,"LI",{});var jqe=s(z2);gbe=n(jqe,"STRONG",{});var s9t=s(gbe);njo=r(s9t,"tapas"),s9t.forEach(t),sjo=r(jqe," \u2014 "),fz=n(jqe,"A",{href:!0});var l9t=s(fz);ljo=r(l9t,"TapasForMaskedLM"),l9t.forEach(t),ijo=r(jqe," (TAPAS model)"),jqe.forEach(t),djo=i(O),Q2=n(O,"LI",{});var Dqe=s(Q2);hbe=n(Dqe,"STRONG",{});var i9t=s(hbe);cjo=r(i9t,"transfo-xl"),i9t.forEach(t),mjo=r(Dqe," \u2014 "),gz=n(Dqe,"A",{href:!0});var d9t=s(gz);fjo=r(d9t,"TransfoXLLMHeadModel"),d9t.forEach(t),gjo=r(Dqe," (Transformer-XL model)"),Dqe.forEach(t),hjo=i(O),W2=n(O,"LI",{});var Gqe=s(W2);ube=n(Gqe,"STRONG",{});var c9t=s(ube);ujo=r(c9t,"unispeech"),c9t.forEach(t),pjo=r(Gqe," \u2014 "),hz=n(Gqe,"A",{href:!0});var m9t=s(hz);_jo=r(m9t,"UniSpeechForPreTraining"),m9t.forEach(t),bjo=r(Gqe," (UniSpeech model)"),Gqe.forEach(t),vjo=i(O),U2=n(O,"LI",{});var Oqe=s(U2);pbe=n(Oqe,"STRONG",{});var f9t=s(pbe);Fjo=r(f9t,"unispeech-sat"),f9t.forEach(t),Tjo=r(Oqe," \u2014 "),uz=n(Oqe,"A",{href:!0});var g9t=s(uz);Mjo=r(g9t,"UniSpeechSatForPreTraining"),g9t.forEach(t),Ejo=r(Oqe," (UniSpeechSat model)"),Oqe.forEach(t),Cjo=i(O),H2=n(O,"LI",{});var Vqe=s(H2);_be=n(Vqe,"STRONG",{});var h9t=s(_be);wjo=r(h9t,"videomae"),h9t.forEach(t),Ajo=r(Vqe," \u2014 "),pz=n(Vqe,"A",{href:!0});var u9t=s(pz);Ljo=r(u9t,"VideoMAEForPreTraining"),u9t.forEach(t),yjo=r(Vqe," (VideoMAE model)"),Vqe.forEach(t),xjo=i(O),J2=n(O,"LI",{});var Xqe=s(J2);bbe=n(Xqe,"STRONG",{});var p9t=s(bbe);$jo=r(p9t,"visual_bert"),p9t.forEach(t),kjo=r(Xqe," \u2014 "),_z=n(Xqe,"A",{href:!0});var _9t=s(_z);Sjo=r(_9t,"VisualBertForPreTraining"),_9t.forEach(t),Rjo=r(Xqe," (VisualBERT model)"),Xqe.forEach(t),Pjo=i(O),Y2=n(O,"LI",{});var zqe=s(Y2);vbe=n(zqe,"STRONG",{});var b9t=s(vbe);Bjo=r(b9t,"vit_mae"),b9t.forEach(t),Ijo=r(zqe," \u2014 "),bz=n(zqe,"A",{href:!0});var v9t=s(bz);Njo=r(v9t,"ViTMAEForPreTraining"),v9t.forEach(t),qjo=r(zqe," (ViTMAE model)"),zqe.forEach(t),jjo=i(O),K2=n(O,"LI",{});var Qqe=s(K2);Fbe=n(Qqe,"STRONG",{});var F9t=s(Fbe);Djo=r(F9t,"wav2vec2"),F9t.forEach(t),Gjo=r(Qqe," \u2014 "),vz=n(Qqe,"A",{href:!0});var T9t=s(vz);Ojo=r(T9t,"Wav2Vec2ForPreTraining"),T9t.forEach(t),Vjo=r(Qqe," (Wav2Vec2 model)"),Qqe.forEach(t),Xjo=i(O),Z2=n(O,"LI",{});var Wqe=s(Z2);Tbe=n(Wqe,"STRONG",{});var M9t=s(Tbe);zjo=r(M9t,"wav2vec2-conformer"),M9t.forEach(t),Qjo=r(Wqe," \u2014 "),Fz=n(Wqe,"A",{href:!0});var E9t=s(Fz);Wjo=r(E9t,"Wav2Vec2ConformerForPreTraining"),E9t.forEach(t),Ujo=r(Wqe," (Wav2Vec2-Conformer model)"),Wqe.forEach(t),Hjo=i(O),e1=n(O,"LI",{});var Uqe=s(e1);Mbe=n(Uqe,"STRONG",{});var C9t=s(Mbe);Jjo=r(C9t,"xlm"),C9t.forEach(t),Yjo=r(Uqe," \u2014 "),Tz=n(Uqe,"A",{href:!0});var w9t=s(Tz);Kjo=r(w9t,"XLMWithLMHeadModel"),w9t.forEach(t),Zjo=r(Uqe," (XLM model)"),Uqe.forEach(t),eDo=i(O),o1=n(O,"LI",{});var Hqe=s(o1);Ebe=n(Hqe,"STRONG",{});var A9t=s(Ebe);oDo=r(A9t,"xlm-roberta"),A9t.forEach(t),rDo=r(Hqe," \u2014 "),Mz=n(Hqe,"A",{href:!0});var L9t=s(Mz);tDo=r(L9t,"XLMRobertaForMaskedLM"),L9t.forEach(t),aDo=r(Hqe," (XLM-RoBERTa model)"),Hqe.forEach(t),nDo=i(O),r1=n(O,"LI",{});var Jqe=s(r1);Cbe=n(Jqe,"STRONG",{});var y9t=s(Cbe);sDo=r(y9t,"xlm-roberta-xl"),y9t.forEach(t),lDo=r(Jqe," \u2014 "),Ez=n(Jqe,"A",{href:!0});var x9t=s(Ez);iDo=r(x9t,"XLMRobertaXLForMaskedLM"),x9t.forEach(t),dDo=r(Jqe," (XLM-RoBERTa-XL model)"),Jqe.forEach(t),cDo=i(O),t1=n(O,"LI",{});var Yqe=s(t1);wbe=n(Yqe,"STRONG",{});var $9t=s(wbe);mDo=r($9t,"xlnet"),$9t.forEach(t),fDo=r(Yqe," \u2014 "),Cz=n(Yqe,"A",{href:!0});var k9t=s(Cz);gDo=r(k9t,"XLNetLMHeadModel"),k9t.forEach(t),hDo=r(Yqe," (XLNet model)"),Yqe.forEach(t),O.forEach(t),uDo=i(Ta),a1=n(Ta,"P",{});var Kqe=s(a1);pDo=r(Kqe,"The model is set in evaluation mode by default using "),Abe=n(Kqe,"CODE",{});var S9t=s(Abe);_Do=r(S9t,"model.eval()"),S9t.forEach(t),bDo=r(Kqe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lbe=n(Kqe,"CODE",{});var R9t=s(Lbe);vDo=r(R9t,"model.train()"),R9t.forEach(t),Kqe.forEach(t),FDo=i(Ta),T(n1.$$.fragment,Ta),Ta.forEach(t),Al.forEach(t),mKe=i(m),Md=n(m,"H2",{class:!0});var weo=s(Md);s1=n(weo,"A",{id:!0,class:!0,href:!0});var P9t=s(s1);ybe=n(P9t,"SPAN",{});var B9t=s(ybe);T(cx.$$.fragment,B9t),B9t.forEach(t),P9t.forEach(t),TDo=i(weo),xbe=n(weo,"SPAN",{});var I9t=s(xbe);MDo=r(I9t,"AutoModelForCausalLM"),I9t.forEach(t),weo.forEach(t),fKe=i(m),Io=n(m,"DIV",{class:!0});var Ll=s(Io);T(mx.$$.fragment,Ll),EDo=i(Ll),Ed=n(Ll,"P",{});var nle=s(Ed);CDo=r(nle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wz=n(nle,"A",{href:!0});var N9t=s(wz);wDo=r(N9t,"from_pretrained()"),N9t.forEach(t),ADo=r(nle," class method or the "),Az=n(nle,"A",{href:!0});var q9t=s(Az);LDo=r(q9t,"from_config()"),q9t.forEach(t),yDo=r(nle,` class
method.`),nle.forEach(t),xDo=i(Ll),fx=n(Ll,"P",{});var Aeo=s(fx);$Do=r(Aeo,"This class cannot be instantiated directly using "),$be=n(Aeo,"CODE",{});var j9t=s($be);kDo=r(j9t,"__init__()"),j9t.forEach(t),SDo=r(Aeo," (throws an error)."),Aeo.forEach(t),RDo=i(Ll),vt=n(Ll,"DIV",{class:!0});var Ly=s(vt);T(gx.$$.fragment,Ly),PDo=i(Ly),kbe=n(Ly,"P",{});var D9t=s(kbe);BDo=r(D9t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),D9t.forEach(t),IDo=i(Ly),Cd=n(Ly,"P",{});var sle=s(Cd);NDo=r(sle,`Note:
Loading a model from its configuration file does `),Sbe=n(sle,"STRONG",{});var G9t=s(Sbe);qDo=r(G9t,"not"),G9t.forEach(t),jDo=r(sle,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lz=n(sle,"A",{href:!0});var O9t=s(Lz);DDo=r(O9t,"from_pretrained()"),O9t.forEach(t),GDo=r(sle," to load the model weights."),sle.forEach(t),ODo=i(Ly),T(l1.$$.fragment,Ly),Ly.forEach(t),VDo=i(Ll),oo=n(Ll,"DIV",{class:!0});var Ma=s(oo);T(hx.$$.fragment,Ma),XDo=i(Ma),Rbe=n(Ma,"P",{});var V9t=s(Rbe);zDo=r(V9t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),V9t.forEach(t),QDo=i(Ma),Ka=n(Ma,"P",{});var yy=s(Ka);WDo=r(yy,"The model class to instantiate is selected based on the "),Pbe=n(yy,"CODE",{});var X9t=s(Pbe);UDo=r(X9t,"model_type"),X9t.forEach(t),HDo=r(yy,` property of the config object (either
passed as an argument or loaded from `),Bbe=n(yy,"CODE",{});var z9t=s(Bbe);JDo=r(z9t,"pretrained_model_name_or_path"),z9t.forEach(t),YDo=r(yy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ibe=n(yy,"CODE",{});var Q9t=s(Ibe);KDo=r(Q9t,"pretrained_model_name_or_path"),Q9t.forEach(t),ZDo=r(yy,":"),yy.forEach(t),eGo=i(Ma),z=n(Ma,"UL",{});var W=s(z);i1=n(W,"LI",{});var Zqe=s(i1);Nbe=n(Zqe,"STRONG",{});var W9t=s(Nbe);oGo=r(W9t,"bart"),W9t.forEach(t),rGo=r(Zqe," \u2014 "),yz=n(Zqe,"A",{href:!0});var U9t=s(yz);tGo=r(U9t,"BartForCausalLM"),U9t.forEach(t),aGo=r(Zqe," (BART model)"),Zqe.forEach(t),nGo=i(W),d1=n(W,"LI",{});var eje=s(d1);qbe=n(eje,"STRONG",{});var H9t=s(qbe);sGo=r(H9t,"bert"),H9t.forEach(t),lGo=r(eje," \u2014 "),xz=n(eje,"A",{href:!0});var J9t=s(xz);iGo=r(J9t,"BertLMHeadModel"),J9t.forEach(t),dGo=r(eje," (BERT model)"),eje.forEach(t),cGo=i(W),c1=n(W,"LI",{});var oje=s(c1);jbe=n(oje,"STRONG",{});var Y9t=s(jbe);mGo=r(Y9t,"bert-generation"),Y9t.forEach(t),fGo=r(oje," \u2014 "),$z=n(oje,"A",{href:!0});var K9t=s($z);gGo=r(K9t,"BertGenerationDecoder"),K9t.forEach(t),hGo=r(oje," (Bert Generation model)"),oje.forEach(t),uGo=i(W),m1=n(W,"LI",{});var rje=s(m1);Dbe=n(rje,"STRONG",{});var Z9t=s(Dbe);pGo=r(Z9t,"big_bird"),Z9t.forEach(t),_Go=r(rje," \u2014 "),kz=n(rje,"A",{href:!0});var ext=s(kz);bGo=r(ext,"BigBirdForCausalLM"),ext.forEach(t),vGo=r(rje," (BigBird model)"),rje.forEach(t),FGo=i(W),f1=n(W,"LI",{});var tje=s(f1);Gbe=n(tje,"STRONG",{});var oxt=s(Gbe);TGo=r(oxt,"bigbird_pegasus"),oxt.forEach(t),MGo=r(tje," \u2014 "),Sz=n(tje,"A",{href:!0});var rxt=s(Sz);EGo=r(rxt,"BigBirdPegasusForCausalLM"),rxt.forEach(t),CGo=r(tje," (BigBird-Pegasus model)"),tje.forEach(t),wGo=i(W),g1=n(W,"LI",{});var aje=s(g1);Obe=n(aje,"STRONG",{});var txt=s(Obe);AGo=r(txt,"blenderbot"),txt.forEach(t),LGo=r(aje," \u2014 "),Rz=n(aje,"A",{href:!0});var axt=s(Rz);yGo=r(axt,"BlenderbotForCausalLM"),axt.forEach(t),xGo=r(aje," (Blenderbot model)"),aje.forEach(t),$Go=i(W),h1=n(W,"LI",{});var nje=s(h1);Vbe=n(nje,"STRONG",{});var nxt=s(Vbe);kGo=r(nxt,"blenderbot-small"),nxt.forEach(t),SGo=r(nje," \u2014 "),Pz=n(nje,"A",{href:!0});var sxt=s(Pz);RGo=r(sxt,"BlenderbotSmallForCausalLM"),sxt.forEach(t),PGo=r(nje," (BlenderbotSmall model)"),nje.forEach(t),BGo=i(W),u1=n(W,"LI",{});var sje=s(u1);Xbe=n(sje,"STRONG",{});var lxt=s(Xbe);IGo=r(lxt,"bloom"),lxt.forEach(t),NGo=r(sje," \u2014 "),Bz=n(sje,"A",{href:!0});var ixt=s(Bz);qGo=r(ixt,"BloomForCausalLM"),ixt.forEach(t),jGo=r(sje," (BLOOM model)"),sje.forEach(t),DGo=i(W),p1=n(W,"LI",{});var lje=s(p1);zbe=n(lje,"STRONG",{});var dxt=s(zbe);GGo=r(dxt,"camembert"),dxt.forEach(t),OGo=r(lje," \u2014 "),Iz=n(lje,"A",{href:!0});var cxt=s(Iz);VGo=r(cxt,"CamembertForCausalLM"),cxt.forEach(t),XGo=r(lje," (CamemBERT model)"),lje.forEach(t),zGo=i(W),_1=n(W,"LI",{});var ije=s(_1);Qbe=n(ije,"STRONG",{});var mxt=s(Qbe);QGo=r(mxt,"codegen"),mxt.forEach(t),WGo=r(ije," \u2014 "),Nz=n(ije,"A",{href:!0});var fxt=s(Nz);UGo=r(fxt,"CodeGenForCausalLM"),fxt.forEach(t),HGo=r(ije," (CodeGen model)"),ije.forEach(t),JGo=i(W),b1=n(W,"LI",{});var dje=s(b1);Wbe=n(dje,"STRONG",{});var gxt=s(Wbe);YGo=r(gxt,"ctrl"),gxt.forEach(t),KGo=r(dje," \u2014 "),qz=n(dje,"A",{href:!0});var hxt=s(qz);ZGo=r(hxt,"CTRLLMHeadModel"),hxt.forEach(t),eOo=r(dje," (CTRL model)"),dje.forEach(t),oOo=i(W),v1=n(W,"LI",{});var cje=s(v1);Ube=n(cje,"STRONG",{});var uxt=s(Ube);rOo=r(uxt,"data2vec-text"),uxt.forEach(t),tOo=r(cje," \u2014 "),jz=n(cje,"A",{href:!0});var pxt=s(jz);aOo=r(pxt,"Data2VecTextForCausalLM"),pxt.forEach(t),nOo=r(cje," (Data2VecText model)"),cje.forEach(t),sOo=i(W),F1=n(W,"LI",{});var mje=s(F1);Hbe=n(mje,"STRONG",{});var _xt=s(Hbe);lOo=r(_xt,"electra"),_xt.forEach(t),iOo=r(mje," \u2014 "),Dz=n(mje,"A",{href:!0});var bxt=s(Dz);dOo=r(bxt,"ElectraForCausalLM"),bxt.forEach(t),cOo=r(mje," (ELECTRA model)"),mje.forEach(t),mOo=i(W),T1=n(W,"LI",{});var fje=s(T1);Jbe=n(fje,"STRONG",{});var vxt=s(Jbe);fOo=r(vxt,"ernie"),vxt.forEach(t),gOo=r(fje," \u2014 "),Gz=n(fje,"A",{href:!0});var Fxt=s(Gz);hOo=r(Fxt,"ErnieForCausalLM"),Fxt.forEach(t),uOo=r(fje," (ERNIE model)"),fje.forEach(t),pOo=i(W),M1=n(W,"LI",{});var gje=s(M1);Ybe=n(gje,"STRONG",{});var Txt=s(Ybe);_Oo=r(Txt,"gpt2"),Txt.forEach(t),bOo=r(gje," \u2014 "),Oz=n(gje,"A",{href:!0});var Mxt=s(Oz);vOo=r(Mxt,"GPT2LMHeadModel"),Mxt.forEach(t),FOo=r(gje," (OpenAI GPT-2 model)"),gje.forEach(t),TOo=i(W),E1=n(W,"LI",{});var hje=s(E1);Kbe=n(hje,"STRONG",{});var Ext=s(Kbe);MOo=r(Ext,"gpt_neo"),Ext.forEach(t),EOo=r(hje," \u2014 "),Vz=n(hje,"A",{href:!0});var Cxt=s(Vz);COo=r(Cxt,"GPTNeoForCausalLM"),Cxt.forEach(t),wOo=r(hje," (GPT Neo model)"),hje.forEach(t),AOo=i(W),C1=n(W,"LI",{});var uje=s(C1);Zbe=n(uje,"STRONG",{});var wxt=s(Zbe);LOo=r(wxt,"gpt_neox"),wxt.forEach(t),yOo=r(uje," \u2014 "),Xz=n(uje,"A",{href:!0});var Axt=s(Xz);xOo=r(Axt,"GPTNeoXForCausalLM"),Axt.forEach(t),$Oo=r(uje," (GPT NeoX model)"),uje.forEach(t),kOo=i(W),w1=n(W,"LI",{});var pje=s(w1);e2e=n(pje,"STRONG",{});var Lxt=s(e2e);SOo=r(Lxt,"gptj"),Lxt.forEach(t),ROo=r(pje," \u2014 "),zz=n(pje,"A",{href:!0});var yxt=s(zz);POo=r(yxt,"GPTJForCausalLM"),yxt.forEach(t),BOo=r(pje," (GPT-J model)"),pje.forEach(t),IOo=i(W),A1=n(W,"LI",{});var _je=s(A1);o2e=n(_je,"STRONG",{});var xxt=s(o2e);NOo=r(xxt,"marian"),xxt.forEach(t),qOo=r(_je," \u2014 "),Qz=n(_je,"A",{href:!0});var $xt=s(Qz);jOo=r($xt,"MarianForCausalLM"),$xt.forEach(t),DOo=r(_je," (Marian model)"),_je.forEach(t),GOo=i(W),L1=n(W,"LI",{});var bje=s(L1);r2e=n(bje,"STRONG",{});var kxt=s(r2e);OOo=r(kxt,"mbart"),kxt.forEach(t),VOo=r(bje," \u2014 "),Wz=n(bje,"A",{href:!0});var Sxt=s(Wz);XOo=r(Sxt,"MBartForCausalLM"),Sxt.forEach(t),zOo=r(bje," (mBART model)"),bje.forEach(t),QOo=i(W),y1=n(W,"LI",{});var vje=s(y1);t2e=n(vje,"STRONG",{});var Rxt=s(t2e);WOo=r(Rxt,"megatron-bert"),Rxt.forEach(t),UOo=r(vje," \u2014 "),Uz=n(vje,"A",{href:!0});var Pxt=s(Uz);HOo=r(Pxt,"MegatronBertForCausalLM"),Pxt.forEach(t),JOo=r(vje," (Megatron-BERT model)"),vje.forEach(t),YOo=i(W),x1=n(W,"LI",{});var Fje=s(x1);a2e=n(Fje,"STRONG",{});var Bxt=s(a2e);KOo=r(Bxt,"mvp"),Bxt.forEach(t),ZOo=r(Fje," \u2014 "),Hz=n(Fje,"A",{href:!0});var Ixt=s(Hz);eVo=r(Ixt,"MvpForCausalLM"),Ixt.forEach(t),oVo=r(Fje," (MVP model)"),Fje.forEach(t),rVo=i(W),$1=n(W,"LI",{});var Tje=s($1);n2e=n(Tje,"STRONG",{});var Nxt=s(n2e);tVo=r(Nxt,"openai-gpt"),Nxt.forEach(t),aVo=r(Tje," \u2014 "),Jz=n(Tje,"A",{href:!0});var qxt=s(Jz);nVo=r(qxt,"OpenAIGPTLMHeadModel"),qxt.forEach(t),sVo=r(Tje," (OpenAI GPT model)"),Tje.forEach(t),lVo=i(W),k1=n(W,"LI",{});var Mje=s(k1);s2e=n(Mje,"STRONG",{});var jxt=s(s2e);iVo=r(jxt,"opt"),jxt.forEach(t),dVo=r(Mje," \u2014 "),Yz=n(Mje,"A",{href:!0});var Dxt=s(Yz);cVo=r(Dxt,"OPTForCausalLM"),Dxt.forEach(t),mVo=r(Mje," (OPT model)"),Mje.forEach(t),fVo=i(W),S1=n(W,"LI",{});var Eje=s(S1);l2e=n(Eje,"STRONG",{});var Gxt=s(l2e);gVo=r(Gxt,"pegasus"),Gxt.forEach(t),hVo=r(Eje," \u2014 "),Kz=n(Eje,"A",{href:!0});var Oxt=s(Kz);uVo=r(Oxt,"PegasusForCausalLM"),Oxt.forEach(t),pVo=r(Eje," (Pegasus model)"),Eje.forEach(t),_Vo=i(W),R1=n(W,"LI",{});var Cje=s(R1);i2e=n(Cje,"STRONG",{});var Vxt=s(i2e);bVo=r(Vxt,"plbart"),Vxt.forEach(t),vVo=r(Cje," \u2014 "),Zz=n(Cje,"A",{href:!0});var Xxt=s(Zz);FVo=r(Xxt,"PLBartForCausalLM"),Xxt.forEach(t),TVo=r(Cje," (PLBart model)"),Cje.forEach(t),MVo=i(W),P1=n(W,"LI",{});var wje=s(P1);d2e=n(wje,"STRONG",{});var zxt=s(d2e);EVo=r(zxt,"prophetnet"),zxt.forEach(t),CVo=r(wje," \u2014 "),eQ=n(wje,"A",{href:!0});var Qxt=s(eQ);wVo=r(Qxt,"ProphetNetForCausalLM"),Qxt.forEach(t),AVo=r(wje," (ProphetNet model)"),wje.forEach(t),LVo=i(W),B1=n(W,"LI",{});var Aje=s(B1);c2e=n(Aje,"STRONG",{});var Wxt=s(c2e);yVo=r(Wxt,"qdqbert"),Wxt.forEach(t),xVo=r(Aje," \u2014 "),oQ=n(Aje,"A",{href:!0});var Uxt=s(oQ);$Vo=r(Uxt,"QDQBertLMHeadModel"),Uxt.forEach(t),kVo=r(Aje," (QDQBert model)"),Aje.forEach(t),SVo=i(W),I1=n(W,"LI",{});var Lje=s(I1);m2e=n(Lje,"STRONG",{});var Hxt=s(m2e);RVo=r(Hxt,"reformer"),Hxt.forEach(t),PVo=r(Lje," \u2014 "),rQ=n(Lje,"A",{href:!0});var Jxt=s(rQ);BVo=r(Jxt,"ReformerModelWithLMHead"),Jxt.forEach(t),IVo=r(Lje," (Reformer model)"),Lje.forEach(t),NVo=i(W),N1=n(W,"LI",{});var yje=s(N1);f2e=n(yje,"STRONG",{});var Yxt=s(f2e);qVo=r(Yxt,"rembert"),Yxt.forEach(t),jVo=r(yje," \u2014 "),tQ=n(yje,"A",{href:!0});var Kxt=s(tQ);DVo=r(Kxt,"RemBertForCausalLM"),Kxt.forEach(t),GVo=r(yje," (RemBERT model)"),yje.forEach(t),OVo=i(W),q1=n(W,"LI",{});var xje=s(q1);g2e=n(xje,"STRONG",{});var Zxt=s(g2e);VVo=r(Zxt,"roberta"),Zxt.forEach(t),XVo=r(xje," \u2014 "),aQ=n(xje,"A",{href:!0});var e$t=s(aQ);zVo=r(e$t,"RobertaForCausalLM"),e$t.forEach(t),QVo=r(xje," (RoBERTa model)"),xje.forEach(t),WVo=i(W),j1=n(W,"LI",{});var $je=s(j1);h2e=n($je,"STRONG",{});var o$t=s(h2e);UVo=r(o$t,"roformer"),o$t.forEach(t),HVo=r($je," \u2014 "),nQ=n($je,"A",{href:!0});var r$t=s(nQ);JVo=r(r$t,"RoFormerForCausalLM"),r$t.forEach(t),YVo=r($je," (RoFormer model)"),$je.forEach(t),KVo=i(W),D1=n(W,"LI",{});var kje=s(D1);u2e=n(kje,"STRONG",{});var t$t=s(u2e);ZVo=r(t$t,"speech_to_text_2"),t$t.forEach(t),eXo=r(kje," \u2014 "),sQ=n(kje,"A",{href:!0});var a$t=s(sQ);oXo=r(a$t,"Speech2Text2ForCausalLM"),a$t.forEach(t),rXo=r(kje," (Speech2Text2 model)"),kje.forEach(t),tXo=i(W),G1=n(W,"LI",{});var Sje=s(G1);p2e=n(Sje,"STRONG",{});var n$t=s(p2e);aXo=r(n$t,"transfo-xl"),n$t.forEach(t),nXo=r(Sje," \u2014 "),lQ=n(Sje,"A",{href:!0});var s$t=s(lQ);sXo=r(s$t,"TransfoXLLMHeadModel"),s$t.forEach(t),lXo=r(Sje," (Transformer-XL model)"),Sje.forEach(t),iXo=i(W),O1=n(W,"LI",{});var Rje=s(O1);_2e=n(Rje,"STRONG",{});var l$t=s(_2e);dXo=r(l$t,"trocr"),l$t.forEach(t),cXo=r(Rje," \u2014 "),iQ=n(Rje,"A",{href:!0});var i$t=s(iQ);mXo=r(i$t,"TrOCRForCausalLM"),i$t.forEach(t),fXo=r(Rje," (TrOCR model)"),Rje.forEach(t),gXo=i(W),V1=n(W,"LI",{});var Pje=s(V1);b2e=n(Pje,"STRONG",{});var d$t=s(b2e);hXo=r(d$t,"xglm"),d$t.forEach(t),uXo=r(Pje," \u2014 "),dQ=n(Pje,"A",{href:!0});var c$t=s(dQ);pXo=r(c$t,"XGLMForCausalLM"),c$t.forEach(t),_Xo=r(Pje," (XGLM model)"),Pje.forEach(t),bXo=i(W),X1=n(W,"LI",{});var Bje=s(X1);v2e=n(Bje,"STRONG",{});var m$t=s(v2e);vXo=r(m$t,"xlm"),m$t.forEach(t),FXo=r(Bje," \u2014 "),cQ=n(Bje,"A",{href:!0});var f$t=s(cQ);TXo=r(f$t,"XLMWithLMHeadModel"),f$t.forEach(t),MXo=r(Bje," (XLM model)"),Bje.forEach(t),EXo=i(W),z1=n(W,"LI",{});var Ije=s(z1);F2e=n(Ije,"STRONG",{});var g$t=s(F2e);CXo=r(g$t,"xlm-prophetnet"),g$t.forEach(t),wXo=r(Ije," \u2014 "),mQ=n(Ije,"A",{href:!0});var h$t=s(mQ);AXo=r(h$t,"XLMProphetNetForCausalLM"),h$t.forEach(t),LXo=r(Ije," (XLM-ProphetNet model)"),Ije.forEach(t),yXo=i(W),Q1=n(W,"LI",{});var Nje=s(Q1);T2e=n(Nje,"STRONG",{});var u$t=s(T2e);xXo=r(u$t,"xlm-roberta"),u$t.forEach(t),$Xo=r(Nje," \u2014 "),fQ=n(Nje,"A",{href:!0});var p$t=s(fQ);kXo=r(p$t,"XLMRobertaForCausalLM"),p$t.forEach(t),SXo=r(Nje," (XLM-RoBERTa model)"),Nje.forEach(t),RXo=i(W),W1=n(W,"LI",{});var qje=s(W1);M2e=n(qje,"STRONG",{});var _$t=s(M2e);PXo=r(_$t,"xlm-roberta-xl"),_$t.forEach(t),BXo=r(qje," \u2014 "),gQ=n(qje,"A",{href:!0});var b$t=s(gQ);IXo=r(b$t,"XLMRobertaXLForCausalLM"),b$t.forEach(t),NXo=r(qje," (XLM-RoBERTa-XL model)"),qje.forEach(t),qXo=i(W),U1=n(W,"LI",{});var jje=s(U1);E2e=n(jje,"STRONG",{});var v$t=s(E2e);jXo=r(v$t,"xlnet"),v$t.forEach(t),DXo=r(jje," \u2014 "),hQ=n(jje,"A",{href:!0});var F$t=s(hQ);GXo=r(F$t,"XLNetLMHeadModel"),F$t.forEach(t),OXo=r(jje," (XLNet model)"),jje.forEach(t),W.forEach(t),VXo=i(Ma),H1=n(Ma,"P",{});var Dje=s(H1);XXo=r(Dje,"The model is set in evaluation mode by default using "),C2e=n(Dje,"CODE",{});var T$t=s(C2e);zXo=r(T$t,"model.eval()"),T$t.forEach(t),QXo=r(Dje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w2e=n(Dje,"CODE",{});var M$t=s(w2e);WXo=r(M$t,"model.train()"),M$t.forEach(t),Dje.forEach(t),UXo=i(Ma),T(J1.$$.fragment,Ma),Ma.forEach(t),Ll.forEach(t),gKe=i(m),wd=n(m,"H2",{class:!0});var Leo=s(wd);Y1=n(Leo,"A",{id:!0,class:!0,href:!0});var E$t=s(Y1);A2e=n(E$t,"SPAN",{});var C$t=s(A2e);T(ux.$$.fragment,C$t),C$t.forEach(t),E$t.forEach(t),HXo=i(Leo),L2e=n(Leo,"SPAN",{});var w$t=s(L2e);JXo=r(w$t,"AutoModelForMaskedLM"),w$t.forEach(t),Leo.forEach(t),hKe=i(m),No=n(m,"DIV",{class:!0});var yl=s(No);T(px.$$.fragment,yl),YXo=i(yl),Ad=n(yl,"P",{});var lle=s(Ad);KXo=r(lle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),uQ=n(lle,"A",{href:!0});var A$t=s(uQ);ZXo=r(A$t,"from_pretrained()"),A$t.forEach(t),ezo=r(lle," class method or the "),pQ=n(lle,"A",{href:!0});var L$t=s(pQ);ozo=r(L$t,"from_config()"),L$t.forEach(t),rzo=r(lle,` class
method.`),lle.forEach(t),tzo=i(yl),_x=n(yl,"P",{});var yeo=s(_x);azo=r(yeo,"This class cannot be instantiated directly using "),y2e=n(yeo,"CODE",{});var y$t=s(y2e);nzo=r(y$t,"__init__()"),y$t.forEach(t),szo=r(yeo," (throws an error)."),yeo.forEach(t),lzo=i(yl),Ft=n(yl,"DIV",{class:!0});var xy=s(Ft);T(bx.$$.fragment,xy),izo=i(xy),x2e=n(xy,"P",{});var x$t=s(x2e);dzo=r(x$t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),x$t.forEach(t),czo=i(xy),Ld=n(xy,"P",{});var ile=s(Ld);mzo=r(ile,`Note:
Loading a model from its configuration file does `),$2e=n(ile,"STRONG",{});var $$t=s($2e);fzo=r($$t,"not"),$$t.forEach(t),gzo=r(ile,` load the model weights. It only affects the
model\u2019s configuration. Use `),_Q=n(ile,"A",{href:!0});var k$t=s(_Q);hzo=r(k$t,"from_pretrained()"),k$t.forEach(t),uzo=r(ile," to load the model weights."),ile.forEach(t),pzo=i(xy),T(K1.$$.fragment,xy),xy.forEach(t),_zo=i(yl),ro=n(yl,"DIV",{class:!0});var Ea=s(ro);T(vx.$$.fragment,Ea),bzo=i(Ea),k2e=n(Ea,"P",{});var S$t=s(k2e);vzo=r(S$t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),S$t.forEach(t),Fzo=i(Ea),Za=n(Ea,"P",{});var $y=s(Za);Tzo=r($y,"The model class to instantiate is selected based on the "),S2e=n($y,"CODE",{});var R$t=s(S2e);Mzo=r(R$t,"model_type"),R$t.forEach(t),Ezo=r($y,` property of the config object (either
passed as an argument or loaded from `),R2e=n($y,"CODE",{});var P$t=s(R2e);Czo=r(P$t,"pretrained_model_name_or_path"),P$t.forEach(t),wzo=r($y,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P2e=n($y,"CODE",{});var B$t=s(P2e);Azo=r(B$t,"pretrained_model_name_or_path"),B$t.forEach(t),Lzo=r($y,":"),$y.forEach(t),yzo=i(Ea),U=n(Ea,"UL",{});var Y=s(U);Z1=n(Y,"LI",{});var Gje=s(Z1);B2e=n(Gje,"STRONG",{});var I$t=s(B2e);xzo=r(I$t,"albert"),I$t.forEach(t),$zo=r(Gje," \u2014 "),bQ=n(Gje,"A",{href:!0});var N$t=s(bQ);kzo=r(N$t,"AlbertForMaskedLM"),N$t.forEach(t),Szo=r(Gje," (ALBERT model)"),Gje.forEach(t),Rzo=i(Y),ev=n(Y,"LI",{});var Oje=s(ev);I2e=n(Oje,"STRONG",{});var q$t=s(I2e);Pzo=r(q$t,"bart"),q$t.forEach(t),Bzo=r(Oje," \u2014 "),vQ=n(Oje,"A",{href:!0});var j$t=s(vQ);Izo=r(j$t,"BartForConditionalGeneration"),j$t.forEach(t),Nzo=r(Oje," (BART model)"),Oje.forEach(t),qzo=i(Y),ov=n(Y,"LI",{});var Vje=s(ov);N2e=n(Vje,"STRONG",{});var D$t=s(N2e);jzo=r(D$t,"bert"),D$t.forEach(t),Dzo=r(Vje," \u2014 "),FQ=n(Vje,"A",{href:!0});var G$t=s(FQ);Gzo=r(G$t,"BertForMaskedLM"),G$t.forEach(t),Ozo=r(Vje," (BERT model)"),Vje.forEach(t),Vzo=i(Y),rv=n(Y,"LI",{});var Xje=s(rv);q2e=n(Xje,"STRONG",{});var O$t=s(q2e);Xzo=r(O$t,"big_bird"),O$t.forEach(t),zzo=r(Xje," \u2014 "),TQ=n(Xje,"A",{href:!0});var V$t=s(TQ);Qzo=r(V$t,"BigBirdForMaskedLM"),V$t.forEach(t),Wzo=r(Xje," (BigBird model)"),Xje.forEach(t),Uzo=i(Y),tv=n(Y,"LI",{});var zje=s(tv);j2e=n(zje,"STRONG",{});var X$t=s(j2e);Hzo=r(X$t,"camembert"),X$t.forEach(t),Jzo=r(zje," \u2014 "),MQ=n(zje,"A",{href:!0});var z$t=s(MQ);Yzo=r(z$t,"CamembertForMaskedLM"),z$t.forEach(t),Kzo=r(zje," (CamemBERT model)"),zje.forEach(t),Zzo=i(Y),av=n(Y,"LI",{});var Qje=s(av);D2e=n(Qje,"STRONG",{});var Q$t=s(D2e);eQo=r(Q$t,"convbert"),Q$t.forEach(t),oQo=r(Qje," \u2014 "),EQ=n(Qje,"A",{href:!0});var W$t=s(EQ);rQo=r(W$t,"ConvBertForMaskedLM"),W$t.forEach(t),tQo=r(Qje," (ConvBERT model)"),Qje.forEach(t),aQo=i(Y),nv=n(Y,"LI",{});var Wje=s(nv);G2e=n(Wje,"STRONG",{});var U$t=s(G2e);nQo=r(U$t,"data2vec-text"),U$t.forEach(t),sQo=r(Wje," \u2014 "),CQ=n(Wje,"A",{href:!0});var H$t=s(CQ);lQo=r(H$t,"Data2VecTextForMaskedLM"),H$t.forEach(t),iQo=r(Wje," (Data2VecText model)"),Wje.forEach(t),dQo=i(Y),sv=n(Y,"LI",{});var Uje=s(sv);O2e=n(Uje,"STRONG",{});var J$t=s(O2e);cQo=r(J$t,"deberta"),J$t.forEach(t),mQo=r(Uje," \u2014 "),wQ=n(Uje,"A",{href:!0});var Y$t=s(wQ);fQo=r(Y$t,"DebertaForMaskedLM"),Y$t.forEach(t),gQo=r(Uje," (DeBERTa model)"),Uje.forEach(t),hQo=i(Y),lv=n(Y,"LI",{});var Hje=s(lv);V2e=n(Hje,"STRONG",{});var K$t=s(V2e);uQo=r(K$t,"deberta-v2"),K$t.forEach(t),pQo=r(Hje," \u2014 "),AQ=n(Hje,"A",{href:!0});var Z$t=s(AQ);_Qo=r(Z$t,"DebertaV2ForMaskedLM"),Z$t.forEach(t),bQo=r(Hje," (DeBERTa-v2 model)"),Hje.forEach(t),vQo=i(Y),iv=n(Y,"LI",{});var Jje=s(iv);X2e=n(Jje,"STRONG",{});var ekt=s(X2e);FQo=r(ekt,"distilbert"),ekt.forEach(t),TQo=r(Jje," \u2014 "),LQ=n(Jje,"A",{href:!0});var okt=s(LQ);MQo=r(okt,"DistilBertForMaskedLM"),okt.forEach(t),EQo=r(Jje," (DistilBERT model)"),Jje.forEach(t),CQo=i(Y),dv=n(Y,"LI",{});var Yje=s(dv);z2e=n(Yje,"STRONG",{});var rkt=s(z2e);wQo=r(rkt,"electra"),rkt.forEach(t),AQo=r(Yje," \u2014 "),yQ=n(Yje,"A",{href:!0});var tkt=s(yQ);LQo=r(tkt,"ElectraForMaskedLM"),tkt.forEach(t),yQo=r(Yje," (ELECTRA model)"),Yje.forEach(t),xQo=i(Y),cv=n(Y,"LI",{});var Kje=s(cv);Q2e=n(Kje,"STRONG",{});var akt=s(Q2e);$Qo=r(akt,"ernie"),akt.forEach(t),kQo=r(Kje," \u2014 "),xQ=n(Kje,"A",{href:!0});var nkt=s(xQ);SQo=r(nkt,"ErnieForMaskedLM"),nkt.forEach(t),RQo=r(Kje," (ERNIE model)"),Kje.forEach(t),PQo=i(Y),mv=n(Y,"LI",{});var Zje=s(mv);W2e=n(Zje,"STRONG",{});var skt=s(W2e);BQo=r(skt,"flaubert"),skt.forEach(t),IQo=r(Zje," \u2014 "),$Q=n(Zje,"A",{href:!0});var lkt=s($Q);NQo=r(lkt,"FlaubertWithLMHeadModel"),lkt.forEach(t),qQo=r(Zje," (FlauBERT model)"),Zje.forEach(t),jQo=i(Y),fv=n(Y,"LI",{});var eDe=s(fv);U2e=n(eDe,"STRONG",{});var ikt=s(U2e);DQo=r(ikt,"fnet"),ikt.forEach(t),GQo=r(eDe," \u2014 "),kQ=n(eDe,"A",{href:!0});var dkt=s(kQ);OQo=r(dkt,"FNetForMaskedLM"),dkt.forEach(t),VQo=r(eDe," (FNet model)"),eDe.forEach(t),XQo=i(Y),gv=n(Y,"LI",{});var oDe=s(gv);H2e=n(oDe,"STRONG",{});var ckt=s(H2e);zQo=r(ckt,"funnel"),ckt.forEach(t),QQo=r(oDe," \u2014 "),SQ=n(oDe,"A",{href:!0});var mkt=s(SQ);WQo=r(mkt,"FunnelForMaskedLM"),mkt.forEach(t),UQo=r(oDe," (Funnel Transformer model)"),oDe.forEach(t),HQo=i(Y),hv=n(Y,"LI",{});var rDe=s(hv);J2e=n(rDe,"STRONG",{});var fkt=s(J2e);JQo=r(fkt,"ibert"),fkt.forEach(t),YQo=r(rDe," \u2014 "),RQ=n(rDe,"A",{href:!0});var gkt=s(RQ);KQo=r(gkt,"IBertForMaskedLM"),gkt.forEach(t),ZQo=r(rDe," (I-BERT model)"),rDe.forEach(t),eWo=i(Y),uv=n(Y,"LI",{});var tDe=s(uv);Y2e=n(tDe,"STRONG",{});var hkt=s(Y2e);oWo=r(hkt,"layoutlm"),hkt.forEach(t),rWo=r(tDe," \u2014 "),PQ=n(tDe,"A",{href:!0});var ukt=s(PQ);tWo=r(ukt,"LayoutLMForMaskedLM"),ukt.forEach(t),aWo=r(tDe," (LayoutLM model)"),tDe.forEach(t),nWo=i(Y),pv=n(Y,"LI",{});var aDe=s(pv);K2e=n(aDe,"STRONG",{});var pkt=s(K2e);sWo=r(pkt,"longformer"),pkt.forEach(t),lWo=r(aDe," \u2014 "),BQ=n(aDe,"A",{href:!0});var _kt=s(BQ);iWo=r(_kt,"LongformerForMaskedLM"),_kt.forEach(t),dWo=r(aDe," (Longformer model)"),aDe.forEach(t),cWo=i(Y),_v=n(Y,"LI",{});var nDe=s(_v);Z2e=n(nDe,"STRONG",{});var bkt=s(Z2e);mWo=r(bkt,"luke"),bkt.forEach(t),fWo=r(nDe," \u2014 "),IQ=n(nDe,"A",{href:!0});var vkt=s(IQ);gWo=r(vkt,"LukeForMaskedLM"),vkt.forEach(t),hWo=r(nDe," (LUKE model)"),nDe.forEach(t),uWo=i(Y),bv=n(Y,"LI",{});var sDe=s(bv);e1e=n(sDe,"STRONG",{});var Fkt=s(e1e);pWo=r(Fkt,"mbart"),Fkt.forEach(t),_Wo=r(sDe," \u2014 "),NQ=n(sDe,"A",{href:!0});var Tkt=s(NQ);bWo=r(Tkt,"MBartForConditionalGeneration"),Tkt.forEach(t),vWo=r(sDe," (mBART model)"),sDe.forEach(t),FWo=i(Y),vv=n(Y,"LI",{});var lDe=s(vv);o1e=n(lDe,"STRONG",{});var Mkt=s(o1e);TWo=r(Mkt,"megatron-bert"),Mkt.forEach(t),MWo=r(lDe," \u2014 "),qQ=n(lDe,"A",{href:!0});var Ekt=s(qQ);EWo=r(Ekt,"MegatronBertForMaskedLM"),Ekt.forEach(t),CWo=r(lDe," (Megatron-BERT model)"),lDe.forEach(t),wWo=i(Y),Fv=n(Y,"LI",{});var iDe=s(Fv);r1e=n(iDe,"STRONG",{});var Ckt=s(r1e);AWo=r(Ckt,"mobilebert"),Ckt.forEach(t),LWo=r(iDe," \u2014 "),jQ=n(iDe,"A",{href:!0});var wkt=s(jQ);yWo=r(wkt,"MobileBertForMaskedLM"),wkt.forEach(t),xWo=r(iDe," (MobileBERT model)"),iDe.forEach(t),$Wo=i(Y),Tv=n(Y,"LI",{});var dDe=s(Tv);t1e=n(dDe,"STRONG",{});var Akt=s(t1e);kWo=r(Akt,"mpnet"),Akt.forEach(t),SWo=r(dDe," \u2014 "),DQ=n(dDe,"A",{href:!0});var Lkt=s(DQ);RWo=r(Lkt,"MPNetForMaskedLM"),Lkt.forEach(t),PWo=r(dDe," (MPNet model)"),dDe.forEach(t),BWo=i(Y),Mv=n(Y,"LI",{});var cDe=s(Mv);a1e=n(cDe,"STRONG",{});var ykt=s(a1e);IWo=r(ykt,"mvp"),ykt.forEach(t),NWo=r(cDe," \u2014 "),GQ=n(cDe,"A",{href:!0});var xkt=s(GQ);qWo=r(xkt,"MvpForConditionalGeneration"),xkt.forEach(t),jWo=r(cDe," (MVP model)"),cDe.forEach(t),DWo=i(Y),Ev=n(Y,"LI",{});var mDe=s(Ev);n1e=n(mDe,"STRONG",{});var $kt=s(n1e);GWo=r($kt,"nezha"),$kt.forEach(t),OWo=r(mDe," \u2014 "),OQ=n(mDe,"A",{href:!0});var kkt=s(OQ);VWo=r(kkt,"NezhaForMaskedLM"),kkt.forEach(t),XWo=r(mDe," (Nezha model)"),mDe.forEach(t),zWo=i(Y),Cv=n(Y,"LI",{});var fDe=s(Cv);s1e=n(fDe,"STRONG",{});var Skt=s(s1e);QWo=r(Skt,"nystromformer"),Skt.forEach(t),WWo=r(fDe," \u2014 "),VQ=n(fDe,"A",{href:!0});var Rkt=s(VQ);UWo=r(Rkt,"NystromformerForMaskedLM"),Rkt.forEach(t),HWo=r(fDe," (Nystr\xF6mformer model)"),fDe.forEach(t),JWo=i(Y),wv=n(Y,"LI",{});var gDe=s(wv);l1e=n(gDe,"STRONG",{});var Pkt=s(l1e);YWo=r(Pkt,"perceiver"),Pkt.forEach(t),KWo=r(gDe," \u2014 "),XQ=n(gDe,"A",{href:!0});var Bkt=s(XQ);ZWo=r(Bkt,"PerceiverForMaskedLM"),Bkt.forEach(t),eUo=r(gDe," (Perceiver model)"),gDe.forEach(t),oUo=i(Y),Av=n(Y,"LI",{});var hDe=s(Av);i1e=n(hDe,"STRONG",{});var Ikt=s(i1e);rUo=r(Ikt,"qdqbert"),Ikt.forEach(t),tUo=r(hDe," \u2014 "),zQ=n(hDe,"A",{href:!0});var Nkt=s(zQ);aUo=r(Nkt,"QDQBertForMaskedLM"),Nkt.forEach(t),nUo=r(hDe," (QDQBert model)"),hDe.forEach(t),sUo=i(Y),Lv=n(Y,"LI",{});var uDe=s(Lv);d1e=n(uDe,"STRONG",{});var qkt=s(d1e);lUo=r(qkt,"reformer"),qkt.forEach(t),iUo=r(uDe," \u2014 "),QQ=n(uDe,"A",{href:!0});var jkt=s(QQ);dUo=r(jkt,"ReformerForMaskedLM"),jkt.forEach(t),cUo=r(uDe," (Reformer model)"),uDe.forEach(t),mUo=i(Y),yv=n(Y,"LI",{});var pDe=s(yv);c1e=n(pDe,"STRONG",{});var Dkt=s(c1e);fUo=r(Dkt,"rembert"),Dkt.forEach(t),gUo=r(pDe," \u2014 "),WQ=n(pDe,"A",{href:!0});var Gkt=s(WQ);hUo=r(Gkt,"RemBertForMaskedLM"),Gkt.forEach(t),uUo=r(pDe," (RemBERT model)"),pDe.forEach(t),pUo=i(Y),xv=n(Y,"LI",{});var _De=s(xv);m1e=n(_De,"STRONG",{});var Okt=s(m1e);_Uo=r(Okt,"roberta"),Okt.forEach(t),bUo=r(_De," \u2014 "),UQ=n(_De,"A",{href:!0});var Vkt=s(UQ);vUo=r(Vkt,"RobertaForMaskedLM"),Vkt.forEach(t),FUo=r(_De," (RoBERTa model)"),_De.forEach(t),TUo=i(Y),$v=n(Y,"LI",{});var bDe=s($v);f1e=n(bDe,"STRONG",{});var Xkt=s(f1e);MUo=r(Xkt,"roformer"),Xkt.forEach(t),EUo=r(bDe," \u2014 "),HQ=n(bDe,"A",{href:!0});var zkt=s(HQ);CUo=r(zkt,"RoFormerForMaskedLM"),zkt.forEach(t),wUo=r(bDe," (RoFormer model)"),bDe.forEach(t),AUo=i(Y),kv=n(Y,"LI",{});var vDe=s(kv);g1e=n(vDe,"STRONG",{});var Qkt=s(g1e);LUo=r(Qkt,"squeezebert"),Qkt.forEach(t),yUo=r(vDe," \u2014 "),JQ=n(vDe,"A",{href:!0});var Wkt=s(JQ);xUo=r(Wkt,"SqueezeBertForMaskedLM"),Wkt.forEach(t),$Uo=r(vDe," (SqueezeBERT model)"),vDe.forEach(t),kUo=i(Y),Sv=n(Y,"LI",{});var FDe=s(Sv);h1e=n(FDe,"STRONG",{});var Ukt=s(h1e);SUo=r(Ukt,"tapas"),Ukt.forEach(t),RUo=r(FDe," \u2014 "),YQ=n(FDe,"A",{href:!0});var Hkt=s(YQ);PUo=r(Hkt,"TapasForMaskedLM"),Hkt.forEach(t),BUo=r(FDe," (TAPAS model)"),FDe.forEach(t),IUo=i(Y),Rv=n(Y,"LI",{});var TDe=s(Rv);u1e=n(TDe,"STRONG",{});var Jkt=s(u1e);NUo=r(Jkt,"wav2vec2"),Jkt.forEach(t),qUo=r(TDe," \u2014 "),p1e=n(TDe,"CODE",{});var Ykt=s(p1e);jUo=r(Ykt,"Wav2Vec2ForMaskedLM"),Ykt.forEach(t),DUo=r(TDe," (Wav2Vec2 model)"),TDe.forEach(t),GUo=i(Y),Pv=n(Y,"LI",{});var MDe=s(Pv);_1e=n(MDe,"STRONG",{});var Kkt=s(_1e);OUo=r(Kkt,"xlm"),Kkt.forEach(t),VUo=r(MDe," \u2014 "),KQ=n(MDe,"A",{href:!0});var Zkt=s(KQ);XUo=r(Zkt,"XLMWithLMHeadModel"),Zkt.forEach(t),zUo=r(MDe," (XLM model)"),MDe.forEach(t),QUo=i(Y),Bv=n(Y,"LI",{});var EDe=s(Bv);b1e=n(EDe,"STRONG",{});var eSt=s(b1e);WUo=r(eSt,"xlm-roberta"),eSt.forEach(t),UUo=r(EDe," \u2014 "),ZQ=n(EDe,"A",{href:!0});var oSt=s(ZQ);HUo=r(oSt,"XLMRobertaForMaskedLM"),oSt.forEach(t),JUo=r(EDe," (XLM-RoBERTa model)"),EDe.forEach(t),YUo=i(Y),Iv=n(Y,"LI",{});var CDe=s(Iv);v1e=n(CDe,"STRONG",{});var rSt=s(v1e);KUo=r(rSt,"xlm-roberta-xl"),rSt.forEach(t),ZUo=r(CDe," \u2014 "),eW=n(CDe,"A",{href:!0});var tSt=s(eW);eHo=r(tSt,"XLMRobertaXLForMaskedLM"),tSt.forEach(t),oHo=r(CDe," (XLM-RoBERTa-XL model)"),CDe.forEach(t),rHo=i(Y),Nv=n(Y,"LI",{});var wDe=s(Nv);F1e=n(wDe,"STRONG",{});var aSt=s(F1e);tHo=r(aSt,"yoso"),aSt.forEach(t),aHo=r(wDe," \u2014 "),oW=n(wDe,"A",{href:!0});var nSt=s(oW);nHo=r(nSt,"YosoForMaskedLM"),nSt.forEach(t),sHo=r(wDe," (YOSO model)"),wDe.forEach(t),Y.forEach(t),lHo=i(Ea),qv=n(Ea,"P",{});var ADe=s(qv);iHo=r(ADe,"The model is set in evaluation mode by default using "),T1e=n(ADe,"CODE",{});var sSt=s(T1e);dHo=r(sSt,"model.eval()"),sSt.forEach(t),cHo=r(ADe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),M1e=n(ADe,"CODE",{});var lSt=s(M1e);mHo=r(lSt,"model.train()"),lSt.forEach(t),ADe.forEach(t),fHo=i(Ea),T(jv.$$.fragment,Ea),Ea.forEach(t),yl.forEach(t),uKe=i(m),yd=n(m,"H2",{class:!0});var xeo=s(yd);Dv=n(xeo,"A",{id:!0,class:!0,href:!0});var iSt=s(Dv);E1e=n(iSt,"SPAN",{});var dSt=s(E1e);T(Fx.$$.fragment,dSt),dSt.forEach(t),iSt.forEach(t),gHo=i(xeo),C1e=n(xeo,"SPAN",{});var cSt=s(C1e);hHo=r(cSt,"AutoModelForSeq2SeqLM"),cSt.forEach(t),xeo.forEach(t),pKe=i(m),qo=n(m,"DIV",{class:!0});var xl=s(qo);T(Tx.$$.fragment,xl),uHo=i(xl),xd=n(xl,"P",{});var dle=s(xd);pHo=r(dle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),rW=n(dle,"A",{href:!0});var mSt=s(rW);_Ho=r(mSt,"from_pretrained()"),mSt.forEach(t),bHo=r(dle," class method or the "),tW=n(dle,"A",{href:!0});var fSt=s(tW);vHo=r(fSt,"from_config()"),fSt.forEach(t),FHo=r(dle,` class
method.`),dle.forEach(t),THo=i(xl),Mx=n(xl,"P",{});var $eo=s(Mx);MHo=r($eo,"This class cannot be instantiated directly using "),w1e=n($eo,"CODE",{});var gSt=s(w1e);EHo=r(gSt,"__init__()"),gSt.forEach(t),CHo=r($eo," (throws an error)."),$eo.forEach(t),wHo=i(xl),Tt=n(xl,"DIV",{class:!0});var ky=s(Tt);T(Ex.$$.fragment,ky),AHo=i(ky),A1e=n(ky,"P",{});var hSt=s(A1e);LHo=r(hSt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),hSt.forEach(t),yHo=i(ky),$d=n(ky,"P",{});var cle=s($d);xHo=r(cle,`Note:
Loading a model from its configuration file does `),L1e=n(cle,"STRONG",{});var uSt=s(L1e);$Ho=r(uSt,"not"),uSt.forEach(t),kHo=r(cle,` load the model weights. It only affects the
model\u2019s configuration. Use `),aW=n(cle,"A",{href:!0});var pSt=s(aW);SHo=r(pSt,"from_pretrained()"),pSt.forEach(t),RHo=r(cle," to load the model weights."),cle.forEach(t),PHo=i(ky),T(Gv.$$.fragment,ky),ky.forEach(t),BHo=i(xl),to=n(xl,"DIV",{class:!0});var Ca=s(to);T(Cx.$$.fragment,Ca),IHo=i(Ca),y1e=n(Ca,"P",{});var _St=s(y1e);NHo=r(_St,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),_St.forEach(t),qHo=i(Ca),en=n(Ca,"P",{});var Sy=s(en);jHo=r(Sy,"The model class to instantiate is selected based on the "),x1e=n(Sy,"CODE",{});var bSt=s(x1e);DHo=r(bSt,"model_type"),bSt.forEach(t),GHo=r(Sy,` property of the config object (either
passed as an argument or loaded from `),$1e=n(Sy,"CODE",{});var vSt=s($1e);OHo=r(vSt,"pretrained_model_name_or_path"),vSt.forEach(t),VHo=r(Sy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k1e=n(Sy,"CODE",{});var FSt=s(k1e);XHo=r(FSt,"pretrained_model_name_or_path"),FSt.forEach(t),zHo=r(Sy,":"),Sy.forEach(t),QHo=i(Ca),me=n(Ca,"UL",{});var pe=s(me);Ov=n(pe,"LI",{});var LDe=s(Ov);S1e=n(LDe,"STRONG",{});var TSt=s(S1e);WHo=r(TSt,"bart"),TSt.forEach(t),UHo=r(LDe," \u2014 "),nW=n(LDe,"A",{href:!0});var MSt=s(nW);HHo=r(MSt,"BartForConditionalGeneration"),MSt.forEach(t),JHo=r(LDe," (BART model)"),LDe.forEach(t),YHo=i(pe),Vv=n(pe,"LI",{});var yDe=s(Vv);R1e=n(yDe,"STRONG",{});var ESt=s(R1e);KHo=r(ESt,"bigbird_pegasus"),ESt.forEach(t),ZHo=r(yDe," \u2014 "),sW=n(yDe,"A",{href:!0});var CSt=s(sW);eJo=r(CSt,"BigBirdPegasusForConditionalGeneration"),CSt.forEach(t),oJo=r(yDe," (BigBird-Pegasus model)"),yDe.forEach(t),rJo=i(pe),Xv=n(pe,"LI",{});var xDe=s(Xv);P1e=n(xDe,"STRONG",{});var wSt=s(P1e);tJo=r(wSt,"blenderbot"),wSt.forEach(t),aJo=r(xDe," \u2014 "),lW=n(xDe,"A",{href:!0});var ASt=s(lW);nJo=r(ASt,"BlenderbotForConditionalGeneration"),ASt.forEach(t),sJo=r(xDe," (Blenderbot model)"),xDe.forEach(t),lJo=i(pe),zv=n(pe,"LI",{});var $De=s(zv);B1e=n($De,"STRONG",{});var LSt=s(B1e);iJo=r(LSt,"blenderbot-small"),LSt.forEach(t),dJo=r($De," \u2014 "),iW=n($De,"A",{href:!0});var ySt=s(iW);cJo=r(ySt,"BlenderbotSmallForConditionalGeneration"),ySt.forEach(t),mJo=r($De," (BlenderbotSmall model)"),$De.forEach(t),fJo=i(pe),Qv=n(pe,"LI",{});var kDe=s(Qv);I1e=n(kDe,"STRONG",{});var xSt=s(I1e);gJo=r(xSt,"encoder-decoder"),xSt.forEach(t),hJo=r(kDe," \u2014 "),dW=n(kDe,"A",{href:!0});var $St=s(dW);uJo=r($St,"EncoderDecoderModel"),$St.forEach(t),pJo=r(kDe," (Encoder decoder model)"),kDe.forEach(t),_Jo=i(pe),Wv=n(pe,"LI",{});var SDe=s(Wv);N1e=n(SDe,"STRONG",{});var kSt=s(N1e);bJo=r(kSt,"fsmt"),kSt.forEach(t),vJo=r(SDe," \u2014 "),cW=n(SDe,"A",{href:!0});var SSt=s(cW);FJo=r(SSt,"FSMTForConditionalGeneration"),SSt.forEach(t),TJo=r(SDe," (FairSeq Machine-Translation model)"),SDe.forEach(t),MJo=i(pe),Uv=n(pe,"LI",{});var RDe=s(Uv);q1e=n(RDe,"STRONG",{});var RSt=s(q1e);EJo=r(RSt,"led"),RSt.forEach(t),CJo=r(RDe," \u2014 "),mW=n(RDe,"A",{href:!0});var PSt=s(mW);wJo=r(PSt,"LEDForConditionalGeneration"),PSt.forEach(t),AJo=r(RDe," (LED model)"),RDe.forEach(t),LJo=i(pe),Hv=n(pe,"LI",{});var PDe=s(Hv);j1e=n(PDe,"STRONG",{});var BSt=s(j1e);yJo=r(BSt,"longt5"),BSt.forEach(t),xJo=r(PDe," \u2014 "),fW=n(PDe,"A",{href:!0});var ISt=s(fW);$Jo=r(ISt,"LongT5ForConditionalGeneration"),ISt.forEach(t),kJo=r(PDe," (LongT5 model)"),PDe.forEach(t),SJo=i(pe),Jv=n(pe,"LI",{});var BDe=s(Jv);D1e=n(BDe,"STRONG",{});var NSt=s(D1e);RJo=r(NSt,"m2m_100"),NSt.forEach(t),PJo=r(BDe," \u2014 "),gW=n(BDe,"A",{href:!0});var qSt=s(gW);BJo=r(qSt,"M2M100ForConditionalGeneration"),qSt.forEach(t),IJo=r(BDe," (M2M100 model)"),BDe.forEach(t),NJo=i(pe),Yv=n(pe,"LI",{});var IDe=s(Yv);G1e=n(IDe,"STRONG",{});var jSt=s(G1e);qJo=r(jSt,"marian"),jSt.forEach(t),jJo=r(IDe," \u2014 "),hW=n(IDe,"A",{href:!0});var DSt=s(hW);DJo=r(DSt,"MarianMTModel"),DSt.forEach(t),GJo=r(IDe," (Marian model)"),IDe.forEach(t),OJo=i(pe),Kv=n(pe,"LI",{});var NDe=s(Kv);O1e=n(NDe,"STRONG",{});var GSt=s(O1e);VJo=r(GSt,"mbart"),GSt.forEach(t),XJo=r(NDe," \u2014 "),uW=n(NDe,"A",{href:!0});var OSt=s(uW);zJo=r(OSt,"MBartForConditionalGeneration"),OSt.forEach(t),QJo=r(NDe," (mBART model)"),NDe.forEach(t),WJo=i(pe),Zv=n(pe,"LI",{});var qDe=s(Zv);V1e=n(qDe,"STRONG",{});var VSt=s(V1e);UJo=r(VSt,"mt5"),VSt.forEach(t),HJo=r(qDe," \u2014 "),pW=n(qDe,"A",{href:!0});var XSt=s(pW);JJo=r(XSt,"MT5ForConditionalGeneration"),XSt.forEach(t),YJo=r(qDe," (MT5 model)"),qDe.forEach(t),KJo=i(pe),eF=n(pe,"LI",{});var jDe=s(eF);X1e=n(jDe,"STRONG",{});var zSt=s(X1e);ZJo=r(zSt,"mvp"),zSt.forEach(t),eYo=r(jDe," \u2014 "),_W=n(jDe,"A",{href:!0});var QSt=s(_W);oYo=r(QSt,"MvpForConditionalGeneration"),QSt.forEach(t),rYo=r(jDe," (MVP model)"),jDe.forEach(t),tYo=i(pe),oF=n(pe,"LI",{});var DDe=s(oF);z1e=n(DDe,"STRONG",{});var WSt=s(z1e);aYo=r(WSt,"nllb"),WSt.forEach(t),nYo=r(DDe," \u2014 "),bW=n(DDe,"A",{href:!0});var USt=s(bW);sYo=r(USt,"M2M100ForConditionalGeneration"),USt.forEach(t),lYo=r(DDe," (NLLB model)"),DDe.forEach(t),iYo=i(pe),rF=n(pe,"LI",{});var GDe=s(rF);Q1e=n(GDe,"STRONG",{});var HSt=s(Q1e);dYo=r(HSt,"pegasus"),HSt.forEach(t),cYo=r(GDe," \u2014 "),vW=n(GDe,"A",{href:!0});var JSt=s(vW);mYo=r(JSt,"PegasusForConditionalGeneration"),JSt.forEach(t),fYo=r(GDe," (Pegasus model)"),GDe.forEach(t),gYo=i(pe),tF=n(pe,"LI",{});var ODe=s(tF);W1e=n(ODe,"STRONG",{});var YSt=s(W1e);hYo=r(YSt,"pegasus_x"),YSt.forEach(t),uYo=r(ODe," \u2014 "),FW=n(ODe,"A",{href:!0});var KSt=s(FW);pYo=r(KSt,"PegasusXForConditionalGeneration"),KSt.forEach(t),_Yo=r(ODe," (PEGASUS-X model)"),ODe.forEach(t),bYo=i(pe),aF=n(pe,"LI",{});var VDe=s(aF);U1e=n(VDe,"STRONG",{});var ZSt=s(U1e);vYo=r(ZSt,"plbart"),ZSt.forEach(t),FYo=r(VDe," \u2014 "),TW=n(VDe,"A",{href:!0});var eRt=s(TW);TYo=r(eRt,"PLBartForConditionalGeneration"),eRt.forEach(t),MYo=r(VDe," (PLBart model)"),VDe.forEach(t),EYo=i(pe),nF=n(pe,"LI",{});var XDe=s(nF);H1e=n(XDe,"STRONG",{});var oRt=s(H1e);CYo=r(oRt,"prophetnet"),oRt.forEach(t),wYo=r(XDe," \u2014 "),MW=n(XDe,"A",{href:!0});var rRt=s(MW);AYo=r(rRt,"ProphetNetForConditionalGeneration"),rRt.forEach(t),LYo=r(XDe," (ProphetNet model)"),XDe.forEach(t),yYo=i(pe),sF=n(pe,"LI",{});var zDe=s(sF);J1e=n(zDe,"STRONG",{});var tRt=s(J1e);xYo=r(tRt,"t5"),tRt.forEach(t),$Yo=r(zDe," \u2014 "),EW=n(zDe,"A",{href:!0});var aRt=s(EW);kYo=r(aRt,"T5ForConditionalGeneration"),aRt.forEach(t),SYo=r(zDe," (T5 model)"),zDe.forEach(t),RYo=i(pe),lF=n(pe,"LI",{});var QDe=s(lF);Y1e=n(QDe,"STRONG",{});var nRt=s(Y1e);PYo=r(nRt,"xlm-prophetnet"),nRt.forEach(t),BYo=r(QDe," \u2014 "),CW=n(QDe,"A",{href:!0});var sRt=s(CW);IYo=r(sRt,"XLMProphetNetForConditionalGeneration"),sRt.forEach(t),NYo=r(QDe," (XLM-ProphetNet model)"),QDe.forEach(t),pe.forEach(t),qYo=i(Ca),iF=n(Ca,"P",{});var WDe=s(iF);jYo=r(WDe,"The model is set in evaluation mode by default using "),K1e=n(WDe,"CODE",{});var lRt=s(K1e);DYo=r(lRt,"model.eval()"),lRt.forEach(t),GYo=r(WDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z1e=n(WDe,"CODE",{});var iRt=s(Z1e);OYo=r(iRt,"model.train()"),iRt.forEach(t),WDe.forEach(t),VYo=i(Ca),T(dF.$$.fragment,Ca),Ca.forEach(t),xl.forEach(t),_Ke=i(m),kd=n(m,"H2",{class:!0});var keo=s(kd);cF=n(keo,"A",{id:!0,class:!0,href:!0});var dRt=s(cF);eve=n(dRt,"SPAN",{});var cRt=s(eve);T(wx.$$.fragment,cRt),cRt.forEach(t),dRt.forEach(t),XYo=i(keo),ove=n(keo,"SPAN",{});var mRt=s(ove);zYo=r(mRt,"AutoModelForSequenceClassification"),mRt.forEach(t),keo.forEach(t),bKe=i(m),jo=n(m,"DIV",{class:!0});var $l=s(jo);T(Ax.$$.fragment,$l),QYo=i($l),Sd=n($l,"P",{});var mle=s(Sd);WYo=r(mle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),wW=n(mle,"A",{href:!0});var fRt=s(wW);UYo=r(fRt,"from_pretrained()"),fRt.forEach(t),HYo=r(mle," class method or the "),AW=n(mle,"A",{href:!0});var gRt=s(AW);JYo=r(gRt,"from_config()"),gRt.forEach(t),YYo=r(mle,` class
method.`),mle.forEach(t),KYo=i($l),Lx=n($l,"P",{});var Seo=s(Lx);ZYo=r(Seo,"This class cannot be instantiated directly using "),rve=n(Seo,"CODE",{});var hRt=s(rve);eKo=r(hRt,"__init__()"),hRt.forEach(t),oKo=r(Seo," (throws an error)."),Seo.forEach(t),rKo=i($l),Mt=n($l,"DIV",{class:!0});var Ry=s(Mt);T(yx.$$.fragment,Ry),tKo=i(Ry),tve=n(Ry,"P",{});var uRt=s(tve);aKo=r(uRt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),uRt.forEach(t),nKo=i(Ry),Rd=n(Ry,"P",{});var fle=s(Rd);sKo=r(fle,`Note:
Loading a model from its configuration file does `),ave=n(fle,"STRONG",{});var pRt=s(ave);lKo=r(pRt,"not"),pRt.forEach(t),iKo=r(fle,` load the model weights. It only affects the
model\u2019s configuration. Use `),LW=n(fle,"A",{href:!0});var _Rt=s(LW);dKo=r(_Rt,"from_pretrained()"),_Rt.forEach(t),cKo=r(fle," to load the model weights."),fle.forEach(t),mKo=i(Ry),T(mF.$$.fragment,Ry),Ry.forEach(t),fKo=i($l),ao=n($l,"DIV",{class:!0});var wa=s(ao);T(xx.$$.fragment,wa),gKo=i(wa),nve=n(wa,"P",{});var bRt=s(nve);hKo=r(bRt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),bRt.forEach(t),uKo=i(wa),on=n(wa,"P",{});var Py=s(on);pKo=r(Py,"The model class to instantiate is selected based on the "),sve=n(Py,"CODE",{});var vRt=s(sve);_Ko=r(vRt,"model_type"),vRt.forEach(t),bKo=r(Py,` property of the config object (either
passed as an argument or loaded from `),lve=n(Py,"CODE",{});var FRt=s(lve);vKo=r(FRt,"pretrained_model_name_or_path"),FRt.forEach(t),FKo=r(Py,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ive=n(Py,"CODE",{});var TRt=s(ive);TKo=r(TRt,"pretrained_model_name_or_path"),TRt.forEach(t),MKo=r(Py,":"),Py.forEach(t),EKo=i(wa),q=n(wa,"UL",{});var D=s(q);fF=n(D,"LI",{});var UDe=s(fF);dve=n(UDe,"STRONG",{});var MRt=s(dve);CKo=r(MRt,"albert"),MRt.forEach(t),wKo=r(UDe," \u2014 "),yW=n(UDe,"A",{href:!0});var ERt=s(yW);AKo=r(ERt,"AlbertForSequenceClassification"),ERt.forEach(t),LKo=r(UDe," (ALBERT model)"),UDe.forEach(t),yKo=i(D),gF=n(D,"LI",{});var HDe=s(gF);cve=n(HDe,"STRONG",{});var CRt=s(cve);xKo=r(CRt,"bart"),CRt.forEach(t),$Ko=r(HDe," \u2014 "),xW=n(HDe,"A",{href:!0});var wRt=s(xW);kKo=r(wRt,"BartForSequenceClassification"),wRt.forEach(t),SKo=r(HDe," (BART model)"),HDe.forEach(t),RKo=i(D),hF=n(D,"LI",{});var JDe=s(hF);mve=n(JDe,"STRONG",{});var ARt=s(mve);PKo=r(ARt,"bert"),ARt.forEach(t),BKo=r(JDe," \u2014 "),$W=n(JDe,"A",{href:!0});var LRt=s($W);IKo=r(LRt,"BertForSequenceClassification"),LRt.forEach(t),NKo=r(JDe," (BERT model)"),JDe.forEach(t),qKo=i(D),uF=n(D,"LI",{});var YDe=s(uF);fve=n(YDe,"STRONG",{});var yRt=s(fve);jKo=r(yRt,"big_bird"),yRt.forEach(t),DKo=r(YDe," \u2014 "),kW=n(YDe,"A",{href:!0});var xRt=s(kW);GKo=r(xRt,"BigBirdForSequenceClassification"),xRt.forEach(t),OKo=r(YDe," (BigBird model)"),YDe.forEach(t),VKo=i(D),pF=n(D,"LI",{});var KDe=s(pF);gve=n(KDe,"STRONG",{});var $Rt=s(gve);XKo=r($Rt,"bigbird_pegasus"),$Rt.forEach(t),zKo=r(KDe," \u2014 "),SW=n(KDe,"A",{href:!0});var kRt=s(SW);QKo=r(kRt,"BigBirdPegasusForSequenceClassification"),kRt.forEach(t),WKo=r(KDe," (BigBird-Pegasus model)"),KDe.forEach(t),UKo=i(D),_F=n(D,"LI",{});var ZDe=s(_F);hve=n(ZDe,"STRONG",{});var SRt=s(hve);HKo=r(SRt,"bloom"),SRt.forEach(t),JKo=r(ZDe," \u2014 "),RW=n(ZDe,"A",{href:!0});var RRt=s(RW);YKo=r(RRt,"BloomForSequenceClassification"),RRt.forEach(t),KKo=r(ZDe," (BLOOM model)"),ZDe.forEach(t),ZKo=i(D),bF=n(D,"LI",{});var eGe=s(bF);uve=n(eGe,"STRONG",{});var PRt=s(uve);eZo=r(PRt,"camembert"),PRt.forEach(t),oZo=r(eGe," \u2014 "),PW=n(eGe,"A",{href:!0});var BRt=s(PW);rZo=r(BRt,"CamembertForSequenceClassification"),BRt.forEach(t),tZo=r(eGe," (CamemBERT model)"),eGe.forEach(t),aZo=i(D),vF=n(D,"LI",{});var oGe=s(vF);pve=n(oGe,"STRONG",{});var IRt=s(pve);nZo=r(IRt,"canine"),IRt.forEach(t),sZo=r(oGe," \u2014 "),BW=n(oGe,"A",{href:!0});var NRt=s(BW);lZo=r(NRt,"CanineForSequenceClassification"),NRt.forEach(t),iZo=r(oGe," (CANINE model)"),oGe.forEach(t),dZo=i(D),FF=n(D,"LI",{});var rGe=s(FF);_ve=n(rGe,"STRONG",{});var qRt=s(_ve);cZo=r(qRt,"convbert"),qRt.forEach(t),mZo=r(rGe," \u2014 "),IW=n(rGe,"A",{href:!0});var jRt=s(IW);fZo=r(jRt,"ConvBertForSequenceClassification"),jRt.forEach(t),gZo=r(rGe," (ConvBERT model)"),rGe.forEach(t),hZo=i(D),TF=n(D,"LI",{});var tGe=s(TF);bve=n(tGe,"STRONG",{});var DRt=s(bve);uZo=r(DRt,"ctrl"),DRt.forEach(t),pZo=r(tGe," \u2014 "),NW=n(tGe,"A",{href:!0});var GRt=s(NW);_Zo=r(GRt,"CTRLForSequenceClassification"),GRt.forEach(t),bZo=r(tGe," (CTRL model)"),tGe.forEach(t),vZo=i(D),MF=n(D,"LI",{});var aGe=s(MF);vve=n(aGe,"STRONG",{});var ORt=s(vve);FZo=r(ORt,"data2vec-text"),ORt.forEach(t),TZo=r(aGe," \u2014 "),qW=n(aGe,"A",{href:!0});var VRt=s(qW);MZo=r(VRt,"Data2VecTextForSequenceClassification"),VRt.forEach(t),EZo=r(aGe," (Data2VecText model)"),aGe.forEach(t),CZo=i(D),EF=n(D,"LI",{});var nGe=s(EF);Fve=n(nGe,"STRONG",{});var XRt=s(Fve);wZo=r(XRt,"deberta"),XRt.forEach(t),AZo=r(nGe," \u2014 "),jW=n(nGe,"A",{href:!0});var zRt=s(jW);LZo=r(zRt,"DebertaForSequenceClassification"),zRt.forEach(t),yZo=r(nGe," (DeBERTa model)"),nGe.forEach(t),xZo=i(D),CF=n(D,"LI",{});var sGe=s(CF);Tve=n(sGe,"STRONG",{});var QRt=s(Tve);$Zo=r(QRt,"deberta-v2"),QRt.forEach(t),kZo=r(sGe," \u2014 "),DW=n(sGe,"A",{href:!0});var WRt=s(DW);SZo=r(WRt,"DebertaV2ForSequenceClassification"),WRt.forEach(t),RZo=r(sGe," (DeBERTa-v2 model)"),sGe.forEach(t),PZo=i(D),wF=n(D,"LI",{});var lGe=s(wF);Mve=n(lGe,"STRONG",{});var URt=s(Mve);BZo=r(URt,"distilbert"),URt.forEach(t),IZo=r(lGe," \u2014 "),GW=n(lGe,"A",{href:!0});var HRt=s(GW);NZo=r(HRt,"DistilBertForSequenceClassification"),HRt.forEach(t),qZo=r(lGe," (DistilBERT model)"),lGe.forEach(t),jZo=i(D),AF=n(D,"LI",{});var iGe=s(AF);Eve=n(iGe,"STRONG",{});var JRt=s(Eve);DZo=r(JRt,"electra"),JRt.forEach(t),GZo=r(iGe," \u2014 "),OW=n(iGe,"A",{href:!0});var YRt=s(OW);OZo=r(YRt,"ElectraForSequenceClassification"),YRt.forEach(t),VZo=r(iGe," (ELECTRA model)"),iGe.forEach(t),XZo=i(D),LF=n(D,"LI",{});var dGe=s(LF);Cve=n(dGe,"STRONG",{});var KRt=s(Cve);zZo=r(KRt,"ernie"),KRt.forEach(t),QZo=r(dGe," \u2014 "),VW=n(dGe,"A",{href:!0});var ZRt=s(VW);WZo=r(ZRt,"ErnieForSequenceClassification"),ZRt.forEach(t),UZo=r(dGe," (ERNIE model)"),dGe.forEach(t),HZo=i(D),yF=n(D,"LI",{});var cGe=s(yF);wve=n(cGe,"STRONG",{});var ePt=s(wve);JZo=r(ePt,"flaubert"),ePt.forEach(t),YZo=r(cGe," \u2014 "),XW=n(cGe,"A",{href:!0});var oPt=s(XW);KZo=r(oPt,"FlaubertForSequenceClassification"),oPt.forEach(t),ZZo=r(cGe," (FlauBERT model)"),cGe.forEach(t),eer=i(D),xF=n(D,"LI",{});var mGe=s(xF);Ave=n(mGe,"STRONG",{});var rPt=s(Ave);oer=r(rPt,"fnet"),rPt.forEach(t),rer=r(mGe," \u2014 "),zW=n(mGe,"A",{href:!0});var tPt=s(zW);ter=r(tPt,"FNetForSequenceClassification"),tPt.forEach(t),aer=r(mGe," (FNet model)"),mGe.forEach(t),ner=i(D),$F=n(D,"LI",{});var fGe=s($F);Lve=n(fGe,"STRONG",{});var aPt=s(Lve);ser=r(aPt,"funnel"),aPt.forEach(t),ler=r(fGe," \u2014 "),QW=n(fGe,"A",{href:!0});var nPt=s(QW);ier=r(nPt,"FunnelForSequenceClassification"),nPt.forEach(t),der=r(fGe," (Funnel Transformer model)"),fGe.forEach(t),cer=i(D),kF=n(D,"LI",{});var gGe=s(kF);yve=n(gGe,"STRONG",{});var sPt=s(yve);mer=r(sPt,"gpt2"),sPt.forEach(t),fer=r(gGe," \u2014 "),WW=n(gGe,"A",{href:!0});var lPt=s(WW);ger=r(lPt,"GPT2ForSequenceClassification"),lPt.forEach(t),her=r(gGe," (OpenAI GPT-2 model)"),gGe.forEach(t),uer=i(D),SF=n(D,"LI",{});var hGe=s(SF);xve=n(hGe,"STRONG",{});var iPt=s(xve);per=r(iPt,"gpt_neo"),iPt.forEach(t),_er=r(hGe," \u2014 "),UW=n(hGe,"A",{href:!0});var dPt=s(UW);ber=r(dPt,"GPTNeoForSequenceClassification"),dPt.forEach(t),ver=r(hGe," (GPT Neo model)"),hGe.forEach(t),Fer=i(D),RF=n(D,"LI",{});var uGe=s(RF);$ve=n(uGe,"STRONG",{});var cPt=s($ve);Ter=r(cPt,"gptj"),cPt.forEach(t),Mer=r(uGe," \u2014 "),HW=n(uGe,"A",{href:!0});var mPt=s(HW);Eer=r(mPt,"GPTJForSequenceClassification"),mPt.forEach(t),Cer=r(uGe," (GPT-J model)"),uGe.forEach(t),wer=i(D),PF=n(D,"LI",{});var pGe=s(PF);kve=n(pGe,"STRONG",{});var fPt=s(kve);Aer=r(fPt,"ibert"),fPt.forEach(t),Ler=r(pGe," \u2014 "),JW=n(pGe,"A",{href:!0});var gPt=s(JW);yer=r(gPt,"IBertForSequenceClassification"),gPt.forEach(t),xer=r(pGe," (I-BERT model)"),pGe.forEach(t),$er=i(D),BF=n(D,"LI",{});var _Ge=s(BF);Sve=n(_Ge,"STRONG",{});var hPt=s(Sve);ker=r(hPt,"layoutlm"),hPt.forEach(t),Ser=r(_Ge," \u2014 "),YW=n(_Ge,"A",{href:!0});var uPt=s(YW);Rer=r(uPt,"LayoutLMForSequenceClassification"),uPt.forEach(t),Per=r(_Ge," (LayoutLM model)"),_Ge.forEach(t),Ber=i(D),IF=n(D,"LI",{});var bGe=s(IF);Rve=n(bGe,"STRONG",{});var pPt=s(Rve);Ier=r(pPt,"layoutlmv2"),pPt.forEach(t),Ner=r(bGe," \u2014 "),KW=n(bGe,"A",{href:!0});var _Pt=s(KW);qer=r(_Pt,"LayoutLMv2ForSequenceClassification"),_Pt.forEach(t),jer=r(bGe," (LayoutLMv2 model)"),bGe.forEach(t),Der=i(D),NF=n(D,"LI",{});var vGe=s(NF);Pve=n(vGe,"STRONG",{});var bPt=s(Pve);Ger=r(bPt,"layoutlmv3"),bPt.forEach(t),Oer=r(vGe," \u2014 "),ZW=n(vGe,"A",{href:!0});var vPt=s(ZW);Ver=r(vPt,"LayoutLMv3ForSequenceClassification"),vPt.forEach(t),Xer=r(vGe," (LayoutLMv3 model)"),vGe.forEach(t),zer=i(D),qF=n(D,"LI",{});var FGe=s(qF);Bve=n(FGe,"STRONG",{});var FPt=s(Bve);Qer=r(FPt,"led"),FPt.forEach(t),Wer=r(FGe," \u2014 "),eU=n(FGe,"A",{href:!0});var TPt=s(eU);Uer=r(TPt,"LEDForSequenceClassification"),TPt.forEach(t),Her=r(FGe," (LED model)"),FGe.forEach(t),Jer=i(D),jF=n(D,"LI",{});var TGe=s(jF);Ive=n(TGe,"STRONG",{});var MPt=s(Ive);Yer=r(MPt,"longformer"),MPt.forEach(t),Ker=r(TGe," \u2014 "),oU=n(TGe,"A",{href:!0});var EPt=s(oU);Zer=r(EPt,"LongformerForSequenceClassification"),EPt.forEach(t),eor=r(TGe," (Longformer model)"),TGe.forEach(t),oor=i(D),DF=n(D,"LI",{});var MGe=s(DF);Nve=n(MGe,"STRONG",{});var CPt=s(Nve);ror=r(CPt,"luke"),CPt.forEach(t),tor=r(MGe," \u2014 "),rU=n(MGe,"A",{href:!0});var wPt=s(rU);aor=r(wPt,"LukeForSequenceClassification"),wPt.forEach(t),nor=r(MGe," (LUKE model)"),MGe.forEach(t),sor=i(D),GF=n(D,"LI",{});var EGe=s(GF);qve=n(EGe,"STRONG",{});var APt=s(qve);lor=r(APt,"mbart"),APt.forEach(t),ior=r(EGe," \u2014 "),tU=n(EGe,"A",{href:!0});var LPt=s(tU);dor=r(LPt,"MBartForSequenceClassification"),LPt.forEach(t),cor=r(EGe," (mBART model)"),EGe.forEach(t),mor=i(D),OF=n(D,"LI",{});var CGe=s(OF);jve=n(CGe,"STRONG",{});var yPt=s(jve);gor=r(yPt,"megatron-bert"),yPt.forEach(t),hor=r(CGe," \u2014 "),aU=n(CGe,"A",{href:!0});var xPt=s(aU);uor=r(xPt,"MegatronBertForSequenceClassification"),xPt.forEach(t),por=r(CGe," (Megatron-BERT model)"),CGe.forEach(t),_or=i(D),VF=n(D,"LI",{});var wGe=s(VF);Dve=n(wGe,"STRONG",{});var $Pt=s(Dve);bor=r($Pt,"mobilebert"),$Pt.forEach(t),vor=r(wGe," \u2014 "),nU=n(wGe,"A",{href:!0});var kPt=s(nU);For=r(kPt,"MobileBertForSequenceClassification"),kPt.forEach(t),Tor=r(wGe," (MobileBERT model)"),wGe.forEach(t),Mor=i(D),XF=n(D,"LI",{});var AGe=s(XF);Gve=n(AGe,"STRONG",{});var SPt=s(Gve);Eor=r(SPt,"mpnet"),SPt.forEach(t),Cor=r(AGe," \u2014 "),sU=n(AGe,"A",{href:!0});var RPt=s(sU);wor=r(RPt,"MPNetForSequenceClassification"),RPt.forEach(t),Aor=r(AGe," (MPNet model)"),AGe.forEach(t),Lor=i(D),zF=n(D,"LI",{});var LGe=s(zF);Ove=n(LGe,"STRONG",{});var PPt=s(Ove);yor=r(PPt,"mvp"),PPt.forEach(t),xor=r(LGe," \u2014 "),lU=n(LGe,"A",{href:!0});var BPt=s(lU);$or=r(BPt,"MvpForSequenceClassification"),BPt.forEach(t),kor=r(LGe," (MVP model)"),LGe.forEach(t),Sor=i(D),QF=n(D,"LI",{});var yGe=s(QF);Vve=n(yGe,"STRONG",{});var IPt=s(Vve);Ror=r(IPt,"nezha"),IPt.forEach(t),Por=r(yGe," \u2014 "),iU=n(yGe,"A",{href:!0});var NPt=s(iU);Bor=r(NPt,"NezhaForSequenceClassification"),NPt.forEach(t),Ior=r(yGe," (Nezha model)"),yGe.forEach(t),Nor=i(D),WF=n(D,"LI",{});var xGe=s(WF);Xve=n(xGe,"STRONG",{});var qPt=s(Xve);qor=r(qPt,"nystromformer"),qPt.forEach(t),jor=r(xGe," \u2014 "),dU=n(xGe,"A",{href:!0});var jPt=s(dU);Dor=r(jPt,"NystromformerForSequenceClassification"),jPt.forEach(t),Gor=r(xGe," (Nystr\xF6mformer model)"),xGe.forEach(t),Oor=i(D),UF=n(D,"LI",{});var $Ge=s(UF);zve=n($Ge,"STRONG",{});var DPt=s(zve);Vor=r(DPt,"openai-gpt"),DPt.forEach(t),Xor=r($Ge," \u2014 "),cU=n($Ge,"A",{href:!0});var GPt=s(cU);zor=r(GPt,"OpenAIGPTForSequenceClassification"),GPt.forEach(t),Qor=r($Ge," (OpenAI GPT model)"),$Ge.forEach(t),Wor=i(D),HF=n(D,"LI",{});var kGe=s(HF);Qve=n(kGe,"STRONG",{});var OPt=s(Qve);Uor=r(OPt,"opt"),OPt.forEach(t),Hor=r(kGe," \u2014 "),mU=n(kGe,"A",{href:!0});var VPt=s(mU);Jor=r(VPt,"OPTForSequenceClassification"),VPt.forEach(t),Yor=r(kGe," (OPT model)"),kGe.forEach(t),Kor=i(D),JF=n(D,"LI",{});var SGe=s(JF);Wve=n(SGe,"STRONG",{});var XPt=s(Wve);Zor=r(XPt,"perceiver"),XPt.forEach(t),err=r(SGe," \u2014 "),fU=n(SGe,"A",{href:!0});var zPt=s(fU);orr=r(zPt,"PerceiverForSequenceClassification"),zPt.forEach(t),rrr=r(SGe," (Perceiver model)"),SGe.forEach(t),trr=i(D),YF=n(D,"LI",{});var RGe=s(YF);Uve=n(RGe,"STRONG",{});var QPt=s(Uve);arr=r(QPt,"plbart"),QPt.forEach(t),nrr=r(RGe," \u2014 "),gU=n(RGe,"A",{href:!0});var WPt=s(gU);srr=r(WPt,"PLBartForSequenceClassification"),WPt.forEach(t),lrr=r(RGe," (PLBart model)"),RGe.forEach(t),irr=i(D),KF=n(D,"LI",{});var PGe=s(KF);Hve=n(PGe,"STRONG",{});var UPt=s(Hve);drr=r(UPt,"qdqbert"),UPt.forEach(t),crr=r(PGe," \u2014 "),hU=n(PGe,"A",{href:!0});var HPt=s(hU);mrr=r(HPt,"QDQBertForSequenceClassification"),HPt.forEach(t),frr=r(PGe," (QDQBert model)"),PGe.forEach(t),grr=i(D),ZF=n(D,"LI",{});var BGe=s(ZF);Jve=n(BGe,"STRONG",{});var JPt=s(Jve);hrr=r(JPt,"reformer"),JPt.forEach(t),urr=r(BGe," \u2014 "),uU=n(BGe,"A",{href:!0});var YPt=s(uU);prr=r(YPt,"ReformerForSequenceClassification"),YPt.forEach(t),_rr=r(BGe," (Reformer model)"),BGe.forEach(t),brr=i(D),eT=n(D,"LI",{});var IGe=s(eT);Yve=n(IGe,"STRONG",{});var KPt=s(Yve);vrr=r(KPt,"rembert"),KPt.forEach(t),Frr=r(IGe," \u2014 "),pU=n(IGe,"A",{href:!0});var ZPt=s(pU);Trr=r(ZPt,"RemBertForSequenceClassification"),ZPt.forEach(t),Mrr=r(IGe," (RemBERT model)"),IGe.forEach(t),Err=i(D),oT=n(D,"LI",{});var NGe=s(oT);Kve=n(NGe,"STRONG",{});var eBt=s(Kve);Crr=r(eBt,"roberta"),eBt.forEach(t),wrr=r(NGe," \u2014 "),_U=n(NGe,"A",{href:!0});var oBt=s(_U);Arr=r(oBt,"RobertaForSequenceClassification"),oBt.forEach(t),Lrr=r(NGe," (RoBERTa model)"),NGe.forEach(t),yrr=i(D),rT=n(D,"LI",{});var qGe=s(rT);Zve=n(qGe,"STRONG",{});var rBt=s(Zve);xrr=r(rBt,"roformer"),rBt.forEach(t),$rr=r(qGe," \u2014 "),bU=n(qGe,"A",{href:!0});var tBt=s(bU);krr=r(tBt,"RoFormerForSequenceClassification"),tBt.forEach(t),Srr=r(qGe," (RoFormer model)"),qGe.forEach(t),Rrr=i(D),tT=n(D,"LI",{});var jGe=s(tT);eFe=n(jGe,"STRONG",{});var aBt=s(eFe);Prr=r(aBt,"squeezebert"),aBt.forEach(t),Brr=r(jGe," \u2014 "),vU=n(jGe,"A",{href:!0});var nBt=s(vU);Irr=r(nBt,"SqueezeBertForSequenceClassification"),nBt.forEach(t),Nrr=r(jGe," (SqueezeBERT model)"),jGe.forEach(t),qrr=i(D),aT=n(D,"LI",{});var DGe=s(aT);oFe=n(DGe,"STRONG",{});var sBt=s(oFe);jrr=r(sBt,"tapas"),sBt.forEach(t),Drr=r(DGe," \u2014 "),FU=n(DGe,"A",{href:!0});var lBt=s(FU);Grr=r(lBt,"TapasForSequenceClassification"),lBt.forEach(t),Orr=r(DGe," (TAPAS model)"),DGe.forEach(t),Vrr=i(D),nT=n(D,"LI",{});var GGe=s(nT);rFe=n(GGe,"STRONG",{});var iBt=s(rFe);Xrr=r(iBt,"transfo-xl"),iBt.forEach(t),zrr=r(GGe," \u2014 "),TU=n(GGe,"A",{href:!0});var dBt=s(TU);Qrr=r(dBt,"TransfoXLForSequenceClassification"),dBt.forEach(t),Wrr=r(GGe," (Transformer-XL model)"),GGe.forEach(t),Urr=i(D),sT=n(D,"LI",{});var OGe=s(sT);tFe=n(OGe,"STRONG",{});var cBt=s(tFe);Hrr=r(cBt,"xlm"),cBt.forEach(t),Jrr=r(OGe," \u2014 "),MU=n(OGe,"A",{href:!0});var mBt=s(MU);Yrr=r(mBt,"XLMForSequenceClassification"),mBt.forEach(t),Krr=r(OGe," (XLM model)"),OGe.forEach(t),Zrr=i(D),lT=n(D,"LI",{});var VGe=s(lT);aFe=n(VGe,"STRONG",{});var fBt=s(aFe);etr=r(fBt,"xlm-roberta"),fBt.forEach(t),otr=r(VGe," \u2014 "),EU=n(VGe,"A",{href:!0});var gBt=s(EU);rtr=r(gBt,"XLMRobertaForSequenceClassification"),gBt.forEach(t),ttr=r(VGe," (XLM-RoBERTa model)"),VGe.forEach(t),atr=i(D),iT=n(D,"LI",{});var XGe=s(iT);nFe=n(XGe,"STRONG",{});var hBt=s(nFe);ntr=r(hBt,"xlm-roberta-xl"),hBt.forEach(t),str=r(XGe," \u2014 "),CU=n(XGe,"A",{href:!0});var uBt=s(CU);ltr=r(uBt,"XLMRobertaXLForSequenceClassification"),uBt.forEach(t),itr=r(XGe," (XLM-RoBERTa-XL model)"),XGe.forEach(t),dtr=i(D),dT=n(D,"LI",{});var zGe=s(dT);sFe=n(zGe,"STRONG",{});var pBt=s(sFe);ctr=r(pBt,"xlnet"),pBt.forEach(t),mtr=r(zGe," \u2014 "),wU=n(zGe,"A",{href:!0});var _Bt=s(wU);ftr=r(_Bt,"XLNetForSequenceClassification"),_Bt.forEach(t),gtr=r(zGe," (XLNet model)"),zGe.forEach(t),htr=i(D),cT=n(D,"LI",{});var QGe=s(cT);lFe=n(QGe,"STRONG",{});var bBt=s(lFe);utr=r(bBt,"yoso"),bBt.forEach(t),ptr=r(QGe," \u2014 "),AU=n(QGe,"A",{href:!0});var vBt=s(AU);_tr=r(vBt,"YosoForSequenceClassification"),vBt.forEach(t),btr=r(QGe," (YOSO model)"),QGe.forEach(t),D.forEach(t),vtr=i(wa),mT=n(wa,"P",{});var WGe=s(mT);Ftr=r(WGe,"The model is set in evaluation mode by default using "),iFe=n(WGe,"CODE",{});var FBt=s(iFe);Ttr=r(FBt,"model.eval()"),FBt.forEach(t),Mtr=r(WGe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dFe=n(WGe,"CODE",{});var TBt=s(dFe);Etr=r(TBt,"model.train()"),TBt.forEach(t),WGe.forEach(t),Ctr=i(wa),T(fT.$$.fragment,wa),wa.forEach(t),$l.forEach(t),vKe=i(m),Pd=n(m,"H2",{class:!0});var Reo=s(Pd);gT=n(Reo,"A",{id:!0,class:!0,href:!0});var MBt=s(gT);cFe=n(MBt,"SPAN",{});var EBt=s(cFe);T($x.$$.fragment,EBt),EBt.forEach(t),MBt.forEach(t),wtr=i(Reo),mFe=n(Reo,"SPAN",{});var CBt=s(mFe);Atr=r(CBt,"AutoModelForMultipleChoice"),CBt.forEach(t),Reo.forEach(t),FKe=i(m),Do=n(m,"DIV",{class:!0});var kl=s(Do);T(kx.$$.fragment,kl),Ltr=i(kl),Bd=n(kl,"P",{});var gle=s(Bd);ytr=r(gle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),LU=n(gle,"A",{href:!0});var wBt=s(LU);xtr=r(wBt,"from_pretrained()"),wBt.forEach(t),$tr=r(gle," class method or the "),yU=n(gle,"A",{href:!0});var ABt=s(yU);ktr=r(ABt,"from_config()"),ABt.forEach(t),Str=r(gle,` class
method.`),gle.forEach(t),Rtr=i(kl),Sx=n(kl,"P",{});var Peo=s(Sx);Ptr=r(Peo,"This class cannot be instantiated directly using "),fFe=n(Peo,"CODE",{});var LBt=s(fFe);Btr=r(LBt,"__init__()"),LBt.forEach(t),Itr=r(Peo," (throws an error)."),Peo.forEach(t),Ntr=i(kl),Et=n(kl,"DIV",{class:!0});var By=s(Et);T(Rx.$$.fragment,By),qtr=i(By),gFe=n(By,"P",{});var yBt=s(gFe);jtr=r(yBt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),yBt.forEach(t),Dtr=i(By),Id=n(By,"P",{});var hle=s(Id);Gtr=r(hle,`Note:
Loading a model from its configuration file does `),hFe=n(hle,"STRONG",{});var xBt=s(hFe);Otr=r(xBt,"not"),xBt.forEach(t),Vtr=r(hle,` load the model weights. It only affects the
model\u2019s configuration. Use `),xU=n(hle,"A",{href:!0});var $Bt=s(xU);Xtr=r($Bt,"from_pretrained()"),$Bt.forEach(t),ztr=r(hle," to load the model weights."),hle.forEach(t),Qtr=i(By),T(hT.$$.fragment,By),By.forEach(t),Wtr=i(kl),no=n(kl,"DIV",{class:!0});var Aa=s(no);T(Px.$$.fragment,Aa),Utr=i(Aa),uFe=n(Aa,"P",{});var kBt=s(uFe);Htr=r(kBt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),kBt.forEach(t),Jtr=i(Aa),rn=n(Aa,"P",{});var Iy=s(rn);Ytr=r(Iy,"The model class to instantiate is selected based on the "),pFe=n(Iy,"CODE",{});var SBt=s(pFe);Ktr=r(SBt,"model_type"),SBt.forEach(t),Ztr=r(Iy,` property of the config object (either
passed as an argument or loaded from `),_Fe=n(Iy,"CODE",{});var RBt=s(_Fe);ear=r(RBt,"pretrained_model_name_or_path"),RBt.forEach(t),oar=r(Iy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bFe=n(Iy,"CODE",{});var PBt=s(bFe);rar=r(PBt,"pretrained_model_name_or_path"),PBt.forEach(t),tar=r(Iy,":"),Iy.forEach(t),aar=i(Aa),Z=n(Aa,"UL",{});var ee=s(Z);uT=n(ee,"LI",{});var UGe=s(uT);vFe=n(UGe,"STRONG",{});var BBt=s(vFe);nar=r(BBt,"albert"),BBt.forEach(t),sar=r(UGe," \u2014 "),$U=n(UGe,"A",{href:!0});var IBt=s($U);lar=r(IBt,"AlbertForMultipleChoice"),IBt.forEach(t),iar=r(UGe," (ALBERT model)"),UGe.forEach(t),dar=i(ee),pT=n(ee,"LI",{});var HGe=s(pT);FFe=n(HGe,"STRONG",{});var NBt=s(FFe);car=r(NBt,"bert"),NBt.forEach(t),mar=r(HGe," \u2014 "),kU=n(HGe,"A",{href:!0});var qBt=s(kU);far=r(qBt,"BertForMultipleChoice"),qBt.forEach(t),gar=r(HGe," (BERT model)"),HGe.forEach(t),har=i(ee),_T=n(ee,"LI",{});var JGe=s(_T);TFe=n(JGe,"STRONG",{});var jBt=s(TFe);uar=r(jBt,"big_bird"),jBt.forEach(t),par=r(JGe," \u2014 "),SU=n(JGe,"A",{href:!0});var DBt=s(SU);_ar=r(DBt,"BigBirdForMultipleChoice"),DBt.forEach(t),bar=r(JGe," (BigBird model)"),JGe.forEach(t),Far=i(ee),bT=n(ee,"LI",{});var YGe=s(bT);MFe=n(YGe,"STRONG",{});var GBt=s(MFe);Tar=r(GBt,"camembert"),GBt.forEach(t),Mar=r(YGe," \u2014 "),RU=n(YGe,"A",{href:!0});var OBt=s(RU);Ear=r(OBt,"CamembertForMultipleChoice"),OBt.forEach(t),Car=r(YGe," (CamemBERT model)"),YGe.forEach(t),war=i(ee),vT=n(ee,"LI",{});var KGe=s(vT);EFe=n(KGe,"STRONG",{});var VBt=s(EFe);Aar=r(VBt,"canine"),VBt.forEach(t),Lar=r(KGe," \u2014 "),PU=n(KGe,"A",{href:!0});var XBt=s(PU);yar=r(XBt,"CanineForMultipleChoice"),XBt.forEach(t),xar=r(KGe," (CANINE model)"),KGe.forEach(t),$ar=i(ee),FT=n(ee,"LI",{});var ZGe=s(FT);CFe=n(ZGe,"STRONG",{});var zBt=s(CFe);kar=r(zBt,"convbert"),zBt.forEach(t),Sar=r(ZGe," \u2014 "),BU=n(ZGe,"A",{href:!0});var QBt=s(BU);Rar=r(QBt,"ConvBertForMultipleChoice"),QBt.forEach(t),Par=r(ZGe," (ConvBERT model)"),ZGe.forEach(t),Bar=i(ee),TT=n(ee,"LI",{});var eOe=s(TT);wFe=n(eOe,"STRONG",{});var WBt=s(wFe);Iar=r(WBt,"data2vec-text"),WBt.forEach(t),Nar=r(eOe," \u2014 "),IU=n(eOe,"A",{href:!0});var UBt=s(IU);qar=r(UBt,"Data2VecTextForMultipleChoice"),UBt.forEach(t),jar=r(eOe," (Data2VecText model)"),eOe.forEach(t),Dar=i(ee),MT=n(ee,"LI",{});var oOe=s(MT);AFe=n(oOe,"STRONG",{});var HBt=s(AFe);Gar=r(HBt,"deberta-v2"),HBt.forEach(t),Oar=r(oOe," \u2014 "),NU=n(oOe,"A",{href:!0});var JBt=s(NU);Var=r(JBt,"DebertaV2ForMultipleChoice"),JBt.forEach(t),Xar=r(oOe," (DeBERTa-v2 model)"),oOe.forEach(t),zar=i(ee),ET=n(ee,"LI",{});var rOe=s(ET);LFe=n(rOe,"STRONG",{});var YBt=s(LFe);Qar=r(YBt,"distilbert"),YBt.forEach(t),War=r(rOe," \u2014 "),qU=n(rOe,"A",{href:!0});var KBt=s(qU);Uar=r(KBt,"DistilBertForMultipleChoice"),KBt.forEach(t),Har=r(rOe," (DistilBERT model)"),rOe.forEach(t),Jar=i(ee),CT=n(ee,"LI",{});var tOe=s(CT);yFe=n(tOe,"STRONG",{});var ZBt=s(yFe);Yar=r(ZBt,"electra"),ZBt.forEach(t),Kar=r(tOe," \u2014 "),jU=n(tOe,"A",{href:!0});var eIt=s(jU);Zar=r(eIt,"ElectraForMultipleChoice"),eIt.forEach(t),enr=r(tOe," (ELECTRA model)"),tOe.forEach(t),onr=i(ee),wT=n(ee,"LI",{});var aOe=s(wT);xFe=n(aOe,"STRONG",{});var oIt=s(xFe);rnr=r(oIt,"ernie"),oIt.forEach(t),tnr=r(aOe," \u2014 "),DU=n(aOe,"A",{href:!0});var rIt=s(DU);anr=r(rIt,"ErnieForMultipleChoice"),rIt.forEach(t),nnr=r(aOe," (ERNIE model)"),aOe.forEach(t),snr=i(ee),AT=n(ee,"LI",{});var nOe=s(AT);$Fe=n(nOe,"STRONG",{});var tIt=s($Fe);lnr=r(tIt,"flaubert"),tIt.forEach(t),inr=r(nOe," \u2014 "),GU=n(nOe,"A",{href:!0});var aIt=s(GU);dnr=r(aIt,"FlaubertForMultipleChoice"),aIt.forEach(t),cnr=r(nOe," (FlauBERT model)"),nOe.forEach(t),mnr=i(ee),LT=n(ee,"LI",{});var sOe=s(LT);kFe=n(sOe,"STRONG",{});var nIt=s(kFe);fnr=r(nIt,"fnet"),nIt.forEach(t),gnr=r(sOe," \u2014 "),OU=n(sOe,"A",{href:!0});var sIt=s(OU);hnr=r(sIt,"FNetForMultipleChoice"),sIt.forEach(t),unr=r(sOe," (FNet model)"),sOe.forEach(t),pnr=i(ee),yT=n(ee,"LI",{});var lOe=s(yT);SFe=n(lOe,"STRONG",{});var lIt=s(SFe);_nr=r(lIt,"funnel"),lIt.forEach(t),bnr=r(lOe," \u2014 "),VU=n(lOe,"A",{href:!0});var iIt=s(VU);vnr=r(iIt,"FunnelForMultipleChoice"),iIt.forEach(t),Fnr=r(lOe," (Funnel Transformer model)"),lOe.forEach(t),Tnr=i(ee),xT=n(ee,"LI",{});var iOe=s(xT);RFe=n(iOe,"STRONG",{});var dIt=s(RFe);Mnr=r(dIt,"ibert"),dIt.forEach(t),Enr=r(iOe," \u2014 "),XU=n(iOe,"A",{href:!0});var cIt=s(XU);Cnr=r(cIt,"IBertForMultipleChoice"),cIt.forEach(t),wnr=r(iOe," (I-BERT model)"),iOe.forEach(t),Anr=i(ee),$T=n(ee,"LI",{});var dOe=s($T);PFe=n(dOe,"STRONG",{});var mIt=s(PFe);Lnr=r(mIt,"longformer"),mIt.forEach(t),ynr=r(dOe," \u2014 "),zU=n(dOe,"A",{href:!0});var fIt=s(zU);xnr=r(fIt,"LongformerForMultipleChoice"),fIt.forEach(t),$nr=r(dOe," (Longformer model)"),dOe.forEach(t),knr=i(ee),kT=n(ee,"LI",{});var cOe=s(kT);BFe=n(cOe,"STRONG",{});var gIt=s(BFe);Snr=r(gIt,"luke"),gIt.forEach(t),Rnr=r(cOe," \u2014 "),QU=n(cOe,"A",{href:!0});var hIt=s(QU);Pnr=r(hIt,"LukeForMultipleChoice"),hIt.forEach(t),Bnr=r(cOe," (LUKE model)"),cOe.forEach(t),Inr=i(ee),ST=n(ee,"LI",{});var mOe=s(ST);IFe=n(mOe,"STRONG",{});var uIt=s(IFe);Nnr=r(uIt,"megatron-bert"),uIt.forEach(t),qnr=r(mOe," \u2014 "),WU=n(mOe,"A",{href:!0});var pIt=s(WU);jnr=r(pIt,"MegatronBertForMultipleChoice"),pIt.forEach(t),Dnr=r(mOe," (Megatron-BERT model)"),mOe.forEach(t),Gnr=i(ee),RT=n(ee,"LI",{});var fOe=s(RT);NFe=n(fOe,"STRONG",{});var _It=s(NFe);Onr=r(_It,"mobilebert"),_It.forEach(t),Vnr=r(fOe," \u2014 "),UU=n(fOe,"A",{href:!0});var bIt=s(UU);Xnr=r(bIt,"MobileBertForMultipleChoice"),bIt.forEach(t),znr=r(fOe," (MobileBERT model)"),fOe.forEach(t),Qnr=i(ee),PT=n(ee,"LI",{});var gOe=s(PT);qFe=n(gOe,"STRONG",{});var vIt=s(qFe);Wnr=r(vIt,"mpnet"),vIt.forEach(t),Unr=r(gOe," \u2014 "),HU=n(gOe,"A",{href:!0});var FIt=s(HU);Hnr=r(FIt,"MPNetForMultipleChoice"),FIt.forEach(t),Jnr=r(gOe," (MPNet model)"),gOe.forEach(t),Ynr=i(ee),BT=n(ee,"LI",{});var hOe=s(BT);jFe=n(hOe,"STRONG",{});var TIt=s(jFe);Knr=r(TIt,"nezha"),TIt.forEach(t),Znr=r(hOe," \u2014 "),JU=n(hOe,"A",{href:!0});var MIt=s(JU);esr=r(MIt,"NezhaForMultipleChoice"),MIt.forEach(t),osr=r(hOe," (Nezha model)"),hOe.forEach(t),rsr=i(ee),IT=n(ee,"LI",{});var uOe=s(IT);DFe=n(uOe,"STRONG",{});var EIt=s(DFe);tsr=r(EIt,"nystromformer"),EIt.forEach(t),asr=r(uOe," \u2014 "),YU=n(uOe,"A",{href:!0});var CIt=s(YU);nsr=r(CIt,"NystromformerForMultipleChoice"),CIt.forEach(t),ssr=r(uOe," (Nystr\xF6mformer model)"),uOe.forEach(t),lsr=i(ee),NT=n(ee,"LI",{});var pOe=s(NT);GFe=n(pOe,"STRONG",{});var wIt=s(GFe);isr=r(wIt,"qdqbert"),wIt.forEach(t),dsr=r(pOe," \u2014 "),KU=n(pOe,"A",{href:!0});var AIt=s(KU);csr=r(AIt,"QDQBertForMultipleChoice"),AIt.forEach(t),msr=r(pOe," (QDQBert model)"),pOe.forEach(t),fsr=i(ee),qT=n(ee,"LI",{});var _Oe=s(qT);OFe=n(_Oe,"STRONG",{});var LIt=s(OFe);gsr=r(LIt,"rembert"),LIt.forEach(t),hsr=r(_Oe," \u2014 "),ZU=n(_Oe,"A",{href:!0});var yIt=s(ZU);usr=r(yIt,"RemBertForMultipleChoice"),yIt.forEach(t),psr=r(_Oe," (RemBERT model)"),_Oe.forEach(t),_sr=i(ee),jT=n(ee,"LI",{});var bOe=s(jT);VFe=n(bOe,"STRONG",{});var xIt=s(VFe);bsr=r(xIt,"roberta"),xIt.forEach(t),vsr=r(bOe," \u2014 "),eH=n(bOe,"A",{href:!0});var $It=s(eH);Fsr=r($It,"RobertaForMultipleChoice"),$It.forEach(t),Tsr=r(bOe," (RoBERTa model)"),bOe.forEach(t),Msr=i(ee),DT=n(ee,"LI",{});var vOe=s(DT);XFe=n(vOe,"STRONG",{});var kIt=s(XFe);Esr=r(kIt,"roformer"),kIt.forEach(t),Csr=r(vOe," \u2014 "),oH=n(vOe,"A",{href:!0});var SIt=s(oH);wsr=r(SIt,"RoFormerForMultipleChoice"),SIt.forEach(t),Asr=r(vOe," (RoFormer model)"),vOe.forEach(t),Lsr=i(ee),GT=n(ee,"LI",{});var FOe=s(GT);zFe=n(FOe,"STRONG",{});var RIt=s(zFe);ysr=r(RIt,"squeezebert"),RIt.forEach(t),xsr=r(FOe," \u2014 "),rH=n(FOe,"A",{href:!0});var PIt=s(rH);$sr=r(PIt,"SqueezeBertForMultipleChoice"),PIt.forEach(t),ksr=r(FOe," (SqueezeBERT model)"),FOe.forEach(t),Ssr=i(ee),OT=n(ee,"LI",{});var TOe=s(OT);QFe=n(TOe,"STRONG",{});var BIt=s(QFe);Rsr=r(BIt,"xlm"),BIt.forEach(t),Psr=r(TOe," \u2014 "),tH=n(TOe,"A",{href:!0});var IIt=s(tH);Bsr=r(IIt,"XLMForMultipleChoice"),IIt.forEach(t),Isr=r(TOe," (XLM model)"),TOe.forEach(t),Nsr=i(ee),VT=n(ee,"LI",{});var MOe=s(VT);WFe=n(MOe,"STRONG",{});var NIt=s(WFe);qsr=r(NIt,"xlm-roberta"),NIt.forEach(t),jsr=r(MOe," \u2014 "),aH=n(MOe,"A",{href:!0});var qIt=s(aH);Dsr=r(qIt,"XLMRobertaForMultipleChoice"),qIt.forEach(t),Gsr=r(MOe," (XLM-RoBERTa model)"),MOe.forEach(t),Osr=i(ee),XT=n(ee,"LI",{});var EOe=s(XT);UFe=n(EOe,"STRONG",{});var jIt=s(UFe);Vsr=r(jIt,"xlm-roberta-xl"),jIt.forEach(t),Xsr=r(EOe," \u2014 "),nH=n(EOe,"A",{href:!0});var DIt=s(nH);zsr=r(DIt,"XLMRobertaXLForMultipleChoice"),DIt.forEach(t),Qsr=r(EOe," (XLM-RoBERTa-XL model)"),EOe.forEach(t),Wsr=i(ee),zT=n(ee,"LI",{});var COe=s(zT);HFe=n(COe,"STRONG",{});var GIt=s(HFe);Usr=r(GIt,"xlnet"),GIt.forEach(t),Hsr=r(COe," \u2014 "),sH=n(COe,"A",{href:!0});var OIt=s(sH);Jsr=r(OIt,"XLNetForMultipleChoice"),OIt.forEach(t),Ysr=r(COe," (XLNet model)"),COe.forEach(t),Ksr=i(ee),QT=n(ee,"LI",{});var wOe=s(QT);JFe=n(wOe,"STRONG",{});var VIt=s(JFe);Zsr=r(VIt,"yoso"),VIt.forEach(t),elr=r(wOe," \u2014 "),lH=n(wOe,"A",{href:!0});var XIt=s(lH);olr=r(XIt,"YosoForMultipleChoice"),XIt.forEach(t),rlr=r(wOe," (YOSO model)"),wOe.forEach(t),ee.forEach(t),tlr=i(Aa),WT=n(Aa,"P",{});var AOe=s(WT);alr=r(AOe,"The model is set in evaluation mode by default using "),YFe=n(AOe,"CODE",{});var zIt=s(YFe);nlr=r(zIt,"model.eval()"),zIt.forEach(t),slr=r(AOe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),KFe=n(AOe,"CODE",{});var QIt=s(KFe);llr=r(QIt,"model.train()"),QIt.forEach(t),AOe.forEach(t),ilr=i(Aa),T(UT.$$.fragment,Aa),Aa.forEach(t),kl.forEach(t),TKe=i(m),Nd=n(m,"H2",{class:!0});var Beo=s(Nd);HT=n(Beo,"A",{id:!0,class:!0,href:!0});var WIt=s(HT);ZFe=n(WIt,"SPAN",{});var UIt=s(ZFe);T(Bx.$$.fragment,UIt),UIt.forEach(t),WIt.forEach(t),dlr=i(Beo),eTe=n(Beo,"SPAN",{});var HIt=s(eTe);clr=r(HIt,"AutoModelForNextSentencePrediction"),HIt.forEach(t),Beo.forEach(t),MKe=i(m),Go=n(m,"DIV",{class:!0});var Sl=s(Go);T(Ix.$$.fragment,Sl),mlr=i(Sl),qd=n(Sl,"P",{});var ule=s(qd);flr=r(ule,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),iH=n(ule,"A",{href:!0});var JIt=s(iH);glr=r(JIt,"from_pretrained()"),JIt.forEach(t),hlr=r(ule," class method or the "),dH=n(ule,"A",{href:!0});var YIt=s(dH);ulr=r(YIt,"from_config()"),YIt.forEach(t),plr=r(ule,` class
method.`),ule.forEach(t),_lr=i(Sl),Nx=n(Sl,"P",{});var Ieo=s(Nx);blr=r(Ieo,"This class cannot be instantiated directly using "),oTe=n(Ieo,"CODE",{});var KIt=s(oTe);vlr=r(KIt,"__init__()"),KIt.forEach(t),Flr=r(Ieo," (throws an error)."),Ieo.forEach(t),Tlr=i(Sl),Ct=n(Sl,"DIV",{class:!0});var Ny=s(Ct);T(qx.$$.fragment,Ny),Mlr=i(Ny),rTe=n(Ny,"P",{});var ZIt=s(rTe);Elr=r(ZIt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),ZIt.forEach(t),Clr=i(Ny),jd=n(Ny,"P",{});var ple=s(jd);wlr=r(ple,`Note:
Loading a model from its configuration file does `),tTe=n(ple,"STRONG",{});var eNt=s(tTe);Alr=r(eNt,"not"),eNt.forEach(t),Llr=r(ple,` load the model weights. It only affects the
model\u2019s configuration. Use `),cH=n(ple,"A",{href:!0});var oNt=s(cH);ylr=r(oNt,"from_pretrained()"),oNt.forEach(t),xlr=r(ple," to load the model weights."),ple.forEach(t),$lr=i(Ny),T(JT.$$.fragment,Ny),Ny.forEach(t),klr=i(Sl),so=n(Sl,"DIV",{class:!0});var La=s(so);T(jx.$$.fragment,La),Slr=i(La),aTe=n(La,"P",{});var rNt=s(aTe);Rlr=r(rNt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),rNt.forEach(t),Plr=i(La),tn=n(La,"P",{});var qy=s(tn);Blr=r(qy,"The model class to instantiate is selected based on the "),nTe=n(qy,"CODE",{});var tNt=s(nTe);Ilr=r(tNt,"model_type"),tNt.forEach(t),Nlr=r(qy,` property of the config object (either
passed as an argument or loaded from `),sTe=n(qy,"CODE",{});var aNt=s(sTe);qlr=r(aNt,"pretrained_model_name_or_path"),aNt.forEach(t),jlr=r(qy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lTe=n(qy,"CODE",{});var nNt=s(lTe);Dlr=r(nNt,"pretrained_model_name_or_path"),nNt.forEach(t),Glr=r(qy,":"),qy.forEach(t),Olr=i(La),Ue=n(La,"UL",{});var ct=s(Ue);YT=n(ct,"LI",{});var LOe=s(YT);iTe=n(LOe,"STRONG",{});var sNt=s(iTe);Vlr=r(sNt,"bert"),sNt.forEach(t),Xlr=r(LOe," \u2014 "),mH=n(LOe,"A",{href:!0});var lNt=s(mH);zlr=r(lNt,"BertForNextSentencePrediction"),lNt.forEach(t),Qlr=r(LOe," (BERT model)"),LOe.forEach(t),Wlr=i(ct),KT=n(ct,"LI",{});var yOe=s(KT);dTe=n(yOe,"STRONG",{});var iNt=s(dTe);Ulr=r(iNt,"ernie"),iNt.forEach(t),Hlr=r(yOe," \u2014 "),fH=n(yOe,"A",{href:!0});var dNt=s(fH);Jlr=r(dNt,"ErnieForNextSentencePrediction"),dNt.forEach(t),Ylr=r(yOe," (ERNIE model)"),yOe.forEach(t),Klr=i(ct),ZT=n(ct,"LI",{});var xOe=s(ZT);cTe=n(xOe,"STRONG",{});var cNt=s(cTe);Zlr=r(cNt,"fnet"),cNt.forEach(t),eir=r(xOe," \u2014 "),gH=n(xOe,"A",{href:!0});var mNt=s(gH);oir=r(mNt,"FNetForNextSentencePrediction"),mNt.forEach(t),rir=r(xOe," (FNet model)"),xOe.forEach(t),tir=i(ct),eM=n(ct,"LI",{});var $Oe=s(eM);mTe=n($Oe,"STRONG",{});var fNt=s(mTe);air=r(fNt,"megatron-bert"),fNt.forEach(t),nir=r($Oe," \u2014 "),hH=n($Oe,"A",{href:!0});var gNt=s(hH);sir=r(gNt,"MegatronBertForNextSentencePrediction"),gNt.forEach(t),lir=r($Oe," (Megatron-BERT model)"),$Oe.forEach(t),iir=i(ct),oM=n(ct,"LI",{});var kOe=s(oM);fTe=n(kOe,"STRONG",{});var hNt=s(fTe);dir=r(hNt,"mobilebert"),hNt.forEach(t),cir=r(kOe," \u2014 "),uH=n(kOe,"A",{href:!0});var uNt=s(uH);mir=r(uNt,"MobileBertForNextSentencePrediction"),uNt.forEach(t),fir=r(kOe," (MobileBERT model)"),kOe.forEach(t),gir=i(ct),rM=n(ct,"LI",{});var SOe=s(rM);gTe=n(SOe,"STRONG",{});var pNt=s(gTe);hir=r(pNt,"nezha"),pNt.forEach(t),uir=r(SOe," \u2014 "),pH=n(SOe,"A",{href:!0});var _Nt=s(pH);pir=r(_Nt,"NezhaForNextSentencePrediction"),_Nt.forEach(t),_ir=r(SOe," (Nezha model)"),SOe.forEach(t),bir=i(ct),tM=n(ct,"LI",{});var ROe=s(tM);hTe=n(ROe,"STRONG",{});var bNt=s(hTe);vir=r(bNt,"qdqbert"),bNt.forEach(t),Fir=r(ROe," \u2014 "),_H=n(ROe,"A",{href:!0});var vNt=s(_H);Tir=r(vNt,"QDQBertForNextSentencePrediction"),vNt.forEach(t),Mir=r(ROe," (QDQBert model)"),ROe.forEach(t),ct.forEach(t),Eir=i(La),aM=n(La,"P",{});var POe=s(aM);Cir=r(POe,"The model is set in evaluation mode by default using "),uTe=n(POe,"CODE",{});var FNt=s(uTe);wir=r(FNt,"model.eval()"),FNt.forEach(t),Air=r(POe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pTe=n(POe,"CODE",{});var TNt=s(pTe);Lir=r(TNt,"model.train()"),TNt.forEach(t),POe.forEach(t),yir=i(La),T(nM.$$.fragment,La),La.forEach(t),Sl.forEach(t),EKe=i(m),Dd=n(m,"H2",{class:!0});var Neo=s(Dd);sM=n(Neo,"A",{id:!0,class:!0,href:!0});var MNt=s(sM);_Te=n(MNt,"SPAN",{});var ENt=s(_Te);T(Dx.$$.fragment,ENt),ENt.forEach(t),MNt.forEach(t),xir=i(Neo),bTe=n(Neo,"SPAN",{});var CNt=s(bTe);$ir=r(CNt,"AutoModelForTokenClassification"),CNt.forEach(t),Neo.forEach(t),CKe=i(m),Oo=n(m,"DIV",{class:!0});var Rl=s(Oo);T(Gx.$$.fragment,Rl),kir=i(Rl),Gd=n(Rl,"P",{});var _le=s(Gd);Sir=r(_le,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),bH=n(_le,"A",{href:!0});var wNt=s(bH);Rir=r(wNt,"from_pretrained()"),wNt.forEach(t),Pir=r(_le," class method or the "),vH=n(_le,"A",{href:!0});var ANt=s(vH);Bir=r(ANt,"from_config()"),ANt.forEach(t),Iir=r(_le,` class
method.`),_le.forEach(t),Nir=i(Rl),Ox=n(Rl,"P",{});var qeo=s(Ox);qir=r(qeo,"This class cannot be instantiated directly using "),vTe=n(qeo,"CODE",{});var LNt=s(vTe);jir=r(LNt,"__init__()"),LNt.forEach(t),Dir=r(qeo," (throws an error)."),qeo.forEach(t),Gir=i(Rl),wt=n(Rl,"DIV",{class:!0});var jy=s(wt);T(Vx.$$.fragment,jy),Oir=i(jy),FTe=n(jy,"P",{});var yNt=s(FTe);Vir=r(yNt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),yNt.forEach(t),Xir=i(jy),Od=n(jy,"P",{});var ble=s(Od);zir=r(ble,`Note:
Loading a model from its configuration file does `),TTe=n(ble,"STRONG",{});var xNt=s(TTe);Qir=r(xNt,"not"),xNt.forEach(t),Wir=r(ble,` load the model weights. It only affects the
model\u2019s configuration. Use `),FH=n(ble,"A",{href:!0});var $Nt=s(FH);Uir=r($Nt,"from_pretrained()"),$Nt.forEach(t),Hir=r(ble," to load the model weights."),ble.forEach(t),Jir=i(jy),T(lM.$$.fragment,jy),jy.forEach(t),Yir=i(Rl),lo=n(Rl,"DIV",{class:!0});var ya=s(lo);T(Xx.$$.fragment,ya),Kir=i(ya),MTe=n(ya,"P",{});var kNt=s(MTe);Zir=r(kNt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),kNt.forEach(t),edr=i(ya),an=n(ya,"P",{});var Dy=s(an);odr=r(Dy,"The model class to instantiate is selected based on the "),ETe=n(Dy,"CODE",{});var SNt=s(ETe);rdr=r(SNt,"model_type"),SNt.forEach(t),tdr=r(Dy,` property of the config object (either
passed as an argument or loaded from `),CTe=n(Dy,"CODE",{});var RNt=s(CTe);adr=r(RNt,"pretrained_model_name_or_path"),RNt.forEach(t),ndr=r(Dy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wTe=n(Dy,"CODE",{});var PNt=s(wTe);sdr=r(PNt,"pretrained_model_name_or_path"),PNt.forEach(t),ldr=r(Dy,":"),Dy.forEach(t),idr=i(ya),J=n(ya,"UL",{});var K=s(J);iM=n(K,"LI",{});var BOe=s(iM);ATe=n(BOe,"STRONG",{});var BNt=s(ATe);ddr=r(BNt,"albert"),BNt.forEach(t),cdr=r(BOe," \u2014 "),TH=n(BOe,"A",{href:!0});var INt=s(TH);mdr=r(INt,"AlbertForTokenClassification"),INt.forEach(t),fdr=r(BOe," (ALBERT model)"),BOe.forEach(t),gdr=i(K),dM=n(K,"LI",{});var IOe=s(dM);LTe=n(IOe,"STRONG",{});var NNt=s(LTe);hdr=r(NNt,"bert"),NNt.forEach(t),udr=r(IOe," \u2014 "),MH=n(IOe,"A",{href:!0});var qNt=s(MH);pdr=r(qNt,"BertForTokenClassification"),qNt.forEach(t),_dr=r(IOe," (BERT model)"),IOe.forEach(t),bdr=i(K),cM=n(K,"LI",{});var NOe=s(cM);yTe=n(NOe,"STRONG",{});var jNt=s(yTe);vdr=r(jNt,"big_bird"),jNt.forEach(t),Fdr=r(NOe," \u2014 "),EH=n(NOe,"A",{href:!0});var DNt=s(EH);Tdr=r(DNt,"BigBirdForTokenClassification"),DNt.forEach(t),Mdr=r(NOe," (BigBird model)"),NOe.forEach(t),Edr=i(K),mM=n(K,"LI",{});var qOe=s(mM);xTe=n(qOe,"STRONG",{});var GNt=s(xTe);Cdr=r(GNt,"bloom"),GNt.forEach(t),wdr=r(qOe," \u2014 "),CH=n(qOe,"A",{href:!0});var ONt=s(CH);Adr=r(ONt,"BloomForTokenClassification"),ONt.forEach(t),Ldr=r(qOe," (BLOOM model)"),qOe.forEach(t),ydr=i(K),fM=n(K,"LI",{});var jOe=s(fM);$Te=n(jOe,"STRONG",{});var VNt=s($Te);xdr=r(VNt,"camembert"),VNt.forEach(t),$dr=r(jOe," \u2014 "),wH=n(jOe,"A",{href:!0});var XNt=s(wH);kdr=r(XNt,"CamembertForTokenClassification"),XNt.forEach(t),Sdr=r(jOe," (CamemBERT model)"),jOe.forEach(t),Rdr=i(K),gM=n(K,"LI",{});var DOe=s(gM);kTe=n(DOe,"STRONG",{});var zNt=s(kTe);Pdr=r(zNt,"canine"),zNt.forEach(t),Bdr=r(DOe," \u2014 "),AH=n(DOe,"A",{href:!0});var QNt=s(AH);Idr=r(QNt,"CanineForTokenClassification"),QNt.forEach(t),Ndr=r(DOe," (CANINE model)"),DOe.forEach(t),qdr=i(K),hM=n(K,"LI",{});var GOe=s(hM);STe=n(GOe,"STRONG",{});var WNt=s(STe);jdr=r(WNt,"convbert"),WNt.forEach(t),Ddr=r(GOe," \u2014 "),LH=n(GOe,"A",{href:!0});var UNt=s(LH);Gdr=r(UNt,"ConvBertForTokenClassification"),UNt.forEach(t),Odr=r(GOe," (ConvBERT model)"),GOe.forEach(t),Vdr=i(K),uM=n(K,"LI",{});var OOe=s(uM);RTe=n(OOe,"STRONG",{});var HNt=s(RTe);Xdr=r(HNt,"data2vec-text"),HNt.forEach(t),zdr=r(OOe," \u2014 "),yH=n(OOe,"A",{href:!0});var JNt=s(yH);Qdr=r(JNt,"Data2VecTextForTokenClassification"),JNt.forEach(t),Wdr=r(OOe," (Data2VecText model)"),OOe.forEach(t),Udr=i(K),pM=n(K,"LI",{});var VOe=s(pM);PTe=n(VOe,"STRONG",{});var YNt=s(PTe);Hdr=r(YNt,"deberta"),YNt.forEach(t),Jdr=r(VOe," \u2014 "),xH=n(VOe,"A",{href:!0});var KNt=s(xH);Ydr=r(KNt,"DebertaForTokenClassification"),KNt.forEach(t),Kdr=r(VOe," (DeBERTa model)"),VOe.forEach(t),Zdr=i(K),_M=n(K,"LI",{});var XOe=s(_M);BTe=n(XOe,"STRONG",{});var ZNt=s(BTe);ecr=r(ZNt,"deberta-v2"),ZNt.forEach(t),ocr=r(XOe," \u2014 "),$H=n(XOe,"A",{href:!0});var eqt=s($H);rcr=r(eqt,"DebertaV2ForTokenClassification"),eqt.forEach(t),tcr=r(XOe," (DeBERTa-v2 model)"),XOe.forEach(t),acr=i(K),bM=n(K,"LI",{});var zOe=s(bM);ITe=n(zOe,"STRONG",{});var oqt=s(ITe);ncr=r(oqt,"distilbert"),oqt.forEach(t),scr=r(zOe," \u2014 "),kH=n(zOe,"A",{href:!0});var rqt=s(kH);lcr=r(rqt,"DistilBertForTokenClassification"),rqt.forEach(t),icr=r(zOe," (DistilBERT model)"),zOe.forEach(t),dcr=i(K),vM=n(K,"LI",{});var QOe=s(vM);NTe=n(QOe,"STRONG",{});var tqt=s(NTe);ccr=r(tqt,"electra"),tqt.forEach(t),mcr=r(QOe," \u2014 "),SH=n(QOe,"A",{href:!0});var aqt=s(SH);fcr=r(aqt,"ElectraForTokenClassification"),aqt.forEach(t),gcr=r(QOe," (ELECTRA model)"),QOe.forEach(t),hcr=i(K),FM=n(K,"LI",{});var WOe=s(FM);qTe=n(WOe,"STRONG",{});var nqt=s(qTe);ucr=r(nqt,"ernie"),nqt.forEach(t),pcr=r(WOe," \u2014 "),RH=n(WOe,"A",{href:!0});var sqt=s(RH);_cr=r(sqt,"ErnieForTokenClassification"),sqt.forEach(t),bcr=r(WOe," (ERNIE model)"),WOe.forEach(t),vcr=i(K),TM=n(K,"LI",{});var UOe=s(TM);jTe=n(UOe,"STRONG",{});var lqt=s(jTe);Fcr=r(lqt,"flaubert"),lqt.forEach(t),Tcr=r(UOe," \u2014 "),PH=n(UOe,"A",{href:!0});var iqt=s(PH);Mcr=r(iqt,"FlaubertForTokenClassification"),iqt.forEach(t),Ecr=r(UOe," (FlauBERT model)"),UOe.forEach(t),Ccr=i(K),MM=n(K,"LI",{});var HOe=s(MM);DTe=n(HOe,"STRONG",{});var dqt=s(DTe);wcr=r(dqt,"fnet"),dqt.forEach(t),Acr=r(HOe," \u2014 "),BH=n(HOe,"A",{href:!0});var cqt=s(BH);Lcr=r(cqt,"FNetForTokenClassification"),cqt.forEach(t),ycr=r(HOe," (FNet model)"),HOe.forEach(t),xcr=i(K),EM=n(K,"LI",{});var JOe=s(EM);GTe=n(JOe,"STRONG",{});var mqt=s(GTe);$cr=r(mqt,"funnel"),mqt.forEach(t),kcr=r(JOe," \u2014 "),IH=n(JOe,"A",{href:!0});var fqt=s(IH);Scr=r(fqt,"FunnelForTokenClassification"),fqt.forEach(t),Rcr=r(JOe," (Funnel Transformer model)"),JOe.forEach(t),Pcr=i(K),CM=n(K,"LI",{});var YOe=s(CM);OTe=n(YOe,"STRONG",{});var gqt=s(OTe);Bcr=r(gqt,"gpt2"),gqt.forEach(t),Icr=r(YOe," \u2014 "),NH=n(YOe,"A",{href:!0});var hqt=s(NH);Ncr=r(hqt,"GPT2ForTokenClassification"),hqt.forEach(t),qcr=r(YOe," (OpenAI GPT-2 model)"),YOe.forEach(t),jcr=i(K),wM=n(K,"LI",{});var KOe=s(wM);VTe=n(KOe,"STRONG",{});var uqt=s(VTe);Dcr=r(uqt,"ibert"),uqt.forEach(t),Gcr=r(KOe," \u2014 "),qH=n(KOe,"A",{href:!0});var pqt=s(qH);Ocr=r(pqt,"IBertForTokenClassification"),pqt.forEach(t),Vcr=r(KOe," (I-BERT model)"),KOe.forEach(t),Xcr=i(K),AM=n(K,"LI",{});var ZOe=s(AM);XTe=n(ZOe,"STRONG",{});var _qt=s(XTe);zcr=r(_qt,"layoutlm"),_qt.forEach(t),Qcr=r(ZOe," \u2014 "),jH=n(ZOe,"A",{href:!0});var bqt=s(jH);Wcr=r(bqt,"LayoutLMForTokenClassification"),bqt.forEach(t),Ucr=r(ZOe," (LayoutLM model)"),ZOe.forEach(t),Hcr=i(K),LM=n(K,"LI",{});var eVe=s(LM);zTe=n(eVe,"STRONG",{});var vqt=s(zTe);Jcr=r(vqt,"layoutlmv2"),vqt.forEach(t),Ycr=r(eVe," \u2014 "),DH=n(eVe,"A",{href:!0});var Fqt=s(DH);Kcr=r(Fqt,"LayoutLMv2ForTokenClassification"),Fqt.forEach(t),Zcr=r(eVe," (LayoutLMv2 model)"),eVe.forEach(t),emr=i(K),yM=n(K,"LI",{});var oVe=s(yM);QTe=n(oVe,"STRONG",{});var Tqt=s(QTe);omr=r(Tqt,"layoutlmv3"),Tqt.forEach(t),rmr=r(oVe," \u2014 "),GH=n(oVe,"A",{href:!0});var Mqt=s(GH);tmr=r(Mqt,"LayoutLMv3ForTokenClassification"),Mqt.forEach(t),amr=r(oVe," (LayoutLMv3 model)"),oVe.forEach(t),nmr=i(K),xM=n(K,"LI",{});var rVe=s(xM);WTe=n(rVe,"STRONG",{});var Eqt=s(WTe);smr=r(Eqt,"longformer"),Eqt.forEach(t),lmr=r(rVe," \u2014 "),OH=n(rVe,"A",{href:!0});var Cqt=s(OH);imr=r(Cqt,"LongformerForTokenClassification"),Cqt.forEach(t),dmr=r(rVe," (Longformer model)"),rVe.forEach(t),cmr=i(K),$M=n(K,"LI",{});var tVe=s($M);UTe=n(tVe,"STRONG",{});var wqt=s(UTe);mmr=r(wqt,"luke"),wqt.forEach(t),fmr=r(tVe," \u2014 "),VH=n(tVe,"A",{href:!0});var Aqt=s(VH);gmr=r(Aqt,"LukeForTokenClassification"),Aqt.forEach(t),hmr=r(tVe," (LUKE model)"),tVe.forEach(t),umr=i(K),kM=n(K,"LI",{});var aVe=s(kM);HTe=n(aVe,"STRONG",{});var Lqt=s(HTe);pmr=r(Lqt,"megatron-bert"),Lqt.forEach(t),_mr=r(aVe," \u2014 "),XH=n(aVe,"A",{href:!0});var yqt=s(XH);bmr=r(yqt,"MegatronBertForTokenClassification"),yqt.forEach(t),vmr=r(aVe," (Megatron-BERT model)"),aVe.forEach(t),Fmr=i(K),SM=n(K,"LI",{});var nVe=s(SM);JTe=n(nVe,"STRONG",{});var xqt=s(JTe);Tmr=r(xqt,"mobilebert"),xqt.forEach(t),Mmr=r(nVe," \u2014 "),zH=n(nVe,"A",{href:!0});var $qt=s(zH);Emr=r($qt,"MobileBertForTokenClassification"),$qt.forEach(t),Cmr=r(nVe," (MobileBERT model)"),nVe.forEach(t),wmr=i(K),RM=n(K,"LI",{});var sVe=s(RM);YTe=n(sVe,"STRONG",{});var kqt=s(YTe);Amr=r(kqt,"mpnet"),kqt.forEach(t),Lmr=r(sVe," \u2014 "),QH=n(sVe,"A",{href:!0});var Sqt=s(QH);ymr=r(Sqt,"MPNetForTokenClassification"),Sqt.forEach(t),xmr=r(sVe," (MPNet model)"),sVe.forEach(t),$mr=i(K),PM=n(K,"LI",{});var lVe=s(PM);KTe=n(lVe,"STRONG",{});var Rqt=s(KTe);kmr=r(Rqt,"nezha"),Rqt.forEach(t),Smr=r(lVe," \u2014 "),WH=n(lVe,"A",{href:!0});var Pqt=s(WH);Rmr=r(Pqt,"NezhaForTokenClassification"),Pqt.forEach(t),Pmr=r(lVe," (Nezha model)"),lVe.forEach(t),Bmr=i(K),BM=n(K,"LI",{});var iVe=s(BM);ZTe=n(iVe,"STRONG",{});var Bqt=s(ZTe);Imr=r(Bqt,"nystromformer"),Bqt.forEach(t),Nmr=r(iVe," \u2014 "),UH=n(iVe,"A",{href:!0});var Iqt=s(UH);qmr=r(Iqt,"NystromformerForTokenClassification"),Iqt.forEach(t),jmr=r(iVe," (Nystr\xF6mformer model)"),iVe.forEach(t),Dmr=i(K),IM=n(K,"LI",{});var dVe=s(IM);eMe=n(dVe,"STRONG",{});var Nqt=s(eMe);Gmr=r(Nqt,"qdqbert"),Nqt.forEach(t),Omr=r(dVe," \u2014 "),HH=n(dVe,"A",{href:!0});var qqt=s(HH);Vmr=r(qqt,"QDQBertForTokenClassification"),qqt.forEach(t),Xmr=r(dVe," (QDQBert model)"),dVe.forEach(t),zmr=i(K),NM=n(K,"LI",{});var cVe=s(NM);oMe=n(cVe,"STRONG",{});var jqt=s(oMe);Qmr=r(jqt,"rembert"),jqt.forEach(t),Wmr=r(cVe," \u2014 "),JH=n(cVe,"A",{href:!0});var Dqt=s(JH);Umr=r(Dqt,"RemBertForTokenClassification"),Dqt.forEach(t),Hmr=r(cVe," (RemBERT model)"),cVe.forEach(t),Jmr=i(K),qM=n(K,"LI",{});var mVe=s(qM);rMe=n(mVe,"STRONG",{});var Gqt=s(rMe);Ymr=r(Gqt,"roberta"),Gqt.forEach(t),Kmr=r(mVe," \u2014 "),YH=n(mVe,"A",{href:!0});var Oqt=s(YH);Zmr=r(Oqt,"RobertaForTokenClassification"),Oqt.forEach(t),efr=r(mVe," (RoBERTa model)"),mVe.forEach(t),ofr=i(K),jM=n(K,"LI",{});var fVe=s(jM);tMe=n(fVe,"STRONG",{});var Vqt=s(tMe);rfr=r(Vqt,"roformer"),Vqt.forEach(t),tfr=r(fVe," \u2014 "),KH=n(fVe,"A",{href:!0});var Xqt=s(KH);afr=r(Xqt,"RoFormerForTokenClassification"),Xqt.forEach(t),nfr=r(fVe," (RoFormer model)"),fVe.forEach(t),sfr=i(K),DM=n(K,"LI",{});var gVe=s(DM);aMe=n(gVe,"STRONG",{});var zqt=s(aMe);lfr=r(zqt,"squeezebert"),zqt.forEach(t),ifr=r(gVe," \u2014 "),ZH=n(gVe,"A",{href:!0});var Qqt=s(ZH);dfr=r(Qqt,"SqueezeBertForTokenClassification"),Qqt.forEach(t),cfr=r(gVe," (SqueezeBERT model)"),gVe.forEach(t),mfr=i(K),GM=n(K,"LI",{});var hVe=s(GM);nMe=n(hVe,"STRONG",{});var Wqt=s(nMe);ffr=r(Wqt,"xlm"),Wqt.forEach(t),gfr=r(hVe," \u2014 "),eJ=n(hVe,"A",{href:!0});var Uqt=s(eJ);hfr=r(Uqt,"XLMForTokenClassification"),Uqt.forEach(t),ufr=r(hVe," (XLM model)"),hVe.forEach(t),pfr=i(K),OM=n(K,"LI",{});var uVe=s(OM);sMe=n(uVe,"STRONG",{});var Hqt=s(sMe);_fr=r(Hqt,"xlm-roberta"),Hqt.forEach(t),bfr=r(uVe," \u2014 "),oJ=n(uVe,"A",{href:!0});var Jqt=s(oJ);vfr=r(Jqt,"XLMRobertaForTokenClassification"),Jqt.forEach(t),Ffr=r(uVe," (XLM-RoBERTa model)"),uVe.forEach(t),Tfr=i(K),VM=n(K,"LI",{});var pVe=s(VM);lMe=n(pVe,"STRONG",{});var Yqt=s(lMe);Mfr=r(Yqt,"xlm-roberta-xl"),Yqt.forEach(t),Efr=r(pVe," \u2014 "),rJ=n(pVe,"A",{href:!0});var Kqt=s(rJ);Cfr=r(Kqt,"XLMRobertaXLForTokenClassification"),Kqt.forEach(t),wfr=r(pVe," (XLM-RoBERTa-XL model)"),pVe.forEach(t),Afr=i(K),XM=n(K,"LI",{});var _Ve=s(XM);iMe=n(_Ve,"STRONG",{});var Zqt=s(iMe);Lfr=r(Zqt,"xlnet"),Zqt.forEach(t),yfr=r(_Ve," \u2014 "),tJ=n(_Ve,"A",{href:!0});var ejt=s(tJ);xfr=r(ejt,"XLNetForTokenClassification"),ejt.forEach(t),$fr=r(_Ve," (XLNet model)"),_Ve.forEach(t),kfr=i(K),zM=n(K,"LI",{});var bVe=s(zM);dMe=n(bVe,"STRONG",{});var ojt=s(dMe);Sfr=r(ojt,"yoso"),ojt.forEach(t),Rfr=r(bVe," \u2014 "),aJ=n(bVe,"A",{href:!0});var rjt=s(aJ);Pfr=r(rjt,"YosoForTokenClassification"),rjt.forEach(t),Bfr=r(bVe," (YOSO model)"),bVe.forEach(t),K.forEach(t),Ifr=i(ya),QM=n(ya,"P",{});var vVe=s(QM);Nfr=r(vVe,"The model is set in evaluation mode by default using "),cMe=n(vVe,"CODE",{});var tjt=s(cMe);qfr=r(tjt,"model.eval()"),tjt.forEach(t),jfr=r(vVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mMe=n(vVe,"CODE",{});var ajt=s(mMe);Dfr=r(ajt,"model.train()"),ajt.forEach(t),vVe.forEach(t),Gfr=i(ya),T(WM.$$.fragment,ya),ya.forEach(t),Rl.forEach(t),wKe=i(m),Vd=n(m,"H2",{class:!0});var jeo=s(Vd);UM=n(jeo,"A",{id:!0,class:!0,href:!0});var njt=s(UM);fMe=n(njt,"SPAN",{});var sjt=s(fMe);T(zx.$$.fragment,sjt),sjt.forEach(t),njt.forEach(t),Ofr=i(jeo),gMe=n(jeo,"SPAN",{});var ljt=s(gMe);Vfr=r(ljt,"AutoModelForQuestionAnswering"),ljt.forEach(t),jeo.forEach(t),AKe=i(m),Vo=n(m,"DIV",{class:!0});var Pl=s(Vo);T(Qx.$$.fragment,Pl),Xfr=i(Pl),Xd=n(Pl,"P",{});var vle=s(Xd);zfr=r(vle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),nJ=n(vle,"A",{href:!0});var ijt=s(nJ);Qfr=r(ijt,"from_pretrained()"),ijt.forEach(t),Wfr=r(vle," class method or the "),sJ=n(vle,"A",{href:!0});var djt=s(sJ);Ufr=r(djt,"from_config()"),djt.forEach(t),Hfr=r(vle,` class
method.`),vle.forEach(t),Jfr=i(Pl),Wx=n(Pl,"P",{});var Deo=s(Wx);Yfr=r(Deo,"This class cannot be instantiated directly using "),hMe=n(Deo,"CODE",{});var cjt=s(hMe);Kfr=r(cjt,"__init__()"),cjt.forEach(t),Zfr=r(Deo," (throws an error)."),Deo.forEach(t),egr=i(Pl),At=n(Pl,"DIV",{class:!0});var Gy=s(At);T(Ux.$$.fragment,Gy),ogr=i(Gy),uMe=n(Gy,"P",{});var mjt=s(uMe);rgr=r(mjt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),mjt.forEach(t),tgr=i(Gy),zd=n(Gy,"P",{});var Fle=s(zd);agr=r(Fle,`Note:
Loading a model from its configuration file does `),pMe=n(Fle,"STRONG",{});var fjt=s(pMe);ngr=r(fjt,"not"),fjt.forEach(t),sgr=r(Fle,` load the model weights. It only affects the
model\u2019s configuration. Use `),lJ=n(Fle,"A",{href:!0});var gjt=s(lJ);lgr=r(gjt,"from_pretrained()"),gjt.forEach(t),igr=r(Fle," to load the model weights."),Fle.forEach(t),dgr=i(Gy),T(HM.$$.fragment,Gy),Gy.forEach(t),cgr=i(Pl),io=n(Pl,"DIV",{class:!0});var xa=s(io);T(Hx.$$.fragment,xa),mgr=i(xa),_Me=n(xa,"P",{});var hjt=s(_Me);fgr=r(hjt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),hjt.forEach(t),ggr=i(xa),nn=n(xa,"P",{});var Oy=s(nn);hgr=r(Oy,"The model class to instantiate is selected based on the "),bMe=n(Oy,"CODE",{});var ujt=s(bMe);ugr=r(ujt,"model_type"),ujt.forEach(t),pgr=r(Oy,` property of the config object (either
passed as an argument or loaded from `),vMe=n(Oy,"CODE",{});var pjt=s(vMe);_gr=r(pjt,"pretrained_model_name_or_path"),pjt.forEach(t),bgr=r(Oy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FMe=n(Oy,"CODE",{});var _jt=s(FMe);vgr=r(_jt,"pretrained_model_name_or_path"),_jt.forEach(t),Fgr=r(Oy,":"),Oy.forEach(t),Tgr=i(xa),V=n(xa,"UL",{});var X=s(V);JM=n(X,"LI",{});var FVe=s(JM);TMe=n(FVe,"STRONG",{});var bjt=s(TMe);Mgr=r(bjt,"albert"),bjt.forEach(t),Egr=r(FVe," \u2014 "),iJ=n(FVe,"A",{href:!0});var vjt=s(iJ);Cgr=r(vjt,"AlbertForQuestionAnswering"),vjt.forEach(t),wgr=r(FVe," (ALBERT model)"),FVe.forEach(t),Agr=i(X),YM=n(X,"LI",{});var TVe=s(YM);MMe=n(TVe,"STRONG",{});var Fjt=s(MMe);Lgr=r(Fjt,"bart"),Fjt.forEach(t),ygr=r(TVe," \u2014 "),dJ=n(TVe,"A",{href:!0});var Tjt=s(dJ);xgr=r(Tjt,"BartForQuestionAnswering"),Tjt.forEach(t),$gr=r(TVe," (BART model)"),TVe.forEach(t),kgr=i(X),KM=n(X,"LI",{});var MVe=s(KM);EMe=n(MVe,"STRONG",{});var Mjt=s(EMe);Sgr=r(Mjt,"bert"),Mjt.forEach(t),Rgr=r(MVe," \u2014 "),cJ=n(MVe,"A",{href:!0});var Ejt=s(cJ);Pgr=r(Ejt,"BertForQuestionAnswering"),Ejt.forEach(t),Bgr=r(MVe," (BERT model)"),MVe.forEach(t),Igr=i(X),ZM=n(X,"LI",{});var EVe=s(ZM);CMe=n(EVe,"STRONG",{});var Cjt=s(CMe);Ngr=r(Cjt,"big_bird"),Cjt.forEach(t),qgr=r(EVe," \u2014 "),mJ=n(EVe,"A",{href:!0});var wjt=s(mJ);jgr=r(wjt,"BigBirdForQuestionAnswering"),wjt.forEach(t),Dgr=r(EVe," (BigBird model)"),EVe.forEach(t),Ggr=i(X),eE=n(X,"LI",{});var CVe=s(eE);wMe=n(CVe,"STRONG",{});var Ajt=s(wMe);Ogr=r(Ajt,"bigbird_pegasus"),Ajt.forEach(t),Vgr=r(CVe," \u2014 "),fJ=n(CVe,"A",{href:!0});var Ljt=s(fJ);Xgr=r(Ljt,"BigBirdPegasusForQuestionAnswering"),Ljt.forEach(t),zgr=r(CVe," (BigBird-Pegasus model)"),CVe.forEach(t),Qgr=i(X),oE=n(X,"LI",{});var wVe=s(oE);AMe=n(wVe,"STRONG",{});var yjt=s(AMe);Wgr=r(yjt,"camembert"),yjt.forEach(t),Ugr=r(wVe," \u2014 "),gJ=n(wVe,"A",{href:!0});var xjt=s(gJ);Hgr=r(xjt,"CamembertForQuestionAnswering"),xjt.forEach(t),Jgr=r(wVe," (CamemBERT model)"),wVe.forEach(t),Ygr=i(X),rE=n(X,"LI",{});var AVe=s(rE);LMe=n(AVe,"STRONG",{});var $jt=s(LMe);Kgr=r($jt,"canine"),$jt.forEach(t),Zgr=r(AVe," \u2014 "),hJ=n(AVe,"A",{href:!0});var kjt=s(hJ);ehr=r(kjt,"CanineForQuestionAnswering"),kjt.forEach(t),ohr=r(AVe," (CANINE model)"),AVe.forEach(t),rhr=i(X),tE=n(X,"LI",{});var LVe=s(tE);yMe=n(LVe,"STRONG",{});var Sjt=s(yMe);thr=r(Sjt,"convbert"),Sjt.forEach(t),ahr=r(LVe," \u2014 "),uJ=n(LVe,"A",{href:!0});var Rjt=s(uJ);nhr=r(Rjt,"ConvBertForQuestionAnswering"),Rjt.forEach(t),shr=r(LVe," (ConvBERT model)"),LVe.forEach(t),lhr=i(X),aE=n(X,"LI",{});var yVe=s(aE);xMe=n(yVe,"STRONG",{});var Pjt=s(xMe);ihr=r(Pjt,"data2vec-text"),Pjt.forEach(t),dhr=r(yVe," \u2014 "),pJ=n(yVe,"A",{href:!0});var Bjt=s(pJ);chr=r(Bjt,"Data2VecTextForQuestionAnswering"),Bjt.forEach(t),mhr=r(yVe," (Data2VecText model)"),yVe.forEach(t),fhr=i(X),nE=n(X,"LI",{});var xVe=s(nE);$Me=n(xVe,"STRONG",{});var Ijt=s($Me);ghr=r(Ijt,"deberta"),Ijt.forEach(t),hhr=r(xVe," \u2014 "),_J=n(xVe,"A",{href:!0});var Njt=s(_J);uhr=r(Njt,"DebertaForQuestionAnswering"),Njt.forEach(t),phr=r(xVe," (DeBERTa model)"),xVe.forEach(t),_hr=i(X),sE=n(X,"LI",{});var $Ve=s(sE);kMe=n($Ve,"STRONG",{});var qjt=s(kMe);bhr=r(qjt,"deberta-v2"),qjt.forEach(t),vhr=r($Ve," \u2014 "),bJ=n($Ve,"A",{href:!0});var jjt=s(bJ);Fhr=r(jjt,"DebertaV2ForQuestionAnswering"),jjt.forEach(t),Thr=r($Ve," (DeBERTa-v2 model)"),$Ve.forEach(t),Mhr=i(X),lE=n(X,"LI",{});var kVe=s(lE);SMe=n(kVe,"STRONG",{});var Djt=s(SMe);Ehr=r(Djt,"distilbert"),Djt.forEach(t),Chr=r(kVe," \u2014 "),vJ=n(kVe,"A",{href:!0});var Gjt=s(vJ);whr=r(Gjt,"DistilBertForQuestionAnswering"),Gjt.forEach(t),Ahr=r(kVe," (DistilBERT model)"),kVe.forEach(t),Lhr=i(X),iE=n(X,"LI",{});var SVe=s(iE);RMe=n(SVe,"STRONG",{});var Ojt=s(RMe);yhr=r(Ojt,"electra"),Ojt.forEach(t),xhr=r(SVe," \u2014 "),FJ=n(SVe,"A",{href:!0});var Vjt=s(FJ);$hr=r(Vjt,"ElectraForQuestionAnswering"),Vjt.forEach(t),khr=r(SVe," (ELECTRA model)"),SVe.forEach(t),Shr=i(X),dE=n(X,"LI",{});var RVe=s(dE);PMe=n(RVe,"STRONG",{});var Xjt=s(PMe);Rhr=r(Xjt,"ernie"),Xjt.forEach(t),Phr=r(RVe," \u2014 "),TJ=n(RVe,"A",{href:!0});var zjt=s(TJ);Bhr=r(zjt,"ErnieForQuestionAnswering"),zjt.forEach(t),Ihr=r(RVe," (ERNIE model)"),RVe.forEach(t),Nhr=i(X),cE=n(X,"LI",{});var PVe=s(cE);BMe=n(PVe,"STRONG",{});var Qjt=s(BMe);qhr=r(Qjt,"flaubert"),Qjt.forEach(t),jhr=r(PVe," \u2014 "),MJ=n(PVe,"A",{href:!0});var Wjt=s(MJ);Dhr=r(Wjt,"FlaubertForQuestionAnsweringSimple"),Wjt.forEach(t),Ghr=r(PVe," (FlauBERT model)"),PVe.forEach(t),Ohr=i(X),mE=n(X,"LI",{});var BVe=s(mE);IMe=n(BVe,"STRONG",{});var Ujt=s(IMe);Vhr=r(Ujt,"fnet"),Ujt.forEach(t),Xhr=r(BVe," \u2014 "),EJ=n(BVe,"A",{href:!0});var Hjt=s(EJ);zhr=r(Hjt,"FNetForQuestionAnswering"),Hjt.forEach(t),Qhr=r(BVe," (FNet model)"),BVe.forEach(t),Whr=i(X),fE=n(X,"LI",{});var IVe=s(fE);NMe=n(IVe,"STRONG",{});var Jjt=s(NMe);Uhr=r(Jjt,"funnel"),Jjt.forEach(t),Hhr=r(IVe," \u2014 "),CJ=n(IVe,"A",{href:!0});var Yjt=s(CJ);Jhr=r(Yjt,"FunnelForQuestionAnswering"),Yjt.forEach(t),Yhr=r(IVe," (Funnel Transformer model)"),IVe.forEach(t),Khr=i(X),gE=n(X,"LI",{});var NVe=s(gE);qMe=n(NVe,"STRONG",{});var Kjt=s(qMe);Zhr=r(Kjt,"gptj"),Kjt.forEach(t),eur=r(NVe," \u2014 "),wJ=n(NVe,"A",{href:!0});var Zjt=s(wJ);our=r(Zjt,"GPTJForQuestionAnswering"),Zjt.forEach(t),rur=r(NVe," (GPT-J model)"),NVe.forEach(t),tur=i(X),hE=n(X,"LI",{});var qVe=s(hE);jMe=n(qVe,"STRONG",{});var eDt=s(jMe);aur=r(eDt,"ibert"),eDt.forEach(t),nur=r(qVe," \u2014 "),AJ=n(qVe,"A",{href:!0});var oDt=s(AJ);sur=r(oDt,"IBertForQuestionAnswering"),oDt.forEach(t),lur=r(qVe," (I-BERT model)"),qVe.forEach(t),iur=i(X),uE=n(X,"LI",{});var jVe=s(uE);DMe=n(jVe,"STRONG",{});var rDt=s(DMe);dur=r(rDt,"layoutlmv2"),rDt.forEach(t),cur=r(jVe," \u2014 "),LJ=n(jVe,"A",{href:!0});var tDt=s(LJ);mur=r(tDt,"LayoutLMv2ForQuestionAnswering"),tDt.forEach(t),fur=r(jVe," (LayoutLMv2 model)"),jVe.forEach(t),gur=i(X),pE=n(X,"LI",{});var DVe=s(pE);GMe=n(DVe,"STRONG",{});var aDt=s(GMe);hur=r(aDt,"layoutlmv3"),aDt.forEach(t),uur=r(DVe," \u2014 "),yJ=n(DVe,"A",{href:!0});var nDt=s(yJ);pur=r(nDt,"LayoutLMv3ForQuestionAnswering"),nDt.forEach(t),_ur=r(DVe," (LayoutLMv3 model)"),DVe.forEach(t),bur=i(X),_E=n(X,"LI",{});var GVe=s(_E);OMe=n(GVe,"STRONG",{});var sDt=s(OMe);vur=r(sDt,"led"),sDt.forEach(t),Fur=r(GVe," \u2014 "),xJ=n(GVe,"A",{href:!0});var lDt=s(xJ);Tur=r(lDt,"LEDForQuestionAnswering"),lDt.forEach(t),Mur=r(GVe," (LED model)"),GVe.forEach(t),Eur=i(X),bE=n(X,"LI",{});var OVe=s(bE);VMe=n(OVe,"STRONG",{});var iDt=s(VMe);Cur=r(iDt,"longformer"),iDt.forEach(t),wur=r(OVe," \u2014 "),$J=n(OVe,"A",{href:!0});var dDt=s($J);Aur=r(dDt,"LongformerForQuestionAnswering"),dDt.forEach(t),Lur=r(OVe," (Longformer model)"),OVe.forEach(t),yur=i(X),vE=n(X,"LI",{});var VVe=s(vE);XMe=n(VVe,"STRONG",{});var cDt=s(XMe);xur=r(cDt,"luke"),cDt.forEach(t),$ur=r(VVe," \u2014 "),kJ=n(VVe,"A",{href:!0});var mDt=s(kJ);kur=r(mDt,"LukeForQuestionAnswering"),mDt.forEach(t),Sur=r(VVe," (LUKE model)"),VVe.forEach(t),Rur=i(X),FE=n(X,"LI",{});var XVe=s(FE);zMe=n(XVe,"STRONG",{});var fDt=s(zMe);Pur=r(fDt,"lxmert"),fDt.forEach(t),Bur=r(XVe," \u2014 "),SJ=n(XVe,"A",{href:!0});var gDt=s(SJ);Iur=r(gDt,"LxmertForQuestionAnswering"),gDt.forEach(t),Nur=r(XVe," (LXMERT model)"),XVe.forEach(t),qur=i(X),TE=n(X,"LI",{});var zVe=s(TE);QMe=n(zVe,"STRONG",{});var hDt=s(QMe);jur=r(hDt,"mbart"),hDt.forEach(t),Dur=r(zVe," \u2014 "),RJ=n(zVe,"A",{href:!0});var uDt=s(RJ);Gur=r(uDt,"MBartForQuestionAnswering"),uDt.forEach(t),Our=r(zVe," (mBART model)"),zVe.forEach(t),Vur=i(X),ME=n(X,"LI",{});var QVe=s(ME);WMe=n(QVe,"STRONG",{});var pDt=s(WMe);Xur=r(pDt,"megatron-bert"),pDt.forEach(t),zur=r(QVe," \u2014 "),PJ=n(QVe,"A",{href:!0});var _Dt=s(PJ);Qur=r(_Dt,"MegatronBertForQuestionAnswering"),_Dt.forEach(t),Wur=r(QVe," (Megatron-BERT model)"),QVe.forEach(t),Uur=i(X),EE=n(X,"LI",{});var WVe=s(EE);UMe=n(WVe,"STRONG",{});var bDt=s(UMe);Hur=r(bDt,"mobilebert"),bDt.forEach(t),Jur=r(WVe," \u2014 "),BJ=n(WVe,"A",{href:!0});var vDt=s(BJ);Yur=r(vDt,"MobileBertForQuestionAnswering"),vDt.forEach(t),Kur=r(WVe," (MobileBERT model)"),WVe.forEach(t),Zur=i(X),CE=n(X,"LI",{});var UVe=s(CE);HMe=n(UVe,"STRONG",{});var FDt=s(HMe);epr=r(FDt,"mpnet"),FDt.forEach(t),opr=r(UVe," \u2014 "),IJ=n(UVe,"A",{href:!0});var TDt=s(IJ);rpr=r(TDt,"MPNetForQuestionAnswering"),TDt.forEach(t),tpr=r(UVe," (MPNet model)"),UVe.forEach(t),apr=i(X),wE=n(X,"LI",{});var HVe=s(wE);JMe=n(HVe,"STRONG",{});var MDt=s(JMe);npr=r(MDt,"mvp"),MDt.forEach(t),spr=r(HVe," \u2014 "),NJ=n(HVe,"A",{href:!0});var EDt=s(NJ);lpr=r(EDt,"MvpForQuestionAnswering"),EDt.forEach(t),ipr=r(HVe," (MVP model)"),HVe.forEach(t),dpr=i(X),AE=n(X,"LI",{});var JVe=s(AE);YMe=n(JVe,"STRONG",{});var CDt=s(YMe);cpr=r(CDt,"nezha"),CDt.forEach(t),mpr=r(JVe," \u2014 "),qJ=n(JVe,"A",{href:!0});var wDt=s(qJ);fpr=r(wDt,"NezhaForQuestionAnswering"),wDt.forEach(t),gpr=r(JVe," (Nezha model)"),JVe.forEach(t),hpr=i(X),LE=n(X,"LI",{});var YVe=s(LE);KMe=n(YVe,"STRONG",{});var ADt=s(KMe);upr=r(ADt,"nystromformer"),ADt.forEach(t),ppr=r(YVe," \u2014 "),jJ=n(YVe,"A",{href:!0});var LDt=s(jJ);_pr=r(LDt,"NystromformerForQuestionAnswering"),LDt.forEach(t),bpr=r(YVe," (Nystr\xF6mformer model)"),YVe.forEach(t),vpr=i(X),yE=n(X,"LI",{});var KVe=s(yE);ZMe=n(KVe,"STRONG",{});var yDt=s(ZMe);Fpr=r(yDt,"qdqbert"),yDt.forEach(t),Tpr=r(KVe," \u2014 "),DJ=n(KVe,"A",{href:!0});var xDt=s(DJ);Mpr=r(xDt,"QDQBertForQuestionAnswering"),xDt.forEach(t),Epr=r(KVe," (QDQBert model)"),KVe.forEach(t),Cpr=i(X),xE=n(X,"LI",{});var ZVe=s(xE);eEe=n(ZVe,"STRONG",{});var $Dt=s(eEe);wpr=r($Dt,"reformer"),$Dt.forEach(t),Apr=r(ZVe," \u2014 "),GJ=n(ZVe,"A",{href:!0});var kDt=s(GJ);Lpr=r(kDt,"ReformerForQuestionAnswering"),kDt.forEach(t),ypr=r(ZVe," (Reformer model)"),ZVe.forEach(t),xpr=i(X),$E=n(X,"LI",{});var eXe=s($E);oEe=n(eXe,"STRONG",{});var SDt=s(oEe);$pr=r(SDt,"rembert"),SDt.forEach(t),kpr=r(eXe," \u2014 "),OJ=n(eXe,"A",{href:!0});var RDt=s(OJ);Spr=r(RDt,"RemBertForQuestionAnswering"),RDt.forEach(t),Rpr=r(eXe," (RemBERT model)"),eXe.forEach(t),Ppr=i(X),kE=n(X,"LI",{});var oXe=s(kE);rEe=n(oXe,"STRONG",{});var PDt=s(rEe);Bpr=r(PDt,"roberta"),PDt.forEach(t),Ipr=r(oXe," \u2014 "),VJ=n(oXe,"A",{href:!0});var BDt=s(VJ);Npr=r(BDt,"RobertaForQuestionAnswering"),BDt.forEach(t),qpr=r(oXe," (RoBERTa model)"),oXe.forEach(t),jpr=i(X),SE=n(X,"LI",{});var rXe=s(SE);tEe=n(rXe,"STRONG",{});var IDt=s(tEe);Dpr=r(IDt,"roformer"),IDt.forEach(t),Gpr=r(rXe," \u2014 "),XJ=n(rXe,"A",{href:!0});var NDt=s(XJ);Opr=r(NDt,"RoFormerForQuestionAnswering"),NDt.forEach(t),Vpr=r(rXe," (RoFormer model)"),rXe.forEach(t),Xpr=i(X),RE=n(X,"LI",{});var tXe=s(RE);aEe=n(tXe,"STRONG",{});var qDt=s(aEe);zpr=r(qDt,"splinter"),qDt.forEach(t),Qpr=r(tXe," \u2014 "),zJ=n(tXe,"A",{href:!0});var jDt=s(zJ);Wpr=r(jDt,"SplinterForQuestionAnswering"),jDt.forEach(t),Upr=r(tXe," (Splinter model)"),tXe.forEach(t),Hpr=i(X),PE=n(X,"LI",{});var aXe=s(PE);nEe=n(aXe,"STRONG",{});var DDt=s(nEe);Jpr=r(DDt,"squeezebert"),DDt.forEach(t),Ypr=r(aXe," \u2014 "),QJ=n(aXe,"A",{href:!0});var GDt=s(QJ);Kpr=r(GDt,"SqueezeBertForQuestionAnswering"),GDt.forEach(t),Zpr=r(aXe," (SqueezeBERT model)"),aXe.forEach(t),e_r=i(X),BE=n(X,"LI",{});var nXe=s(BE);sEe=n(nXe,"STRONG",{});var ODt=s(sEe);o_r=r(ODt,"xlm"),ODt.forEach(t),r_r=r(nXe," \u2014 "),WJ=n(nXe,"A",{href:!0});var VDt=s(WJ);t_r=r(VDt,"XLMForQuestionAnsweringSimple"),VDt.forEach(t),a_r=r(nXe," (XLM model)"),nXe.forEach(t),n_r=i(X),IE=n(X,"LI",{});var sXe=s(IE);lEe=n(sXe,"STRONG",{});var XDt=s(lEe);s_r=r(XDt,"xlm-roberta"),XDt.forEach(t),l_r=r(sXe," \u2014 "),UJ=n(sXe,"A",{href:!0});var zDt=s(UJ);i_r=r(zDt,"XLMRobertaForQuestionAnswering"),zDt.forEach(t),d_r=r(sXe," (XLM-RoBERTa model)"),sXe.forEach(t),c_r=i(X),NE=n(X,"LI",{});var lXe=s(NE);iEe=n(lXe,"STRONG",{});var QDt=s(iEe);m_r=r(QDt,"xlm-roberta-xl"),QDt.forEach(t),f_r=r(lXe," \u2014 "),HJ=n(lXe,"A",{href:!0});var WDt=s(HJ);g_r=r(WDt,"XLMRobertaXLForQuestionAnswering"),WDt.forEach(t),h_r=r(lXe," (XLM-RoBERTa-XL model)"),lXe.forEach(t),u_r=i(X),qE=n(X,"LI",{});var iXe=s(qE);dEe=n(iXe,"STRONG",{});var UDt=s(dEe);p_r=r(UDt,"xlnet"),UDt.forEach(t),__r=r(iXe," \u2014 "),JJ=n(iXe,"A",{href:!0});var HDt=s(JJ);b_r=r(HDt,"XLNetForQuestionAnsweringSimple"),HDt.forEach(t),v_r=r(iXe," (XLNet model)"),iXe.forEach(t),F_r=i(X),jE=n(X,"LI",{});var dXe=s(jE);cEe=n(dXe,"STRONG",{});var JDt=s(cEe);T_r=r(JDt,"yoso"),JDt.forEach(t),M_r=r(dXe," \u2014 "),YJ=n(dXe,"A",{href:!0});var YDt=s(YJ);E_r=r(YDt,"YosoForQuestionAnswering"),YDt.forEach(t),C_r=r(dXe," (YOSO model)"),dXe.forEach(t),X.forEach(t),w_r=i(xa),DE=n(xa,"P",{});var cXe=s(DE);A_r=r(cXe,"The model is set in evaluation mode by default using "),mEe=n(cXe,"CODE",{});var KDt=s(mEe);L_r=r(KDt,"model.eval()"),KDt.forEach(t),y_r=r(cXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fEe=n(cXe,"CODE",{});var ZDt=s(fEe);x_r=r(ZDt,"model.train()"),ZDt.forEach(t),cXe.forEach(t),$_r=i(xa),T(GE.$$.fragment,xa),xa.forEach(t),Pl.forEach(t),LKe=i(m),Qd=n(m,"H2",{class:!0});var Geo=s(Qd);OE=n(Geo,"A",{id:!0,class:!0,href:!0});var eGt=s(OE);gEe=n(eGt,"SPAN",{});var oGt=s(gEe);T(Jx.$$.fragment,oGt),oGt.forEach(t),eGt.forEach(t),k_r=i(Geo),hEe=n(Geo,"SPAN",{});var rGt=s(hEe);S_r=r(rGt,"AutoModelForTableQuestionAnswering"),rGt.forEach(t),Geo.forEach(t),yKe=i(m),Xo=n(m,"DIV",{class:!0});var Bl=s(Xo);T(Yx.$$.fragment,Bl),R_r=i(Bl),Wd=n(Bl,"P",{});var Tle=s(Wd);P_r=r(Tle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),KJ=n(Tle,"A",{href:!0});var tGt=s(KJ);B_r=r(tGt,"from_pretrained()"),tGt.forEach(t),I_r=r(Tle," class method or the "),ZJ=n(Tle,"A",{href:!0});var aGt=s(ZJ);N_r=r(aGt,"from_config()"),aGt.forEach(t),q_r=r(Tle,` class
method.`),Tle.forEach(t),j_r=i(Bl),Kx=n(Bl,"P",{});var Oeo=s(Kx);D_r=r(Oeo,"This class cannot be instantiated directly using "),uEe=n(Oeo,"CODE",{});var nGt=s(uEe);G_r=r(nGt,"__init__()"),nGt.forEach(t),O_r=r(Oeo," (throws an error)."),Oeo.forEach(t),V_r=i(Bl),Lt=n(Bl,"DIV",{class:!0});var Vy=s(Lt);T(Zx.$$.fragment,Vy),X_r=i(Vy),pEe=n(Vy,"P",{});var sGt=s(pEe);z_r=r(sGt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),sGt.forEach(t),Q_r=i(Vy),Ud=n(Vy,"P",{});var Mle=s(Ud);W_r=r(Mle,`Note:
Loading a model from its configuration file does `),_Ee=n(Mle,"STRONG",{});var lGt=s(_Ee);U_r=r(lGt,"not"),lGt.forEach(t),H_r=r(Mle,` load the model weights. It only affects the
model\u2019s configuration. Use `),eY=n(Mle,"A",{href:!0});var iGt=s(eY);J_r=r(iGt,"from_pretrained()"),iGt.forEach(t),Y_r=r(Mle," to load the model weights."),Mle.forEach(t),K_r=i(Vy),T(VE.$$.fragment,Vy),Vy.forEach(t),Z_r=i(Bl),co=n(Bl,"DIV",{class:!0});var $a=s(co);T(e$.$$.fragment,$a),ebr=i($a),bEe=n($a,"P",{});var dGt=s(bEe);obr=r(dGt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),dGt.forEach(t),rbr=i($a),sn=n($a,"P",{});var Xy=s(sn);tbr=r(Xy,"The model class to instantiate is selected based on the "),vEe=n(Xy,"CODE",{});var cGt=s(vEe);abr=r(cGt,"model_type"),cGt.forEach(t),nbr=r(Xy,` property of the config object (either
passed as an argument or loaded from `),FEe=n(Xy,"CODE",{});var mGt=s(FEe);sbr=r(mGt,"pretrained_model_name_or_path"),mGt.forEach(t),lbr=r(Xy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TEe=n(Xy,"CODE",{});var fGt=s(TEe);ibr=r(fGt,"pretrained_model_name_or_path"),fGt.forEach(t),dbr=r(Xy,":"),Xy.forEach(t),cbr=i($a),MEe=n($a,"UL",{});var gGt=s(MEe);XE=n(gGt,"LI",{});var mXe=s(XE);EEe=n(mXe,"STRONG",{});var hGt=s(EEe);mbr=r(hGt,"tapas"),hGt.forEach(t),fbr=r(mXe," \u2014 "),oY=n(mXe,"A",{href:!0});var uGt=s(oY);gbr=r(uGt,"TapasForQuestionAnswering"),uGt.forEach(t),hbr=r(mXe," (TAPAS model)"),mXe.forEach(t),gGt.forEach(t),ubr=i($a),zE=n($a,"P",{});var fXe=s(zE);pbr=r(fXe,"The model is set in evaluation mode by default using "),CEe=n(fXe,"CODE",{});var pGt=s(CEe);_br=r(pGt,"model.eval()"),pGt.forEach(t),bbr=r(fXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wEe=n(fXe,"CODE",{});var _Gt=s(wEe);vbr=r(_Gt,"model.train()"),_Gt.forEach(t),fXe.forEach(t),Fbr=i($a),T(QE.$$.fragment,$a),$a.forEach(t),Bl.forEach(t),xKe=i(m),Hd=n(m,"H2",{class:!0});var Veo=s(Hd);WE=n(Veo,"A",{id:!0,class:!0,href:!0});var bGt=s(WE);AEe=n(bGt,"SPAN",{});var vGt=s(AEe);T(o$.$$.fragment,vGt),vGt.forEach(t),bGt.forEach(t),Tbr=i(Veo),LEe=n(Veo,"SPAN",{});var FGt=s(LEe);Mbr=r(FGt,"AutoModelForDocumentQuestionAnswering"),FGt.forEach(t),Veo.forEach(t),$Ke=i(m),zo=n(m,"DIV",{class:!0});var Il=s(zo);T(r$.$$.fragment,Il),Ebr=i(Il),Jd=n(Il,"P",{});var Ele=s(Jd);Cbr=r(Ele,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),rY=n(Ele,"A",{href:!0});var TGt=s(rY);wbr=r(TGt,"from_pretrained()"),TGt.forEach(t),Abr=r(Ele," class method or the "),tY=n(Ele,"A",{href:!0});var MGt=s(tY);Lbr=r(MGt,"from_config()"),MGt.forEach(t),ybr=r(Ele,` class
method.`),Ele.forEach(t),xbr=i(Il),t$=n(Il,"P",{});var Xeo=s(t$);$br=r(Xeo,"This class cannot be instantiated directly using "),yEe=n(Xeo,"CODE",{});var EGt=s(yEe);kbr=r(EGt,"__init__()"),EGt.forEach(t),Sbr=r(Xeo," (throws an error)."),Xeo.forEach(t),Rbr=i(Il),yt=n(Il,"DIV",{class:!0});var zy=s(yt);T(a$.$$.fragment,zy),Pbr=i(zy),xEe=n(zy,"P",{});var CGt=s(xEe);Bbr=r(CGt,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),CGt.forEach(t),Ibr=i(zy),Yd=n(zy,"P",{});var Cle=s(Yd);Nbr=r(Cle,`Note:
Loading a model from its configuration file does `),$Ee=n(Cle,"STRONG",{});var wGt=s($Ee);qbr=r(wGt,"not"),wGt.forEach(t),jbr=r(Cle,` load the model weights. It only affects the
model\u2019s configuration. Use `),aY=n(Cle,"A",{href:!0});var AGt=s(aY);Dbr=r(AGt,"from_pretrained()"),AGt.forEach(t),Gbr=r(Cle," to load the model weights."),Cle.forEach(t),Obr=i(zy),T(UE.$$.fragment,zy),zy.forEach(t),Vbr=i(Il),mo=n(Il,"DIV",{class:!0});var ka=s(mo);T(n$.$$.fragment,ka),Xbr=i(ka),kEe=n(ka,"P",{});var LGt=s(kEe);zbr=r(LGt,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),LGt.forEach(t),Qbr=i(ka),ln=n(ka,"P",{});var Qy=s(ln);Wbr=r(Qy,"The model class to instantiate is selected based on the "),SEe=n(Qy,"CODE",{});var yGt=s(SEe);Ubr=r(yGt,"model_type"),yGt.forEach(t),Hbr=r(Qy,` property of the config object (either
passed as an argument or loaded from `),REe=n(Qy,"CODE",{});var xGt=s(REe);Jbr=r(xGt,"pretrained_model_name_or_path"),xGt.forEach(t),Ybr=r(Qy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PEe=n(Qy,"CODE",{});var $Gt=s(PEe);Kbr=r($Gt,"pretrained_model_name_or_path"),$Gt.forEach(t),Zbr=r(Qy,":"),Qy.forEach(t),e2r=i(ka),Kd=n(ka,"UL",{});var wle=s(Kd);HE=n(wle,"LI",{});var gXe=s(HE);BEe=n(gXe,"STRONG",{});var kGt=s(BEe);o2r=r(kGt,"layoutlm"),kGt.forEach(t),r2r=r(gXe," \u2014 "),nY=n(gXe,"A",{href:!0});var SGt=s(nY);t2r=r(SGt,"LayoutLMForQuestionAnswering"),SGt.forEach(t),a2r=r(gXe," (LayoutLM model)"),gXe.forEach(t),n2r=i(wle),JE=n(wle,"LI",{});var hXe=s(JE);IEe=n(hXe,"STRONG",{});var RGt=s(IEe);s2r=r(RGt,"layoutlmv2"),RGt.forEach(t),l2r=r(hXe," \u2014 "),sY=n(hXe,"A",{href:!0});var PGt=s(sY);i2r=r(PGt,"LayoutLMv2ForQuestionAnswering"),PGt.forEach(t),d2r=r(hXe," (LayoutLMv2 model)"),hXe.forEach(t),c2r=i(wle),YE=n(wle,"LI",{});var uXe=s(YE);NEe=n(uXe,"STRONG",{});var BGt=s(NEe);m2r=r(BGt,"layoutlmv3"),BGt.forEach(t),f2r=r(uXe," \u2014 "),lY=n(uXe,"A",{href:!0});var IGt=s(lY);g2r=r(IGt,"LayoutLMv3ForQuestionAnswering"),IGt.forEach(t),h2r=r(uXe," (LayoutLMv3 model)"),uXe.forEach(t),wle.forEach(t),u2r=i(ka),KE=n(ka,"P",{});var pXe=s(KE);p2r=r(pXe,"The model is set in evaluation mode by default using "),qEe=n(pXe,"CODE",{});var NGt=s(qEe);_2r=r(NGt,"model.eval()"),NGt.forEach(t),b2r=r(pXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),jEe=n(pXe,"CODE",{});var qGt=s(jEe);v2r=r(qGt,"model.train()"),qGt.forEach(t),pXe.forEach(t),F2r=i(ka),T(ZE.$$.fragment,ka),ka.forEach(t),Il.forEach(t),kKe=i(m),Zd=n(m,"H2",{class:!0});var zeo=s(Zd);e4=n(zeo,"A",{id:!0,class:!0,href:!0});var jGt=s(e4);DEe=n(jGt,"SPAN",{});var DGt=s(DEe);T(s$.$$.fragment,DGt),DGt.forEach(t),jGt.forEach(t),T2r=i(zeo),GEe=n(zeo,"SPAN",{});var GGt=s(GEe);M2r=r(GGt,"AutoModelForImageClassification"),GGt.forEach(t),zeo.forEach(t),SKe=i(m),Qo=n(m,"DIV",{class:!0});var Nl=s(Qo);T(l$.$$.fragment,Nl),E2r=i(Nl),ec=n(Nl,"P",{});var Ale=s(ec);C2r=r(Ale,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),iY=n(Ale,"A",{href:!0});var OGt=s(iY);w2r=r(OGt,"from_pretrained()"),OGt.forEach(t),A2r=r(Ale," class method or the "),dY=n(Ale,"A",{href:!0});var VGt=s(dY);L2r=r(VGt,"from_config()"),VGt.forEach(t),y2r=r(Ale,` class
method.`),Ale.forEach(t),x2r=i(Nl),i$=n(Nl,"P",{});var Qeo=s(i$);$2r=r(Qeo,"This class cannot be instantiated directly using "),OEe=n(Qeo,"CODE",{});var XGt=s(OEe);k2r=r(XGt,"__init__()"),XGt.forEach(t),S2r=r(Qeo," (throws an error)."),Qeo.forEach(t),R2r=i(Nl),xt=n(Nl,"DIV",{class:!0});var Wy=s(xt);T(d$.$$.fragment,Wy),P2r=i(Wy),VEe=n(Wy,"P",{});var zGt=s(VEe);B2r=r(zGt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),zGt.forEach(t),I2r=i(Wy),oc=n(Wy,"P",{});var Lle=s(oc);N2r=r(Lle,`Note:
Loading a model from its configuration file does `),XEe=n(Lle,"STRONG",{});var QGt=s(XEe);q2r=r(QGt,"not"),QGt.forEach(t),j2r=r(Lle,` load the model weights. It only affects the
model\u2019s configuration. Use `),cY=n(Lle,"A",{href:!0});var WGt=s(cY);D2r=r(WGt,"from_pretrained()"),WGt.forEach(t),G2r=r(Lle," to load the model weights."),Lle.forEach(t),O2r=i(Wy),T(o4.$$.fragment,Wy),Wy.forEach(t),V2r=i(Nl),fo=n(Nl,"DIV",{class:!0});var Sa=s(fo);T(c$.$$.fragment,Sa),X2r=i(Sa),zEe=n(Sa,"P",{});var UGt=s(zEe);z2r=r(UGt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),UGt.forEach(t),Q2r=i(Sa),dn=n(Sa,"P",{});var Uy=s(dn);W2r=r(Uy,"The model class to instantiate is selected based on the "),QEe=n(Uy,"CODE",{});var HGt=s(QEe);U2r=r(HGt,"model_type"),HGt.forEach(t),H2r=r(Uy,` property of the config object (either
passed as an argument or loaded from `),WEe=n(Uy,"CODE",{});var JGt=s(WEe);J2r=r(JGt,"pretrained_model_name_or_path"),JGt.forEach(t),Y2r=r(Uy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),UEe=n(Uy,"CODE",{});var YGt=s(UEe);K2r=r(YGt,"pretrained_model_name_or_path"),YGt.forEach(t),Z2r=r(Uy,":"),Uy.forEach(t),e1r=i(Sa),be=n(Sa,"UL",{});var Fe=s(be);r4=n(Fe,"LI",{});var _Xe=s(r4);HEe=n(_Xe,"STRONG",{});var KGt=s(HEe);o1r=r(KGt,"beit"),KGt.forEach(t),r1r=r(_Xe," \u2014 "),mY=n(_Xe,"A",{href:!0});var ZGt=s(mY);t1r=r(ZGt,"BeitForImageClassification"),ZGt.forEach(t),a1r=r(_Xe," (BEiT model)"),_Xe.forEach(t),n1r=i(Fe),t4=n(Fe,"LI",{});var bXe=s(t4);JEe=n(bXe,"STRONG",{});var eOt=s(JEe);s1r=r(eOt,"convnext"),eOt.forEach(t),l1r=r(bXe," \u2014 "),fY=n(bXe,"A",{href:!0});var oOt=s(fY);i1r=r(oOt,"ConvNextForImageClassification"),oOt.forEach(t),d1r=r(bXe," (ConvNeXT model)"),bXe.forEach(t),c1r=i(Fe),a4=n(Fe,"LI",{});var vXe=s(a4);YEe=n(vXe,"STRONG",{});var rOt=s(YEe);m1r=r(rOt,"cvt"),rOt.forEach(t),f1r=r(vXe," \u2014 "),gY=n(vXe,"A",{href:!0});var tOt=s(gY);g1r=r(tOt,"CvtForImageClassification"),tOt.forEach(t),h1r=r(vXe," (CvT model)"),vXe.forEach(t),u1r=i(Fe),n4=n(Fe,"LI",{});var FXe=s(n4);KEe=n(FXe,"STRONG",{});var aOt=s(KEe);p1r=r(aOt,"data2vec-vision"),aOt.forEach(t),_1r=r(FXe," \u2014 "),hY=n(FXe,"A",{href:!0});var nOt=s(hY);b1r=r(nOt,"Data2VecVisionForImageClassification"),nOt.forEach(t),v1r=r(FXe," (Data2VecVision model)"),FXe.forEach(t),F1r=i(Fe),_l=n(Fe,"LI",{});var CB=s(_l);ZEe=n(CB,"STRONG",{});var sOt=s(ZEe);T1r=r(sOt,"deit"),sOt.forEach(t),M1r=r(CB," \u2014 "),uY=n(CB,"A",{href:!0});var lOt=s(uY);E1r=r(lOt,"DeiTForImageClassification"),lOt.forEach(t),C1r=r(CB," or "),pY=n(CB,"A",{href:!0});var iOt=s(pY);w1r=r(iOt,"DeiTForImageClassificationWithTeacher"),iOt.forEach(t),A1r=r(CB," (DeiT model)"),CB.forEach(t),L1r=i(Fe),s4=n(Fe,"LI",{});var TXe=s(s4);e4e=n(TXe,"STRONG",{});var dOt=s(e4e);y1r=r(dOt,"imagegpt"),dOt.forEach(t),x1r=r(TXe," \u2014 "),_Y=n(TXe,"A",{href:!0});var cOt=s(_Y);$1r=r(cOt,"ImageGPTForImageClassification"),cOt.forEach(t),k1r=r(TXe," (ImageGPT model)"),TXe.forEach(t),S1r=i(Fe),bl=n(Fe,"LI",{});var wB=s(bl);o4e=n(wB,"STRONG",{});var mOt=s(o4e);R1r=r(mOt,"levit"),mOt.forEach(t),P1r=r(wB," \u2014 "),bY=n(wB,"A",{href:!0});var fOt=s(bY);B1r=r(fOt,"LevitForImageClassification"),fOt.forEach(t),I1r=r(wB," or "),vY=n(wB,"A",{href:!0});var gOt=s(vY);N1r=r(gOt,"LevitForImageClassificationWithTeacher"),gOt.forEach(t),q1r=r(wB," (LeViT model)"),wB.forEach(t),j1r=i(Fe),l4=n(Fe,"LI",{});var MXe=s(l4);r4e=n(MXe,"STRONG",{});var hOt=s(r4e);D1r=r(hOt,"mobilevit"),hOt.forEach(t),G1r=r(MXe," \u2014 "),FY=n(MXe,"A",{href:!0});var uOt=s(FY);O1r=r(uOt,"MobileViTForImageClassification"),uOt.forEach(t),V1r=r(MXe," (MobileViT model)"),MXe.forEach(t),X1r=i(Fe),$t=n(Fe,"LI",{});var Mf=s($t);t4e=n(Mf,"STRONG",{});var pOt=s(t4e);z1r=r(pOt,"perceiver"),pOt.forEach(t),Q1r=r(Mf," \u2014 "),TY=n(Mf,"A",{href:!0});var _Ot=s(TY);W1r=r(_Ot,"PerceiverForImageClassificationLearned"),_Ot.forEach(t),U1r=r(Mf," or "),MY=n(Mf,"A",{href:!0});var bOt=s(MY);H1r=r(bOt,"PerceiverForImageClassificationFourier"),bOt.forEach(t),J1r=r(Mf," or "),EY=n(Mf,"A",{href:!0});var vOt=s(EY);Y1r=r(vOt,"PerceiverForImageClassificationConvProcessing"),vOt.forEach(t),K1r=r(Mf," (Perceiver model)"),Mf.forEach(t),Z1r=i(Fe),i4=n(Fe,"LI",{});var EXe=s(i4);a4e=n(EXe,"STRONG",{});var FOt=s(a4e);evr=r(FOt,"poolformer"),FOt.forEach(t),ovr=r(EXe," \u2014 "),CY=n(EXe,"A",{href:!0});var TOt=s(CY);rvr=r(TOt,"PoolFormerForImageClassification"),TOt.forEach(t),tvr=r(EXe," (PoolFormer model)"),EXe.forEach(t),avr=i(Fe),d4=n(Fe,"LI",{});var CXe=s(d4);n4e=n(CXe,"STRONG",{});var MOt=s(n4e);nvr=r(MOt,"regnet"),MOt.forEach(t),svr=r(CXe," \u2014 "),wY=n(CXe,"A",{href:!0});var EOt=s(wY);lvr=r(EOt,"RegNetForImageClassification"),EOt.forEach(t),ivr=r(CXe," (RegNet model)"),CXe.forEach(t),dvr=i(Fe),c4=n(Fe,"LI",{});var wXe=s(c4);s4e=n(wXe,"STRONG",{});var COt=s(s4e);cvr=r(COt,"resnet"),COt.forEach(t),mvr=r(wXe," \u2014 "),AY=n(wXe,"A",{href:!0});var wOt=s(AY);fvr=r(wOt,"ResNetForImageClassification"),wOt.forEach(t),gvr=r(wXe," (ResNet model)"),wXe.forEach(t),hvr=i(Fe),m4=n(Fe,"LI",{});var AXe=s(m4);l4e=n(AXe,"STRONG",{});var AOt=s(l4e);uvr=r(AOt,"segformer"),AOt.forEach(t),pvr=r(AXe," \u2014 "),LY=n(AXe,"A",{href:!0});var LOt=s(LY);_vr=r(LOt,"SegformerForImageClassification"),LOt.forEach(t),bvr=r(AXe," (SegFormer model)"),AXe.forEach(t),vvr=i(Fe),f4=n(Fe,"LI",{});var LXe=s(f4);i4e=n(LXe,"STRONG",{});var yOt=s(i4e);Fvr=r(yOt,"swin"),yOt.forEach(t),Tvr=r(LXe," \u2014 "),yY=n(LXe,"A",{href:!0});var xOt=s(yY);Mvr=r(xOt,"SwinForImageClassification"),xOt.forEach(t),Evr=r(LXe," (Swin Transformer model)"),LXe.forEach(t),Cvr=i(Fe),g4=n(Fe,"LI",{});var yXe=s(g4);d4e=n(yXe,"STRONG",{});var $Ot=s(d4e);wvr=r($Ot,"swinv2"),$Ot.forEach(t),Avr=r(yXe," \u2014 "),xY=n(yXe,"A",{href:!0});var kOt=s(xY);Lvr=r(kOt,"Swinv2ForImageClassification"),kOt.forEach(t),yvr=r(yXe," (Swin Transformer V2 model)"),yXe.forEach(t),xvr=i(Fe),h4=n(Fe,"LI",{});var xXe=s(h4);c4e=n(xXe,"STRONG",{});var SOt=s(c4e);$vr=r(SOt,"van"),SOt.forEach(t),kvr=r(xXe," \u2014 "),$Y=n(xXe,"A",{href:!0});var ROt=s($Y);Svr=r(ROt,"VanForImageClassification"),ROt.forEach(t),Rvr=r(xXe," (VAN model)"),xXe.forEach(t),Pvr=i(Fe),u4=n(Fe,"LI",{});var $Xe=s(u4);m4e=n($Xe,"STRONG",{});var POt=s(m4e);Bvr=r(POt,"vit"),POt.forEach(t),Ivr=r($Xe," \u2014 "),kY=n($Xe,"A",{href:!0});var BOt=s(kY);Nvr=r(BOt,"ViTForImageClassification"),BOt.forEach(t),qvr=r($Xe," (ViT model)"),$Xe.forEach(t),Fe.forEach(t),jvr=i(Sa),p4=n(Sa,"P",{});var kXe=s(p4);Dvr=r(kXe,"The model is set in evaluation mode by default using "),f4e=n(kXe,"CODE",{});var IOt=s(f4e);Gvr=r(IOt,"model.eval()"),IOt.forEach(t),Ovr=r(kXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),g4e=n(kXe,"CODE",{});var NOt=s(g4e);Vvr=r(NOt,"model.train()"),NOt.forEach(t),kXe.forEach(t),Xvr=i(Sa),T(_4.$$.fragment,Sa),Sa.forEach(t),Nl.forEach(t),RKe=i(m),rc=n(m,"H2",{class:!0});var Weo=s(rc);b4=n(Weo,"A",{id:!0,class:!0,href:!0});var qOt=s(b4);h4e=n(qOt,"SPAN",{});var jOt=s(h4e);T(m$.$$.fragment,jOt),jOt.forEach(t),qOt.forEach(t),zvr=i(Weo),u4e=n(Weo,"SPAN",{});var DOt=s(u4e);Qvr=r(DOt,"AutoModelForVideoClassification"),DOt.forEach(t),Weo.forEach(t),PKe=i(m),Wo=n(m,"DIV",{class:!0});var ql=s(Wo);T(f$.$$.fragment,ql),Wvr=i(ql),tc=n(ql,"P",{});var yle=s(tc);Uvr=r(yle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),SY=n(yle,"A",{href:!0});var GOt=s(SY);Hvr=r(GOt,"from_pretrained()"),GOt.forEach(t),Jvr=r(yle," class method or the "),RY=n(yle,"A",{href:!0});var OOt=s(RY);Yvr=r(OOt,"from_config()"),OOt.forEach(t),Kvr=r(yle,` class
method.`),yle.forEach(t),Zvr=i(ql),g$=n(ql,"P",{});var Ueo=s(g$);eFr=r(Ueo,"This class cannot be instantiated directly using "),p4e=n(Ueo,"CODE",{});var VOt=s(p4e);oFr=r(VOt,"__init__()"),VOt.forEach(t),rFr=r(Ueo," (throws an error)."),Ueo.forEach(t),tFr=i(ql),kt=n(ql,"DIV",{class:!0});var Hy=s(kt);T(h$.$$.fragment,Hy),aFr=i(Hy),_4e=n(Hy,"P",{});var XOt=s(_4e);nFr=r(XOt,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),XOt.forEach(t),sFr=i(Hy),ac=n(Hy,"P",{});var xle=s(ac);lFr=r(xle,`Note:
Loading a model from its configuration file does `),b4e=n(xle,"STRONG",{});var zOt=s(b4e);iFr=r(zOt,"not"),zOt.forEach(t),dFr=r(xle,` load the model weights. It only affects the
model\u2019s configuration. Use `),PY=n(xle,"A",{href:!0});var QOt=s(PY);cFr=r(QOt,"from_pretrained()"),QOt.forEach(t),mFr=r(xle," to load the model weights."),xle.forEach(t),fFr=i(Hy),T(v4.$$.fragment,Hy),Hy.forEach(t),gFr=i(ql),go=n(ql,"DIV",{class:!0});var Ra=s(go);T(u$.$$.fragment,Ra),hFr=i(Ra),v4e=n(Ra,"P",{});var WOt=s(v4e);uFr=r(WOt,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),WOt.forEach(t),pFr=i(Ra),cn=n(Ra,"P",{});var Jy=s(cn);_Fr=r(Jy,"The model class to instantiate is selected based on the "),F4e=n(Jy,"CODE",{});var UOt=s(F4e);bFr=r(UOt,"model_type"),UOt.forEach(t),vFr=r(Jy,` property of the config object (either
passed as an argument or loaded from `),T4e=n(Jy,"CODE",{});var HOt=s(T4e);FFr=r(HOt,"pretrained_model_name_or_path"),HOt.forEach(t),TFr=r(Jy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M4e=n(Jy,"CODE",{});var JOt=s(M4e);MFr=r(JOt,"pretrained_model_name_or_path"),JOt.forEach(t),EFr=r(Jy,":"),Jy.forEach(t),CFr=i(Ra),E4e=n(Ra,"UL",{});var YOt=s(E4e);F4=n(YOt,"LI",{});var SXe=s(F4);C4e=n(SXe,"STRONG",{});var KOt=s(C4e);wFr=r(KOt,"videomae"),KOt.forEach(t),AFr=r(SXe," \u2014 "),BY=n(SXe,"A",{href:!0});var ZOt=s(BY);LFr=r(ZOt,"VideoMAEForVideoClassification"),ZOt.forEach(t),yFr=r(SXe," (VideoMAE model)"),SXe.forEach(t),YOt.forEach(t),xFr=i(Ra),T4=n(Ra,"P",{});var RXe=s(T4);$Fr=r(RXe,"The model is set in evaluation mode by default using "),w4e=n(RXe,"CODE",{});var eVt=s(w4e);kFr=r(eVt,"model.eval()"),eVt.forEach(t),SFr=r(RXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),A4e=n(RXe,"CODE",{});var oVt=s(A4e);RFr=r(oVt,"model.train()"),oVt.forEach(t),RXe.forEach(t),PFr=i(Ra),T(M4.$$.fragment,Ra),Ra.forEach(t),ql.forEach(t),BKe=i(m),nc=n(m,"H2",{class:!0});var Heo=s(nc);E4=n(Heo,"A",{id:!0,class:!0,href:!0});var rVt=s(E4);L4e=n(rVt,"SPAN",{});var tVt=s(L4e);T(p$.$$.fragment,tVt),tVt.forEach(t),rVt.forEach(t),BFr=i(Heo),y4e=n(Heo,"SPAN",{});var aVt=s(y4e);IFr=r(aVt,"AutoModelForVision2Seq"),aVt.forEach(t),Heo.forEach(t),IKe=i(m),Uo=n(m,"DIV",{class:!0});var jl=s(Uo);T(_$.$$.fragment,jl),NFr=i(jl),sc=n(jl,"P",{});var $le=s(sc);qFr=r($le,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),IY=n($le,"A",{href:!0});var nVt=s(IY);jFr=r(nVt,"from_pretrained()"),nVt.forEach(t),DFr=r($le," class method or the "),NY=n($le,"A",{href:!0});var sVt=s(NY);GFr=r(sVt,"from_config()"),sVt.forEach(t),OFr=r($le,` class
method.`),$le.forEach(t),VFr=i(jl),b$=n(jl,"P",{});var Jeo=s(b$);XFr=r(Jeo,"This class cannot be instantiated directly using "),x4e=n(Jeo,"CODE",{});var lVt=s(x4e);zFr=r(lVt,"__init__()"),lVt.forEach(t),QFr=r(Jeo," (throws an error)."),Jeo.forEach(t),WFr=i(jl),St=n(jl,"DIV",{class:!0});var Yy=s(St);T(v$.$$.fragment,Yy),UFr=i(Yy),$4e=n(Yy,"P",{});var iVt=s($4e);HFr=r(iVt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),iVt.forEach(t),JFr=i(Yy),lc=n(Yy,"P",{});var kle=s(lc);YFr=r(kle,`Note:
Loading a model from its configuration file does `),k4e=n(kle,"STRONG",{});var dVt=s(k4e);KFr=r(dVt,"not"),dVt.forEach(t),ZFr=r(kle,` load the model weights. It only affects the
model\u2019s configuration. Use `),qY=n(kle,"A",{href:!0});var cVt=s(qY);eTr=r(cVt,"from_pretrained()"),cVt.forEach(t),oTr=r(kle," to load the model weights."),kle.forEach(t),rTr=i(Yy),T(C4.$$.fragment,Yy),Yy.forEach(t),tTr=i(jl),ho=n(jl,"DIV",{class:!0});var Pa=s(ho);T(F$.$$.fragment,Pa),aTr=i(Pa),S4e=n(Pa,"P",{});var mVt=s(S4e);nTr=r(mVt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),mVt.forEach(t),sTr=i(Pa),mn=n(Pa,"P",{});var Ky=s(mn);lTr=r(Ky,"The model class to instantiate is selected based on the "),R4e=n(Ky,"CODE",{});var fVt=s(R4e);iTr=r(fVt,"model_type"),fVt.forEach(t),dTr=r(Ky,` property of the config object (either
passed as an argument or loaded from `),P4e=n(Ky,"CODE",{});var gVt=s(P4e);cTr=r(gVt,"pretrained_model_name_or_path"),gVt.forEach(t),mTr=r(Ky,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B4e=n(Ky,"CODE",{});var hVt=s(B4e);fTr=r(hVt,"pretrained_model_name_or_path"),hVt.forEach(t),gTr=r(Ky,":"),Ky.forEach(t),hTr=i(Pa),I4e=n(Pa,"UL",{});var uVt=s(I4e);w4=n(uVt,"LI",{});var PXe=s(w4);N4e=n(PXe,"STRONG",{});var pVt=s(N4e);uTr=r(pVt,"vision-encoder-decoder"),pVt.forEach(t),pTr=r(PXe," \u2014 "),jY=n(PXe,"A",{href:!0});var _Vt=s(jY);_Tr=r(_Vt,"VisionEncoderDecoderModel"),_Vt.forEach(t),bTr=r(PXe," (Vision Encoder decoder model)"),PXe.forEach(t),uVt.forEach(t),vTr=i(Pa),A4=n(Pa,"P",{});var BXe=s(A4);FTr=r(BXe,"The model is set in evaluation mode by default using "),q4e=n(BXe,"CODE",{});var bVt=s(q4e);TTr=r(bVt,"model.eval()"),bVt.forEach(t),MTr=r(BXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j4e=n(BXe,"CODE",{});var vVt=s(j4e);ETr=r(vVt,"model.train()"),vVt.forEach(t),BXe.forEach(t),CTr=i(Pa),T(L4.$$.fragment,Pa),Pa.forEach(t),jl.forEach(t),NKe=i(m),ic=n(m,"H2",{class:!0});var Yeo=s(ic);y4=n(Yeo,"A",{id:!0,class:!0,href:!0});var FVt=s(y4);D4e=n(FVt,"SPAN",{});var TVt=s(D4e);T(T$.$$.fragment,TVt),TVt.forEach(t),FVt.forEach(t),wTr=i(Yeo),G4e=n(Yeo,"SPAN",{});var MVt=s(G4e);ATr=r(MVt,"AutoModelForVisualQuestionAnswering"),MVt.forEach(t),Yeo.forEach(t),qKe=i(m),Ho=n(m,"DIV",{class:!0});var Dl=s(Ho);T(M$.$$.fragment,Dl),LTr=i(Dl),dc=n(Dl,"P",{});var Sle=s(dc);yTr=r(Sle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),DY=n(Sle,"A",{href:!0});var EVt=s(DY);xTr=r(EVt,"from_pretrained()"),EVt.forEach(t),$Tr=r(Sle," class method or the "),GY=n(Sle,"A",{href:!0});var CVt=s(GY);kTr=r(CVt,"from_config()"),CVt.forEach(t),STr=r(Sle,` class
method.`),Sle.forEach(t),RTr=i(Dl),E$=n(Dl,"P",{});var Keo=s(E$);PTr=r(Keo,"This class cannot be instantiated directly using "),O4e=n(Keo,"CODE",{});var wVt=s(O4e);BTr=r(wVt,"__init__()"),wVt.forEach(t),ITr=r(Keo," (throws an error)."),Keo.forEach(t),NTr=i(Dl),Rt=n(Dl,"DIV",{class:!0});var Zy=s(Rt);T(C$.$$.fragment,Zy),qTr=i(Zy),V4e=n(Zy,"P",{});var AVt=s(V4e);jTr=r(AVt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),AVt.forEach(t),DTr=i(Zy),cc=n(Zy,"P",{});var Rle=s(cc);GTr=r(Rle,`Note:
Loading a model from its configuration file does `),X4e=n(Rle,"STRONG",{});var LVt=s(X4e);OTr=r(LVt,"not"),LVt.forEach(t),VTr=r(Rle,` load the model weights. It only affects the
model\u2019s configuration. Use `),OY=n(Rle,"A",{href:!0});var yVt=s(OY);XTr=r(yVt,"from_pretrained()"),yVt.forEach(t),zTr=r(Rle," to load the model weights."),Rle.forEach(t),QTr=i(Zy),T(x4.$$.fragment,Zy),Zy.forEach(t),WTr=i(Dl),uo=n(Dl,"DIV",{class:!0});var Ba=s(uo);T(w$.$$.fragment,Ba),UTr=i(Ba),z4e=n(Ba,"P",{});var xVt=s(z4e);HTr=r(xVt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),xVt.forEach(t),JTr=i(Ba),fn=n(Ba,"P",{});var e8=s(fn);YTr=r(e8,"The model class to instantiate is selected based on the "),Q4e=n(e8,"CODE",{});var $Vt=s(Q4e);KTr=r($Vt,"model_type"),$Vt.forEach(t),ZTr=r(e8,` property of the config object (either
passed as an argument or loaded from `),W4e=n(e8,"CODE",{});var kVt=s(W4e);eMr=r(kVt,"pretrained_model_name_or_path"),kVt.forEach(t),oMr=r(e8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U4e=n(e8,"CODE",{});var SVt=s(U4e);rMr=r(SVt,"pretrained_model_name_or_path"),SVt.forEach(t),tMr=r(e8,":"),e8.forEach(t),aMr=i(Ba),H4e=n(Ba,"UL",{});var RVt=s(H4e);$4=n(RVt,"LI",{});var IXe=s($4);J4e=n(IXe,"STRONG",{});var PVt=s(J4e);nMr=r(PVt,"vilt"),PVt.forEach(t),sMr=r(IXe," \u2014 "),VY=n(IXe,"A",{href:!0});var BVt=s(VY);lMr=r(BVt,"ViltForQuestionAnswering"),BVt.forEach(t),iMr=r(IXe," (ViLT model)"),IXe.forEach(t),RVt.forEach(t),dMr=i(Ba),k4=n(Ba,"P",{});var NXe=s(k4);cMr=r(NXe,"The model is set in evaluation mode by default using "),Y4e=n(NXe,"CODE",{});var IVt=s(Y4e);mMr=r(IVt,"model.eval()"),IVt.forEach(t),fMr=r(NXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),K4e=n(NXe,"CODE",{});var NVt=s(K4e);gMr=r(NVt,"model.train()"),NVt.forEach(t),NXe.forEach(t),hMr=i(Ba),T(S4.$$.fragment,Ba),Ba.forEach(t),Dl.forEach(t),jKe=i(m),mc=n(m,"H2",{class:!0});var Zeo=s(mc);R4=n(Zeo,"A",{id:!0,class:!0,href:!0});var qVt=s(R4);Z4e=n(qVt,"SPAN",{});var jVt=s(Z4e);T(A$.$$.fragment,jVt),jVt.forEach(t),qVt.forEach(t),uMr=i(Zeo),eCe=n(Zeo,"SPAN",{});var DVt=s(eCe);pMr=r(DVt,"AutoModelForAudioClassification"),DVt.forEach(t),Zeo.forEach(t),DKe=i(m),Jo=n(m,"DIV",{class:!0});var Gl=s(Jo);T(L$.$$.fragment,Gl),_Mr=i(Gl),fc=n(Gl,"P",{});var Ple=s(fc);bMr=r(Ple,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),XY=n(Ple,"A",{href:!0});var GVt=s(XY);vMr=r(GVt,"from_pretrained()"),GVt.forEach(t),FMr=r(Ple," class method or the "),zY=n(Ple,"A",{href:!0});var OVt=s(zY);TMr=r(OVt,"from_config()"),OVt.forEach(t),MMr=r(Ple,` class
method.`),Ple.forEach(t),EMr=i(Gl),y$=n(Gl,"P",{});var eoo=s(y$);CMr=r(eoo,"This class cannot be instantiated directly using "),oCe=n(eoo,"CODE",{});var VVt=s(oCe);wMr=r(VVt,"__init__()"),VVt.forEach(t),AMr=r(eoo," (throws an error)."),eoo.forEach(t),LMr=i(Gl),Pt=n(Gl,"DIV",{class:!0});var o8=s(Pt);T(x$.$$.fragment,o8),yMr=i(o8),rCe=n(o8,"P",{});var XVt=s(rCe);xMr=r(XVt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),XVt.forEach(t),$Mr=i(o8),gc=n(o8,"P",{});var Ble=s(gc);kMr=r(Ble,`Note:
Loading a model from its configuration file does `),tCe=n(Ble,"STRONG",{});var zVt=s(tCe);SMr=r(zVt,"not"),zVt.forEach(t),RMr=r(Ble,` load the model weights. It only affects the
model\u2019s configuration. Use `),QY=n(Ble,"A",{href:!0});var QVt=s(QY);PMr=r(QVt,"from_pretrained()"),QVt.forEach(t),BMr=r(Ble," to load the model weights."),Ble.forEach(t),IMr=i(o8),T(P4.$$.fragment,o8),o8.forEach(t),NMr=i(Gl),po=n(Gl,"DIV",{class:!0});var Ia=s(po);T($$.$$.fragment,Ia),qMr=i(Ia),aCe=n(Ia,"P",{});var WVt=s(aCe);jMr=r(WVt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),WVt.forEach(t),DMr=i(Ia),gn=n(Ia,"P",{});var r8=s(gn);GMr=r(r8,"The model class to instantiate is selected based on the "),nCe=n(r8,"CODE",{});var UVt=s(nCe);OMr=r(UVt,"model_type"),UVt.forEach(t),VMr=r(r8,` property of the config object (either
passed as an argument or loaded from `),sCe=n(r8,"CODE",{});var HVt=s(sCe);XMr=r(HVt,"pretrained_model_name_or_path"),HVt.forEach(t),zMr=r(r8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lCe=n(r8,"CODE",{});var JVt=s(lCe);QMr=r(JVt,"pretrained_model_name_or_path"),JVt.forEach(t),WMr=r(r8,":"),r8.forEach(t),UMr=i(Ia),Pe=n(Ia,"UL",{});var Qe=s(Pe);B4=n(Qe,"LI",{});var qXe=s(B4);iCe=n(qXe,"STRONG",{});var YVt=s(iCe);HMr=r(YVt,"data2vec-audio"),YVt.forEach(t),JMr=r(qXe," \u2014 "),WY=n(qXe,"A",{href:!0});var KVt=s(WY);YMr=r(KVt,"Data2VecAudioForSequenceClassification"),KVt.forEach(t),KMr=r(qXe," (Data2VecAudio model)"),qXe.forEach(t),ZMr=i(Qe),I4=n(Qe,"LI",{});var jXe=s(I4);dCe=n(jXe,"STRONG",{});var ZVt=s(dCe);eEr=r(ZVt,"hubert"),ZVt.forEach(t),oEr=r(jXe," \u2014 "),UY=n(jXe,"A",{href:!0});var eXt=s(UY);rEr=r(eXt,"HubertForSequenceClassification"),eXt.forEach(t),tEr=r(jXe," (Hubert model)"),jXe.forEach(t),aEr=i(Qe),N4=n(Qe,"LI",{});var DXe=s(N4);cCe=n(DXe,"STRONG",{});var oXt=s(cCe);nEr=r(oXt,"sew"),oXt.forEach(t),sEr=r(DXe," \u2014 "),HY=n(DXe,"A",{href:!0});var rXt=s(HY);lEr=r(rXt,"SEWForSequenceClassification"),rXt.forEach(t),iEr=r(DXe," (SEW model)"),DXe.forEach(t),dEr=i(Qe),q4=n(Qe,"LI",{});var GXe=s(q4);mCe=n(GXe,"STRONG",{});var tXt=s(mCe);cEr=r(tXt,"sew-d"),tXt.forEach(t),mEr=r(GXe," \u2014 "),JY=n(GXe,"A",{href:!0});var aXt=s(JY);fEr=r(aXt,"SEWDForSequenceClassification"),aXt.forEach(t),gEr=r(GXe," (SEW-D model)"),GXe.forEach(t),hEr=i(Qe),j4=n(Qe,"LI",{});var OXe=s(j4);fCe=n(OXe,"STRONG",{});var nXt=s(fCe);uEr=r(nXt,"unispeech"),nXt.forEach(t),pEr=r(OXe," \u2014 "),YY=n(OXe,"A",{href:!0});var sXt=s(YY);_Er=r(sXt,"UniSpeechForSequenceClassification"),sXt.forEach(t),bEr=r(OXe," (UniSpeech model)"),OXe.forEach(t),vEr=i(Qe),D4=n(Qe,"LI",{});var VXe=s(D4);gCe=n(VXe,"STRONG",{});var lXt=s(gCe);FEr=r(lXt,"unispeech-sat"),lXt.forEach(t),TEr=r(VXe," \u2014 "),KY=n(VXe,"A",{href:!0});var iXt=s(KY);MEr=r(iXt,"UniSpeechSatForSequenceClassification"),iXt.forEach(t),EEr=r(VXe," (UniSpeechSat model)"),VXe.forEach(t),CEr=i(Qe),G4=n(Qe,"LI",{});var XXe=s(G4);hCe=n(XXe,"STRONG",{});var dXt=s(hCe);wEr=r(dXt,"wav2vec2"),dXt.forEach(t),AEr=r(XXe," \u2014 "),ZY=n(XXe,"A",{href:!0});var cXt=s(ZY);LEr=r(cXt,"Wav2Vec2ForSequenceClassification"),cXt.forEach(t),yEr=r(XXe," (Wav2Vec2 model)"),XXe.forEach(t),xEr=i(Qe),O4=n(Qe,"LI",{});var zXe=s(O4);uCe=n(zXe,"STRONG",{});var mXt=s(uCe);$Er=r(mXt,"wav2vec2-conformer"),mXt.forEach(t),kEr=r(zXe," \u2014 "),eK=n(zXe,"A",{href:!0});var fXt=s(eK);SEr=r(fXt,"Wav2Vec2ConformerForSequenceClassification"),fXt.forEach(t),REr=r(zXe," (Wav2Vec2-Conformer model)"),zXe.forEach(t),PEr=i(Qe),V4=n(Qe,"LI",{});var QXe=s(V4);pCe=n(QXe,"STRONG",{});var gXt=s(pCe);BEr=r(gXt,"wavlm"),gXt.forEach(t),IEr=r(QXe," \u2014 "),oK=n(QXe,"A",{href:!0});var hXt=s(oK);NEr=r(hXt,"WavLMForSequenceClassification"),hXt.forEach(t),qEr=r(QXe," (WavLM model)"),QXe.forEach(t),Qe.forEach(t),jEr=i(Ia),X4=n(Ia,"P",{});var WXe=s(X4);DEr=r(WXe,"The model is set in evaluation mode by default using "),_Ce=n(WXe,"CODE",{});var uXt=s(_Ce);GEr=r(uXt,"model.eval()"),uXt.forEach(t),OEr=r(WXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bCe=n(WXe,"CODE",{});var pXt=s(bCe);VEr=r(pXt,"model.train()"),pXt.forEach(t),WXe.forEach(t),XEr=i(Ia),T(z4.$$.fragment,Ia),Ia.forEach(t),Gl.forEach(t),GKe=i(m),hc=n(m,"H2",{class:!0});var ooo=s(hc);Q4=n(ooo,"A",{id:!0,class:!0,href:!0});var _Xt=s(Q4);vCe=n(_Xt,"SPAN",{});var bXt=s(vCe);T(k$.$$.fragment,bXt),bXt.forEach(t),_Xt.forEach(t),zEr=i(ooo),FCe=n(ooo,"SPAN",{});var vXt=s(FCe);QEr=r(vXt,"AutoModelForAudioFrameClassification"),vXt.forEach(t),ooo.forEach(t),OKe=i(m),Yo=n(m,"DIV",{class:!0});var Ol=s(Yo);T(S$.$$.fragment,Ol),WEr=i(Ol),uc=n(Ol,"P",{});var Ile=s(uc);UEr=r(Ile,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),rK=n(Ile,"A",{href:!0});var FXt=s(rK);HEr=r(FXt,"from_pretrained()"),FXt.forEach(t),JEr=r(Ile," class method or the "),tK=n(Ile,"A",{href:!0});var TXt=s(tK);YEr=r(TXt,"from_config()"),TXt.forEach(t),KEr=r(Ile,` class
method.`),Ile.forEach(t),ZEr=i(Ol),R$=n(Ol,"P",{});var roo=s(R$);e4r=r(roo,"This class cannot be instantiated directly using "),TCe=n(roo,"CODE",{});var MXt=s(TCe);o4r=r(MXt,"__init__()"),MXt.forEach(t),r4r=r(roo," (throws an error)."),roo.forEach(t),t4r=i(Ol),Bt=n(Ol,"DIV",{class:!0});var t8=s(Bt);T(P$.$$.fragment,t8),a4r=i(t8),MCe=n(t8,"P",{});var EXt=s(MCe);n4r=r(EXt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),EXt.forEach(t),s4r=i(t8),pc=n(t8,"P",{});var Nle=s(pc);l4r=r(Nle,`Note:
Loading a model from its configuration file does `),ECe=n(Nle,"STRONG",{});var CXt=s(ECe);i4r=r(CXt,"not"),CXt.forEach(t),d4r=r(Nle,` load the model weights. It only affects the
model\u2019s configuration. Use `),aK=n(Nle,"A",{href:!0});var wXt=s(aK);c4r=r(wXt,"from_pretrained()"),wXt.forEach(t),m4r=r(Nle," to load the model weights."),Nle.forEach(t),f4r=i(t8),T(W4.$$.fragment,t8),t8.forEach(t),g4r=i(Ol),_o=n(Ol,"DIV",{class:!0});var Na=s(_o);T(B$.$$.fragment,Na),h4r=i(Na),CCe=n(Na,"P",{});var AXt=s(CCe);u4r=r(AXt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),AXt.forEach(t),p4r=i(Na),hn=n(Na,"P",{});var a8=s(hn);_4r=r(a8,"The model class to instantiate is selected based on the "),wCe=n(a8,"CODE",{});var LXt=s(wCe);b4r=r(LXt,"model_type"),LXt.forEach(t),v4r=r(a8,` property of the config object (either
passed as an argument or loaded from `),ACe=n(a8,"CODE",{});var yXt=s(ACe);F4r=r(yXt,"pretrained_model_name_or_path"),yXt.forEach(t),T4r=r(a8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LCe=n(a8,"CODE",{});var xXt=s(LCe);M4r=r(xXt,"pretrained_model_name_or_path"),xXt.forEach(t),E4r=r(a8,":"),a8.forEach(t),C4r=i(Na),mt=n(Na,"UL",{});var Vl=s(mt);U4=n(Vl,"LI",{});var UXe=s(U4);yCe=n(UXe,"STRONG",{});var $Xt=s(yCe);w4r=r($Xt,"data2vec-audio"),$Xt.forEach(t),A4r=r(UXe," \u2014 "),nK=n(UXe,"A",{href:!0});var kXt=s(nK);L4r=r(kXt,"Data2VecAudioForAudioFrameClassification"),kXt.forEach(t),y4r=r(UXe," (Data2VecAudio model)"),UXe.forEach(t),x4r=i(Vl),H4=n(Vl,"LI",{});var HXe=s(H4);xCe=n(HXe,"STRONG",{});var SXt=s(xCe);$4r=r(SXt,"unispeech-sat"),SXt.forEach(t),k4r=r(HXe," \u2014 "),sK=n(HXe,"A",{href:!0});var RXt=s(sK);S4r=r(RXt,"UniSpeechSatForAudioFrameClassification"),RXt.forEach(t),R4r=r(HXe," (UniSpeechSat model)"),HXe.forEach(t),P4r=i(Vl),J4=n(Vl,"LI",{});var JXe=s(J4);$Ce=n(JXe,"STRONG",{});var PXt=s($Ce);B4r=r(PXt,"wav2vec2"),PXt.forEach(t),I4r=r(JXe," \u2014 "),lK=n(JXe,"A",{href:!0});var BXt=s(lK);N4r=r(BXt,"Wav2Vec2ForAudioFrameClassification"),BXt.forEach(t),q4r=r(JXe," (Wav2Vec2 model)"),JXe.forEach(t),j4r=i(Vl),Y4=n(Vl,"LI",{});var YXe=s(Y4);kCe=n(YXe,"STRONG",{});var IXt=s(kCe);D4r=r(IXt,"wav2vec2-conformer"),IXt.forEach(t),G4r=r(YXe," \u2014 "),iK=n(YXe,"A",{href:!0});var NXt=s(iK);O4r=r(NXt,"Wav2Vec2ConformerForAudioFrameClassification"),NXt.forEach(t),V4r=r(YXe," (Wav2Vec2-Conformer model)"),YXe.forEach(t),X4r=i(Vl),K4=n(Vl,"LI",{});var KXe=s(K4);SCe=n(KXe,"STRONG",{});var qXt=s(SCe);z4r=r(qXt,"wavlm"),qXt.forEach(t),Q4r=r(KXe," \u2014 "),dK=n(KXe,"A",{href:!0});var jXt=s(dK);W4r=r(jXt,"WavLMForAudioFrameClassification"),jXt.forEach(t),U4r=r(KXe," (WavLM model)"),KXe.forEach(t),Vl.forEach(t),H4r=i(Na),Z4=n(Na,"P",{});var ZXe=s(Z4);J4r=r(ZXe,"The model is set in evaluation mode by default using "),RCe=n(ZXe,"CODE",{});var DXt=s(RCe);Y4r=r(DXt,"model.eval()"),DXt.forEach(t),K4r=r(ZXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),PCe=n(ZXe,"CODE",{});var GXt=s(PCe);Z4r=r(GXt,"model.train()"),GXt.forEach(t),ZXe.forEach(t),eCr=i(Na),T(eC.$$.fragment,Na),Na.forEach(t),Ol.forEach(t),VKe=i(m),_c=n(m,"H2",{class:!0});var too=s(_c);oC=n(too,"A",{id:!0,class:!0,href:!0});var OXt=s(oC);BCe=n(OXt,"SPAN",{});var VXt=s(BCe);T(I$.$$.fragment,VXt),VXt.forEach(t),OXt.forEach(t),oCr=i(too),ICe=n(too,"SPAN",{});var XXt=s(ICe);rCr=r(XXt,"AutoModelForCTC"),XXt.forEach(t),too.forEach(t),XKe=i(m),Ko=n(m,"DIV",{class:!0});var Xl=s(Ko);T(N$.$$.fragment,Xl),tCr=i(Xl),bc=n(Xl,"P",{});var qle=s(bc);aCr=r(qle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),cK=n(qle,"A",{href:!0});var zXt=s(cK);nCr=r(zXt,"from_pretrained()"),zXt.forEach(t),sCr=r(qle," class method or the "),mK=n(qle,"A",{href:!0});var QXt=s(mK);lCr=r(QXt,"from_config()"),QXt.forEach(t),iCr=r(qle,` class
method.`),qle.forEach(t),dCr=i(Xl),q$=n(Xl,"P",{});var aoo=s(q$);cCr=r(aoo,"This class cannot be instantiated directly using "),NCe=n(aoo,"CODE",{});var WXt=s(NCe);mCr=r(WXt,"__init__()"),WXt.forEach(t),fCr=r(aoo," (throws an error)."),aoo.forEach(t),gCr=i(Xl),It=n(Xl,"DIV",{class:!0});var n8=s(It);T(j$.$$.fragment,n8),hCr=i(n8),qCe=n(n8,"P",{});var UXt=s(qCe);uCr=r(UXt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),UXt.forEach(t),pCr=i(n8),vc=n(n8,"P",{});var jle=s(vc);_Cr=r(jle,`Note:
Loading a model from its configuration file does `),jCe=n(jle,"STRONG",{});var HXt=s(jCe);bCr=r(HXt,"not"),HXt.forEach(t),vCr=r(jle,` load the model weights. It only affects the
model\u2019s configuration. Use `),fK=n(jle,"A",{href:!0});var JXt=s(fK);FCr=r(JXt,"from_pretrained()"),JXt.forEach(t),TCr=r(jle," to load the model weights."),jle.forEach(t),MCr=i(n8),T(rC.$$.fragment,n8),n8.forEach(t),ECr=i(Xl),bo=n(Xl,"DIV",{class:!0});var qa=s(bo);T(D$.$$.fragment,qa),CCr=i(qa),DCe=n(qa,"P",{});var YXt=s(DCe);wCr=r(YXt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),YXt.forEach(t),ACr=i(qa),un=n(qa,"P",{});var s8=s(un);LCr=r(s8,"The model class to instantiate is selected based on the "),GCe=n(s8,"CODE",{});var KXt=s(GCe);yCr=r(KXt,"model_type"),KXt.forEach(t),xCr=r(s8,` property of the config object (either
passed as an argument or loaded from `),OCe=n(s8,"CODE",{});var ZXt=s(OCe);$Cr=r(ZXt,"pretrained_model_name_or_path"),ZXt.forEach(t),kCr=r(s8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VCe=n(s8,"CODE",{});var ezt=s(VCe);SCr=r(ezt,"pretrained_model_name_or_path"),ezt.forEach(t),RCr=r(s8,":"),s8.forEach(t),PCr=i(qa),Le=n(qa,"UL",{});var Ie=s(Le);tC=n(Ie,"LI",{});var eze=s(tC);XCe=n(eze,"STRONG",{});var ozt=s(XCe);BCr=r(ozt,"data2vec-audio"),ozt.forEach(t),ICr=r(eze," \u2014 "),gK=n(eze,"A",{href:!0});var rzt=s(gK);NCr=r(rzt,"Data2VecAudioForCTC"),rzt.forEach(t),qCr=r(eze," (Data2VecAudio model)"),eze.forEach(t),jCr=i(Ie),aC=n(Ie,"LI",{});var oze=s(aC);zCe=n(oze,"STRONG",{});var tzt=s(zCe);DCr=r(tzt,"hubert"),tzt.forEach(t),GCr=r(oze," \u2014 "),hK=n(oze,"A",{href:!0});var azt=s(hK);OCr=r(azt,"HubertForCTC"),azt.forEach(t),VCr=r(oze," (Hubert model)"),oze.forEach(t),XCr=i(Ie),nC=n(Ie,"LI",{});var rze=s(nC);QCe=n(rze,"STRONG",{});var nzt=s(QCe);zCr=r(nzt,"mctct"),nzt.forEach(t),QCr=r(rze," \u2014 "),uK=n(rze,"A",{href:!0});var szt=s(uK);WCr=r(szt,"MCTCTForCTC"),szt.forEach(t),UCr=r(rze," (M-CTC-T model)"),rze.forEach(t),HCr=i(Ie),sC=n(Ie,"LI",{});var tze=s(sC);WCe=n(tze,"STRONG",{});var lzt=s(WCe);JCr=r(lzt,"sew"),lzt.forEach(t),YCr=r(tze," \u2014 "),pK=n(tze,"A",{href:!0});var izt=s(pK);KCr=r(izt,"SEWForCTC"),izt.forEach(t),ZCr=r(tze," (SEW model)"),tze.forEach(t),e3r=i(Ie),lC=n(Ie,"LI",{});var aze=s(lC);UCe=n(aze,"STRONG",{});var dzt=s(UCe);o3r=r(dzt,"sew-d"),dzt.forEach(t),r3r=r(aze," \u2014 "),_K=n(aze,"A",{href:!0});var czt=s(_K);t3r=r(czt,"SEWDForCTC"),czt.forEach(t),a3r=r(aze," (SEW-D model)"),aze.forEach(t),n3r=i(Ie),iC=n(Ie,"LI",{});var nze=s(iC);HCe=n(nze,"STRONG",{});var mzt=s(HCe);s3r=r(mzt,"unispeech"),mzt.forEach(t),l3r=r(nze," \u2014 "),bK=n(nze,"A",{href:!0});var fzt=s(bK);i3r=r(fzt,"UniSpeechForCTC"),fzt.forEach(t),d3r=r(nze," (UniSpeech model)"),nze.forEach(t),c3r=i(Ie),dC=n(Ie,"LI",{});var sze=s(dC);JCe=n(sze,"STRONG",{});var gzt=s(JCe);m3r=r(gzt,"unispeech-sat"),gzt.forEach(t),f3r=r(sze," \u2014 "),vK=n(sze,"A",{href:!0});var hzt=s(vK);g3r=r(hzt,"UniSpeechSatForCTC"),hzt.forEach(t),h3r=r(sze," (UniSpeechSat model)"),sze.forEach(t),u3r=i(Ie),cC=n(Ie,"LI",{});var lze=s(cC);YCe=n(lze,"STRONG",{});var uzt=s(YCe);p3r=r(uzt,"wav2vec2"),uzt.forEach(t),_3r=r(lze," \u2014 "),FK=n(lze,"A",{href:!0});var pzt=s(FK);b3r=r(pzt,"Wav2Vec2ForCTC"),pzt.forEach(t),v3r=r(lze," (Wav2Vec2 model)"),lze.forEach(t),F3r=i(Ie),mC=n(Ie,"LI",{});var ize=s(mC);KCe=n(ize,"STRONG",{});var _zt=s(KCe);T3r=r(_zt,"wav2vec2-conformer"),_zt.forEach(t),M3r=r(ize," \u2014 "),TK=n(ize,"A",{href:!0});var bzt=s(TK);E3r=r(bzt,"Wav2Vec2ConformerForCTC"),bzt.forEach(t),C3r=r(ize," (Wav2Vec2-Conformer model)"),ize.forEach(t),w3r=i(Ie),fC=n(Ie,"LI",{});var dze=s(fC);ZCe=n(dze,"STRONG",{});var vzt=s(ZCe);A3r=r(vzt,"wavlm"),vzt.forEach(t),L3r=r(dze," \u2014 "),MK=n(dze,"A",{href:!0});var Fzt=s(MK);y3r=r(Fzt,"WavLMForCTC"),Fzt.forEach(t),x3r=r(dze," (WavLM model)"),dze.forEach(t),Ie.forEach(t),$3r=i(qa),gC=n(qa,"P",{});var cze=s(gC);k3r=r(cze,"The model is set in evaluation mode by default using "),e3e=n(cze,"CODE",{});var Tzt=s(e3e);S3r=r(Tzt,"model.eval()"),Tzt.forEach(t),R3r=r(cze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o3e=n(cze,"CODE",{});var Mzt=s(o3e);P3r=r(Mzt,"model.train()"),Mzt.forEach(t),cze.forEach(t),B3r=i(qa),T(hC.$$.fragment,qa),qa.forEach(t),Xl.forEach(t),zKe=i(m),Fc=n(m,"H2",{class:!0});var noo=s(Fc);uC=n(noo,"A",{id:!0,class:!0,href:!0});var Ezt=s(uC);r3e=n(Ezt,"SPAN",{});var Czt=s(r3e);T(G$.$$.fragment,Czt),Czt.forEach(t),Ezt.forEach(t),I3r=i(noo),t3e=n(noo,"SPAN",{});var wzt=s(t3e);N3r=r(wzt,"AutoModelForSpeechSeq2Seq"),wzt.forEach(t),noo.forEach(t),QKe=i(m),Zo=n(m,"DIV",{class:!0});var zl=s(Zo);T(O$.$$.fragment,zl),q3r=i(zl),Tc=n(zl,"P",{});var Dle=s(Tc);j3r=r(Dle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),EK=n(Dle,"A",{href:!0});var Azt=s(EK);D3r=r(Azt,"from_pretrained()"),Azt.forEach(t),G3r=r(Dle," class method or the "),CK=n(Dle,"A",{href:!0});var Lzt=s(CK);O3r=r(Lzt,"from_config()"),Lzt.forEach(t),V3r=r(Dle,` class
method.`),Dle.forEach(t),X3r=i(zl),V$=n(zl,"P",{});var soo=s(V$);z3r=r(soo,"This class cannot be instantiated directly using "),a3e=n(soo,"CODE",{});var yzt=s(a3e);Q3r=r(yzt,"__init__()"),yzt.forEach(t),W3r=r(soo," (throws an error)."),soo.forEach(t),U3r=i(zl),Nt=n(zl,"DIV",{class:!0});var l8=s(Nt);T(X$.$$.fragment,l8),H3r=i(l8),n3e=n(l8,"P",{});var xzt=s(n3e);J3r=r(xzt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),xzt.forEach(t),Y3r=i(l8),Mc=n(l8,"P",{});var Gle=s(Mc);K3r=r(Gle,`Note:
Loading a model from its configuration file does `),s3e=n(Gle,"STRONG",{});var $zt=s(s3e);Z3r=r($zt,"not"),$zt.forEach(t),e5r=r(Gle,` load the model weights. It only affects the
model\u2019s configuration. Use `),wK=n(Gle,"A",{href:!0});var kzt=s(wK);o5r=r(kzt,"from_pretrained()"),kzt.forEach(t),r5r=r(Gle," to load the model weights."),Gle.forEach(t),t5r=i(l8),T(pC.$$.fragment,l8),l8.forEach(t),a5r=i(zl),vo=n(zl,"DIV",{class:!0});var ja=s(vo);T(z$.$$.fragment,ja),n5r=i(ja),l3e=n(ja,"P",{});var Szt=s(l3e);s5r=r(Szt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Szt.forEach(t),l5r=i(ja),pn=n(ja,"P",{});var i8=s(pn);i5r=r(i8,"The model class to instantiate is selected based on the "),i3e=n(i8,"CODE",{});var Rzt=s(i3e);d5r=r(Rzt,"model_type"),Rzt.forEach(t),c5r=r(i8,` property of the config object (either
passed as an argument or loaded from `),d3e=n(i8,"CODE",{});var Pzt=s(d3e);m5r=r(Pzt,"pretrained_model_name_or_path"),Pzt.forEach(t),f5r=r(i8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c3e=n(i8,"CODE",{});var Bzt=s(c3e);g5r=r(Bzt,"pretrained_model_name_or_path"),Bzt.forEach(t),h5r=r(i8,":"),i8.forEach(t),u5r=i(ja),Q$=n(ja,"UL",{});var loo=s(Q$);_C=n(loo,"LI",{});var mze=s(_C);m3e=n(mze,"STRONG",{});var Izt=s(m3e);p5r=r(Izt,"speech-encoder-decoder"),Izt.forEach(t),_5r=r(mze," \u2014 "),AK=n(mze,"A",{href:!0});var Nzt=s(AK);b5r=r(Nzt,"SpeechEncoderDecoderModel"),Nzt.forEach(t),v5r=r(mze," (Speech Encoder decoder model)"),mze.forEach(t),F5r=i(loo),bC=n(loo,"LI",{});var fze=s(bC);f3e=n(fze,"STRONG",{});var qzt=s(f3e);T5r=r(qzt,"speech_to_text"),qzt.forEach(t),M5r=r(fze," \u2014 "),LK=n(fze,"A",{href:!0});var jzt=s(LK);E5r=r(jzt,"Speech2TextForConditionalGeneration"),jzt.forEach(t),C5r=r(fze," (Speech2Text model)"),fze.forEach(t),loo.forEach(t),w5r=i(ja),vC=n(ja,"P",{});var gze=s(vC);A5r=r(gze,"The model is set in evaluation mode by default using "),g3e=n(gze,"CODE",{});var Dzt=s(g3e);L5r=r(Dzt,"model.eval()"),Dzt.forEach(t),y5r=r(gze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h3e=n(gze,"CODE",{});var Gzt=s(h3e);x5r=r(Gzt,"model.train()"),Gzt.forEach(t),gze.forEach(t),$5r=i(ja),T(FC.$$.fragment,ja),ja.forEach(t),zl.forEach(t),WKe=i(m),Ec=n(m,"H2",{class:!0});var ioo=s(Ec);TC=n(ioo,"A",{id:!0,class:!0,href:!0});var Ozt=s(TC);u3e=n(Ozt,"SPAN",{});var Vzt=s(u3e);T(W$.$$.fragment,Vzt),Vzt.forEach(t),Ozt.forEach(t),k5r=i(ioo),p3e=n(ioo,"SPAN",{});var Xzt=s(p3e);S5r=r(Xzt,"AutoModelForAudioXVector"),Xzt.forEach(t),ioo.forEach(t),UKe=i(m),er=n(m,"DIV",{class:!0});var Ql=s(er);T(U$.$$.fragment,Ql),R5r=i(Ql),Cc=n(Ql,"P",{});var Ole=s(Cc);P5r=r(Ole,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),yK=n(Ole,"A",{href:!0});var zzt=s(yK);B5r=r(zzt,"from_pretrained()"),zzt.forEach(t),I5r=r(Ole," class method or the "),xK=n(Ole,"A",{href:!0});var Qzt=s(xK);N5r=r(Qzt,"from_config()"),Qzt.forEach(t),q5r=r(Ole,` class
method.`),Ole.forEach(t),j5r=i(Ql),H$=n(Ql,"P",{});var doo=s(H$);D5r=r(doo,"This class cannot be instantiated directly using "),_3e=n(doo,"CODE",{});var Wzt=s(_3e);G5r=r(Wzt,"__init__()"),Wzt.forEach(t),O5r=r(doo," (throws an error)."),doo.forEach(t),V5r=i(Ql),qt=n(Ql,"DIV",{class:!0});var d8=s(qt);T(J$.$$.fragment,d8),X5r=i(d8),b3e=n(d8,"P",{});var Uzt=s(b3e);z5r=r(Uzt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Uzt.forEach(t),Q5r=i(d8),wc=n(d8,"P",{});var Vle=s(wc);W5r=r(Vle,`Note:
Loading a model from its configuration file does `),v3e=n(Vle,"STRONG",{});var Hzt=s(v3e);U5r=r(Hzt,"not"),Hzt.forEach(t),H5r=r(Vle,` load the model weights. It only affects the
model\u2019s configuration. Use `),$K=n(Vle,"A",{href:!0});var Jzt=s($K);J5r=r(Jzt,"from_pretrained()"),Jzt.forEach(t),Y5r=r(Vle," to load the model weights."),Vle.forEach(t),K5r=i(d8),T(MC.$$.fragment,d8),d8.forEach(t),Z5r=i(Ql),Fo=n(Ql,"DIV",{class:!0});var Da=s(Fo);T(Y$.$$.fragment,Da),e0r=i(Da),F3e=n(Da,"P",{});var Yzt=s(F3e);o0r=r(Yzt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Yzt.forEach(t),r0r=i(Da),_n=n(Da,"P",{});var c8=s(_n);t0r=r(c8,"The model class to instantiate is selected based on the "),T3e=n(c8,"CODE",{});var Kzt=s(T3e);a0r=r(Kzt,"model_type"),Kzt.forEach(t),n0r=r(c8,` property of the config object (either
passed as an argument or loaded from `),M3e=n(c8,"CODE",{});var Zzt=s(M3e);s0r=r(Zzt,"pretrained_model_name_or_path"),Zzt.forEach(t),l0r=r(c8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E3e=n(c8,"CODE",{});var eQt=s(E3e);i0r=r(eQt,"pretrained_model_name_or_path"),eQt.forEach(t),d0r=r(c8,":"),c8.forEach(t),c0r=i(Da),ft=n(Da,"UL",{});var Wl=s(ft);EC=n(Wl,"LI",{});var hze=s(EC);C3e=n(hze,"STRONG",{});var oQt=s(C3e);m0r=r(oQt,"data2vec-audio"),oQt.forEach(t),f0r=r(hze," \u2014 "),kK=n(hze,"A",{href:!0});var rQt=s(kK);g0r=r(rQt,"Data2VecAudioForXVector"),rQt.forEach(t),h0r=r(hze," (Data2VecAudio model)"),hze.forEach(t),u0r=i(Wl),CC=n(Wl,"LI",{});var uze=s(CC);w3e=n(uze,"STRONG",{});var tQt=s(w3e);p0r=r(tQt,"unispeech-sat"),tQt.forEach(t),_0r=r(uze," \u2014 "),SK=n(uze,"A",{href:!0});var aQt=s(SK);b0r=r(aQt,"UniSpeechSatForXVector"),aQt.forEach(t),v0r=r(uze," (UniSpeechSat model)"),uze.forEach(t),F0r=i(Wl),wC=n(Wl,"LI",{});var pze=s(wC);A3e=n(pze,"STRONG",{});var nQt=s(A3e);T0r=r(nQt,"wav2vec2"),nQt.forEach(t),M0r=r(pze," \u2014 "),RK=n(pze,"A",{href:!0});var sQt=s(RK);E0r=r(sQt,"Wav2Vec2ForXVector"),sQt.forEach(t),C0r=r(pze," (Wav2Vec2 model)"),pze.forEach(t),w0r=i(Wl),AC=n(Wl,"LI",{});var _ze=s(AC);L3e=n(_ze,"STRONG",{});var lQt=s(L3e);A0r=r(lQt,"wav2vec2-conformer"),lQt.forEach(t),L0r=r(_ze," \u2014 "),PK=n(_ze,"A",{href:!0});var iQt=s(PK);y0r=r(iQt,"Wav2Vec2ConformerForXVector"),iQt.forEach(t),x0r=r(_ze," (Wav2Vec2-Conformer model)"),_ze.forEach(t),$0r=i(Wl),LC=n(Wl,"LI",{});var bze=s(LC);y3e=n(bze,"STRONG",{});var dQt=s(y3e);k0r=r(dQt,"wavlm"),dQt.forEach(t),S0r=r(bze," \u2014 "),BK=n(bze,"A",{href:!0});var cQt=s(BK);R0r=r(cQt,"WavLMForXVector"),cQt.forEach(t),P0r=r(bze," (WavLM model)"),bze.forEach(t),Wl.forEach(t),B0r=i(Da),yC=n(Da,"P",{});var vze=s(yC);I0r=r(vze,"The model is set in evaluation mode by default using "),x3e=n(vze,"CODE",{});var mQt=s(x3e);N0r=r(mQt,"model.eval()"),mQt.forEach(t),q0r=r(vze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$3e=n(vze,"CODE",{});var fQt=s($3e);j0r=r(fQt,"model.train()"),fQt.forEach(t),vze.forEach(t),D0r=i(Da),T(xC.$$.fragment,Da),Da.forEach(t),Ql.forEach(t),HKe=i(m),Ac=n(m,"H2",{class:!0});var coo=s(Ac);$C=n(coo,"A",{id:!0,class:!0,href:!0});var gQt=s($C);k3e=n(gQt,"SPAN",{});var hQt=s(k3e);T(K$.$$.fragment,hQt),hQt.forEach(t),gQt.forEach(t),G0r=i(coo),S3e=n(coo,"SPAN",{});var uQt=s(S3e);O0r=r(uQt,"AutoModelForMaskedImageModeling"),uQt.forEach(t),coo.forEach(t),JKe=i(m),or=n(m,"DIV",{class:!0});var Ul=s(or);T(Z$.$$.fragment,Ul),V0r=i(Ul),Lc=n(Ul,"P",{});var Xle=s(Lc);X0r=r(Xle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),IK=n(Xle,"A",{href:!0});var pQt=s(IK);z0r=r(pQt,"from_pretrained()"),pQt.forEach(t),Q0r=r(Xle," class method or the "),NK=n(Xle,"A",{href:!0});var _Qt=s(NK);W0r=r(_Qt,"from_config()"),_Qt.forEach(t),U0r=r(Xle,` class
method.`),Xle.forEach(t),H0r=i(Ul),ek=n(Ul,"P",{});var moo=s(ek);J0r=r(moo,"This class cannot be instantiated directly using "),R3e=n(moo,"CODE",{});var bQt=s(R3e);Y0r=r(bQt,"__init__()"),bQt.forEach(t),K0r=r(moo," (throws an error)."),moo.forEach(t),Z0r=i(Ul),jt=n(Ul,"DIV",{class:!0});var m8=s(jt);T(ok.$$.fragment,m8),ewr=i(m8),P3e=n(m8,"P",{});var vQt=s(P3e);owr=r(vQt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),vQt.forEach(t),rwr=i(m8),yc=n(m8,"P",{});var zle=s(yc);twr=r(zle,`Note:
Loading a model from its configuration file does `),B3e=n(zle,"STRONG",{});var FQt=s(B3e);awr=r(FQt,"not"),FQt.forEach(t),nwr=r(zle,` load the model weights. It only affects the
model\u2019s configuration. Use `),qK=n(zle,"A",{href:!0});var TQt=s(qK);swr=r(TQt,"from_pretrained()"),TQt.forEach(t),lwr=r(zle," to load the model weights."),zle.forEach(t),iwr=i(m8),T(kC.$$.fragment,m8),m8.forEach(t),dwr=i(Ul),To=n(Ul,"DIV",{class:!0});var Ga=s(To);T(rk.$$.fragment,Ga),cwr=i(Ga),I3e=n(Ga,"P",{});var MQt=s(I3e);mwr=r(MQt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),MQt.forEach(t),fwr=i(Ga),bn=n(Ga,"P",{});var f8=s(bn);gwr=r(f8,"The model class to instantiate is selected based on the "),N3e=n(f8,"CODE",{});var EQt=s(N3e);hwr=r(EQt,"model_type"),EQt.forEach(t),uwr=r(f8,` property of the config object (either
passed as an argument or loaded from `),q3e=n(f8,"CODE",{});var CQt=s(q3e);pwr=r(CQt,"pretrained_model_name_or_path"),CQt.forEach(t),_wr=r(f8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j3e=n(f8,"CODE",{});var wQt=s(j3e);bwr=r(wQt,"pretrained_model_name_or_path"),wQt.forEach(t),vwr=r(f8,":"),f8.forEach(t),Fwr=i(Ga),vn=n(Ga,"UL",{});var g8=s(vn);SC=n(g8,"LI",{});var Fze=s(SC);D3e=n(Fze,"STRONG",{});var AQt=s(D3e);Twr=r(AQt,"deit"),AQt.forEach(t),Mwr=r(Fze," \u2014 "),jK=n(Fze,"A",{href:!0});var LQt=s(jK);Ewr=r(LQt,"DeiTForMaskedImageModeling"),LQt.forEach(t),Cwr=r(Fze," (DeiT model)"),Fze.forEach(t),wwr=i(g8),RC=n(g8,"LI",{});var Tze=s(RC);G3e=n(Tze,"STRONG",{});var yQt=s(G3e);Awr=r(yQt,"swin"),yQt.forEach(t),Lwr=r(Tze," \u2014 "),DK=n(Tze,"A",{href:!0});var xQt=s(DK);ywr=r(xQt,"SwinForMaskedImageModeling"),xQt.forEach(t),xwr=r(Tze," (Swin Transformer model)"),Tze.forEach(t),$wr=i(g8),PC=n(g8,"LI",{});var Mze=s(PC);O3e=n(Mze,"STRONG",{});var $Qt=s(O3e);kwr=r($Qt,"swinv2"),$Qt.forEach(t),Swr=r(Mze," \u2014 "),GK=n(Mze,"A",{href:!0});var kQt=s(GK);Rwr=r(kQt,"Swinv2ForMaskedImageModeling"),kQt.forEach(t),Pwr=r(Mze," (Swin Transformer V2 model)"),Mze.forEach(t),Bwr=i(g8),BC=n(g8,"LI",{});var Eze=s(BC);V3e=n(Eze,"STRONG",{});var SQt=s(V3e);Iwr=r(SQt,"vit"),SQt.forEach(t),Nwr=r(Eze," \u2014 "),OK=n(Eze,"A",{href:!0});var RQt=s(OK);qwr=r(RQt,"ViTForMaskedImageModeling"),RQt.forEach(t),jwr=r(Eze," (ViT model)"),Eze.forEach(t),g8.forEach(t),Dwr=i(Ga),IC=n(Ga,"P",{});var Cze=s(IC);Gwr=r(Cze,"The model is set in evaluation mode by default using "),X3e=n(Cze,"CODE",{});var PQt=s(X3e);Owr=r(PQt,"model.eval()"),PQt.forEach(t),Vwr=r(Cze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z3e=n(Cze,"CODE",{});var BQt=s(z3e);Xwr=r(BQt,"model.train()"),BQt.forEach(t),Cze.forEach(t),zwr=i(Ga),T(NC.$$.fragment,Ga),Ga.forEach(t),Ul.forEach(t),YKe=i(m),xc=n(m,"H2",{class:!0});var foo=s(xc);qC=n(foo,"A",{id:!0,class:!0,href:!0});var IQt=s(qC);Q3e=n(IQt,"SPAN",{});var NQt=s(Q3e);T(tk.$$.fragment,NQt),NQt.forEach(t),IQt.forEach(t),Qwr=i(foo),W3e=n(foo,"SPAN",{});var qQt=s(W3e);Wwr=r(qQt,"AutoModelForObjectDetection"),qQt.forEach(t),foo.forEach(t),KKe=i(m),rr=n(m,"DIV",{class:!0});var Hl=s(rr);T(ak.$$.fragment,Hl),Uwr=i(Hl),$c=n(Hl,"P",{});var Qle=s($c);Hwr=r(Qle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),VK=n(Qle,"A",{href:!0});var jQt=s(VK);Jwr=r(jQt,"from_pretrained()"),jQt.forEach(t),Ywr=r(Qle," class method or the "),XK=n(Qle,"A",{href:!0});var DQt=s(XK);Kwr=r(DQt,"from_config()"),DQt.forEach(t),Zwr=r(Qle,` class
method.`),Qle.forEach(t),eAr=i(Hl),nk=n(Hl,"P",{});var goo=s(nk);oAr=r(goo,"This class cannot be instantiated directly using "),U3e=n(goo,"CODE",{});var GQt=s(U3e);rAr=r(GQt,"__init__()"),GQt.forEach(t),tAr=r(goo," (throws an error)."),goo.forEach(t),aAr=i(Hl),Dt=n(Hl,"DIV",{class:!0});var h8=s(Dt);T(sk.$$.fragment,h8),nAr=i(h8),H3e=n(h8,"P",{});var OQt=s(H3e);sAr=r(OQt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),OQt.forEach(t),lAr=i(h8),kc=n(h8,"P",{});var Wle=s(kc);iAr=r(Wle,`Note:
Loading a model from its configuration file does `),J3e=n(Wle,"STRONG",{});var VQt=s(J3e);dAr=r(VQt,"not"),VQt.forEach(t),cAr=r(Wle,` load the model weights. It only affects the
model\u2019s configuration. Use `),zK=n(Wle,"A",{href:!0});var XQt=s(zK);mAr=r(XQt,"from_pretrained()"),XQt.forEach(t),fAr=r(Wle," to load the model weights."),Wle.forEach(t),gAr=i(h8),T(jC.$$.fragment,h8),h8.forEach(t),hAr=i(Hl),Mo=n(Hl,"DIV",{class:!0});var Oa=s(Mo);T(lk.$$.fragment,Oa),uAr=i(Oa),Y3e=n(Oa,"P",{});var zQt=s(Y3e);pAr=r(zQt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),zQt.forEach(t),_Ar=i(Oa),Fn=n(Oa,"P",{});var u8=s(Fn);bAr=r(u8,"The model class to instantiate is selected based on the "),K3e=n(u8,"CODE",{});var QQt=s(K3e);vAr=r(QQt,"model_type"),QQt.forEach(t),FAr=r(u8,` property of the config object (either
passed as an argument or loaded from `),Z3e=n(u8,"CODE",{});var WQt=s(Z3e);TAr=r(WQt,"pretrained_model_name_or_path"),WQt.forEach(t),MAr=r(u8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e5e=n(u8,"CODE",{});var UQt=s(e5e);EAr=r(UQt,"pretrained_model_name_or_path"),UQt.forEach(t),CAr=r(u8,":"),u8.forEach(t),wAr=i(Oa),Sc=n(Oa,"UL",{});var Ule=s(Sc);DC=n(Ule,"LI",{});var wze=s(DC);o5e=n(wze,"STRONG",{});var HQt=s(o5e);AAr=r(HQt,"deformable_detr"),HQt.forEach(t),LAr=r(wze," \u2014 "),QK=n(wze,"A",{href:!0});var JQt=s(QK);yAr=r(JQt,"DeformableDetrForObjectDetection"),JQt.forEach(t),xAr=r(wze," (Deformable DETR model)"),wze.forEach(t),$Ar=i(Ule),GC=n(Ule,"LI",{});var Aze=s(GC);r5e=n(Aze,"STRONG",{});var YQt=s(r5e);kAr=r(YQt,"detr"),YQt.forEach(t),SAr=r(Aze," \u2014 "),WK=n(Aze,"A",{href:!0});var KQt=s(WK);RAr=r(KQt,"DetrForObjectDetection"),KQt.forEach(t),PAr=r(Aze," (DETR model)"),Aze.forEach(t),BAr=i(Ule),OC=n(Ule,"LI",{});var Lze=s(OC);t5e=n(Lze,"STRONG",{});var ZQt=s(t5e);IAr=r(ZQt,"yolos"),ZQt.forEach(t),NAr=r(Lze," \u2014 "),UK=n(Lze,"A",{href:!0});var eWt=s(UK);qAr=r(eWt,"YolosForObjectDetection"),eWt.forEach(t),jAr=r(Lze," (YOLOS model)"),Lze.forEach(t),Ule.forEach(t),DAr=i(Oa),VC=n(Oa,"P",{});var yze=s(VC);GAr=r(yze,"The model is set in evaluation mode by default using "),a5e=n(yze,"CODE",{});var oWt=s(a5e);OAr=r(oWt,"model.eval()"),oWt.forEach(t),VAr=r(yze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n5e=n(yze,"CODE",{});var rWt=s(n5e);XAr=r(rWt,"model.train()"),rWt.forEach(t),yze.forEach(t),zAr=i(Oa),T(XC.$$.fragment,Oa),Oa.forEach(t),Hl.forEach(t),ZKe=i(m),Rc=n(m,"H2",{class:!0});var hoo=s(Rc);zC=n(hoo,"A",{id:!0,class:!0,href:!0});var tWt=s(zC);s5e=n(tWt,"SPAN",{});var aWt=s(s5e);T(ik.$$.fragment,aWt),aWt.forEach(t),tWt.forEach(t),QAr=i(hoo),l5e=n(hoo,"SPAN",{});var nWt=s(l5e);WAr=r(nWt,"AutoModelForImageSegmentation"),nWt.forEach(t),hoo.forEach(t),eZe=i(m),tr=n(m,"DIV",{class:!0});var Jl=s(tr);T(dk.$$.fragment,Jl),UAr=i(Jl),Pc=n(Jl,"P",{});var Hle=s(Pc);HAr=r(Hle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),HK=n(Hle,"A",{href:!0});var sWt=s(HK);JAr=r(sWt,"from_pretrained()"),sWt.forEach(t),YAr=r(Hle," class method or the "),JK=n(Hle,"A",{href:!0});var lWt=s(JK);KAr=r(lWt,"from_config()"),lWt.forEach(t),ZAr=r(Hle,` class
method.`),Hle.forEach(t),e6r=i(Jl),ck=n(Jl,"P",{});var uoo=s(ck);o6r=r(uoo,"This class cannot be instantiated directly using "),i5e=n(uoo,"CODE",{});var iWt=s(i5e);r6r=r(iWt,"__init__()"),iWt.forEach(t),t6r=r(uoo," (throws an error)."),uoo.forEach(t),a6r=i(Jl),Gt=n(Jl,"DIV",{class:!0});var p8=s(Gt);T(mk.$$.fragment,p8),n6r=i(p8),d5e=n(p8,"P",{});var dWt=s(d5e);s6r=r(dWt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),dWt.forEach(t),l6r=i(p8),Bc=n(p8,"P",{});var Jle=s(Bc);i6r=r(Jle,`Note:
Loading a model from its configuration file does `),c5e=n(Jle,"STRONG",{});var cWt=s(c5e);d6r=r(cWt,"not"),cWt.forEach(t),c6r=r(Jle,` load the model weights. It only affects the
model\u2019s configuration. Use `),YK=n(Jle,"A",{href:!0});var mWt=s(YK);m6r=r(mWt,"from_pretrained()"),mWt.forEach(t),f6r=r(Jle," to load the model weights."),Jle.forEach(t),g6r=i(p8),T(QC.$$.fragment,p8),p8.forEach(t),h6r=i(Jl),Eo=n(Jl,"DIV",{class:!0});var Va=s(Eo);T(fk.$$.fragment,Va),u6r=i(Va),m5e=n(Va,"P",{});var fWt=s(m5e);p6r=r(fWt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),fWt.forEach(t),_6r=i(Va),Tn=n(Va,"P",{});var _8=s(Tn);b6r=r(_8,"The model class to instantiate is selected based on the "),f5e=n(_8,"CODE",{});var gWt=s(f5e);v6r=r(gWt,"model_type"),gWt.forEach(t),F6r=r(_8,` property of the config object (either
passed as an argument or loaded from `),g5e=n(_8,"CODE",{});var hWt=s(g5e);T6r=r(hWt,"pretrained_model_name_or_path"),hWt.forEach(t),M6r=r(_8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h5e=n(_8,"CODE",{});var uWt=s(h5e);E6r=r(uWt,"pretrained_model_name_or_path"),uWt.forEach(t),C6r=r(_8,":"),_8.forEach(t),w6r=i(Va),u5e=n(Va,"UL",{});var pWt=s(u5e);WC=n(pWt,"LI",{});var xze=s(WC);p5e=n(xze,"STRONG",{});var _Wt=s(p5e);A6r=r(_Wt,"detr"),_Wt.forEach(t),L6r=r(xze," \u2014 "),KK=n(xze,"A",{href:!0});var bWt=s(KK);y6r=r(bWt,"DetrForSegmentation"),bWt.forEach(t),x6r=r(xze," (DETR model)"),xze.forEach(t),pWt.forEach(t),$6r=i(Va),UC=n(Va,"P",{});var $ze=s(UC);k6r=r($ze,"The model is set in evaluation mode by default using "),_5e=n($ze,"CODE",{});var vWt=s(_5e);S6r=r(vWt,"model.eval()"),vWt.forEach(t),R6r=r($ze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b5e=n($ze,"CODE",{});var FWt=s(b5e);P6r=r(FWt,"model.train()"),FWt.forEach(t),$ze.forEach(t),B6r=i(Va),T(HC.$$.fragment,Va),Va.forEach(t),Jl.forEach(t),oZe=i(m),Ic=n(m,"H2",{class:!0});var poo=s(Ic);JC=n(poo,"A",{id:!0,class:!0,href:!0});var TWt=s(JC);v5e=n(TWt,"SPAN",{});var MWt=s(v5e);T(gk.$$.fragment,MWt),MWt.forEach(t),TWt.forEach(t),I6r=i(poo),F5e=n(poo,"SPAN",{});var EWt=s(F5e);N6r=r(EWt,"AutoModelForSemanticSegmentation"),EWt.forEach(t),poo.forEach(t),rZe=i(m),ar=n(m,"DIV",{class:!0});var Yl=s(ar);T(hk.$$.fragment,Yl),q6r=i(Yl),Nc=n(Yl,"P",{});var Yle=s(Nc);j6r=r(Yle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),ZK=n(Yle,"A",{href:!0});var CWt=s(ZK);D6r=r(CWt,"from_pretrained()"),CWt.forEach(t),G6r=r(Yle," class method or the "),eZ=n(Yle,"A",{href:!0});var wWt=s(eZ);O6r=r(wWt,"from_config()"),wWt.forEach(t),V6r=r(Yle,` class
method.`),Yle.forEach(t),X6r=i(Yl),uk=n(Yl,"P",{});var _oo=s(uk);z6r=r(_oo,"This class cannot be instantiated directly using "),T5e=n(_oo,"CODE",{});var AWt=s(T5e);Q6r=r(AWt,"__init__()"),AWt.forEach(t),W6r=r(_oo," (throws an error)."),_oo.forEach(t),U6r=i(Yl),Ot=n(Yl,"DIV",{class:!0});var b8=s(Ot);T(pk.$$.fragment,b8),H6r=i(b8),M5e=n(b8,"P",{});var LWt=s(M5e);J6r=r(LWt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),LWt.forEach(t),Y6r=i(b8),qc=n(b8,"P",{});var Kle=s(qc);K6r=r(Kle,`Note:
Loading a model from its configuration file does `),E5e=n(Kle,"STRONG",{});var yWt=s(E5e);Z6r=r(yWt,"not"),yWt.forEach(t),e7r=r(Kle,` load the model weights. It only affects the
model\u2019s configuration. Use `),oZ=n(Kle,"A",{href:!0});var xWt=s(oZ);o7r=r(xWt,"from_pretrained()"),xWt.forEach(t),r7r=r(Kle," to load the model weights."),Kle.forEach(t),t7r=i(b8),T(YC.$$.fragment,b8),b8.forEach(t),a7r=i(Yl),Co=n(Yl,"DIV",{class:!0});var Xa=s(Co);T(_k.$$.fragment,Xa),n7r=i(Xa),C5e=n(Xa,"P",{});var $Wt=s(C5e);s7r=r($Wt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),$Wt.forEach(t),l7r=i(Xa),Mn=n(Xa,"P",{});var v8=s(Mn);i7r=r(v8,"The model class to instantiate is selected based on the "),w5e=n(v8,"CODE",{});var kWt=s(w5e);d7r=r(kWt,"model_type"),kWt.forEach(t),c7r=r(v8,` property of the config object (either
passed as an argument or loaded from `),A5e=n(v8,"CODE",{});var SWt=s(A5e);m7r=r(SWt,"pretrained_model_name_or_path"),SWt.forEach(t),f7r=r(v8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L5e=n(v8,"CODE",{});var RWt=s(L5e);g7r=r(RWt,"pretrained_model_name_or_path"),RWt.forEach(t),h7r=r(v8,":"),v8.forEach(t),u7r=i(Xa),gt=n(Xa,"UL",{});var Kl=s(gt);KC=n(Kl,"LI",{});var kze=s(KC);y5e=n(kze,"STRONG",{});var PWt=s(y5e);p7r=r(PWt,"beit"),PWt.forEach(t),_7r=r(kze," \u2014 "),rZ=n(kze,"A",{href:!0});var BWt=s(rZ);b7r=r(BWt,"BeitForSemanticSegmentation"),BWt.forEach(t),v7r=r(kze," (BEiT model)"),kze.forEach(t),F7r=i(Kl),ZC=n(Kl,"LI",{});var Sze=s(ZC);x5e=n(Sze,"STRONG",{});var IWt=s(x5e);T7r=r(IWt,"data2vec-vision"),IWt.forEach(t),M7r=r(Sze," \u2014 "),tZ=n(Sze,"A",{href:!0});var NWt=s(tZ);E7r=r(NWt,"Data2VecVisionForSemanticSegmentation"),NWt.forEach(t),C7r=r(Sze," (Data2VecVision model)"),Sze.forEach(t),w7r=i(Kl),e3=n(Kl,"LI",{});var Rze=s(e3);$5e=n(Rze,"STRONG",{});var qWt=s($5e);A7r=r(qWt,"dpt"),qWt.forEach(t),L7r=r(Rze," \u2014 "),aZ=n(Rze,"A",{href:!0});var jWt=s(aZ);y7r=r(jWt,"DPTForSemanticSegmentation"),jWt.forEach(t),x7r=r(Rze," (DPT model)"),Rze.forEach(t),$7r=i(Kl),o3=n(Kl,"LI",{});var Pze=s(o3);k5e=n(Pze,"STRONG",{});var DWt=s(k5e);k7r=r(DWt,"mobilevit"),DWt.forEach(t),S7r=r(Pze," \u2014 "),nZ=n(Pze,"A",{href:!0});var GWt=s(nZ);R7r=r(GWt,"MobileViTForSemanticSegmentation"),GWt.forEach(t),P7r=r(Pze," (MobileViT model)"),Pze.forEach(t),B7r=i(Kl),r3=n(Kl,"LI",{});var Bze=s(r3);S5e=n(Bze,"STRONG",{});var OWt=s(S5e);I7r=r(OWt,"segformer"),OWt.forEach(t),N7r=r(Bze," \u2014 "),sZ=n(Bze,"A",{href:!0});var VWt=s(sZ);q7r=r(VWt,"SegformerForSemanticSegmentation"),VWt.forEach(t),j7r=r(Bze," (SegFormer model)"),Bze.forEach(t),Kl.forEach(t),D7r=i(Xa),t3=n(Xa,"P",{});var Ize=s(t3);G7r=r(Ize,"The model is set in evaluation mode by default using "),R5e=n(Ize,"CODE",{});var XWt=s(R5e);O7r=r(XWt,"model.eval()"),XWt.forEach(t),V7r=r(Ize,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P5e=n(Ize,"CODE",{});var zWt=s(P5e);X7r=r(zWt,"model.train()"),zWt.forEach(t),Ize.forEach(t),z7r=i(Xa),T(a3.$$.fragment,Xa),Xa.forEach(t),Yl.forEach(t),tZe=i(m),jc=n(m,"H2",{class:!0});var boo=s(jc);n3=n(boo,"A",{id:!0,class:!0,href:!0});var QWt=s(n3);B5e=n(QWt,"SPAN",{});var WWt=s(B5e);T(bk.$$.fragment,WWt),WWt.forEach(t),QWt.forEach(t),Q7r=i(boo),I5e=n(boo,"SPAN",{});var UWt=s(I5e);W7r=r(UWt,"AutoModelForInstanceSegmentation"),UWt.forEach(t),boo.forEach(t),aZe=i(m),nr=n(m,"DIV",{class:!0});var Zl=s(nr);T(vk.$$.fragment,Zl),U7r=i(Zl),Dc=n(Zl,"P",{});var Zle=s(Dc);H7r=r(Zle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),lZ=n(Zle,"A",{href:!0});var HWt=s(lZ);J7r=r(HWt,"from_pretrained()"),HWt.forEach(t),Y7r=r(Zle," class method or the "),iZ=n(Zle,"A",{href:!0});var JWt=s(iZ);K7r=r(JWt,"from_config()"),JWt.forEach(t),Z7r=r(Zle,` class
method.`),Zle.forEach(t),eLr=i(Zl),Fk=n(Zl,"P",{});var voo=s(Fk);oLr=r(voo,"This class cannot be instantiated directly using "),N5e=n(voo,"CODE",{});var YWt=s(N5e);rLr=r(YWt,"__init__()"),YWt.forEach(t),tLr=r(voo," (throws an error)."),voo.forEach(t),aLr=i(Zl),Vt=n(Zl,"DIV",{class:!0});var F8=s(Vt);T(Tk.$$.fragment,F8),nLr=i(F8),q5e=n(F8,"P",{});var KWt=s(q5e);sLr=r(KWt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),KWt.forEach(t),lLr=i(F8),Gc=n(F8,"P",{});var eie=s(Gc);iLr=r(eie,`Note:
Loading a model from its configuration file does `),j5e=n(eie,"STRONG",{});var ZWt=s(j5e);dLr=r(ZWt,"not"),ZWt.forEach(t),cLr=r(eie,` load the model weights. It only affects the
model\u2019s configuration. Use `),dZ=n(eie,"A",{href:!0});var eUt=s(dZ);mLr=r(eUt,"from_pretrained()"),eUt.forEach(t),fLr=r(eie," to load the model weights."),eie.forEach(t),gLr=i(F8),T(s3.$$.fragment,F8),F8.forEach(t),hLr=i(Zl),wo=n(Zl,"DIV",{class:!0});var za=s(wo);T(Mk.$$.fragment,za),uLr=i(za),D5e=n(za,"P",{});var oUt=s(D5e);pLr=r(oUt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),oUt.forEach(t),_Lr=i(za),En=n(za,"P",{});var T8=s(En);bLr=r(T8,"The model class to instantiate is selected based on the "),G5e=n(T8,"CODE",{});var rUt=s(G5e);vLr=r(rUt,"model_type"),rUt.forEach(t),FLr=r(T8,` property of the config object (either
passed as an argument or loaded from `),O5e=n(T8,"CODE",{});var tUt=s(O5e);TLr=r(tUt,"pretrained_model_name_or_path"),tUt.forEach(t),MLr=r(T8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V5e=n(T8,"CODE",{});var aUt=s(V5e);ELr=r(aUt,"pretrained_model_name_or_path"),aUt.forEach(t),CLr=r(T8,":"),T8.forEach(t),wLr=i(za),X5e=n(za,"UL",{});var nUt=s(X5e);l3=n(nUt,"LI",{});var Nze=s(l3);z5e=n(Nze,"STRONG",{});var sUt=s(z5e);ALr=r(sUt,"maskformer"),sUt.forEach(t),LLr=r(Nze," \u2014 "),cZ=n(Nze,"A",{href:!0});var lUt=s(cZ);yLr=r(lUt,"MaskFormerForInstanceSegmentation"),lUt.forEach(t),xLr=r(Nze," (MaskFormer model)"),Nze.forEach(t),nUt.forEach(t),$Lr=i(za),i3=n(za,"P",{});var qze=s(i3);kLr=r(qze,"The model is set in evaluation mode by default using "),Q5e=n(qze,"CODE",{});var iUt=s(Q5e);SLr=r(iUt,"model.eval()"),iUt.forEach(t),RLr=r(qze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W5e=n(qze,"CODE",{});var dUt=s(W5e);PLr=r(dUt,"model.train()"),dUt.forEach(t),qze.forEach(t),BLr=i(za),T(d3.$$.fragment,za),za.forEach(t),Zl.forEach(t),nZe=i(m),Oc=n(m,"H2",{class:!0});var Foo=s(Oc);c3=n(Foo,"A",{id:!0,class:!0,href:!0});var cUt=s(c3);U5e=n(cUt,"SPAN",{});var mUt=s(U5e);T(Ek.$$.fragment,mUt),mUt.forEach(t),cUt.forEach(t),ILr=i(Foo),H5e=n(Foo,"SPAN",{});var fUt=s(H5e);NLr=r(fUt,"TFAutoModel"),fUt.forEach(t),Foo.forEach(t),sZe=i(m),sr=n(m,"DIV",{class:!0});var ei=s(sr);T(Ck.$$.fragment,ei),qLr=i(ei),Vc=n(ei,"P",{});var oie=s(Vc);jLr=r(oie,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),mZ=n(oie,"A",{href:!0});var gUt=s(mZ);DLr=r(gUt,"from_pretrained()"),gUt.forEach(t),GLr=r(oie," class method or the "),fZ=n(oie,"A",{href:!0});var hUt=s(fZ);OLr=r(hUt,"from_config()"),hUt.forEach(t),VLr=r(oie,` class
method.`),oie.forEach(t),XLr=i(ei),wk=n(ei,"P",{});var Too=s(wk);zLr=r(Too,"This class cannot be instantiated directly using "),J5e=n(Too,"CODE",{});var uUt=s(J5e);QLr=r(uUt,"__init__()"),uUt.forEach(t),WLr=r(Too," (throws an error)."),Too.forEach(t),ULr=i(ei),Xt=n(ei,"DIV",{class:!0});var M8=s(Xt);T(Ak.$$.fragment,M8),HLr=i(M8),Y5e=n(M8,"P",{});var pUt=s(Y5e);JLr=r(pUt,"Instantiates one of the base model classes of the library from a configuration."),pUt.forEach(t),YLr=i(M8),Xc=n(M8,"P",{});var rie=s(Xc);KLr=r(rie,`Note:
Loading a model from its configuration file does `),K5e=n(rie,"STRONG",{});var _Ut=s(K5e);ZLr=r(_Ut,"not"),_Ut.forEach(t),eyr=r(rie,` load the model weights. It only affects the
model\u2019s configuration. Use `),gZ=n(rie,"A",{href:!0});var bUt=s(gZ);oyr=r(bUt,"from_pretrained()"),bUt.forEach(t),ryr=r(rie," to load the model weights."),rie.forEach(t),tyr=i(M8),T(m3.$$.fragment,M8),M8.forEach(t),ayr=i(ei),Ir=n(ei,"DIV",{class:!0});var oi=s(Ir);T(Lk.$$.fragment,oi),nyr=i(oi),Z5e=n(oi,"P",{});var vUt=s(Z5e);syr=r(vUt,"Instantiate one of the base model classes of the library from a pretrained model."),vUt.forEach(t),lyr=i(oi),Cn=n(oi,"P",{});var E8=s(Cn);iyr=r(E8,"The model class to instantiate is selected based on the "),e0e=n(E8,"CODE",{});var FUt=s(e0e);dyr=r(FUt,"model_type"),FUt.forEach(t),cyr=r(E8,` property of the config object (either
passed as an argument or loaded from `),o0e=n(E8,"CODE",{});var TUt=s(o0e);myr=r(TUt,"pretrained_model_name_or_path"),TUt.forEach(t),fyr=r(E8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r0e=n(E8,"CODE",{});var MUt=s(r0e);gyr=r(MUt,"pretrained_model_name_or_path"),MUt.forEach(t),hyr=r(E8,":"),E8.forEach(t),uyr=i(oi),N=n(oi,"UL",{});var j=s(N);f3=n(j,"LI",{});var jze=s(f3);t0e=n(jze,"STRONG",{});var EUt=s(t0e);pyr=r(EUt,"albert"),EUt.forEach(t),_yr=r(jze," \u2014 "),hZ=n(jze,"A",{href:!0});var CUt=s(hZ);byr=r(CUt,"TFAlbertModel"),CUt.forEach(t),vyr=r(jze," (ALBERT model)"),jze.forEach(t),Fyr=i(j),g3=n(j,"LI",{});var Dze=s(g3);a0e=n(Dze,"STRONG",{});var wUt=s(a0e);Tyr=r(wUt,"bart"),wUt.forEach(t),Myr=r(Dze," \u2014 "),uZ=n(Dze,"A",{href:!0});var AUt=s(uZ);Eyr=r(AUt,"TFBartModel"),AUt.forEach(t),Cyr=r(Dze," (BART model)"),Dze.forEach(t),wyr=i(j),h3=n(j,"LI",{});var Gze=s(h3);n0e=n(Gze,"STRONG",{});var LUt=s(n0e);Ayr=r(LUt,"bert"),LUt.forEach(t),Lyr=r(Gze," \u2014 "),pZ=n(Gze,"A",{href:!0});var yUt=s(pZ);yyr=r(yUt,"TFBertModel"),yUt.forEach(t),xyr=r(Gze," (BERT model)"),Gze.forEach(t),$yr=i(j),u3=n(j,"LI",{});var Oze=s(u3);s0e=n(Oze,"STRONG",{});var xUt=s(s0e);kyr=r(xUt,"blenderbot"),xUt.forEach(t),Syr=r(Oze," \u2014 "),_Z=n(Oze,"A",{href:!0});var $Ut=s(_Z);Ryr=r($Ut,"TFBlenderbotModel"),$Ut.forEach(t),Pyr=r(Oze," (Blenderbot model)"),Oze.forEach(t),Byr=i(j),p3=n(j,"LI",{});var Vze=s(p3);l0e=n(Vze,"STRONG",{});var kUt=s(l0e);Iyr=r(kUt,"blenderbot-small"),kUt.forEach(t),Nyr=r(Vze," \u2014 "),bZ=n(Vze,"A",{href:!0});var SUt=s(bZ);qyr=r(SUt,"TFBlenderbotSmallModel"),SUt.forEach(t),jyr=r(Vze," (BlenderbotSmall model)"),Vze.forEach(t),Dyr=i(j),_3=n(j,"LI",{});var Xze=s(_3);i0e=n(Xze,"STRONG",{});var RUt=s(i0e);Gyr=r(RUt,"camembert"),RUt.forEach(t),Oyr=r(Xze," \u2014 "),vZ=n(Xze,"A",{href:!0});var PUt=s(vZ);Vyr=r(PUt,"TFCamembertModel"),PUt.forEach(t),Xyr=r(Xze," (CamemBERT model)"),Xze.forEach(t),zyr=i(j),b3=n(j,"LI",{});var zze=s(b3);d0e=n(zze,"STRONG",{});var BUt=s(d0e);Qyr=r(BUt,"clip"),BUt.forEach(t),Wyr=r(zze," \u2014 "),FZ=n(zze,"A",{href:!0});var IUt=s(FZ);Uyr=r(IUt,"TFCLIPModel"),IUt.forEach(t),Hyr=r(zze," (CLIP model)"),zze.forEach(t),Jyr=i(j),v3=n(j,"LI",{});var Qze=s(v3);c0e=n(Qze,"STRONG",{});var NUt=s(c0e);Yyr=r(NUt,"convbert"),NUt.forEach(t),Kyr=r(Qze," \u2014 "),TZ=n(Qze,"A",{href:!0});var qUt=s(TZ);Zyr=r(qUt,"TFConvBertModel"),qUt.forEach(t),e8r=r(Qze," (ConvBERT model)"),Qze.forEach(t),o8r=i(j),F3=n(j,"LI",{});var Wze=s(F3);m0e=n(Wze,"STRONG",{});var jUt=s(m0e);r8r=r(jUt,"convnext"),jUt.forEach(t),t8r=r(Wze," \u2014 "),MZ=n(Wze,"A",{href:!0});var DUt=s(MZ);a8r=r(DUt,"TFConvNextModel"),DUt.forEach(t),n8r=r(Wze," (ConvNeXT model)"),Wze.forEach(t),s8r=i(j),T3=n(j,"LI",{});var Uze=s(T3);f0e=n(Uze,"STRONG",{});var GUt=s(f0e);l8r=r(GUt,"ctrl"),GUt.forEach(t),i8r=r(Uze," \u2014 "),EZ=n(Uze,"A",{href:!0});var OUt=s(EZ);d8r=r(OUt,"TFCTRLModel"),OUt.forEach(t),c8r=r(Uze," (CTRL model)"),Uze.forEach(t),m8r=i(j),M3=n(j,"LI",{});var Hze=s(M3);g0e=n(Hze,"STRONG",{});var VUt=s(g0e);f8r=r(VUt,"data2vec-vision"),VUt.forEach(t),g8r=r(Hze," \u2014 "),CZ=n(Hze,"A",{href:!0});var XUt=s(CZ);h8r=r(XUt,"TFData2VecVisionModel"),XUt.forEach(t),u8r=r(Hze," (Data2VecVision model)"),Hze.forEach(t),p8r=i(j),E3=n(j,"LI",{});var Jze=s(E3);h0e=n(Jze,"STRONG",{});var zUt=s(h0e);_8r=r(zUt,"deberta"),zUt.forEach(t),b8r=r(Jze," \u2014 "),wZ=n(Jze,"A",{href:!0});var QUt=s(wZ);v8r=r(QUt,"TFDebertaModel"),QUt.forEach(t),F8r=r(Jze," (DeBERTa model)"),Jze.forEach(t),T8r=i(j),C3=n(j,"LI",{});var Yze=s(C3);u0e=n(Yze,"STRONG",{});var WUt=s(u0e);M8r=r(WUt,"deberta-v2"),WUt.forEach(t),E8r=r(Yze," \u2014 "),AZ=n(Yze,"A",{href:!0});var UUt=s(AZ);C8r=r(UUt,"TFDebertaV2Model"),UUt.forEach(t),w8r=r(Yze," (DeBERTa-v2 model)"),Yze.forEach(t),A8r=i(j),w3=n(j,"LI",{});var Kze=s(w3);p0e=n(Kze,"STRONG",{});var HUt=s(p0e);L8r=r(HUt,"deit"),HUt.forEach(t),y8r=r(Kze," \u2014 "),LZ=n(Kze,"A",{href:!0});var JUt=s(LZ);x8r=r(JUt,"TFDeiTModel"),JUt.forEach(t),$8r=r(Kze," (DeiT model)"),Kze.forEach(t),k8r=i(j),A3=n(j,"LI",{});var Zze=s(A3);_0e=n(Zze,"STRONG",{});var YUt=s(_0e);S8r=r(YUt,"distilbert"),YUt.forEach(t),R8r=r(Zze," \u2014 "),yZ=n(Zze,"A",{href:!0});var KUt=s(yZ);P8r=r(KUt,"TFDistilBertModel"),KUt.forEach(t),B8r=r(Zze," (DistilBERT model)"),Zze.forEach(t),I8r=i(j),L3=n(j,"LI",{});var eQe=s(L3);b0e=n(eQe,"STRONG",{});var ZUt=s(b0e);N8r=r(ZUt,"dpr"),ZUt.forEach(t),q8r=r(eQe," \u2014 "),xZ=n(eQe,"A",{href:!0});var eHt=s(xZ);j8r=r(eHt,"TFDPRQuestionEncoder"),eHt.forEach(t),D8r=r(eQe," (DPR model)"),eQe.forEach(t),G8r=i(j),y3=n(j,"LI",{});var oQe=s(y3);v0e=n(oQe,"STRONG",{});var oHt=s(v0e);O8r=r(oHt,"electra"),oHt.forEach(t),V8r=r(oQe," \u2014 "),$Z=n(oQe,"A",{href:!0});var rHt=s($Z);X8r=r(rHt,"TFElectraModel"),rHt.forEach(t),z8r=r(oQe," (ELECTRA model)"),oQe.forEach(t),Q8r=i(j),x3=n(j,"LI",{});var rQe=s(x3);F0e=n(rQe,"STRONG",{});var tHt=s(F0e);W8r=r(tHt,"flaubert"),tHt.forEach(t),U8r=r(rQe," \u2014 "),kZ=n(rQe,"A",{href:!0});var aHt=s(kZ);H8r=r(aHt,"TFFlaubertModel"),aHt.forEach(t),J8r=r(rQe," (FlauBERT model)"),rQe.forEach(t),Y8r=i(j),vl=n(j,"LI",{});var AB=s(vl);T0e=n(AB,"STRONG",{});var nHt=s(T0e);K8r=r(nHt,"funnel"),nHt.forEach(t),Z8r=r(AB," \u2014 "),SZ=n(AB,"A",{href:!0});var sHt=s(SZ);e9r=r(sHt,"TFFunnelModel"),sHt.forEach(t),o9r=r(AB," or "),RZ=n(AB,"A",{href:!0});var lHt=s(RZ);r9r=r(lHt,"TFFunnelBaseModel"),lHt.forEach(t),t9r=r(AB," (Funnel Transformer model)"),AB.forEach(t),a9r=i(j),$3=n(j,"LI",{});var tQe=s($3);M0e=n(tQe,"STRONG",{});var iHt=s(M0e);n9r=r(iHt,"gpt2"),iHt.forEach(t),s9r=r(tQe," \u2014 "),PZ=n(tQe,"A",{href:!0});var dHt=s(PZ);l9r=r(dHt,"TFGPT2Model"),dHt.forEach(t),i9r=r(tQe," (OpenAI GPT-2 model)"),tQe.forEach(t),d9r=i(j),k3=n(j,"LI",{});var aQe=s(k3);E0e=n(aQe,"STRONG",{});var cHt=s(E0e);c9r=r(cHt,"gptj"),cHt.forEach(t),m9r=r(aQe," \u2014 "),BZ=n(aQe,"A",{href:!0});var mHt=s(BZ);f9r=r(mHt,"TFGPTJModel"),mHt.forEach(t),g9r=r(aQe," (GPT-J model)"),aQe.forEach(t),h9r=i(j),S3=n(j,"LI",{});var nQe=s(S3);C0e=n(nQe,"STRONG",{});var fHt=s(C0e);u9r=r(fHt,"hubert"),fHt.forEach(t),p9r=r(nQe," \u2014 "),IZ=n(nQe,"A",{href:!0});var gHt=s(IZ);_9r=r(gHt,"TFHubertModel"),gHt.forEach(t),b9r=r(nQe," (Hubert model)"),nQe.forEach(t),v9r=i(j),R3=n(j,"LI",{});var sQe=s(R3);w0e=n(sQe,"STRONG",{});var hHt=s(w0e);F9r=r(hHt,"layoutlm"),hHt.forEach(t),T9r=r(sQe," \u2014 "),NZ=n(sQe,"A",{href:!0});var uHt=s(NZ);M9r=r(uHt,"TFLayoutLMModel"),uHt.forEach(t),E9r=r(sQe," (LayoutLM model)"),sQe.forEach(t),C9r=i(j),P3=n(j,"LI",{});var lQe=s(P3);A0e=n(lQe,"STRONG",{});var pHt=s(A0e);w9r=r(pHt,"layoutlmv3"),pHt.forEach(t),A9r=r(lQe," \u2014 "),qZ=n(lQe,"A",{href:!0});var _Ht=s(qZ);L9r=r(_Ht,"TFLayoutLMv3Model"),_Ht.forEach(t),y9r=r(lQe," (LayoutLMv3 model)"),lQe.forEach(t),x9r=i(j),B3=n(j,"LI",{});var iQe=s(B3);L0e=n(iQe,"STRONG",{});var bHt=s(L0e);$9r=r(bHt,"led"),bHt.forEach(t),k9r=r(iQe," \u2014 "),jZ=n(iQe,"A",{href:!0});var vHt=s(jZ);S9r=r(vHt,"TFLEDModel"),vHt.forEach(t),R9r=r(iQe," (LED model)"),iQe.forEach(t),P9r=i(j),I3=n(j,"LI",{});var dQe=s(I3);y0e=n(dQe,"STRONG",{});var FHt=s(y0e);B9r=r(FHt,"longformer"),FHt.forEach(t),I9r=r(dQe," \u2014 "),DZ=n(dQe,"A",{href:!0});var THt=s(DZ);N9r=r(THt,"TFLongformerModel"),THt.forEach(t),q9r=r(dQe," (Longformer model)"),dQe.forEach(t),j9r=i(j),N3=n(j,"LI",{});var cQe=s(N3);x0e=n(cQe,"STRONG",{});var MHt=s(x0e);D9r=r(MHt,"lxmert"),MHt.forEach(t),G9r=r(cQe," \u2014 "),GZ=n(cQe,"A",{href:!0});var EHt=s(GZ);O9r=r(EHt,"TFLxmertModel"),EHt.forEach(t),V9r=r(cQe," (LXMERT model)"),cQe.forEach(t),X9r=i(j),q3=n(j,"LI",{});var mQe=s(q3);$0e=n(mQe,"STRONG",{});var CHt=s($0e);z9r=r(CHt,"marian"),CHt.forEach(t),Q9r=r(mQe," \u2014 "),OZ=n(mQe,"A",{href:!0});var wHt=s(OZ);W9r=r(wHt,"TFMarianModel"),wHt.forEach(t),U9r=r(mQe," (Marian model)"),mQe.forEach(t),H9r=i(j),j3=n(j,"LI",{});var fQe=s(j3);k0e=n(fQe,"STRONG",{});var AHt=s(k0e);J9r=r(AHt,"mbart"),AHt.forEach(t),Y9r=r(fQe," \u2014 "),VZ=n(fQe,"A",{href:!0});var LHt=s(VZ);K9r=r(LHt,"TFMBartModel"),LHt.forEach(t),Z9r=r(fQe," (mBART model)"),fQe.forEach(t),exr=i(j),D3=n(j,"LI",{});var gQe=s(D3);S0e=n(gQe,"STRONG",{});var yHt=s(S0e);oxr=r(yHt,"mobilebert"),yHt.forEach(t),rxr=r(gQe," \u2014 "),XZ=n(gQe,"A",{href:!0});var xHt=s(XZ);txr=r(xHt,"TFMobileBertModel"),xHt.forEach(t),axr=r(gQe," (MobileBERT model)"),gQe.forEach(t),nxr=i(j),G3=n(j,"LI",{});var hQe=s(G3);R0e=n(hQe,"STRONG",{});var $Ht=s(R0e);sxr=r($Ht,"mobilevit"),$Ht.forEach(t),lxr=r(hQe," \u2014 "),zZ=n(hQe,"A",{href:!0});var kHt=s(zZ);ixr=r(kHt,"TFMobileViTModel"),kHt.forEach(t),dxr=r(hQe," (MobileViT model)"),hQe.forEach(t),cxr=i(j),O3=n(j,"LI",{});var uQe=s(O3);P0e=n(uQe,"STRONG",{});var SHt=s(P0e);mxr=r(SHt,"mpnet"),SHt.forEach(t),fxr=r(uQe," \u2014 "),QZ=n(uQe,"A",{href:!0});var RHt=s(QZ);gxr=r(RHt,"TFMPNetModel"),RHt.forEach(t),hxr=r(uQe," (MPNet model)"),uQe.forEach(t),uxr=i(j),V3=n(j,"LI",{});var pQe=s(V3);B0e=n(pQe,"STRONG",{});var PHt=s(B0e);pxr=r(PHt,"mt5"),PHt.forEach(t),_xr=r(pQe," \u2014 "),WZ=n(pQe,"A",{href:!0});var BHt=s(WZ);bxr=r(BHt,"TFMT5Model"),BHt.forEach(t),vxr=r(pQe," (MT5 model)"),pQe.forEach(t),Fxr=i(j),X3=n(j,"LI",{});var _Qe=s(X3);I0e=n(_Qe,"STRONG",{});var IHt=s(I0e);Txr=r(IHt,"openai-gpt"),IHt.forEach(t),Mxr=r(_Qe," \u2014 "),UZ=n(_Qe,"A",{href:!0});var NHt=s(UZ);Exr=r(NHt,"TFOpenAIGPTModel"),NHt.forEach(t),Cxr=r(_Qe," (OpenAI GPT model)"),_Qe.forEach(t),wxr=i(j),z3=n(j,"LI",{});var bQe=s(z3);N0e=n(bQe,"STRONG",{});var qHt=s(N0e);Axr=r(qHt,"opt"),qHt.forEach(t),Lxr=r(bQe," \u2014 "),HZ=n(bQe,"A",{href:!0});var jHt=s(HZ);yxr=r(jHt,"TFOPTModel"),jHt.forEach(t),xxr=r(bQe," (OPT model)"),bQe.forEach(t),$xr=i(j),Q3=n(j,"LI",{});var vQe=s(Q3);q0e=n(vQe,"STRONG",{});var DHt=s(q0e);kxr=r(DHt,"pegasus"),DHt.forEach(t),Sxr=r(vQe," \u2014 "),JZ=n(vQe,"A",{href:!0});var GHt=s(JZ);Rxr=r(GHt,"TFPegasusModel"),GHt.forEach(t),Pxr=r(vQe," (Pegasus model)"),vQe.forEach(t),Bxr=i(j),W3=n(j,"LI",{});var FQe=s(W3);j0e=n(FQe,"STRONG",{});var OHt=s(j0e);Ixr=r(OHt,"regnet"),OHt.forEach(t),Nxr=r(FQe," \u2014 "),YZ=n(FQe,"A",{href:!0});var VHt=s(YZ);qxr=r(VHt,"TFRegNetModel"),VHt.forEach(t),jxr=r(FQe," (RegNet model)"),FQe.forEach(t),Dxr=i(j),U3=n(j,"LI",{});var TQe=s(U3);D0e=n(TQe,"STRONG",{});var XHt=s(D0e);Gxr=r(XHt,"rembert"),XHt.forEach(t),Oxr=r(TQe," \u2014 "),KZ=n(TQe,"A",{href:!0});var zHt=s(KZ);Vxr=r(zHt,"TFRemBertModel"),zHt.forEach(t),Xxr=r(TQe," (RemBERT model)"),TQe.forEach(t),zxr=i(j),H3=n(j,"LI",{});var MQe=s(H3);G0e=n(MQe,"STRONG",{});var QHt=s(G0e);Qxr=r(QHt,"resnet"),QHt.forEach(t),Wxr=r(MQe," \u2014 "),ZZ=n(MQe,"A",{href:!0});var WHt=s(ZZ);Uxr=r(WHt,"TFResNetModel"),WHt.forEach(t),Hxr=r(MQe," (ResNet model)"),MQe.forEach(t),Jxr=i(j),J3=n(j,"LI",{});var EQe=s(J3);O0e=n(EQe,"STRONG",{});var UHt=s(O0e);Yxr=r(UHt,"roberta"),UHt.forEach(t),Kxr=r(EQe," \u2014 "),eee=n(EQe,"A",{href:!0});var HHt=s(eee);Zxr=r(HHt,"TFRobertaModel"),HHt.forEach(t),e$r=r(EQe," (RoBERTa model)"),EQe.forEach(t),o$r=i(j),Y3=n(j,"LI",{});var CQe=s(Y3);V0e=n(CQe,"STRONG",{});var JHt=s(V0e);r$r=r(JHt,"roformer"),JHt.forEach(t),t$r=r(CQe," \u2014 "),oee=n(CQe,"A",{href:!0});var YHt=s(oee);a$r=r(YHt,"TFRoFormerModel"),YHt.forEach(t),n$r=r(CQe," (RoFormer model)"),CQe.forEach(t),s$r=i(j),K3=n(j,"LI",{});var wQe=s(K3);X0e=n(wQe,"STRONG",{});var KHt=s(X0e);l$r=r(KHt,"segformer"),KHt.forEach(t),i$r=r(wQe," \u2014 "),ree=n(wQe,"A",{href:!0});var ZHt=s(ree);d$r=r(ZHt,"TFSegformerModel"),ZHt.forEach(t),c$r=r(wQe," (SegFormer model)"),wQe.forEach(t),m$r=i(j),Z3=n(j,"LI",{});var AQe=s(Z3);z0e=n(AQe,"STRONG",{});var eJt=s(z0e);f$r=r(eJt,"speech_to_text"),eJt.forEach(t),g$r=r(AQe," \u2014 "),tee=n(AQe,"A",{href:!0});var oJt=s(tee);h$r=r(oJt,"TFSpeech2TextModel"),oJt.forEach(t),u$r=r(AQe," (Speech2Text model)"),AQe.forEach(t),p$r=i(j),e5=n(j,"LI",{});var LQe=s(e5);Q0e=n(LQe,"STRONG",{});var rJt=s(Q0e);_$r=r(rJt,"swin"),rJt.forEach(t),b$r=r(LQe," \u2014 "),aee=n(LQe,"A",{href:!0});var tJt=s(aee);v$r=r(tJt,"TFSwinModel"),tJt.forEach(t),F$r=r(LQe," (Swin Transformer model)"),LQe.forEach(t),T$r=i(j),o5=n(j,"LI",{});var yQe=s(o5);W0e=n(yQe,"STRONG",{});var aJt=s(W0e);M$r=r(aJt,"t5"),aJt.forEach(t),E$r=r(yQe," \u2014 "),nee=n(yQe,"A",{href:!0});var nJt=s(nee);C$r=r(nJt,"TFT5Model"),nJt.forEach(t),w$r=r(yQe," (T5 model)"),yQe.forEach(t),A$r=i(j),r5=n(j,"LI",{});var xQe=s(r5);U0e=n(xQe,"STRONG",{});var sJt=s(U0e);L$r=r(sJt,"tapas"),sJt.forEach(t),y$r=r(xQe," \u2014 "),see=n(xQe,"A",{href:!0});var lJt=s(see);x$r=r(lJt,"TFTapasModel"),lJt.forEach(t),$$r=r(xQe," (TAPAS model)"),xQe.forEach(t),k$r=i(j),t5=n(j,"LI",{});var $Qe=s(t5);H0e=n($Qe,"STRONG",{});var iJt=s(H0e);S$r=r(iJt,"transfo-xl"),iJt.forEach(t),R$r=r($Qe," \u2014 "),lee=n($Qe,"A",{href:!0});var dJt=s(lee);P$r=r(dJt,"TFTransfoXLModel"),dJt.forEach(t),B$r=r($Qe," (Transformer-XL model)"),$Qe.forEach(t),I$r=i(j),a5=n(j,"LI",{});var kQe=s(a5);J0e=n(kQe,"STRONG",{});var cJt=s(J0e);N$r=r(cJt,"vit"),cJt.forEach(t),q$r=r(kQe," \u2014 "),iee=n(kQe,"A",{href:!0});var mJt=s(iee);j$r=r(mJt,"TFViTModel"),mJt.forEach(t),D$r=r(kQe," (ViT model)"),kQe.forEach(t),G$r=i(j),n5=n(j,"LI",{});var SQe=s(n5);Y0e=n(SQe,"STRONG",{});var fJt=s(Y0e);O$r=r(fJt,"vit_mae"),fJt.forEach(t),V$r=r(SQe," \u2014 "),dee=n(SQe,"A",{href:!0});var gJt=s(dee);X$r=r(gJt,"TFViTMAEModel"),gJt.forEach(t),z$r=r(SQe," (ViTMAE model)"),SQe.forEach(t),Q$r=i(j),s5=n(j,"LI",{});var RQe=s(s5);K0e=n(RQe,"STRONG",{});var hJt=s(K0e);W$r=r(hJt,"wav2vec2"),hJt.forEach(t),U$r=r(RQe," \u2014 "),cee=n(RQe,"A",{href:!0});var uJt=s(cee);H$r=r(uJt,"TFWav2Vec2Model"),uJt.forEach(t),J$r=r(RQe," (Wav2Vec2 model)"),RQe.forEach(t),Y$r=i(j),l5=n(j,"LI",{});var PQe=s(l5);Z0e=n(PQe,"STRONG",{});var pJt=s(Z0e);K$r=r(pJt,"xglm"),pJt.forEach(t),Z$r=r(PQe," \u2014 "),mee=n(PQe,"A",{href:!0});var _Jt=s(mee);ekr=r(_Jt,"TFXGLMModel"),_Jt.forEach(t),okr=r(PQe," (XGLM model)"),PQe.forEach(t),rkr=i(j),i5=n(j,"LI",{});var BQe=s(i5);ewe=n(BQe,"STRONG",{});var bJt=s(ewe);tkr=r(bJt,"xlm"),bJt.forEach(t),akr=r(BQe," \u2014 "),fee=n(BQe,"A",{href:!0});var vJt=s(fee);nkr=r(vJt,"TFXLMModel"),vJt.forEach(t),skr=r(BQe," (XLM model)"),BQe.forEach(t),lkr=i(j),d5=n(j,"LI",{});var IQe=s(d5);owe=n(IQe,"STRONG",{});var FJt=s(owe);ikr=r(FJt,"xlm-roberta"),FJt.forEach(t),dkr=r(IQe," \u2014 "),gee=n(IQe,"A",{href:!0});var TJt=s(gee);ckr=r(TJt,"TFXLMRobertaModel"),TJt.forEach(t),mkr=r(IQe," (XLM-RoBERTa model)"),IQe.forEach(t),fkr=i(j),c5=n(j,"LI",{});var NQe=s(c5);rwe=n(NQe,"STRONG",{});var MJt=s(rwe);gkr=r(MJt,"xlnet"),MJt.forEach(t),hkr=r(NQe," \u2014 "),hee=n(NQe,"A",{href:!0});var EJt=s(hee);ukr=r(EJt,"TFXLNetModel"),EJt.forEach(t),pkr=r(NQe," (XLNet model)"),NQe.forEach(t),j.forEach(t),_kr=i(oi),T(m5.$$.fragment,oi),oi.forEach(t),ei.forEach(t),lZe=i(m),zc=n(m,"H2",{class:!0});var Moo=s(zc);f5=n(Moo,"A",{id:!0,class:!0,href:!0});var CJt=s(f5);twe=n(CJt,"SPAN",{});var wJt=s(twe);T(yk.$$.fragment,wJt),wJt.forEach(t),CJt.forEach(t),bkr=i(Moo),awe=n(Moo,"SPAN",{});var AJt=s(awe);vkr=r(AJt,"TFAutoModelForPreTraining"),AJt.forEach(t),Moo.forEach(t),iZe=i(m),lr=n(m,"DIV",{class:!0});var ri=s(lr);T(xk.$$.fragment,ri),Fkr=i(ri),Qc=n(ri,"P",{});var tie=s(Qc);Tkr=r(tie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),uee=n(tie,"A",{href:!0});var LJt=s(uee);Mkr=r(LJt,"from_pretrained()"),LJt.forEach(t),Ekr=r(tie," class method or the "),pee=n(tie,"A",{href:!0});var yJt=s(pee);Ckr=r(yJt,"from_config()"),yJt.forEach(t),wkr=r(tie,` class
method.`),tie.forEach(t),Akr=i(ri),$k=n(ri,"P",{});var Eoo=s($k);Lkr=r(Eoo,"This class cannot be instantiated directly using "),nwe=n(Eoo,"CODE",{});var xJt=s(nwe);ykr=r(xJt,"__init__()"),xJt.forEach(t),xkr=r(Eoo," (throws an error)."),Eoo.forEach(t),$kr=i(ri),zt=n(ri,"DIV",{class:!0});var C8=s(zt);T(kk.$$.fragment,C8),kkr=i(C8),swe=n(C8,"P",{});var $Jt=s(swe);Skr=r($Jt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),$Jt.forEach(t),Rkr=i(C8),Wc=n(C8,"P",{});var aie=s(Wc);Pkr=r(aie,`Note:
Loading a model from its configuration file does `),lwe=n(aie,"STRONG",{});var kJt=s(lwe);Bkr=r(kJt,"not"),kJt.forEach(t),Ikr=r(aie,` load the model weights. It only affects the
model\u2019s configuration. Use `),_ee=n(aie,"A",{href:!0});var SJt=s(_ee);Nkr=r(SJt,"from_pretrained()"),SJt.forEach(t),qkr=r(aie," to load the model weights."),aie.forEach(t),jkr=i(C8),T(g5.$$.fragment,C8),C8.forEach(t),Dkr=i(ri),Nr=n(ri,"DIV",{class:!0});var ti=s(Nr);T(Sk.$$.fragment,ti),Gkr=i(ti),iwe=n(ti,"P",{});var RJt=s(iwe);Okr=r(RJt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),RJt.forEach(t),Vkr=i(ti),wn=n(ti,"P",{});var w8=s(wn);Xkr=r(w8,"The model class to instantiate is selected based on the "),dwe=n(w8,"CODE",{});var PJt=s(dwe);zkr=r(PJt,"model_type"),PJt.forEach(t),Qkr=r(w8,` property of the config object (either
passed as an argument or loaded from `),cwe=n(w8,"CODE",{});var BJt=s(cwe);Wkr=r(BJt,"pretrained_model_name_or_path"),BJt.forEach(t),Ukr=r(w8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mwe=n(w8,"CODE",{});var IJt=s(mwe);Hkr=r(IJt,"pretrained_model_name_or_path"),IJt.forEach(t),Jkr=r(w8,":"),w8.forEach(t),Ykr=i(ti),se=n(ti,"UL",{});var le=s(se);h5=n(le,"LI",{});var qQe=s(h5);fwe=n(qQe,"STRONG",{});var NJt=s(fwe);Kkr=r(NJt,"albert"),NJt.forEach(t),Zkr=r(qQe," \u2014 "),bee=n(qQe,"A",{href:!0});var qJt=s(bee);eSr=r(qJt,"TFAlbertForPreTraining"),qJt.forEach(t),oSr=r(qQe," (ALBERT model)"),qQe.forEach(t),rSr=i(le),u5=n(le,"LI",{});var jQe=s(u5);gwe=n(jQe,"STRONG",{});var jJt=s(gwe);tSr=r(jJt,"bart"),jJt.forEach(t),aSr=r(jQe," \u2014 "),vee=n(jQe,"A",{href:!0});var DJt=s(vee);nSr=r(DJt,"TFBartForConditionalGeneration"),DJt.forEach(t),sSr=r(jQe," (BART model)"),jQe.forEach(t),lSr=i(le),p5=n(le,"LI",{});var DQe=s(p5);hwe=n(DQe,"STRONG",{});var GJt=s(hwe);iSr=r(GJt,"bert"),GJt.forEach(t),dSr=r(DQe," \u2014 "),Fee=n(DQe,"A",{href:!0});var OJt=s(Fee);cSr=r(OJt,"TFBertForPreTraining"),OJt.forEach(t),mSr=r(DQe," (BERT model)"),DQe.forEach(t),fSr=i(le),_5=n(le,"LI",{});var GQe=s(_5);uwe=n(GQe,"STRONG",{});var VJt=s(uwe);gSr=r(VJt,"camembert"),VJt.forEach(t),hSr=r(GQe," \u2014 "),Tee=n(GQe,"A",{href:!0});var XJt=s(Tee);uSr=r(XJt,"TFCamembertForMaskedLM"),XJt.forEach(t),pSr=r(GQe," (CamemBERT model)"),GQe.forEach(t),_Sr=i(le),b5=n(le,"LI",{});var OQe=s(b5);pwe=n(OQe,"STRONG",{});var zJt=s(pwe);bSr=r(zJt,"ctrl"),zJt.forEach(t),vSr=r(OQe," \u2014 "),Mee=n(OQe,"A",{href:!0});var QJt=s(Mee);FSr=r(QJt,"TFCTRLLMHeadModel"),QJt.forEach(t),TSr=r(OQe," (CTRL model)"),OQe.forEach(t),MSr=i(le),v5=n(le,"LI",{});var VQe=s(v5);_we=n(VQe,"STRONG",{});var WJt=s(_we);ESr=r(WJt,"distilbert"),WJt.forEach(t),CSr=r(VQe," \u2014 "),Eee=n(VQe,"A",{href:!0});var UJt=s(Eee);wSr=r(UJt,"TFDistilBertForMaskedLM"),UJt.forEach(t),ASr=r(VQe," (DistilBERT model)"),VQe.forEach(t),LSr=i(le),F5=n(le,"LI",{});var XQe=s(F5);bwe=n(XQe,"STRONG",{});var HJt=s(bwe);ySr=r(HJt,"electra"),HJt.forEach(t),xSr=r(XQe," \u2014 "),Cee=n(XQe,"A",{href:!0});var JJt=s(Cee);$Sr=r(JJt,"TFElectraForPreTraining"),JJt.forEach(t),kSr=r(XQe," (ELECTRA model)"),XQe.forEach(t),SSr=i(le),T5=n(le,"LI",{});var zQe=s(T5);vwe=n(zQe,"STRONG",{});var YJt=s(vwe);RSr=r(YJt,"flaubert"),YJt.forEach(t),PSr=r(zQe," \u2014 "),wee=n(zQe,"A",{href:!0});var KJt=s(wee);BSr=r(KJt,"TFFlaubertWithLMHeadModel"),KJt.forEach(t),ISr=r(zQe," (FlauBERT model)"),zQe.forEach(t),NSr=i(le),M5=n(le,"LI",{});var QQe=s(M5);Fwe=n(QQe,"STRONG",{});var ZJt=s(Fwe);qSr=r(ZJt,"funnel"),ZJt.forEach(t),jSr=r(QQe," \u2014 "),Aee=n(QQe,"A",{href:!0});var eYt=s(Aee);DSr=r(eYt,"TFFunnelForPreTraining"),eYt.forEach(t),GSr=r(QQe," (Funnel Transformer model)"),QQe.forEach(t),OSr=i(le),E5=n(le,"LI",{});var WQe=s(E5);Twe=n(WQe,"STRONG",{});var oYt=s(Twe);VSr=r(oYt,"gpt2"),oYt.forEach(t),XSr=r(WQe," \u2014 "),Lee=n(WQe,"A",{href:!0});var rYt=s(Lee);zSr=r(rYt,"TFGPT2LMHeadModel"),rYt.forEach(t),QSr=r(WQe," (OpenAI GPT-2 model)"),WQe.forEach(t),WSr=i(le),C5=n(le,"LI",{});var UQe=s(C5);Mwe=n(UQe,"STRONG",{});var tYt=s(Mwe);USr=r(tYt,"layoutlm"),tYt.forEach(t),HSr=r(UQe," \u2014 "),yee=n(UQe,"A",{href:!0});var aYt=s(yee);JSr=r(aYt,"TFLayoutLMForMaskedLM"),aYt.forEach(t),YSr=r(UQe," (LayoutLM model)"),UQe.forEach(t),KSr=i(le),w5=n(le,"LI",{});var HQe=s(w5);Ewe=n(HQe,"STRONG",{});var nYt=s(Ewe);ZSr=r(nYt,"lxmert"),nYt.forEach(t),eRr=r(HQe," \u2014 "),xee=n(HQe,"A",{href:!0});var sYt=s(xee);oRr=r(sYt,"TFLxmertForPreTraining"),sYt.forEach(t),rRr=r(HQe," (LXMERT model)"),HQe.forEach(t),tRr=i(le),A5=n(le,"LI",{});var JQe=s(A5);Cwe=n(JQe,"STRONG",{});var lYt=s(Cwe);aRr=r(lYt,"mobilebert"),lYt.forEach(t),nRr=r(JQe," \u2014 "),$ee=n(JQe,"A",{href:!0});var iYt=s($ee);sRr=r(iYt,"TFMobileBertForPreTraining"),iYt.forEach(t),lRr=r(JQe," (MobileBERT model)"),JQe.forEach(t),iRr=i(le),L5=n(le,"LI",{});var YQe=s(L5);wwe=n(YQe,"STRONG",{});var dYt=s(wwe);dRr=r(dYt,"mpnet"),dYt.forEach(t),cRr=r(YQe," \u2014 "),kee=n(YQe,"A",{href:!0});var cYt=s(kee);mRr=r(cYt,"TFMPNetForMaskedLM"),cYt.forEach(t),fRr=r(YQe," (MPNet model)"),YQe.forEach(t),gRr=i(le),y5=n(le,"LI",{});var KQe=s(y5);Awe=n(KQe,"STRONG",{});var mYt=s(Awe);hRr=r(mYt,"openai-gpt"),mYt.forEach(t),uRr=r(KQe," \u2014 "),See=n(KQe,"A",{href:!0});var fYt=s(See);pRr=r(fYt,"TFOpenAIGPTLMHeadModel"),fYt.forEach(t),_Rr=r(KQe," (OpenAI GPT model)"),KQe.forEach(t),bRr=i(le),x5=n(le,"LI",{});var ZQe=s(x5);Lwe=n(ZQe,"STRONG",{});var gYt=s(Lwe);vRr=r(gYt,"roberta"),gYt.forEach(t),FRr=r(ZQe," \u2014 "),Ree=n(ZQe,"A",{href:!0});var hYt=s(Ree);TRr=r(hYt,"TFRobertaForMaskedLM"),hYt.forEach(t),MRr=r(ZQe," (RoBERTa model)"),ZQe.forEach(t),ERr=i(le),$5=n(le,"LI",{});var eWe=s($5);ywe=n(eWe,"STRONG",{});var uYt=s(ywe);CRr=r(uYt,"t5"),uYt.forEach(t),wRr=r(eWe," \u2014 "),Pee=n(eWe,"A",{href:!0});var pYt=s(Pee);ARr=r(pYt,"TFT5ForConditionalGeneration"),pYt.forEach(t),LRr=r(eWe," (T5 model)"),eWe.forEach(t),yRr=i(le),k5=n(le,"LI",{});var oWe=s(k5);xwe=n(oWe,"STRONG",{});var _Yt=s(xwe);xRr=r(_Yt,"tapas"),_Yt.forEach(t),$Rr=r(oWe," \u2014 "),Bee=n(oWe,"A",{href:!0});var bYt=s(Bee);kRr=r(bYt,"TFTapasForMaskedLM"),bYt.forEach(t),SRr=r(oWe," (TAPAS model)"),oWe.forEach(t),RRr=i(le),S5=n(le,"LI",{});var rWe=s(S5);$we=n(rWe,"STRONG",{});var vYt=s($we);PRr=r(vYt,"transfo-xl"),vYt.forEach(t),BRr=r(rWe," \u2014 "),Iee=n(rWe,"A",{href:!0});var FYt=s(Iee);IRr=r(FYt,"TFTransfoXLLMHeadModel"),FYt.forEach(t),NRr=r(rWe," (Transformer-XL model)"),rWe.forEach(t),qRr=i(le),R5=n(le,"LI",{});var tWe=s(R5);kwe=n(tWe,"STRONG",{});var TYt=s(kwe);jRr=r(TYt,"vit_mae"),TYt.forEach(t),DRr=r(tWe," \u2014 "),Nee=n(tWe,"A",{href:!0});var MYt=s(Nee);GRr=r(MYt,"TFViTMAEForPreTraining"),MYt.forEach(t),ORr=r(tWe," (ViTMAE model)"),tWe.forEach(t),VRr=i(le),P5=n(le,"LI",{});var aWe=s(P5);Swe=n(aWe,"STRONG",{});var EYt=s(Swe);XRr=r(EYt,"xlm"),EYt.forEach(t),zRr=r(aWe," \u2014 "),qee=n(aWe,"A",{href:!0});var CYt=s(qee);QRr=r(CYt,"TFXLMWithLMHeadModel"),CYt.forEach(t),WRr=r(aWe," (XLM model)"),aWe.forEach(t),URr=i(le),B5=n(le,"LI",{});var nWe=s(B5);Rwe=n(nWe,"STRONG",{});var wYt=s(Rwe);HRr=r(wYt,"xlm-roberta"),wYt.forEach(t),JRr=r(nWe," \u2014 "),jee=n(nWe,"A",{href:!0});var AYt=s(jee);YRr=r(AYt,"TFXLMRobertaForMaskedLM"),AYt.forEach(t),KRr=r(nWe," (XLM-RoBERTa model)"),nWe.forEach(t),ZRr=i(le),I5=n(le,"LI",{});var sWe=s(I5);Pwe=n(sWe,"STRONG",{});var LYt=s(Pwe);ePr=r(LYt,"xlnet"),LYt.forEach(t),oPr=r(sWe," \u2014 "),Dee=n(sWe,"A",{href:!0});var yYt=s(Dee);rPr=r(yYt,"TFXLNetLMHeadModel"),yYt.forEach(t),tPr=r(sWe," (XLNet model)"),sWe.forEach(t),le.forEach(t),aPr=i(ti),T(N5.$$.fragment,ti),ti.forEach(t),ri.forEach(t),dZe=i(m),Uc=n(m,"H2",{class:!0});var Coo=s(Uc);q5=n(Coo,"A",{id:!0,class:!0,href:!0});var xYt=s(q5);Bwe=n(xYt,"SPAN",{});var $Yt=s(Bwe);T(Rk.$$.fragment,$Yt),$Yt.forEach(t),xYt.forEach(t),nPr=i(Coo),Iwe=n(Coo,"SPAN",{});var kYt=s(Iwe);sPr=r(kYt,"TFAutoModelForCausalLM"),kYt.forEach(t),Coo.forEach(t),cZe=i(m),ir=n(m,"DIV",{class:!0});var ai=s(ir);T(Pk.$$.fragment,ai),lPr=i(ai),Hc=n(ai,"P",{});var nie=s(Hc);iPr=r(nie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Gee=n(nie,"A",{href:!0});var SYt=s(Gee);dPr=r(SYt,"from_pretrained()"),SYt.forEach(t),cPr=r(nie," class method or the "),Oee=n(nie,"A",{href:!0});var RYt=s(Oee);mPr=r(RYt,"from_config()"),RYt.forEach(t),fPr=r(nie,` class
method.`),nie.forEach(t),gPr=i(ai),Bk=n(ai,"P",{});var woo=s(Bk);hPr=r(woo,"This class cannot be instantiated directly using "),Nwe=n(woo,"CODE",{});var PYt=s(Nwe);uPr=r(PYt,"__init__()"),PYt.forEach(t),pPr=r(woo," (throws an error)."),woo.forEach(t),_Pr=i(ai),Qt=n(ai,"DIV",{class:!0});var A8=s(Qt);T(Ik.$$.fragment,A8),bPr=i(A8),qwe=n(A8,"P",{});var BYt=s(qwe);vPr=r(BYt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),BYt.forEach(t),FPr=i(A8),Jc=n(A8,"P",{});var sie=s(Jc);TPr=r(sie,`Note:
Loading a model from its configuration file does `),jwe=n(sie,"STRONG",{});var IYt=s(jwe);MPr=r(IYt,"not"),IYt.forEach(t),EPr=r(sie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vee=n(sie,"A",{href:!0});var NYt=s(Vee);CPr=r(NYt,"from_pretrained()"),NYt.forEach(t),wPr=r(sie," to load the model weights."),sie.forEach(t),APr=i(A8),T(j5.$$.fragment,A8),A8.forEach(t),LPr=i(ai),qr=n(ai,"DIV",{class:!0});var ni=s(qr);T(Nk.$$.fragment,ni),yPr=i(ni),Dwe=n(ni,"P",{});var qYt=s(Dwe);xPr=r(qYt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),qYt.forEach(t),$Pr=i(ni),An=n(ni,"P",{});var L8=s(An);kPr=r(L8,"The model class to instantiate is selected based on the "),Gwe=n(L8,"CODE",{});var jYt=s(Gwe);SPr=r(jYt,"model_type"),jYt.forEach(t),RPr=r(L8,` property of the config object (either
passed as an argument or loaded from `),Owe=n(L8,"CODE",{});var DYt=s(Owe);PPr=r(DYt,"pretrained_model_name_or_path"),DYt.forEach(t),BPr=r(L8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vwe=n(L8,"CODE",{});var GYt=s(Vwe);IPr=r(GYt,"pretrained_model_name_or_path"),GYt.forEach(t),NPr=r(L8,":"),L8.forEach(t),qPr=i(ni),Me=n(ni,"UL",{});var Ce=s(Me);D5=n(Ce,"LI",{});var lWe=s(D5);Xwe=n(lWe,"STRONG",{});var OYt=s(Xwe);jPr=r(OYt,"bert"),OYt.forEach(t),DPr=r(lWe," \u2014 "),Xee=n(lWe,"A",{href:!0});var VYt=s(Xee);GPr=r(VYt,"TFBertLMHeadModel"),VYt.forEach(t),OPr=r(lWe," (BERT model)"),lWe.forEach(t),VPr=i(Ce),G5=n(Ce,"LI",{});var iWe=s(G5);zwe=n(iWe,"STRONG",{});var XYt=s(zwe);XPr=r(XYt,"camembert"),XYt.forEach(t),zPr=r(iWe," \u2014 "),zee=n(iWe,"A",{href:!0});var zYt=s(zee);QPr=r(zYt,"TFCamembertForCausalLM"),zYt.forEach(t),WPr=r(iWe," (CamemBERT model)"),iWe.forEach(t),UPr=i(Ce),O5=n(Ce,"LI",{});var dWe=s(O5);Qwe=n(dWe,"STRONG",{});var QYt=s(Qwe);HPr=r(QYt,"ctrl"),QYt.forEach(t),JPr=r(dWe," \u2014 "),Qee=n(dWe,"A",{href:!0});var WYt=s(Qee);YPr=r(WYt,"TFCTRLLMHeadModel"),WYt.forEach(t),KPr=r(dWe," (CTRL model)"),dWe.forEach(t),ZPr=i(Ce),V5=n(Ce,"LI",{});var cWe=s(V5);Wwe=n(cWe,"STRONG",{});var UYt=s(Wwe);eBr=r(UYt,"gpt2"),UYt.forEach(t),oBr=r(cWe," \u2014 "),Wee=n(cWe,"A",{href:!0});var HYt=s(Wee);rBr=r(HYt,"TFGPT2LMHeadModel"),HYt.forEach(t),tBr=r(cWe," (OpenAI GPT-2 model)"),cWe.forEach(t),aBr=i(Ce),X5=n(Ce,"LI",{});var mWe=s(X5);Uwe=n(mWe,"STRONG",{});var JYt=s(Uwe);nBr=r(JYt,"gptj"),JYt.forEach(t),sBr=r(mWe," \u2014 "),Uee=n(mWe,"A",{href:!0});var YYt=s(Uee);lBr=r(YYt,"TFGPTJForCausalLM"),YYt.forEach(t),iBr=r(mWe," (GPT-J model)"),mWe.forEach(t),dBr=i(Ce),z5=n(Ce,"LI",{});var fWe=s(z5);Hwe=n(fWe,"STRONG",{});var KYt=s(Hwe);cBr=r(KYt,"openai-gpt"),KYt.forEach(t),mBr=r(fWe," \u2014 "),Hee=n(fWe,"A",{href:!0});var ZYt=s(Hee);fBr=r(ZYt,"TFOpenAIGPTLMHeadModel"),ZYt.forEach(t),gBr=r(fWe," (OpenAI GPT model)"),fWe.forEach(t),hBr=i(Ce),Q5=n(Ce,"LI",{});var gWe=s(Q5);Jwe=n(gWe,"STRONG",{});var eKt=s(Jwe);uBr=r(eKt,"opt"),eKt.forEach(t),pBr=r(gWe," \u2014 "),Jee=n(gWe,"A",{href:!0});var oKt=s(Jee);_Br=r(oKt,"TFOPTForCausalLM"),oKt.forEach(t),bBr=r(gWe," (OPT model)"),gWe.forEach(t),vBr=i(Ce),W5=n(Ce,"LI",{});var hWe=s(W5);Ywe=n(hWe,"STRONG",{});var rKt=s(Ywe);FBr=r(rKt,"rembert"),rKt.forEach(t),TBr=r(hWe," \u2014 "),Yee=n(hWe,"A",{href:!0});var tKt=s(Yee);MBr=r(tKt,"TFRemBertForCausalLM"),tKt.forEach(t),EBr=r(hWe," (RemBERT model)"),hWe.forEach(t),CBr=i(Ce),U5=n(Ce,"LI",{});var uWe=s(U5);Kwe=n(uWe,"STRONG",{});var aKt=s(Kwe);wBr=r(aKt,"roberta"),aKt.forEach(t),ABr=r(uWe," \u2014 "),Kee=n(uWe,"A",{href:!0});var nKt=s(Kee);LBr=r(nKt,"TFRobertaForCausalLM"),nKt.forEach(t),yBr=r(uWe," (RoBERTa model)"),uWe.forEach(t),xBr=i(Ce),H5=n(Ce,"LI",{});var pWe=s(H5);Zwe=n(pWe,"STRONG",{});var sKt=s(Zwe);$Br=r(sKt,"roformer"),sKt.forEach(t),kBr=r(pWe," \u2014 "),Zee=n(pWe,"A",{href:!0});var lKt=s(Zee);SBr=r(lKt,"TFRoFormerForCausalLM"),lKt.forEach(t),RBr=r(pWe," (RoFormer model)"),pWe.forEach(t),PBr=i(Ce),J5=n(Ce,"LI",{});var _We=s(J5);eAe=n(_We,"STRONG",{});var iKt=s(eAe);BBr=r(iKt,"transfo-xl"),iKt.forEach(t),IBr=r(_We," \u2014 "),eoe=n(_We,"A",{href:!0});var dKt=s(eoe);NBr=r(dKt,"TFTransfoXLLMHeadModel"),dKt.forEach(t),qBr=r(_We," (Transformer-XL model)"),_We.forEach(t),jBr=i(Ce),Y5=n(Ce,"LI",{});var bWe=s(Y5);oAe=n(bWe,"STRONG",{});var cKt=s(oAe);DBr=r(cKt,"xglm"),cKt.forEach(t),GBr=r(bWe," \u2014 "),ooe=n(bWe,"A",{href:!0});var mKt=s(ooe);OBr=r(mKt,"TFXGLMForCausalLM"),mKt.forEach(t),VBr=r(bWe," (XGLM model)"),bWe.forEach(t),XBr=i(Ce),K5=n(Ce,"LI",{});var vWe=s(K5);rAe=n(vWe,"STRONG",{});var fKt=s(rAe);zBr=r(fKt,"xlm"),fKt.forEach(t),QBr=r(vWe," \u2014 "),roe=n(vWe,"A",{href:!0});var gKt=s(roe);WBr=r(gKt,"TFXLMWithLMHeadModel"),gKt.forEach(t),UBr=r(vWe," (XLM model)"),vWe.forEach(t),HBr=i(Ce),Z5=n(Ce,"LI",{});var FWe=s(Z5);tAe=n(FWe,"STRONG",{});var hKt=s(tAe);JBr=r(hKt,"xlnet"),hKt.forEach(t),YBr=r(FWe," \u2014 "),toe=n(FWe,"A",{href:!0});var uKt=s(toe);KBr=r(uKt,"TFXLNetLMHeadModel"),uKt.forEach(t),ZBr=r(FWe," (XLNet model)"),FWe.forEach(t),Ce.forEach(t),eIr=i(ni),T(e0.$$.fragment,ni),ni.forEach(t),ai.forEach(t),mZe=i(m),Yc=n(m,"H2",{class:!0});var Aoo=s(Yc);o0=n(Aoo,"A",{id:!0,class:!0,href:!0});var pKt=s(o0);aAe=n(pKt,"SPAN",{});var _Kt=s(aAe);T(qk.$$.fragment,_Kt),_Kt.forEach(t),pKt.forEach(t),oIr=i(Aoo),nAe=n(Aoo,"SPAN",{});var bKt=s(nAe);rIr=r(bKt,"TFAutoModelForImageClassification"),bKt.forEach(t),Aoo.forEach(t),fZe=i(m),dr=n(m,"DIV",{class:!0});var si=s(dr);T(jk.$$.fragment,si),tIr=i(si),Kc=n(si,"P",{});var lie=s(Kc);aIr=r(lie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),aoe=n(lie,"A",{href:!0});var vKt=s(aoe);nIr=r(vKt,"from_pretrained()"),vKt.forEach(t),sIr=r(lie," class method or the "),noe=n(lie,"A",{href:!0});var FKt=s(noe);lIr=r(FKt,"from_config()"),FKt.forEach(t),iIr=r(lie,` class
method.`),lie.forEach(t),dIr=i(si),Dk=n(si,"P",{});var Loo=s(Dk);cIr=r(Loo,"This class cannot be instantiated directly using "),sAe=n(Loo,"CODE",{});var TKt=s(sAe);mIr=r(TKt,"__init__()"),TKt.forEach(t),fIr=r(Loo," (throws an error)."),Loo.forEach(t),gIr=i(si),Wt=n(si,"DIV",{class:!0});var y8=s(Wt);T(Gk.$$.fragment,y8),hIr=i(y8),lAe=n(y8,"P",{});var MKt=s(lAe);uIr=r(MKt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),MKt.forEach(t),pIr=i(y8),Zc=n(y8,"P",{});var iie=s(Zc);_Ir=r(iie,`Note:
Loading a model from its configuration file does `),iAe=n(iie,"STRONG",{});var EKt=s(iAe);bIr=r(EKt,"not"),EKt.forEach(t),vIr=r(iie,` load the model weights. It only affects the
model\u2019s configuration. Use `),soe=n(iie,"A",{href:!0});var CKt=s(soe);FIr=r(CKt,"from_pretrained()"),CKt.forEach(t),TIr=r(iie," to load the model weights."),iie.forEach(t),MIr=i(y8),T(r0.$$.fragment,y8),y8.forEach(t),EIr=i(si),jr=n(si,"DIV",{class:!0});var li=s(jr);T(Ok.$$.fragment,li),CIr=i(li),dAe=n(li,"P",{});var wKt=s(dAe);wIr=r(wKt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),wKt.forEach(t),AIr=i(li),Ln=n(li,"P",{});var x8=s(Ln);LIr=r(x8,"The model class to instantiate is selected based on the "),cAe=n(x8,"CODE",{});var AKt=s(cAe);yIr=r(AKt,"model_type"),AKt.forEach(t),xIr=r(x8,` property of the config object (either
passed as an argument or loaded from `),mAe=n(x8,"CODE",{});var LKt=s(mAe);$Ir=r(LKt,"pretrained_model_name_or_path"),LKt.forEach(t),kIr=r(x8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fAe=n(x8,"CODE",{});var yKt=s(fAe);SIr=r(yKt,"pretrained_model_name_or_path"),yKt.forEach(t),RIr=r(x8,":"),x8.forEach(t),PIr=i(li),Be=n(li,"UL",{});var We=s(Be);t0=n(We,"LI",{});var TWe=s(t0);gAe=n(TWe,"STRONG",{});var xKt=s(gAe);BIr=r(xKt,"convnext"),xKt.forEach(t),IIr=r(TWe," \u2014 "),loe=n(TWe,"A",{href:!0});var $Kt=s(loe);NIr=r($Kt,"TFConvNextForImageClassification"),$Kt.forEach(t),qIr=r(TWe," (ConvNeXT model)"),TWe.forEach(t),jIr=i(We),a0=n(We,"LI",{});var MWe=s(a0);hAe=n(MWe,"STRONG",{});var kKt=s(hAe);DIr=r(kKt,"data2vec-vision"),kKt.forEach(t),GIr=r(MWe," \u2014 "),ioe=n(MWe,"A",{href:!0});var SKt=s(ioe);OIr=r(SKt,"TFData2VecVisionForImageClassification"),SKt.forEach(t),VIr=r(MWe," (Data2VecVision model)"),MWe.forEach(t),XIr=i(We),Fl=n(We,"LI",{});var LB=s(Fl);uAe=n(LB,"STRONG",{});var RKt=s(uAe);zIr=r(RKt,"deit"),RKt.forEach(t),QIr=r(LB," \u2014 "),doe=n(LB,"A",{href:!0});var PKt=s(doe);WIr=r(PKt,"TFDeiTForImageClassification"),PKt.forEach(t),UIr=r(LB," or "),coe=n(LB,"A",{href:!0});var BKt=s(coe);HIr=r(BKt,"TFDeiTForImageClassificationWithTeacher"),BKt.forEach(t),JIr=r(LB," (DeiT model)"),LB.forEach(t),YIr=i(We),n0=n(We,"LI",{});var EWe=s(n0);pAe=n(EWe,"STRONG",{});var IKt=s(pAe);KIr=r(IKt,"mobilevit"),IKt.forEach(t),ZIr=r(EWe," \u2014 "),moe=n(EWe,"A",{href:!0});var NKt=s(moe);eNr=r(NKt,"TFMobileViTForImageClassification"),NKt.forEach(t),oNr=r(EWe," (MobileViT model)"),EWe.forEach(t),rNr=i(We),s0=n(We,"LI",{});var CWe=s(s0);_Ae=n(CWe,"STRONG",{});var qKt=s(_Ae);tNr=r(qKt,"regnet"),qKt.forEach(t),aNr=r(CWe," \u2014 "),foe=n(CWe,"A",{href:!0});var jKt=s(foe);nNr=r(jKt,"TFRegNetForImageClassification"),jKt.forEach(t),sNr=r(CWe," (RegNet model)"),CWe.forEach(t),lNr=i(We),l0=n(We,"LI",{});var wWe=s(l0);bAe=n(wWe,"STRONG",{});var DKt=s(bAe);iNr=r(DKt,"resnet"),DKt.forEach(t),dNr=r(wWe," \u2014 "),goe=n(wWe,"A",{href:!0});var GKt=s(goe);cNr=r(GKt,"TFResNetForImageClassification"),GKt.forEach(t),mNr=r(wWe," (ResNet model)"),wWe.forEach(t),fNr=i(We),i0=n(We,"LI",{});var AWe=s(i0);vAe=n(AWe,"STRONG",{});var OKt=s(vAe);gNr=r(OKt,"segformer"),OKt.forEach(t),hNr=r(AWe," \u2014 "),hoe=n(AWe,"A",{href:!0});var VKt=s(hoe);uNr=r(VKt,"TFSegformerForImageClassification"),VKt.forEach(t),pNr=r(AWe," (SegFormer model)"),AWe.forEach(t),_Nr=i(We),d0=n(We,"LI",{});var LWe=s(d0);FAe=n(LWe,"STRONG",{});var XKt=s(FAe);bNr=r(XKt,"swin"),XKt.forEach(t),vNr=r(LWe," \u2014 "),uoe=n(LWe,"A",{href:!0});var zKt=s(uoe);FNr=r(zKt,"TFSwinForImageClassification"),zKt.forEach(t),TNr=r(LWe," (Swin Transformer model)"),LWe.forEach(t),MNr=i(We),c0=n(We,"LI",{});var yWe=s(c0);TAe=n(yWe,"STRONG",{});var QKt=s(TAe);ENr=r(QKt,"vit"),QKt.forEach(t),CNr=r(yWe," \u2014 "),poe=n(yWe,"A",{href:!0});var WKt=s(poe);wNr=r(WKt,"TFViTForImageClassification"),WKt.forEach(t),ANr=r(yWe," (ViT model)"),yWe.forEach(t),We.forEach(t),LNr=i(li),T(m0.$$.fragment,li),li.forEach(t),si.forEach(t),gZe=i(m),em=n(m,"H2",{class:!0});var yoo=s(em);f0=n(yoo,"A",{id:!0,class:!0,href:!0});var UKt=s(f0);MAe=n(UKt,"SPAN",{});var HKt=s(MAe);T(Vk.$$.fragment,HKt),HKt.forEach(t),UKt.forEach(t),yNr=i(yoo),EAe=n(yoo,"SPAN",{});var JKt=s(EAe);xNr=r(JKt,"TFAutoModelForSemanticSegmentation"),JKt.forEach(t),yoo.forEach(t),hZe=i(m),cr=n(m,"DIV",{class:!0});var ii=s(cr);T(Xk.$$.fragment,ii),$Nr=i(ii),om=n(ii,"P",{});var die=s(om);kNr=r(die,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),_oe=n(die,"A",{href:!0});var YKt=s(_oe);SNr=r(YKt,"from_pretrained()"),YKt.forEach(t),RNr=r(die," class method or the "),boe=n(die,"A",{href:!0});var KKt=s(boe);PNr=r(KKt,"from_config()"),KKt.forEach(t),BNr=r(die,` class
method.`),die.forEach(t),INr=i(ii),zk=n(ii,"P",{});var xoo=s(zk);NNr=r(xoo,"This class cannot be instantiated directly using "),CAe=n(xoo,"CODE",{});var ZKt=s(CAe);qNr=r(ZKt,"__init__()"),ZKt.forEach(t),jNr=r(xoo," (throws an error)."),xoo.forEach(t),DNr=i(ii),Ut=n(ii,"DIV",{class:!0});var $8=s(Ut);T(Qk.$$.fragment,$8),GNr=i($8),wAe=n($8,"P",{});var eZt=s(wAe);ONr=r(eZt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),eZt.forEach(t),VNr=i($8),rm=n($8,"P",{});var cie=s(rm);XNr=r(cie,`Note:
Loading a model from its configuration file does `),AAe=n(cie,"STRONG",{});var oZt=s(AAe);zNr=r(oZt,"not"),oZt.forEach(t),QNr=r(cie,` load the model weights. It only affects the
model\u2019s configuration. Use `),voe=n(cie,"A",{href:!0});var rZt=s(voe);WNr=r(rZt,"from_pretrained()"),rZt.forEach(t),UNr=r(cie," to load the model weights."),cie.forEach(t),HNr=i($8),T(g0.$$.fragment,$8),$8.forEach(t),JNr=i(ii),Dr=n(ii,"DIV",{class:!0});var di=s(Dr);T(Wk.$$.fragment,di),YNr=i(di),LAe=n(di,"P",{});var tZt=s(LAe);KNr=r(tZt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),tZt.forEach(t),ZNr=i(di),yn=n(di,"P",{});var k8=s(yn);eqr=r(k8,"The model class to instantiate is selected based on the "),yAe=n(k8,"CODE",{});var aZt=s(yAe);oqr=r(aZt,"model_type"),aZt.forEach(t),rqr=r(k8,` property of the config object (either
passed as an argument or loaded from `),xAe=n(k8,"CODE",{});var nZt=s(xAe);tqr=r(nZt,"pretrained_model_name_or_path"),nZt.forEach(t),aqr=r(k8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ae=n(k8,"CODE",{});var sZt=s($Ae);nqr=r(sZt,"pretrained_model_name_or_path"),sZt.forEach(t),sqr=r(k8,":"),k8.forEach(t),lqr=i(di),tm=n(di,"UL",{});var mie=s(tm);h0=n(mie,"LI",{});var xWe=s(h0);kAe=n(xWe,"STRONG",{});var lZt=s(kAe);iqr=r(lZt,"data2vec-vision"),lZt.forEach(t),dqr=r(xWe," \u2014 "),Foe=n(xWe,"A",{href:!0});var iZt=s(Foe);cqr=r(iZt,"TFData2VecVisionForSemanticSegmentation"),iZt.forEach(t),mqr=r(xWe," (Data2VecVision model)"),xWe.forEach(t),fqr=i(mie),u0=n(mie,"LI",{});var $We=s(u0);SAe=n($We,"STRONG",{});var dZt=s(SAe);gqr=r(dZt,"mobilevit"),dZt.forEach(t),hqr=r($We," \u2014 "),Toe=n($We,"A",{href:!0});var cZt=s(Toe);uqr=r(cZt,"TFMobileViTForSemanticSegmentation"),cZt.forEach(t),pqr=r($We," (MobileViT model)"),$We.forEach(t),_qr=i(mie),p0=n(mie,"LI",{});var kWe=s(p0);RAe=n(kWe,"STRONG",{});var mZt=s(RAe);bqr=r(mZt,"segformer"),mZt.forEach(t),vqr=r(kWe," \u2014 "),Moe=n(kWe,"A",{href:!0});var fZt=s(Moe);Fqr=r(fZt,"TFSegformerForSemanticSegmentation"),fZt.forEach(t),Tqr=r(kWe," (SegFormer model)"),kWe.forEach(t),mie.forEach(t),Mqr=i(di),T(_0.$$.fragment,di),di.forEach(t),ii.forEach(t),uZe=i(m),am=n(m,"H2",{class:!0});var $oo=s(am);b0=n($oo,"A",{id:!0,class:!0,href:!0});var gZt=s(b0);PAe=n(gZt,"SPAN",{});var hZt=s(PAe);T(Uk.$$.fragment,hZt),hZt.forEach(t),gZt.forEach(t),Eqr=i($oo),BAe=n($oo,"SPAN",{});var uZt=s(BAe);Cqr=r(uZt,"TFAutoModelForMaskedLM"),uZt.forEach(t),$oo.forEach(t),pZe=i(m),mr=n(m,"DIV",{class:!0});var ci=s(mr);T(Hk.$$.fragment,ci),wqr=i(ci),nm=n(ci,"P",{});var fie=s(nm);Aqr=r(fie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Eoe=n(fie,"A",{href:!0});var pZt=s(Eoe);Lqr=r(pZt,"from_pretrained()"),pZt.forEach(t),yqr=r(fie," class method or the "),Coe=n(fie,"A",{href:!0});var _Zt=s(Coe);xqr=r(_Zt,"from_config()"),_Zt.forEach(t),$qr=r(fie,` class
method.`),fie.forEach(t),kqr=i(ci),Jk=n(ci,"P",{});var koo=s(Jk);Sqr=r(koo,"This class cannot be instantiated directly using "),IAe=n(koo,"CODE",{});var bZt=s(IAe);Rqr=r(bZt,"__init__()"),bZt.forEach(t),Pqr=r(koo," (throws an error)."),koo.forEach(t),Bqr=i(ci),Ht=n(ci,"DIV",{class:!0});var S8=s(Ht);T(Yk.$$.fragment,S8),Iqr=i(S8),NAe=n(S8,"P",{});var vZt=s(NAe);Nqr=r(vZt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),vZt.forEach(t),qqr=i(S8),sm=n(S8,"P",{});var gie=s(sm);jqr=r(gie,`Note:
Loading a model from its configuration file does `),qAe=n(gie,"STRONG",{});var FZt=s(qAe);Dqr=r(FZt,"not"),FZt.forEach(t),Gqr=r(gie,` load the model weights. It only affects the
model\u2019s configuration. Use `),woe=n(gie,"A",{href:!0});var TZt=s(woe);Oqr=r(TZt,"from_pretrained()"),TZt.forEach(t),Vqr=r(gie," to load the model weights."),gie.forEach(t),Xqr=i(S8),T(v0.$$.fragment,S8),S8.forEach(t),zqr=i(ci),Gr=n(ci,"DIV",{class:!0});var mi=s(Gr);T(Kk.$$.fragment,mi),Qqr=i(mi),jAe=n(mi,"P",{});var MZt=s(jAe);Wqr=r(MZt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),MZt.forEach(t),Uqr=i(mi),xn=n(mi,"P",{});var R8=s(xn);Hqr=r(R8,"The model class to instantiate is selected based on the "),DAe=n(R8,"CODE",{});var EZt=s(DAe);Jqr=r(EZt,"model_type"),EZt.forEach(t),Yqr=r(R8,` property of the config object (either
passed as an argument or loaded from `),GAe=n(R8,"CODE",{});var CZt=s(GAe);Kqr=r(CZt,"pretrained_model_name_or_path"),CZt.forEach(t),Zqr=r(R8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),OAe=n(R8,"CODE",{});var wZt=s(OAe);ejr=r(wZt,"pretrained_model_name_or_path"),wZt.forEach(t),ojr=r(R8,":"),R8.forEach(t),rjr=i(mi),fe=n(mi,"UL",{});var _e=s(fe);F0=n(_e,"LI",{});var SWe=s(F0);VAe=n(SWe,"STRONG",{});var AZt=s(VAe);tjr=r(AZt,"albert"),AZt.forEach(t),ajr=r(SWe," \u2014 "),Aoe=n(SWe,"A",{href:!0});var LZt=s(Aoe);njr=r(LZt,"TFAlbertForMaskedLM"),LZt.forEach(t),sjr=r(SWe," (ALBERT model)"),SWe.forEach(t),ljr=i(_e),T0=n(_e,"LI",{});var RWe=s(T0);XAe=n(RWe,"STRONG",{});var yZt=s(XAe);ijr=r(yZt,"bert"),yZt.forEach(t),djr=r(RWe," \u2014 "),Loe=n(RWe,"A",{href:!0});var xZt=s(Loe);cjr=r(xZt,"TFBertForMaskedLM"),xZt.forEach(t),mjr=r(RWe," (BERT model)"),RWe.forEach(t),fjr=i(_e),M0=n(_e,"LI",{});var PWe=s(M0);zAe=n(PWe,"STRONG",{});var $Zt=s(zAe);gjr=r($Zt,"camembert"),$Zt.forEach(t),hjr=r(PWe," \u2014 "),yoe=n(PWe,"A",{href:!0});var kZt=s(yoe);ujr=r(kZt,"TFCamembertForMaskedLM"),kZt.forEach(t),pjr=r(PWe," (CamemBERT model)"),PWe.forEach(t),_jr=i(_e),E0=n(_e,"LI",{});var BWe=s(E0);QAe=n(BWe,"STRONG",{});var SZt=s(QAe);bjr=r(SZt,"convbert"),SZt.forEach(t),vjr=r(BWe," \u2014 "),xoe=n(BWe,"A",{href:!0});var RZt=s(xoe);Fjr=r(RZt,"TFConvBertForMaskedLM"),RZt.forEach(t),Tjr=r(BWe," (ConvBERT model)"),BWe.forEach(t),Mjr=i(_e),C0=n(_e,"LI",{});var IWe=s(C0);WAe=n(IWe,"STRONG",{});var PZt=s(WAe);Ejr=r(PZt,"deberta"),PZt.forEach(t),Cjr=r(IWe," \u2014 "),$oe=n(IWe,"A",{href:!0});var BZt=s($oe);wjr=r(BZt,"TFDebertaForMaskedLM"),BZt.forEach(t),Ajr=r(IWe," (DeBERTa model)"),IWe.forEach(t),Ljr=i(_e),w0=n(_e,"LI",{});var NWe=s(w0);UAe=n(NWe,"STRONG",{});var IZt=s(UAe);yjr=r(IZt,"deberta-v2"),IZt.forEach(t),xjr=r(NWe," \u2014 "),koe=n(NWe,"A",{href:!0});var NZt=s(koe);$jr=r(NZt,"TFDebertaV2ForMaskedLM"),NZt.forEach(t),kjr=r(NWe," (DeBERTa-v2 model)"),NWe.forEach(t),Sjr=i(_e),A0=n(_e,"LI",{});var qWe=s(A0);HAe=n(qWe,"STRONG",{});var qZt=s(HAe);Rjr=r(qZt,"distilbert"),qZt.forEach(t),Pjr=r(qWe," \u2014 "),Soe=n(qWe,"A",{href:!0});var jZt=s(Soe);Bjr=r(jZt,"TFDistilBertForMaskedLM"),jZt.forEach(t),Ijr=r(qWe," (DistilBERT model)"),qWe.forEach(t),Njr=i(_e),L0=n(_e,"LI",{});var jWe=s(L0);JAe=n(jWe,"STRONG",{});var DZt=s(JAe);qjr=r(DZt,"electra"),DZt.forEach(t),jjr=r(jWe," \u2014 "),Roe=n(jWe,"A",{href:!0});var GZt=s(Roe);Djr=r(GZt,"TFElectraForMaskedLM"),GZt.forEach(t),Gjr=r(jWe," (ELECTRA model)"),jWe.forEach(t),Ojr=i(_e),y0=n(_e,"LI",{});var DWe=s(y0);YAe=n(DWe,"STRONG",{});var OZt=s(YAe);Vjr=r(OZt,"flaubert"),OZt.forEach(t),Xjr=r(DWe," \u2014 "),Poe=n(DWe,"A",{href:!0});var VZt=s(Poe);zjr=r(VZt,"TFFlaubertWithLMHeadModel"),VZt.forEach(t),Qjr=r(DWe," (FlauBERT model)"),DWe.forEach(t),Wjr=i(_e),x0=n(_e,"LI",{});var GWe=s(x0);KAe=n(GWe,"STRONG",{});var XZt=s(KAe);Ujr=r(XZt,"funnel"),XZt.forEach(t),Hjr=r(GWe," \u2014 "),Boe=n(GWe,"A",{href:!0});var zZt=s(Boe);Jjr=r(zZt,"TFFunnelForMaskedLM"),zZt.forEach(t),Yjr=r(GWe," (Funnel Transformer model)"),GWe.forEach(t),Kjr=i(_e),$0=n(_e,"LI",{});var OWe=s($0);ZAe=n(OWe,"STRONG",{});var QZt=s(ZAe);Zjr=r(QZt,"layoutlm"),QZt.forEach(t),eDr=r(OWe," \u2014 "),Ioe=n(OWe,"A",{href:!0});var WZt=s(Ioe);oDr=r(WZt,"TFLayoutLMForMaskedLM"),WZt.forEach(t),rDr=r(OWe," (LayoutLM model)"),OWe.forEach(t),tDr=i(_e),k0=n(_e,"LI",{});var VWe=s(k0);e6e=n(VWe,"STRONG",{});var UZt=s(e6e);aDr=r(UZt,"longformer"),UZt.forEach(t),nDr=r(VWe," \u2014 "),Noe=n(VWe,"A",{href:!0});var HZt=s(Noe);sDr=r(HZt,"TFLongformerForMaskedLM"),HZt.forEach(t),lDr=r(VWe," (Longformer model)"),VWe.forEach(t),iDr=i(_e),S0=n(_e,"LI",{});var XWe=s(S0);o6e=n(XWe,"STRONG",{});var JZt=s(o6e);dDr=r(JZt,"mobilebert"),JZt.forEach(t),cDr=r(XWe," \u2014 "),qoe=n(XWe,"A",{href:!0});var YZt=s(qoe);mDr=r(YZt,"TFMobileBertForMaskedLM"),YZt.forEach(t),fDr=r(XWe," (MobileBERT model)"),XWe.forEach(t),gDr=i(_e),R0=n(_e,"LI",{});var zWe=s(R0);r6e=n(zWe,"STRONG",{});var KZt=s(r6e);hDr=r(KZt,"mpnet"),KZt.forEach(t),uDr=r(zWe," \u2014 "),joe=n(zWe,"A",{href:!0});var ZZt=s(joe);pDr=r(ZZt,"TFMPNetForMaskedLM"),ZZt.forEach(t),_Dr=r(zWe," (MPNet model)"),zWe.forEach(t),bDr=i(_e),P0=n(_e,"LI",{});var QWe=s(P0);t6e=n(QWe,"STRONG",{});var eea=s(t6e);vDr=r(eea,"rembert"),eea.forEach(t),FDr=r(QWe," \u2014 "),Doe=n(QWe,"A",{href:!0});var oea=s(Doe);TDr=r(oea,"TFRemBertForMaskedLM"),oea.forEach(t),MDr=r(QWe," (RemBERT model)"),QWe.forEach(t),EDr=i(_e),B0=n(_e,"LI",{});var WWe=s(B0);a6e=n(WWe,"STRONG",{});var rea=s(a6e);CDr=r(rea,"roberta"),rea.forEach(t),wDr=r(WWe," \u2014 "),Goe=n(WWe,"A",{href:!0});var tea=s(Goe);ADr=r(tea,"TFRobertaForMaskedLM"),tea.forEach(t),LDr=r(WWe," (RoBERTa model)"),WWe.forEach(t),yDr=i(_e),I0=n(_e,"LI",{});var UWe=s(I0);n6e=n(UWe,"STRONG",{});var aea=s(n6e);xDr=r(aea,"roformer"),aea.forEach(t),$Dr=r(UWe," \u2014 "),Ooe=n(UWe,"A",{href:!0});var nea=s(Ooe);kDr=r(nea,"TFRoFormerForMaskedLM"),nea.forEach(t),SDr=r(UWe," (RoFormer model)"),UWe.forEach(t),RDr=i(_e),N0=n(_e,"LI",{});var HWe=s(N0);s6e=n(HWe,"STRONG",{});var sea=s(s6e);PDr=r(sea,"tapas"),sea.forEach(t),BDr=r(HWe," \u2014 "),Voe=n(HWe,"A",{href:!0});var lea=s(Voe);IDr=r(lea,"TFTapasForMaskedLM"),lea.forEach(t),NDr=r(HWe," (TAPAS model)"),HWe.forEach(t),qDr=i(_e),q0=n(_e,"LI",{});var JWe=s(q0);l6e=n(JWe,"STRONG",{});var iea=s(l6e);jDr=r(iea,"xlm"),iea.forEach(t),DDr=r(JWe," \u2014 "),Xoe=n(JWe,"A",{href:!0});var dea=s(Xoe);GDr=r(dea,"TFXLMWithLMHeadModel"),dea.forEach(t),ODr=r(JWe," (XLM model)"),JWe.forEach(t),VDr=i(_e),j0=n(_e,"LI",{});var YWe=s(j0);i6e=n(YWe,"STRONG",{});var cea=s(i6e);XDr=r(cea,"xlm-roberta"),cea.forEach(t),zDr=r(YWe," \u2014 "),zoe=n(YWe,"A",{href:!0});var mea=s(zoe);QDr=r(mea,"TFXLMRobertaForMaskedLM"),mea.forEach(t),WDr=r(YWe," (XLM-RoBERTa model)"),YWe.forEach(t),_e.forEach(t),UDr=i(mi),T(D0.$$.fragment,mi),mi.forEach(t),ci.forEach(t),_Ze=i(m),lm=n(m,"H2",{class:!0});var Soo=s(lm);G0=n(Soo,"A",{id:!0,class:!0,href:!0});var fea=s(G0);d6e=n(fea,"SPAN",{});var gea=s(d6e);T(Zk.$$.fragment,gea),gea.forEach(t),fea.forEach(t),HDr=i(Soo),c6e=n(Soo,"SPAN",{});var hea=s(c6e);JDr=r(hea,"TFAutoModelForSeq2SeqLM"),hea.forEach(t),Soo.forEach(t),bZe=i(m),fr=n(m,"DIV",{class:!0});var fi=s(fr);T(eS.$$.fragment,fi),YDr=i(fi),im=n(fi,"P",{});var hie=s(im);KDr=r(hie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Qoe=n(hie,"A",{href:!0});var uea=s(Qoe);ZDr=r(uea,"from_pretrained()"),uea.forEach(t),eGr=r(hie," class method or the "),Woe=n(hie,"A",{href:!0});var pea=s(Woe);oGr=r(pea,"from_config()"),pea.forEach(t),rGr=r(hie,` class
method.`),hie.forEach(t),tGr=i(fi),oS=n(fi,"P",{});var Roo=s(oS);aGr=r(Roo,"This class cannot be instantiated directly using "),m6e=n(Roo,"CODE",{});var _ea=s(m6e);nGr=r(_ea,"__init__()"),_ea.forEach(t),sGr=r(Roo," (throws an error)."),Roo.forEach(t),lGr=i(fi),Jt=n(fi,"DIV",{class:!0});var P8=s(Jt);T(rS.$$.fragment,P8),iGr=i(P8),f6e=n(P8,"P",{});var bea=s(f6e);dGr=r(bea,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),bea.forEach(t),cGr=i(P8),dm=n(P8,"P",{});var uie=s(dm);mGr=r(uie,`Note:
Loading a model from its configuration file does `),g6e=n(uie,"STRONG",{});var vea=s(g6e);fGr=r(vea,"not"),vea.forEach(t),gGr=r(uie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Uoe=n(uie,"A",{href:!0});var Fea=s(Uoe);hGr=r(Fea,"from_pretrained()"),Fea.forEach(t),uGr=r(uie," to load the model weights."),uie.forEach(t),pGr=i(P8),T(O0.$$.fragment,P8),P8.forEach(t),_Gr=i(fi),Or=n(fi,"DIV",{class:!0});var gi=s(Or);T(tS.$$.fragment,gi),bGr=i(gi),h6e=n(gi,"P",{});var Tea=s(h6e);vGr=r(Tea,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Tea.forEach(t),FGr=i(gi),$n=n(gi,"P",{});var B8=s($n);TGr=r(B8,"The model class to instantiate is selected based on the "),u6e=n(B8,"CODE",{});var Mea=s(u6e);MGr=r(Mea,"model_type"),Mea.forEach(t),EGr=r(B8,` property of the config object (either
passed as an argument or loaded from `),p6e=n(B8,"CODE",{});var Eea=s(p6e);CGr=r(Eea,"pretrained_model_name_or_path"),Eea.forEach(t),wGr=r(B8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_6e=n(B8,"CODE",{});var Cea=s(_6e);AGr=r(Cea,"pretrained_model_name_or_path"),Cea.forEach(t),LGr=r(B8,":"),B8.forEach(t),yGr=i(gi),ye=n(gi,"UL",{});var Ne=s(ye);V0=n(Ne,"LI",{});var KWe=s(V0);b6e=n(KWe,"STRONG",{});var wea=s(b6e);xGr=r(wea,"bart"),wea.forEach(t),$Gr=r(KWe," \u2014 "),Hoe=n(KWe,"A",{href:!0});var Aea=s(Hoe);kGr=r(Aea,"TFBartForConditionalGeneration"),Aea.forEach(t),SGr=r(KWe," (BART model)"),KWe.forEach(t),RGr=i(Ne),X0=n(Ne,"LI",{});var ZWe=s(X0);v6e=n(ZWe,"STRONG",{});var Lea=s(v6e);PGr=r(Lea,"blenderbot"),Lea.forEach(t),BGr=r(ZWe," \u2014 "),Joe=n(ZWe,"A",{href:!0});var yea=s(Joe);IGr=r(yea,"TFBlenderbotForConditionalGeneration"),yea.forEach(t),NGr=r(ZWe," (Blenderbot model)"),ZWe.forEach(t),qGr=i(Ne),z0=n(Ne,"LI",{});var eUe=s(z0);F6e=n(eUe,"STRONG",{});var xea=s(F6e);jGr=r(xea,"blenderbot-small"),xea.forEach(t),DGr=r(eUe," \u2014 "),Yoe=n(eUe,"A",{href:!0});var $ea=s(Yoe);GGr=r($ea,"TFBlenderbotSmallForConditionalGeneration"),$ea.forEach(t),OGr=r(eUe," (BlenderbotSmall model)"),eUe.forEach(t),VGr=i(Ne),Q0=n(Ne,"LI",{});var oUe=s(Q0);T6e=n(oUe,"STRONG",{});var kea=s(T6e);XGr=r(kea,"encoder-decoder"),kea.forEach(t),zGr=r(oUe," \u2014 "),Koe=n(oUe,"A",{href:!0});var Sea=s(Koe);QGr=r(Sea,"TFEncoderDecoderModel"),Sea.forEach(t),WGr=r(oUe," (Encoder decoder model)"),oUe.forEach(t),UGr=i(Ne),W0=n(Ne,"LI",{});var rUe=s(W0);M6e=n(rUe,"STRONG",{});var Rea=s(M6e);HGr=r(Rea,"led"),Rea.forEach(t),JGr=r(rUe," \u2014 "),Zoe=n(rUe,"A",{href:!0});var Pea=s(Zoe);YGr=r(Pea,"TFLEDForConditionalGeneration"),Pea.forEach(t),KGr=r(rUe," (LED model)"),rUe.forEach(t),ZGr=i(Ne),U0=n(Ne,"LI",{});var tUe=s(U0);E6e=n(tUe,"STRONG",{});var Bea=s(E6e);eOr=r(Bea,"marian"),Bea.forEach(t),oOr=r(tUe," \u2014 "),ere=n(tUe,"A",{href:!0});var Iea=s(ere);rOr=r(Iea,"TFMarianMTModel"),Iea.forEach(t),tOr=r(tUe," (Marian model)"),tUe.forEach(t),aOr=i(Ne),H0=n(Ne,"LI",{});var aUe=s(H0);C6e=n(aUe,"STRONG",{});var Nea=s(C6e);nOr=r(Nea,"mbart"),Nea.forEach(t),sOr=r(aUe," \u2014 "),ore=n(aUe,"A",{href:!0});var qea=s(ore);lOr=r(qea,"TFMBartForConditionalGeneration"),qea.forEach(t),iOr=r(aUe," (mBART model)"),aUe.forEach(t),dOr=i(Ne),J0=n(Ne,"LI",{});var nUe=s(J0);w6e=n(nUe,"STRONG",{});var jea=s(w6e);cOr=r(jea,"mt5"),jea.forEach(t),mOr=r(nUe," \u2014 "),rre=n(nUe,"A",{href:!0});var Dea=s(rre);fOr=r(Dea,"TFMT5ForConditionalGeneration"),Dea.forEach(t),gOr=r(nUe," (MT5 model)"),nUe.forEach(t),hOr=i(Ne),Y0=n(Ne,"LI",{});var sUe=s(Y0);A6e=n(sUe,"STRONG",{});var Gea=s(A6e);uOr=r(Gea,"pegasus"),Gea.forEach(t),pOr=r(sUe," \u2014 "),tre=n(sUe,"A",{href:!0});var Oea=s(tre);_Or=r(Oea,"TFPegasusForConditionalGeneration"),Oea.forEach(t),bOr=r(sUe," (Pegasus model)"),sUe.forEach(t),vOr=i(Ne),K0=n(Ne,"LI",{});var lUe=s(K0);L6e=n(lUe,"STRONG",{});var Vea=s(L6e);FOr=r(Vea,"t5"),Vea.forEach(t),TOr=r(lUe," \u2014 "),are=n(lUe,"A",{href:!0});var Xea=s(are);MOr=r(Xea,"TFT5ForConditionalGeneration"),Xea.forEach(t),EOr=r(lUe," (T5 model)"),lUe.forEach(t),Ne.forEach(t),COr=i(gi),T(Z0.$$.fragment,gi),gi.forEach(t),fi.forEach(t),vZe=i(m),cm=n(m,"H2",{class:!0});var Poo=s(cm);ew=n(Poo,"A",{id:!0,class:!0,href:!0});var zea=s(ew);y6e=n(zea,"SPAN",{});var Qea=s(y6e);T(aS.$$.fragment,Qea),Qea.forEach(t),zea.forEach(t),wOr=i(Poo),x6e=n(Poo,"SPAN",{});var Wea=s(x6e);AOr=r(Wea,"TFAutoModelForSequenceClassification"),Wea.forEach(t),Poo.forEach(t),FZe=i(m),gr=n(m,"DIV",{class:!0});var hi=s(gr);T(nS.$$.fragment,hi),LOr=i(hi),mm=n(hi,"P",{});var pie=s(mm);yOr=r(pie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),nre=n(pie,"A",{href:!0});var Uea=s(nre);xOr=r(Uea,"from_pretrained()"),Uea.forEach(t),$Or=r(pie," class method or the "),sre=n(pie,"A",{href:!0});var Hea=s(sre);kOr=r(Hea,"from_config()"),Hea.forEach(t),SOr=r(pie,` class
method.`),pie.forEach(t),ROr=i(hi),sS=n(hi,"P",{});var Boo=s(sS);POr=r(Boo,"This class cannot be instantiated directly using "),$6e=n(Boo,"CODE",{});var Jea=s($6e);BOr=r(Jea,"__init__()"),Jea.forEach(t),IOr=r(Boo," (throws an error)."),Boo.forEach(t),NOr=i(hi),Yt=n(hi,"DIV",{class:!0});var I8=s(Yt);T(lS.$$.fragment,I8),qOr=i(I8),k6e=n(I8,"P",{});var Yea=s(k6e);jOr=r(Yea,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Yea.forEach(t),DOr=i(I8),fm=n(I8,"P",{});var _ie=s(fm);GOr=r(_ie,`Note:
Loading a model from its configuration file does `),S6e=n(_ie,"STRONG",{});var Kea=s(S6e);OOr=r(Kea,"not"),Kea.forEach(t),VOr=r(_ie,` load the model weights. It only affects the
model\u2019s configuration. Use `),lre=n(_ie,"A",{href:!0});var Zea=s(lre);XOr=r(Zea,"from_pretrained()"),Zea.forEach(t),zOr=r(_ie," to load the model weights."),_ie.forEach(t),QOr=i(I8),T(ow.$$.fragment,I8),I8.forEach(t),WOr=i(hi),Vr=n(hi,"DIV",{class:!0});var ui=s(Vr);T(iS.$$.fragment,ui),UOr=i(ui),R6e=n(ui,"P",{});var eoa=s(R6e);HOr=r(eoa,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),eoa.forEach(t),JOr=i(ui),kn=n(ui,"P",{});var N8=s(kn);YOr=r(N8,"The model class to instantiate is selected based on the "),P6e=n(N8,"CODE",{});var ooa=s(P6e);KOr=r(ooa,"model_type"),ooa.forEach(t),ZOr=r(N8,` property of the config object (either
passed as an argument or loaded from `),B6e=n(N8,"CODE",{});var roa=s(B6e);eVr=r(roa,"pretrained_model_name_or_path"),roa.forEach(t),oVr=r(N8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I6e=n(N8,"CODE",{});var toa=s(I6e);rVr=r(toa,"pretrained_model_name_or_path"),toa.forEach(t),tVr=r(N8,":"),N8.forEach(t),aVr=i(ui),re=n(ui,"UL",{});var ae=s(re);rw=n(ae,"LI",{});var iUe=s(rw);N6e=n(iUe,"STRONG",{});var aoa=s(N6e);nVr=r(aoa,"albert"),aoa.forEach(t),sVr=r(iUe," \u2014 "),ire=n(iUe,"A",{href:!0});var noa=s(ire);lVr=r(noa,"TFAlbertForSequenceClassification"),noa.forEach(t),iVr=r(iUe," (ALBERT model)"),iUe.forEach(t),dVr=i(ae),tw=n(ae,"LI",{});var dUe=s(tw);q6e=n(dUe,"STRONG",{});var soa=s(q6e);cVr=r(soa,"bert"),soa.forEach(t),mVr=r(dUe," \u2014 "),dre=n(dUe,"A",{href:!0});var loa=s(dre);fVr=r(loa,"TFBertForSequenceClassification"),loa.forEach(t),gVr=r(dUe," (BERT model)"),dUe.forEach(t),hVr=i(ae),aw=n(ae,"LI",{});var cUe=s(aw);j6e=n(cUe,"STRONG",{});var ioa=s(j6e);uVr=r(ioa,"camembert"),ioa.forEach(t),pVr=r(cUe," \u2014 "),cre=n(cUe,"A",{href:!0});var doa=s(cre);_Vr=r(doa,"TFCamembertForSequenceClassification"),doa.forEach(t),bVr=r(cUe," (CamemBERT model)"),cUe.forEach(t),vVr=i(ae),nw=n(ae,"LI",{});var mUe=s(nw);D6e=n(mUe,"STRONG",{});var coa=s(D6e);FVr=r(coa,"convbert"),coa.forEach(t),TVr=r(mUe," \u2014 "),mre=n(mUe,"A",{href:!0});var moa=s(mre);MVr=r(moa,"TFConvBertForSequenceClassification"),moa.forEach(t),EVr=r(mUe," (ConvBERT model)"),mUe.forEach(t),CVr=i(ae),sw=n(ae,"LI",{});var fUe=s(sw);G6e=n(fUe,"STRONG",{});var foa=s(G6e);wVr=r(foa,"ctrl"),foa.forEach(t),AVr=r(fUe," \u2014 "),fre=n(fUe,"A",{href:!0});var goa=s(fre);LVr=r(goa,"TFCTRLForSequenceClassification"),goa.forEach(t),yVr=r(fUe," (CTRL model)"),fUe.forEach(t),xVr=i(ae),lw=n(ae,"LI",{});var gUe=s(lw);O6e=n(gUe,"STRONG",{});var hoa=s(O6e);$Vr=r(hoa,"deberta"),hoa.forEach(t),kVr=r(gUe," \u2014 "),gre=n(gUe,"A",{href:!0});var uoa=s(gre);SVr=r(uoa,"TFDebertaForSequenceClassification"),uoa.forEach(t),RVr=r(gUe," (DeBERTa model)"),gUe.forEach(t),PVr=i(ae),iw=n(ae,"LI",{});var hUe=s(iw);V6e=n(hUe,"STRONG",{});var poa=s(V6e);BVr=r(poa,"deberta-v2"),poa.forEach(t),IVr=r(hUe," \u2014 "),hre=n(hUe,"A",{href:!0});var _oa=s(hre);NVr=r(_oa,"TFDebertaV2ForSequenceClassification"),_oa.forEach(t),qVr=r(hUe," (DeBERTa-v2 model)"),hUe.forEach(t),jVr=i(ae),dw=n(ae,"LI",{});var uUe=s(dw);X6e=n(uUe,"STRONG",{});var boa=s(X6e);DVr=r(boa,"distilbert"),boa.forEach(t),GVr=r(uUe," \u2014 "),ure=n(uUe,"A",{href:!0});var voa=s(ure);OVr=r(voa,"TFDistilBertForSequenceClassification"),voa.forEach(t),VVr=r(uUe," (DistilBERT model)"),uUe.forEach(t),XVr=i(ae),cw=n(ae,"LI",{});var pUe=s(cw);z6e=n(pUe,"STRONG",{});var Foa=s(z6e);zVr=r(Foa,"electra"),Foa.forEach(t),QVr=r(pUe," \u2014 "),pre=n(pUe,"A",{href:!0});var Toa=s(pre);WVr=r(Toa,"TFElectraForSequenceClassification"),Toa.forEach(t),UVr=r(pUe," (ELECTRA model)"),pUe.forEach(t),HVr=i(ae),mw=n(ae,"LI",{});var _Ue=s(mw);Q6e=n(_Ue,"STRONG",{});var Moa=s(Q6e);JVr=r(Moa,"flaubert"),Moa.forEach(t),YVr=r(_Ue," \u2014 "),_re=n(_Ue,"A",{href:!0});var Eoa=s(_re);KVr=r(Eoa,"TFFlaubertForSequenceClassification"),Eoa.forEach(t),ZVr=r(_Ue," (FlauBERT model)"),_Ue.forEach(t),eXr=i(ae),fw=n(ae,"LI",{});var bUe=s(fw);W6e=n(bUe,"STRONG",{});var Coa=s(W6e);oXr=r(Coa,"funnel"),Coa.forEach(t),rXr=r(bUe," \u2014 "),bre=n(bUe,"A",{href:!0});var woa=s(bre);tXr=r(woa,"TFFunnelForSequenceClassification"),woa.forEach(t),aXr=r(bUe," (Funnel Transformer model)"),bUe.forEach(t),nXr=i(ae),gw=n(ae,"LI",{});var vUe=s(gw);U6e=n(vUe,"STRONG",{});var Aoa=s(U6e);sXr=r(Aoa,"gpt2"),Aoa.forEach(t),lXr=r(vUe," \u2014 "),vre=n(vUe,"A",{href:!0});var Loa=s(vre);iXr=r(Loa,"TFGPT2ForSequenceClassification"),Loa.forEach(t),dXr=r(vUe," (OpenAI GPT-2 model)"),vUe.forEach(t),cXr=i(ae),hw=n(ae,"LI",{});var FUe=s(hw);H6e=n(FUe,"STRONG",{});var yoa=s(H6e);mXr=r(yoa,"gptj"),yoa.forEach(t),fXr=r(FUe," \u2014 "),Fre=n(FUe,"A",{href:!0});var xoa=s(Fre);gXr=r(xoa,"TFGPTJForSequenceClassification"),xoa.forEach(t),hXr=r(FUe," (GPT-J model)"),FUe.forEach(t),uXr=i(ae),uw=n(ae,"LI",{});var TUe=s(uw);J6e=n(TUe,"STRONG",{});var $oa=s(J6e);pXr=r($oa,"layoutlm"),$oa.forEach(t),_Xr=r(TUe," \u2014 "),Tre=n(TUe,"A",{href:!0});var koa=s(Tre);bXr=r(koa,"TFLayoutLMForSequenceClassification"),koa.forEach(t),vXr=r(TUe," (LayoutLM model)"),TUe.forEach(t),FXr=i(ae),pw=n(ae,"LI",{});var MUe=s(pw);Y6e=n(MUe,"STRONG",{});var Soa=s(Y6e);TXr=r(Soa,"layoutlmv3"),Soa.forEach(t),MXr=r(MUe," \u2014 "),Mre=n(MUe,"A",{href:!0});var Roa=s(Mre);EXr=r(Roa,"TFLayoutLMv3ForSequenceClassification"),Roa.forEach(t),CXr=r(MUe," (LayoutLMv3 model)"),MUe.forEach(t),wXr=i(ae),_w=n(ae,"LI",{});var EUe=s(_w);K6e=n(EUe,"STRONG",{});var Poa=s(K6e);AXr=r(Poa,"longformer"),Poa.forEach(t),LXr=r(EUe," \u2014 "),Ere=n(EUe,"A",{href:!0});var Boa=s(Ere);yXr=r(Boa,"TFLongformerForSequenceClassification"),Boa.forEach(t),xXr=r(EUe," (Longformer model)"),EUe.forEach(t),$Xr=i(ae),bw=n(ae,"LI",{});var CUe=s(bw);Z6e=n(CUe,"STRONG",{});var Ioa=s(Z6e);kXr=r(Ioa,"mobilebert"),Ioa.forEach(t),SXr=r(CUe," \u2014 "),Cre=n(CUe,"A",{href:!0});var Noa=s(Cre);RXr=r(Noa,"TFMobileBertForSequenceClassification"),Noa.forEach(t),PXr=r(CUe," (MobileBERT model)"),CUe.forEach(t),BXr=i(ae),vw=n(ae,"LI",{});var wUe=s(vw);e7e=n(wUe,"STRONG",{});var qoa=s(e7e);IXr=r(qoa,"mpnet"),qoa.forEach(t),NXr=r(wUe," \u2014 "),wre=n(wUe,"A",{href:!0});var joa=s(wre);qXr=r(joa,"TFMPNetForSequenceClassification"),joa.forEach(t),jXr=r(wUe," (MPNet model)"),wUe.forEach(t),DXr=i(ae),Fw=n(ae,"LI",{});var AUe=s(Fw);o7e=n(AUe,"STRONG",{});var Doa=s(o7e);GXr=r(Doa,"openai-gpt"),Doa.forEach(t),OXr=r(AUe," \u2014 "),Are=n(AUe,"A",{href:!0});var Goa=s(Are);VXr=r(Goa,"TFOpenAIGPTForSequenceClassification"),Goa.forEach(t),XXr=r(AUe," (OpenAI GPT model)"),AUe.forEach(t),zXr=i(ae),Tw=n(ae,"LI",{});var LUe=s(Tw);r7e=n(LUe,"STRONG",{});var Ooa=s(r7e);QXr=r(Ooa,"rembert"),Ooa.forEach(t),WXr=r(LUe," \u2014 "),Lre=n(LUe,"A",{href:!0});var Voa=s(Lre);UXr=r(Voa,"TFRemBertForSequenceClassification"),Voa.forEach(t),HXr=r(LUe," (RemBERT model)"),LUe.forEach(t),JXr=i(ae),Mw=n(ae,"LI",{});var yUe=s(Mw);t7e=n(yUe,"STRONG",{});var Xoa=s(t7e);YXr=r(Xoa,"roberta"),Xoa.forEach(t),KXr=r(yUe," \u2014 "),yre=n(yUe,"A",{href:!0});var zoa=s(yre);ZXr=r(zoa,"TFRobertaForSequenceClassification"),zoa.forEach(t),ezr=r(yUe," (RoBERTa model)"),yUe.forEach(t),ozr=i(ae),Ew=n(ae,"LI",{});var xUe=s(Ew);a7e=n(xUe,"STRONG",{});var Qoa=s(a7e);rzr=r(Qoa,"roformer"),Qoa.forEach(t),tzr=r(xUe," \u2014 "),xre=n(xUe,"A",{href:!0});var Woa=s(xre);azr=r(Woa,"TFRoFormerForSequenceClassification"),Woa.forEach(t),nzr=r(xUe," (RoFormer model)"),xUe.forEach(t),szr=i(ae),Cw=n(ae,"LI",{});var $Ue=s(Cw);n7e=n($Ue,"STRONG",{});var Uoa=s(n7e);lzr=r(Uoa,"tapas"),Uoa.forEach(t),izr=r($Ue," \u2014 "),$re=n($Ue,"A",{href:!0});var Hoa=s($re);dzr=r(Hoa,"TFTapasForSequenceClassification"),Hoa.forEach(t),czr=r($Ue," (TAPAS model)"),$Ue.forEach(t),mzr=i(ae),ww=n(ae,"LI",{});var kUe=s(ww);s7e=n(kUe,"STRONG",{});var Joa=s(s7e);fzr=r(Joa,"transfo-xl"),Joa.forEach(t),gzr=r(kUe," \u2014 "),kre=n(kUe,"A",{href:!0});var Yoa=s(kre);hzr=r(Yoa,"TFTransfoXLForSequenceClassification"),Yoa.forEach(t),uzr=r(kUe," (Transformer-XL model)"),kUe.forEach(t),pzr=i(ae),Aw=n(ae,"LI",{});var SUe=s(Aw);l7e=n(SUe,"STRONG",{});var Koa=s(l7e);_zr=r(Koa,"xlm"),Koa.forEach(t),bzr=r(SUe," \u2014 "),Sre=n(SUe,"A",{href:!0});var Zoa=s(Sre);vzr=r(Zoa,"TFXLMForSequenceClassification"),Zoa.forEach(t),Fzr=r(SUe," (XLM model)"),SUe.forEach(t),Tzr=i(ae),Lw=n(ae,"LI",{});var RUe=s(Lw);i7e=n(RUe,"STRONG",{});var era=s(i7e);Mzr=r(era,"xlm-roberta"),era.forEach(t),Ezr=r(RUe," \u2014 "),Rre=n(RUe,"A",{href:!0});var ora=s(Rre);Czr=r(ora,"TFXLMRobertaForSequenceClassification"),ora.forEach(t),wzr=r(RUe," (XLM-RoBERTa model)"),RUe.forEach(t),Azr=i(ae),yw=n(ae,"LI",{});var PUe=s(yw);d7e=n(PUe,"STRONG",{});var rra=s(d7e);Lzr=r(rra,"xlnet"),rra.forEach(t),yzr=r(PUe," \u2014 "),Pre=n(PUe,"A",{href:!0});var tra=s(Pre);xzr=r(tra,"TFXLNetForSequenceClassification"),tra.forEach(t),$zr=r(PUe," (XLNet model)"),PUe.forEach(t),ae.forEach(t),kzr=i(ui),T(xw.$$.fragment,ui),ui.forEach(t),hi.forEach(t),TZe=i(m),gm=n(m,"H2",{class:!0});var Ioo=s(gm);$w=n(Ioo,"A",{id:!0,class:!0,href:!0});var ara=s($w);c7e=n(ara,"SPAN",{});var nra=s(c7e);T(dS.$$.fragment,nra),nra.forEach(t),ara.forEach(t),Szr=i(Ioo),m7e=n(Ioo,"SPAN",{});var sra=s(m7e);Rzr=r(sra,"TFAutoModelForMultipleChoice"),sra.forEach(t),Ioo.forEach(t),MZe=i(m),hr=n(m,"DIV",{class:!0});var pi=s(hr);T(cS.$$.fragment,pi),Pzr=i(pi),hm=n(pi,"P",{});var bie=s(hm);Bzr=r(bie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Bre=n(bie,"A",{href:!0});var lra=s(Bre);Izr=r(lra,"from_pretrained()"),lra.forEach(t),Nzr=r(bie," class method or the "),Ire=n(bie,"A",{href:!0});var ira=s(Ire);qzr=r(ira,"from_config()"),ira.forEach(t),jzr=r(bie,` class
method.`),bie.forEach(t),Dzr=i(pi),mS=n(pi,"P",{});var Noo=s(mS);Gzr=r(Noo,"This class cannot be instantiated directly using "),f7e=n(Noo,"CODE",{});var dra=s(f7e);Ozr=r(dra,"__init__()"),dra.forEach(t),Vzr=r(Noo," (throws an error)."),Noo.forEach(t),Xzr=i(pi),Kt=n(pi,"DIV",{class:!0});var q8=s(Kt);T(fS.$$.fragment,q8),zzr=i(q8),g7e=n(q8,"P",{});var cra=s(g7e);Qzr=r(cra,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),cra.forEach(t),Wzr=i(q8),um=n(q8,"P",{});var vie=s(um);Uzr=r(vie,`Note:
Loading a model from its configuration file does `),h7e=n(vie,"STRONG",{});var mra=s(h7e);Hzr=r(mra,"not"),mra.forEach(t),Jzr=r(vie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nre=n(vie,"A",{href:!0});var fra=s(Nre);Yzr=r(fra,"from_pretrained()"),fra.forEach(t),Kzr=r(vie," to load the model weights."),vie.forEach(t),Zzr=i(q8),T(kw.$$.fragment,q8),q8.forEach(t),eQr=i(pi),Xr=n(pi,"DIV",{class:!0});var _i=s(Xr);T(gS.$$.fragment,_i),oQr=i(_i),u7e=n(_i,"P",{});var gra=s(u7e);rQr=r(gra,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),gra.forEach(t),tQr=i(_i),Sn=n(_i,"P",{});var j8=s(Sn);aQr=r(j8,"The model class to instantiate is selected based on the "),p7e=n(j8,"CODE",{});var hra=s(p7e);nQr=r(hra,"model_type"),hra.forEach(t),sQr=r(j8,` property of the config object (either
passed as an argument or loaded from `),_7e=n(j8,"CODE",{});var ura=s(_7e);lQr=r(ura,"pretrained_model_name_or_path"),ura.forEach(t),iQr=r(j8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b7e=n(j8,"CODE",{});var pra=s(b7e);dQr=r(pra,"pretrained_model_name_or_path"),pra.forEach(t),cQr=r(j8,":"),j8.forEach(t),mQr=i(_i),ve=n(_i,"UL",{});var Te=s(ve);Sw=n(Te,"LI",{});var BUe=s(Sw);v7e=n(BUe,"STRONG",{});var _ra=s(v7e);fQr=r(_ra,"albert"),_ra.forEach(t),gQr=r(BUe," \u2014 "),qre=n(BUe,"A",{href:!0});var bra=s(qre);hQr=r(bra,"TFAlbertForMultipleChoice"),bra.forEach(t),uQr=r(BUe," (ALBERT model)"),BUe.forEach(t),pQr=i(Te),Rw=n(Te,"LI",{});var IUe=s(Rw);F7e=n(IUe,"STRONG",{});var vra=s(F7e);_Qr=r(vra,"bert"),vra.forEach(t),bQr=r(IUe," \u2014 "),jre=n(IUe,"A",{href:!0});var Fra=s(jre);vQr=r(Fra,"TFBertForMultipleChoice"),Fra.forEach(t),FQr=r(IUe," (BERT model)"),IUe.forEach(t),TQr=i(Te),Pw=n(Te,"LI",{});var NUe=s(Pw);T7e=n(NUe,"STRONG",{});var Tra=s(T7e);MQr=r(Tra,"camembert"),Tra.forEach(t),EQr=r(NUe," \u2014 "),Dre=n(NUe,"A",{href:!0});var Mra=s(Dre);CQr=r(Mra,"TFCamembertForMultipleChoice"),Mra.forEach(t),wQr=r(NUe," (CamemBERT model)"),NUe.forEach(t),AQr=i(Te),Bw=n(Te,"LI",{});var qUe=s(Bw);M7e=n(qUe,"STRONG",{});var Era=s(M7e);LQr=r(Era,"convbert"),Era.forEach(t),yQr=r(qUe," \u2014 "),Gre=n(qUe,"A",{href:!0});var Cra=s(Gre);xQr=r(Cra,"TFConvBertForMultipleChoice"),Cra.forEach(t),$Qr=r(qUe," (ConvBERT model)"),qUe.forEach(t),kQr=i(Te),Iw=n(Te,"LI",{});var jUe=s(Iw);E7e=n(jUe,"STRONG",{});var wra=s(E7e);SQr=r(wra,"distilbert"),wra.forEach(t),RQr=r(jUe," \u2014 "),Ore=n(jUe,"A",{href:!0});var Ara=s(Ore);PQr=r(Ara,"TFDistilBertForMultipleChoice"),Ara.forEach(t),BQr=r(jUe," (DistilBERT model)"),jUe.forEach(t),IQr=i(Te),Nw=n(Te,"LI",{});var DUe=s(Nw);C7e=n(DUe,"STRONG",{});var Lra=s(C7e);NQr=r(Lra,"electra"),Lra.forEach(t),qQr=r(DUe," \u2014 "),Vre=n(DUe,"A",{href:!0});var yra=s(Vre);jQr=r(yra,"TFElectraForMultipleChoice"),yra.forEach(t),DQr=r(DUe," (ELECTRA model)"),DUe.forEach(t),GQr=i(Te),qw=n(Te,"LI",{});var GUe=s(qw);w7e=n(GUe,"STRONG",{});var xra=s(w7e);OQr=r(xra,"flaubert"),xra.forEach(t),VQr=r(GUe," \u2014 "),Xre=n(GUe,"A",{href:!0});var $ra=s(Xre);XQr=r($ra,"TFFlaubertForMultipleChoice"),$ra.forEach(t),zQr=r(GUe," (FlauBERT model)"),GUe.forEach(t),QQr=i(Te),jw=n(Te,"LI",{});var OUe=s(jw);A7e=n(OUe,"STRONG",{});var kra=s(A7e);WQr=r(kra,"funnel"),kra.forEach(t),UQr=r(OUe," \u2014 "),zre=n(OUe,"A",{href:!0});var Sra=s(zre);HQr=r(Sra,"TFFunnelForMultipleChoice"),Sra.forEach(t),JQr=r(OUe," (Funnel Transformer model)"),OUe.forEach(t),YQr=i(Te),Dw=n(Te,"LI",{});var VUe=s(Dw);L7e=n(VUe,"STRONG",{});var Rra=s(L7e);KQr=r(Rra,"longformer"),Rra.forEach(t),ZQr=r(VUe," \u2014 "),Qre=n(VUe,"A",{href:!0});var Pra=s(Qre);eWr=r(Pra,"TFLongformerForMultipleChoice"),Pra.forEach(t),oWr=r(VUe," (Longformer model)"),VUe.forEach(t),rWr=i(Te),Gw=n(Te,"LI",{});var XUe=s(Gw);y7e=n(XUe,"STRONG",{});var Bra=s(y7e);tWr=r(Bra,"mobilebert"),Bra.forEach(t),aWr=r(XUe," \u2014 "),Wre=n(XUe,"A",{href:!0});var Ira=s(Wre);nWr=r(Ira,"TFMobileBertForMultipleChoice"),Ira.forEach(t),sWr=r(XUe," (MobileBERT model)"),XUe.forEach(t),lWr=i(Te),Ow=n(Te,"LI",{});var zUe=s(Ow);x7e=n(zUe,"STRONG",{});var Nra=s(x7e);iWr=r(Nra,"mpnet"),Nra.forEach(t),dWr=r(zUe," \u2014 "),Ure=n(zUe,"A",{href:!0});var qra=s(Ure);cWr=r(qra,"TFMPNetForMultipleChoice"),qra.forEach(t),mWr=r(zUe," (MPNet model)"),zUe.forEach(t),fWr=i(Te),Vw=n(Te,"LI",{});var QUe=s(Vw);$7e=n(QUe,"STRONG",{});var jra=s($7e);gWr=r(jra,"rembert"),jra.forEach(t),hWr=r(QUe," \u2014 "),Hre=n(QUe,"A",{href:!0});var Dra=s(Hre);uWr=r(Dra,"TFRemBertForMultipleChoice"),Dra.forEach(t),pWr=r(QUe," (RemBERT model)"),QUe.forEach(t),_Wr=i(Te),Xw=n(Te,"LI",{});var WUe=s(Xw);k7e=n(WUe,"STRONG",{});var Gra=s(k7e);bWr=r(Gra,"roberta"),Gra.forEach(t),vWr=r(WUe," \u2014 "),Jre=n(WUe,"A",{href:!0});var Ora=s(Jre);FWr=r(Ora,"TFRobertaForMultipleChoice"),Ora.forEach(t),TWr=r(WUe," (RoBERTa model)"),WUe.forEach(t),MWr=i(Te),zw=n(Te,"LI",{});var UUe=s(zw);S7e=n(UUe,"STRONG",{});var Vra=s(S7e);EWr=r(Vra,"roformer"),Vra.forEach(t),CWr=r(UUe," \u2014 "),Yre=n(UUe,"A",{href:!0});var Xra=s(Yre);wWr=r(Xra,"TFRoFormerForMultipleChoice"),Xra.forEach(t),AWr=r(UUe," (RoFormer model)"),UUe.forEach(t),LWr=i(Te),Qw=n(Te,"LI",{});var HUe=s(Qw);R7e=n(HUe,"STRONG",{});var zra=s(R7e);yWr=r(zra,"xlm"),zra.forEach(t),xWr=r(HUe," \u2014 "),Kre=n(HUe,"A",{href:!0});var Qra=s(Kre);$Wr=r(Qra,"TFXLMForMultipleChoice"),Qra.forEach(t),kWr=r(HUe," (XLM model)"),HUe.forEach(t),SWr=i(Te),Ww=n(Te,"LI",{});var JUe=s(Ww);P7e=n(JUe,"STRONG",{});var Wra=s(P7e);RWr=r(Wra,"xlm-roberta"),Wra.forEach(t),PWr=r(JUe," \u2014 "),Zre=n(JUe,"A",{href:!0});var Ura=s(Zre);BWr=r(Ura,"TFXLMRobertaForMultipleChoice"),Ura.forEach(t),IWr=r(JUe," (XLM-RoBERTa model)"),JUe.forEach(t),NWr=i(Te),Uw=n(Te,"LI",{});var YUe=s(Uw);B7e=n(YUe,"STRONG",{});var Hra=s(B7e);qWr=r(Hra,"xlnet"),Hra.forEach(t),jWr=r(YUe," \u2014 "),ete=n(YUe,"A",{href:!0});var Jra=s(ete);DWr=r(Jra,"TFXLNetForMultipleChoice"),Jra.forEach(t),GWr=r(YUe," (XLNet model)"),YUe.forEach(t),Te.forEach(t),OWr=i(_i),T(Hw.$$.fragment,_i),_i.forEach(t),pi.forEach(t),EZe=i(m),pm=n(m,"H2",{class:!0});var qoo=s(pm);Jw=n(qoo,"A",{id:!0,class:!0,href:!0});var Yra=s(Jw);I7e=n(Yra,"SPAN",{});var Kra=s(I7e);T(hS.$$.fragment,Kra),Kra.forEach(t),Yra.forEach(t),VWr=i(qoo),N7e=n(qoo,"SPAN",{});var Zra=s(N7e);XWr=r(Zra,"TFAutoModelForNextSentencePrediction"),Zra.forEach(t),qoo.forEach(t),CZe=i(m),ur=n(m,"DIV",{class:!0});var bi=s(ur);T(uS.$$.fragment,bi),zWr=i(bi),_m=n(bi,"P",{});var Fie=s(_m);QWr=r(Fie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),ote=n(Fie,"A",{href:!0});var eta=s(ote);WWr=r(eta,"from_pretrained()"),eta.forEach(t),UWr=r(Fie," class method or the "),rte=n(Fie,"A",{href:!0});var ota=s(rte);HWr=r(ota,"from_config()"),ota.forEach(t),JWr=r(Fie,` class
method.`),Fie.forEach(t),YWr=i(bi),pS=n(bi,"P",{});var joo=s(pS);KWr=r(joo,"This class cannot be instantiated directly using "),q7e=n(joo,"CODE",{});var rta=s(q7e);ZWr=r(rta,"__init__()"),rta.forEach(t),eUr=r(joo," (throws an error)."),joo.forEach(t),oUr=i(bi),Zt=n(bi,"DIV",{class:!0});var D8=s(Zt);T(_S.$$.fragment,D8),rUr=i(D8),j7e=n(D8,"P",{});var tta=s(j7e);tUr=r(tta,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),tta.forEach(t),aUr=i(D8),bm=n(D8,"P",{});var Tie=s(bm);nUr=r(Tie,`Note:
Loading a model from its configuration file does `),D7e=n(Tie,"STRONG",{});var ata=s(D7e);sUr=r(ata,"not"),ata.forEach(t),lUr=r(Tie,` load the model weights. It only affects the
model\u2019s configuration. Use `),tte=n(Tie,"A",{href:!0});var nta=s(tte);iUr=r(nta,"from_pretrained()"),nta.forEach(t),dUr=r(Tie," to load the model weights."),Tie.forEach(t),cUr=i(D8),T(Yw.$$.fragment,D8),D8.forEach(t),mUr=i(bi),zr=n(bi,"DIV",{class:!0});var vi=s(zr);T(bS.$$.fragment,vi),fUr=i(vi),G7e=n(vi,"P",{});var sta=s(G7e);gUr=r(sta,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),sta.forEach(t),hUr=i(vi),Rn=n(vi,"P",{});var G8=s(Rn);uUr=r(G8,"The model class to instantiate is selected based on the "),O7e=n(G8,"CODE",{});var lta=s(O7e);pUr=r(lta,"model_type"),lta.forEach(t),_Ur=r(G8,` property of the config object (either
passed as an argument or loaded from `),V7e=n(G8,"CODE",{});var ita=s(V7e);bUr=r(ita,"pretrained_model_name_or_path"),ita.forEach(t),vUr=r(G8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X7e=n(G8,"CODE",{});var dta=s(X7e);FUr=r(dta,"pretrained_model_name_or_path"),dta.forEach(t),TUr=r(G8,":"),G8.forEach(t),MUr=i(vi),vS=n(vi,"UL",{});var Doo=s(vS);Kw=n(Doo,"LI",{});var KUe=s(Kw);z7e=n(KUe,"STRONG",{});var cta=s(z7e);EUr=r(cta,"bert"),cta.forEach(t),CUr=r(KUe," \u2014 "),ate=n(KUe,"A",{href:!0});var mta=s(ate);wUr=r(mta,"TFBertForNextSentencePrediction"),mta.forEach(t),AUr=r(KUe," (BERT model)"),KUe.forEach(t),LUr=i(Doo),Zw=n(Doo,"LI",{});var ZUe=s(Zw);Q7e=n(ZUe,"STRONG",{});var fta=s(Q7e);yUr=r(fta,"mobilebert"),fta.forEach(t),xUr=r(ZUe," \u2014 "),nte=n(ZUe,"A",{href:!0});var gta=s(nte);$Ur=r(gta,"TFMobileBertForNextSentencePrediction"),gta.forEach(t),kUr=r(ZUe," (MobileBERT model)"),ZUe.forEach(t),Doo.forEach(t),SUr=i(vi),T(eA.$$.fragment,vi),vi.forEach(t),bi.forEach(t),wZe=i(m),vm=n(m,"H2",{class:!0});var Goo=s(vm);oA=n(Goo,"A",{id:!0,class:!0,href:!0});var hta=s(oA);W7e=n(hta,"SPAN",{});var uta=s(W7e);T(FS.$$.fragment,uta),uta.forEach(t),hta.forEach(t),RUr=i(Goo),U7e=n(Goo,"SPAN",{});var pta=s(U7e);PUr=r(pta,"TFAutoModelForTableQuestionAnswering"),pta.forEach(t),Goo.forEach(t),AZe=i(m),pr=n(m,"DIV",{class:!0});var Fi=s(pr);T(TS.$$.fragment,Fi),BUr=i(Fi),Fm=n(Fi,"P",{});var Mie=s(Fm);IUr=r(Mie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),ste=n(Mie,"A",{href:!0});var _ta=s(ste);NUr=r(_ta,"from_pretrained()"),_ta.forEach(t),qUr=r(Mie," class method or the "),lte=n(Mie,"A",{href:!0});var bta=s(lte);jUr=r(bta,"from_config()"),bta.forEach(t),DUr=r(Mie,` class
method.`),Mie.forEach(t),GUr=i(Fi),MS=n(Fi,"P",{});var Ooo=s(MS);OUr=r(Ooo,"This class cannot be instantiated directly using "),H7e=n(Ooo,"CODE",{});var vta=s(H7e);VUr=r(vta,"__init__()"),vta.forEach(t),XUr=r(Ooo," (throws an error)."),Ooo.forEach(t),zUr=i(Fi),ea=n(Fi,"DIV",{class:!0});var O8=s(ea);T(ES.$$.fragment,O8),QUr=i(O8),J7e=n(O8,"P",{});var Fta=s(J7e);WUr=r(Fta,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Fta.forEach(t),UUr=i(O8),Tm=n(O8,"P",{});var Eie=s(Tm);HUr=r(Eie,`Note:
Loading a model from its configuration file does `),Y7e=n(Eie,"STRONG",{});var Tta=s(Y7e);JUr=r(Tta,"not"),Tta.forEach(t),YUr=r(Eie,` load the model weights. It only affects the
model\u2019s configuration. Use `),ite=n(Eie,"A",{href:!0});var Mta=s(ite);KUr=r(Mta,"from_pretrained()"),Mta.forEach(t),ZUr=r(Eie," to load the model weights."),Eie.forEach(t),eHr=i(O8),T(rA.$$.fragment,O8),O8.forEach(t),oHr=i(Fi),Qr=n(Fi,"DIV",{class:!0});var Ti=s(Qr);T(CS.$$.fragment,Ti),rHr=i(Ti),K7e=n(Ti,"P",{});var Eta=s(K7e);tHr=r(Eta,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Eta.forEach(t),aHr=i(Ti),Pn=n(Ti,"P",{});var V8=s(Pn);nHr=r(V8,"The model class to instantiate is selected based on the "),Z7e=n(V8,"CODE",{});var Cta=s(Z7e);sHr=r(Cta,"model_type"),Cta.forEach(t),lHr=r(V8,` property of the config object (either
passed as an argument or loaded from `),eLe=n(V8,"CODE",{});var wta=s(eLe);iHr=r(wta,"pretrained_model_name_or_path"),wta.forEach(t),dHr=r(V8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oLe=n(V8,"CODE",{});var Ata=s(oLe);cHr=r(Ata,"pretrained_model_name_or_path"),Ata.forEach(t),mHr=r(V8,":"),V8.forEach(t),fHr=i(Ti),rLe=n(Ti,"UL",{});var Lta=s(rLe);tA=n(Lta,"LI",{});var eHe=s(tA);tLe=n(eHe,"STRONG",{});var yta=s(tLe);gHr=r(yta,"tapas"),yta.forEach(t),hHr=r(eHe," \u2014 "),dte=n(eHe,"A",{href:!0});var xta=s(dte);uHr=r(xta,"TFTapasForQuestionAnswering"),xta.forEach(t),pHr=r(eHe," (TAPAS model)"),eHe.forEach(t),Lta.forEach(t),_Hr=i(Ti),T(aA.$$.fragment,Ti),Ti.forEach(t),Fi.forEach(t),LZe=i(m),Mm=n(m,"H2",{class:!0});var Voo=s(Mm);nA=n(Voo,"A",{id:!0,class:!0,href:!0});var $ta=s(nA);aLe=n($ta,"SPAN",{});var kta=s(aLe);T(wS.$$.fragment,kta),kta.forEach(t),$ta.forEach(t),bHr=i(Voo),nLe=n(Voo,"SPAN",{});var Sta=s(nLe);vHr=r(Sta,"TFAutoModelForDocumentQuestionAnswering"),Sta.forEach(t),Voo.forEach(t),yZe=i(m),_r=n(m,"DIV",{class:!0});var Mi=s(_r);T(AS.$$.fragment,Mi),FHr=i(Mi),Em=n(Mi,"P",{});var Cie=s(Em);THr=r(Cie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),cte=n(Cie,"A",{href:!0});var Rta=s(cte);MHr=r(Rta,"from_pretrained()"),Rta.forEach(t),EHr=r(Cie," class method or the "),mte=n(Cie,"A",{href:!0});var Pta=s(mte);CHr=r(Pta,"from_config()"),Pta.forEach(t),wHr=r(Cie,` class
method.`),Cie.forEach(t),AHr=i(Mi),LS=n(Mi,"P",{});var Xoo=s(LS);LHr=r(Xoo,"This class cannot be instantiated directly using "),sLe=n(Xoo,"CODE",{});var Bta=s(sLe);yHr=r(Bta,"__init__()"),Bta.forEach(t),xHr=r(Xoo," (throws an error)."),Xoo.forEach(t),$Hr=i(Mi),oa=n(Mi,"DIV",{class:!0});var X8=s(oa);T(yS.$$.fragment,X8),kHr=i(X8),lLe=n(X8,"P",{});var Ita=s(lLe);SHr=r(Ita,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Ita.forEach(t),RHr=i(X8),Cm=n(X8,"P",{});var wie=s(Cm);PHr=r(wie,`Note:
Loading a model from its configuration file does `),iLe=n(wie,"STRONG",{});var Nta=s(iLe);BHr=r(Nta,"not"),Nta.forEach(t),IHr=r(wie,` load the model weights. It only affects the
model\u2019s configuration. Use `),fte=n(wie,"A",{href:!0});var qta=s(fte);NHr=r(qta,"from_pretrained()"),qta.forEach(t),qHr=r(wie," to load the model weights."),wie.forEach(t),jHr=i(X8),T(sA.$$.fragment,X8),X8.forEach(t),DHr=i(Mi),Wr=n(Mi,"DIV",{class:!0});var Ei=s(Wr);T(xS.$$.fragment,Ei),GHr=i(Ei),dLe=n(Ei,"P",{});var jta=s(dLe);OHr=r(jta,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),jta.forEach(t),VHr=i(Ei),Bn=n(Ei,"P",{});var z8=s(Bn);XHr=r(z8,"The model class to instantiate is selected based on the "),cLe=n(z8,"CODE",{});var Dta=s(cLe);zHr=r(Dta,"model_type"),Dta.forEach(t),QHr=r(z8,` property of the config object (either
passed as an argument or loaded from `),mLe=n(z8,"CODE",{});var Gta=s(mLe);WHr=r(Gta,"pretrained_model_name_or_path"),Gta.forEach(t),UHr=r(z8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fLe=n(z8,"CODE",{});var Ota=s(fLe);HHr=r(Ota,"pretrained_model_name_or_path"),Ota.forEach(t),JHr=r(z8,":"),z8.forEach(t),YHr=i(Ei),gLe=n(Ei,"UL",{});var Vta=s(gLe);lA=n(Vta,"LI",{});var oHe=s(lA);hLe=n(oHe,"STRONG",{});var Xta=s(hLe);KHr=r(Xta,"layoutlm"),Xta.forEach(t),ZHr=r(oHe," \u2014 "),gte=n(oHe,"A",{href:!0});var zta=s(gte);eJr=r(zta,"TFLayoutLMForQuestionAnswering"),zta.forEach(t),oJr=r(oHe," (LayoutLM model)"),oHe.forEach(t),Vta.forEach(t),rJr=i(Ei),T(iA.$$.fragment,Ei),Ei.forEach(t),Mi.forEach(t),xZe=i(m),wm=n(m,"H2",{class:!0});var zoo=s(wm);dA=n(zoo,"A",{id:!0,class:!0,href:!0});var Qta=s(dA);uLe=n(Qta,"SPAN",{});var Wta=s(uLe);T($S.$$.fragment,Wta),Wta.forEach(t),Qta.forEach(t),tJr=i(zoo),pLe=n(zoo,"SPAN",{});var Uta=s(pLe);aJr=r(Uta,"TFAutoModelForTokenClassification"),Uta.forEach(t),zoo.forEach(t),$Ze=i(m),br=n(m,"DIV",{class:!0});var Ci=s(br);T(kS.$$.fragment,Ci),nJr=i(Ci),Am=n(Ci,"P",{});var Aie=s(Am);sJr=r(Aie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),hte=n(Aie,"A",{href:!0});var Hta=s(hte);lJr=r(Hta,"from_pretrained()"),Hta.forEach(t),iJr=r(Aie," class method or the "),ute=n(Aie,"A",{href:!0});var Jta=s(ute);dJr=r(Jta,"from_config()"),Jta.forEach(t),cJr=r(Aie,` class
method.`),Aie.forEach(t),mJr=i(Ci),SS=n(Ci,"P",{});var Qoo=s(SS);fJr=r(Qoo,"This class cannot be instantiated directly using "),_Le=n(Qoo,"CODE",{});var Yta=s(_Le);gJr=r(Yta,"__init__()"),Yta.forEach(t),hJr=r(Qoo," (throws an error)."),Qoo.forEach(t),uJr=i(Ci),ra=n(Ci,"DIV",{class:!0});var Q8=s(ra);T(RS.$$.fragment,Q8),pJr=i(Q8),bLe=n(Q8,"P",{});var Kta=s(bLe);_Jr=r(Kta,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Kta.forEach(t),bJr=i(Q8),Lm=n(Q8,"P",{});var Lie=s(Lm);vJr=r(Lie,`Note:
Loading a model from its configuration file does `),vLe=n(Lie,"STRONG",{});var Zta=s(vLe);FJr=r(Zta,"not"),Zta.forEach(t),TJr=r(Lie,` load the model weights. It only affects the
model\u2019s configuration. Use `),pte=n(Lie,"A",{href:!0});var eaa=s(pte);MJr=r(eaa,"from_pretrained()"),eaa.forEach(t),EJr=r(Lie," to load the model weights."),Lie.forEach(t),CJr=i(Q8),T(cA.$$.fragment,Q8),Q8.forEach(t),wJr=i(Ci),Ur=n(Ci,"DIV",{class:!0});var wi=s(Ur);T(PS.$$.fragment,wi),AJr=i(wi),FLe=n(wi,"P",{});var oaa=s(FLe);LJr=r(oaa,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),oaa.forEach(t),yJr=i(wi),In=n(wi,"P",{});var W8=s(In);xJr=r(W8,"The model class to instantiate is selected based on the "),TLe=n(W8,"CODE",{});var raa=s(TLe);$Jr=r(raa,"model_type"),raa.forEach(t),kJr=r(W8,` property of the config object (either
passed as an argument or loaded from `),MLe=n(W8,"CODE",{});var taa=s(MLe);SJr=r(taa,"pretrained_model_name_or_path"),taa.forEach(t),RJr=r(W8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ELe=n(W8,"CODE",{});var aaa=s(ELe);PJr=r(aaa,"pretrained_model_name_or_path"),aaa.forEach(t),BJr=r(W8,":"),W8.forEach(t),IJr=i(wi),de=n(wi,"UL",{});var he=s(de);mA=n(he,"LI",{});var rHe=s(mA);CLe=n(rHe,"STRONG",{});var naa=s(CLe);NJr=r(naa,"albert"),naa.forEach(t),qJr=r(rHe," \u2014 "),_te=n(rHe,"A",{href:!0});var saa=s(_te);jJr=r(saa,"TFAlbertForTokenClassification"),saa.forEach(t),DJr=r(rHe," (ALBERT model)"),rHe.forEach(t),GJr=i(he),fA=n(he,"LI",{});var tHe=s(fA);wLe=n(tHe,"STRONG",{});var laa=s(wLe);OJr=r(laa,"bert"),laa.forEach(t),VJr=r(tHe," \u2014 "),bte=n(tHe,"A",{href:!0});var iaa=s(bte);XJr=r(iaa,"TFBertForTokenClassification"),iaa.forEach(t),zJr=r(tHe," (BERT model)"),tHe.forEach(t),QJr=i(he),gA=n(he,"LI",{});var aHe=s(gA);ALe=n(aHe,"STRONG",{});var daa=s(ALe);WJr=r(daa,"camembert"),daa.forEach(t),UJr=r(aHe," \u2014 "),vte=n(aHe,"A",{href:!0});var caa=s(vte);HJr=r(caa,"TFCamembertForTokenClassification"),caa.forEach(t),JJr=r(aHe," (CamemBERT model)"),aHe.forEach(t),YJr=i(he),hA=n(he,"LI",{});var nHe=s(hA);LLe=n(nHe,"STRONG",{});var maa=s(LLe);KJr=r(maa,"convbert"),maa.forEach(t),ZJr=r(nHe," \u2014 "),Fte=n(nHe,"A",{href:!0});var faa=s(Fte);eYr=r(faa,"TFConvBertForTokenClassification"),faa.forEach(t),oYr=r(nHe," (ConvBERT model)"),nHe.forEach(t),rYr=i(he),uA=n(he,"LI",{});var sHe=s(uA);yLe=n(sHe,"STRONG",{});var gaa=s(yLe);tYr=r(gaa,"deberta"),gaa.forEach(t),aYr=r(sHe," \u2014 "),Tte=n(sHe,"A",{href:!0});var haa=s(Tte);nYr=r(haa,"TFDebertaForTokenClassification"),haa.forEach(t),sYr=r(sHe," (DeBERTa model)"),sHe.forEach(t),lYr=i(he),pA=n(he,"LI",{});var lHe=s(pA);xLe=n(lHe,"STRONG",{});var uaa=s(xLe);iYr=r(uaa,"deberta-v2"),uaa.forEach(t),dYr=r(lHe," \u2014 "),Mte=n(lHe,"A",{href:!0});var paa=s(Mte);cYr=r(paa,"TFDebertaV2ForTokenClassification"),paa.forEach(t),mYr=r(lHe," (DeBERTa-v2 model)"),lHe.forEach(t),fYr=i(he),_A=n(he,"LI",{});var iHe=s(_A);$Le=n(iHe,"STRONG",{});var _aa=s($Le);gYr=r(_aa,"distilbert"),_aa.forEach(t),hYr=r(iHe," \u2014 "),Ete=n(iHe,"A",{href:!0});var baa=s(Ete);uYr=r(baa,"TFDistilBertForTokenClassification"),baa.forEach(t),pYr=r(iHe," (DistilBERT model)"),iHe.forEach(t),_Yr=i(he),bA=n(he,"LI",{});var dHe=s(bA);kLe=n(dHe,"STRONG",{});var vaa=s(kLe);bYr=r(vaa,"electra"),vaa.forEach(t),vYr=r(dHe," \u2014 "),Cte=n(dHe,"A",{href:!0});var Faa=s(Cte);FYr=r(Faa,"TFElectraForTokenClassification"),Faa.forEach(t),TYr=r(dHe," (ELECTRA model)"),dHe.forEach(t),MYr=i(he),vA=n(he,"LI",{});var cHe=s(vA);SLe=n(cHe,"STRONG",{});var Taa=s(SLe);EYr=r(Taa,"flaubert"),Taa.forEach(t),CYr=r(cHe," \u2014 "),wte=n(cHe,"A",{href:!0});var Maa=s(wte);wYr=r(Maa,"TFFlaubertForTokenClassification"),Maa.forEach(t),AYr=r(cHe," (FlauBERT model)"),cHe.forEach(t),LYr=i(he),FA=n(he,"LI",{});var mHe=s(FA);RLe=n(mHe,"STRONG",{});var Eaa=s(RLe);yYr=r(Eaa,"funnel"),Eaa.forEach(t),xYr=r(mHe," \u2014 "),Ate=n(mHe,"A",{href:!0});var Caa=s(Ate);$Yr=r(Caa,"TFFunnelForTokenClassification"),Caa.forEach(t),kYr=r(mHe," (Funnel Transformer model)"),mHe.forEach(t),SYr=i(he),TA=n(he,"LI",{});var fHe=s(TA);PLe=n(fHe,"STRONG",{});var waa=s(PLe);RYr=r(waa,"layoutlm"),waa.forEach(t),PYr=r(fHe," \u2014 "),Lte=n(fHe,"A",{href:!0});var Aaa=s(Lte);BYr=r(Aaa,"TFLayoutLMForTokenClassification"),Aaa.forEach(t),IYr=r(fHe," (LayoutLM model)"),fHe.forEach(t),NYr=i(he),MA=n(he,"LI",{});var gHe=s(MA);BLe=n(gHe,"STRONG",{});var Laa=s(BLe);qYr=r(Laa,"layoutlmv3"),Laa.forEach(t),jYr=r(gHe," \u2014 "),yte=n(gHe,"A",{href:!0});var yaa=s(yte);DYr=r(yaa,"TFLayoutLMv3ForTokenClassification"),yaa.forEach(t),GYr=r(gHe," (LayoutLMv3 model)"),gHe.forEach(t),OYr=i(he),EA=n(he,"LI",{});var hHe=s(EA);ILe=n(hHe,"STRONG",{});var xaa=s(ILe);VYr=r(xaa,"longformer"),xaa.forEach(t),XYr=r(hHe," \u2014 "),xte=n(hHe,"A",{href:!0});var $aa=s(xte);zYr=r($aa,"TFLongformerForTokenClassification"),$aa.forEach(t),QYr=r(hHe," (Longformer model)"),hHe.forEach(t),WYr=i(he),CA=n(he,"LI",{});var uHe=s(CA);NLe=n(uHe,"STRONG",{});var kaa=s(NLe);UYr=r(kaa,"mobilebert"),kaa.forEach(t),HYr=r(uHe," \u2014 "),$te=n(uHe,"A",{href:!0});var Saa=s($te);JYr=r(Saa,"TFMobileBertForTokenClassification"),Saa.forEach(t),YYr=r(uHe," (MobileBERT model)"),uHe.forEach(t),KYr=i(he),wA=n(he,"LI",{});var pHe=s(wA);qLe=n(pHe,"STRONG",{});var Raa=s(qLe);ZYr=r(Raa,"mpnet"),Raa.forEach(t),eKr=r(pHe," \u2014 "),kte=n(pHe,"A",{href:!0});var Paa=s(kte);oKr=r(Paa,"TFMPNetForTokenClassification"),Paa.forEach(t),rKr=r(pHe," (MPNet model)"),pHe.forEach(t),tKr=i(he),AA=n(he,"LI",{});var _He=s(AA);jLe=n(_He,"STRONG",{});var Baa=s(jLe);aKr=r(Baa,"rembert"),Baa.forEach(t),nKr=r(_He," \u2014 "),Ste=n(_He,"A",{href:!0});var Iaa=s(Ste);sKr=r(Iaa,"TFRemBertForTokenClassification"),Iaa.forEach(t),lKr=r(_He," (RemBERT model)"),_He.forEach(t),iKr=i(he),LA=n(he,"LI",{});var bHe=s(LA);DLe=n(bHe,"STRONG",{});var Naa=s(DLe);dKr=r(Naa,"roberta"),Naa.forEach(t),cKr=r(bHe," \u2014 "),Rte=n(bHe,"A",{href:!0});var qaa=s(Rte);mKr=r(qaa,"TFRobertaForTokenClassification"),qaa.forEach(t),fKr=r(bHe," (RoBERTa model)"),bHe.forEach(t),gKr=i(he),yA=n(he,"LI",{});var vHe=s(yA);GLe=n(vHe,"STRONG",{});var jaa=s(GLe);hKr=r(jaa,"roformer"),jaa.forEach(t),uKr=r(vHe," \u2014 "),Pte=n(vHe,"A",{href:!0});var Daa=s(Pte);pKr=r(Daa,"TFRoFormerForTokenClassification"),Daa.forEach(t),_Kr=r(vHe," (RoFormer model)"),vHe.forEach(t),bKr=i(he),xA=n(he,"LI",{});var FHe=s(xA);OLe=n(FHe,"STRONG",{});var Gaa=s(OLe);vKr=r(Gaa,"xlm"),Gaa.forEach(t),FKr=r(FHe," \u2014 "),Bte=n(FHe,"A",{href:!0});var Oaa=s(Bte);TKr=r(Oaa,"TFXLMForTokenClassification"),Oaa.forEach(t),MKr=r(FHe," (XLM model)"),FHe.forEach(t),EKr=i(he),$A=n(he,"LI",{});var THe=s($A);VLe=n(THe,"STRONG",{});var Vaa=s(VLe);CKr=r(Vaa,"xlm-roberta"),Vaa.forEach(t),wKr=r(THe," \u2014 "),Ite=n(THe,"A",{href:!0});var Xaa=s(Ite);AKr=r(Xaa,"TFXLMRobertaForTokenClassification"),Xaa.forEach(t),LKr=r(THe," (XLM-RoBERTa model)"),THe.forEach(t),yKr=i(he),kA=n(he,"LI",{});var MHe=s(kA);XLe=n(MHe,"STRONG",{});var zaa=s(XLe);xKr=r(zaa,"xlnet"),zaa.forEach(t),$Kr=r(MHe," \u2014 "),Nte=n(MHe,"A",{href:!0});var Qaa=s(Nte);kKr=r(Qaa,"TFXLNetForTokenClassification"),Qaa.forEach(t),SKr=r(MHe," (XLNet model)"),MHe.forEach(t),he.forEach(t),RKr=i(wi),T(SA.$$.fragment,wi),wi.forEach(t),Ci.forEach(t),kZe=i(m),ym=n(m,"H2",{class:!0});var Woo=s(ym);RA=n(Woo,"A",{id:!0,class:!0,href:!0});var Waa=s(RA);zLe=n(Waa,"SPAN",{});var Uaa=s(zLe);T(BS.$$.fragment,Uaa),Uaa.forEach(t),Waa.forEach(t),PKr=i(Woo),QLe=n(Woo,"SPAN",{});var Haa=s(QLe);BKr=r(Haa,"TFAutoModelForQuestionAnswering"),Haa.forEach(t),Woo.forEach(t),SZe=i(m),vr=n(m,"DIV",{class:!0});var Ai=s(vr);T(IS.$$.fragment,Ai),IKr=i(Ai),xm=n(Ai,"P",{});var yie=s(xm);NKr=r(yie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),qte=n(yie,"A",{href:!0});var Jaa=s(qte);qKr=r(Jaa,"from_pretrained()"),Jaa.forEach(t),jKr=r(yie," class method or the "),jte=n(yie,"A",{href:!0});var Yaa=s(jte);DKr=r(Yaa,"from_config()"),Yaa.forEach(t),GKr=r(yie,` class
method.`),yie.forEach(t),OKr=i(Ai),NS=n(Ai,"P",{});var Uoo=s(NS);VKr=r(Uoo,"This class cannot be instantiated directly using "),WLe=n(Uoo,"CODE",{});var Kaa=s(WLe);XKr=r(Kaa,"__init__()"),Kaa.forEach(t),zKr=r(Uoo," (throws an error)."),Uoo.forEach(t),QKr=i(Ai),ta=n(Ai,"DIV",{class:!0});var U8=s(ta);T(qS.$$.fragment,U8),WKr=i(U8),ULe=n(U8,"P",{});var Zaa=s(ULe);UKr=r(Zaa,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Zaa.forEach(t),HKr=i(U8),$m=n(U8,"P",{});var xie=s($m);JKr=r(xie,`Note:
Loading a model from its configuration file does `),HLe=n(xie,"STRONG",{});var ena=s(HLe);YKr=r(ena,"not"),ena.forEach(t),KKr=r(xie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Dte=n(xie,"A",{href:!0});var ona=s(Dte);ZKr=r(ona,"from_pretrained()"),ona.forEach(t),eZr=r(xie," to load the model weights."),xie.forEach(t),oZr=i(U8),T(PA.$$.fragment,U8),U8.forEach(t),rZr=i(Ai),Hr=n(Ai,"DIV",{class:!0});var Li=s(Hr);T(jS.$$.fragment,Li),tZr=i(Li),JLe=n(Li,"P",{});var rna=s(JLe);aZr=r(rna,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),rna.forEach(t),nZr=i(Li),Nn=n(Li,"P",{});var H8=s(Nn);sZr=r(H8,"The model class to instantiate is selected based on the "),YLe=n(H8,"CODE",{});var tna=s(YLe);lZr=r(tna,"model_type"),tna.forEach(t),iZr=r(H8,` property of the config object (either
passed as an argument or loaded from `),KLe=n(H8,"CODE",{});var ana=s(KLe);dZr=r(ana,"pretrained_model_name_or_path"),ana.forEach(t),cZr=r(H8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZLe=n(H8,"CODE",{});var nna=s(ZLe);mZr=r(nna,"pretrained_model_name_or_path"),nna.forEach(t),fZr=r(H8,":"),H8.forEach(t),gZr=i(Li),ce=n(Li,"UL",{});var ue=s(ce);BA=n(ue,"LI",{});var EHe=s(BA);eye=n(EHe,"STRONG",{});var sna=s(eye);hZr=r(sna,"albert"),sna.forEach(t),uZr=r(EHe," \u2014 "),Gte=n(EHe,"A",{href:!0});var lna=s(Gte);pZr=r(lna,"TFAlbertForQuestionAnswering"),lna.forEach(t),_Zr=r(EHe," (ALBERT model)"),EHe.forEach(t),bZr=i(ue),IA=n(ue,"LI",{});var CHe=s(IA);oye=n(CHe,"STRONG",{});var ina=s(oye);vZr=r(ina,"bert"),ina.forEach(t),FZr=r(CHe," \u2014 "),Ote=n(CHe,"A",{href:!0});var dna=s(Ote);TZr=r(dna,"TFBertForQuestionAnswering"),dna.forEach(t),MZr=r(CHe," (BERT model)"),CHe.forEach(t),EZr=i(ue),NA=n(ue,"LI",{});var wHe=s(NA);rye=n(wHe,"STRONG",{});var cna=s(rye);CZr=r(cna,"camembert"),cna.forEach(t),wZr=r(wHe," \u2014 "),Vte=n(wHe,"A",{href:!0});var mna=s(Vte);AZr=r(mna,"TFCamembertForQuestionAnswering"),mna.forEach(t),LZr=r(wHe," (CamemBERT model)"),wHe.forEach(t),yZr=i(ue),qA=n(ue,"LI",{});var AHe=s(qA);tye=n(AHe,"STRONG",{});var fna=s(tye);xZr=r(fna,"convbert"),fna.forEach(t),$Zr=r(AHe," \u2014 "),Xte=n(AHe,"A",{href:!0});var gna=s(Xte);kZr=r(gna,"TFConvBertForQuestionAnswering"),gna.forEach(t),SZr=r(AHe," (ConvBERT model)"),AHe.forEach(t),RZr=i(ue),jA=n(ue,"LI",{});var LHe=s(jA);aye=n(LHe,"STRONG",{});var hna=s(aye);PZr=r(hna,"deberta"),hna.forEach(t),BZr=r(LHe," \u2014 "),zte=n(LHe,"A",{href:!0});var una=s(zte);IZr=r(una,"TFDebertaForQuestionAnswering"),una.forEach(t),NZr=r(LHe," (DeBERTa model)"),LHe.forEach(t),qZr=i(ue),DA=n(ue,"LI",{});var yHe=s(DA);nye=n(yHe,"STRONG",{});var pna=s(nye);jZr=r(pna,"deberta-v2"),pna.forEach(t),DZr=r(yHe," \u2014 "),Qte=n(yHe,"A",{href:!0});var _na=s(Qte);GZr=r(_na,"TFDebertaV2ForQuestionAnswering"),_na.forEach(t),OZr=r(yHe," (DeBERTa-v2 model)"),yHe.forEach(t),VZr=i(ue),GA=n(ue,"LI",{});var xHe=s(GA);sye=n(xHe,"STRONG",{});var bna=s(sye);XZr=r(bna,"distilbert"),bna.forEach(t),zZr=r(xHe," \u2014 "),Wte=n(xHe,"A",{href:!0});var vna=s(Wte);QZr=r(vna,"TFDistilBertForQuestionAnswering"),vna.forEach(t),WZr=r(xHe," (DistilBERT model)"),xHe.forEach(t),UZr=i(ue),OA=n(ue,"LI",{});var $He=s(OA);lye=n($He,"STRONG",{});var Fna=s(lye);HZr=r(Fna,"electra"),Fna.forEach(t),JZr=r($He," \u2014 "),Ute=n($He,"A",{href:!0});var Tna=s(Ute);YZr=r(Tna,"TFElectraForQuestionAnswering"),Tna.forEach(t),KZr=r($He," (ELECTRA model)"),$He.forEach(t),ZZr=i(ue),VA=n(ue,"LI",{});var kHe=s(VA);iye=n(kHe,"STRONG",{});var Mna=s(iye);eet=r(Mna,"flaubert"),Mna.forEach(t),oet=r(kHe," \u2014 "),Hte=n(kHe,"A",{href:!0});var Ena=s(Hte);ret=r(Ena,"TFFlaubertForQuestionAnsweringSimple"),Ena.forEach(t),tet=r(kHe," (FlauBERT model)"),kHe.forEach(t),aet=i(ue),XA=n(ue,"LI",{});var SHe=s(XA);dye=n(SHe,"STRONG",{});var Cna=s(dye);net=r(Cna,"funnel"),Cna.forEach(t),set=r(SHe," \u2014 "),Jte=n(SHe,"A",{href:!0});var wna=s(Jte);iet=r(wna,"TFFunnelForQuestionAnswering"),wna.forEach(t),det=r(SHe," (Funnel Transformer model)"),SHe.forEach(t),cet=i(ue),zA=n(ue,"LI",{});var RHe=s(zA);cye=n(RHe,"STRONG",{});var Ana=s(cye);met=r(Ana,"gptj"),Ana.forEach(t),fet=r(RHe," \u2014 "),Yte=n(RHe,"A",{href:!0});var Lna=s(Yte);get=r(Lna,"TFGPTJForQuestionAnswering"),Lna.forEach(t),het=r(RHe," (GPT-J model)"),RHe.forEach(t),uet=i(ue),QA=n(ue,"LI",{});var PHe=s(QA);mye=n(PHe,"STRONG",{});var yna=s(mye);pet=r(yna,"layoutlmv3"),yna.forEach(t),_et=r(PHe," \u2014 "),Kte=n(PHe,"A",{href:!0});var xna=s(Kte);bet=r(xna,"TFLayoutLMv3ForQuestionAnswering"),xna.forEach(t),vet=r(PHe," (LayoutLMv3 model)"),PHe.forEach(t),Fet=i(ue),WA=n(ue,"LI",{});var BHe=s(WA);fye=n(BHe,"STRONG",{});var $na=s(fye);Tet=r($na,"longformer"),$na.forEach(t),Met=r(BHe," \u2014 "),Zte=n(BHe,"A",{href:!0});var kna=s(Zte);Eet=r(kna,"TFLongformerForQuestionAnswering"),kna.forEach(t),Cet=r(BHe," (Longformer model)"),BHe.forEach(t),wet=i(ue),UA=n(ue,"LI",{});var IHe=s(UA);gye=n(IHe,"STRONG",{});var Sna=s(gye);Aet=r(Sna,"mobilebert"),Sna.forEach(t),Let=r(IHe," \u2014 "),eae=n(IHe,"A",{href:!0});var Rna=s(eae);yet=r(Rna,"TFMobileBertForQuestionAnswering"),Rna.forEach(t),xet=r(IHe," (MobileBERT model)"),IHe.forEach(t),$et=i(ue),HA=n(ue,"LI",{});var NHe=s(HA);hye=n(NHe,"STRONG",{});var Pna=s(hye);ket=r(Pna,"mpnet"),Pna.forEach(t),Set=r(NHe," \u2014 "),oae=n(NHe,"A",{href:!0});var Bna=s(oae);Ret=r(Bna,"TFMPNetForQuestionAnswering"),Bna.forEach(t),Pet=r(NHe," (MPNet model)"),NHe.forEach(t),Bet=i(ue),JA=n(ue,"LI",{});var qHe=s(JA);uye=n(qHe,"STRONG",{});var Ina=s(uye);Iet=r(Ina,"rembert"),Ina.forEach(t),Net=r(qHe," \u2014 "),rae=n(qHe,"A",{href:!0});var Nna=s(rae);qet=r(Nna,"TFRemBertForQuestionAnswering"),Nna.forEach(t),jet=r(qHe," (RemBERT model)"),qHe.forEach(t),Det=i(ue),YA=n(ue,"LI",{});var jHe=s(YA);pye=n(jHe,"STRONG",{});var qna=s(pye);Get=r(qna,"roberta"),qna.forEach(t),Oet=r(jHe," \u2014 "),tae=n(jHe,"A",{href:!0});var jna=s(tae);Vet=r(jna,"TFRobertaForQuestionAnswering"),jna.forEach(t),Xet=r(jHe," (RoBERTa model)"),jHe.forEach(t),zet=i(ue),KA=n(ue,"LI",{});var DHe=s(KA);_ye=n(DHe,"STRONG",{});var Dna=s(_ye);Qet=r(Dna,"roformer"),Dna.forEach(t),Wet=r(DHe," \u2014 "),aae=n(DHe,"A",{href:!0});var Gna=s(aae);Uet=r(Gna,"TFRoFormerForQuestionAnswering"),Gna.forEach(t),Het=r(DHe," (RoFormer model)"),DHe.forEach(t),Jet=i(ue),ZA=n(ue,"LI",{});var GHe=s(ZA);bye=n(GHe,"STRONG",{});var Ona=s(bye);Yet=r(Ona,"xlm"),Ona.forEach(t),Ket=r(GHe," \u2014 "),nae=n(GHe,"A",{href:!0});var Vna=s(nae);Zet=r(Vna,"TFXLMForQuestionAnsweringSimple"),Vna.forEach(t),eot=r(GHe," (XLM model)"),GHe.forEach(t),oot=i(ue),e6=n(ue,"LI",{});var OHe=s(e6);vye=n(OHe,"STRONG",{});var Xna=s(vye);rot=r(Xna,"xlm-roberta"),Xna.forEach(t),tot=r(OHe," \u2014 "),sae=n(OHe,"A",{href:!0});var zna=s(sae);aot=r(zna,"TFXLMRobertaForQuestionAnswering"),zna.forEach(t),not=r(OHe," (XLM-RoBERTa model)"),OHe.forEach(t),sot=i(ue),o6=n(ue,"LI",{});var VHe=s(o6);Fye=n(VHe,"STRONG",{});var Qna=s(Fye);lot=r(Qna,"xlnet"),Qna.forEach(t),iot=r(VHe," \u2014 "),lae=n(VHe,"A",{href:!0});var Wna=s(lae);dot=r(Wna,"TFXLNetForQuestionAnsweringSimple"),Wna.forEach(t),cot=r(VHe," (XLNet model)"),VHe.forEach(t),ue.forEach(t),mot=i(Li),T(r6.$$.fragment,Li),Li.forEach(t),Ai.forEach(t),RZe=i(m),km=n(m,"H2",{class:!0});var Hoo=s(km);t6=n(Hoo,"A",{id:!0,class:!0,href:!0});var Una=s(t6);Tye=n(Una,"SPAN",{});var Hna=s(Tye);T(DS.$$.fragment,Hna),Hna.forEach(t),Una.forEach(t),fot=i(Hoo),Mye=n(Hoo,"SPAN",{});var Jna=s(Mye);got=r(Jna,"TFAutoModelForVision2Seq"),Jna.forEach(t),Hoo.forEach(t),PZe=i(m),Fr=n(m,"DIV",{class:!0});var yi=s(Fr);T(GS.$$.fragment,yi),hot=i(yi),Sm=n(yi,"P",{});var $ie=s(Sm);uot=r($ie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),iae=n($ie,"A",{href:!0});var Yna=s(iae);pot=r(Yna,"from_pretrained()"),Yna.forEach(t),_ot=r($ie," class method or the "),dae=n($ie,"A",{href:!0});var Kna=s(dae);bot=r(Kna,"from_config()"),Kna.forEach(t),vot=r($ie,` class
method.`),$ie.forEach(t),Fot=i(yi),OS=n(yi,"P",{});var Joo=s(OS);Tot=r(Joo,"This class cannot be instantiated directly using "),Eye=n(Joo,"CODE",{});var Zna=s(Eye);Mot=r(Zna,"__init__()"),Zna.forEach(t),Eot=r(Joo," (throws an error)."),Joo.forEach(t),Cot=i(yi),aa=n(yi,"DIV",{class:!0});var J8=s(aa);T(VS.$$.fragment,J8),wot=i(J8),Cye=n(J8,"P",{});var esa=s(Cye);Aot=r(esa,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),esa.forEach(t),Lot=i(J8),Rm=n(J8,"P",{});var kie=s(Rm);yot=r(kie,`Note:
Loading a model from its configuration file does `),wye=n(kie,"STRONG",{});var osa=s(wye);xot=r(osa,"not"),osa.forEach(t),$ot=r(kie,` load the model weights. It only affects the
model\u2019s configuration. Use `),cae=n(kie,"A",{href:!0});var rsa=s(cae);kot=r(rsa,"from_pretrained()"),rsa.forEach(t),Sot=r(kie," to load the model weights."),kie.forEach(t),Rot=i(J8),T(a6.$$.fragment,J8),J8.forEach(t),Pot=i(yi),Jr=n(yi,"DIV",{class:!0});var xi=s(Jr);T(XS.$$.fragment,xi),Bot=i(xi),Aye=n(xi,"P",{});var tsa=s(Aye);Iot=r(tsa,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),tsa.forEach(t),Not=i(xi),qn=n(xi,"P",{});var Y8=s(qn);qot=r(Y8,"The model class to instantiate is selected based on the "),Lye=n(Y8,"CODE",{});var asa=s(Lye);jot=r(asa,"model_type"),asa.forEach(t),Dot=r(Y8,` property of the config object (either
passed as an argument or loaded from `),yye=n(Y8,"CODE",{});var nsa=s(yye);Got=r(nsa,"pretrained_model_name_or_path"),nsa.forEach(t),Oot=r(Y8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xye=n(Y8,"CODE",{});var ssa=s(xye);Vot=r(ssa,"pretrained_model_name_or_path"),ssa.forEach(t),Xot=r(Y8,":"),Y8.forEach(t),zot=i(xi),$ye=n(xi,"UL",{});var lsa=s($ye);n6=n(lsa,"LI",{});var XHe=s(n6);kye=n(XHe,"STRONG",{});var isa=s(kye);Qot=r(isa,"vision-encoder-decoder"),isa.forEach(t),Wot=r(XHe," \u2014 "),mae=n(XHe,"A",{href:!0});var dsa=s(mae);Uot=r(dsa,"TFVisionEncoderDecoderModel"),dsa.forEach(t),Hot=r(XHe," (Vision Encoder decoder model)"),XHe.forEach(t),lsa.forEach(t),Jot=i(xi),T(s6.$$.fragment,xi),xi.forEach(t),yi.forEach(t),BZe=i(m),Pm=n(m,"H2",{class:!0});var Yoo=s(Pm);l6=n(Yoo,"A",{id:!0,class:!0,href:!0});var csa=s(l6);Sye=n(csa,"SPAN",{});var msa=s(Sye);T(zS.$$.fragment,msa),msa.forEach(t),csa.forEach(t),Yot=i(Yoo),Rye=n(Yoo,"SPAN",{});var fsa=s(Rye);Kot=r(fsa,"TFAutoModelForSpeechSeq2Seq"),fsa.forEach(t),Yoo.forEach(t),IZe=i(m),Tr=n(m,"DIV",{class:!0});var $i=s(Tr);T(QS.$$.fragment,$i),Zot=i($i),Bm=n($i,"P",{});var Sie=s(Bm);ert=r(Sie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),fae=n(Sie,"A",{href:!0});var gsa=s(fae);ort=r(gsa,"from_pretrained()"),gsa.forEach(t),rrt=r(Sie," class method or the "),gae=n(Sie,"A",{href:!0});var hsa=s(gae);trt=r(hsa,"from_config()"),hsa.forEach(t),art=r(Sie,` class
method.`),Sie.forEach(t),nrt=i($i),WS=n($i,"P",{});var Koo=s(WS);srt=r(Koo,"This class cannot be instantiated directly using "),Pye=n(Koo,"CODE",{});var usa=s(Pye);lrt=r(usa,"__init__()"),usa.forEach(t),irt=r(Koo," (throws an error)."),Koo.forEach(t),drt=i($i),na=n($i,"DIV",{class:!0});var K8=s(na);T(US.$$.fragment,K8),crt=i(K8),Bye=n(K8,"P",{});var psa=s(Bye);mrt=r(psa,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),psa.forEach(t),frt=i(K8),Im=n(K8,"P",{});var Rie=s(Im);grt=r(Rie,`Note:
Loading a model from its configuration file does `),Iye=n(Rie,"STRONG",{});var _sa=s(Iye);hrt=r(_sa,"not"),_sa.forEach(t),urt=r(Rie,` load the model weights. It only affects the
model\u2019s configuration. Use `),hae=n(Rie,"A",{href:!0});var bsa=s(hae);prt=r(bsa,"from_pretrained()"),bsa.forEach(t),_rt=r(Rie," to load the model weights."),Rie.forEach(t),brt=i(K8),T(i6.$$.fragment,K8),K8.forEach(t),vrt=i($i),Yr=n($i,"DIV",{class:!0});var ki=s(Yr);T(HS.$$.fragment,ki),Frt=i(ki),Nye=n(ki,"P",{});var vsa=s(Nye);Trt=r(vsa,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),vsa.forEach(t),Mrt=i(ki),jn=n(ki,"P",{});var Z8=s(jn);Ert=r(Z8,"The model class to instantiate is selected based on the "),qye=n(Z8,"CODE",{});var Fsa=s(qye);Crt=r(Fsa,"model_type"),Fsa.forEach(t),wrt=r(Z8,` property of the config object (either
passed as an argument or loaded from `),jye=n(Z8,"CODE",{});var Tsa=s(jye);Art=r(Tsa,"pretrained_model_name_or_path"),Tsa.forEach(t),Lrt=r(Z8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dye=n(Z8,"CODE",{});var Msa=s(Dye);yrt=r(Msa,"pretrained_model_name_or_path"),Msa.forEach(t),xrt=r(Z8,":"),Z8.forEach(t),$rt=i(ki),Gye=n(ki,"UL",{});var Esa=s(Gye);d6=n(Esa,"LI",{});var zHe=s(d6);Oye=n(zHe,"STRONG",{});var Csa=s(Oye);krt=r(Csa,"speech_to_text"),Csa.forEach(t),Srt=r(zHe," \u2014 "),uae=n(zHe,"A",{href:!0});var wsa=s(uae);Rrt=r(wsa,"TFSpeech2TextForConditionalGeneration"),wsa.forEach(t),Prt=r(zHe," (Speech2Text model)"),zHe.forEach(t),Esa.forEach(t),Brt=i(ki),T(c6.$$.fragment,ki),ki.forEach(t),$i.forEach(t),NZe=i(m),Nm=n(m,"H2",{class:!0});var Zoo=s(Nm);m6=n(Zoo,"A",{id:!0,class:!0,href:!0});var Asa=s(m6);Vye=n(Asa,"SPAN",{});var Lsa=s(Vye);T(JS.$$.fragment,Lsa),Lsa.forEach(t),Asa.forEach(t),Irt=i(Zoo),Xye=n(Zoo,"SPAN",{});var ysa=s(Xye);Nrt=r(ysa,"FlaxAutoModel"),ysa.forEach(t),Zoo.forEach(t),qZe=i(m),Mr=n(m,"DIV",{class:!0});var Si=s(Mr);T(YS.$$.fragment,Si),qrt=i(Si),qm=n(Si,"P",{});var Pie=s(qm);jrt=r(Pie,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),pae=n(Pie,"A",{href:!0});var xsa=s(pae);Drt=r(xsa,"from_pretrained()"),xsa.forEach(t),Grt=r(Pie," class method or the "),_ae=n(Pie,"A",{href:!0});var $sa=s(_ae);Ort=r($sa,"from_config()"),$sa.forEach(t),Vrt=r(Pie,` class
method.`),Pie.forEach(t),Xrt=i(Si),KS=n(Si,"P",{});var ero=s(KS);zrt=r(ero,"This class cannot be instantiated directly using "),zye=n(ero,"CODE",{});var ksa=s(zye);Qrt=r(ksa,"__init__()"),ksa.forEach(t),Wrt=r(ero," (throws an error)."),ero.forEach(t),Urt=i(Si),sa=n(Si,"DIV",{class:!0});var e9=s(sa);T(ZS.$$.fragment,e9),Hrt=i(e9),Qye=n(e9,"P",{});var Ssa=s(Qye);Jrt=r(Ssa,"Instantiates one of the base model classes of the library from a configuration."),Ssa.forEach(t),Yrt=i(e9),jm=n(e9,"P",{});var Bie=s(jm);Krt=r(Bie,`Note:
Loading a model from its configuration file does `),Wye=n(Bie,"STRONG",{});var Rsa=s(Wye);Zrt=r(Rsa,"not"),Rsa.forEach(t),ett=r(Bie,` load the model weights. It only affects the
model\u2019s configuration. Use `),bae=n(Bie,"A",{href:!0});var Psa=s(bae);ott=r(Psa,"from_pretrained()"),Psa.forEach(t),rtt=r(Bie," to load the model weights."),Bie.forEach(t),ttt=i(e9),T(f6.$$.fragment,e9),e9.forEach(t),att=i(Si),Kr=n(Si,"DIV",{class:!0});var Ri=s(Kr);T(eR.$$.fragment,Ri),ntt=i(Ri),Uye=n(Ri,"P",{});var Bsa=s(Uye);stt=r(Bsa,"Instantiate one of the base model classes of the library from a pretrained model."),Bsa.forEach(t),ltt=i(Ri),Dn=n(Ri,"P",{});var o9=s(Dn);itt=r(o9,"The model class to instantiate is selected based on the "),Hye=n(o9,"CODE",{});var Isa=s(Hye);dtt=r(Isa,"model_type"),Isa.forEach(t),ctt=r(o9,` property of the config object (either
passed as an argument or loaded from `),Jye=n(o9,"CODE",{});var Nsa=s(Jye);mtt=r(Nsa,"pretrained_model_name_or_path"),Nsa.forEach(t),ftt=r(o9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yye=n(o9,"CODE",{});var qsa=s(Yye);gtt=r(qsa,"pretrained_model_name_or_path"),qsa.forEach(t),htt=r(o9,":"),o9.forEach(t),utt=i(Ri),te=n(Ri,"UL",{});var ne=s(te);g6=n(ne,"LI",{});var QHe=s(g6);Kye=n(QHe,"STRONG",{});var jsa=s(Kye);ptt=r(jsa,"albert"),jsa.forEach(t),_tt=r(QHe," \u2014 "),vae=n(QHe,"A",{href:!0});var Dsa=s(vae);btt=r(Dsa,"FlaxAlbertModel"),Dsa.forEach(t),vtt=r(QHe," (ALBERT model)"),QHe.forEach(t),Ftt=i(ne),h6=n(ne,"LI",{});var WHe=s(h6);Zye=n(WHe,"STRONG",{});var Gsa=s(Zye);Ttt=r(Gsa,"bart"),Gsa.forEach(t),Mtt=r(WHe," \u2014 "),Fae=n(WHe,"A",{href:!0});var Osa=s(Fae);Ett=r(Osa,"FlaxBartModel"),Osa.forEach(t),Ctt=r(WHe," (BART model)"),WHe.forEach(t),wtt=i(ne),u6=n(ne,"LI",{});var UHe=s(u6);e8e=n(UHe,"STRONG",{});var Vsa=s(e8e);Att=r(Vsa,"beit"),Vsa.forEach(t),Ltt=r(UHe," \u2014 "),Tae=n(UHe,"A",{href:!0});var Xsa=s(Tae);ytt=r(Xsa,"FlaxBeitModel"),Xsa.forEach(t),xtt=r(UHe," (BEiT model)"),UHe.forEach(t),$tt=i(ne),p6=n(ne,"LI",{});var HHe=s(p6);o8e=n(HHe,"STRONG",{});var zsa=s(o8e);ktt=r(zsa,"bert"),zsa.forEach(t),Stt=r(HHe," \u2014 "),Mae=n(HHe,"A",{href:!0});var Qsa=s(Mae);Rtt=r(Qsa,"FlaxBertModel"),Qsa.forEach(t),Ptt=r(HHe," (BERT model)"),HHe.forEach(t),Btt=i(ne),_6=n(ne,"LI",{});var JHe=s(_6);r8e=n(JHe,"STRONG",{});var Wsa=s(r8e);Itt=r(Wsa,"big_bird"),Wsa.forEach(t),Ntt=r(JHe," \u2014 "),Eae=n(JHe,"A",{href:!0});var Usa=s(Eae);qtt=r(Usa,"FlaxBigBirdModel"),Usa.forEach(t),jtt=r(JHe," (BigBird model)"),JHe.forEach(t),Dtt=i(ne),b6=n(ne,"LI",{});var YHe=s(b6);t8e=n(YHe,"STRONG",{});var Hsa=s(t8e);Gtt=r(Hsa,"blenderbot"),Hsa.forEach(t),Ott=r(YHe," \u2014 "),Cae=n(YHe,"A",{href:!0});var Jsa=s(Cae);Vtt=r(Jsa,"FlaxBlenderbotModel"),Jsa.forEach(t),Xtt=r(YHe," (Blenderbot model)"),YHe.forEach(t),ztt=i(ne),v6=n(ne,"LI",{});var KHe=s(v6);a8e=n(KHe,"STRONG",{});var Ysa=s(a8e);Qtt=r(Ysa,"blenderbot-small"),Ysa.forEach(t),Wtt=r(KHe," \u2014 "),wae=n(KHe,"A",{href:!0});var Ksa=s(wae);Utt=r(Ksa,"FlaxBlenderbotSmallModel"),Ksa.forEach(t),Htt=r(KHe," (BlenderbotSmall model)"),KHe.forEach(t),Jtt=i(ne),F6=n(ne,"LI",{});var ZHe=s(F6);n8e=n(ZHe,"STRONG",{});var Zsa=s(n8e);Ytt=r(Zsa,"clip"),Zsa.forEach(t),Ktt=r(ZHe," \u2014 "),Aae=n(ZHe,"A",{href:!0});var ela=s(Aae);Ztt=r(ela,"FlaxCLIPModel"),ela.forEach(t),eat=r(ZHe," (CLIP model)"),ZHe.forEach(t),oat=i(ne),T6=n(ne,"LI",{});var eJe=s(T6);s8e=n(eJe,"STRONG",{});var ola=s(s8e);rat=r(ola,"distilbert"),ola.forEach(t),tat=r(eJe," \u2014 "),Lae=n(eJe,"A",{href:!0});var rla=s(Lae);aat=r(rla,"FlaxDistilBertModel"),rla.forEach(t),nat=r(eJe," (DistilBERT model)"),eJe.forEach(t),sat=i(ne),M6=n(ne,"LI",{});var oJe=s(M6);l8e=n(oJe,"STRONG",{});var tla=s(l8e);lat=r(tla,"electra"),tla.forEach(t),iat=r(oJe," \u2014 "),yae=n(oJe,"A",{href:!0});var ala=s(yae);dat=r(ala,"FlaxElectraModel"),ala.forEach(t),cat=r(oJe," (ELECTRA model)"),oJe.forEach(t),mat=i(ne),E6=n(ne,"LI",{});var rJe=s(E6);i8e=n(rJe,"STRONG",{});var nla=s(i8e);fat=r(nla,"gpt2"),nla.forEach(t),gat=r(rJe," \u2014 "),xae=n(rJe,"A",{href:!0});var sla=s(xae);hat=r(sla,"FlaxGPT2Model"),sla.forEach(t),uat=r(rJe," (OpenAI GPT-2 model)"),rJe.forEach(t),pat=i(ne),C6=n(ne,"LI",{});var tJe=s(C6);d8e=n(tJe,"STRONG",{});var lla=s(d8e);_at=r(lla,"gpt_neo"),lla.forEach(t),bat=r(tJe," \u2014 "),$ae=n(tJe,"A",{href:!0});var ila=s($ae);vat=r(ila,"FlaxGPTNeoModel"),ila.forEach(t),Fat=r(tJe," (GPT Neo model)"),tJe.forEach(t),Tat=i(ne),w6=n(ne,"LI",{});var aJe=s(w6);c8e=n(aJe,"STRONG",{});var dla=s(c8e);Mat=r(dla,"gptj"),dla.forEach(t),Eat=r(aJe," \u2014 "),kae=n(aJe,"A",{href:!0});var cla=s(kae);Cat=r(cla,"FlaxGPTJModel"),cla.forEach(t),wat=r(aJe," (GPT-J model)"),aJe.forEach(t),Aat=i(ne),A6=n(ne,"LI",{});var nJe=s(A6);m8e=n(nJe,"STRONG",{});var mla=s(m8e);Lat=r(mla,"longt5"),mla.forEach(t),yat=r(nJe," \u2014 "),Sae=n(nJe,"A",{href:!0});var fla=s(Sae);xat=r(fla,"FlaxLongT5Model"),fla.forEach(t),$at=r(nJe," (LongT5 model)"),nJe.forEach(t),kat=i(ne),L6=n(ne,"LI",{});var sJe=s(L6);f8e=n(sJe,"STRONG",{});var gla=s(f8e);Sat=r(gla,"marian"),gla.forEach(t),Rat=r(sJe," \u2014 "),Rae=n(sJe,"A",{href:!0});var hla=s(Rae);Pat=r(hla,"FlaxMarianModel"),hla.forEach(t),Bat=r(sJe," (Marian model)"),sJe.forEach(t),Iat=i(ne),y6=n(ne,"LI",{});var lJe=s(y6);g8e=n(lJe,"STRONG",{});var ula=s(g8e);Nat=r(ula,"mbart"),ula.forEach(t),qat=r(lJe," \u2014 "),Pae=n(lJe,"A",{href:!0});var pla=s(Pae);jat=r(pla,"FlaxMBartModel"),pla.forEach(t),Dat=r(lJe," (mBART model)"),lJe.forEach(t),Gat=i(ne),x6=n(ne,"LI",{});var iJe=s(x6);h8e=n(iJe,"STRONG",{});var _la=s(h8e);Oat=r(_la,"mt5"),_la.forEach(t),Vat=r(iJe," \u2014 "),Bae=n(iJe,"A",{href:!0});var bla=s(Bae);Xat=r(bla,"FlaxMT5Model"),bla.forEach(t),zat=r(iJe," (MT5 model)"),iJe.forEach(t),Qat=i(ne),$6=n(ne,"LI",{});var dJe=s($6);u8e=n(dJe,"STRONG",{});var vla=s(u8e);Wat=r(vla,"opt"),vla.forEach(t),Uat=r(dJe," \u2014 "),Iae=n(dJe,"A",{href:!0});var Fla=s(Iae);Hat=r(Fla,"FlaxOPTModel"),Fla.forEach(t),Jat=r(dJe," (OPT model)"),dJe.forEach(t),Yat=i(ne),k6=n(ne,"LI",{});var cJe=s(k6);p8e=n(cJe,"STRONG",{});var Tla=s(p8e);Kat=r(Tla,"pegasus"),Tla.forEach(t),Zat=r(cJe," \u2014 "),Nae=n(cJe,"A",{href:!0});var Mla=s(Nae);ent=r(Mla,"FlaxPegasusModel"),Mla.forEach(t),ont=r(cJe," (Pegasus model)"),cJe.forEach(t),rnt=i(ne),S6=n(ne,"LI",{});var mJe=s(S6);_8e=n(mJe,"STRONG",{});var Ela=s(_8e);tnt=r(Ela,"roberta"),Ela.forEach(t),ant=r(mJe," \u2014 "),qae=n(mJe,"A",{href:!0});var Cla=s(qae);nnt=r(Cla,"FlaxRobertaModel"),Cla.forEach(t),snt=r(mJe," (RoBERTa model)"),mJe.forEach(t),lnt=i(ne),R6=n(ne,"LI",{});var fJe=s(R6);b8e=n(fJe,"STRONG",{});var wla=s(b8e);int=r(wla,"roformer"),wla.forEach(t),dnt=r(fJe," \u2014 "),jae=n(fJe,"A",{href:!0});var Ala=s(jae);cnt=r(Ala,"FlaxRoFormerModel"),Ala.forEach(t),mnt=r(fJe," (RoFormer model)"),fJe.forEach(t),fnt=i(ne),P6=n(ne,"LI",{});var gJe=s(P6);v8e=n(gJe,"STRONG",{});var Lla=s(v8e);gnt=r(Lla,"t5"),Lla.forEach(t),hnt=r(gJe," \u2014 "),Dae=n(gJe,"A",{href:!0});var yla=s(Dae);unt=r(yla,"FlaxT5Model"),yla.forEach(t),pnt=r(gJe," (T5 model)"),gJe.forEach(t),_nt=i(ne),B6=n(ne,"LI",{});var hJe=s(B6);F8e=n(hJe,"STRONG",{});var xla=s(F8e);bnt=r(xla,"vision-text-dual-encoder"),xla.forEach(t),vnt=r(hJe," \u2014 "),Gae=n(hJe,"A",{href:!0});var $la=s(Gae);Fnt=r($la,"FlaxVisionTextDualEncoderModel"),$la.forEach(t),Tnt=r(hJe," (VisionTextDualEncoder model)"),hJe.forEach(t),Mnt=i(ne),I6=n(ne,"LI",{});var uJe=s(I6);T8e=n(uJe,"STRONG",{});var kla=s(T8e);Ent=r(kla,"vit"),kla.forEach(t),Cnt=r(uJe," \u2014 "),Oae=n(uJe,"A",{href:!0});var Sla=s(Oae);wnt=r(Sla,"FlaxViTModel"),Sla.forEach(t),Ant=r(uJe," (ViT model)"),uJe.forEach(t),Lnt=i(ne),N6=n(ne,"LI",{});var pJe=s(N6);M8e=n(pJe,"STRONG",{});var Rla=s(M8e);ynt=r(Rla,"wav2vec2"),Rla.forEach(t),xnt=r(pJe," \u2014 "),Vae=n(pJe,"A",{href:!0});var Pla=s(Vae);$nt=r(Pla,"FlaxWav2Vec2Model"),Pla.forEach(t),knt=r(pJe," (Wav2Vec2 model)"),pJe.forEach(t),Snt=i(ne),q6=n(ne,"LI",{});var _Je=s(q6);E8e=n(_Je,"STRONG",{});var Bla=s(E8e);Rnt=r(Bla,"xglm"),Bla.forEach(t),Pnt=r(_Je," \u2014 "),Xae=n(_Je,"A",{href:!0});var Ila=s(Xae);Bnt=r(Ila,"FlaxXGLMModel"),Ila.forEach(t),Int=r(_Je," (XGLM model)"),_Je.forEach(t),Nnt=i(ne),j6=n(ne,"LI",{});var bJe=s(j6);C8e=n(bJe,"STRONG",{});var Nla=s(C8e);qnt=r(Nla,"xlm-roberta"),Nla.forEach(t),jnt=r(bJe," \u2014 "),zae=n(bJe,"A",{href:!0});var qla=s(zae);Dnt=r(qla,"FlaxXLMRobertaModel"),qla.forEach(t),Gnt=r(bJe," (XLM-RoBERTa model)"),bJe.forEach(t),ne.forEach(t),Ont=i(Ri),T(D6.$$.fragment,Ri),Ri.forEach(t),Si.forEach(t),jZe=i(m),Dm=n(m,"H2",{class:!0});var oro=s(Dm);G6=n(oro,"A",{id:!0,class:!0,href:!0});var jla=s(G6);w8e=n(jla,"SPAN",{});var Dla=s(w8e);T(oR.$$.fragment,Dla),Dla.forEach(t),jla.forEach(t),Vnt=i(oro),A8e=n(oro,"SPAN",{});var Gla=s(A8e);Xnt=r(Gla,"FlaxAutoModelForCausalLM"),Gla.forEach(t),oro.forEach(t),DZe=i(m),Er=n(m,"DIV",{class:!0});var Pi=s(Er);T(rR.$$.fragment,Pi),znt=i(Pi),Gm=n(Pi,"P",{});var Iie=s(Gm);Qnt=r(Iie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Qae=n(Iie,"A",{href:!0});var Ola=s(Qae);Wnt=r(Ola,"from_pretrained()"),Ola.forEach(t),Unt=r(Iie," class method or the "),Wae=n(Iie,"A",{href:!0});var Vla=s(Wae);Hnt=r(Vla,"from_config()"),Vla.forEach(t),Jnt=r(Iie,` class
method.`),Iie.forEach(t),Ynt=i(Pi),tR=n(Pi,"P",{});var rro=s(tR);Knt=r(rro,"This class cannot be instantiated directly using "),L8e=n(rro,"CODE",{});var Xla=s(L8e);Znt=r(Xla,"__init__()"),Xla.forEach(t),est=r(rro," (throws an error)."),rro.forEach(t),ost=i(Pi),la=n(Pi,"DIV",{class:!0});var r9=s(la);T(aR.$$.fragment,r9),rst=i(r9),y8e=n(r9,"P",{});var zla=s(y8e);tst=r(zla,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),zla.forEach(t),ast=i(r9),Om=n(r9,"P",{});var Nie=s(Om);nst=r(Nie,`Note:
Loading a model from its configuration file does `),x8e=n(Nie,"STRONG",{});var Qla=s(x8e);sst=r(Qla,"not"),Qla.forEach(t),lst=r(Nie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Uae=n(Nie,"A",{href:!0});var Wla=s(Uae);ist=r(Wla,"from_pretrained()"),Wla.forEach(t),dst=r(Nie," to load the model weights."),Nie.forEach(t),cst=i(r9),T(O6.$$.fragment,r9),r9.forEach(t),mst=i(Pi),Zr=n(Pi,"DIV",{class:!0});var Bi=s(Zr);T(nR.$$.fragment,Bi),fst=i(Bi),$8e=n(Bi,"P",{});var Ula=s($8e);gst=r(Ula,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Ula.forEach(t),hst=i(Bi),Gn=n(Bi,"P",{});var t9=s(Gn);ust=r(t9,"The model class to instantiate is selected based on the "),k8e=n(t9,"CODE",{});var Hla=s(k8e);pst=r(Hla,"model_type"),Hla.forEach(t),_st=r(t9,` property of the config object (either
passed as an argument or loaded from `),S8e=n(t9,"CODE",{});var Jla=s(S8e);bst=r(Jla,"pretrained_model_name_or_path"),Jla.forEach(t),vst=r(t9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R8e=n(t9,"CODE",{});var Yla=s(R8e);Fst=r(Yla,"pretrained_model_name_or_path"),Yla.forEach(t),Tst=r(t9,":"),t9.forEach(t),Mst=i(Bi),xe=n(Bi,"UL",{});var qe=s(xe);V6=n(qe,"LI",{});var vJe=s(V6);P8e=n(vJe,"STRONG",{});var Kla=s(P8e);Est=r(Kla,"bart"),Kla.forEach(t),Cst=r(vJe," \u2014 "),Hae=n(vJe,"A",{href:!0});var Zla=s(Hae);wst=r(Zla,"FlaxBartForCausalLM"),Zla.forEach(t),Ast=r(vJe," (BART model)"),vJe.forEach(t),Lst=i(qe),X6=n(qe,"LI",{});var FJe=s(X6);B8e=n(FJe,"STRONG",{});var eia=s(B8e);yst=r(eia,"bert"),eia.forEach(t),xst=r(FJe," \u2014 "),Jae=n(FJe,"A",{href:!0});var oia=s(Jae);$st=r(oia,"FlaxBertForCausalLM"),oia.forEach(t),kst=r(FJe," (BERT model)"),FJe.forEach(t),Sst=i(qe),z6=n(qe,"LI",{});var TJe=s(z6);I8e=n(TJe,"STRONG",{});var ria=s(I8e);Rst=r(ria,"big_bird"),ria.forEach(t),Pst=r(TJe," \u2014 "),Yae=n(TJe,"A",{href:!0});var tia=s(Yae);Bst=r(tia,"FlaxBigBirdForCausalLM"),tia.forEach(t),Ist=r(TJe," (BigBird model)"),TJe.forEach(t),Nst=i(qe),Q6=n(qe,"LI",{});var MJe=s(Q6);N8e=n(MJe,"STRONG",{});var aia=s(N8e);qst=r(aia,"electra"),aia.forEach(t),jst=r(MJe," \u2014 "),Kae=n(MJe,"A",{href:!0});var nia=s(Kae);Dst=r(nia,"FlaxElectraForCausalLM"),nia.forEach(t),Gst=r(MJe," (ELECTRA model)"),MJe.forEach(t),Ost=i(qe),W6=n(qe,"LI",{});var EJe=s(W6);q8e=n(EJe,"STRONG",{});var sia=s(q8e);Vst=r(sia,"gpt2"),sia.forEach(t),Xst=r(EJe," \u2014 "),Zae=n(EJe,"A",{href:!0});var lia=s(Zae);zst=r(lia,"FlaxGPT2LMHeadModel"),lia.forEach(t),Qst=r(EJe," (OpenAI GPT-2 model)"),EJe.forEach(t),Wst=i(qe),U6=n(qe,"LI",{});var CJe=s(U6);j8e=n(CJe,"STRONG",{});var iia=s(j8e);Ust=r(iia,"gpt_neo"),iia.forEach(t),Hst=r(CJe," \u2014 "),ene=n(CJe,"A",{href:!0});var dia=s(ene);Jst=r(dia,"FlaxGPTNeoForCausalLM"),dia.forEach(t),Yst=r(CJe," (GPT Neo model)"),CJe.forEach(t),Kst=i(qe),H6=n(qe,"LI",{});var wJe=s(H6);D8e=n(wJe,"STRONG",{});var cia=s(D8e);Zst=r(cia,"gptj"),cia.forEach(t),elt=r(wJe," \u2014 "),one=n(wJe,"A",{href:!0});var mia=s(one);olt=r(mia,"FlaxGPTJForCausalLM"),mia.forEach(t),rlt=r(wJe," (GPT-J model)"),wJe.forEach(t),tlt=i(qe),J6=n(qe,"LI",{});var AJe=s(J6);G8e=n(AJe,"STRONG",{});var fia=s(G8e);alt=r(fia,"opt"),fia.forEach(t),nlt=r(AJe," \u2014 "),rne=n(AJe,"A",{href:!0});var gia=s(rne);slt=r(gia,"FlaxOPTForCausalLM"),gia.forEach(t),llt=r(AJe," (OPT model)"),AJe.forEach(t),ilt=i(qe),Y6=n(qe,"LI",{});var LJe=s(Y6);O8e=n(LJe,"STRONG",{});var hia=s(O8e);dlt=r(hia,"roberta"),hia.forEach(t),clt=r(LJe," \u2014 "),tne=n(LJe,"A",{href:!0});var uia=s(tne);mlt=r(uia,"FlaxRobertaForCausalLM"),uia.forEach(t),flt=r(LJe," (RoBERTa model)"),LJe.forEach(t),glt=i(qe),K6=n(qe,"LI",{});var yJe=s(K6);V8e=n(yJe,"STRONG",{});var pia=s(V8e);hlt=r(pia,"xglm"),pia.forEach(t),ult=r(yJe," \u2014 "),ane=n(yJe,"A",{href:!0});var _ia=s(ane);plt=r(_ia,"FlaxXGLMForCausalLM"),_ia.forEach(t),_lt=r(yJe," (XGLM model)"),yJe.forEach(t),qe.forEach(t),blt=i(Bi),T(Z6.$$.fragment,Bi),Bi.forEach(t),Pi.forEach(t),GZe=i(m),Vm=n(m,"H2",{class:!0});var tro=s(Vm);e7=n(tro,"A",{id:!0,class:!0,href:!0});var bia=s(e7);X8e=n(bia,"SPAN",{});var via=s(X8e);T(sR.$$.fragment,via),via.forEach(t),bia.forEach(t),vlt=i(tro),z8e=n(tro,"SPAN",{});var Fia=s(z8e);Flt=r(Fia,"FlaxAutoModelForPreTraining"),Fia.forEach(t),tro.forEach(t),OZe=i(m),Cr=n(m,"DIV",{class:!0});var Ii=s(Cr);T(lR.$$.fragment,Ii),Tlt=i(Ii),Xm=n(Ii,"P",{});var qie=s(Xm);Mlt=r(qie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),nne=n(qie,"A",{href:!0});var Tia=s(nne);Elt=r(Tia,"from_pretrained()"),Tia.forEach(t),Clt=r(qie," class method or the "),sne=n(qie,"A",{href:!0});var Mia=s(sne);wlt=r(Mia,"from_config()"),Mia.forEach(t),Alt=r(qie,` class
method.`),qie.forEach(t),Llt=i(Ii),iR=n(Ii,"P",{});var aro=s(iR);ylt=r(aro,"This class cannot be instantiated directly using "),Q8e=n(aro,"CODE",{});var Eia=s(Q8e);xlt=r(Eia,"__init__()"),Eia.forEach(t),$lt=r(aro," (throws an error)."),aro.forEach(t),klt=i(Ii),ia=n(Ii,"DIV",{class:!0});var a9=s(ia);T(dR.$$.fragment,a9),Slt=i(a9),W8e=n(a9,"P",{});var Cia=s(W8e);Rlt=r(Cia,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Cia.forEach(t),Plt=i(a9),zm=n(a9,"P",{});var jie=s(zm);Blt=r(jie,`Note:
Loading a model from its configuration file does `),U8e=n(jie,"STRONG",{});var wia=s(U8e);Ilt=r(wia,"not"),wia.forEach(t),Nlt=r(jie,` load the model weights. It only affects the
model\u2019s configuration. Use `),lne=n(jie,"A",{href:!0});var Aia=s(lne);qlt=r(Aia,"from_pretrained()"),Aia.forEach(t),jlt=r(jie," to load the model weights."),jie.forEach(t),Dlt=i(a9),T(o7.$$.fragment,a9),a9.forEach(t),Glt=i(Ii),et=n(Ii,"DIV",{class:!0});var Ni=s(et);T(cR.$$.fragment,Ni),Olt=i(Ni),H8e=n(Ni,"P",{});var Lia=s(H8e);Vlt=r(Lia,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Lia.forEach(t),Xlt=i(Ni),On=n(Ni,"P",{});var n9=s(On);zlt=r(n9,"The model class to instantiate is selected based on the "),J8e=n(n9,"CODE",{});var yia=s(J8e);Qlt=r(yia,"model_type"),yia.forEach(t),Wlt=r(n9,` property of the config object (either
passed as an argument or loaded from `),Y8e=n(n9,"CODE",{});var xia=s(Y8e);Ult=r(xia,"pretrained_model_name_or_path"),xia.forEach(t),Hlt=r(n9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K8e=n(n9,"CODE",{});var $ia=s(K8e);Jlt=r($ia,"pretrained_model_name_or_path"),$ia.forEach(t),Ylt=r(n9,":"),n9.forEach(t),Klt=i(Ni),Ee=n(Ni,"UL",{});var we=s(Ee);r7=n(we,"LI",{});var xJe=s(r7);Z8e=n(xJe,"STRONG",{});var kia=s(Z8e);Zlt=r(kia,"albert"),kia.forEach(t),eit=r(xJe," \u2014 "),ine=n(xJe,"A",{href:!0});var Sia=s(ine);oit=r(Sia,"FlaxAlbertForPreTraining"),Sia.forEach(t),rit=r(xJe," (ALBERT model)"),xJe.forEach(t),tit=i(we),t7=n(we,"LI",{});var $Je=s(t7);e9e=n($Je,"STRONG",{});var Ria=s(e9e);ait=r(Ria,"bart"),Ria.forEach(t),nit=r($Je," \u2014 "),dne=n($Je,"A",{href:!0});var Pia=s(dne);sit=r(Pia,"FlaxBartForConditionalGeneration"),Pia.forEach(t),lit=r($Je," (BART model)"),$Je.forEach(t),iit=i(we),a7=n(we,"LI",{});var kJe=s(a7);o9e=n(kJe,"STRONG",{});var Bia=s(o9e);dit=r(Bia,"bert"),Bia.forEach(t),cit=r(kJe," \u2014 "),cne=n(kJe,"A",{href:!0});var Iia=s(cne);mit=r(Iia,"FlaxBertForPreTraining"),Iia.forEach(t),fit=r(kJe," (BERT model)"),kJe.forEach(t),git=i(we),n7=n(we,"LI",{});var SJe=s(n7);r9e=n(SJe,"STRONG",{});var Nia=s(r9e);hit=r(Nia,"big_bird"),Nia.forEach(t),uit=r(SJe," \u2014 "),mne=n(SJe,"A",{href:!0});var qia=s(mne);pit=r(qia,"FlaxBigBirdForPreTraining"),qia.forEach(t),_it=r(SJe," (BigBird model)"),SJe.forEach(t),bit=i(we),s7=n(we,"LI",{});var RJe=s(s7);t9e=n(RJe,"STRONG",{});var jia=s(t9e);vit=r(jia,"electra"),jia.forEach(t),Fit=r(RJe," \u2014 "),fne=n(RJe,"A",{href:!0});var Dia=s(fne);Tit=r(Dia,"FlaxElectraForPreTraining"),Dia.forEach(t),Mit=r(RJe," (ELECTRA model)"),RJe.forEach(t),Eit=i(we),l7=n(we,"LI",{});var PJe=s(l7);a9e=n(PJe,"STRONG",{});var Gia=s(a9e);Cit=r(Gia,"longt5"),Gia.forEach(t),wit=r(PJe," \u2014 "),gne=n(PJe,"A",{href:!0});var Oia=s(gne);Ait=r(Oia,"FlaxLongT5ForConditionalGeneration"),Oia.forEach(t),Lit=r(PJe," (LongT5 model)"),PJe.forEach(t),yit=i(we),i7=n(we,"LI",{});var BJe=s(i7);n9e=n(BJe,"STRONG",{});var Via=s(n9e);xit=r(Via,"mbart"),Via.forEach(t),$it=r(BJe," \u2014 "),hne=n(BJe,"A",{href:!0});var Xia=s(hne);kit=r(Xia,"FlaxMBartForConditionalGeneration"),Xia.forEach(t),Sit=r(BJe," (mBART model)"),BJe.forEach(t),Rit=i(we),d7=n(we,"LI",{});var IJe=s(d7);s9e=n(IJe,"STRONG",{});var zia=s(s9e);Pit=r(zia,"mt5"),zia.forEach(t),Bit=r(IJe," \u2014 "),une=n(IJe,"A",{href:!0});var Qia=s(une);Iit=r(Qia,"FlaxMT5ForConditionalGeneration"),Qia.forEach(t),Nit=r(IJe," (MT5 model)"),IJe.forEach(t),qit=i(we),c7=n(we,"LI",{});var NJe=s(c7);l9e=n(NJe,"STRONG",{});var Wia=s(l9e);jit=r(Wia,"roberta"),Wia.forEach(t),Dit=r(NJe," \u2014 "),pne=n(NJe,"A",{href:!0});var Uia=s(pne);Git=r(Uia,"FlaxRobertaForMaskedLM"),Uia.forEach(t),Oit=r(NJe," (RoBERTa model)"),NJe.forEach(t),Vit=i(we),m7=n(we,"LI",{});var qJe=s(m7);i9e=n(qJe,"STRONG",{});var Hia=s(i9e);Xit=r(Hia,"roformer"),Hia.forEach(t),zit=r(qJe," \u2014 "),_ne=n(qJe,"A",{href:!0});var Jia=s(_ne);Qit=r(Jia,"FlaxRoFormerForMaskedLM"),Jia.forEach(t),Wit=r(qJe," (RoFormer model)"),qJe.forEach(t),Uit=i(we),f7=n(we,"LI",{});var jJe=s(f7);d9e=n(jJe,"STRONG",{});var Yia=s(d9e);Hit=r(Yia,"t5"),Yia.forEach(t),Jit=r(jJe," \u2014 "),bne=n(jJe,"A",{href:!0});var Kia=s(bne);Yit=r(Kia,"FlaxT5ForConditionalGeneration"),Kia.forEach(t),Kit=r(jJe," (T5 model)"),jJe.forEach(t),Zit=i(we),g7=n(we,"LI",{});var DJe=s(g7);c9e=n(DJe,"STRONG",{});var Zia=s(c9e);edt=r(Zia,"wav2vec2"),Zia.forEach(t),odt=r(DJe," \u2014 "),vne=n(DJe,"A",{href:!0});var eda=s(vne);rdt=r(eda,"FlaxWav2Vec2ForPreTraining"),eda.forEach(t),tdt=r(DJe," (Wav2Vec2 model)"),DJe.forEach(t),adt=i(we),h7=n(we,"LI",{});var GJe=s(h7);m9e=n(GJe,"STRONG",{});var oda=s(m9e);ndt=r(oda,"xlm-roberta"),oda.forEach(t),sdt=r(GJe," \u2014 "),Fne=n(GJe,"A",{href:!0});var rda=s(Fne);ldt=r(rda,"FlaxXLMRobertaForMaskedLM"),rda.forEach(t),idt=r(GJe," (XLM-RoBERTa model)"),GJe.forEach(t),we.forEach(t),ddt=i(Ni),T(u7.$$.fragment,Ni),Ni.forEach(t),Ii.forEach(t),VZe=i(m),Qm=n(m,"H2",{class:!0});var nro=s(Qm);p7=n(nro,"A",{id:!0,class:!0,href:!0});var tda=s(p7);f9e=n(tda,"SPAN",{});var ada=s(f9e);T(mR.$$.fragment,ada),ada.forEach(t),tda.forEach(t),cdt=i(nro),g9e=n(nro,"SPAN",{});var nda=s(g9e);mdt=r(nda,"FlaxAutoModelForMaskedLM"),nda.forEach(t),nro.forEach(t),XZe=i(m),wr=n(m,"DIV",{class:!0});var qi=s(wr);T(fR.$$.fragment,qi),fdt=i(qi),Wm=n(qi,"P",{});var Die=s(Wm);gdt=r(Die,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Tne=n(Die,"A",{href:!0});var sda=s(Tne);hdt=r(sda,"from_pretrained()"),sda.forEach(t),udt=r(Die," class method or the "),Mne=n(Die,"A",{href:!0});var lda=s(Mne);pdt=r(lda,"from_config()"),lda.forEach(t),_dt=r(Die,` class
method.`),Die.forEach(t),bdt=i(qi),gR=n(qi,"P",{});var sro=s(gR);vdt=r(sro,"This class cannot be instantiated directly using "),h9e=n(sro,"CODE",{});var ida=s(h9e);Fdt=r(ida,"__init__()"),ida.forEach(t),Tdt=r(sro," (throws an error)."),sro.forEach(t),Mdt=i(qi),da=n(qi,"DIV",{class:!0});var s9=s(da);T(hR.$$.fragment,s9),Edt=i(s9),u9e=n(s9,"P",{});var dda=s(u9e);Cdt=r(dda,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),dda.forEach(t),wdt=i(s9),Um=n(s9,"P",{});var Gie=s(Um);Adt=r(Gie,`Note:
Loading a model from its configuration file does `),p9e=n(Gie,"STRONG",{});var cda=s(p9e);Ldt=r(cda,"not"),cda.forEach(t),ydt=r(Gie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ene=n(Gie,"A",{href:!0});var mda=s(Ene);xdt=r(mda,"from_pretrained()"),mda.forEach(t),$dt=r(Gie," to load the model weights."),Gie.forEach(t),kdt=i(s9),T(_7.$$.fragment,s9),s9.forEach(t),Sdt=i(qi),ot=n(qi,"DIV",{class:!0});var ji=s(ot);T(uR.$$.fragment,ji),Rdt=i(ji),_9e=n(ji,"P",{});var fda=s(_9e);Pdt=r(fda,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),fda.forEach(t),Bdt=i(ji),Vn=n(ji,"P",{});var l9=s(Vn);Idt=r(l9,"The model class to instantiate is selected based on the "),b9e=n(l9,"CODE",{});var gda=s(b9e);Ndt=r(gda,"model_type"),gda.forEach(t),qdt=r(l9,` property of the config object (either
passed as an argument or loaded from `),v9e=n(l9,"CODE",{});var hda=s(v9e);jdt=r(hda,"pretrained_model_name_or_path"),hda.forEach(t),Ddt=r(l9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F9e=n(l9,"CODE",{});var uda=s(F9e);Gdt=r(uda,"pretrained_model_name_or_path"),uda.forEach(t),Odt=r(l9,":"),l9.forEach(t),Vdt=i(ji),$e=n(ji,"UL",{});var je=s($e);b7=n(je,"LI",{});var OJe=s(b7);T9e=n(OJe,"STRONG",{});var pda=s(T9e);Xdt=r(pda,"albert"),pda.forEach(t),zdt=r(OJe," \u2014 "),Cne=n(OJe,"A",{href:!0});var _da=s(Cne);Qdt=r(_da,"FlaxAlbertForMaskedLM"),_da.forEach(t),Wdt=r(OJe," (ALBERT model)"),OJe.forEach(t),Udt=i(je),v7=n(je,"LI",{});var VJe=s(v7);M9e=n(VJe,"STRONG",{});var bda=s(M9e);Hdt=r(bda,"bart"),bda.forEach(t),Jdt=r(VJe," \u2014 "),wne=n(VJe,"A",{href:!0});var vda=s(wne);Ydt=r(vda,"FlaxBartForConditionalGeneration"),vda.forEach(t),Kdt=r(VJe," (BART model)"),VJe.forEach(t),Zdt=i(je),F7=n(je,"LI",{});var XJe=s(F7);E9e=n(XJe,"STRONG",{});var Fda=s(E9e);ect=r(Fda,"bert"),Fda.forEach(t),oct=r(XJe," \u2014 "),Ane=n(XJe,"A",{href:!0});var Tda=s(Ane);rct=r(Tda,"FlaxBertForMaskedLM"),Tda.forEach(t),tct=r(XJe," (BERT model)"),XJe.forEach(t),act=i(je),T7=n(je,"LI",{});var zJe=s(T7);C9e=n(zJe,"STRONG",{});var Mda=s(C9e);nct=r(Mda,"big_bird"),Mda.forEach(t),sct=r(zJe," \u2014 "),Lne=n(zJe,"A",{href:!0});var Eda=s(Lne);lct=r(Eda,"FlaxBigBirdForMaskedLM"),Eda.forEach(t),ict=r(zJe," (BigBird model)"),zJe.forEach(t),dct=i(je),M7=n(je,"LI",{});var QJe=s(M7);w9e=n(QJe,"STRONG",{});var Cda=s(w9e);cct=r(Cda,"distilbert"),Cda.forEach(t),mct=r(QJe," \u2014 "),yne=n(QJe,"A",{href:!0});var wda=s(yne);fct=r(wda,"FlaxDistilBertForMaskedLM"),wda.forEach(t),gct=r(QJe," (DistilBERT model)"),QJe.forEach(t),hct=i(je),E7=n(je,"LI",{});var WJe=s(E7);A9e=n(WJe,"STRONG",{});var Ada=s(A9e);uct=r(Ada,"electra"),Ada.forEach(t),pct=r(WJe," \u2014 "),xne=n(WJe,"A",{href:!0});var Lda=s(xne);_ct=r(Lda,"FlaxElectraForMaskedLM"),Lda.forEach(t),bct=r(WJe," (ELECTRA model)"),WJe.forEach(t),vct=i(je),C7=n(je,"LI",{});var UJe=s(C7);L9e=n(UJe,"STRONG",{});var yda=s(L9e);Fct=r(yda,"mbart"),yda.forEach(t),Tct=r(UJe," \u2014 "),$ne=n(UJe,"A",{href:!0});var xda=s($ne);Mct=r(xda,"FlaxMBartForConditionalGeneration"),xda.forEach(t),Ect=r(UJe," (mBART model)"),UJe.forEach(t),Cct=i(je),w7=n(je,"LI",{});var HJe=s(w7);y9e=n(HJe,"STRONG",{});var $da=s(y9e);wct=r($da,"roberta"),$da.forEach(t),Act=r(HJe," \u2014 "),kne=n(HJe,"A",{href:!0});var kda=s(kne);Lct=r(kda,"FlaxRobertaForMaskedLM"),kda.forEach(t),yct=r(HJe," (RoBERTa model)"),HJe.forEach(t),xct=i(je),A7=n(je,"LI",{});var JJe=s(A7);x9e=n(JJe,"STRONG",{});var Sda=s(x9e);$ct=r(Sda,"roformer"),Sda.forEach(t),kct=r(JJe," \u2014 "),Sne=n(JJe,"A",{href:!0});var Rda=s(Sne);Sct=r(Rda,"FlaxRoFormerForMaskedLM"),Rda.forEach(t),Rct=r(JJe," (RoFormer model)"),JJe.forEach(t),Pct=i(je),L7=n(je,"LI",{});var YJe=s(L7);$9e=n(YJe,"STRONG",{});var Pda=s($9e);Bct=r(Pda,"xlm-roberta"),Pda.forEach(t),Ict=r(YJe," \u2014 "),Rne=n(YJe,"A",{href:!0});var Bda=s(Rne);Nct=r(Bda,"FlaxXLMRobertaForMaskedLM"),Bda.forEach(t),qct=r(YJe," (XLM-RoBERTa model)"),YJe.forEach(t),je.forEach(t),jct=i(ji),T(y7.$$.fragment,ji),ji.forEach(t),qi.forEach(t),zZe=i(m),Hm=n(m,"H2",{class:!0});var lro=s(Hm);x7=n(lro,"A",{id:!0,class:!0,href:!0});var Ida=s(x7);k9e=n(Ida,"SPAN",{});var Nda=s(k9e);T(pR.$$.fragment,Nda),Nda.forEach(t),Ida.forEach(t),Dct=i(lro),S9e=n(lro,"SPAN",{});var qda=s(S9e);Gct=r(qda,"FlaxAutoModelForSeq2SeqLM"),qda.forEach(t),lro.forEach(t),QZe=i(m),Ar=n(m,"DIV",{class:!0});var Di=s(Ar);T(_R.$$.fragment,Di),Oct=i(Di),Jm=n(Di,"P",{});var Oie=s(Jm);Vct=r(Oie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Pne=n(Oie,"A",{href:!0});var jda=s(Pne);Xct=r(jda,"from_pretrained()"),jda.forEach(t),zct=r(Oie," class method or the "),Bne=n(Oie,"A",{href:!0});var Dda=s(Bne);Qct=r(Dda,"from_config()"),Dda.forEach(t),Wct=r(Oie,` class
method.`),Oie.forEach(t),Uct=i(Di),bR=n(Di,"P",{});var iro=s(bR);Hct=r(iro,"This class cannot be instantiated directly using "),R9e=n(iro,"CODE",{});var Gda=s(R9e);Jct=r(Gda,"__init__()"),Gda.forEach(t),Yct=r(iro," (throws an error)."),iro.forEach(t),Kct=i(Di),ca=n(Di,"DIV",{class:!0});var i9=s(ca);T(vR.$$.fragment,i9),Zct=i(i9),P9e=n(i9,"P",{});var Oda=s(P9e);emt=r(Oda,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Oda.forEach(t),omt=i(i9),Ym=n(i9,"P",{});var Vie=s(Ym);rmt=r(Vie,`Note:
Loading a model from its configuration file does `),B9e=n(Vie,"STRONG",{});var Vda=s(B9e);tmt=r(Vda,"not"),Vda.forEach(t),amt=r(Vie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ine=n(Vie,"A",{href:!0});var Xda=s(Ine);nmt=r(Xda,"from_pretrained()"),Xda.forEach(t),smt=r(Vie," to load the model weights."),Vie.forEach(t),lmt=i(i9),T($7.$$.fragment,i9),i9.forEach(t),imt=i(Di),rt=n(Di,"DIV",{class:!0});var Gi=s(rt);T(FR.$$.fragment,Gi),dmt=i(Gi),I9e=n(Gi,"P",{});var zda=s(I9e);cmt=r(zda,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),zda.forEach(t),mmt=i(Gi),Xn=n(Gi,"P",{});var d9=s(Xn);fmt=r(d9,"The model class to instantiate is selected based on the "),N9e=n(d9,"CODE",{});var Qda=s(N9e);gmt=r(Qda,"model_type"),Qda.forEach(t),hmt=r(d9,` property of the config object (either
passed as an argument or loaded from `),q9e=n(d9,"CODE",{});var Wda=s(q9e);umt=r(Wda,"pretrained_model_name_or_path"),Wda.forEach(t),pmt=r(d9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j9e=n(d9,"CODE",{});var Uda=s(j9e);_mt=r(Uda,"pretrained_model_name_or_path"),Uda.forEach(t),bmt=r(d9,":"),d9.forEach(t),vmt=i(Gi),ke=n(Gi,"UL",{});var De=s(ke);k7=n(De,"LI",{});var KJe=s(k7);D9e=n(KJe,"STRONG",{});var Hda=s(D9e);Fmt=r(Hda,"bart"),Hda.forEach(t),Tmt=r(KJe," \u2014 "),Nne=n(KJe,"A",{href:!0});var Jda=s(Nne);Mmt=r(Jda,"FlaxBartForConditionalGeneration"),Jda.forEach(t),Emt=r(KJe," (BART model)"),KJe.forEach(t),Cmt=i(De),S7=n(De,"LI",{});var ZJe=s(S7);G9e=n(ZJe,"STRONG",{});var Yda=s(G9e);wmt=r(Yda,"blenderbot"),Yda.forEach(t),Amt=r(ZJe," \u2014 "),qne=n(ZJe,"A",{href:!0});var Kda=s(qne);Lmt=r(Kda,"FlaxBlenderbotForConditionalGeneration"),Kda.forEach(t),ymt=r(ZJe," (Blenderbot model)"),ZJe.forEach(t),xmt=i(De),R7=n(De,"LI",{});var eYe=s(R7);O9e=n(eYe,"STRONG",{});var Zda=s(O9e);$mt=r(Zda,"blenderbot-small"),Zda.forEach(t),kmt=r(eYe," \u2014 "),jne=n(eYe,"A",{href:!0});var eca=s(jne);Smt=r(eca,"FlaxBlenderbotSmallForConditionalGeneration"),eca.forEach(t),Rmt=r(eYe," (BlenderbotSmall model)"),eYe.forEach(t),Pmt=i(De),P7=n(De,"LI",{});var oYe=s(P7);V9e=n(oYe,"STRONG",{});var oca=s(V9e);Bmt=r(oca,"encoder-decoder"),oca.forEach(t),Imt=r(oYe," \u2014 "),Dne=n(oYe,"A",{href:!0});var rca=s(Dne);Nmt=r(rca,"FlaxEncoderDecoderModel"),rca.forEach(t),qmt=r(oYe," (Encoder decoder model)"),oYe.forEach(t),jmt=i(De),B7=n(De,"LI",{});var rYe=s(B7);X9e=n(rYe,"STRONG",{});var tca=s(X9e);Dmt=r(tca,"longt5"),tca.forEach(t),Gmt=r(rYe," \u2014 "),Gne=n(rYe,"A",{href:!0});var aca=s(Gne);Omt=r(aca,"FlaxLongT5ForConditionalGeneration"),aca.forEach(t),Vmt=r(rYe," (LongT5 model)"),rYe.forEach(t),Xmt=i(De),I7=n(De,"LI",{});var tYe=s(I7);z9e=n(tYe,"STRONG",{});var nca=s(z9e);zmt=r(nca,"marian"),nca.forEach(t),Qmt=r(tYe," \u2014 "),One=n(tYe,"A",{href:!0});var sca=s(One);Wmt=r(sca,"FlaxMarianMTModel"),sca.forEach(t),Umt=r(tYe," (Marian model)"),tYe.forEach(t),Hmt=i(De),N7=n(De,"LI",{});var aYe=s(N7);Q9e=n(aYe,"STRONG",{});var lca=s(Q9e);Jmt=r(lca,"mbart"),lca.forEach(t),Ymt=r(aYe," \u2014 "),Vne=n(aYe,"A",{href:!0});var ica=s(Vne);Kmt=r(ica,"FlaxMBartForConditionalGeneration"),ica.forEach(t),Zmt=r(aYe," (mBART model)"),aYe.forEach(t),eft=i(De),q7=n(De,"LI",{});var nYe=s(q7);W9e=n(nYe,"STRONG",{});var dca=s(W9e);oft=r(dca,"mt5"),dca.forEach(t),rft=r(nYe," \u2014 "),Xne=n(nYe,"A",{href:!0});var cca=s(Xne);tft=r(cca,"FlaxMT5ForConditionalGeneration"),cca.forEach(t),aft=r(nYe," (MT5 model)"),nYe.forEach(t),nft=i(De),j7=n(De,"LI",{});var sYe=s(j7);U9e=n(sYe,"STRONG",{});var mca=s(U9e);sft=r(mca,"pegasus"),mca.forEach(t),lft=r(sYe," \u2014 "),zne=n(sYe,"A",{href:!0});var fca=s(zne);ift=r(fca,"FlaxPegasusForConditionalGeneration"),fca.forEach(t),dft=r(sYe," (Pegasus model)"),sYe.forEach(t),cft=i(De),D7=n(De,"LI",{});var lYe=s(D7);H9e=n(lYe,"STRONG",{});var gca=s(H9e);mft=r(gca,"t5"),gca.forEach(t),fft=r(lYe," \u2014 "),Qne=n(lYe,"A",{href:!0});var hca=s(Qne);gft=r(hca,"FlaxT5ForConditionalGeneration"),hca.forEach(t),hft=r(lYe," (T5 model)"),lYe.forEach(t),De.forEach(t),uft=i(Gi),T(G7.$$.fragment,Gi),Gi.forEach(t),Di.forEach(t),WZe=i(m),Km=n(m,"H2",{class:!0});var dro=s(Km);O7=n(dro,"A",{id:!0,class:!0,href:!0});var uca=s(O7);J9e=n(uca,"SPAN",{});var pca=s(J9e);T(TR.$$.fragment,pca),pca.forEach(t),uca.forEach(t),pft=i(dro),Y9e=n(dro,"SPAN",{});var _ca=s(Y9e);_ft=r(_ca,"FlaxAutoModelForSequenceClassification"),_ca.forEach(t),dro.forEach(t),UZe=i(m),Lr=n(m,"DIV",{class:!0});var Oi=s(Lr);T(MR.$$.fragment,Oi),bft=i(Oi),Zm=n(Oi,"P",{});var Xie=s(Zm);vft=r(Xie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Wne=n(Xie,"A",{href:!0});var bca=s(Wne);Fft=r(bca,"from_pretrained()"),bca.forEach(t),Tft=r(Xie," class method or the "),Une=n(Xie,"A",{href:!0});var vca=s(Une);Mft=r(vca,"from_config()"),vca.forEach(t),Eft=r(Xie,` class
method.`),Xie.forEach(t),Cft=i(Oi),ER=n(Oi,"P",{});var cro=s(ER);wft=r(cro,"This class cannot be instantiated directly using "),K9e=n(cro,"CODE",{});var Fca=s(K9e);Aft=r(Fca,"__init__()"),Fca.forEach(t),Lft=r(cro," (throws an error)."),cro.forEach(t),yft=i(Oi),ma=n(Oi,"DIV",{class:!0});var c9=s(ma);T(CR.$$.fragment,c9),xft=i(c9),Z9e=n(c9,"P",{});var Tca=s(Z9e);$ft=r(Tca,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Tca.forEach(t),kft=i(c9),ef=n(c9,"P",{});var zie=s(ef);Sft=r(zie,`Note:
Loading a model from its configuration file does `),exe=n(zie,"STRONG",{});var Mca=s(exe);Rft=r(Mca,"not"),Mca.forEach(t),Pft=r(zie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Hne=n(zie,"A",{href:!0});var Eca=s(Hne);Bft=r(Eca,"from_pretrained()"),Eca.forEach(t),Ift=r(zie," to load the model weights."),zie.forEach(t),Nft=i(c9),T(V7.$$.fragment,c9),c9.forEach(t),qft=i(Oi),tt=n(Oi,"DIV",{class:!0});var Vi=s(tt);T(wR.$$.fragment,Vi),jft=i(Vi),oxe=n(Vi,"P",{});var Cca=s(oxe);Dft=r(Cca,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Cca.forEach(t),Gft=i(Vi),zn=n(Vi,"P",{});var m9=s(zn);Oft=r(m9,"The model class to instantiate is selected based on the "),rxe=n(m9,"CODE",{});var wca=s(rxe);Vft=r(wca,"model_type"),wca.forEach(t),Xft=r(m9,` property of the config object (either
passed as an argument or loaded from `),txe=n(m9,"CODE",{});var Aca=s(txe);zft=r(Aca,"pretrained_model_name_or_path"),Aca.forEach(t),Qft=r(m9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),axe=n(m9,"CODE",{});var Lca=s(axe);Wft=r(Lca,"pretrained_model_name_or_path"),Lca.forEach(t),Uft=r(m9,":"),m9.forEach(t),Hft=i(Vi),Se=n(Vi,"UL",{});var Ge=s(Se);X7=n(Ge,"LI",{});var iYe=s(X7);nxe=n(iYe,"STRONG",{});var yca=s(nxe);Jft=r(yca,"albert"),yca.forEach(t),Yft=r(iYe," \u2014 "),Jne=n(iYe,"A",{href:!0});var xca=s(Jne);Kft=r(xca,"FlaxAlbertForSequenceClassification"),xca.forEach(t),Zft=r(iYe," (ALBERT model)"),iYe.forEach(t),egt=i(Ge),z7=n(Ge,"LI",{});var dYe=s(z7);sxe=n(dYe,"STRONG",{});var $ca=s(sxe);ogt=r($ca,"bart"),$ca.forEach(t),rgt=r(dYe," \u2014 "),Yne=n(dYe,"A",{href:!0});var kca=s(Yne);tgt=r(kca,"FlaxBartForSequenceClassification"),kca.forEach(t),agt=r(dYe," (BART model)"),dYe.forEach(t),ngt=i(Ge),Q7=n(Ge,"LI",{});var cYe=s(Q7);lxe=n(cYe,"STRONG",{});var Sca=s(lxe);sgt=r(Sca,"bert"),Sca.forEach(t),lgt=r(cYe," \u2014 "),Kne=n(cYe,"A",{href:!0});var Rca=s(Kne);igt=r(Rca,"FlaxBertForSequenceClassification"),Rca.forEach(t),dgt=r(cYe," (BERT model)"),cYe.forEach(t),cgt=i(Ge),W7=n(Ge,"LI",{});var mYe=s(W7);ixe=n(mYe,"STRONG",{});var Pca=s(ixe);mgt=r(Pca,"big_bird"),Pca.forEach(t),fgt=r(mYe," \u2014 "),Zne=n(mYe,"A",{href:!0});var Bca=s(Zne);ggt=r(Bca,"FlaxBigBirdForSequenceClassification"),Bca.forEach(t),hgt=r(mYe," (BigBird model)"),mYe.forEach(t),ugt=i(Ge),U7=n(Ge,"LI",{});var fYe=s(U7);dxe=n(fYe,"STRONG",{});var Ica=s(dxe);pgt=r(Ica,"distilbert"),Ica.forEach(t),_gt=r(fYe," \u2014 "),ese=n(fYe,"A",{href:!0});var Nca=s(ese);bgt=r(Nca,"FlaxDistilBertForSequenceClassification"),Nca.forEach(t),vgt=r(fYe," (DistilBERT model)"),fYe.forEach(t),Fgt=i(Ge),H7=n(Ge,"LI",{});var gYe=s(H7);cxe=n(gYe,"STRONG",{});var qca=s(cxe);Tgt=r(qca,"electra"),qca.forEach(t),Mgt=r(gYe," \u2014 "),ose=n(gYe,"A",{href:!0});var jca=s(ose);Egt=r(jca,"FlaxElectraForSequenceClassification"),jca.forEach(t),Cgt=r(gYe," (ELECTRA model)"),gYe.forEach(t),wgt=i(Ge),J7=n(Ge,"LI",{});var hYe=s(J7);mxe=n(hYe,"STRONG",{});var Dca=s(mxe);Agt=r(Dca,"mbart"),Dca.forEach(t),Lgt=r(hYe," \u2014 "),rse=n(hYe,"A",{href:!0});var Gca=s(rse);ygt=r(Gca,"FlaxMBartForSequenceClassification"),Gca.forEach(t),xgt=r(hYe," (mBART model)"),hYe.forEach(t),$gt=i(Ge),Y7=n(Ge,"LI",{});var uYe=s(Y7);fxe=n(uYe,"STRONG",{});var Oca=s(fxe);kgt=r(Oca,"roberta"),Oca.forEach(t),Sgt=r(uYe," \u2014 "),tse=n(uYe,"A",{href:!0});var Vca=s(tse);Rgt=r(Vca,"FlaxRobertaForSequenceClassification"),Vca.forEach(t),Pgt=r(uYe," (RoBERTa model)"),uYe.forEach(t),Bgt=i(Ge),K7=n(Ge,"LI",{});var pYe=s(K7);gxe=n(pYe,"STRONG",{});var Xca=s(gxe);Igt=r(Xca,"roformer"),Xca.forEach(t),Ngt=r(pYe," \u2014 "),ase=n(pYe,"A",{href:!0});var zca=s(ase);qgt=r(zca,"FlaxRoFormerForSequenceClassification"),zca.forEach(t),jgt=r(pYe," (RoFormer model)"),pYe.forEach(t),Dgt=i(Ge),Z7=n(Ge,"LI",{});var _Ye=s(Z7);hxe=n(_Ye,"STRONG",{});var Qca=s(hxe);Ggt=r(Qca,"xlm-roberta"),Qca.forEach(t),Ogt=r(_Ye," \u2014 "),nse=n(_Ye,"A",{href:!0});var Wca=s(nse);Vgt=r(Wca,"FlaxXLMRobertaForSequenceClassification"),Wca.forEach(t),Xgt=r(_Ye," (XLM-RoBERTa model)"),_Ye.forEach(t),Ge.forEach(t),zgt=i(Vi),T(eL.$$.fragment,Vi),Vi.forEach(t),Oi.forEach(t),HZe=i(m),of=n(m,"H2",{class:!0});var mro=s(of);oL=n(mro,"A",{id:!0,class:!0,href:!0});var Uca=s(oL);uxe=n(Uca,"SPAN",{});var Hca=s(uxe);T(AR.$$.fragment,Hca),Hca.forEach(t),Uca.forEach(t),Qgt=i(mro),pxe=n(mro,"SPAN",{});var Jca=s(pxe);Wgt=r(Jca,"FlaxAutoModelForQuestionAnswering"),Jca.forEach(t),mro.forEach(t),JZe=i(m),yr=n(m,"DIV",{class:!0});var Xi=s(yr);T(LR.$$.fragment,Xi),Ugt=i(Xi),rf=n(Xi,"P",{});var Qie=s(rf);Hgt=r(Qie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),sse=n(Qie,"A",{href:!0});var Yca=s(sse);Jgt=r(Yca,"from_pretrained()"),Yca.forEach(t),Ygt=r(Qie," class method or the "),lse=n(Qie,"A",{href:!0});var Kca=s(lse);Kgt=r(Kca,"from_config()"),Kca.forEach(t),Zgt=r(Qie,` class
method.`),Qie.forEach(t),eht=i(Xi),yR=n(Xi,"P",{});var fro=s(yR);oht=r(fro,"This class cannot be instantiated directly using "),_xe=n(fro,"CODE",{});var Zca=s(_xe);rht=r(Zca,"__init__()"),Zca.forEach(t),tht=r(fro," (throws an error)."),fro.forEach(t),aht=i(Xi),fa=n(Xi,"DIV",{class:!0});var f9=s(fa);T(xR.$$.fragment,f9),nht=i(f9),bxe=n(f9,"P",{});var ema=s(bxe);sht=r(ema,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),ema.forEach(t),lht=i(f9),tf=n(f9,"P",{});var Wie=s(tf);iht=r(Wie,`Note:
Loading a model from its configuration file does `),vxe=n(Wie,"STRONG",{});var oma=s(vxe);dht=r(oma,"not"),oma.forEach(t),cht=r(Wie,` load the model weights. It only affects the
model\u2019s configuration. Use `),ise=n(Wie,"A",{href:!0});var rma=s(ise);mht=r(rma,"from_pretrained()"),rma.forEach(t),fht=r(Wie," to load the model weights."),Wie.forEach(t),ght=i(f9),T(rL.$$.fragment,f9),f9.forEach(t),hht=i(Xi),at=n(Xi,"DIV",{class:!0});var zi=s(at);T($R.$$.fragment,zi),uht=i(zi),Fxe=n(zi,"P",{});var tma=s(Fxe);pht=r(tma,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),tma.forEach(t),_ht=i(zi),Qn=n(zi,"P",{});var g9=s(Qn);bht=r(g9,"The model class to instantiate is selected based on the "),Txe=n(g9,"CODE",{});var ama=s(Txe);vht=r(ama,"model_type"),ama.forEach(t),Fht=r(g9,` property of the config object (either
passed as an argument or loaded from `),Mxe=n(g9,"CODE",{});var nma=s(Mxe);Tht=r(nma,"pretrained_model_name_or_path"),nma.forEach(t),Mht=r(g9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Exe=n(g9,"CODE",{});var sma=s(Exe);Eht=r(sma,"pretrained_model_name_or_path"),sma.forEach(t),Cht=r(g9,":"),g9.forEach(t),wht=i(zi),Re=n(zi,"UL",{});var Oe=s(Re);tL=n(Oe,"LI",{});var bYe=s(tL);Cxe=n(bYe,"STRONG",{});var lma=s(Cxe);Aht=r(lma,"albert"),lma.forEach(t),Lht=r(bYe," \u2014 "),dse=n(bYe,"A",{href:!0});var ima=s(dse);yht=r(ima,"FlaxAlbertForQuestionAnswering"),ima.forEach(t),xht=r(bYe," (ALBERT model)"),bYe.forEach(t),$ht=i(Oe),aL=n(Oe,"LI",{});var vYe=s(aL);wxe=n(vYe,"STRONG",{});var dma=s(wxe);kht=r(dma,"bart"),dma.forEach(t),Sht=r(vYe," \u2014 "),cse=n(vYe,"A",{href:!0});var cma=s(cse);Rht=r(cma,"FlaxBartForQuestionAnswering"),cma.forEach(t),Pht=r(vYe," (BART model)"),vYe.forEach(t),Bht=i(Oe),nL=n(Oe,"LI",{});var FYe=s(nL);Axe=n(FYe,"STRONG",{});var mma=s(Axe);Iht=r(mma,"bert"),mma.forEach(t),Nht=r(FYe," \u2014 "),mse=n(FYe,"A",{href:!0});var fma=s(mse);qht=r(fma,"FlaxBertForQuestionAnswering"),fma.forEach(t),jht=r(FYe," (BERT model)"),FYe.forEach(t),Dht=i(Oe),sL=n(Oe,"LI",{});var TYe=s(sL);Lxe=n(TYe,"STRONG",{});var gma=s(Lxe);Ght=r(gma,"big_bird"),gma.forEach(t),Oht=r(TYe," \u2014 "),fse=n(TYe,"A",{href:!0});var hma=s(fse);Vht=r(hma,"FlaxBigBirdForQuestionAnswering"),hma.forEach(t),Xht=r(TYe," (BigBird model)"),TYe.forEach(t),zht=i(Oe),lL=n(Oe,"LI",{});var MYe=s(lL);yxe=n(MYe,"STRONG",{});var uma=s(yxe);Qht=r(uma,"distilbert"),uma.forEach(t),Wht=r(MYe," \u2014 "),gse=n(MYe,"A",{href:!0});var pma=s(gse);Uht=r(pma,"FlaxDistilBertForQuestionAnswering"),pma.forEach(t),Hht=r(MYe," (DistilBERT model)"),MYe.forEach(t),Jht=i(Oe),iL=n(Oe,"LI",{});var EYe=s(iL);xxe=n(EYe,"STRONG",{});var _ma=s(xxe);Yht=r(_ma,"electra"),_ma.forEach(t),Kht=r(EYe," \u2014 "),hse=n(EYe,"A",{href:!0});var bma=s(hse);Zht=r(bma,"FlaxElectraForQuestionAnswering"),bma.forEach(t),eut=r(EYe," (ELECTRA model)"),EYe.forEach(t),out=i(Oe),dL=n(Oe,"LI",{});var CYe=s(dL);$xe=n(CYe,"STRONG",{});var vma=s($xe);rut=r(vma,"mbart"),vma.forEach(t),tut=r(CYe," \u2014 "),use=n(CYe,"A",{href:!0});var Fma=s(use);aut=r(Fma,"FlaxMBartForQuestionAnswering"),Fma.forEach(t),nut=r(CYe," (mBART model)"),CYe.forEach(t),sut=i(Oe),cL=n(Oe,"LI",{});var wYe=s(cL);kxe=n(wYe,"STRONG",{});var Tma=s(kxe);lut=r(Tma,"roberta"),Tma.forEach(t),iut=r(wYe," \u2014 "),pse=n(wYe,"A",{href:!0});var Mma=s(pse);dut=r(Mma,"FlaxRobertaForQuestionAnswering"),Mma.forEach(t),cut=r(wYe," (RoBERTa model)"),wYe.forEach(t),mut=i(Oe),mL=n(Oe,"LI",{});var AYe=s(mL);Sxe=n(AYe,"STRONG",{});var Ema=s(Sxe);fut=r(Ema,"roformer"),Ema.forEach(t),gut=r(AYe," \u2014 "),_se=n(AYe,"A",{href:!0});var Cma=s(_se);hut=r(Cma,"FlaxRoFormerForQuestionAnswering"),Cma.forEach(t),uut=r(AYe," (RoFormer model)"),AYe.forEach(t),put=i(Oe),fL=n(Oe,"LI",{});var LYe=s(fL);Rxe=n(LYe,"STRONG",{});var wma=s(Rxe);_ut=r(wma,"xlm-roberta"),wma.forEach(t),but=r(LYe," \u2014 "),bse=n(LYe,"A",{href:!0});var Ama=s(bse);vut=r(Ama,"FlaxXLMRobertaForQuestionAnswering"),Ama.forEach(t),Fut=r(LYe," (XLM-RoBERTa model)"),LYe.forEach(t),Oe.forEach(t),Tut=i(zi),T(gL.$$.fragment,zi),zi.forEach(t),Xi.forEach(t),YZe=i(m),af=n(m,"H2",{class:!0});var gro=s(af);hL=n(gro,"A",{id:!0,class:!0,href:!0});var Lma=s(hL);Pxe=n(Lma,"SPAN",{});var yma=s(Pxe);T(kR.$$.fragment,yma),yma.forEach(t),Lma.forEach(t),Mut=i(gro),Bxe=n(gro,"SPAN",{});var xma=s(Bxe);Eut=r(xma,"FlaxAutoModelForTokenClassification"),xma.forEach(t),gro.forEach(t),KZe=i(m),xr=n(m,"DIV",{class:!0});var Qi=s(xr);T(SR.$$.fragment,Qi),Cut=i(Qi),nf=n(Qi,"P",{});var Uie=s(nf);wut=r(Uie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),vse=n(Uie,"A",{href:!0});var $ma=s(vse);Aut=r($ma,"from_pretrained()"),$ma.forEach(t),Lut=r(Uie," class method or the "),Fse=n(Uie,"A",{href:!0});var kma=s(Fse);yut=r(kma,"from_config()"),kma.forEach(t),xut=r(Uie,` class
method.`),Uie.forEach(t),$ut=i(Qi),RR=n(Qi,"P",{});var hro=s(RR);kut=r(hro,"This class cannot be instantiated directly using "),Ixe=n(hro,"CODE",{});var Sma=s(Ixe);Sut=r(Sma,"__init__()"),Sma.forEach(t),Rut=r(hro," (throws an error)."),hro.forEach(t),Put=i(Qi),ga=n(Qi,"DIV",{class:!0});var h9=s(ga);T(PR.$$.fragment,h9),But=i(h9),Nxe=n(h9,"P",{});var Rma=s(Nxe);Iut=r(Rma,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Rma.forEach(t),Nut=i(h9),sf=n(h9,"P",{});var Hie=s(sf);qut=r(Hie,`Note:
Loading a model from its configuration file does `),qxe=n(Hie,"STRONG",{});var Pma=s(qxe);jut=r(Pma,"not"),Pma.forEach(t),Dut=r(Hie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tse=n(Hie,"A",{href:!0});var Bma=s(Tse);Gut=r(Bma,"from_pretrained()"),Bma.forEach(t),Out=r(Hie," to load the model weights."),Hie.forEach(t),Vut=i(h9),T(uL.$$.fragment,h9),h9.forEach(t),Xut=i(Qi),nt=n(Qi,"DIV",{class:!0});var Wi=s(nt);T(BR.$$.fragment,Wi),zut=i(Wi),jxe=n(Wi,"P",{});var Ima=s(jxe);Qut=r(Ima,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Ima.forEach(t),Wut=i(Wi),Wn=n(Wi,"P",{});var u9=s(Wn);Uut=r(u9,"The model class to instantiate is selected based on the "),Dxe=n(u9,"CODE",{});var Nma=s(Dxe);Hut=r(Nma,"model_type"),Nma.forEach(t),Jut=r(u9,` property of the config object (either
passed as an argument or loaded from `),Gxe=n(u9,"CODE",{});var qma=s(Gxe);Yut=r(qma,"pretrained_model_name_or_path"),qma.forEach(t),Kut=r(u9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Oxe=n(u9,"CODE",{});var jma=s(Oxe);Zut=r(jma,"pretrained_model_name_or_path"),jma.forEach(t),ept=r(u9,":"),u9.forEach(t),opt=i(Wi),Xe=n(Wi,"UL",{});var Ao=s(Xe);pL=n(Ao,"LI",{});var yYe=s(pL);Vxe=n(yYe,"STRONG",{});var Dma=s(Vxe);rpt=r(Dma,"albert"),Dma.forEach(t),tpt=r(yYe," \u2014 "),Mse=n(yYe,"A",{href:!0});var Gma=s(Mse);apt=r(Gma,"FlaxAlbertForTokenClassification"),Gma.forEach(t),npt=r(yYe," (ALBERT model)"),yYe.forEach(t),spt=i(Ao),_L=n(Ao,"LI",{});var xYe=s(_L);Xxe=n(xYe,"STRONG",{});var Oma=s(Xxe);lpt=r(Oma,"bert"),Oma.forEach(t),ipt=r(xYe," \u2014 "),Ese=n(xYe,"A",{href:!0});var Vma=s(Ese);dpt=r(Vma,"FlaxBertForTokenClassification"),Vma.forEach(t),cpt=r(xYe," (BERT model)"),xYe.forEach(t),mpt=i(Ao),bL=n(Ao,"LI",{});var $Ye=s(bL);zxe=n($Ye,"STRONG",{});var Xma=s(zxe);fpt=r(Xma,"big_bird"),Xma.forEach(t),gpt=r($Ye," \u2014 "),Cse=n($Ye,"A",{href:!0});var zma=s(Cse);hpt=r(zma,"FlaxBigBirdForTokenClassification"),zma.forEach(t),upt=r($Ye," (BigBird model)"),$Ye.forEach(t),ppt=i(Ao),vL=n(Ao,"LI",{});var kYe=s(vL);Qxe=n(kYe,"STRONG",{});var Qma=s(Qxe);_pt=r(Qma,"distilbert"),Qma.forEach(t),bpt=r(kYe," \u2014 "),wse=n(kYe,"A",{href:!0});var Wma=s(wse);vpt=r(Wma,"FlaxDistilBertForTokenClassification"),Wma.forEach(t),Fpt=r(kYe," (DistilBERT model)"),kYe.forEach(t),Tpt=i(Ao),FL=n(Ao,"LI",{});var SYe=s(FL);Wxe=n(SYe,"STRONG",{});var Uma=s(Wxe);Mpt=r(Uma,"electra"),Uma.forEach(t),Ept=r(SYe," \u2014 "),Ase=n(SYe,"A",{href:!0});var Hma=s(Ase);Cpt=r(Hma,"FlaxElectraForTokenClassification"),Hma.forEach(t),wpt=r(SYe," (ELECTRA model)"),SYe.forEach(t),Apt=i(Ao),TL=n(Ao,"LI",{});var RYe=s(TL);Uxe=n(RYe,"STRONG",{});var Jma=s(Uxe);Lpt=r(Jma,"roberta"),Jma.forEach(t),ypt=r(RYe," \u2014 "),Lse=n(RYe,"A",{href:!0});var Yma=s(Lse);xpt=r(Yma,"FlaxRobertaForTokenClassification"),Yma.forEach(t),$pt=r(RYe," (RoBERTa model)"),RYe.forEach(t),kpt=i(Ao),ML=n(Ao,"LI",{});var PYe=s(ML);Hxe=n(PYe,"STRONG",{});var Kma=s(Hxe);Spt=r(Kma,"roformer"),Kma.forEach(t),Rpt=r(PYe," \u2014 "),yse=n(PYe,"A",{href:!0});var Zma=s(yse);Ppt=r(Zma,"FlaxRoFormerForTokenClassification"),Zma.forEach(t),Bpt=r(PYe," (RoFormer model)"),PYe.forEach(t),Ipt=i(Ao),EL=n(Ao,"LI",{});var BYe=s(EL);Jxe=n(BYe,"STRONG",{});var efa=s(Jxe);Npt=r(efa,"xlm-roberta"),efa.forEach(t),qpt=r(BYe," \u2014 "),xse=n(BYe,"A",{href:!0});var ofa=s(xse);jpt=r(ofa,"FlaxXLMRobertaForTokenClassification"),ofa.forEach(t),Dpt=r(BYe," (XLM-RoBERTa model)"),BYe.forEach(t),Ao.forEach(t),Gpt=i(Wi),T(CL.$$.fragment,Wi),Wi.forEach(t),Qi.forEach(t),ZZe=i(m),lf=n(m,"H2",{class:!0});var uro=s(lf);wL=n(uro,"A",{id:!0,class:!0,href:!0});var rfa=s(wL);Yxe=n(rfa,"SPAN",{});var tfa=s(Yxe);T(IR.$$.fragment,tfa),tfa.forEach(t),rfa.forEach(t),Opt=i(uro),Kxe=n(uro,"SPAN",{});var afa=s(Kxe);Vpt=r(afa,"FlaxAutoModelForMultipleChoice"),afa.forEach(t),uro.forEach(t),eeo=i(m),$r=n(m,"DIV",{class:!0});var Ui=s($r);T(NR.$$.fragment,Ui),Xpt=i(Ui),df=n(Ui,"P",{});var Jie=s(df);zpt=r(Jie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),$se=n(Jie,"A",{href:!0});var nfa=s($se);Qpt=r(nfa,"from_pretrained()"),nfa.forEach(t),Wpt=r(Jie," class method or the "),kse=n(Jie,"A",{href:!0});var sfa=s(kse);Upt=r(sfa,"from_config()"),sfa.forEach(t),Hpt=r(Jie,` class
method.`),Jie.forEach(t),Jpt=i(Ui),qR=n(Ui,"P",{});var pro=s(qR);Ypt=r(pro,"This class cannot be instantiated directly using "),Zxe=n(pro,"CODE",{});var lfa=s(Zxe);Kpt=r(lfa,"__init__()"),lfa.forEach(t),Zpt=r(pro," (throws an error)."),pro.forEach(t),e_t=i(Ui),ha=n(Ui,"DIV",{class:!0});var p9=s(ha);T(jR.$$.fragment,p9),o_t=i(p9),e$e=n(p9,"P",{});var ifa=s(e$e);r_t=r(ifa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),ifa.forEach(t),t_t=i(p9),cf=n(p9,"P",{});var Yie=s(cf);a_t=r(Yie,`Note:
Loading a model from its configuration file does `),o$e=n(Yie,"STRONG",{});var dfa=s(o$e);n_t=r(dfa,"not"),dfa.forEach(t),s_t=r(Yie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Sse=n(Yie,"A",{href:!0});var cfa=s(Sse);l_t=r(cfa,"from_pretrained()"),cfa.forEach(t),i_t=r(Yie," to load the model weights."),Yie.forEach(t),d_t=i(p9),T(AL.$$.fragment,p9),p9.forEach(t),c_t=i(Ui),st=n(Ui,"DIV",{class:!0});var Hi=s(st);T(DR.$$.fragment,Hi),m_t=i(Hi),r$e=n(Hi,"P",{});var mfa=s(r$e);f_t=r(mfa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),mfa.forEach(t),g_t=i(Hi),Un=n(Hi,"P",{});var _9=s(Un);h_t=r(_9,"The model class to instantiate is selected based on the "),t$e=n(_9,"CODE",{});var ffa=s(t$e);u_t=r(ffa,"model_type"),ffa.forEach(t),p_t=r(_9,` property of the config object (either
passed as an argument or loaded from `),a$e=n(_9,"CODE",{});var gfa=s(a$e);__t=r(gfa,"pretrained_model_name_or_path"),gfa.forEach(t),b_t=r(_9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n$e=n(_9,"CODE",{});var hfa=s(n$e);v_t=r(hfa,"pretrained_model_name_or_path"),hfa.forEach(t),F_t=r(_9,":"),_9.forEach(t),T_t=i(Hi),ze=n(Hi,"UL",{});var Lo=s(ze);LL=n(Lo,"LI",{});var IYe=s(LL);s$e=n(IYe,"STRONG",{});var ufa=s(s$e);M_t=r(ufa,"albert"),ufa.forEach(t),E_t=r(IYe," \u2014 "),Rse=n(IYe,"A",{href:!0});var pfa=s(Rse);C_t=r(pfa,"FlaxAlbertForMultipleChoice"),pfa.forEach(t),w_t=r(IYe," (ALBERT model)"),IYe.forEach(t),A_t=i(Lo),yL=n(Lo,"LI",{});var NYe=s(yL);l$e=n(NYe,"STRONG",{});var _fa=s(l$e);L_t=r(_fa,"bert"),_fa.forEach(t),y_t=r(NYe," \u2014 "),Pse=n(NYe,"A",{href:!0});var bfa=s(Pse);x_t=r(bfa,"FlaxBertForMultipleChoice"),bfa.forEach(t),$_t=r(NYe," (BERT model)"),NYe.forEach(t),k_t=i(Lo),xL=n(Lo,"LI",{});var qYe=s(xL);i$e=n(qYe,"STRONG",{});var vfa=s(i$e);S_t=r(vfa,"big_bird"),vfa.forEach(t),R_t=r(qYe," \u2014 "),Bse=n(qYe,"A",{href:!0});var Ffa=s(Bse);P_t=r(Ffa,"FlaxBigBirdForMultipleChoice"),Ffa.forEach(t),B_t=r(qYe," (BigBird model)"),qYe.forEach(t),I_t=i(Lo),$L=n(Lo,"LI",{});var jYe=s($L);d$e=n(jYe,"STRONG",{});var Tfa=s(d$e);N_t=r(Tfa,"distilbert"),Tfa.forEach(t),q_t=r(jYe," \u2014 "),Ise=n(jYe,"A",{href:!0});var Mfa=s(Ise);j_t=r(Mfa,"FlaxDistilBertForMultipleChoice"),Mfa.forEach(t),D_t=r(jYe," (DistilBERT model)"),jYe.forEach(t),G_t=i(Lo),kL=n(Lo,"LI",{});var DYe=s(kL);c$e=n(DYe,"STRONG",{});var Efa=s(c$e);O_t=r(Efa,"electra"),Efa.forEach(t),V_t=r(DYe," \u2014 "),Nse=n(DYe,"A",{href:!0});var Cfa=s(Nse);X_t=r(Cfa,"FlaxElectraForMultipleChoice"),Cfa.forEach(t),z_t=r(DYe," (ELECTRA model)"),DYe.forEach(t),Q_t=i(Lo),SL=n(Lo,"LI",{});var GYe=s(SL);m$e=n(GYe,"STRONG",{});var wfa=s(m$e);W_t=r(wfa,"roberta"),wfa.forEach(t),U_t=r(GYe," \u2014 "),qse=n(GYe,"A",{href:!0});var Afa=s(qse);H_t=r(Afa,"FlaxRobertaForMultipleChoice"),Afa.forEach(t),J_t=r(GYe," (RoBERTa model)"),GYe.forEach(t),Y_t=i(Lo),RL=n(Lo,"LI",{});var OYe=s(RL);f$e=n(OYe,"STRONG",{});var Lfa=s(f$e);K_t=r(Lfa,"roformer"),Lfa.forEach(t),Z_t=r(OYe," \u2014 "),jse=n(OYe,"A",{href:!0});var yfa=s(jse);ebt=r(yfa,"FlaxRoFormerForMultipleChoice"),yfa.forEach(t),obt=r(OYe," (RoFormer model)"),OYe.forEach(t),rbt=i(Lo),PL=n(Lo,"LI",{});var VYe=s(PL);g$e=n(VYe,"STRONG",{});var xfa=s(g$e);tbt=r(xfa,"xlm-roberta"),xfa.forEach(t),abt=r(VYe," \u2014 "),Dse=n(VYe,"A",{href:!0});var $fa=s(Dse);nbt=r($fa,"FlaxXLMRobertaForMultipleChoice"),$fa.forEach(t),sbt=r(VYe," (XLM-RoBERTa model)"),VYe.forEach(t),Lo.forEach(t),lbt=i(Hi),T(BL.$$.fragment,Hi),Hi.forEach(t),Ui.forEach(t),oeo=i(m),mf=n(m,"H2",{class:!0});var _ro=s(mf);IL=n(_ro,"A",{id:!0,class:!0,href:!0});var kfa=s(IL);h$e=n(kfa,"SPAN",{});var Sfa=s(h$e);T(GR.$$.fragment,Sfa),Sfa.forEach(t),kfa.forEach(t),ibt=i(_ro),u$e=n(_ro,"SPAN",{});var Rfa=s(u$e);dbt=r(Rfa,"FlaxAutoModelForNextSentencePrediction"),Rfa.forEach(t),_ro.forEach(t),reo=i(m),kr=n(m,"DIV",{class:!0});var Ji=s(kr);T(OR.$$.fragment,Ji),cbt=i(Ji),ff=n(Ji,"P",{});var Kie=s(ff);mbt=r(Kie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Gse=n(Kie,"A",{href:!0});var Pfa=s(Gse);fbt=r(Pfa,"from_pretrained()"),Pfa.forEach(t),gbt=r(Kie," class method or the "),Ose=n(Kie,"A",{href:!0});var Bfa=s(Ose);hbt=r(Bfa,"from_config()"),Bfa.forEach(t),ubt=r(Kie,` class
method.`),Kie.forEach(t),pbt=i(Ji),VR=n(Ji,"P",{});var bro=s(VR);_bt=r(bro,"This class cannot be instantiated directly using "),p$e=n(bro,"CODE",{});var Ifa=s(p$e);bbt=r(Ifa,"__init__()"),Ifa.forEach(t),vbt=r(bro," (throws an error)."),bro.forEach(t),Fbt=i(Ji),ua=n(Ji,"DIV",{class:!0});var b9=s(ua);T(XR.$$.fragment,b9),Tbt=i(b9),_$e=n(b9,"P",{});var Nfa=s(_$e);Mbt=r(Nfa,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Nfa.forEach(t),Ebt=i(b9),gf=n(b9,"P",{});var Zie=s(gf);Cbt=r(Zie,`Note:
Loading a model from its configuration file does `),b$e=n(Zie,"STRONG",{});var qfa=s(b$e);wbt=r(qfa,"not"),qfa.forEach(t),Abt=r(Zie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vse=n(Zie,"A",{href:!0});var jfa=s(Vse);Lbt=r(jfa,"from_pretrained()"),jfa.forEach(t),ybt=r(Zie," to load the model weights."),Zie.forEach(t),xbt=i(b9),T(NL.$$.fragment,b9),b9.forEach(t),$bt=i(Ji),lt=n(Ji,"DIV",{class:!0});var Yi=s(lt);T(zR.$$.fragment,Yi),kbt=i(Yi),v$e=n(Yi,"P",{});var Dfa=s(v$e);Sbt=r(Dfa,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Dfa.forEach(t),Rbt=i(Yi),Hn=n(Yi,"P",{});var v9=s(Hn);Pbt=r(v9,"The model class to instantiate is selected based on the "),F$e=n(v9,"CODE",{});var Gfa=s(F$e);Bbt=r(Gfa,"model_type"),Gfa.forEach(t),Ibt=r(v9,` property of the config object (either
passed as an argument or loaded from `),T$e=n(v9,"CODE",{});var Ofa=s(T$e);Nbt=r(Ofa,"pretrained_model_name_or_path"),Ofa.forEach(t),qbt=r(v9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M$e=n(v9,"CODE",{});var Vfa=s(M$e);jbt=r(Vfa,"pretrained_model_name_or_path"),Vfa.forEach(t),Dbt=r(v9,":"),v9.forEach(t),Gbt=i(Yi),E$e=n(Yi,"UL",{});var Xfa=s(E$e);qL=n(Xfa,"LI",{});var XYe=s(qL);C$e=n(XYe,"STRONG",{});var zfa=s(C$e);Obt=r(zfa,"bert"),zfa.forEach(t),Vbt=r(XYe," \u2014 "),Xse=n(XYe,"A",{href:!0});var Qfa=s(Xse);Xbt=r(Qfa,"FlaxBertForNextSentencePrediction"),Qfa.forEach(t),zbt=r(XYe," (BERT model)"),XYe.forEach(t),Xfa.forEach(t),Qbt=i(Yi),T(jL.$$.fragment,Yi),Yi.forEach(t),Ji.forEach(t),teo=i(m),hf=n(m,"H2",{class:!0});var vro=s(hf);DL=n(vro,"A",{id:!0,class:!0,href:!0});var Wfa=s(DL);w$e=n(Wfa,"SPAN",{});var Ufa=s(w$e);T(QR.$$.fragment,Ufa),Ufa.forEach(t),Wfa.forEach(t),Wbt=i(vro),A$e=n(vro,"SPAN",{});var Hfa=s(A$e);Ubt=r(Hfa,"FlaxAutoModelForImageClassification"),Hfa.forEach(t),vro.forEach(t),aeo=i(m),Sr=n(m,"DIV",{class:!0});var Ki=s(Sr);T(WR.$$.fragment,Ki),Hbt=i(Ki),uf=n(Ki,"P",{});var ede=s(uf);Jbt=r(ede,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),zse=n(ede,"A",{href:!0});var Jfa=s(zse);Ybt=r(Jfa,"from_pretrained()"),Jfa.forEach(t),Kbt=r(ede," class method or the "),Qse=n(ede,"A",{href:!0});var Yfa=s(Qse);Zbt=r(Yfa,"from_config()"),Yfa.forEach(t),e2t=r(ede,` class
method.`),ede.forEach(t),o2t=i(Ki),UR=n(Ki,"P",{});var Fro=s(UR);r2t=r(Fro,"This class cannot be instantiated directly using "),L$e=n(Fro,"CODE",{});var Kfa=s(L$e);t2t=r(Kfa,"__init__()"),Kfa.forEach(t),a2t=r(Fro," (throws an error)."),Fro.forEach(t),n2t=i(Ki),pa=n(Ki,"DIV",{class:!0});var F9=s(pa);T(HR.$$.fragment,F9),s2t=i(F9),y$e=n(F9,"P",{});var Zfa=s(y$e);l2t=r(Zfa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Zfa.forEach(t),i2t=i(F9),pf=n(F9,"P",{});var ode=s(pf);d2t=r(ode,`Note:
Loading a model from its configuration file does `),x$e=n(ode,"STRONG",{});var ega=s(x$e);c2t=r(ega,"not"),ega.forEach(t),m2t=r(ode,` load the model weights. It only affects the
model\u2019s configuration. Use `),Wse=n(ode,"A",{href:!0});var oga=s(Wse);f2t=r(oga,"from_pretrained()"),oga.forEach(t),g2t=r(ode," to load the model weights."),ode.forEach(t),h2t=i(F9),T(GL.$$.fragment,F9),F9.forEach(t),u2t=i(Ki),it=n(Ki,"DIV",{class:!0});var Zi=s(it);T(JR.$$.fragment,Zi),p2t=i(Zi),$$e=n(Zi,"P",{});var rga=s($$e);_2t=r(rga,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),rga.forEach(t),b2t=i(Zi),Jn=n(Zi,"P",{});var T9=s(Jn);v2t=r(T9,"The model class to instantiate is selected based on the "),k$e=n(T9,"CODE",{});var tga=s(k$e);F2t=r(tga,"model_type"),tga.forEach(t),T2t=r(T9,` property of the config object (either
passed as an argument or loaded from `),S$e=n(T9,"CODE",{});var aga=s(S$e);M2t=r(aga,"pretrained_model_name_or_path"),aga.forEach(t),E2t=r(T9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R$e=n(T9,"CODE",{});var nga=s(R$e);C2t=r(nga,"pretrained_model_name_or_path"),nga.forEach(t),w2t=r(T9,":"),T9.forEach(t),A2t=i(Zi),YR=n(Zi,"UL",{});var Tro=s(YR);OL=n(Tro,"LI",{});var zYe=s(OL);P$e=n(zYe,"STRONG",{});var sga=s(P$e);L2t=r(sga,"beit"),sga.forEach(t),y2t=r(zYe," \u2014 "),Use=n(zYe,"A",{href:!0});var lga=s(Use);x2t=r(lga,"FlaxBeitForImageClassification"),lga.forEach(t),$2t=r(zYe," (BEiT model)"),zYe.forEach(t),k2t=i(Tro),VL=n(Tro,"LI",{});var QYe=s(VL);B$e=n(QYe,"STRONG",{});var iga=s(B$e);S2t=r(iga,"vit"),iga.forEach(t),R2t=r(QYe," \u2014 "),Hse=n(QYe,"A",{href:!0});var dga=s(Hse);P2t=r(dga,"FlaxViTForImageClassification"),dga.forEach(t),B2t=r(QYe," (ViT model)"),QYe.forEach(t),Tro.forEach(t),I2t=i(Zi),T(XL.$$.fragment,Zi),Zi.forEach(t),Ki.forEach(t),neo=i(m),_f=n(m,"H2",{class:!0});var Mro=s(_f);zL=n(Mro,"A",{id:!0,class:!0,href:!0});var cga=s(zL);I$e=n(cga,"SPAN",{});var mga=s(I$e);T(KR.$$.fragment,mga),mga.forEach(t),cga.forEach(t),N2t=i(Mro),N$e=n(Mro,"SPAN",{});var fga=s(N$e);q2t=r(fga,"FlaxAutoModelForVision2Seq"),fga.forEach(t),Mro.forEach(t),seo=i(m),Rr=n(m,"DIV",{class:!0});var ed=s(Rr);T(ZR.$$.fragment,ed),j2t=i(ed),bf=n(ed,"P",{});var rde=s(bf);D2t=r(rde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Jse=n(rde,"A",{href:!0});var gga=s(Jse);G2t=r(gga,"from_pretrained()"),gga.forEach(t),O2t=r(rde," class method or the "),Yse=n(rde,"A",{href:!0});var hga=s(Yse);V2t=r(hga,"from_config()"),hga.forEach(t),X2t=r(rde,` class
method.`),rde.forEach(t),z2t=i(ed),eP=n(ed,"P",{});var Ero=s(eP);Q2t=r(Ero,"This class cannot be instantiated directly using "),q$e=n(Ero,"CODE",{});var uga=s(q$e);W2t=r(uga,"__init__()"),uga.forEach(t),U2t=r(Ero," (throws an error)."),Ero.forEach(t),H2t=i(ed),_a=n(ed,"DIV",{class:!0});var M9=s(_a);T(oP.$$.fragment,M9),J2t=i(M9),j$e=n(M9,"P",{});var pga=s(j$e);Y2t=r(pga,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),pga.forEach(t),K2t=i(M9),vf=n(M9,"P",{});var tde=s(vf);Z2t=r(tde,`Note:
Loading a model from its configuration file does `),D$e=n(tde,"STRONG",{});var _ga=s(D$e);e1t=r(_ga,"not"),_ga.forEach(t),o1t=r(tde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kse=n(tde,"A",{href:!0});var bga=s(Kse);r1t=r(bga,"from_pretrained()"),bga.forEach(t),t1t=r(tde," to load the model weights."),tde.forEach(t),a1t=i(M9),T(QL.$$.fragment,M9),M9.forEach(t),n1t=i(ed),dt=n(ed,"DIV",{class:!0});var od=s(dt);T(rP.$$.fragment,od),s1t=i(od),G$e=n(od,"P",{});var vga=s(G$e);l1t=r(vga,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),vga.forEach(t),i1t=i(od),Yn=n(od,"P",{});var E9=s(Yn);d1t=r(E9,"The model class to instantiate is selected based on the "),O$e=n(E9,"CODE",{});var Fga=s(O$e);c1t=r(Fga,"model_type"),Fga.forEach(t),m1t=r(E9,` property of the config object (either
passed as an argument or loaded from `),V$e=n(E9,"CODE",{});var Tga=s(V$e);f1t=r(Tga,"pretrained_model_name_or_path"),Tga.forEach(t),g1t=r(E9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X$e=n(E9,"CODE",{});var Mga=s(X$e);h1t=r(Mga,"pretrained_model_name_or_path"),Mga.forEach(t),u1t=r(E9,":"),E9.forEach(t),p1t=i(od),z$e=n(od,"UL",{});var Ega=s(z$e);WL=n(Ega,"LI",{});var WYe=s(WL);Q$e=n(WYe,"STRONG",{});var Cga=s(Q$e);_1t=r(Cga,"vision-encoder-decoder"),Cga.forEach(t),b1t=r(WYe," \u2014 "),Zse=n(WYe,"A",{href:!0});var wga=s(Zse);v1t=r(wga,"FlaxVisionEncoderDecoderModel"),wga.forEach(t),F1t=r(WYe," (Vision Encoder decoder model)"),WYe.forEach(t),Ega.forEach(t),T1t=i(od),T(UL.$$.fragment,od),od.forEach(t),ed.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(jua)),c(f,"id","auto-classes"),c(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f,"href","#auto-classes"),c(u,"class","relative group"),c(Zn,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),c(os,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),c(rs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),c(id,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),c(Lf,"id","extending-the-auto-classes"),c(Lf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Lf,"href","#extending-the-auto-classes"),c(dd,"class","relative group"),c(xf,"id","transformers.AutoConfig"),c(xf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xf,"href","#transformers.AutoConfig"),c(cd,"class","relative group"),c(PB,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(BB,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),c(IB,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),c(NB,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),c(qB,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),c(jB,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(DB,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),c(GB,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(OB,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(VB,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(XB,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),c(zB,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),c(QB,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),c(WB,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),c(UB,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),c(HB,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),c(JB,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),c(YB,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),c(KB,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),c(ZB,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(eI,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(oI,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(rI,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),c(tI,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(aI,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(nI,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),c(sI,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),c(lI,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),c(iI,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),c(dI,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),c(cI,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),c(mI,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),c(fI,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),c(gI,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(hI,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),c(uI,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),c(pI,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),c(_I,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),c(bI,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),c(vI,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),c(FI,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),c(TI,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),c(MI,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(EI,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(CI,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),c(wI,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),c(AI,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),c(LI,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),c(yI,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(xI,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c($I,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(kI,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(SI,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),c(RI,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),c(PI,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),c(BI,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),c(II,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),c(NI,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),c(qI,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),c(jI,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),c(DI,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(GI,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),c(OI,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),c(VI,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(XI,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(zI,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),c(QI,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),c(WI,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),c(UI,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),c(HI,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),c(JI,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(YI,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(KI,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),c(ZI,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),c(eN,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),c(oN,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),c(rN,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),c(tN,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),c(aN,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(nN,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(sN,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(lN,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),c(iN,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),c(dN,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),c(cN,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),c(mN,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),c(fN,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),c(gN,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),c(hN,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),c(uN,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),c(pN,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),c(_N,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),c(bN,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),c(vN,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(FN,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(TN,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(MN,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),c(EN,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(CN,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),c(wN,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),c(AN,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),c(LN,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),c(yN,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(xN,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c($N,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),c(kN,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(SN,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(RN,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),c(PN,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),c(BN,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),c(IN,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(NN,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(qN,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(jN,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),c(DN,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(GN,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(ON,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(VN,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),c(XN,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),c(zN,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),c(QN,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),c(WN,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(UN,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(HN,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(JN,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),c(YN,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),c(KN,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jh,"id","transformers.AutoTokenizer"),c(Jh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Jh,"href","#transformers.AutoTokenizer"),c(fd,"class","relative group"),c(ZN,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(eq,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(oq,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(rq,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),c(tq,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),c(aq,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),c(nq,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(sq,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(lq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(iq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(dq,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(cq,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(mq,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(fq,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(gq,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(hq,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(uq,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(pq,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(_q,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(bq,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(vq,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(Fq,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(Tq,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),c(Mq,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(Eq,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),c(Cq,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(wq,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(Aq,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),c(Lq,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),c(yq,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(xq,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c($q,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),c(kq,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(Sq,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(Rq,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(Pq,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(Bq,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),c(Iq,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(Nq,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(qq,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(jq,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(Dq,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(Gq,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(Oq,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(Vq,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),c(Xq,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(zq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(Qq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(Wq,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(Uq,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),c(Hq,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(Jq,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(Yq,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),c(Kq,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(Zq,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(ej,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(oj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(rj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(tj,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(aj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(nj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(sj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(lj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(ij,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),c(dj,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(cj,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(mj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(fj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(gj,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(hj,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(uj,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(pj,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(_j,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(bj,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(vj,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(Fj,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(Tj,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),c(Mj,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),c(Ej,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),c(Cj,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(wj,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Tokenizer"),c(Aj,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5TokenizerFast"),c(Lj,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),c(yj,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(xj,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c($j,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(kj,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),c(Sj,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),c(Rj,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(Pj,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(Bj,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(Ij,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(Nj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(qj,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),c(jj,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(Dj,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(Gj,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(Oj,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(Vj,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Tokenizer"),c(Xj,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5TokenizerFast"),c(zj,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),c(Qj,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),c(Wj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(Uj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(Hj,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),c(Jj,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),c(Yj,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(Kj,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Zj,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(eD,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(oD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(rD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(tD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(aD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(nD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(sD,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(lD,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),c(iD,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),c(dD,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(cD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(mD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(fD,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),c(gD,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),c(hD,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),c(uD,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),c(pD,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(_D,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),c(bD,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(vD,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(FD,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(TD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(MD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(ED,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(CD,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(wD,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(AD,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(LD,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),c(yD,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(xD,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c($D,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(kD,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Tokenizer"),c(SD,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5TokenizerFast"),c(RD,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),c(PD,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),c(BD,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(ID,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(ND,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(qD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(jD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(DD,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(GD,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(OD,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(VD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(XD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(zD,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),c(QD,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(WD,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),c(UD,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(HD,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(JD,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(YD,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(KD,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(ZD,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(eG,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(oG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(rG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ku,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Su,"id","transformers.AutoFeatureExtractor"),c(Su,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Su,"href","#transformers.AutoFeatureExtractor"),c(gd,"class","relative group"),c(tG,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(aG,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(nG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(sG,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(lG,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(iG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(dG,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(cG,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(mG,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(fG,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(gG,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),c(hG,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(uG,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(pG,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(_G,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(bG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(vG,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(FG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(TG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(MG,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(EG,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(CG,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(wG,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),c(AG,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),c(LG,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(yG,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(xG,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c($G,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(kG,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(SG,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(RG,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(PG,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(BG,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(IG,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor"),c(NG,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(qG,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(jG,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(DG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(GG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(OG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(VG,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mp,"id","transformers.AutoProcessor"),c(Mp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Mp,"href","#transformers.AutoProcessor"),c(hd,"class","relative group"),c(XG,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(zG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(QG,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutProcessor"),c(WG,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),c(UG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(HG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(JG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(YG,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(KG,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),c(ZG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(eO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(oO,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(rO,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(tO,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),c(aO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(nO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(sO,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),c(lO,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(iO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(dO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(cO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(mO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wp,"id","transformers.AutoModel"),c(Wp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Wp,"href","#transformers.AutoModel"),c(pd,"class","relative group"),c(fO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),c(pO,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),c(_O,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),c(bO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),c(vO,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(FO,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),c(TO,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(MO,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(EO,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(CO,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),c(wO,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),c(AO,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),c(LO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),c(yO,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),c(xO,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),c($O,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),c(kO,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),c(SO,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),c(RO,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(PO,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(BO,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(IO,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),c(NO,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(qO,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(jO,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),c(DO,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),c(GO,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),c(OO,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),c(VO,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),c(XO,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(zO,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),c(QO,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),c(WO,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),c(UO,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),c(HO,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),c(JO,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),c(YO,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),c(KO,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),c(ZO,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),c(eV,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),c(oV,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),c(rV,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(tV,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(aV,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),c(nV,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),c(sV,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),c(lV,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),c(iV,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(dV,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(cV,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(mV,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(fV,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),c(gV,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),c(hV,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),c(uV,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),c(pV,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),c(_V,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),c(bV,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),c(vV,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),c(FV,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),c(TV,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),c(MV,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),c(EV,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(CV,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),c(wV,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),c(AV,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),c(LV,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),c(yV,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),c(xV,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),c($V,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),c(kV,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),c(SV,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(RV,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),c(PV,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),c(BV,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),c(IV,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),c(NV,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),c(qV,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),c(jV,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),c(DV,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(GV,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),c(OV,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),c(VV,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),c(XV,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),c(zV,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),c(QV,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),c(WV,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),c(UV,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),c(HV,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),c(JV,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),c(YV,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),c(KV,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(ZV,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),c(eX,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(oX,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),c(rX,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),c(tX,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),c(aX,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),c(nX,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(sX,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(lX,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),c(iX,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(dX,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),c(cX,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),c(mX,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),c(fX,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(gX,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),c(hX,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),c(uX,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(pX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(_X,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(bX,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),c(vX,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),c(FX,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),c(TX,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),c(MX,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(EX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(CX,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(wX,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),c(AX,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),c(LX,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(i2,"id","transformers.AutoModelForPreTraining"),c(i2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(i2,"href","#transformers.AutoModelForPreTraining"),c(vd,"class","relative group"),c(yX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($X,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kX,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),c(SX,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(RX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),c(PX,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(BX,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),c(IX,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(NX,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(qX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(jX,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(DX,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(GX,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(OX,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),c(VX,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),c(XX,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(zX,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),c(QX,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),c(WX,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(UX,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(HX,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(JX,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(YX,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(KX,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(ZX,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),c(ez,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(oz,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(rz,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(tz,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(az,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(nz,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(sz,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(lz,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),c(iz,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(dz,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(cz,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(mz,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(fz,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(gz,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(hz,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(uz,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(pz,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),c(_z,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(bz,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(vz,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(Fz,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(Tz,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(Mz,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(Ez,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(Cz,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s1,"id","transformers.AutoModelForCausalLM"),c(s1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s1,"href","#transformers.AutoModelForCausalLM"),c(Md,"class","relative group"),c(wz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Az,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Lz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yz,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),c(xz,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),c($z,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(kz,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(Sz,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(Rz,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(Pz,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(Bz,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),c(Iz,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(Nz,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),c(qz,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(jz,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(Dz,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),c(Gz,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),c(Oz,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(Vz,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(Xz,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(zz,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(Qz,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),c(Wz,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),c(Uz,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(Hz,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),c(Jz,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(Yz,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),c(Kz,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(Zz,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(eQ,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(oQ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(rQ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(tQ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(aQ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(nQ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(sQ,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(lQ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(iQ,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(dQ,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(cQ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(mQ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(fQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(gQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(hQ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Y1,"id","transformers.AutoModelForMaskedLM"),c(Y1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y1,"href","#transformers.AutoModelForMaskedLM"),c(wd,"class","relative group"),c(uQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_Q,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bQ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(vQ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(FQ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),c(TQ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(MQ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(EQ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(CQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(wQ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(AQ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(LQ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(yQ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(xQ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),c($Q,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(kQ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(SQ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(RQ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(PQ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(BQ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(IQ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),c(NQ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(qQ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(jQ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(DQ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(GQ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(OQ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(VQ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(XQ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(zQ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(QQ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(WQ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(UQ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(HQ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(JQ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(YQ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(KQ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(ZQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(eW,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(oW,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dv,"id","transformers.AutoModelForSeq2SeqLM"),c(Dv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Dv,"href","#transformers.AutoModelForSeq2SeqLM"),c(yd,"class","relative group"),c(rW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(sW,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(lW,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(iW,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(dW,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(cW,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(mW,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(fW,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(gW,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(hW,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),c(uW,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(pW,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(_W,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(bW,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(vW,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(FW,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),c(TW,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(MW,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(EW,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(CW,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cF,"id","transformers.AutoModelForSequenceClassification"),c(cF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cF,"href","#transformers.AutoModelForSequenceClassification"),c(kd,"class","relative group"),c(wW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yW,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(xW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),c($W,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),c(kW,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(SW,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(RW,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(PW,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(BW,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(IW,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(NW,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(qW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(jW,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(DW,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(GW,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(OW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(VW,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),c(XW,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(zW,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(QW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(WW,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(UW,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(HW,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(JW,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(YW,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(KW,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(ZW,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(eU,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),c(oU,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(rU,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),c(tU,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(aU,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(nU,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(sU,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(lU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),c(iU,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(dU,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(cU,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(mU,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),c(fU,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(gU,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(hU,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(uU,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(pU,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(_U,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(bU,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(vU,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(FU,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(TU,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(MU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(EU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(CU,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(wU,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(AU,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gT,"id","transformers.AutoModelForMultipleChoice"),c(gT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gT,"href","#transformers.AutoModelForMultipleChoice"),c(Pd,"class","relative group"),c(LU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($U,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(kU,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),c(SU,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(RU,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(PU,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(BU,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(IU,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(NU,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(qU,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(jU,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(DU,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),c(GU,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(OU,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(VU,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(XU,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(zU,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(QU,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),c(WU,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(UU,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(HU,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(JU,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(YU,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(KU,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(ZU,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(eH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(oH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(rH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(tH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(aH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(nH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(sH,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(lH,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HT,"id","transformers.AutoModelForNextSentencePrediction"),c(HT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(HT,"href","#transformers.AutoModelForNextSentencePrediction"),c(Nd,"class","relative group"),c(iH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(fH,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),c(gH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(hH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(uH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(pH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(_H,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sM,"id","transformers.AutoModelForTokenClassification"),c(sM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sM,"href","#transformers.AutoModelForTokenClassification"),c(Dd,"class","relative group"),c(bH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(FH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TH,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(MH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),c(EH,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(CH,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(wH,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(AH,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),c(LH,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(yH,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(xH,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c($H,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(kH,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(SH,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(RH,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),c(PH,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(BH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(IH,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(NH,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(qH,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(jH,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(DH,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(GH,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(OH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(VH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),c(XH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(zH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(QH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(WH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(UH,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(HH,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(JH,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(YH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(KH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(ZH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(eJ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(oJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(rJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(tJ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(aJ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UM,"id","transformers.AutoModelForQuestionAnswering"),c(UM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(UM,"href","#transformers.AutoModelForQuestionAnswering"),c(Vd,"class","relative group"),c(nJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(dJ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(cJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(mJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(fJ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(gJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(hJ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(uJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(pJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(_J,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(bJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(vJ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(FJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(TJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),c(MJ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(EJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(CJ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(wJ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(AJ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(LJ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(yJ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(xJ,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),c($J,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(kJ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),c(SJ,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(RJ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(PJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(BJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(IJ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(NJ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),c(qJ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(jJ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(DJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(GJ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(OJ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(VJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(XJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(zJ,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(QJ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(WJ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(UJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(HJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(JJ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(YJ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OE,"id","transformers.AutoModelForTableQuestionAnswering"),c(OE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(OE,"href","#transformers.AutoModelForTableQuestionAnswering"),c(Qd,"class","relative group"),c(KJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oY,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WE,"id","transformers.AutoModelForDocumentQuestionAnswering"),c(WE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(WE,"href","#transformers.AutoModelForDocumentQuestionAnswering"),c(Hd,"class","relative group"),c(rY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nY,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),c(sY,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(lY,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(e4,"id","transformers.AutoModelForImageClassification"),c(e4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(e4,"href","#transformers.AutoModelForImageClassification"),c(Zd,"class","relative group"),c(iY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mY,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),c(fY,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(gY,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),c(hY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(uY,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),c(pY,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(_Y,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(bY,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),c(vY,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(FY,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),c(TY,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(MY,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(EY,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(CY,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(wY,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(AY,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(LY,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(yY,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),c(xY,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),c($Y,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),c(kY,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(b4,"id","transformers.AutoModelForVideoClassification"),c(b4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(b4,"href","#transformers.AutoModelForVideoClassification"),c(rc,"class","relative group"),c(SY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(RY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(PY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BY,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(E4,"id","transformers.AutoModelForVision2Seq"),c(E4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(E4,"href","#transformers.AutoModelForVision2Seq"),c(nc,"class","relative group"),c(IY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jY,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(y4,"id","transformers.AutoModelForVisualQuestionAnswering"),c(y4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y4,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(ic,"class","relative group"),c(DY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VY,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(R4,"id","transformers.AutoModelForAudioClassification"),c(R4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R4,"href","#transformers.AutoModelForAudioClassification"),c(mc,"class","relative group"),c(XY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(UY,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(HY,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(JY,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(YY,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(KY,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(ZY,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(eK,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(oK,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Q4,"id","transformers.AutoModelForAudioFrameClassification"),c(Q4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Q4,"href","#transformers.AutoModelForAudioFrameClassification"),c(hc,"class","relative group"),c(rK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(sK,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(lK,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(iK,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(dK,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oC,"id","transformers.AutoModelForCTC"),c(oC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oC,"href","#transformers.AutoModelForCTC"),c(_c,"class","relative group"),c(cK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(hK,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),c(uK,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),c(pK,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),c(_K,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),c(bK,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(vK,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(FK,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(TK,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(MK,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uC,"id","transformers.AutoModelForSpeechSeq2Seq"),c(uC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uC,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Fc,"class","relative group"),c(EK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AK,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(LK,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TC,"id","transformers.AutoModelForAudioXVector"),c(TC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(TC,"href","#transformers.AutoModelForAudioXVector"),c(Ec,"class","relative group"),c(yK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($K,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(SK,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(RK,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(PK,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(BK,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($C,"id","transformers.AutoModelForMaskedImageModeling"),c($C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($C,"href","#transformers.AutoModelForMaskedImageModeling"),c(Ac,"class","relative group"),c(IK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jK,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(DK,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(GK,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),c(OK,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qC,"id","transformers.AutoModelForObjectDetection"),c(qC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qC,"href","#transformers.AutoModelForObjectDetection"),c(xc,"class","relative group"),c(VK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QK,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),c(WK,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),c(UK,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zC,"id","transformers.AutoModelForImageSegmentation"),c(zC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zC,"href","#transformers.AutoModelForImageSegmentation"),c(Rc,"class","relative group"),c(HK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KK,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),c(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JC,"id","transformers.AutoModelForSemanticSegmentation"),c(JC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(JC,"href","#transformers.AutoModelForSemanticSegmentation"),c(Ic,"class","relative group"),c(ZK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rZ,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(tZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(aZ,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(nZ,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),c(sZ,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n3,"id","transformers.AutoModelForInstanceSegmentation"),c(n3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n3,"href","#transformers.AutoModelForInstanceSegmentation"),c(jc,"class","relative group"),c(lZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cZ,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(c3,"id","transformers.TFAutoModel"),c(c3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(c3,"href","#transformers.TFAutoModel"),c(Oc,"class","relative group"),c(mZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),c(uZ,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),c(pZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),c(_Z,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(bZ,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(vZ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),c(FZ,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),c(TZ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),c(MZ,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),c(EZ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),c(CZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(wZ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),c(AZ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(LZ,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),c(yZ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(xZ,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c($Z,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),c(kZ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(SZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),c(RZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(PZ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),c(BZ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),c(IZ,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),c(NZ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(qZ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),c(jZ,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),c(DZ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),c(GZ,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),c(OZ,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),c(VZ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),c(XZ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(zZ,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),c(QZ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),c(WZ,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),c(UZ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(HZ,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),c(JZ,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),c(YZ,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),c(KZ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),c(ZZ,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),c(eee,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),c(oee,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),c(ree,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),c(tee,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(aee,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),c(nee,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),c(see,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),c(lee,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(iee,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),c(dee,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(cee,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(mee,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),c(fee,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),c(gee,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(hee,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f5,"id","transformers.TFAutoModelForPreTraining"),c(f5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f5,"href","#transformers.TFAutoModelForPreTraining"),c(zc,"class","relative group"),c(uee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_ee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bee,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(vee,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(Fee,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),c(Tee,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(Mee,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(Eee,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(Cee,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(wee,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(Aee,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(Lee,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(yee,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(xee,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c($ee,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(kee,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(See,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(Ree,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(Pee,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Bee,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(Iee,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(Nee,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(qee,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(jee,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Dee,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q5,"id","transformers.TFAutoModelForCausalLM"),c(q5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q5,"href","#transformers.TFAutoModelForCausalLM"),c(Uc,"class","relative group"),c(Gee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Oee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Vee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xee,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(zee,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(Qee,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(Wee,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(Uee,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(Hee,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(Jee,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(Yee,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(Kee,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(Zee,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(eoe,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(ooe,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),c(roe,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(toe,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(o0,"id","transformers.TFAutoModelForImageClassification"),c(o0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(o0,"href","#transformers.TFAutoModelForImageClassification"),c(Yc,"class","relative group"),c(aoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(noe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(soe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(loe,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(ioe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(doe,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),c(coe,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),c(moe,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),c(foe,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),c(goe,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),c(hoe,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),c(uoe,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(poe,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f0,"id","transformers.TFAutoModelForSemanticSegmentation"),c(f0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f0,"href","#transformers.TFAutoModelForSemanticSegmentation"),c(em,"class","relative group"),c(_oe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(boe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(voe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Foe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),c(Toe,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),c(Moe,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(b0,"id","transformers.TFAutoModelForMaskedLM"),c(b0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(b0,"href","#transformers.TFAutoModelForMaskedLM"),c(am,"class","relative group"),c(Eoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Coe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(woe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Aoe,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(Loe,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(yoe,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(xoe,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c($oe,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(koe,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(Soe,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(Roe,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(Poe,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(Boe,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(Ioe,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(Noe,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(qoe,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(joe,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(Doe,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(Goe,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(Ooe,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(Voe,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(Xoe,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(zoe,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(G0,"id","transformers.TFAutoModelForSeq2SeqLM"),c(G0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(G0,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(lm,"class","relative group"),c(Qoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Woe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Uoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hoe,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(Joe,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(Yoe,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(Koe,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(Zoe,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(ere,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),c(ore,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(rre,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(tre,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(are,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ew,"id","transformers.TFAutoModelForSequenceClassification"),c(ew,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ew,"href","#transformers.TFAutoModelForSequenceClassification"),c(cm,"class","relative group"),c(nre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ire,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(dre,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(cre,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(mre,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(fre,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(gre,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(hre,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(ure,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(pre,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(_re,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(bre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(vre,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(Fre,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(Tre,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(Mre,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),c(Ere,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(Cre,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(wre,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(Are,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(Lre,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(yre,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(xre,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c($re,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(kre,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(Sre,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(Rre,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(Pre,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($w,"id","transformers.TFAutoModelForMultipleChoice"),c($w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($w,"href","#transformers.TFAutoModelForMultipleChoice"),c(gm,"class","relative group"),c(Bre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ire,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Nre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qre,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(jre,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(Dre,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(Gre,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(Ore,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(Vre,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(Xre,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(zre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(Qre,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(Wre,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(Ure,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(Hre,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(Jre,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(Yre,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(Kre,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(Zre,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(ete,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jw,"id","transformers.TFAutoModelForNextSentencePrediction"),c(Jw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Jw,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(pm,"class","relative group"),c(ote,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ate,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(nte,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oA,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(oA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oA,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(vm,"class","relative group"),c(ste,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ite,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dte,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nA,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),c(nA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(nA,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),c(Mm,"class","relative group"),c(cte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gte,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dA,"id","transformers.TFAutoModelForTokenClassification"),c(dA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dA,"href","#transformers.TFAutoModelForTokenClassification"),c(wm,"class","relative group"),c(hte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ute,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_te,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(bte,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(vte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(Fte,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(Tte,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(Mte,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(Ete,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(Cte,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(wte,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(Ate,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(Lte,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(yte,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),c(xte,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c($te,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(kte,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(Ste,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(Rte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(Pte,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(Bte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(Ite,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(Nte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RA,"id","transformers.TFAutoModelForQuestionAnswering"),c(RA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(RA,"href","#transformers.TFAutoModelForQuestionAnswering"),c(ym,"class","relative group"),c(qte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Dte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gte,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(Ote,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(Vte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(Xte,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(zte,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(Qte,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(Wte,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(Ute,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(Hte,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(Jte,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(Yte,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(Kte,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),c(Zte,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(eae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(oae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(rae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(tae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(aae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(nae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(sae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(lae,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t6,"id","transformers.TFAutoModelForVision2Seq"),c(t6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t6,"href","#transformers.TFAutoModelForVision2Seq"),c(km,"class","relative group"),c(iae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mae,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l6,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(l6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l6,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(Pm,"class","relative group"),c(fae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uae,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m6,"id","transformers.FlaxAutoModel"),c(m6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m6,"href","#transformers.FlaxAutoModel"),c(Nm,"class","relative group"),c(pae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_ae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vae,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),c(Fae,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),c(Tae,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),c(Mae,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),c(Eae,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(Cae,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(wae,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(Aae,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),c(Lae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(yae,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),c(xae,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c($ae,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(kae,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(Sae,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(Rae,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),c(Pae,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),c(Bae,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),c(Iae,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),c(Nae,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(qae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(jae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(Dae,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),c(Gae,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(Oae,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),c(Vae,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(Xae,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(zae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(G6,"id","transformers.FlaxAutoModelForCausalLM"),c(G6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(G6,"href","#transformers.FlaxAutoModelForCausalLM"),c(Dm,"class","relative group"),c(Qae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Uae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hae,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(Jae,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(Yae,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(Kae,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(Zae,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(ene,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(one,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(rne,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(tne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(ane,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(e7,"id","transformers.FlaxAutoModelForPreTraining"),c(e7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(e7,"href","#transformers.FlaxAutoModelForPreTraining"),c(Vm,"class","relative group"),c(nne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ine,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(dne,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(cne,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(mne,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(fne,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(gne,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(hne,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(une,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(pne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(_ne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(bne,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(vne,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(Fne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p7,"id","transformers.FlaxAutoModelForMaskedLM"),c(p7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p7,"href","#transformers.FlaxAutoModelForMaskedLM"),c(Qm,"class","relative group"),c(Tne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Ene,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cne,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(wne,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Ane,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(Lne,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(yne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(xne,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c($ne,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(kne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(Sne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(Rne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(x7,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(x7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x7,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(Hm,"class","relative group"),c(Pne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Ine,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Nne,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(qne,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(jne,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(Dne,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(Gne,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(One,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(Vne,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Xne,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(zne,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(Qne,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(O7,"id","transformers.FlaxAutoModelForSequenceClassification"),c(O7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(O7,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Km,"class","relative group"),c(Wne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Une,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Hne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jne,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(Yne,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(Kne,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(Zne,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(ese,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(ose,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(rse,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(tse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(ase,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(nse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oL,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(oL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oL,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(of,"class","relative group"),c(sse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ise,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dse,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(cse,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(mse,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(fse,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(gse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(hse,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(use,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(pse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(_se,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(bse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hL,"id","transformers.FlaxAutoModelForTokenClassification"),c(hL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hL,"href","#transformers.FlaxAutoModelForTokenClassification"),c(af,"class","relative group"),c(vse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Fse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Tse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mse,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(Ese,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(Cse,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(wse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(Ase,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(Lse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(yse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(xse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wL,"id","transformers.FlaxAutoModelForMultipleChoice"),c(wL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(wL,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(lf,"class","relative group"),c($se,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Sse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rse,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(Pse,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(Bse,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(Ise,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(Nse,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(qse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(jse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(Dse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IL,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(IL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(IL,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(mf,"class","relative group"),c(Gse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ose,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Vse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xse,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DL,"id","transformers.FlaxAutoModelForImageClassification"),c(DL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DL,"href","#transformers.FlaxAutoModelForImageClassification"),c(hf,"class","relative group"),c(zse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Wse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Use,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(Hse,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zL,"id","transformers.FlaxAutoModelForVision2Seq"),c(zL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zL,"href","#transformers.FlaxAutoModelForVision2Seq"),c(_f,"class","relative group"),c(Jse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Kse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zse,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(m,_){e(document.head,g),b(m,v,_),b(m,u,_),e(u,f),e(f,p),M(d,p,null),e(u,h),e(u,yo),e(yo,rd),b(m,Ef,_),b(m,pt,_),e(pt,td),e(pt,ad),e(ad,C9),e(pt,Cf),b(m,Ve,_),b(m,He,_),e(He,nd),e(He,Zn),e(Zn,w9),e(He,es),e(He,os),e(os,A9),e(He,sd),e(He,rs),e(rs,L9),e(He,ld),b(m,wf,_),M(Qa,m,_),b(m,Je,_),b(m,Ae,_),e(Ae,yB),e(Ae,id),e(id,xB),e(Ae,$B),b(m,xo,_),b(m,Wa,_),e(Wa,kB),e(Wa,Af),e(Af,SB),e(Wa,Cro),b(m,UYe,_),b(m,dd,_),e(dd,Lf),e(Lf,ade),M(y9,ade,null),e(dd,wro),e(dd,nde),e(nde,Aro),b(m,HYe,_),b(m,ts,_),e(ts,Lro),e(ts,sde),e(sde,yro),e(ts,xro),e(ts,lde),e(lde,$ro),e(ts,kro),b(m,JYe,_),M(x9,m,_),b(m,YYe,_),b(m,RB,_),e(RB,Sro),b(m,KYe,_),M(yf,m,_),b(m,ZYe,_),b(m,cd,_),e(cd,xf),e(xf,ide),M($9,ide,null),e(cd,Rro),e(cd,dde),e(dde,Pro),b(m,eKe,_),b(m,$o,_),M(k9,$o,null),e($o,Bro),e($o,S9),e(S9,Iro),e(S9,PB),e(PB,Nro),e(S9,qro),e($o,jro),e($o,R9),e(R9,Dro),e(R9,cde),e(cde,Gro),e(R9,Oro),e($o,Vro),e($o,Pr),M(P9,Pr,null),e(Pr,Xro),e(Pr,mde),e(mde,zro),e(Pr,Qro),e(Pr,md),e(md,Wro),e(md,fde),e(fde,Uro),e(md,Hro),e(md,gde),e(gde,Jro),e(md,Yro),e(Pr,Kro),e(Pr,A),e(A,$f),e($f,hde),e(hde,Zro),e($f,eto),e($f,BB),e(BB,oto),e($f,rto),e(A,tto),e(A,kf),e(kf,ude),e(ude,ato),e(kf,nto),e(kf,IB),e(IB,sto),e(kf,lto),e(A,ito),e(A,Sf),e(Sf,pde),e(pde,dto),e(Sf,cto),e(Sf,NB),e(NB,mto),e(Sf,fto),e(A,gto),e(A,Rf),e(Rf,_de),e(_de,hto),e(Rf,uto),e(Rf,qB),e(qB,pto),e(Rf,_to),e(A,bto),e(A,Pf),e(Pf,bde),e(bde,vto),e(Pf,Fto),e(Pf,jB),e(jB,Tto),e(Pf,Mto),e(A,Eto),e(A,Bf),e(Bf,vde),e(vde,Cto),e(Bf,wto),e(Bf,DB),e(DB,Ato),e(Bf,Lto),e(A,yto),e(A,If),e(If,Fde),e(Fde,xto),e(If,$to),e(If,GB),e(GB,kto),e(If,Sto),e(A,Rto),e(A,Nf),e(Nf,Tde),e(Tde,Pto),e(Nf,Bto),e(Nf,OB),e(OB,Ito),e(Nf,Nto),e(A,qto),e(A,qf),e(qf,Mde),e(Mde,jto),e(qf,Dto),e(qf,VB),e(VB,Gto),e(qf,Oto),e(A,Vto),e(A,jf),e(jf,Ede),e(Ede,Xto),e(jf,zto),e(jf,XB),e(XB,Qto),e(jf,Wto),e(A,Uto),e(A,Df),e(Df,Cde),e(Cde,Hto),e(Df,Jto),e(Df,zB),e(zB,Yto),e(Df,Kto),e(A,Zto),e(A,Gf),e(Gf,wde),e(wde,eao),e(Gf,oao),e(Gf,QB),e(QB,rao),e(Gf,tao),e(A,aao),e(A,Of),e(Of,Ade),e(Ade,nao),e(Of,sao),e(Of,WB),e(WB,lao),e(Of,iao),e(A,dao),e(A,Vf),e(Vf,Lde),e(Lde,cao),e(Vf,mao),e(Vf,UB),e(UB,fao),e(Vf,gao),e(A,hao),e(A,Xf),e(Xf,yde),e(yde,uao),e(Xf,pao),e(Xf,HB),e(HB,_ao),e(Xf,bao),e(A,vao),e(A,zf),e(zf,xde),e(xde,Fao),e(zf,Tao),e(zf,JB),e(JB,Mao),e(zf,Eao),e(A,Cao),e(A,Qf),e(Qf,$de),e($de,wao),e(Qf,Aao),e(Qf,YB),e(YB,Lao),e(Qf,yao),e(A,xao),e(A,Wf),e(Wf,kde),e(kde,$ao),e(Wf,kao),e(Wf,KB),e(KB,Sao),e(Wf,Rao),e(A,Pao),e(A,Uf),e(Uf,Sde),e(Sde,Bao),e(Uf,Iao),e(Uf,ZB),e(ZB,Nao),e(Uf,qao),e(A,jao),e(A,Hf),e(Hf,Rde),e(Rde,Dao),e(Hf,Gao),e(Hf,eI),e(eI,Oao),e(Hf,Vao),e(A,Xao),e(A,Jf),e(Jf,Pde),e(Pde,zao),e(Jf,Qao),e(Jf,oI),e(oI,Wao),e(Jf,Uao),e(A,Hao),e(A,Yf),e(Yf,Bde),e(Bde,Jao),e(Yf,Yao),e(Yf,rI),e(rI,Kao),e(Yf,Zao),e(A,eno),e(A,Kf),e(Kf,Ide),e(Ide,ono),e(Kf,rno),e(Kf,tI),e(tI,tno),e(Kf,ano),e(A,nno),e(A,Zf),e(Zf,Nde),e(Nde,sno),e(Zf,lno),e(Zf,aI),e(aI,ino),e(Zf,dno),e(A,cno),e(A,eg),e(eg,qde),e(qde,mno),e(eg,fno),e(eg,nI),e(nI,gno),e(eg,hno),e(A,uno),e(A,og),e(og,jde),e(jde,pno),e(og,_no),e(og,sI),e(sI,bno),e(og,vno),e(A,Fno),e(A,rg),e(rg,Dde),e(Dde,Tno),e(rg,Mno),e(rg,lI),e(lI,Eno),e(rg,Cno),e(A,wno),e(A,tg),e(tg,Gde),e(Gde,Ano),e(tg,Lno),e(tg,iI),e(iI,yno),e(tg,xno),e(A,$no),e(A,ag),e(ag,Ode),e(Ode,kno),e(ag,Sno),e(ag,dI),e(dI,Rno),e(ag,Pno),e(A,Bno),e(A,ng),e(ng,Vde),e(Vde,Ino),e(ng,Nno),e(ng,cI),e(cI,qno),e(ng,jno),e(A,Dno),e(A,sg),e(sg,Xde),e(Xde,Gno),e(sg,Ono),e(sg,mI),e(mI,Vno),e(sg,Xno),e(A,zno),e(A,lg),e(lg,zde),e(zde,Qno),e(lg,Wno),e(lg,fI),e(fI,Uno),e(lg,Hno),e(A,Jno),e(A,ig),e(ig,Qde),e(Qde,Yno),e(ig,Kno),e(ig,gI),e(gI,Zno),e(ig,eso),e(A,oso),e(A,dg),e(dg,Wde),e(Wde,rso),e(dg,tso),e(dg,hI),e(hI,aso),e(dg,nso),e(A,sso),e(A,cg),e(cg,Ude),e(Ude,lso),e(cg,iso),e(cg,uI),e(uI,dso),e(cg,cso),e(A,mso),e(A,mg),e(mg,Hde),e(Hde,fso),e(mg,gso),e(mg,pI),e(pI,hso),e(mg,uso),e(A,pso),e(A,fg),e(fg,Jde),e(Jde,_so),e(fg,bso),e(fg,_I),e(_I,vso),e(fg,Fso),e(A,Tso),e(A,gg),e(gg,Yde),e(Yde,Mso),e(gg,Eso),e(gg,bI),e(bI,Cso),e(gg,wso),e(A,Aso),e(A,hg),e(hg,Kde),e(Kde,Lso),e(hg,yso),e(hg,vI),e(vI,xso),e(hg,$so),e(A,kso),e(A,ug),e(ug,Zde),e(Zde,Sso),e(ug,Rso),e(ug,FI),e(FI,Pso),e(ug,Bso),e(A,Iso),e(A,pg),e(pg,ece),e(ece,Nso),e(pg,qso),e(pg,TI),e(TI,jso),e(pg,Dso),e(A,Gso),e(A,_g),e(_g,oce),e(oce,Oso),e(_g,Vso),e(_g,MI),e(MI,Xso),e(_g,zso),e(A,Qso),e(A,bg),e(bg,rce),e(rce,Wso),e(bg,Uso),e(bg,EI),e(EI,Hso),e(bg,Jso),e(A,Yso),e(A,vg),e(vg,tce),e(tce,Kso),e(vg,Zso),e(vg,CI),e(CI,elo),e(vg,olo),e(A,rlo),e(A,Fg),e(Fg,ace),e(ace,tlo),e(Fg,alo),e(Fg,wI),e(wI,nlo),e(Fg,slo),e(A,llo),e(A,Tg),e(Tg,nce),e(nce,ilo),e(Tg,dlo),e(Tg,AI),e(AI,clo),e(Tg,mlo),e(A,flo),e(A,Mg),e(Mg,sce),e(sce,glo),e(Mg,hlo),e(Mg,LI),e(LI,ulo),e(Mg,plo),e(A,_lo),e(A,Eg),e(Eg,lce),e(lce,blo),e(Eg,vlo),e(Eg,yI),e(yI,Flo),e(Eg,Tlo),e(A,Mlo),e(A,Cg),e(Cg,ice),e(ice,Elo),e(Cg,Clo),e(Cg,xI),e(xI,wlo),e(Cg,Alo),e(A,Llo),e(A,wg),e(wg,dce),e(dce,ylo),e(wg,xlo),e(wg,$I),e($I,$lo),e(wg,klo),e(A,Slo),e(A,Ag),e(Ag,cce),e(cce,Rlo),e(Ag,Plo),e(Ag,kI),e(kI,Blo),e(Ag,Ilo),e(A,Nlo),e(A,Lg),e(Lg,mce),e(mce,qlo),e(Lg,jlo),e(Lg,SI),e(SI,Dlo),e(Lg,Glo),e(A,Olo),e(A,yg),e(yg,fce),e(fce,Vlo),e(yg,Xlo),e(yg,RI),e(RI,zlo),e(yg,Qlo),e(A,Wlo),e(A,xg),e(xg,gce),e(gce,Ulo),e(xg,Hlo),e(xg,PI),e(PI,Jlo),e(xg,Ylo),e(A,Klo),e(A,$g),e($g,hce),e(hce,Zlo),e($g,eio),e($g,BI),e(BI,oio),e($g,rio),e(A,tio),e(A,kg),e(kg,uce),e(uce,aio),e(kg,nio),e(kg,II),e(II,sio),e(kg,lio),e(A,iio),e(A,Sg),e(Sg,pce),e(pce,dio),e(Sg,cio),e(Sg,NI),e(NI,mio),e(Sg,fio),e(A,gio),e(A,Rg),e(Rg,_ce),e(_ce,hio),e(Rg,uio),e(Rg,qI),e(qI,pio),e(Rg,_io),e(A,bio),e(A,Pg),e(Pg,bce),e(bce,vio),e(Pg,Fio),e(Pg,jI),e(jI,Tio),e(Pg,Mio),e(A,Eio),e(A,Bg),e(Bg,vce),e(vce,Cio),e(Bg,wio),e(Bg,DI),e(DI,Aio),e(Bg,Lio),e(A,yio),e(A,Ig),e(Ig,Fce),e(Fce,xio),e(Ig,$io),e(Ig,GI),e(GI,kio),e(Ig,Sio),e(A,Rio),e(A,Ng),e(Ng,Tce),e(Tce,Pio),e(Ng,Bio),e(Ng,OI),e(OI,Iio),e(Ng,Nio),e(A,qio),e(A,qg),e(qg,Mce),e(Mce,jio),e(qg,Dio),e(qg,VI),e(VI,Gio),e(qg,Oio),e(A,Vio),e(A,jg),e(jg,Ece),e(Ece,Xio),e(jg,zio),e(jg,XI),e(XI,Qio),e(jg,Wio),e(A,Uio),e(A,Dg),e(Dg,Cce),e(Cce,Hio),e(Dg,Jio),e(Dg,zI),e(zI,Yio),e(Dg,Kio),e(A,Zio),e(A,Gg),e(Gg,wce),e(wce,edo),e(Gg,odo),e(Gg,QI),e(QI,rdo),e(Gg,tdo),e(A,ado),e(A,Og),e(Og,Ace),e(Ace,ndo),e(Og,sdo),e(Og,WI),e(WI,ldo),e(Og,ido),e(A,ddo),e(A,Vg),e(Vg,Lce),e(Lce,cdo),e(Vg,mdo),e(Vg,UI),e(UI,fdo),e(Vg,gdo),e(A,hdo),e(A,Xg),e(Xg,yce),e(yce,udo),e(Xg,pdo),e(Xg,HI),e(HI,_do),e(Xg,bdo),e(A,vdo),e(A,zg),e(zg,xce),e(xce,Fdo),e(zg,Tdo),e(zg,JI),e(JI,Mdo),e(zg,Edo),e(A,Cdo),e(A,Qg),e(Qg,$ce),e($ce,wdo),e(Qg,Ado),e(Qg,YI),e(YI,Ldo),e(Qg,ydo),e(A,xdo),e(A,Wg),e(Wg,kce),e(kce,$do),e(Wg,kdo),e(Wg,KI),e(KI,Sdo),e(Wg,Rdo),e(A,Pdo),e(A,Ug),e(Ug,Sce),e(Sce,Bdo),e(Ug,Ido),e(Ug,ZI),e(ZI,Ndo),e(Ug,qdo),e(A,jdo),e(A,Hg),e(Hg,Rce),e(Rce,Ddo),e(Hg,Gdo),e(Hg,eN),e(eN,Odo),e(Hg,Vdo),e(A,Xdo),e(A,Jg),e(Jg,Pce),e(Pce,zdo),e(Jg,Qdo),e(Jg,oN),e(oN,Wdo),e(Jg,Udo),e(A,Hdo),e(A,Yg),e(Yg,Bce),e(Bce,Jdo),e(Yg,Ydo),e(Yg,rN),e(rN,Kdo),e(Yg,Zdo),e(A,eco),e(A,Kg),e(Kg,Ice),e(Ice,oco),e(Kg,rco),e(Kg,tN),e(tN,tco),e(Kg,aco),e(A,nco),e(A,Zg),e(Zg,Nce),e(Nce,sco),e(Zg,lco),e(Zg,aN),e(aN,ico),e(Zg,dco),e(A,cco),e(A,eh),e(eh,qce),e(qce,mco),e(eh,fco),e(eh,nN),e(nN,gco),e(eh,hco),e(A,uco),e(A,oh),e(oh,jce),e(jce,pco),e(oh,_co),e(oh,sN),e(sN,bco),e(oh,vco),e(A,Fco),e(A,rh),e(rh,Dce),e(Dce,Tco),e(rh,Mco),e(rh,lN),e(lN,Eco),e(rh,Cco),e(A,wco),e(A,th),e(th,Gce),e(Gce,Aco),e(th,Lco),e(th,iN),e(iN,yco),e(th,xco),e(A,$co),e(A,ah),e(ah,Oce),e(Oce,kco),e(ah,Sco),e(ah,dN),e(dN,Rco),e(ah,Pco),e(A,Bco),e(A,nh),e(nh,Vce),e(Vce,Ico),e(nh,Nco),e(nh,cN),e(cN,qco),e(nh,jco),e(A,Dco),e(A,sh),e(sh,Xce),e(Xce,Gco),e(sh,Oco),e(sh,mN),e(mN,Vco),e(sh,Xco),e(A,zco),e(A,lh),e(lh,zce),e(zce,Qco),e(lh,Wco),e(lh,fN),e(fN,Uco),e(lh,Hco),e(A,Jco),e(A,ih),e(ih,Qce),e(Qce,Yco),e(ih,Kco),e(ih,gN),e(gN,Zco),e(ih,emo),e(A,omo),e(A,dh),e(dh,Wce),e(Wce,rmo),e(dh,tmo),e(dh,hN),e(hN,amo),e(dh,nmo),e(A,smo),e(A,ch),e(ch,Uce),e(Uce,lmo),e(ch,imo),e(ch,uN),e(uN,dmo),e(ch,cmo),e(A,mmo),e(A,mh),e(mh,Hce),e(Hce,fmo),e(mh,gmo),e(mh,pN),e(pN,hmo),e(mh,umo),e(A,pmo),e(A,fh),e(fh,Jce),e(Jce,_mo),e(fh,bmo),e(fh,_N),e(_N,vmo),e(fh,Fmo),e(A,Tmo),e(A,gh),e(gh,Yce),e(Yce,Mmo),e(gh,Emo),e(gh,bN),e(bN,Cmo),e(gh,wmo),e(A,Amo),e(A,hh),e(hh,Kce),e(Kce,Lmo),e(hh,ymo),e(hh,vN),e(vN,xmo),e(hh,$mo),e(A,kmo),e(A,uh),e(uh,Zce),e(Zce,Smo),e(uh,Rmo),e(uh,FN),e(FN,Pmo),e(uh,Bmo),e(A,Imo),e(A,ph),e(ph,eme),e(eme,Nmo),e(ph,qmo),e(ph,TN),e(TN,jmo),e(ph,Dmo),e(A,Gmo),e(A,_h),e(_h,ome),e(ome,Omo),e(_h,Vmo),e(_h,MN),e(MN,Xmo),e(_h,zmo),e(A,Qmo),e(A,bh),e(bh,rme),e(rme,Wmo),e(bh,Umo),e(bh,EN),e(EN,Hmo),e(bh,Jmo),e(A,Ymo),e(A,vh),e(vh,tme),e(tme,Kmo),e(vh,Zmo),e(vh,CN),e(CN,efo),e(vh,ofo),e(A,rfo),e(A,Fh),e(Fh,ame),e(ame,tfo),e(Fh,afo),e(Fh,wN),e(wN,nfo),e(Fh,sfo),e(A,lfo),e(A,Th),e(Th,nme),e(nme,ifo),e(Th,dfo),e(Th,AN),e(AN,cfo),e(Th,mfo),e(A,ffo),e(A,Mh),e(Mh,sme),e(sme,gfo),e(Mh,hfo),e(Mh,LN),e(LN,ufo),e(Mh,pfo),e(A,_fo),e(A,Eh),e(Eh,lme),e(lme,bfo),e(Eh,vfo),e(Eh,yN),e(yN,Ffo),e(Eh,Tfo),e(A,Mfo),e(A,Ch),e(Ch,ime),e(ime,Efo),e(Ch,Cfo),e(Ch,xN),e(xN,wfo),e(Ch,Afo),e(A,Lfo),e(A,wh),e(wh,dme),e(dme,yfo),e(wh,xfo),e(wh,$N),e($N,$fo),e(wh,kfo),e(A,Sfo),e(A,Ah),e(Ah,cme),e(cme,Rfo),e(Ah,Pfo),e(Ah,kN),e(kN,Bfo),e(Ah,Ifo),e(A,Nfo),e(A,Lh),e(Lh,mme),e(mme,qfo),e(Lh,jfo),e(Lh,SN),e(SN,Dfo),e(Lh,Gfo),e(A,Ofo),e(A,yh),e(yh,fme),e(fme,Vfo),e(yh,Xfo),e(yh,RN),e(RN,zfo),e(yh,Qfo),e(A,Wfo),e(A,xh),e(xh,gme),e(gme,Ufo),e(xh,Hfo),e(xh,PN),e(PN,Jfo),e(xh,Yfo),e(A,Kfo),e(A,$h),e($h,hme),e(hme,Zfo),e($h,ego),e($h,BN),e(BN,ogo),e($h,rgo),e(A,tgo),e(A,kh),e(kh,ume),e(ume,ago),e(kh,ngo),e(kh,IN),e(IN,sgo),e(kh,lgo),e(A,igo),e(A,Sh),e(Sh,pme),e(pme,dgo),e(Sh,cgo),e(Sh,NN),e(NN,mgo),e(Sh,fgo),e(A,ggo),e(A,Rh),e(Rh,_me),e(_me,hgo),e(Rh,ugo),e(Rh,qN),e(qN,pgo),e(Rh,_go),e(A,bgo),e(A,Ph),e(Ph,bme),e(bme,vgo),e(Ph,Fgo),e(Ph,jN),e(jN,Tgo),e(Ph,Mgo),e(A,Ego),e(A,Bh),e(Bh,vme),e(vme,Cgo),e(Bh,wgo),e(Bh,DN),e(DN,Ago),e(Bh,Lgo),e(A,ygo),e(A,Ih),e(Ih,Fme),e(Fme,xgo),e(Ih,$go),e(Ih,GN),e(GN,kgo),e(Ih,Sgo),e(A,Rgo),e(A,Nh),e(Nh,Tme),e(Tme,Pgo),e(Nh,Bgo),e(Nh,ON),e(ON,Igo),e(Nh,Ngo),e(A,qgo),e(A,qh),e(qh,Mme),e(Mme,jgo),e(qh,Dgo),e(qh,VN),e(VN,Ggo),e(qh,Ogo),e(A,Vgo),e(A,jh),e(jh,Eme),e(Eme,Xgo),e(jh,zgo),e(jh,XN),e(XN,Qgo),e(jh,Wgo),e(A,Ugo),e(A,Dh),e(Dh,Cme),e(Cme,Hgo),e(Dh,Jgo),e(Dh,zN),e(zN,Ygo),e(Dh,Kgo),e(A,Zgo),e(A,Gh),e(Gh,wme),e(wme,eho),e(Gh,oho),e(Gh,QN),e(QN,rho),e(Gh,tho),e(A,aho),e(A,Oh),e(Oh,Ame),e(Ame,nho),e(Oh,sho),e(Oh,WN),e(WN,lho),e(Oh,iho),e(A,dho),e(A,Vh),e(Vh,Lme),e(Lme,cho),e(Vh,mho),e(Vh,UN),e(UN,fho),e(Vh,gho),e(A,hho),e(A,Xh),e(Xh,yme),e(yme,uho),e(Xh,pho),e(Xh,HN),e(HN,_ho),e(Xh,bho),e(A,vho),e(A,zh),e(zh,xme),e(xme,Fho),e(zh,Tho),e(zh,JN),e(JN,Mho),e(zh,Eho),e(A,Cho),e(A,Qh),e(Qh,$me),e($me,who),e(Qh,Aho),e(Qh,YN),e(YN,Lho),e(Qh,yho),e(A,xho),e(A,Wh),e(Wh,kme),e(kme,$ho),e(Wh,kho),e(Wh,KN),e(KN,Sho),e(Wh,Rho),e(Pr,Pho),M(Uh,Pr,null),e($o,Bho),e($o,Hh),M(B9,Hh,null),e(Hh,Iho),e(Hh,Sme),e(Sme,Nho),b(m,oKe,_),b(m,fd,_),e(fd,Jh),e(Jh,Rme),M(I9,Rme,null),e(fd,qho),e(fd,Pme),e(Pme,jho),b(m,rKe,_),b(m,ko,_),M(N9,ko,null),e(ko,Dho),e(ko,q9),e(q9,Gho),e(q9,ZN),e(ZN,Oho),e(q9,Vho),e(ko,Xho),e(ko,j9),e(j9,zho),e(j9,Bme),e(Bme,Qho),e(j9,Who),e(ko,Uho),e(ko,Br),M(D9,Br,null),e(Br,Hho),e(Br,Ime),e(Ime,Jho),e(Br,Yho),e(Br,Ua),e(Ua,Kho),e(Ua,Nme),e(Nme,Zho),e(Ua,euo),e(Ua,qme),e(qme,ouo),e(Ua,ruo),e(Ua,jme),e(jme,tuo),e(Ua,auo),e(Br,nuo),e(Br,k),e(k,as),e(as,Dme),e(Dme,suo),e(as,luo),e(as,eq),e(eq,iuo),e(as,duo),e(as,oq),e(oq,cuo),e(as,muo),e(k,fuo),e(k,ns),e(ns,Gme),e(Gme,guo),e(ns,huo),e(ns,rq),e(rq,uuo),e(ns,puo),e(ns,tq),e(tq,_uo),e(ns,buo),e(k,vuo),e(k,ss),e(ss,Ome),e(Ome,Fuo),e(ss,Tuo),e(ss,aq),e(aq,Muo),e(ss,Euo),e(ss,nq),e(nq,Cuo),e(ss,wuo),e(k,Auo),e(k,Yh),e(Yh,Vme),e(Vme,Luo),e(Yh,yuo),e(Yh,sq),e(sq,xuo),e(Yh,$uo),e(k,kuo),e(k,ls),e(ls,Xme),e(Xme,Suo),e(ls,Ruo),e(ls,lq),e(lq,Puo),e(ls,Buo),e(ls,iq),e(iq,Iuo),e(ls,Nuo),e(k,quo),e(k,Kh),e(Kh,zme),e(zme,juo),e(Kh,Duo),e(Kh,dq),e(dq,Guo),e(Kh,Ouo),e(k,Vuo),e(k,Zh),e(Zh,Qme),e(Qme,Xuo),e(Zh,zuo),e(Zh,cq),e(cq,Quo),e(Zh,Wuo),e(k,Uuo),e(k,eu),e(eu,Wme),e(Wme,Huo),e(eu,Juo),e(eu,mq),e(mq,Yuo),e(eu,Kuo),e(k,Zuo),e(k,is),e(is,Ume),e(Ume,epo),e(is,opo),e(is,fq),e(fq,rpo),e(is,tpo),e(is,gq),e(gq,apo),e(is,npo),e(k,spo),e(k,ds),e(ds,Hme),e(Hme,lpo),e(ds,ipo),e(ds,hq),e(hq,dpo),e(ds,cpo),e(ds,uq),e(uq,mpo),e(ds,fpo),e(k,gpo),e(k,cs),e(cs,Jme),e(Jme,hpo),e(cs,upo),e(cs,pq),e(pq,ppo),e(cs,_po),e(cs,_q),e(_q,bpo),e(cs,vpo),e(k,Fpo),e(k,ou),e(ou,Yme),e(Yme,Tpo),e(ou,Mpo),e(ou,bq),e(bq,Epo),e(ou,Cpo),e(k,wpo),e(k,ru),e(ru,Kme),e(Kme,Apo),e(ru,Lpo),e(ru,vq),e(vq,ypo),e(ru,xpo),e(k,$po),e(k,tu),e(tu,Zme),e(Zme,kpo),e(tu,Spo),e(tu,Fq),e(Fq,Rpo),e(tu,Ppo),e(k,Bpo),e(k,ms),e(ms,efe),e(efe,Ipo),e(ms,Npo),e(ms,Tq),e(Tq,qpo),e(ms,jpo),e(ms,Mq),e(Mq,Dpo),e(ms,Gpo),e(k,Opo),e(k,au),e(au,ofe),e(ofe,Vpo),e(au,Xpo),e(au,Eq),e(Eq,zpo),e(au,Qpo),e(k,Wpo),e(k,fs),e(fs,rfe),e(rfe,Upo),e(fs,Hpo),e(fs,Cq),e(Cq,Jpo),e(fs,Ypo),e(fs,wq),e(wq,Kpo),e(fs,Zpo),e(k,e_o),e(k,gs),e(gs,tfe),e(tfe,o_o),e(gs,r_o),e(gs,Aq),e(Aq,t_o),e(gs,a_o),e(gs,Lq),e(Lq,n_o),e(gs,s_o),e(k,l_o),e(k,hs),e(hs,afe),e(afe,i_o),e(hs,d_o),e(hs,yq),e(yq,c_o),e(hs,m_o),e(hs,xq),e(xq,f_o),e(hs,g_o),e(k,h_o),e(k,us),e(us,nfe),e(nfe,u_o),e(us,p_o),e(us,$q),e($q,__o),e(us,b_o),e(us,kq),e(kq,v_o),e(us,F_o),e(k,T_o),e(k,nu),e(nu,sfe),e(sfe,M_o),e(nu,E_o),e(nu,Sq),e(Sq,C_o),e(nu,w_o),e(k,A_o),e(k,ps),e(ps,lfe),e(lfe,L_o),e(ps,y_o),e(ps,Rq),e(Rq,x_o),e(ps,$_o),e(ps,Pq),e(Pq,k_o),e(ps,S_o),e(k,R_o),e(k,_s),e(_s,ife),e(ife,P_o),e(_s,B_o),e(_s,Bq),e(Bq,I_o),e(_s,N_o),e(_s,Iq),e(Iq,q_o),e(_s,j_o),e(k,D_o),e(k,bs),e(bs,dfe),e(dfe,G_o),e(bs,O_o),e(bs,Nq),e(Nq,V_o),e(bs,X_o),e(bs,qq),e(qq,z_o),e(bs,Q_o),e(k,W_o),e(k,vs),e(vs,cfe),e(cfe,U_o),e(vs,H_o),e(vs,jq),e(jq,J_o),e(vs,Y_o),e(vs,Dq),e(Dq,K_o),e(vs,Z_o),e(k,ebo),e(k,Fs),e(Fs,mfe),e(mfe,obo),e(Fs,rbo),e(Fs,Gq),e(Gq,tbo),e(Fs,abo),e(Fs,Oq),e(Oq,nbo),e(Fs,sbo),e(k,lbo),e(k,Ts),e(Ts,ffe),e(ffe,ibo),e(Ts,dbo),e(Ts,Vq),e(Vq,cbo),e(Ts,mbo),e(Ts,Xq),e(Xq,fbo),e(Ts,gbo),e(k,hbo),e(k,Ms),e(Ms,gfe),e(gfe,ubo),e(Ms,pbo),e(Ms,zq),e(zq,_bo),e(Ms,bbo),e(Ms,Qq),e(Qq,vbo),e(Ms,Fbo),e(k,Tbo),e(k,su),e(su,hfe),e(hfe,Mbo),e(su,Ebo),e(su,Wq),e(Wq,Cbo),e(su,wbo),e(k,Abo),e(k,Es),e(Es,ufe),e(ufe,Lbo),e(Es,ybo),e(Es,Uq),e(Uq,xbo),e(Es,$bo),e(Es,Hq),e(Hq,kbo),e(Es,Sbo),e(k,Rbo),e(k,lu),e(lu,pfe),e(pfe,Pbo),e(lu,Bbo),e(lu,Jq),e(Jq,Ibo),e(lu,Nbo),e(k,qbo),e(k,Cs),e(Cs,_fe),e(_fe,jbo),e(Cs,Dbo),e(Cs,Yq),e(Yq,Gbo),e(Cs,Obo),e(Cs,Kq),e(Kq,Vbo),e(Cs,Xbo),e(k,zbo),e(k,ws),e(ws,bfe),e(bfe,Qbo),e(ws,Wbo),e(ws,Zq),e(Zq,Ubo),e(ws,Hbo),e(ws,ej),e(ej,Jbo),e(ws,Ybo),e(k,Kbo),e(k,As),e(As,vfe),e(vfe,Zbo),e(As,e2o),e(As,oj),e(oj,o2o),e(As,r2o),e(As,rj),e(rj,t2o),e(As,a2o),e(k,n2o),e(k,iu),e(iu,Ffe),e(Ffe,s2o),e(iu,l2o),e(iu,tj),e(tj,i2o),e(iu,d2o),e(k,c2o),e(k,Ls),e(Ls,Tfe),e(Tfe,m2o),e(Ls,f2o),e(Ls,aj),e(aj,g2o),e(Ls,h2o),e(Ls,nj),e(nj,u2o),e(Ls,p2o),e(k,_2o),e(k,ys),e(ys,Mfe),e(Mfe,b2o),e(ys,v2o),e(ys,sj),e(sj,F2o),e(ys,T2o),e(ys,lj),e(lj,M2o),e(ys,E2o),e(k,C2o),e(k,xs),e(xs,Efe),e(Efe,w2o),e(xs,A2o),e(xs,ij),e(ij,L2o),e(xs,y2o),e(xs,dj),e(dj,x2o),e(xs,$2o),e(k,k2o),e(k,du),e(du,Cfe),e(Cfe,S2o),e(du,R2o),e(du,cj),e(cj,P2o),e(du,B2o),e(k,I2o),e(k,$s),e($s,wfe),e(wfe,N2o),e($s,q2o),e($s,mj),e(mj,j2o),e($s,D2o),e($s,fj),e(fj,G2o),e($s,O2o),e(k,V2o),e(k,ks),e(ks,Afe),e(Afe,X2o),e(ks,z2o),e(ks,gj),e(gj,Q2o),e(ks,W2o),e(ks,hj),e(hj,U2o),e(ks,H2o),e(k,J2o),e(k,Ss),e(Ss,Lfe),e(Lfe,Y2o),e(Ss,K2o),e(Ss,uj),e(uj,Z2o),e(Ss,e1o),e(Ss,pj),e(pj,o1o),e(Ss,r1o),e(k,t1o),e(k,Rs),e(Rs,yfe),e(yfe,a1o),e(Rs,n1o),e(Rs,_j),e(_j,s1o),e(Rs,l1o),e(Rs,bj),e(bj,i1o),e(Rs,d1o),e(k,c1o),e(k,Ps),e(Ps,xfe),e(xfe,m1o),e(Ps,f1o),e(Ps,vj),e(vj,g1o),e(Ps,h1o),e(Ps,Fj),e(Fj,u1o),e(Ps,p1o),e(k,_1o),e(k,Bs),e(Bs,$fe),e($fe,b1o),e(Bs,v1o),e(Bs,Tj),e(Tj,F1o),e(Bs,T1o),e(Bs,Mj),e(Mj,M1o),e(Bs,E1o),e(k,C1o),e(k,Is),e(Is,kfe),e(kfe,w1o),e(Is,A1o),e(Is,Ej),e(Ej,L1o),e(Is,y1o),e(Is,Cj),e(Cj,x1o),e(Is,$1o),e(k,k1o),e(k,Ns),e(Ns,Sfe),e(Sfe,S1o),e(Ns,R1o),e(Ns,wj),e(wj,P1o),e(Ns,B1o),e(Ns,Aj),e(Aj,I1o),e(Ns,N1o),e(k,q1o),e(k,cu),e(cu,Rfe),e(Rfe,j1o),e(cu,D1o),e(cu,Lj),e(Lj,G1o),e(cu,O1o),e(k,V1o),e(k,qs),e(qs,Pfe),e(Pfe,X1o),e(qs,z1o),e(qs,yj),e(yj,Q1o),e(qs,W1o),e(qs,xj),e(xj,U1o),e(qs,H1o),e(k,J1o),e(k,mu),e(mu,Bfe),e(Bfe,Y1o),e(mu,K1o),e(mu,$j),e($j,Z1o),e(mu,evo),e(k,ovo),e(k,fu),e(fu,Ife),e(Ife,rvo),e(fu,tvo),e(fu,kj),e(kj,avo),e(fu,nvo),e(k,svo),e(k,js),e(js,Nfe),e(Nfe,lvo),e(js,ivo),e(js,Sj),e(Sj,dvo),e(js,cvo),e(js,Rj),e(Rj,mvo),e(js,fvo),e(k,gvo),e(k,Ds),e(Ds,qfe),e(qfe,hvo),e(Ds,uvo),e(Ds,Pj),e(Pj,pvo),e(Ds,_vo),e(Ds,Bj),e(Bj,bvo),e(Ds,vvo),e(k,Fvo),e(k,Gs),e(Gs,jfe),e(jfe,Tvo),e(Gs,Mvo),e(Gs,Ij),e(Ij,Evo),e(Gs,Cvo),e(Gs,Nj),e(Nj,wvo),e(Gs,Avo),e(k,Lvo),e(k,gu),e(gu,Dfe),e(Dfe,yvo),e(gu,xvo),e(gu,qj),e(qj,$vo),e(gu,kvo),e(k,Svo),e(k,Os),e(Os,Gfe),e(Gfe,Rvo),e(Os,Pvo),e(Os,jj),e(jj,Bvo),e(Os,Ivo),e(Os,Dj),e(Dj,Nvo),e(Os,qvo),e(k,jvo),e(k,Vs),e(Vs,Ofe),e(Ofe,Dvo),e(Vs,Gvo),e(Vs,Gj),e(Gj,Ovo),e(Vs,Vvo),e(Vs,Oj),e(Oj,Xvo),e(Vs,zvo),e(k,Qvo),e(k,Xs),e(Xs,Vfe),e(Vfe,Wvo),e(Xs,Uvo),e(Xs,Vj),e(Vj,Hvo),e(Xs,Jvo),e(Xs,Xj),e(Xj,Yvo),e(Xs,Kvo),e(k,Zvo),e(k,zs),e(zs,Xfe),e(Xfe,eFo),e(zs,oFo),e(zs,zj),e(zj,rFo),e(zs,tFo),e(zs,Qj),e(Qj,aFo),e(zs,nFo),e(k,sFo),e(k,Qs),e(Qs,zfe),e(zfe,lFo),e(Qs,iFo),e(Qs,Wj),e(Wj,dFo),e(Qs,cFo),e(Qs,Uj),e(Uj,mFo),e(Qs,fFo),e(k,gFo),e(k,Ws),e(Ws,Qfe),e(Qfe,hFo),e(Ws,uFo),e(Ws,Hj),e(Hj,pFo),e(Ws,_Fo),e(Ws,Jj),e(Jj,bFo),e(Ws,vFo),e(k,FFo),e(k,Us),e(Us,Wfe),e(Wfe,TFo),e(Us,MFo),e(Us,Yj),e(Yj,EFo),e(Us,CFo),e(Us,Kj),e(Kj,wFo),e(Us,AFo),e(k,LFo),e(k,Hs),e(Hs,Ufe),e(Ufe,yFo),e(Hs,xFo),e(Hs,Zj),e(Zj,$Fo),e(Hs,kFo),e(Hs,eD),e(eD,SFo),e(Hs,RFo),e(k,PFo),e(k,hu),e(hu,Hfe),e(Hfe,BFo),e(hu,IFo),e(hu,oD),e(oD,NFo),e(hu,qFo),e(k,jFo),e(k,Js),e(Js,Jfe),e(Jfe,DFo),e(Js,GFo),e(Js,rD),e(rD,OFo),e(Js,VFo),e(Js,tD),e(tD,XFo),e(Js,zFo),e(k,QFo),e(k,Ys),e(Ys,Yfe),e(Yfe,WFo),e(Ys,UFo),e(Ys,aD),e(aD,HFo),e(Ys,JFo),e(Ys,nD),e(nD,YFo),e(Ys,KFo),e(k,ZFo),e(k,uu),e(uu,Kfe),e(Kfe,eTo),e(uu,oTo),e(uu,sD),e(sD,rTo),e(uu,tTo),e(k,aTo),e(k,pu),e(pu,Zfe),e(Zfe,nTo),e(pu,sTo),e(pu,lD),e(lD,lTo),e(pu,iTo),e(k,dTo),e(k,_u),e(_u,ege),e(ege,cTo),e(_u,mTo),e(_u,iD),e(iD,fTo),e(_u,gTo),e(k,hTo),e(k,bu),e(bu,oge),e(oge,uTo),e(bu,pTo),e(bu,dD),e(dD,_To),e(bu,bTo),e(k,vTo),e(k,Ks),e(Ks,rge),e(rge,FTo),e(Ks,TTo),e(Ks,cD),e(cD,MTo),e(Ks,ETo),e(Ks,mD),e(mD,CTo),e(Ks,wTo),e(k,ATo),e(k,vu),e(vu,tge),e(tge,LTo),e(vu,yTo),e(vu,fD),e(fD,xTo),e(vu,$To),e(k,kTo),e(k,Zs),e(Zs,age),e(age,STo),e(Zs,RTo),e(Zs,gD),e(gD,PTo),e(Zs,BTo),e(Zs,hD),e(hD,ITo),e(Zs,NTo),e(k,qTo),e(k,el),e(el,nge),e(nge,jTo),e(el,DTo),e(el,uD),e(uD,GTo),e(el,OTo),e(el,pD),e(pD,VTo),e(el,XTo),e(k,zTo),e(k,ol),e(ol,sge),e(sge,QTo),e(ol,WTo),e(ol,_D),e(_D,UTo),e(ol,HTo),e(ol,bD),e(bD,JTo),e(ol,YTo),e(k,KTo),e(k,rl),e(rl,lge),e(lge,ZTo),e(rl,eMo),e(rl,vD),e(vD,oMo),e(rl,rMo),e(rl,FD),e(FD,tMo),e(rl,aMo),e(k,nMo),e(k,tl),e(tl,ige),e(ige,sMo),e(tl,lMo),e(tl,TD),e(TD,iMo),e(tl,dMo),e(tl,MD),e(MD,cMo),e(tl,mMo),e(k,fMo),e(k,al),e(al,dge),e(dge,gMo),e(al,hMo),e(al,ED),e(ED,uMo),e(al,pMo),e(al,CD),e(CD,_Mo),e(al,bMo),e(k,vMo),e(k,Fu),e(Fu,cge),e(cge,FMo),e(Fu,TMo),e(Fu,wD),e(wD,MMo),e(Fu,EMo),e(k,CMo),e(k,Tu),e(Tu,mge),e(mge,wMo),e(Tu,AMo),e(Tu,AD),e(AD,LMo),e(Tu,yMo),e(k,xMo),e(k,nl),e(nl,fge),e(fge,$Mo),e(nl,kMo),e(nl,LD),e(LD,SMo),e(nl,RMo),e(nl,yD),e(yD,PMo),e(nl,BMo),e(k,IMo),e(k,sl),e(sl,gge),e(gge,NMo),e(sl,qMo),e(sl,xD),e(xD,jMo),e(sl,DMo),e(sl,$D),e($D,GMo),e(sl,OMo),e(k,VMo),e(k,ll),e(ll,hge),e(hge,XMo),e(ll,zMo),e(ll,kD),e(kD,QMo),e(ll,WMo),e(ll,SD),e(SD,UMo),e(ll,HMo),e(k,JMo),e(k,Mu),e(Mu,uge),e(uge,YMo),e(Mu,KMo),e(Mu,RD),e(RD,ZMo),e(Mu,eEo),e(k,oEo),e(k,Eu),e(Eu,pge),e(pge,rEo),e(Eu,tEo),e(Eu,PD),e(PD,aEo),e(Eu,nEo),e(k,sEo),e(k,Cu),e(Cu,_ge),e(_ge,lEo),e(Cu,iEo),e(Cu,BD),e(BD,dEo),e(Cu,cEo),e(k,mEo),e(k,il),e(il,bge),e(bge,fEo),e(il,gEo),e(il,ID),e(ID,hEo),e(il,uEo),e(il,ND),e(ND,pEo),e(il,_Eo),e(k,bEo),e(k,dl),e(dl,vge),e(vge,vEo),e(dl,FEo),e(dl,qD),e(qD,TEo),e(dl,MEo),e(dl,jD),e(jD,EEo),e(dl,CEo),e(k,wEo),e(k,wu),e(wu,Fge),e(Fge,AEo),e(wu,LEo),e(wu,DD),e(DD,yEo),e(wu,xEo),e(k,$Eo),e(k,Au),e(Au,Tge),e(Tge,kEo),e(Au,SEo),e(Au,GD),e(GD,REo),e(Au,PEo),e(k,BEo),e(k,Lu),e(Lu,Mge),e(Mge,IEo),e(Lu,NEo),e(Lu,OD),e(OD,qEo),e(Lu,jEo),e(k,DEo),e(k,cl),e(cl,Ege),e(Ege,GEo),e(cl,OEo),e(cl,VD),e(VD,VEo),e(cl,XEo),e(cl,XD),e(XD,zEo),e(cl,QEo),e(k,WEo),e(k,ml),e(ml,Cge),e(Cge,UEo),e(ml,HEo),e(ml,zD),e(zD,JEo),e(ml,YEo),e(ml,QD),e(QD,KEo),e(ml,ZEo),e(k,e4o),e(k,yu),e(yu,wge),e(wge,o4o),e(yu,r4o),e(yu,WD),e(WD,t4o),e(yu,a4o),e(k,n4o),e(k,xu),e(xu,Age),e(Age,s4o),e(xu,l4o),e(xu,UD),e(UD,i4o),e(xu,d4o),e(k,c4o),e(k,fl),e(fl,Lge),e(Lge,m4o),e(fl,f4o),e(fl,HD),e(HD,g4o),e(fl,h4o),e(fl,JD),e(JD,u4o),e(fl,p4o),e(k,_4o),e(k,gl),e(gl,yge),e(yge,b4o),e(gl,v4o),e(gl,YD),e(YD,F4o),e(gl,T4o),e(gl,KD),e(KD,M4o),e(gl,E4o),e(k,C4o),e(k,hl),e(hl,xge),e(xge,w4o),e(hl,A4o),e(hl,ZD),e(ZD,L4o),e(hl,y4o),e(hl,eG),e(eG,x4o),e(hl,$4o),e(k,k4o),e(k,ul),e(ul,$ge),e($ge,S4o),e(ul,R4o),e(ul,oG),e(oG,P4o),e(ul,B4o),e(ul,rG),e(rG,I4o),e(ul,N4o),e(Br,q4o),M($u,Br,null),e(ko,j4o),e(ko,ku),M(G9,ku,null),e(ku,D4o),e(ku,kge),e(kge,G4o),b(m,tKe,_),b(m,gd,_),e(gd,Su),e(Su,Sge),M(O9,Sge,null),e(gd,O4o),e(gd,Rge),e(Rge,V4o),b(m,aKe,_),b(m,So,_),M(V9,So,null),e(So,X4o),e(So,X9),e(X9,z4o),e(X9,tG),e(tG,Q4o),e(X9,W4o),e(So,U4o),e(So,z9),e(z9,H4o),e(z9,Pge),e(Pge,J4o),e(z9,Y4o),e(So,K4o),e(So,Ye),M(Q9,Ye,null),e(Ye,Z4o),e(Ye,Bge),e(Bge,eCo),e(Ye,oCo),e(Ye,Ha),e(Ha,rCo),e(Ha,Ige),e(Ige,tCo),e(Ha,aCo),e(Ha,Nge),e(Nge,nCo),e(Ha,sCo),e(Ha,qge),e(qge,lCo),e(Ha,iCo),e(Ye,dCo),e(Ye,Q),e(Q,Ru),e(Ru,jge),e(jge,cCo),e(Ru,mCo),e(Ru,aG),e(aG,fCo),e(Ru,gCo),e(Q,hCo),e(Q,Pu),e(Pu,Dge),e(Dge,uCo),e(Pu,pCo),e(Pu,nG),e(nG,_Co),e(Pu,bCo),e(Q,vCo),e(Q,Bu),e(Bu,Gge),e(Gge,FCo),e(Bu,TCo),e(Bu,sG),e(sG,MCo),e(Bu,ECo),e(Q,CCo),e(Q,Iu),e(Iu,Oge),e(Oge,wCo),e(Iu,ACo),e(Iu,lG),e(lG,LCo),e(Iu,yCo),e(Q,xCo),e(Q,Nu),e(Nu,Vge),e(Vge,$Co),e(Nu,kCo),e(Nu,iG),e(iG,SCo),e(Nu,RCo),e(Q,PCo),e(Q,qu),e(qu,Xge),e(Xge,BCo),e(qu,ICo),e(qu,dG),e(dG,NCo),e(qu,qCo),e(Q,jCo),e(Q,ju),e(ju,zge),e(zge,DCo),e(ju,GCo),e(ju,cG),e(cG,OCo),e(ju,VCo),e(Q,XCo),e(Q,Du),e(Du,Qge),e(Qge,zCo),e(Du,QCo),e(Du,mG),e(mG,WCo),e(Du,UCo),e(Q,HCo),e(Q,Gu),e(Gu,Wge),e(Wge,JCo),e(Gu,YCo),e(Gu,fG),e(fG,KCo),e(Gu,ZCo),e(Q,e3o),e(Q,Ou),e(Ou,Uge),e(Uge,o3o),e(Ou,r3o),e(Ou,gG),e(gG,t3o),e(Ou,a3o),e(Q,n3o),e(Q,Vu),e(Vu,Hge),e(Hge,s3o),e(Vu,l3o),e(Vu,hG),e(hG,i3o),e(Vu,d3o),e(Q,c3o),e(Q,Xu),e(Xu,Jge),e(Jge,m3o),e(Xu,f3o),e(Xu,uG),e(uG,g3o),e(Xu,h3o),e(Q,u3o),e(Q,zu),e(zu,Yge),e(Yge,p3o),e(zu,_3o),e(zu,pG),e(pG,b3o),e(zu,v3o),e(Q,F3o),e(Q,Qu),e(Qu,Kge),e(Kge,T3o),e(Qu,M3o),e(Qu,_G),e(_G,E3o),e(Qu,C3o),e(Q,w3o),e(Q,Wu),e(Wu,Zge),e(Zge,A3o),e(Wu,L3o),e(Wu,bG),e(bG,y3o),e(Wu,x3o),e(Q,$3o),e(Q,Uu),e(Uu,ehe),e(ehe,k3o),e(Uu,S3o),e(Uu,vG),e(vG,R3o),e(Uu,P3o),e(Q,B3o),e(Q,Hu),e(Hu,ohe),e(ohe,I3o),e(Hu,N3o),e(Hu,FG),e(FG,q3o),e(Hu,j3o),e(Q,D3o),e(Q,Ju),e(Ju,rhe),e(rhe,G3o),e(Ju,O3o),e(Ju,TG),e(TG,V3o),e(Ju,X3o),e(Q,z3o),e(Q,Yu),e(Yu,the),e(the,Q3o),e(Yu,W3o),e(Yu,MG),e(MG,U3o),e(Yu,H3o),e(Q,J3o),e(Q,Ku),e(Ku,ahe),e(ahe,Y3o),e(Ku,K3o),e(Ku,EG),e(EG,Z3o),e(Ku,e5o),e(Q,o5o),e(Q,Zu),e(Zu,nhe),e(nhe,r5o),e(Zu,t5o),e(Zu,CG),e(CG,a5o),e(Zu,n5o),e(Q,s5o),e(Q,ep),e(ep,she),e(she,l5o),e(ep,i5o),e(ep,wG),e(wG,d5o),e(ep,c5o),e(Q,m5o),e(Q,op),e(op,lhe),e(lhe,f5o),e(op,g5o),e(op,AG),e(AG,h5o),e(op,u5o),e(Q,p5o),e(Q,rp),e(rp,ihe),e(ihe,_5o),e(rp,b5o),e(rp,LG),e(LG,v5o),e(rp,F5o),e(Q,T5o),e(Q,tp),e(tp,dhe),e(dhe,M5o),e(tp,E5o),e(tp,yG),e(yG,C5o),e(tp,w5o),e(Q,A5o),e(Q,ap),e(ap,che),e(che,L5o),e(ap,y5o),e(ap,xG),e(xG,x5o),e(ap,$5o),e(Q,k5o),e(Q,np),e(np,mhe),e(mhe,S5o),e(np,R5o),e(np,$G),e($G,P5o),e(np,B5o),e(Q,I5o),e(Q,sp),e(sp,fhe),e(fhe,N5o),e(sp,q5o),e(sp,kG),e(kG,j5o),e(sp,D5o),e(Q,G5o),e(Q,lp),e(lp,ghe),e(ghe,O5o),e(lp,V5o),e(lp,SG),e(SG,X5o),e(lp,z5o),e(Q,Q5o),e(Q,ip),e(ip,hhe),e(hhe,W5o),e(ip,U5o),e(ip,RG),e(RG,H5o),e(ip,J5o),e(Q,Y5o),e(Q,dp),e(dp,uhe),e(uhe,K5o),e(dp,Z5o),e(dp,PG),e(PG,e0o),e(dp,o0o),e(Q,r0o),e(Q,cp),e(cp,phe),e(phe,t0o),e(cp,a0o),e(cp,BG),e(BG,n0o),e(cp,s0o),e(Q,l0o),e(Q,mp),e(mp,_he),e(_he,i0o),e(mp,d0o),e(mp,IG),e(IG,c0o),e(mp,m0o),e(Q,f0o),e(Q,fp),e(fp,bhe),e(bhe,g0o),e(fp,h0o),e(fp,NG),e(NG,u0o),e(fp,p0o),e(Q,_0o),e(Q,gp),e(gp,vhe),e(vhe,b0o),e(gp,v0o),e(gp,qG),e(qG,F0o),e(gp,T0o),e(Q,M0o),e(Q,hp),e(hp,Fhe),e(Fhe,E0o),e(hp,C0o),e(hp,jG),e(jG,w0o),e(hp,A0o),e(Q,L0o),e(Q,up),e(up,The),e(The,y0o),e(up,x0o),e(up,DG),e(DG,$0o),e(up,k0o),e(Q,S0o),e(Q,pp),e(pp,Mhe),e(Mhe,R0o),e(pp,P0o),e(pp,GG),e(GG,B0o),e(pp,I0o),e(Q,N0o),e(Q,_p),e(_p,Ehe),e(Ehe,q0o),e(_p,j0o),e(_p,OG),e(OG,D0o),e(_p,G0o),e(Q,O0o),e(Q,bp),e(bp,Che),e(Che,V0o),e(bp,X0o),e(bp,VG),e(VG,z0o),e(bp,Q0o),e(Ye,W0o),M(vp,Ye,null),e(Ye,U0o),M(Fp,Ye,null),e(So,H0o),e(So,Tp),M(W9,Tp,null),e(Tp,J0o),e(Tp,whe),e(whe,Y0o),b(m,nKe,_),b(m,hd,_),e(hd,Mp),e(Mp,Ahe),M(U9,Ahe,null),e(hd,K0o),e(hd,Lhe),e(Lhe,Z0o),b(m,sKe,_),b(m,Ro,_),M(H9,Ro,null),e(Ro,ewo),e(Ro,J9),e(J9,owo),e(J9,XG),e(XG,rwo),e(J9,two),e(Ro,awo),e(Ro,Y9),e(Y9,nwo),e(Y9,yhe),e(yhe,swo),e(Y9,lwo),e(Ro,iwo),e(Ro,Ke),M(K9,Ke,null),e(Ke,dwo),e(Ke,xhe),e(xhe,cwo),e(Ke,mwo),e(Ke,ud),e(ud,fwo),e(ud,$he),e($he,gwo),e(ud,hwo),e(ud,khe),e(khe,uwo),e(ud,pwo),e(Ke,_wo),e(Ke,ie),e(ie,Ep),e(Ep,She),e(She,bwo),e(Ep,vwo),e(Ep,zG),e(zG,Fwo),e(Ep,Two),e(ie,Mwo),e(ie,Cp),e(Cp,Rhe),e(Rhe,Ewo),e(Cp,Cwo),e(Cp,QG),e(QG,wwo),e(Cp,Awo),e(ie,Lwo),e(ie,wp),e(wp,Phe),e(Phe,ywo),e(wp,xwo),e(wp,WG),e(WG,$wo),e(wp,kwo),e(ie,Swo),e(ie,Ap),e(Ap,Bhe),e(Bhe,Rwo),e(Ap,Pwo),e(Ap,UG),e(UG,Bwo),e(Ap,Iwo),e(ie,Nwo),e(ie,Lp),e(Lp,Ihe),e(Ihe,qwo),e(Lp,jwo),e(Lp,HG),e(HG,Dwo),e(Lp,Gwo),e(ie,Owo),e(ie,yp),e(yp,Nhe),e(Nhe,Vwo),e(yp,Xwo),e(yp,JG),e(JG,zwo),e(yp,Qwo),e(ie,Wwo),e(ie,xp),e(xp,qhe),e(qhe,Uwo),e(xp,Hwo),e(xp,YG),e(YG,Jwo),e(xp,Ywo),e(ie,Kwo),e(ie,$p),e($p,jhe),e(jhe,Zwo),e($p,eAo),e($p,KG),e(KG,oAo),e($p,rAo),e(ie,tAo),e(ie,kp),e(kp,Dhe),e(Dhe,aAo),e(kp,nAo),e(kp,ZG),e(ZG,sAo),e(kp,lAo),e(ie,iAo),e(ie,Sp),e(Sp,Ghe),e(Ghe,dAo),e(Sp,cAo),e(Sp,eO),e(eO,mAo),e(Sp,fAo),e(ie,gAo),e(ie,Rp),e(Rp,Ohe),e(Ohe,hAo),e(Rp,uAo),e(Rp,oO),e(oO,pAo),e(Rp,_Ao),e(ie,bAo),e(ie,Pp),e(Pp,Vhe),e(Vhe,vAo),e(Pp,FAo),e(Pp,rO),e(rO,TAo),e(Pp,MAo),e(ie,EAo),e(ie,Bp),e(Bp,Xhe),e(Xhe,CAo),e(Bp,wAo),e(Bp,tO),e(tO,AAo),e(Bp,LAo),e(ie,yAo),e(ie,Ip),e(Ip,zhe),e(zhe,xAo),e(Ip,$Ao),e(Ip,aO),e(aO,kAo),e(Ip,SAo),e(ie,RAo),e(ie,Np),e(Np,Qhe),e(Qhe,PAo),e(Np,BAo),e(Np,nO),e(nO,IAo),e(Np,NAo),e(ie,qAo),e(ie,qp),e(qp,Whe),e(Whe,jAo),e(qp,DAo),e(qp,sO),e(sO,GAo),e(qp,OAo),e(ie,VAo),e(ie,jp),e(jp,Uhe),e(Uhe,XAo),e(jp,zAo),e(jp,lO),e(lO,QAo),e(jp,WAo),e(ie,UAo),e(ie,Dp),e(Dp,Hhe),e(Hhe,HAo),e(Dp,JAo),e(Dp,iO),e(iO,YAo),e(Dp,KAo),e(ie,ZAo),e(ie,Gp),e(Gp,Jhe),e(Jhe,e6o),e(Gp,o6o),e(Gp,dO),e(dO,r6o),e(Gp,t6o),e(ie,a6o),e(ie,Op),e(Op,Yhe),e(Yhe,n6o),e(Op,s6o),e(Op,cO),e(cO,l6o),e(Op,i6o),e(ie,d6o),e(ie,Vp),e(Vp,Khe),e(Khe,c6o),e(Vp,m6o),e(Vp,mO),e(mO,f6o),e(Vp,g6o),e(Ke,h6o),M(Xp,Ke,null),e(Ke,u6o),M(zp,Ke,null),e(Ro,p6o),e(Ro,Qp),M(Z9,Qp,null),e(Qp,_6o),e(Qp,Zhe),e(Zhe,b6o),b(m,lKe,_),b(m,pd,_),e(pd,Wp),e(Wp,eue),M(ex,eue,null),e(pd,v6o),e(pd,oue),e(oue,F6o),b(m,iKe,_),b(m,Po,_),M(ox,Po,null),e(Po,T6o),e(Po,_d),e(_d,M6o),e(_d,fO),e(fO,E6o),e(_d,C6o),e(_d,gO),e(gO,w6o),e(_d,A6o),e(Po,L6o),e(Po,rx),e(rx,y6o),e(rx,rue),e(rue,x6o),e(rx,$6o),e(Po,k6o),e(Po,_t),M(tx,_t,null),e(_t,S6o),e(_t,tue),e(tue,R6o),e(_t,P6o),e(_t,bd),e(bd,B6o),e(bd,aue),e(aue,I6o),e(bd,N6o),e(bd,hO),e(hO,q6o),e(bd,j6o),e(_t,D6o),M(Up,_t,null),e(Po,G6o),e(Po,Ze),M(ax,Ze,null),e(Ze,O6o),e(Ze,nue),e(nue,V6o),e(Ze,X6o),e(Ze,Ja),e(Ja,z6o),e(Ja,sue),e(sue,Q6o),e(Ja,W6o),e(Ja,lue),e(lue,U6o),e(Ja,H6o),e(Ja,iue),e(iue,J6o),e(Ja,Y6o),e(Ze,K6o),e(Ze,y),e(y,Hp),e(Hp,due),e(due,Z6o),e(Hp,e7o),e(Hp,uO),e(uO,o7o),e(Hp,r7o),e(y,t7o),e(y,Jp),e(Jp,cue),e(cue,a7o),e(Jp,n7o),e(Jp,pO),e(pO,s7o),e(Jp,l7o),e(y,i7o),e(y,Yp),e(Yp,mue),e(mue,d7o),e(Yp,c7o),e(Yp,_O),e(_O,m7o),e(Yp,f7o),e(y,g7o),e(y,Kp),e(Kp,fue),e(fue,h7o),e(Kp,u7o),e(Kp,bO),e(bO,p7o),e(Kp,_7o),e(y,b7o),e(y,Zp),e(Zp,gue),e(gue,v7o),e(Zp,F7o),e(Zp,vO),e(vO,T7o),e(Zp,M7o),e(y,E7o),e(y,e_),e(e_,hue),e(hue,C7o),e(e_,w7o),e(e_,FO),e(FO,A7o),e(e_,L7o),e(y,y7o),e(y,o_),e(o_,uue),e(uue,x7o),e(o_,$7o),e(o_,TO),e(TO,k7o),e(o_,S7o),e(y,R7o),e(y,r_),e(r_,pue),e(pue,P7o),e(r_,B7o),e(r_,MO),e(MO,I7o),e(r_,N7o),e(y,q7o),e(y,t_),e(t_,_ue),e(_ue,j7o),e(t_,D7o),e(t_,EO),e(EO,G7o),e(t_,O7o),e(y,V7o),e(y,a_),e(a_,bue),e(bue,X7o),e(a_,z7o),e(a_,CO),e(CO,Q7o),e(a_,W7o),e(y,U7o),e(y,n_),e(n_,vue),e(vue,H7o),e(n_,J7o),e(n_,wO),e(wO,Y7o),e(n_,K7o),e(y,Z7o),e(y,s_),e(s_,Fue),e(Fue,eLo),e(s_,oLo),e(s_,AO),e(AO,rLo),e(s_,tLo),e(y,aLo),e(y,l_),e(l_,Tue),e(Tue,nLo),e(l_,sLo),e(l_,LO),e(LO,lLo),e(l_,iLo),e(y,dLo),e(y,i_),e(i_,Mue),e(Mue,cLo),e(i_,mLo),e(i_,yO),e(yO,fLo),e(i_,gLo),e(y,hLo),e(y,d_),e(d_,Eue),e(Eue,uLo),e(d_,pLo),e(d_,xO),e(xO,_Lo),e(d_,bLo),e(y,vLo),e(y,c_),e(c_,Cue),e(Cue,FLo),e(c_,TLo),e(c_,$O),e($O,MLo),e(c_,ELo),e(y,CLo),e(y,m_),e(m_,wue),e(wue,wLo),e(m_,ALo),e(m_,kO),e(kO,LLo),e(m_,yLo),e(y,xLo),e(y,f_),e(f_,Aue),e(Aue,$Lo),e(f_,kLo),e(f_,SO),e(SO,SLo),e(f_,RLo),e(y,PLo),e(y,g_),e(g_,Lue),e(Lue,BLo),e(g_,ILo),e(g_,RO),e(RO,NLo),e(g_,qLo),e(y,jLo),e(y,h_),e(h_,yue),e(yue,DLo),e(h_,GLo),e(h_,PO),e(PO,OLo),e(h_,VLo),e(y,XLo),e(y,u_),e(u_,xue),e(xue,zLo),e(u_,QLo),e(u_,BO),e(BO,WLo),e(u_,ULo),e(y,HLo),e(y,p_),e(p_,$ue),e($ue,JLo),e(p_,YLo),e(p_,IO),e(IO,KLo),e(p_,ZLo),e(y,eyo),e(y,__),e(__,kue),e(kue,oyo),e(__,ryo),e(__,NO),e(NO,tyo),e(__,ayo),e(y,nyo),e(y,b_),e(b_,Sue),e(Sue,syo),e(b_,lyo),e(b_,qO),e(qO,iyo),e(b_,dyo),e(y,cyo),e(y,v_),e(v_,Rue),e(Rue,myo),e(v_,fyo),e(v_,jO),e(jO,gyo),e(v_,hyo),e(y,uyo),e(y,F_),e(F_,Pue),e(Pue,pyo),e(F_,_yo),e(F_,DO),e(DO,byo),e(F_,vyo),e(y,Fyo),e(y,T_),e(T_,Bue),e(Bue,Tyo),e(T_,Myo),e(T_,GO),e(GO,Eyo),e(T_,Cyo),e(y,wyo),e(y,M_),e(M_,Iue),e(Iue,Ayo),e(M_,Lyo),e(M_,OO),e(OO,yyo),e(M_,xyo),e(y,$yo),e(y,E_),e(E_,Nue),e(Nue,kyo),e(E_,Syo),e(E_,VO),e(VO,Ryo),e(E_,Pyo),e(y,Byo),e(y,C_),e(C_,que),e(que,Iyo),e(C_,Nyo),e(C_,XO),e(XO,qyo),e(C_,jyo),e(y,Dyo),e(y,w_),e(w_,jue),e(jue,Gyo),e(w_,Oyo),e(w_,zO),e(zO,Vyo),e(w_,Xyo),e(y,zyo),e(y,A_),e(A_,Due),e(Due,Qyo),e(A_,Wyo),e(A_,QO),e(QO,Uyo),e(A_,Hyo),e(y,Jyo),e(y,L_),e(L_,Gue),e(Gue,Yyo),e(L_,Kyo),e(L_,WO),e(WO,Zyo),e(L_,e8o),e(y,o8o),e(y,y_),e(y_,Oue),e(Oue,r8o),e(y_,t8o),e(y_,UO),e(UO,a8o),e(y_,n8o),e(y,s8o),e(y,x_),e(x_,Vue),e(Vue,l8o),e(x_,i8o),e(x_,HO),e(HO,d8o),e(x_,c8o),e(y,m8o),e(y,$_),e($_,Xue),e(Xue,f8o),e($_,g8o),e($_,JO),e(JO,h8o),e($_,u8o),e(y,p8o),e(y,k_),e(k_,zue),e(zue,_8o),e(k_,b8o),e(k_,YO),e(YO,v8o),e(k_,F8o),e(y,T8o),e(y,pl),e(pl,Que),e(Que,M8o),e(pl,E8o),e(pl,KO),e(KO,C8o),e(pl,w8o),e(pl,ZO),e(ZO,A8o),e(pl,L8o),e(y,y8o),e(y,S_),e(S_,Wue),e(Wue,x8o),e(S_,$8o),e(S_,eV),e(eV,k8o),e(S_,S8o),e(y,R8o),e(y,R_),e(R_,Uue),e(Uue,P8o),e(R_,B8o),e(R_,oV),e(oV,I8o),e(R_,N8o),e(y,q8o),e(y,P_),e(P_,Hue),e(Hue,j8o),e(P_,D8o),e(P_,rV),e(rV,G8o),e(P_,O8o),e(y,V8o),e(y,B_),e(B_,Jue),e(Jue,X8o),e(B_,z8o),e(B_,tV),e(tV,Q8o),e(B_,W8o),e(y,U8o),e(y,I_),e(I_,Yue),e(Yue,H8o),e(I_,J8o),e(I_,aV),e(aV,Y8o),e(I_,K8o),e(y,Z8o),e(y,N_),e(N_,Kue),e(Kue,e9o),e(N_,o9o),e(N_,nV),e(nV,r9o),e(N_,t9o),e(y,a9o),e(y,q_),e(q_,Zue),e(Zue,n9o),e(q_,s9o),e(q_,sV),e(sV,l9o),e(q_,i9o),e(y,d9o),e(y,j_),e(j_,epe),e(epe,c9o),e(j_,m9o),e(j_,lV),e(lV,f9o),e(j_,g9o),e(y,h9o),e(y,D_),e(D_,ope),e(ope,u9o),e(D_,p9o),e(D_,iV),e(iV,_9o),e(D_,b9o),e(y,v9o),e(y,G_),e(G_,rpe),e(rpe,F9o),e(G_,T9o),e(G_,dV),e(dV,M9o),e(G_,E9o),e(y,C9o),e(y,O_),e(O_,tpe),e(tpe,w9o),e(O_,A9o),e(O_,cV),e(cV,L9o),e(O_,y9o),e(y,x9o),e(y,V_),e(V_,ape),e(ape,$9o),e(V_,k9o),e(V_,mV),e(mV,S9o),e(V_,R9o),e(y,P9o),e(y,X_),e(X_,npe),e(npe,B9o),e(X_,I9o),e(X_,fV),e(fV,N9o),e(X_,q9o),e(y,j9o),e(y,z_),e(z_,spe),e(spe,D9o),e(z_,G9o),e(z_,gV),e(gV,O9o),e(z_,V9o),e(y,X9o),e(y,Q_),e(Q_,lpe),e(lpe,z9o),e(Q_,Q9o),e(Q_,hV),e(hV,W9o),e(Q_,U9o),e(y,H9o),e(y,W_),e(W_,ipe),e(ipe,J9o),e(W_,Y9o),e(W_,uV),e(uV,K9o),e(W_,Z9o),e(y,exo),e(y,U_),e(U_,dpe),e(dpe,oxo),e(U_,rxo),e(U_,pV),e(pV,txo),e(U_,axo),e(y,nxo),e(y,H_),e(H_,cpe),e(cpe,sxo),e(H_,lxo),e(H_,_V),e(_V,ixo),e(H_,dxo),e(y,cxo),e(y,J_),e(J_,mpe),e(mpe,mxo),e(J_,fxo),e(J_,bV),e(bV,gxo),e(J_,hxo),e(y,uxo),e(y,Y_),e(Y_,fpe),e(fpe,pxo),e(Y_,_xo),e(Y_,vV),e(vV,bxo),e(Y_,vxo),e(y,Fxo),e(y,K_),e(K_,gpe),e(gpe,Txo),e(K_,Mxo),e(K_,FV),e(FV,Exo),e(K_,Cxo),e(y,wxo),e(y,Z_),e(Z_,hpe),e(hpe,Axo),e(Z_,Lxo),e(Z_,TV),e(TV,yxo),e(Z_,xxo),e(y,$xo),e(y,eb),e(eb,upe),e(upe,kxo),e(eb,Sxo),e(eb,MV),e(MV,Rxo),e(eb,Pxo),e(y,Bxo),e(y,ob),e(ob,ppe),e(ppe,Ixo),e(ob,Nxo),e(ob,EV),e(EV,qxo),e(ob,jxo),e(y,Dxo),e(y,rb),e(rb,_pe),e(_pe,Gxo),e(rb,Oxo),e(rb,CV),e(CV,Vxo),e(rb,Xxo),e(y,zxo),e(y,tb),e(tb,bpe),e(bpe,Qxo),e(tb,Wxo),e(tb,wV),e(wV,Uxo),e(tb,Hxo),e(y,Jxo),e(y,ab),e(ab,vpe),e(vpe,Yxo),e(ab,Kxo),e(ab,AV),e(AV,Zxo),e(ab,e$o),e(y,o$o),e(y,nb),e(nb,Fpe),e(Fpe,r$o),e(nb,t$o),e(nb,LV),e(LV,a$o),e(nb,n$o),e(y,s$o),e(y,sb),e(sb,Tpe),e(Tpe,l$o),e(sb,i$o),e(sb,yV),e(yV,d$o),e(sb,c$o),e(y,m$o),e(y,lb),e(lb,Mpe),e(Mpe,f$o),e(lb,g$o),e(lb,xV),e(xV,h$o),e(lb,u$o),e(y,p$o),e(y,ib),e(ib,Epe),e(Epe,_$o),e(ib,b$o),e(ib,$V),e($V,v$o),e(ib,F$o),e(y,T$o),e(y,db),e(db,Cpe),e(Cpe,M$o),e(db,E$o),e(db,kV),e(kV,C$o),e(db,w$o),e(y,A$o),e(y,cb),e(cb,wpe),e(wpe,L$o),e(cb,y$o),e(cb,SV),e(SV,x$o),e(cb,$$o),e(y,k$o),e(y,mb),e(mb,Ape),e(Ape,S$o),e(mb,R$o),e(mb,RV),e(RV,P$o),e(mb,B$o),e(y,I$o),e(y,fb),e(fb,Lpe),e(Lpe,N$o),e(fb,q$o),e(fb,PV),e(PV,j$o),e(fb,D$o),e(y,G$o),e(y,gb),e(gb,ype),e(ype,O$o),e(gb,V$o),e(gb,BV),e(BV,X$o),e(gb,z$o),e(y,Q$o),e(y,hb),e(hb,xpe),e(xpe,W$o),e(hb,U$o),e(hb,IV),e(IV,H$o),e(hb,J$o),e(y,Y$o),e(y,ub),e(ub,$pe),e($pe,K$o),e(ub,Z$o),e(ub,NV),e(NV,eko),e(ub,oko),e(y,rko),e(y,pb),e(pb,kpe),e(kpe,tko),e(pb,ako),e(pb,qV),e(qV,nko),e(pb,sko),e(y,lko),e(y,_b),e(_b,Spe),e(Spe,iko),e(_b,dko),e(_b,jV),e(jV,cko),e(_b,mko),e(y,fko),e(y,bb),e(bb,Rpe),e(Rpe,gko),e(bb,hko),e(bb,DV),e(DV,uko),e(bb,pko),e(y,_ko),e(y,vb),e(vb,Ppe),e(Ppe,bko),e(vb,vko),e(vb,GV),e(GV,Fko),e(vb,Tko),e(y,Mko),e(y,Fb),e(Fb,Bpe),e(Bpe,Eko),e(Fb,Cko),e(Fb,OV),e(OV,wko),e(Fb,Ako),e(y,Lko),e(y,Tb),e(Tb,Ipe),e(Ipe,yko),e(Tb,xko),e(Tb,VV),e(VV,$ko),e(Tb,kko),e(y,Sko),e(y,Mb),e(Mb,Npe),e(Npe,Rko),e(Mb,Pko),e(Mb,XV),e(XV,Bko),e(Mb,Iko),e(y,Nko),e(y,Eb),e(Eb,qpe),e(qpe,qko),e(Eb,jko),e(Eb,zV),e(zV,Dko),e(Eb,Gko),e(y,Oko),e(y,Cb),e(Cb,jpe),e(jpe,Vko),e(Cb,Xko),e(Cb,QV),e(QV,zko),e(Cb,Qko),e(y,Wko),e(y,wb),e(wb,Dpe),e(Dpe,Uko),e(wb,Hko),e(wb,WV),e(WV,Jko),e(wb,Yko),e(y,Kko),e(y,Ab),e(Ab,Gpe),e(Gpe,Zko),e(Ab,eSo),e(Ab,UV),e(UV,oSo),e(Ab,rSo),e(y,tSo),e(y,Lb),e(Lb,Ope),e(Ope,aSo),e(Lb,nSo),e(Lb,HV),e(HV,sSo),e(Lb,lSo),e(y,iSo),e(y,yb),e(yb,Vpe),e(Vpe,dSo),e(yb,cSo),e(yb,JV),e(JV,mSo),e(yb,fSo),e(y,gSo),e(y,xb),e(xb,Xpe),e(Xpe,hSo),e(xb,uSo),e(xb,YV),e(YV,pSo),e(xb,_So),e(y,bSo),e(y,$b),e($b,zpe),e(zpe,vSo),e($b,FSo),e($b,KV),e(KV,TSo),e($b,MSo),e(y,ESo),e(y,kb),e(kb,Qpe),e(Qpe,CSo),e(kb,wSo),e(kb,ZV),e(ZV,ASo),e(kb,LSo),e(y,ySo),e(y,Sb),e(Sb,Wpe),e(Wpe,xSo),e(Sb,$So),e(Sb,eX),e(eX,kSo),e(Sb,SSo),e(y,RSo),e(y,Rb),e(Rb,Upe),e(Upe,PSo),e(Rb,BSo),e(Rb,oX),e(oX,ISo),e(Rb,NSo),e(y,qSo),e(y,Pb),e(Pb,Hpe),e(Hpe,jSo),e(Pb,DSo),e(Pb,rX),e(rX,GSo),e(Pb,OSo),e(y,VSo),e(y,Bb),e(Bb,Jpe),e(Jpe,XSo),e(Bb,zSo),e(Bb,tX),e(tX,QSo),e(Bb,WSo),e(y,USo),e(y,Ib),e(Ib,Ype),e(Ype,HSo),e(Ib,JSo),e(Ib,aX),e(aX,YSo),e(Ib,KSo),e(y,ZSo),e(y,Nb),e(Nb,Kpe),e(Kpe,eRo),e(Nb,oRo),e(Nb,nX),e(nX,rRo),e(Nb,tRo),e(y,aRo),e(y,qb),e(qb,Zpe),e(Zpe,nRo),e(qb,sRo),e(qb,sX),e(sX,lRo),e(qb,iRo),e(y,dRo),e(y,jb),e(jb,e_e),e(e_e,cRo),e(jb,mRo),e(jb,lX),e(lX,fRo),e(jb,gRo),e(y,hRo),e(y,Db),e(Db,o_e),e(o_e,uRo),e(Db,pRo),e(Db,iX),e(iX,_Ro),e(Db,bRo),e(y,vRo),e(y,Gb),e(Gb,r_e),e(r_e,FRo),e(Gb,TRo),e(Gb,dX),e(dX,MRo),e(Gb,ERo),e(y,CRo),e(y,Ob),e(Ob,t_e),e(t_e,wRo),e(Ob,ARo),e(Ob,cX),e(cX,LRo),e(Ob,yRo),e(y,xRo),e(y,Vb),e(Vb,a_e),e(a_e,$Ro),e(Vb,kRo),e(Vb,mX),e(mX,SRo),e(Vb,RRo),e(y,PRo),e(y,Xb),e(Xb,n_e),e(n_e,BRo),e(Xb,IRo),e(Xb,fX),e(fX,NRo),e(Xb,qRo),e(y,jRo),e(y,zb),e(zb,s_e),e(s_e,DRo),e(zb,GRo),e(zb,gX),e(gX,ORo),e(zb,VRo),e(y,XRo),e(y,Qb),e(Qb,l_e),e(l_e,zRo),e(Qb,QRo),e(Qb,hX),e(hX,WRo),e(Qb,URo),e(y,HRo),e(y,Wb),e(Wb,i_e),e(i_e,JRo),e(Wb,YRo),e(Wb,uX),e(uX,KRo),e(Wb,ZRo),e(y,ePo),e(y,Ub),e(Ub,d_e),e(d_e,oPo),e(Ub,rPo),e(Ub,pX),e(pX,tPo),e(Ub,aPo),e(y,nPo),e(y,Hb),e(Hb,c_e),e(c_e,sPo),e(Hb,lPo),e(Hb,_X),e(_X,iPo),e(Hb,dPo),e(y,cPo),e(y,Jb),e(Jb,m_e),e(m_e,mPo),e(Jb,fPo),e(Jb,bX),e(bX,gPo),e(Jb,hPo),e(y,uPo),e(y,Yb),e(Yb,f_e),e(f_e,pPo),e(Yb,_Po),e(Yb,vX),e(vX,bPo),e(Yb,vPo),e(y,FPo),e(y,Kb),e(Kb,g_e),e(g_e,TPo),e(Kb,MPo),e(Kb,FX),e(FX,EPo),e(Kb,CPo),e(y,wPo),e(y,Zb),e(Zb,h_e),e(h_e,APo),e(Zb,LPo),e(Zb,TX),e(TX,yPo),e(Zb,xPo),e(y,$Po),e(y,e2),e(e2,u_e),e(u_e,kPo),e(e2,SPo),e(e2,MX),e(MX,RPo),e(e2,PPo),e(y,BPo),e(y,o2),e(o2,p_e),e(p_e,IPo),e(o2,NPo),e(o2,EX),e(EX,qPo),e(o2,jPo),e(y,DPo),e(y,r2),e(r2,__e),e(__e,GPo),e(r2,OPo),e(r2,CX),e(CX,VPo),e(r2,XPo),e(y,zPo),e(y,t2),e(t2,b_e),e(b_e,QPo),e(t2,WPo),e(t2,wX),e(wX,UPo),e(t2,HPo),e(y,JPo),e(y,a2),e(a2,v_e),e(v_e,YPo),e(a2,KPo),e(a2,AX),e(AX,ZPo),e(a2,eBo),e(y,oBo),e(y,n2),e(n2,F_e),e(F_e,rBo),e(n2,tBo),e(n2,LX),e(LX,aBo),e(n2,nBo),e(Ze,sBo),e(Ze,s2),e(s2,lBo),e(s2,T_e),e(T_e,iBo),e(s2,dBo),e(s2,M_e),e(M_e,cBo),e(Ze,mBo),M(l2,Ze,null),b(m,dKe,_),b(m,vd,_),e(vd,i2),e(i2,E_e),M(nx,E_e,null),e(vd,fBo),e(vd,C_e),e(C_e,gBo),b(m,cKe,_),b(m,Bo,_),M(sx,Bo,null),e(Bo,hBo),e(Bo,Fd),e(Fd,uBo),e(Fd,yX),e(yX,pBo),e(Fd,_Bo),e(Fd,xX),e(xX,bBo),e(Fd,vBo),e(Bo,FBo),e(Bo,lx),e(lx,TBo),e(lx,w_e),e(w_e,MBo),e(lx,EBo),e(Bo,CBo),e(Bo,bt),M(ix,bt,null),e(bt,wBo),e(bt,A_e),e(A_e,ABo),e(bt,LBo),e(bt,Td),e(Td,yBo),e(Td,L_e),e(L_e,xBo),e(Td,$Bo),e(Td,$X),e($X,kBo),e(Td,SBo),e(bt,RBo),M(d2,bt,null),e(Bo,PBo),e(Bo,eo),M(dx,eo,null),e(eo,BBo),e(eo,y_e),e(y_e,IBo),e(eo,NBo),e(eo,Ya),e(Ya,qBo),e(Ya,x_e),e(x_e,jBo),e(Ya,DBo),e(Ya,$_e),e($_e,GBo),e(Ya,OBo),e(Ya,k_e),e(k_e,VBo),e(Ya,XBo),e(eo,zBo),e(eo,G),e(G,c2),e(c2,S_e),e(S_e,QBo),e(c2,WBo),e(c2,kX),e(kX,UBo),e(c2,HBo),e(G,JBo),e(G,m2),e(m2,R_e),e(R_e,YBo),e(m2,KBo),e(m2,SX),e(SX,ZBo),e(m2,eIo),e(G,oIo),e(G,f2),e(f2,P_e),e(P_e,rIo),e(f2,tIo),e(f2,RX),e(RX,aIo),e(f2,nIo),e(G,sIo),e(G,g2),e(g2,B_e),e(B_e,lIo),e(g2,iIo),e(g2,PX),e(PX,dIo),e(g2,cIo),e(G,mIo),e(G,h2),e(h2,I_e),e(I_e,fIo),e(h2,gIo),e(h2,BX),e(BX,hIo),e(h2,uIo),e(G,pIo),e(G,u2),e(u2,N_e),e(N_e,_Io),e(u2,bIo),e(u2,IX),e(IX,vIo),e(u2,FIo),e(G,TIo),e(G,p2),e(p2,q_e),e(q_e,MIo),e(p2,EIo),e(p2,NX),e(NX,CIo),e(p2,wIo),e(G,AIo),e(G,_2),e(_2,j_e),e(j_e,LIo),e(_2,yIo),e(_2,qX),e(qX,xIo),e(_2,$Io),e(G,kIo),e(G,b2),e(b2,D_e),e(D_e,SIo),e(b2,RIo),e(b2,jX),e(jX,PIo),e(b2,BIo),e(G,IIo),e(G,v2),e(v2,G_e),e(G_e,NIo),e(v2,qIo),e(v2,DX),e(DX,jIo),e(v2,DIo),e(G,GIo),e(G,F2),e(F2,O_e),e(O_e,OIo),e(F2,VIo),e(F2,GX),e(GX,XIo),e(F2,zIo),e(G,QIo),e(G,T2),e(T2,V_e),e(V_e,WIo),e(T2,UIo),e(T2,OX),e(OX,HIo),e(T2,JIo),e(G,YIo),e(G,M2),e(M2,X_e),e(X_e,KIo),e(M2,ZIo),e(M2,VX),e(VX,eNo),e(M2,oNo),e(G,rNo),e(G,E2),e(E2,z_e),e(z_e,tNo),e(E2,aNo),e(E2,XX),e(XX,nNo),e(E2,sNo),e(G,lNo),e(G,C2),e(C2,Q_e),e(Q_e,iNo),e(C2,dNo),e(C2,zX),e(zX,cNo),e(C2,mNo),e(G,fNo),e(G,w2),e(w2,W_e),e(W_e,gNo),e(w2,hNo),e(w2,QX),e(QX,uNo),e(w2,pNo),e(G,_No),e(G,A2),e(A2,U_e),e(U_e,bNo),e(A2,vNo),e(A2,WX),e(WX,FNo),e(A2,TNo),e(G,MNo),e(G,L2),e(L2,H_e),e(H_e,ENo),e(L2,CNo),e(L2,UX),e(UX,wNo),e(L2,ANo),e(G,LNo),e(G,y2),e(y2,J_e),e(J_e,yNo),e(y2,xNo),e(y2,HX),e(HX,$No),e(y2,kNo),e(G,SNo),e(G,x2),e(x2,Y_e),e(Y_e,RNo),e(x2,PNo),e(x2,JX),e(JX,BNo),e(x2,INo),e(G,NNo),e(G,$2),e($2,K_e),e(K_e,qNo),e($2,jNo),e($2,YX),e(YX,DNo),e($2,GNo),e(G,ONo),e(G,k2),e(k2,Z_e),e(Z_e,VNo),e(k2,XNo),e(k2,KX),e(KX,zNo),e(k2,QNo),e(G,WNo),e(G,S2),e(S2,ebe),e(ebe,UNo),e(S2,HNo),e(S2,ZX),e(ZX,JNo),e(S2,YNo),e(G,KNo),e(G,R2),e(R2,obe),e(obe,ZNo),e(R2,eqo),e(R2,ez),e(ez,oqo),e(R2,rqo),e(G,tqo),e(G,P2),e(P2,rbe),e(rbe,aqo),e(P2,nqo),e(P2,oz),e(oz,sqo),e(P2,lqo),e(G,iqo),e(G,B2),e(B2,tbe),e(tbe,dqo),e(B2,cqo),e(B2,rz),e(rz,mqo),e(B2,fqo),e(G,gqo),e(G,I2),e(I2,abe),e(abe,hqo),e(I2,uqo),e(I2,tz),e(tz,pqo),e(I2,_qo),e(G,bqo),e(G,N2),e(N2,nbe),e(nbe,vqo),e(N2,Fqo),e(N2,az),e(az,Tqo),e(N2,Mqo),e(G,Eqo),e(G,q2),e(q2,sbe),e(sbe,Cqo),e(q2,wqo),e(q2,nz),e(nz,Aqo),e(q2,Lqo),e(G,yqo),e(G,j2),e(j2,lbe),e(lbe,xqo),e(j2,$qo),e(j2,sz),e(sz,kqo),e(j2,Sqo),e(G,Rqo),e(G,D2),e(D2,ibe),e(ibe,Pqo),e(D2,Bqo),e(D2,lz),e(lz,Iqo),e(D2,Nqo),e(G,qqo),e(G,G2),e(G2,dbe),e(dbe,jqo),e(G2,Dqo),e(G2,iz),e(iz,Gqo),e(G2,Oqo),e(G,Vqo),e(G,O2),e(O2,cbe),e(cbe,Xqo),e(O2,zqo),e(O2,dz),e(dz,Qqo),e(O2,Wqo),e(G,Uqo),e(G,V2),e(V2,mbe),e(mbe,Hqo),e(V2,Jqo),e(V2,cz),e(cz,Yqo),e(V2,Kqo),e(G,Zqo),e(G,X2),e(X2,fbe),e(fbe,ejo),e(X2,ojo),e(X2,mz),e(mz,rjo),e(X2,tjo),e(G,ajo),e(G,z2),e(z2,gbe),e(gbe,njo),e(z2,sjo),e(z2,fz),e(fz,ljo),e(z2,ijo),e(G,djo),e(G,Q2),e(Q2,hbe),e(hbe,cjo),e(Q2,mjo),e(Q2,gz),e(gz,fjo),e(Q2,gjo),e(G,hjo),e(G,W2),e(W2,ube),e(ube,ujo),e(W2,pjo),e(W2,hz),e(hz,_jo),e(W2,bjo),e(G,vjo),e(G,U2),e(U2,pbe),e(pbe,Fjo),e(U2,Tjo),e(U2,uz),e(uz,Mjo),e(U2,Ejo),e(G,Cjo),e(G,H2),e(H2,_be),e(_be,wjo),e(H2,Ajo),e(H2,pz),e(pz,Ljo),e(H2,yjo),e(G,xjo),e(G,J2),e(J2,bbe),e(bbe,$jo),e(J2,kjo),e(J2,_z),e(_z,Sjo),e(J2,Rjo),e(G,Pjo),e(G,Y2),e(Y2,vbe),e(vbe,Bjo),e(Y2,Ijo),e(Y2,bz),e(bz,Njo),e(Y2,qjo),e(G,jjo),e(G,K2),e(K2,Fbe),e(Fbe,Djo),e(K2,Gjo),e(K2,vz),e(vz,Ojo),e(K2,Vjo),e(G,Xjo),e(G,Z2),e(Z2,Tbe),e(Tbe,zjo),e(Z2,Qjo),e(Z2,Fz),e(Fz,Wjo),e(Z2,Ujo),e(G,Hjo),e(G,e1),e(e1,Mbe),e(Mbe,Jjo),e(e1,Yjo),e(e1,Tz),e(Tz,Kjo),e(e1,Zjo),e(G,eDo),e(G,o1),e(o1,Ebe),e(Ebe,oDo),e(o1,rDo),e(o1,Mz),e(Mz,tDo),e(o1,aDo),e(G,nDo),e(G,r1),e(r1,Cbe),e(Cbe,sDo),e(r1,lDo),e(r1,Ez),e(Ez,iDo),e(r1,dDo),e(G,cDo),e(G,t1),e(t1,wbe),e(wbe,mDo),e(t1,fDo),e(t1,Cz),e(Cz,gDo),e(t1,hDo),e(eo,uDo),e(eo,a1),e(a1,pDo),e(a1,Abe),e(Abe,_Do),e(a1,bDo),e(a1,Lbe),e(Lbe,vDo),e(eo,FDo),M(n1,eo,null),b(m,mKe,_),b(m,Md,_),e(Md,s1),e(s1,ybe),M(cx,ybe,null),e(Md,TDo),e(Md,xbe),e(xbe,MDo),b(m,fKe,_),b(m,Io,_),M(mx,Io,null),e(Io,EDo),e(Io,Ed),e(Ed,CDo),e(Ed,wz),e(wz,wDo),e(Ed,ADo),e(Ed,Az),e(Az,LDo),e(Ed,yDo),e(Io,xDo),e(Io,fx),e(fx,$Do),e(fx,$be),e($be,kDo),e(fx,SDo),e(Io,RDo),e(Io,vt),M(gx,vt,null),e(vt,PDo),e(vt,kbe),e(kbe,BDo),e(vt,IDo),e(vt,Cd),e(Cd,NDo),e(Cd,Sbe),e(Sbe,qDo),e(Cd,jDo),e(Cd,Lz),e(Lz,DDo),e(Cd,GDo),e(vt,ODo),M(l1,vt,null),e(Io,VDo),e(Io,oo),M(hx,oo,null),e(oo,XDo),e(oo,Rbe),e(Rbe,zDo),e(oo,QDo),e(oo,Ka),e(Ka,WDo),e(Ka,Pbe),e(Pbe,UDo),e(Ka,HDo),e(Ka,Bbe),e(Bbe,JDo),e(Ka,YDo),e(Ka,Ibe),e(Ibe,KDo),e(Ka,ZDo),e(oo,eGo),e(oo,z),e(z,i1),e(i1,Nbe),e(Nbe,oGo),e(i1,rGo),e(i1,yz),e(yz,tGo),e(i1,aGo),e(z,nGo),e(z,d1),e(d1,qbe),e(qbe,sGo),e(d1,lGo),e(d1,xz),e(xz,iGo),e(d1,dGo),e(z,cGo),e(z,c1),e(c1,jbe),e(jbe,mGo),e(c1,fGo),e(c1,$z),e($z,gGo),e(c1,hGo),e(z,uGo),e(z,m1),e(m1,Dbe),e(Dbe,pGo),e(m1,_Go),e(m1,kz),e(kz,bGo),e(m1,vGo),e(z,FGo),e(z,f1),e(f1,Gbe),e(Gbe,TGo),e(f1,MGo),e(f1,Sz),e(Sz,EGo),e(f1,CGo),e(z,wGo),e(z,g1),e(g1,Obe),e(Obe,AGo),e(g1,LGo),e(g1,Rz),e(Rz,yGo),e(g1,xGo),e(z,$Go),e(z,h1),e(h1,Vbe),e(Vbe,kGo),e(h1,SGo),e(h1,Pz),e(Pz,RGo),e(h1,PGo),e(z,BGo),e(z,u1),e(u1,Xbe),e(Xbe,IGo),e(u1,NGo),e(u1,Bz),e(Bz,qGo),e(u1,jGo),e(z,DGo),e(z,p1),e(p1,zbe),e(zbe,GGo),e(p1,OGo),e(p1,Iz),e(Iz,VGo),e(p1,XGo),e(z,zGo),e(z,_1),e(_1,Qbe),e(Qbe,QGo),e(_1,WGo),e(_1,Nz),e(Nz,UGo),e(_1,HGo),e(z,JGo),e(z,b1),e(b1,Wbe),e(Wbe,YGo),e(b1,KGo),e(b1,qz),e(qz,ZGo),e(b1,eOo),e(z,oOo),e(z,v1),e(v1,Ube),e(Ube,rOo),e(v1,tOo),e(v1,jz),e(jz,aOo),e(v1,nOo),e(z,sOo),e(z,F1),e(F1,Hbe),e(Hbe,lOo),e(F1,iOo),e(F1,Dz),e(Dz,dOo),e(F1,cOo),e(z,mOo),e(z,T1),e(T1,Jbe),e(Jbe,fOo),e(T1,gOo),e(T1,Gz),e(Gz,hOo),e(T1,uOo),e(z,pOo),e(z,M1),e(M1,Ybe),e(Ybe,_Oo),e(M1,bOo),e(M1,Oz),e(Oz,vOo),e(M1,FOo),e(z,TOo),e(z,E1),e(E1,Kbe),e(Kbe,MOo),e(E1,EOo),e(E1,Vz),e(Vz,COo),e(E1,wOo),e(z,AOo),e(z,C1),e(C1,Zbe),e(Zbe,LOo),e(C1,yOo),e(C1,Xz),e(Xz,xOo),e(C1,$Oo),e(z,kOo),e(z,w1),e(w1,e2e),e(e2e,SOo),e(w1,ROo),e(w1,zz),e(zz,POo),e(w1,BOo),e(z,IOo),e(z,A1),e(A1,o2e),e(o2e,NOo),e(A1,qOo),e(A1,Qz),e(Qz,jOo),e(A1,DOo),e(z,GOo),e(z,L1),e(L1,r2e),e(r2e,OOo),e(L1,VOo),e(L1,Wz),e(Wz,XOo),e(L1,zOo),e(z,QOo),e(z,y1),e(y1,t2e),e(t2e,WOo),e(y1,UOo),e(y1,Uz),e(Uz,HOo),e(y1,JOo),e(z,YOo),e(z,x1),e(x1,a2e),e(a2e,KOo),e(x1,ZOo),e(x1,Hz),e(Hz,eVo),e(x1,oVo),e(z,rVo),e(z,$1),e($1,n2e),e(n2e,tVo),e($1,aVo),e($1,Jz),e(Jz,nVo),e($1,sVo),e(z,lVo),e(z,k1),e(k1,s2e),e(s2e,iVo),e(k1,dVo),e(k1,Yz),e(Yz,cVo),e(k1,mVo),e(z,fVo),e(z,S1),e(S1,l2e),e(l2e,gVo),e(S1,hVo),e(S1,Kz),e(Kz,uVo),e(S1,pVo),e(z,_Vo),e(z,R1),e(R1,i2e),e(i2e,bVo),e(R1,vVo),e(R1,Zz),e(Zz,FVo),e(R1,TVo),e(z,MVo),e(z,P1),e(P1,d2e),e(d2e,EVo),e(P1,CVo),e(P1,eQ),e(eQ,wVo),e(P1,AVo),e(z,LVo),e(z,B1),e(B1,c2e),e(c2e,yVo),e(B1,xVo),e(B1,oQ),e(oQ,$Vo),e(B1,kVo),e(z,SVo),e(z,I1),e(I1,m2e),e(m2e,RVo),e(I1,PVo),e(I1,rQ),e(rQ,BVo),e(I1,IVo),e(z,NVo),e(z,N1),e(N1,f2e),e(f2e,qVo),e(N1,jVo),e(N1,tQ),e(tQ,DVo),e(N1,GVo),e(z,OVo),e(z,q1),e(q1,g2e),e(g2e,VVo),e(q1,XVo),e(q1,aQ),e(aQ,zVo),e(q1,QVo),e(z,WVo),e(z,j1),e(j1,h2e),e(h2e,UVo),e(j1,HVo),e(j1,nQ),e(nQ,JVo),e(j1,YVo),e(z,KVo),e(z,D1),e(D1,u2e),e(u2e,ZVo),e(D1,eXo),e(D1,sQ),e(sQ,oXo),e(D1,rXo),e(z,tXo),e(z,G1),e(G1,p2e),e(p2e,aXo),e(G1,nXo),e(G1,lQ),e(lQ,sXo),e(G1,lXo),e(z,iXo),e(z,O1),e(O1,_2e),e(_2e,dXo),e(O1,cXo),e(O1,iQ),e(iQ,mXo),e(O1,fXo),e(z,gXo),e(z,V1),e(V1,b2e),e(b2e,hXo),e(V1,uXo),e(V1,dQ),e(dQ,pXo),e(V1,_Xo),e(z,bXo),e(z,X1),e(X1,v2e),e(v2e,vXo),e(X1,FXo),e(X1,cQ),e(cQ,TXo),e(X1,MXo),e(z,EXo),e(z,z1),e(z1,F2e),e(F2e,CXo),e(z1,wXo),e(z1,mQ),e(mQ,AXo),e(z1,LXo),e(z,yXo),e(z,Q1),e(Q1,T2e),e(T2e,xXo),e(Q1,$Xo),e(Q1,fQ),e(fQ,kXo),e(Q1,SXo),e(z,RXo),e(z,W1),e(W1,M2e),e(M2e,PXo),e(W1,BXo),e(W1,gQ),e(gQ,IXo),e(W1,NXo),e(z,qXo),e(z,U1),e(U1,E2e),e(E2e,jXo),e(U1,DXo),e(U1,hQ),e(hQ,GXo),e(U1,OXo),e(oo,VXo),e(oo,H1),e(H1,XXo),e(H1,C2e),e(C2e,zXo),e(H1,QXo),e(H1,w2e),e(w2e,WXo),e(oo,UXo),M(J1,oo,null),b(m,gKe,_),b(m,wd,_),e(wd,Y1),e(Y1,A2e),M(ux,A2e,null),e(wd,HXo),e(wd,L2e),e(L2e,JXo),b(m,hKe,_),b(m,No,_),M(px,No,null),e(No,YXo),e(No,Ad),e(Ad,KXo),e(Ad,uQ),e(uQ,ZXo),e(Ad,ezo),e(Ad,pQ),e(pQ,ozo),e(Ad,rzo),e(No,tzo),e(No,_x),e(_x,azo),e(_x,y2e),e(y2e,nzo),e(_x,szo),e(No,lzo),e(No,Ft),M(bx,Ft,null),e(Ft,izo),e(Ft,x2e),e(x2e,dzo),e(Ft,czo),e(Ft,Ld),e(Ld,mzo),e(Ld,$2e),e($2e,fzo),e(Ld,gzo),e(Ld,_Q),e(_Q,hzo),e(Ld,uzo),e(Ft,pzo),M(K1,Ft,null),e(No,_zo),e(No,ro),M(vx,ro,null),e(ro,bzo),e(ro,k2e),e(k2e,vzo),e(ro,Fzo),e(ro,Za),e(Za,Tzo),e(Za,S2e),e(S2e,Mzo),e(Za,Ezo),e(Za,R2e),e(R2e,Czo),e(Za,wzo),e(Za,P2e),e(P2e,Azo),e(Za,Lzo),e(ro,yzo),e(ro,U),e(U,Z1),e(Z1,B2e),e(B2e,xzo),e(Z1,$zo),e(Z1,bQ),e(bQ,kzo),e(Z1,Szo),e(U,Rzo),e(U,ev),e(ev,I2e),e(I2e,Pzo),e(ev,Bzo),e(ev,vQ),e(vQ,Izo),e(ev,Nzo),e(U,qzo),e(U,ov),e(ov,N2e),e(N2e,jzo),e(ov,Dzo),e(ov,FQ),e(FQ,Gzo),e(ov,Ozo),e(U,Vzo),e(U,rv),e(rv,q2e),e(q2e,Xzo),e(rv,zzo),e(rv,TQ),e(TQ,Qzo),e(rv,Wzo),e(U,Uzo),e(U,tv),e(tv,j2e),e(j2e,Hzo),e(tv,Jzo),e(tv,MQ),e(MQ,Yzo),e(tv,Kzo),e(U,Zzo),e(U,av),e(av,D2e),e(D2e,eQo),e(av,oQo),e(av,EQ),e(EQ,rQo),e(av,tQo),e(U,aQo),e(U,nv),e(nv,G2e),e(G2e,nQo),e(nv,sQo),e(nv,CQ),e(CQ,lQo),e(nv,iQo),e(U,dQo),e(U,sv),e(sv,O2e),e(O2e,cQo),e(sv,mQo),e(sv,wQ),e(wQ,fQo),e(sv,gQo),e(U,hQo),e(U,lv),e(lv,V2e),e(V2e,uQo),e(lv,pQo),e(lv,AQ),e(AQ,_Qo),e(lv,bQo),e(U,vQo),e(U,iv),e(iv,X2e),e(X2e,FQo),e(iv,TQo),e(iv,LQ),e(LQ,MQo),e(iv,EQo),e(U,CQo),e(U,dv),e(dv,z2e),e(z2e,wQo),e(dv,AQo),e(dv,yQ),e(yQ,LQo),e(dv,yQo),e(U,xQo),e(U,cv),e(cv,Q2e),e(Q2e,$Qo),e(cv,kQo),e(cv,xQ),e(xQ,SQo),e(cv,RQo),e(U,PQo),e(U,mv),e(mv,W2e),e(W2e,BQo),e(mv,IQo),e(mv,$Q),e($Q,NQo),e(mv,qQo),e(U,jQo),e(U,fv),e(fv,U2e),e(U2e,DQo),e(fv,GQo),e(fv,kQ),e(kQ,OQo),e(fv,VQo),e(U,XQo),e(U,gv),e(gv,H2e),e(H2e,zQo),e(gv,QQo),e(gv,SQ),e(SQ,WQo),e(gv,UQo),e(U,HQo),e(U,hv),e(hv,J2e),e(J2e,JQo),e(hv,YQo),e(hv,RQ),e(RQ,KQo),e(hv,ZQo),e(U,eWo),e(U,uv),e(uv,Y2e),e(Y2e,oWo),e(uv,rWo),e(uv,PQ),e(PQ,tWo),e(uv,aWo),e(U,nWo),e(U,pv),e(pv,K2e),e(K2e,sWo),e(pv,lWo),e(pv,BQ),e(BQ,iWo),e(pv,dWo),e(U,cWo),e(U,_v),e(_v,Z2e),e(Z2e,mWo),e(_v,fWo),e(_v,IQ),e(IQ,gWo),e(_v,hWo),e(U,uWo),e(U,bv),e(bv,e1e),e(e1e,pWo),e(bv,_Wo),e(bv,NQ),e(NQ,bWo),e(bv,vWo),e(U,FWo),e(U,vv),e(vv,o1e),e(o1e,TWo),e(vv,MWo),e(vv,qQ),e(qQ,EWo),e(vv,CWo),e(U,wWo),e(U,Fv),e(Fv,r1e),e(r1e,AWo),e(Fv,LWo),e(Fv,jQ),e(jQ,yWo),e(Fv,xWo),e(U,$Wo),e(U,Tv),e(Tv,t1e),e(t1e,kWo),e(Tv,SWo),e(Tv,DQ),e(DQ,RWo),e(Tv,PWo),e(U,BWo),e(U,Mv),e(Mv,a1e),e(a1e,IWo),e(Mv,NWo),e(Mv,GQ),e(GQ,qWo),e(Mv,jWo),e(U,DWo),e(U,Ev),e(Ev,n1e),e(n1e,GWo),e(Ev,OWo),e(Ev,OQ),e(OQ,VWo),e(Ev,XWo),e(U,zWo),e(U,Cv),e(Cv,s1e),e(s1e,QWo),e(Cv,WWo),e(Cv,VQ),e(VQ,UWo),e(Cv,HWo),e(U,JWo),e(U,wv),e(wv,l1e),e(l1e,YWo),e(wv,KWo),e(wv,XQ),e(XQ,ZWo),e(wv,eUo),e(U,oUo),e(U,Av),e(Av,i1e),e(i1e,rUo),e(Av,tUo),e(Av,zQ),e(zQ,aUo),e(Av,nUo),e(U,sUo),e(U,Lv),e(Lv,d1e),e(d1e,lUo),e(Lv,iUo),e(Lv,QQ),e(QQ,dUo),e(Lv,cUo),e(U,mUo),e(U,yv),e(yv,c1e),e(c1e,fUo),e(yv,gUo),e(yv,WQ),e(WQ,hUo),e(yv,uUo),e(U,pUo),e(U,xv),e(xv,m1e),e(m1e,_Uo),e(xv,bUo),e(xv,UQ),e(UQ,vUo),e(xv,FUo),e(U,TUo),e(U,$v),e($v,f1e),e(f1e,MUo),e($v,EUo),e($v,HQ),e(HQ,CUo),e($v,wUo),e(U,AUo),e(U,kv),e(kv,g1e),e(g1e,LUo),e(kv,yUo),e(kv,JQ),e(JQ,xUo),e(kv,$Uo),e(U,kUo),e(U,Sv),e(Sv,h1e),e(h1e,SUo),e(Sv,RUo),e(Sv,YQ),e(YQ,PUo),e(Sv,BUo),e(U,IUo),e(U,Rv),e(Rv,u1e),e(u1e,NUo),e(Rv,qUo),e(Rv,p1e),e(p1e,jUo),e(Rv,DUo),e(U,GUo),e(U,Pv),e(Pv,_1e),e(_1e,OUo),e(Pv,VUo),e(Pv,KQ),e(KQ,XUo),e(Pv,zUo),e(U,QUo),e(U,Bv),e(Bv,b1e),e(b1e,WUo),e(Bv,UUo),e(Bv,ZQ),e(ZQ,HUo),e(Bv,JUo),e(U,YUo),e(U,Iv),e(Iv,v1e),e(v1e,KUo),e(Iv,ZUo),e(Iv,eW),e(eW,eHo),e(Iv,oHo),e(U,rHo),e(U,Nv),e(Nv,F1e),e(F1e,tHo),e(Nv,aHo),e(Nv,oW),e(oW,nHo),e(Nv,sHo),e(ro,lHo),e(ro,qv),e(qv,iHo),e(qv,T1e),e(T1e,dHo),e(qv,cHo),e(qv,M1e),e(M1e,mHo),e(ro,fHo),M(jv,ro,null),b(m,uKe,_),b(m,yd,_),e(yd,Dv),e(Dv,E1e),M(Fx,E1e,null),e(yd,gHo),e(yd,C1e),e(C1e,hHo),b(m,pKe,_),b(m,qo,_),M(Tx,qo,null),e(qo,uHo),e(qo,xd),e(xd,pHo),e(xd,rW),e(rW,_Ho),e(xd,bHo),e(xd,tW),e(tW,vHo),e(xd,FHo),e(qo,THo),e(qo,Mx),e(Mx,MHo),e(Mx,w1e),e(w1e,EHo),e(Mx,CHo),e(qo,wHo),e(qo,Tt),M(Ex,Tt,null),e(Tt,AHo),e(Tt,A1e),e(A1e,LHo),e(Tt,yHo),e(Tt,$d),e($d,xHo),e($d,L1e),e(L1e,$Ho),e($d,kHo),e($d,aW),e(aW,SHo),e($d,RHo),e(Tt,PHo),M(Gv,Tt,null),e(qo,BHo),e(qo,to),M(Cx,to,null),e(to,IHo),e(to,y1e),e(y1e,NHo),e(to,qHo),e(to,en),e(en,jHo),e(en,x1e),e(x1e,DHo),e(en,GHo),e(en,$1e),e($1e,OHo),e(en,VHo),e(en,k1e),e(k1e,XHo),e(en,zHo),e(to,QHo),e(to,me),e(me,Ov),e(Ov,S1e),e(S1e,WHo),e(Ov,UHo),e(Ov,nW),e(nW,HHo),e(Ov,JHo),e(me,YHo),e(me,Vv),e(Vv,R1e),e(R1e,KHo),e(Vv,ZHo),e(Vv,sW),e(sW,eJo),e(Vv,oJo),e(me,rJo),e(me,Xv),e(Xv,P1e),e(P1e,tJo),e(Xv,aJo),e(Xv,lW),e(lW,nJo),e(Xv,sJo),e(me,lJo),e(me,zv),e(zv,B1e),e(B1e,iJo),e(zv,dJo),e(zv,iW),e(iW,cJo),e(zv,mJo),e(me,fJo),e(me,Qv),e(Qv,I1e),e(I1e,gJo),e(Qv,hJo),e(Qv,dW),e(dW,uJo),e(Qv,pJo),e(me,_Jo),e(me,Wv),e(Wv,N1e),e(N1e,bJo),e(Wv,vJo),e(Wv,cW),e(cW,FJo),e(Wv,TJo),e(me,MJo),e(me,Uv),e(Uv,q1e),e(q1e,EJo),e(Uv,CJo),e(Uv,mW),e(mW,wJo),e(Uv,AJo),e(me,LJo),e(me,Hv),e(Hv,j1e),e(j1e,yJo),e(Hv,xJo),e(Hv,fW),e(fW,$Jo),e(Hv,kJo),e(me,SJo),e(me,Jv),e(Jv,D1e),e(D1e,RJo),e(Jv,PJo),e(Jv,gW),e(gW,BJo),e(Jv,IJo),e(me,NJo),e(me,Yv),e(Yv,G1e),e(G1e,qJo),e(Yv,jJo),e(Yv,hW),e(hW,DJo),e(Yv,GJo),e(me,OJo),e(me,Kv),e(Kv,O1e),e(O1e,VJo),e(Kv,XJo),e(Kv,uW),e(uW,zJo),e(Kv,QJo),e(me,WJo),e(me,Zv),e(Zv,V1e),e(V1e,UJo),e(Zv,HJo),e(Zv,pW),e(pW,JJo),e(Zv,YJo),e(me,KJo),e(me,eF),e(eF,X1e),e(X1e,ZJo),e(eF,eYo),e(eF,_W),e(_W,oYo),e(eF,rYo),e(me,tYo),e(me,oF),e(oF,z1e),e(z1e,aYo),e(oF,nYo),e(oF,bW),e(bW,sYo),e(oF,lYo),e(me,iYo),e(me,rF),e(rF,Q1e),e(Q1e,dYo),e(rF,cYo),e(rF,vW),e(vW,mYo),e(rF,fYo),e(me,gYo),e(me,tF),e(tF,W1e),e(W1e,hYo),e(tF,uYo),e(tF,FW),e(FW,pYo),e(tF,_Yo),e(me,bYo),e(me,aF),e(aF,U1e),e(U1e,vYo),e(aF,FYo),e(aF,TW),e(TW,TYo),e(aF,MYo),e(me,EYo),e(me,nF),e(nF,H1e),e(H1e,CYo),e(nF,wYo),e(nF,MW),e(MW,AYo),e(nF,LYo),e(me,yYo),e(me,sF),e(sF,J1e),e(J1e,xYo),e(sF,$Yo),e(sF,EW),e(EW,kYo),e(sF,SYo),e(me,RYo),e(me,lF),e(lF,Y1e),e(Y1e,PYo),e(lF,BYo),e(lF,CW),e(CW,IYo),e(lF,NYo),e(to,qYo),e(to,iF),e(iF,jYo),e(iF,K1e),e(K1e,DYo),e(iF,GYo),e(iF,Z1e),e(Z1e,OYo),e(to,VYo),M(dF,to,null),b(m,_Ke,_),b(m,kd,_),e(kd,cF),e(cF,eve),M(wx,eve,null),e(kd,XYo),e(kd,ove),e(ove,zYo),b(m,bKe,_),b(m,jo,_),M(Ax,jo,null),e(jo,QYo),e(jo,Sd),e(Sd,WYo),e(Sd,wW),e(wW,UYo),e(Sd,HYo),e(Sd,AW),e(AW,JYo),e(Sd,YYo),e(jo,KYo),e(jo,Lx),e(Lx,ZYo),e(Lx,rve),e(rve,eKo),e(Lx,oKo),e(jo,rKo),e(jo,Mt),M(yx,Mt,null),e(Mt,tKo),e(Mt,tve),e(tve,aKo),e(Mt,nKo),e(Mt,Rd),e(Rd,sKo),e(Rd,ave),e(ave,lKo),e(Rd,iKo),e(Rd,LW),e(LW,dKo),e(Rd,cKo),e(Mt,mKo),M(mF,Mt,null),e(jo,fKo),e(jo,ao),M(xx,ao,null),e(ao,gKo),e(ao,nve),e(nve,hKo),e(ao,uKo),e(ao,on),e(on,pKo),e(on,sve),e(sve,_Ko),e(on,bKo),e(on,lve),e(lve,vKo),e(on,FKo),e(on,ive),e(ive,TKo),e(on,MKo),e(ao,EKo),e(ao,q),e(q,fF),e(fF,dve),e(dve,CKo),e(fF,wKo),e(fF,yW),e(yW,AKo),e(fF,LKo),e(q,yKo),e(q,gF),e(gF,cve),e(cve,xKo),e(gF,$Ko),e(gF,xW),e(xW,kKo),e(gF,SKo),e(q,RKo),e(q,hF),e(hF,mve),e(mve,PKo),e(hF,BKo),e(hF,$W),e($W,IKo),e(hF,NKo),e(q,qKo),e(q,uF),e(uF,fve),e(fve,jKo),e(uF,DKo),e(uF,kW),e(kW,GKo),e(uF,OKo),e(q,VKo),e(q,pF),e(pF,gve),e(gve,XKo),e(pF,zKo),e(pF,SW),e(SW,QKo),e(pF,WKo),e(q,UKo),e(q,_F),e(_F,hve),e(hve,HKo),e(_F,JKo),e(_F,RW),e(RW,YKo),e(_F,KKo),e(q,ZKo),e(q,bF),e(bF,uve),e(uve,eZo),e(bF,oZo),e(bF,PW),e(PW,rZo),e(bF,tZo),e(q,aZo),e(q,vF),e(vF,pve),e(pve,nZo),e(vF,sZo),e(vF,BW),e(BW,lZo),e(vF,iZo),e(q,dZo),e(q,FF),e(FF,_ve),e(_ve,cZo),e(FF,mZo),e(FF,IW),e(IW,fZo),e(FF,gZo),e(q,hZo),e(q,TF),e(TF,bve),e(bve,uZo),e(TF,pZo),e(TF,NW),e(NW,_Zo),e(TF,bZo),e(q,vZo),e(q,MF),e(MF,vve),e(vve,FZo),e(MF,TZo),e(MF,qW),e(qW,MZo),e(MF,EZo),e(q,CZo),e(q,EF),e(EF,Fve),e(Fve,wZo),e(EF,AZo),e(EF,jW),e(jW,LZo),e(EF,yZo),e(q,xZo),e(q,CF),e(CF,Tve),e(Tve,$Zo),e(CF,kZo),e(CF,DW),e(DW,SZo),e(CF,RZo),e(q,PZo),e(q,wF),e(wF,Mve),e(Mve,BZo),e(wF,IZo),e(wF,GW),e(GW,NZo),e(wF,qZo),e(q,jZo),e(q,AF),e(AF,Eve),e(Eve,DZo),e(AF,GZo),e(AF,OW),e(OW,OZo),e(AF,VZo),e(q,XZo),e(q,LF),e(LF,Cve),e(Cve,zZo),e(LF,QZo),e(LF,VW),e(VW,WZo),e(LF,UZo),e(q,HZo),e(q,yF),e(yF,wve),e(wve,JZo),e(yF,YZo),e(yF,XW),e(XW,KZo),e(yF,ZZo),e(q,eer),e(q,xF),e(xF,Ave),e(Ave,oer),e(xF,rer),e(xF,zW),e(zW,ter),e(xF,aer),e(q,ner),e(q,$F),e($F,Lve),e(Lve,ser),e($F,ler),e($F,QW),e(QW,ier),e($F,der),e(q,cer),e(q,kF),e(kF,yve),e(yve,mer),e(kF,fer),e(kF,WW),e(WW,ger),e(kF,her),e(q,uer),e(q,SF),e(SF,xve),e(xve,per),e(SF,_er),e(SF,UW),e(UW,ber),e(SF,ver),e(q,Fer),e(q,RF),e(RF,$ve),e($ve,Ter),e(RF,Mer),e(RF,HW),e(HW,Eer),e(RF,Cer),e(q,wer),e(q,PF),e(PF,kve),e(kve,Aer),e(PF,Ler),e(PF,JW),e(JW,yer),e(PF,xer),e(q,$er),e(q,BF),e(BF,Sve),e(Sve,ker),e(BF,Ser),e(BF,YW),e(YW,Rer),e(BF,Per),e(q,Ber),e(q,IF),e(IF,Rve),e(Rve,Ier),e(IF,Ner),e(IF,KW),e(KW,qer),e(IF,jer),e(q,Der),e(q,NF),e(NF,Pve),e(Pve,Ger),e(NF,Oer),e(NF,ZW),e(ZW,Ver),e(NF,Xer),e(q,zer),e(q,qF),e(qF,Bve),e(Bve,Qer),e(qF,Wer),e(qF,eU),e(eU,Uer),e(qF,Her),e(q,Jer),e(q,jF),e(jF,Ive),e(Ive,Yer),e(jF,Ker),e(jF,oU),e(oU,Zer),e(jF,eor),e(q,oor),e(q,DF),e(DF,Nve),e(Nve,ror),e(DF,tor),e(DF,rU),e(rU,aor),e(DF,nor),e(q,sor),e(q,GF),e(GF,qve),e(qve,lor),e(GF,ior),e(GF,tU),e(tU,dor),e(GF,cor),e(q,mor),e(q,OF),e(OF,jve),e(jve,gor),e(OF,hor),e(OF,aU),e(aU,uor),e(OF,por),e(q,_or),e(q,VF),e(VF,Dve),e(Dve,bor),e(VF,vor),e(VF,nU),e(nU,For),e(VF,Tor),e(q,Mor),e(q,XF),e(XF,Gve),e(Gve,Eor),e(XF,Cor),e(XF,sU),e(sU,wor),e(XF,Aor),e(q,Lor),e(q,zF),e(zF,Ove),e(Ove,yor),e(zF,xor),e(zF,lU),e(lU,$or),e(zF,kor),e(q,Sor),e(q,QF),e(QF,Vve),e(Vve,Ror),e(QF,Por),e(QF,iU),e(iU,Bor),e(QF,Ior),e(q,Nor),e(q,WF),e(WF,Xve),e(Xve,qor),e(WF,jor),e(WF,dU),e(dU,Dor),e(WF,Gor),e(q,Oor),e(q,UF),e(UF,zve),e(zve,Vor),e(UF,Xor),e(UF,cU),e(cU,zor),e(UF,Qor),e(q,Wor),e(q,HF),e(HF,Qve),e(Qve,Uor),e(HF,Hor),e(HF,mU),e(mU,Jor),e(HF,Yor),e(q,Kor),e(q,JF),e(JF,Wve),e(Wve,Zor),e(JF,err),e(JF,fU),e(fU,orr),e(JF,rrr),e(q,trr),e(q,YF),e(YF,Uve),e(Uve,arr),e(YF,nrr),e(YF,gU),e(gU,srr),e(YF,lrr),e(q,irr),e(q,KF),e(KF,Hve),e(Hve,drr),e(KF,crr),e(KF,hU),e(hU,mrr),e(KF,frr),e(q,grr),e(q,ZF),e(ZF,Jve),e(Jve,hrr),e(ZF,urr),e(ZF,uU),e(uU,prr),e(ZF,_rr),e(q,brr),e(q,eT),e(eT,Yve),e(Yve,vrr),e(eT,Frr),e(eT,pU),e(pU,Trr),e(eT,Mrr),e(q,Err),e(q,oT),e(oT,Kve),e(Kve,Crr),e(oT,wrr),e(oT,_U),e(_U,Arr),e(oT,Lrr),e(q,yrr),e(q,rT),e(rT,Zve),e(Zve,xrr),e(rT,$rr),e(rT,bU),e(bU,krr),e(rT,Srr),e(q,Rrr),e(q,tT),e(tT,eFe),e(eFe,Prr),e(tT,Brr),e(tT,vU),e(vU,Irr),e(tT,Nrr),e(q,qrr),e(q,aT),e(aT,oFe),e(oFe,jrr),e(aT,Drr),e(aT,FU),e(FU,Grr),e(aT,Orr),e(q,Vrr),e(q,nT),e(nT,rFe),e(rFe,Xrr),e(nT,zrr),e(nT,TU),e(TU,Qrr),e(nT,Wrr),e(q,Urr),e(q,sT),e(sT,tFe),e(tFe,Hrr),e(sT,Jrr),e(sT,MU),e(MU,Yrr),e(sT,Krr),e(q,Zrr),e(q,lT),e(lT,aFe),e(aFe,etr),e(lT,otr),e(lT,EU),e(EU,rtr),e(lT,ttr),e(q,atr),e(q,iT),e(iT,nFe),e(nFe,ntr),e(iT,str),e(iT,CU),e(CU,ltr),e(iT,itr),e(q,dtr),e(q,dT),e(dT,sFe),e(sFe,ctr),e(dT,mtr),e(dT,wU),e(wU,ftr),e(dT,gtr),e(q,htr),e(q,cT),e(cT,lFe),e(lFe,utr),e(cT,ptr),e(cT,AU),e(AU,_tr),e(cT,btr),e(ao,vtr),e(ao,mT),e(mT,Ftr),e(mT,iFe),e(iFe,Ttr),e(mT,Mtr),e(mT,dFe),e(dFe,Etr),e(ao,Ctr),M(fT,ao,null),b(m,vKe,_),b(m,Pd,_),e(Pd,gT),e(gT,cFe),M($x,cFe,null),e(Pd,wtr),e(Pd,mFe),e(mFe,Atr),b(m,FKe,_),b(m,Do,_),M(kx,Do,null),e(Do,Ltr),e(Do,Bd),e(Bd,ytr),e(Bd,LU),e(LU,xtr),e(Bd,$tr),e(Bd,yU),e(yU,ktr),e(Bd,Str),e(Do,Rtr),e(Do,Sx),e(Sx,Ptr),e(Sx,fFe),e(fFe,Btr),e(Sx,Itr),e(Do,Ntr),e(Do,Et),M(Rx,Et,null),e(Et,qtr),e(Et,gFe),e(gFe,jtr),e(Et,Dtr),e(Et,Id),e(Id,Gtr),e(Id,hFe),e(hFe,Otr),e(Id,Vtr),e(Id,xU),e(xU,Xtr),e(Id,ztr),e(Et,Qtr),M(hT,Et,null),e(Do,Wtr),e(Do,no),M(Px,no,null),e(no,Utr),e(no,uFe),e(uFe,Htr),e(no,Jtr),e(no,rn),e(rn,Ytr),e(rn,pFe),e(pFe,Ktr),e(rn,Ztr),e(rn,_Fe),e(_Fe,ear),e(rn,oar),e(rn,bFe),e(bFe,rar),e(rn,tar),e(no,aar),e(no,Z),e(Z,uT),e(uT,vFe),e(vFe,nar),e(uT,sar),e(uT,$U),e($U,lar),e(uT,iar),e(Z,dar),e(Z,pT),e(pT,FFe),e(FFe,car),e(pT,mar),e(pT,kU),e(kU,far),e(pT,gar),e(Z,har),e(Z,_T),e(_T,TFe),e(TFe,uar),e(_T,par),e(_T,SU),e(SU,_ar),e(_T,bar),e(Z,Far),e(Z,bT),e(bT,MFe),e(MFe,Tar),e(bT,Mar),e(bT,RU),e(RU,Ear),e(bT,Car),e(Z,war),e(Z,vT),e(vT,EFe),e(EFe,Aar),e(vT,Lar),e(vT,PU),e(PU,yar),e(vT,xar),e(Z,$ar),e(Z,FT),e(FT,CFe),e(CFe,kar),e(FT,Sar),e(FT,BU),e(BU,Rar),e(FT,Par),e(Z,Bar),e(Z,TT),e(TT,wFe),e(wFe,Iar),e(TT,Nar),e(TT,IU),e(IU,qar),e(TT,jar),e(Z,Dar),e(Z,MT),e(MT,AFe),e(AFe,Gar),e(MT,Oar),e(MT,NU),e(NU,Var),e(MT,Xar),e(Z,zar),e(Z,ET),e(ET,LFe),e(LFe,Qar),e(ET,War),e(ET,qU),e(qU,Uar),e(ET,Har),e(Z,Jar),e(Z,CT),e(CT,yFe),e(yFe,Yar),e(CT,Kar),e(CT,jU),e(jU,Zar),e(CT,enr),e(Z,onr),e(Z,wT),e(wT,xFe),e(xFe,rnr),e(wT,tnr),e(wT,DU),e(DU,anr),e(wT,nnr),e(Z,snr),e(Z,AT),e(AT,$Fe),e($Fe,lnr),e(AT,inr),e(AT,GU),e(GU,dnr),e(AT,cnr),e(Z,mnr),e(Z,LT),e(LT,kFe),e(kFe,fnr),e(LT,gnr),e(LT,OU),e(OU,hnr),e(LT,unr),e(Z,pnr),e(Z,yT),e(yT,SFe),e(SFe,_nr),e(yT,bnr),e(yT,VU),e(VU,vnr),e(yT,Fnr),e(Z,Tnr),e(Z,xT),e(xT,RFe),e(RFe,Mnr),e(xT,Enr),e(xT,XU),e(XU,Cnr),e(xT,wnr),e(Z,Anr),e(Z,$T),e($T,PFe),e(PFe,Lnr),e($T,ynr),e($T,zU),e(zU,xnr),e($T,$nr),e(Z,knr),e(Z,kT),e(kT,BFe),e(BFe,Snr),e(kT,Rnr),e(kT,QU),e(QU,Pnr),e(kT,Bnr),e(Z,Inr),e(Z,ST),e(ST,IFe),e(IFe,Nnr),e(ST,qnr),e(ST,WU),e(WU,jnr),e(ST,Dnr),e(Z,Gnr),e(Z,RT),e(RT,NFe),e(NFe,Onr),e(RT,Vnr),e(RT,UU),e(UU,Xnr),e(RT,znr),e(Z,Qnr),e(Z,PT),e(PT,qFe),e(qFe,Wnr),e(PT,Unr),e(PT,HU),e(HU,Hnr),e(PT,Jnr),e(Z,Ynr),e(Z,BT),e(BT,jFe),e(jFe,Knr),e(BT,Znr),e(BT,JU),e(JU,esr),e(BT,osr),e(Z,rsr),e(Z,IT),e(IT,DFe),e(DFe,tsr),e(IT,asr),e(IT,YU),e(YU,nsr),e(IT,ssr),e(Z,lsr),e(Z,NT),e(NT,GFe),e(GFe,isr),e(NT,dsr),e(NT,KU),e(KU,csr),e(NT,msr),e(Z,fsr),e(Z,qT),e(qT,OFe),e(OFe,gsr),e(qT,hsr),e(qT,ZU),e(ZU,usr),e(qT,psr),e(Z,_sr),e(Z,jT),e(jT,VFe),e(VFe,bsr),e(jT,vsr),e(jT,eH),e(eH,Fsr),e(jT,Tsr),e(Z,Msr),e(Z,DT),e(DT,XFe),e(XFe,Esr),e(DT,Csr),e(DT,oH),e(oH,wsr),e(DT,Asr),e(Z,Lsr),e(Z,GT),e(GT,zFe),e(zFe,ysr),e(GT,xsr),e(GT,rH),e(rH,$sr),e(GT,ksr),e(Z,Ssr),e(Z,OT),e(OT,QFe),e(QFe,Rsr),e(OT,Psr),e(OT,tH),e(tH,Bsr),e(OT,Isr),e(Z,Nsr),e(Z,VT),e(VT,WFe),e(WFe,qsr),e(VT,jsr),e(VT,aH),e(aH,Dsr),e(VT,Gsr),e(Z,Osr),e(Z,XT),e(XT,UFe),e(UFe,Vsr),e(XT,Xsr),e(XT,nH),e(nH,zsr),e(XT,Qsr),e(Z,Wsr),e(Z,zT),e(zT,HFe),e(HFe,Usr),e(zT,Hsr),e(zT,sH),e(sH,Jsr),e(zT,Ysr),e(Z,Ksr),e(Z,QT),e(QT,JFe),e(JFe,Zsr),e(QT,elr),e(QT,lH),e(lH,olr),e(QT,rlr),e(no,tlr),e(no,WT),e(WT,alr),e(WT,YFe),e(YFe,nlr),e(WT,slr),e(WT,KFe),e(KFe,llr),e(no,ilr),M(UT,no,null),b(m,TKe,_),b(m,Nd,_),e(Nd,HT),e(HT,ZFe),M(Bx,ZFe,null),e(Nd,dlr),e(Nd,eTe),e(eTe,clr),b(m,MKe,_),b(m,Go,_),M(Ix,Go,null),e(Go,mlr),e(Go,qd),e(qd,flr),e(qd,iH),e(iH,glr),e(qd,hlr),e(qd,dH),e(dH,ulr),e(qd,plr),e(Go,_lr),e(Go,Nx),e(Nx,blr),e(Nx,oTe),e(oTe,vlr),e(Nx,Flr),e(Go,Tlr),e(Go,Ct),M(qx,Ct,null),e(Ct,Mlr),e(Ct,rTe),e(rTe,Elr),e(Ct,Clr),e(Ct,jd),e(jd,wlr),e(jd,tTe),e(tTe,Alr),e(jd,Llr),e(jd,cH),e(cH,ylr),e(jd,xlr),e(Ct,$lr),M(JT,Ct,null),e(Go,klr),e(Go,so),M(jx,so,null),e(so,Slr),e(so,aTe),e(aTe,Rlr),e(so,Plr),e(so,tn),e(tn,Blr),e(tn,nTe),e(nTe,Ilr),e(tn,Nlr),e(tn,sTe),e(sTe,qlr),e(tn,jlr),e(tn,lTe),e(lTe,Dlr),e(tn,Glr),e(so,Olr),e(so,Ue),e(Ue,YT),e(YT,iTe),e(iTe,Vlr),e(YT,Xlr),e(YT,mH),e(mH,zlr),e(YT,Qlr),e(Ue,Wlr),e(Ue,KT),e(KT,dTe),e(dTe,Ulr),e(KT,Hlr),e(KT,fH),e(fH,Jlr),e(KT,Ylr),e(Ue,Klr),e(Ue,ZT),e(ZT,cTe),e(cTe,Zlr),e(ZT,eir),e(ZT,gH),e(gH,oir),e(ZT,rir),e(Ue,tir),e(Ue,eM),e(eM,mTe),e(mTe,air),e(eM,nir),e(eM,hH),e(hH,sir),e(eM,lir),e(Ue,iir),e(Ue,oM),e(oM,fTe),e(fTe,dir),e(oM,cir),e(oM,uH),e(uH,mir),e(oM,fir),e(Ue,gir),e(Ue,rM),e(rM,gTe),e(gTe,hir),e(rM,uir),e(rM,pH),e(pH,pir),e(rM,_ir),e(Ue,bir),e(Ue,tM),e(tM,hTe),e(hTe,vir),e(tM,Fir),e(tM,_H),e(_H,Tir),e(tM,Mir),e(so,Eir),e(so,aM),e(aM,Cir),e(aM,uTe),e(uTe,wir),e(aM,Air),e(aM,pTe),e(pTe,Lir),e(so,yir),M(nM,so,null),b(m,EKe,_),b(m,Dd,_),e(Dd,sM),e(sM,_Te),M(Dx,_Te,null),e(Dd,xir),e(Dd,bTe),e(bTe,$ir),b(m,CKe,_),b(m,Oo,_),M(Gx,Oo,null),e(Oo,kir),e(Oo,Gd),e(Gd,Sir),e(Gd,bH),e(bH,Rir),e(Gd,Pir),e(Gd,vH),e(vH,Bir),e(Gd,Iir),e(Oo,Nir),e(Oo,Ox),e(Ox,qir),e(Ox,vTe),e(vTe,jir),e(Ox,Dir),e(Oo,Gir),e(Oo,wt),M(Vx,wt,null),e(wt,Oir),e(wt,FTe),e(FTe,Vir),e(wt,Xir),e(wt,Od),e(Od,zir),e(Od,TTe),e(TTe,Qir),e(Od,Wir),e(Od,FH),e(FH,Uir),e(Od,Hir),e(wt,Jir),M(lM,wt,null),e(Oo,Yir),e(Oo,lo),M(Xx,lo,null),e(lo,Kir),e(lo,MTe),e(MTe,Zir),e(lo,edr),e(lo,an),e(an,odr),e(an,ETe),e(ETe,rdr),e(an,tdr),e(an,CTe),e(CTe,adr),e(an,ndr),e(an,wTe),e(wTe,sdr),e(an,ldr),e(lo,idr),e(lo,J),e(J,iM),e(iM,ATe),e(ATe,ddr),e(iM,cdr),e(iM,TH),e(TH,mdr),e(iM,fdr),e(J,gdr),e(J,dM),e(dM,LTe),e(LTe,hdr),e(dM,udr),e(dM,MH),e(MH,pdr),e(dM,_dr),e(J,bdr),e(J,cM),e(cM,yTe),e(yTe,vdr),e(cM,Fdr),e(cM,EH),e(EH,Tdr),e(cM,Mdr),e(J,Edr),e(J,mM),e(mM,xTe),e(xTe,Cdr),e(mM,wdr),e(mM,CH),e(CH,Adr),e(mM,Ldr),e(J,ydr),e(J,fM),e(fM,$Te),e($Te,xdr),e(fM,$dr),e(fM,wH),e(wH,kdr),e(fM,Sdr),e(J,Rdr),e(J,gM),e(gM,kTe),e(kTe,Pdr),e(gM,Bdr),e(gM,AH),e(AH,Idr),e(gM,Ndr),e(J,qdr),e(J,hM),e(hM,STe),e(STe,jdr),e(hM,Ddr),e(hM,LH),e(LH,Gdr),e(hM,Odr),e(J,Vdr),e(J,uM),e(uM,RTe),e(RTe,Xdr),e(uM,zdr),e(uM,yH),e(yH,Qdr),e(uM,Wdr),e(J,Udr),e(J,pM),e(pM,PTe),e(PTe,Hdr),e(pM,Jdr),e(pM,xH),e(xH,Ydr),e(pM,Kdr),e(J,Zdr),e(J,_M),e(_M,BTe),e(BTe,ecr),e(_M,ocr),e(_M,$H),e($H,rcr),e(_M,tcr),e(J,acr),e(J,bM),e(bM,ITe),e(ITe,ncr),e(bM,scr),e(bM,kH),e(kH,lcr),e(bM,icr),e(J,dcr),e(J,vM),e(vM,NTe),e(NTe,ccr),e(vM,mcr),e(vM,SH),e(SH,fcr),e(vM,gcr),e(J,hcr),e(J,FM),e(FM,qTe),e(qTe,ucr),e(FM,pcr),e(FM,RH),e(RH,_cr),e(FM,bcr),e(J,vcr),e(J,TM),e(TM,jTe),e(jTe,Fcr),e(TM,Tcr),e(TM,PH),e(PH,Mcr),e(TM,Ecr),e(J,Ccr),e(J,MM),e(MM,DTe),e(DTe,wcr),e(MM,Acr),e(MM,BH),e(BH,Lcr),e(MM,ycr),e(J,xcr),e(J,EM),e(EM,GTe),e(GTe,$cr),e(EM,kcr),e(EM,IH),e(IH,Scr),e(EM,Rcr),e(J,Pcr),e(J,CM),e(CM,OTe),e(OTe,Bcr),e(CM,Icr),e(CM,NH),e(NH,Ncr),e(CM,qcr),e(J,jcr),e(J,wM),e(wM,VTe),e(VTe,Dcr),e(wM,Gcr),e(wM,qH),e(qH,Ocr),e(wM,Vcr),e(J,Xcr),e(J,AM),e(AM,XTe),e(XTe,zcr),e(AM,Qcr),e(AM,jH),e(jH,Wcr),e(AM,Ucr),e(J,Hcr),e(J,LM),e(LM,zTe),e(zTe,Jcr),e(LM,Ycr),e(LM,DH),e(DH,Kcr),e(LM,Zcr),e(J,emr),e(J,yM),e(yM,QTe),e(QTe,omr),e(yM,rmr),e(yM,GH),e(GH,tmr),e(yM,amr),e(J,nmr),e(J,xM),e(xM,WTe),e(WTe,smr),e(xM,lmr),e(xM,OH),e(OH,imr),e(xM,dmr),e(J,cmr),e(J,$M),e($M,UTe),e(UTe,mmr),e($M,fmr),e($M,VH),e(VH,gmr),e($M,hmr),e(J,umr),e(J,kM),e(kM,HTe),e(HTe,pmr),e(kM,_mr),e(kM,XH),e(XH,bmr),e(kM,vmr),e(J,Fmr),e(J,SM),e(SM,JTe),e(JTe,Tmr),e(SM,Mmr),e(SM,zH),e(zH,Emr),e(SM,Cmr),e(J,wmr),e(J,RM),e(RM,YTe),e(YTe,Amr),e(RM,Lmr),e(RM,QH),e(QH,ymr),e(RM,xmr),e(J,$mr),e(J,PM),e(PM,KTe),e(KTe,kmr),e(PM,Smr),e(PM,WH),e(WH,Rmr),e(PM,Pmr),e(J,Bmr),e(J,BM),e(BM,ZTe),e(ZTe,Imr),e(BM,Nmr),e(BM,UH),e(UH,qmr),e(BM,jmr),e(J,Dmr),e(J,IM),e(IM,eMe),e(eMe,Gmr),e(IM,Omr),e(IM,HH),e(HH,Vmr),e(IM,Xmr),e(J,zmr),e(J,NM),e(NM,oMe),e(oMe,Qmr),e(NM,Wmr),e(NM,JH),e(JH,Umr),e(NM,Hmr),e(J,Jmr),e(J,qM),e(qM,rMe),e(rMe,Ymr),e(qM,Kmr),e(qM,YH),e(YH,Zmr),e(qM,efr),e(J,ofr),e(J,jM),e(jM,tMe),e(tMe,rfr),e(jM,tfr),e(jM,KH),e(KH,afr),e(jM,nfr),e(J,sfr),e(J,DM),e(DM,aMe),e(aMe,lfr),e(DM,ifr),e(DM,ZH),e(ZH,dfr),e(DM,cfr),e(J,mfr),e(J,GM),e(GM,nMe),e(nMe,ffr),e(GM,gfr),e(GM,eJ),e(eJ,hfr),e(GM,ufr),e(J,pfr),e(J,OM),e(OM,sMe),e(sMe,_fr),e(OM,bfr),e(OM,oJ),e(oJ,vfr),e(OM,Ffr),e(J,Tfr),e(J,VM),e(VM,lMe),e(lMe,Mfr),e(VM,Efr),e(VM,rJ),e(rJ,Cfr),e(VM,wfr),e(J,Afr),e(J,XM),e(XM,iMe),e(iMe,Lfr),e(XM,yfr),e(XM,tJ),e(tJ,xfr),e(XM,$fr),e(J,kfr),e(J,zM),e(zM,dMe),e(dMe,Sfr),e(zM,Rfr),e(zM,aJ),e(aJ,Pfr),e(zM,Bfr),e(lo,Ifr),e(lo,QM),e(QM,Nfr),e(QM,cMe),e(cMe,qfr),e(QM,jfr),e(QM,mMe),e(mMe,Dfr),e(lo,Gfr),M(WM,lo,null),b(m,wKe,_),b(m,Vd,_),e(Vd,UM),e(UM,fMe),M(zx,fMe,null),e(Vd,Ofr),e(Vd,gMe),e(gMe,Vfr),b(m,AKe,_),b(m,Vo,_),M(Qx,Vo,null),e(Vo,Xfr),e(Vo,Xd),e(Xd,zfr),e(Xd,nJ),e(nJ,Qfr),e(Xd,Wfr),e(Xd,sJ),e(sJ,Ufr),e(Xd,Hfr),e(Vo,Jfr),e(Vo,Wx),e(Wx,Yfr),e(Wx,hMe),e(hMe,Kfr),e(Wx,Zfr),e(Vo,egr),e(Vo,At),M(Ux,At,null),e(At,ogr),e(At,uMe),e(uMe,rgr),e(At,tgr),e(At,zd),e(zd,agr),e(zd,pMe),e(pMe,ngr),e(zd,sgr),e(zd,lJ),e(lJ,lgr),e(zd,igr),e(At,dgr),M(HM,At,null),e(Vo,cgr),e(Vo,io),M(Hx,io,null),e(io,mgr),e(io,_Me),e(_Me,fgr),e(io,ggr),e(io,nn),e(nn,hgr),e(nn,bMe),e(bMe,ugr),e(nn,pgr),e(nn,vMe),e(vMe,_gr),e(nn,bgr),e(nn,FMe),e(FMe,vgr),e(nn,Fgr),e(io,Tgr),e(io,V),e(V,JM),e(JM,TMe),e(TMe,Mgr),e(JM,Egr),e(JM,iJ),e(iJ,Cgr),e(JM,wgr),e(V,Agr),e(V,YM),e(YM,MMe),e(MMe,Lgr),e(YM,ygr),e(YM,dJ),e(dJ,xgr),e(YM,$gr),e(V,kgr),e(V,KM),e(KM,EMe),e(EMe,Sgr),e(KM,Rgr),e(KM,cJ),e(cJ,Pgr),e(KM,Bgr),e(V,Igr),e(V,ZM),e(ZM,CMe),e(CMe,Ngr),e(ZM,qgr),e(ZM,mJ),e(mJ,jgr),e(ZM,Dgr),e(V,Ggr),e(V,eE),e(eE,wMe),e(wMe,Ogr),e(eE,Vgr),e(eE,fJ),e(fJ,Xgr),e(eE,zgr),e(V,Qgr),e(V,oE),e(oE,AMe),e(AMe,Wgr),e(oE,Ugr),e(oE,gJ),e(gJ,Hgr),e(oE,Jgr),e(V,Ygr),e(V,rE),e(rE,LMe),e(LMe,Kgr),e(rE,Zgr),e(rE,hJ),e(hJ,ehr),e(rE,ohr),e(V,rhr),e(V,tE),e(tE,yMe),e(yMe,thr),e(tE,ahr),e(tE,uJ),e(uJ,nhr),e(tE,shr),e(V,lhr),e(V,aE),e(aE,xMe),e(xMe,ihr),e(aE,dhr),e(aE,pJ),e(pJ,chr),e(aE,mhr),e(V,fhr),e(V,nE),e(nE,$Me),e($Me,ghr),e(nE,hhr),e(nE,_J),e(_J,uhr),e(nE,phr),e(V,_hr),e(V,sE),e(sE,kMe),e(kMe,bhr),e(sE,vhr),e(sE,bJ),e(bJ,Fhr),e(sE,Thr),e(V,Mhr),e(V,lE),e(lE,SMe),e(SMe,Ehr),e(lE,Chr),e(lE,vJ),e(vJ,whr),e(lE,Ahr),e(V,Lhr),e(V,iE),e(iE,RMe),e(RMe,yhr),e(iE,xhr),e(iE,FJ),e(FJ,$hr),e(iE,khr),e(V,Shr),e(V,dE),e(dE,PMe),e(PMe,Rhr),e(dE,Phr),e(dE,TJ),e(TJ,Bhr),e(dE,Ihr),e(V,Nhr),e(V,cE),e(cE,BMe),e(BMe,qhr),e(cE,jhr),e(cE,MJ),e(MJ,Dhr),e(cE,Ghr),e(V,Ohr),e(V,mE),e(mE,IMe),e(IMe,Vhr),e(mE,Xhr),e(mE,EJ),e(EJ,zhr),e(mE,Qhr),e(V,Whr),e(V,fE),e(fE,NMe),e(NMe,Uhr),e(fE,Hhr),e(fE,CJ),e(CJ,Jhr),e(fE,Yhr),e(V,Khr),e(V,gE),e(gE,qMe),e(qMe,Zhr),e(gE,eur),e(gE,wJ),e(wJ,our),e(gE,rur),e(V,tur),e(V,hE),e(hE,jMe),e(jMe,aur),e(hE,nur),e(hE,AJ),e(AJ,sur),e(hE,lur),e(V,iur),e(V,uE),e(uE,DMe),e(DMe,dur),e(uE,cur),e(uE,LJ),e(LJ,mur),e(uE,fur),e(V,gur),e(V,pE),e(pE,GMe),e(GMe,hur),e(pE,uur),e(pE,yJ),e(yJ,pur),e(pE,_ur),e(V,bur),e(V,_E),e(_E,OMe),e(OMe,vur),e(_E,Fur),e(_E,xJ),e(xJ,Tur),e(_E,Mur),e(V,Eur),e(V,bE),e(bE,VMe),e(VMe,Cur),e(bE,wur),e(bE,$J),e($J,Aur),e(bE,Lur),e(V,yur),e(V,vE),e(vE,XMe),e(XMe,xur),e(vE,$ur),e(vE,kJ),e(kJ,kur),e(vE,Sur),e(V,Rur),e(V,FE),e(FE,zMe),e(zMe,Pur),e(FE,Bur),e(FE,SJ),e(SJ,Iur),e(FE,Nur),e(V,qur),e(V,TE),e(TE,QMe),e(QMe,jur),e(TE,Dur),e(TE,RJ),e(RJ,Gur),e(TE,Our),e(V,Vur),e(V,ME),e(ME,WMe),e(WMe,Xur),e(ME,zur),e(ME,PJ),e(PJ,Qur),e(ME,Wur),e(V,Uur),e(V,EE),e(EE,UMe),e(UMe,Hur),e(EE,Jur),e(EE,BJ),e(BJ,Yur),e(EE,Kur),e(V,Zur),e(V,CE),e(CE,HMe),e(HMe,epr),e(CE,opr),e(CE,IJ),e(IJ,rpr),e(CE,tpr),e(V,apr),e(V,wE),e(wE,JMe),e(JMe,npr),e(wE,spr),e(wE,NJ),e(NJ,lpr),e(wE,ipr),e(V,dpr),e(V,AE),e(AE,YMe),e(YMe,cpr),e(AE,mpr),e(AE,qJ),e(qJ,fpr),e(AE,gpr),e(V,hpr),e(V,LE),e(LE,KMe),e(KMe,upr),e(LE,ppr),e(LE,jJ),e(jJ,_pr),e(LE,bpr),e(V,vpr),e(V,yE),e(yE,ZMe),e(ZMe,Fpr),e(yE,Tpr),e(yE,DJ),e(DJ,Mpr),e(yE,Epr),e(V,Cpr),e(V,xE),e(xE,eEe),e(eEe,wpr),e(xE,Apr),e(xE,GJ),e(GJ,Lpr),e(xE,ypr),e(V,xpr),e(V,$E),e($E,oEe),e(oEe,$pr),e($E,kpr),e($E,OJ),e(OJ,Spr),e($E,Rpr),e(V,Ppr),e(V,kE),e(kE,rEe),e(rEe,Bpr),e(kE,Ipr),e(kE,VJ),e(VJ,Npr),e(kE,qpr),e(V,jpr),e(V,SE),e(SE,tEe),e(tEe,Dpr),e(SE,Gpr),e(SE,XJ),e(XJ,Opr),e(SE,Vpr),e(V,Xpr),e(V,RE),e(RE,aEe),e(aEe,zpr),e(RE,Qpr),e(RE,zJ),e(zJ,Wpr),e(RE,Upr),e(V,Hpr),e(V,PE),e(PE,nEe),e(nEe,Jpr),e(PE,Ypr),e(PE,QJ),e(QJ,Kpr),e(PE,Zpr),e(V,e_r),e(V,BE),e(BE,sEe),e(sEe,o_r),e(BE,r_r),e(BE,WJ),e(WJ,t_r),e(BE,a_r),e(V,n_r),e(V,IE),e(IE,lEe),e(lEe,s_r),e(IE,l_r),e(IE,UJ),e(UJ,i_r),e(IE,d_r),e(V,c_r),e(V,NE),e(NE,iEe),e(iEe,m_r),e(NE,f_r),e(NE,HJ),e(HJ,g_r),e(NE,h_r),e(V,u_r),e(V,qE),e(qE,dEe),e(dEe,p_r),e(qE,__r),e(qE,JJ),e(JJ,b_r),e(qE,v_r),e(V,F_r),e(V,jE),e(jE,cEe),e(cEe,T_r),e(jE,M_r),e(jE,YJ),e(YJ,E_r),e(jE,C_r),e(io,w_r),e(io,DE),e(DE,A_r),e(DE,mEe),e(mEe,L_r),e(DE,y_r),e(DE,fEe),e(fEe,x_r),e(io,$_r),M(GE,io,null),b(m,LKe,_),b(m,Qd,_),e(Qd,OE),e(OE,gEe),M(Jx,gEe,null),e(Qd,k_r),e(Qd,hEe),e(hEe,S_r),b(m,yKe,_),b(m,Xo,_),M(Yx,Xo,null),e(Xo,R_r),e(Xo,Wd),e(Wd,P_r),e(Wd,KJ),e(KJ,B_r),e(Wd,I_r),e(Wd,ZJ),e(ZJ,N_r),e(Wd,q_r),e(Xo,j_r),e(Xo,Kx),e(Kx,D_r),e(Kx,uEe),e(uEe,G_r),e(Kx,O_r),e(Xo,V_r),e(Xo,Lt),M(Zx,Lt,null),e(Lt,X_r),e(Lt,pEe),e(pEe,z_r),e(Lt,Q_r),e(Lt,Ud),e(Ud,W_r),e(Ud,_Ee),e(_Ee,U_r),e(Ud,H_r),e(Ud,eY),e(eY,J_r),e(Ud,Y_r),e(Lt,K_r),M(VE,Lt,null),e(Xo,Z_r),e(Xo,co),M(e$,co,null),e(co,ebr),e(co,bEe),e(bEe,obr),e(co,rbr),e(co,sn),e(sn,tbr),e(sn,vEe),e(vEe,abr),e(sn,nbr),e(sn,FEe),e(FEe,sbr),e(sn,lbr),e(sn,TEe),e(TEe,ibr),e(sn,dbr),e(co,cbr),e(co,MEe),e(MEe,XE),e(XE,EEe),e(EEe,mbr),e(XE,fbr),e(XE,oY),e(oY,gbr),e(XE,hbr),e(co,ubr),e(co,zE),e(zE,pbr),e(zE,CEe),e(CEe,_br),e(zE,bbr),e(zE,wEe),e(wEe,vbr),e(co,Fbr),M(QE,co,null),b(m,xKe,_),b(m,Hd,_),e(Hd,WE),e(WE,AEe),M(o$,AEe,null),e(Hd,Tbr),e(Hd,LEe),e(LEe,Mbr),b(m,$Ke,_),b(m,zo,_),M(r$,zo,null),e(zo,Ebr),e(zo,Jd),e(Jd,Cbr),e(Jd,rY),e(rY,wbr),e(Jd,Abr),e(Jd,tY),e(tY,Lbr),e(Jd,ybr),e(zo,xbr),e(zo,t$),e(t$,$br),e(t$,yEe),e(yEe,kbr),e(t$,Sbr),e(zo,Rbr),e(zo,yt),M(a$,yt,null),e(yt,Pbr),e(yt,xEe),e(xEe,Bbr),e(yt,Ibr),e(yt,Yd),e(Yd,Nbr),e(Yd,$Ee),e($Ee,qbr),e(Yd,jbr),e(Yd,aY),e(aY,Dbr),e(Yd,Gbr),e(yt,Obr),M(UE,yt,null),e(zo,Vbr),e(zo,mo),M(n$,mo,null),e(mo,Xbr),e(mo,kEe),e(kEe,zbr),e(mo,Qbr),e(mo,ln),e(ln,Wbr),e(ln,SEe),e(SEe,Ubr),e(ln,Hbr),e(ln,REe),e(REe,Jbr),e(ln,Ybr),e(ln,PEe),e(PEe,Kbr),e(ln,Zbr),e(mo,e2r),e(mo,Kd),e(Kd,HE),e(HE,BEe),e(BEe,o2r),e(HE,r2r),e(HE,nY),e(nY,t2r),e(HE,a2r),e(Kd,n2r),e(Kd,JE),e(JE,IEe),e(IEe,s2r),e(JE,l2r),e(JE,sY),e(sY,i2r),e(JE,d2r),e(Kd,c2r),e(Kd,YE),e(YE,NEe),e(NEe,m2r),e(YE,f2r),e(YE,lY),e(lY,g2r),e(YE,h2r),e(mo,u2r),e(mo,KE),e(KE,p2r),e(KE,qEe),e(qEe,_2r),e(KE,b2r),e(KE,jEe),e(jEe,v2r),e(mo,F2r),M(ZE,mo,null),b(m,kKe,_),b(m,Zd,_),e(Zd,e4),e(e4,DEe),M(s$,DEe,null),e(Zd,T2r),e(Zd,GEe),e(GEe,M2r),b(m,SKe,_),b(m,Qo,_),M(l$,Qo,null),e(Qo,E2r),e(Qo,ec),e(ec,C2r),e(ec,iY),e(iY,w2r),e(ec,A2r),e(ec,dY),e(dY,L2r),e(ec,y2r),e(Qo,x2r),e(Qo,i$),e(i$,$2r),e(i$,OEe),e(OEe,k2r),e(i$,S2r),e(Qo,R2r),e(Qo,xt),M(d$,xt,null),e(xt,P2r),e(xt,VEe),e(VEe,B2r),e(xt,I2r),e(xt,oc),e(oc,N2r),e(oc,XEe),e(XEe,q2r),e(oc,j2r),e(oc,cY),e(cY,D2r),e(oc,G2r),e(xt,O2r),M(o4,xt,null),e(Qo,V2r),e(Qo,fo),M(c$,fo,null),e(fo,X2r),e(fo,zEe),e(zEe,z2r),e(fo,Q2r),e(fo,dn),e(dn,W2r),e(dn,QEe),e(QEe,U2r),e(dn,H2r),e(dn,WEe),e(WEe,J2r),e(dn,Y2r),e(dn,UEe),e(UEe,K2r),e(dn,Z2r),e(fo,e1r),e(fo,be),e(be,r4),e(r4,HEe),e(HEe,o1r),e(r4,r1r),e(r4,mY),e(mY,t1r),e(r4,a1r),e(be,n1r),e(be,t4),e(t4,JEe),e(JEe,s1r),e(t4,l1r),e(t4,fY),e(fY,i1r),e(t4,d1r),e(be,c1r),e(be,a4),e(a4,YEe),e(YEe,m1r),e(a4,f1r),e(a4,gY),e(gY,g1r),e(a4,h1r),e(be,u1r),e(be,n4),e(n4,KEe),e(KEe,p1r),e(n4,_1r),e(n4,hY),e(hY,b1r),e(n4,v1r),e(be,F1r),e(be,_l),e(_l,ZEe),e(ZEe,T1r),e(_l,M1r),e(_l,uY),e(uY,E1r),e(_l,C1r),e(_l,pY),e(pY,w1r),e(_l,A1r),e(be,L1r),e(be,s4),e(s4,e4e),e(e4e,y1r),e(s4,x1r),e(s4,_Y),e(_Y,$1r),e(s4,k1r),e(be,S1r),e(be,bl),e(bl,o4e),e(o4e,R1r),e(bl,P1r),e(bl,bY),e(bY,B1r),e(bl,I1r),e(bl,vY),e(vY,N1r),e(bl,q1r),e(be,j1r),e(be,l4),e(l4,r4e),e(r4e,D1r),e(l4,G1r),e(l4,FY),e(FY,O1r),e(l4,V1r),e(be,X1r),e(be,$t),e($t,t4e),e(t4e,z1r),e($t,Q1r),e($t,TY),e(TY,W1r),e($t,U1r),e($t,MY),e(MY,H1r),e($t,J1r),e($t,EY),e(EY,Y1r),e($t,K1r),e(be,Z1r),e(be,i4),e(i4,a4e),e(a4e,evr),e(i4,ovr),e(i4,CY),e(CY,rvr),e(i4,tvr),e(be,avr),e(be,d4),e(d4,n4e),e(n4e,nvr),e(d4,svr),e(d4,wY),e(wY,lvr),e(d4,ivr),e(be,dvr),e(be,c4),e(c4,s4e),e(s4e,cvr),e(c4,mvr),e(c4,AY),e(AY,fvr),e(c4,gvr),e(be,hvr),e(be,m4),e(m4,l4e),e(l4e,uvr),e(m4,pvr),e(m4,LY),e(LY,_vr),e(m4,bvr),e(be,vvr),e(be,f4),e(f4,i4e),e(i4e,Fvr),e(f4,Tvr),e(f4,yY),e(yY,Mvr),e(f4,Evr),e(be,Cvr),e(be,g4),e(g4,d4e),e(d4e,wvr),e(g4,Avr),e(g4,xY),e(xY,Lvr),e(g4,yvr),e(be,xvr),e(be,h4),e(h4,c4e),e(c4e,$vr),e(h4,kvr),e(h4,$Y),e($Y,Svr),e(h4,Rvr),e(be,Pvr),e(be,u4),e(u4,m4e),e(m4e,Bvr),e(u4,Ivr),e(u4,kY),e(kY,Nvr),e(u4,qvr),e(fo,jvr),e(fo,p4),e(p4,Dvr),e(p4,f4e),e(f4e,Gvr),e(p4,Ovr),e(p4,g4e),e(g4e,Vvr),e(fo,Xvr),M(_4,fo,null),b(m,RKe,_),b(m,rc,_),e(rc,b4),e(b4,h4e),M(m$,h4e,null),e(rc,zvr),e(rc,u4e),e(u4e,Qvr),b(m,PKe,_),b(m,Wo,_),M(f$,Wo,null),e(Wo,Wvr),e(Wo,tc),e(tc,Uvr),e(tc,SY),e(SY,Hvr),e(tc,Jvr),e(tc,RY),e(RY,Yvr),e(tc,Kvr),e(Wo,Zvr),e(Wo,g$),e(g$,eFr),e(g$,p4e),e(p4e,oFr),e(g$,rFr),e(Wo,tFr),e(Wo,kt),M(h$,kt,null),e(kt,aFr),e(kt,_4e),e(_4e,nFr),e(kt,sFr),e(kt,ac),e(ac,lFr),e(ac,b4e),e(b4e,iFr),e(ac,dFr),e(ac,PY),e(PY,cFr),e(ac,mFr),e(kt,fFr),M(v4,kt,null),e(Wo,gFr),e(Wo,go),M(u$,go,null),e(go,hFr),e(go,v4e),e(v4e,uFr),e(go,pFr),e(go,cn),e(cn,_Fr),e(cn,F4e),e(F4e,bFr),e(cn,vFr),e(cn,T4e),e(T4e,FFr),e(cn,TFr),e(cn,M4e),e(M4e,MFr),e(cn,EFr),e(go,CFr),e(go,E4e),e(E4e,F4),e(F4,C4e),e(C4e,wFr),e(F4,AFr),e(F4,BY),e(BY,LFr),e(F4,yFr),e(go,xFr),e(go,T4),e(T4,$Fr),e(T4,w4e),e(w4e,kFr),e(T4,SFr),e(T4,A4e),e(A4e,RFr),e(go,PFr),M(M4,go,null),b(m,BKe,_),b(m,nc,_),e(nc,E4),e(E4,L4e),M(p$,L4e,null),e(nc,BFr),e(nc,y4e),e(y4e,IFr),b(m,IKe,_),b(m,Uo,_),M(_$,Uo,null),e(Uo,NFr),e(Uo,sc),e(sc,qFr),e(sc,IY),e(IY,jFr),e(sc,DFr),e(sc,NY),e(NY,GFr),e(sc,OFr),e(Uo,VFr),e(Uo,b$),e(b$,XFr),e(b$,x4e),e(x4e,zFr),e(b$,QFr),e(Uo,WFr),e(Uo,St),M(v$,St,null),e(St,UFr),e(St,$4e),e($4e,HFr),e(St,JFr),e(St,lc),e(lc,YFr),e(lc,k4e),e(k4e,KFr),e(lc,ZFr),e(lc,qY),e(qY,eTr),e(lc,oTr),e(St,rTr),M(C4,St,null),e(Uo,tTr),e(Uo,ho),M(F$,ho,null),e(ho,aTr),e(ho,S4e),e(S4e,nTr),e(ho,sTr),e(ho,mn),e(mn,lTr),e(mn,R4e),e(R4e,iTr),e(mn,dTr),e(mn,P4e),e(P4e,cTr),e(mn,mTr),e(mn,B4e),e(B4e,fTr),e(mn,gTr),e(ho,hTr),e(ho,I4e),e(I4e,w4),e(w4,N4e),e(N4e,uTr),e(w4,pTr),e(w4,jY),e(jY,_Tr),e(w4,bTr),e(ho,vTr),e(ho,A4),e(A4,FTr),e(A4,q4e),e(q4e,TTr),e(A4,MTr),e(A4,j4e),e(j4e,ETr),e(ho,CTr),M(L4,ho,null),b(m,NKe,_),b(m,ic,_),e(ic,y4),e(y4,D4e),M(T$,D4e,null),e(ic,wTr),e(ic,G4e),e(G4e,ATr),b(m,qKe,_),b(m,Ho,_),M(M$,Ho,null),e(Ho,LTr),e(Ho,dc),e(dc,yTr),e(dc,DY),e(DY,xTr),e(dc,$Tr),e(dc,GY),e(GY,kTr),e(dc,STr),e(Ho,RTr),e(Ho,E$),e(E$,PTr),e(E$,O4e),e(O4e,BTr),e(E$,ITr),e(Ho,NTr),e(Ho,Rt),M(C$,Rt,null),e(Rt,qTr),e(Rt,V4e),e(V4e,jTr),e(Rt,DTr),e(Rt,cc),e(cc,GTr),e(cc,X4e),e(X4e,OTr),e(cc,VTr),e(cc,OY),e(OY,XTr),e(cc,zTr),e(Rt,QTr),M(x4,Rt,null),e(Ho,WTr),e(Ho,uo),M(w$,uo,null),e(uo,UTr),e(uo,z4e),e(z4e,HTr),e(uo,JTr),e(uo,fn),e(fn,YTr),e(fn,Q4e),e(Q4e,KTr),e(fn,ZTr),e(fn,W4e),e(W4e,eMr),e(fn,oMr),e(fn,U4e),e(U4e,rMr),e(fn,tMr),e(uo,aMr),e(uo,H4e),e(H4e,$4),e($4,J4e),e(J4e,nMr),e($4,sMr),e($4,VY),e(VY,lMr),e($4,iMr),e(uo,dMr),e(uo,k4),e(k4,cMr),e(k4,Y4e),e(Y4e,mMr),e(k4,fMr),e(k4,K4e),e(K4e,gMr),e(uo,hMr),M(S4,uo,null),b(m,jKe,_),b(m,mc,_),e(mc,R4),e(R4,Z4e),M(A$,Z4e,null),e(mc,uMr),e(mc,eCe),e(eCe,pMr),b(m,DKe,_),b(m,Jo,_),M(L$,Jo,null),e(Jo,_Mr),e(Jo,fc),e(fc,bMr),e(fc,XY),e(XY,vMr),e(fc,FMr),e(fc,zY),e(zY,TMr),e(fc,MMr),e(Jo,EMr),e(Jo,y$),e(y$,CMr),e(y$,oCe),e(oCe,wMr),e(y$,AMr),e(Jo,LMr),e(Jo,Pt),M(x$,Pt,null),e(Pt,yMr),e(Pt,rCe),e(rCe,xMr),e(Pt,$Mr),e(Pt,gc),e(gc,kMr),e(gc,tCe),e(tCe,SMr),e(gc,RMr),e(gc,QY),e(QY,PMr),e(gc,BMr),e(Pt,IMr),M(P4,Pt,null),e(Jo,NMr),e(Jo,po),M($$,po,null),e(po,qMr),e(po,aCe),e(aCe,jMr),e(po,DMr),e(po,gn),e(gn,GMr),e(gn,nCe),e(nCe,OMr),e(gn,VMr),e(gn,sCe),e(sCe,XMr),e(gn,zMr),e(gn,lCe),e(lCe,QMr),e(gn,WMr),e(po,UMr),e(po,Pe),e(Pe,B4),e(B4,iCe),e(iCe,HMr),e(B4,JMr),e(B4,WY),e(WY,YMr),e(B4,KMr),e(Pe,ZMr),e(Pe,I4),e(I4,dCe),e(dCe,eEr),e(I4,oEr),e(I4,UY),e(UY,rEr),e(I4,tEr),e(Pe,aEr),e(Pe,N4),e(N4,cCe),e(cCe,nEr),e(N4,sEr),e(N4,HY),e(HY,lEr),e(N4,iEr),e(Pe,dEr),e(Pe,q4),e(q4,mCe),e(mCe,cEr),e(q4,mEr),e(q4,JY),e(JY,fEr),e(q4,gEr),e(Pe,hEr),e(Pe,j4),e(j4,fCe),e(fCe,uEr),e(j4,pEr),e(j4,YY),e(YY,_Er),e(j4,bEr),e(Pe,vEr),e(Pe,D4),e(D4,gCe),e(gCe,FEr),e(D4,TEr),e(D4,KY),e(KY,MEr),e(D4,EEr),e(Pe,CEr),e(Pe,G4),e(G4,hCe),e(hCe,wEr),e(G4,AEr),e(G4,ZY),e(ZY,LEr),e(G4,yEr),e(Pe,xEr),e(Pe,O4),e(O4,uCe),e(uCe,$Er),e(O4,kEr),e(O4,eK),e(eK,SEr),e(O4,REr),e(Pe,PEr),e(Pe,V4),e(V4,pCe),e(pCe,BEr),e(V4,IEr),e(V4,oK),e(oK,NEr),e(V4,qEr),e(po,jEr),e(po,X4),e(X4,DEr),e(X4,_Ce),e(_Ce,GEr),e(X4,OEr),e(X4,bCe),e(bCe,VEr),e(po,XEr),M(z4,po,null),b(m,GKe,_),b(m,hc,_),e(hc,Q4),e(Q4,vCe),M(k$,vCe,null),e(hc,zEr),e(hc,FCe),e(FCe,QEr),b(m,OKe,_),b(m,Yo,_),M(S$,Yo,null),e(Yo,WEr),e(Yo,uc),e(uc,UEr),e(uc,rK),e(rK,HEr),e(uc,JEr),e(uc,tK),e(tK,YEr),e(uc,KEr),e(Yo,ZEr),e(Yo,R$),e(R$,e4r),e(R$,TCe),e(TCe,o4r),e(R$,r4r),e(Yo,t4r),e(Yo,Bt),M(P$,Bt,null),e(Bt,a4r),e(Bt,MCe),e(MCe,n4r),e(Bt,s4r),e(Bt,pc),e(pc,l4r),e(pc,ECe),e(ECe,i4r),e(pc,d4r),e(pc,aK),e(aK,c4r),e(pc,m4r),e(Bt,f4r),M(W4,Bt,null),e(Yo,g4r),e(Yo,_o),M(B$,_o,null),e(_o,h4r),e(_o,CCe),e(CCe,u4r),e(_o,p4r),e(_o,hn),e(hn,_4r),e(hn,wCe),e(wCe,b4r),e(hn,v4r),e(hn,ACe),e(ACe,F4r),e(hn,T4r),e(hn,LCe),e(LCe,M4r),e(hn,E4r),e(_o,C4r),e(_o,mt),e(mt,U4),e(U4,yCe),e(yCe,w4r),e(U4,A4r),e(U4,nK),e(nK,L4r),e(U4,y4r),e(mt,x4r),e(mt,H4),e(H4,xCe),e(xCe,$4r),e(H4,k4r),e(H4,sK),e(sK,S4r),e(H4,R4r),e(mt,P4r),e(mt,J4),e(J4,$Ce),e($Ce,B4r),e(J4,I4r),e(J4,lK),e(lK,N4r),e(J4,q4r),e(mt,j4r),e(mt,Y4),e(Y4,kCe),e(kCe,D4r),e(Y4,G4r),e(Y4,iK),e(iK,O4r),e(Y4,V4r),e(mt,X4r),e(mt,K4),e(K4,SCe),e(SCe,z4r),e(K4,Q4r),e(K4,dK),e(dK,W4r),e(K4,U4r),e(_o,H4r),e(_o,Z4),e(Z4,J4r),e(Z4,RCe),e(RCe,Y4r),e(Z4,K4r),e(Z4,PCe),e(PCe,Z4r),e(_o,eCr),M(eC,_o,null),b(m,VKe,_),b(m,_c,_),e(_c,oC),e(oC,BCe),M(I$,BCe,null),e(_c,oCr),e(_c,ICe),e(ICe,rCr),b(m,XKe,_),b(m,Ko,_),M(N$,Ko,null),e(Ko,tCr),e(Ko,bc),e(bc,aCr),e(bc,cK),e(cK,nCr),e(bc,sCr),e(bc,mK),e(mK,lCr),e(bc,iCr),e(Ko,dCr),e(Ko,q$),e(q$,cCr),e(q$,NCe),e(NCe,mCr),e(q$,fCr),e(Ko,gCr),e(Ko,It),M(j$,It,null),e(It,hCr),e(It,qCe),e(qCe,uCr),e(It,pCr),e(It,vc),e(vc,_Cr),e(vc,jCe),e(jCe,bCr),e(vc,vCr),e(vc,fK),e(fK,FCr),e(vc,TCr),e(It,MCr),M(rC,It,null),e(Ko,ECr),e(Ko,bo),M(D$,bo,null),e(bo,CCr),e(bo,DCe),e(DCe,wCr),e(bo,ACr),e(bo,un),e(un,LCr),e(un,GCe),e(GCe,yCr),e(un,xCr),e(un,OCe),e(OCe,$Cr),e(un,kCr),e(un,VCe),e(VCe,SCr),e(un,RCr),e(bo,PCr),e(bo,Le),e(Le,tC),e(tC,XCe),e(XCe,BCr),e(tC,ICr),e(tC,gK),e(gK,NCr),e(tC,qCr),e(Le,jCr),e(Le,aC),e(aC,zCe),e(zCe,DCr),e(aC,GCr),e(aC,hK),e(hK,OCr),e(aC,VCr),e(Le,XCr),e(Le,nC),e(nC,QCe),e(QCe,zCr),e(nC,QCr),e(nC,uK),e(uK,WCr),e(nC,UCr),e(Le,HCr),e(Le,sC),e(sC,WCe),e(WCe,JCr),e(sC,YCr),e(sC,pK),e(pK,KCr),e(sC,ZCr),e(Le,e3r),e(Le,lC),e(lC,UCe),e(UCe,o3r),e(lC,r3r),e(lC,_K),e(_K,t3r),e(lC,a3r),e(Le,n3r),e(Le,iC),e(iC,HCe),e(HCe,s3r),e(iC,l3r),e(iC,bK),e(bK,i3r),e(iC,d3r),e(Le,c3r),e(Le,dC),e(dC,JCe),e(JCe,m3r),e(dC,f3r),e(dC,vK),e(vK,g3r),e(dC,h3r),e(Le,u3r),e(Le,cC),e(cC,YCe),e(YCe,p3r),e(cC,_3r),e(cC,FK),e(FK,b3r),e(cC,v3r),e(Le,F3r),e(Le,mC),e(mC,KCe),e(KCe,T3r),e(mC,M3r),e(mC,TK),e(TK,E3r),e(mC,C3r),e(Le,w3r),e(Le,fC),e(fC,ZCe),e(ZCe,A3r),e(fC,L3r),e(fC,MK),e(MK,y3r),e(fC,x3r),e(bo,$3r),e(bo,gC),e(gC,k3r),e(gC,e3e),e(e3e,S3r),e(gC,R3r),e(gC,o3e),e(o3e,P3r),e(bo,B3r),M(hC,bo,null),b(m,zKe,_),b(m,Fc,_),e(Fc,uC),e(uC,r3e),M(G$,r3e,null),e(Fc,I3r),e(Fc,t3e),e(t3e,N3r),b(m,QKe,_),b(m,Zo,_),M(O$,Zo,null),e(Zo,q3r),e(Zo,Tc),e(Tc,j3r),e(Tc,EK),e(EK,D3r),e(Tc,G3r),e(Tc,CK),e(CK,O3r),e(Tc,V3r),e(Zo,X3r),e(Zo,V$),e(V$,z3r),e(V$,a3e),e(a3e,Q3r),e(V$,W3r),e(Zo,U3r),e(Zo,Nt),M(X$,Nt,null),e(Nt,H3r),e(Nt,n3e),e(n3e,J3r),e(Nt,Y3r),e(Nt,Mc),e(Mc,K3r),e(Mc,s3e),e(s3e,Z3r),e(Mc,e5r),e(Mc,wK),e(wK,o5r),e(Mc,r5r),e(Nt,t5r),M(pC,Nt,null),e(Zo,a5r),e(Zo,vo),M(z$,vo,null),e(vo,n5r),e(vo,l3e),e(l3e,s5r),e(vo,l5r),e(vo,pn),e(pn,i5r),e(pn,i3e),e(i3e,d5r),e(pn,c5r),e(pn,d3e),e(d3e,m5r),e(pn,f5r),e(pn,c3e),e(c3e,g5r),e(pn,h5r),e(vo,u5r),e(vo,Q$),e(Q$,_C),e(_C,m3e),e(m3e,p5r),e(_C,_5r),e(_C,AK),e(AK,b5r),e(_C,v5r),e(Q$,F5r),e(Q$,bC),e(bC,f3e),e(f3e,T5r),e(bC,M5r),e(bC,LK),e(LK,E5r),e(bC,C5r),e(vo,w5r),e(vo,vC),e(vC,A5r),e(vC,g3e),e(g3e,L5r),e(vC,y5r),e(vC,h3e),e(h3e,x5r),e(vo,$5r),M(FC,vo,null),b(m,WKe,_),b(m,Ec,_),e(Ec,TC),e(TC,u3e),M(W$,u3e,null),e(Ec,k5r),e(Ec,p3e),e(p3e,S5r),b(m,UKe,_),b(m,er,_),M(U$,er,null),e(er,R5r),e(er,Cc),e(Cc,P5r),e(Cc,yK),e(yK,B5r),e(Cc,I5r),e(Cc,xK),e(xK,N5r),e(Cc,q5r),e(er,j5r),e(er,H$),e(H$,D5r),e(H$,_3e),e(_3e,G5r),e(H$,O5r),e(er,V5r),e(er,qt),M(J$,qt,null),e(qt,X5r),e(qt,b3e),e(b3e,z5r),e(qt,Q5r),e(qt,wc),e(wc,W5r),e(wc,v3e),e(v3e,U5r),e(wc,H5r),e(wc,$K),e($K,J5r),e(wc,Y5r),e(qt,K5r),M(MC,qt,null),e(er,Z5r),e(er,Fo),M(Y$,Fo,null),e(Fo,e0r),e(Fo,F3e),e(F3e,o0r),e(Fo,r0r),e(Fo,_n),e(_n,t0r),e(_n,T3e),e(T3e,a0r),e(_n,n0r),e(_n,M3e),e(M3e,s0r),e(_n,l0r),e(_n,E3e),e(E3e,i0r),e(_n,d0r),e(Fo,c0r),e(Fo,ft),e(ft,EC),e(EC,C3e),e(C3e,m0r),e(EC,f0r),e(EC,kK),e(kK,g0r),e(EC,h0r),e(ft,u0r),e(ft,CC),e(CC,w3e),e(w3e,p0r),e(CC,_0r),e(CC,SK),e(SK,b0r),e(CC,v0r),e(ft,F0r),e(ft,wC),e(wC,A3e),e(A3e,T0r),e(wC,M0r),e(wC,RK),e(RK,E0r),e(wC,C0r),e(ft,w0r),e(ft,AC),e(AC,L3e),e(L3e,A0r),e(AC,L0r),e(AC,PK),e(PK,y0r),e(AC,x0r),e(ft,$0r),e(ft,LC),e(LC,y3e),e(y3e,k0r),e(LC,S0r),e(LC,BK),e(BK,R0r),e(LC,P0r),e(Fo,B0r),e(Fo,yC),e(yC,I0r),e(yC,x3e),e(x3e,N0r),e(yC,q0r),e(yC,$3e),e($3e,j0r),e(Fo,D0r),M(xC,Fo,null),b(m,HKe,_),b(m,Ac,_),e(Ac,$C),e($C,k3e),M(K$,k3e,null),e(Ac,G0r),e(Ac,S3e),e(S3e,O0r),b(m,JKe,_),b(m,or,_),M(Z$,or,null),e(or,V0r),e(or,Lc),e(Lc,X0r),e(Lc,IK),e(IK,z0r),e(Lc,Q0r),e(Lc,NK),e(NK,W0r),e(Lc,U0r),e(or,H0r),e(or,ek),e(ek,J0r),e(ek,R3e),e(R3e,Y0r),e(ek,K0r),e(or,Z0r),e(or,jt),M(ok,jt,null),e(jt,ewr),e(jt,P3e),e(P3e,owr),e(jt,rwr),e(jt,yc),e(yc,twr),e(yc,B3e),e(B3e,awr),e(yc,nwr),e(yc,qK),e(qK,swr),e(yc,lwr),e(jt,iwr),M(kC,jt,null),e(or,dwr),e(or,To),M(rk,To,null),e(To,cwr),e(To,I3e),e(I3e,mwr),e(To,fwr),e(To,bn),e(bn,gwr),e(bn,N3e),e(N3e,hwr),e(bn,uwr),e(bn,q3e),e(q3e,pwr),e(bn,_wr),e(bn,j3e),e(j3e,bwr),e(bn,vwr),e(To,Fwr),e(To,vn),e(vn,SC),e(SC,D3e),e(D3e,Twr),e(SC,Mwr),e(SC,jK),e(jK,Ewr),e(SC,Cwr),e(vn,wwr),e(vn,RC),e(RC,G3e),e(G3e,Awr),e(RC,Lwr),e(RC,DK),e(DK,ywr),e(RC,xwr),e(vn,$wr),e(vn,PC),e(PC,O3e),e(O3e,kwr),e(PC,Swr),e(PC,GK),e(GK,Rwr),e(PC,Pwr),e(vn,Bwr),e(vn,BC),e(BC,V3e),e(V3e,Iwr),e(BC,Nwr),e(BC,OK),e(OK,qwr),e(BC,jwr),e(To,Dwr),e(To,IC),e(IC,Gwr),e(IC,X3e),e(X3e,Owr),e(IC,Vwr),e(IC,z3e),e(z3e,Xwr),e(To,zwr),M(NC,To,null),b(m,YKe,_),b(m,xc,_),e(xc,qC),e(qC,Q3e),M(tk,Q3e,null),e(xc,Qwr),e(xc,W3e),e(W3e,Wwr),b(m,KKe,_),b(m,rr,_),M(ak,rr,null),e(rr,Uwr),e(rr,$c),e($c,Hwr),e($c,VK),e(VK,Jwr),e($c,Ywr),e($c,XK),e(XK,Kwr),e($c,Zwr),e(rr,eAr),e(rr,nk),e(nk,oAr),e(nk,U3e),e(U3e,rAr),e(nk,tAr),e(rr,aAr),e(rr,Dt),M(sk,Dt,null),e(Dt,nAr),e(Dt,H3e),e(H3e,sAr),e(Dt,lAr),e(Dt,kc),e(kc,iAr),e(kc,J3e),e(J3e,dAr),e(kc,cAr),e(kc,zK),e(zK,mAr),e(kc,fAr),e(Dt,gAr),M(jC,Dt,null),e(rr,hAr),e(rr,Mo),M(lk,Mo,null),e(Mo,uAr),e(Mo,Y3e),e(Y3e,pAr),e(Mo,_Ar),e(Mo,Fn),e(Fn,bAr),e(Fn,K3e),e(K3e,vAr),e(Fn,FAr),e(Fn,Z3e),e(Z3e,TAr),e(Fn,MAr),e(Fn,e5e),e(e5e,EAr),e(Fn,CAr),e(Mo,wAr),e(Mo,Sc),e(Sc,DC),e(DC,o5e),e(o5e,AAr),e(DC,LAr),e(DC,QK),e(QK,yAr),e(DC,xAr),e(Sc,$Ar),e(Sc,GC),e(GC,r5e),e(r5e,kAr),e(GC,SAr),e(GC,WK),e(WK,RAr),e(GC,PAr),e(Sc,BAr),e(Sc,OC),e(OC,t5e),e(t5e,IAr),e(OC,NAr),e(OC,UK),e(UK,qAr),e(OC,jAr),e(Mo,DAr),e(Mo,VC),e(VC,GAr),e(VC,a5e),e(a5e,OAr),e(VC,VAr),e(VC,n5e),e(n5e,XAr),e(Mo,zAr),M(XC,Mo,null),b(m,ZKe,_),b(m,Rc,_),e(Rc,zC),e(zC,s5e),M(ik,s5e,null),e(Rc,QAr),e(Rc,l5e),e(l5e,WAr),b(m,eZe,_),b(m,tr,_),M(dk,tr,null),e(tr,UAr),e(tr,Pc),e(Pc,HAr),e(Pc,HK),e(HK,JAr),e(Pc,YAr),e(Pc,JK),e(JK,KAr),e(Pc,ZAr),e(tr,e6r),e(tr,ck),e(ck,o6r),e(ck,i5e),e(i5e,r6r),e(ck,t6r),e(tr,a6r),e(tr,Gt),M(mk,Gt,null),e(Gt,n6r),e(Gt,d5e),e(d5e,s6r),e(Gt,l6r),e(Gt,Bc),e(Bc,i6r),e(Bc,c5e),e(c5e,d6r),e(Bc,c6r),e(Bc,YK),e(YK,m6r),e(Bc,f6r),e(Gt,g6r),M(QC,Gt,null),e(tr,h6r),e(tr,Eo),M(fk,Eo,null),e(Eo,u6r),e(Eo,m5e),e(m5e,p6r),e(Eo,_6r),e(Eo,Tn),e(Tn,b6r),e(Tn,f5e),e(f5e,v6r),e(Tn,F6r),e(Tn,g5e),e(g5e,T6r),e(Tn,M6r),e(Tn,h5e),e(h5e,E6r),e(Tn,C6r),e(Eo,w6r),e(Eo,u5e),e(u5e,WC),e(WC,p5e),e(p5e,A6r),e(WC,L6r),e(WC,KK),e(KK,y6r),e(WC,x6r),e(Eo,$6r),e(Eo,UC),e(UC,k6r),e(UC,_5e),e(_5e,S6r),e(UC,R6r),e(UC,b5e),e(b5e,P6r),e(Eo,B6r),M(HC,Eo,null),b(m,oZe,_),b(m,Ic,_),e(Ic,JC),e(JC,v5e),M(gk,v5e,null),e(Ic,I6r),e(Ic,F5e),e(F5e,N6r),b(m,rZe,_),b(m,ar,_),M(hk,ar,null),e(ar,q6r),e(ar,Nc),e(Nc,j6r),e(Nc,ZK),e(ZK,D6r),e(Nc,G6r),e(Nc,eZ),e(eZ,O6r),e(Nc,V6r),e(ar,X6r),e(ar,uk),e(uk,z6r),e(uk,T5e),e(T5e,Q6r),e(uk,W6r),e(ar,U6r),e(ar,Ot),M(pk,Ot,null),e(Ot,H6r),e(Ot,M5e),e(M5e,J6r),e(Ot,Y6r),e(Ot,qc),e(qc,K6r),e(qc,E5e),e(E5e,Z6r),e(qc,e7r),e(qc,oZ),e(oZ,o7r),e(qc,r7r),e(Ot,t7r),M(YC,Ot,null),e(ar,a7r),e(ar,Co),M(_k,Co,null),e(Co,n7r),e(Co,C5e),e(C5e,s7r),e(Co,l7r),e(Co,Mn),e(Mn,i7r),e(Mn,w5e),e(w5e,d7r),e(Mn,c7r),e(Mn,A5e),e(A5e,m7r),e(Mn,f7r),e(Mn,L5e),e(L5e,g7r),e(Mn,h7r),e(Co,u7r),e(Co,gt),e(gt,KC),e(KC,y5e),e(y5e,p7r),e(KC,_7r),e(KC,rZ),e(rZ,b7r),e(KC,v7r),e(gt,F7r),e(gt,ZC),e(ZC,x5e),e(x5e,T7r),e(ZC,M7r),e(ZC,tZ),e(tZ,E7r),e(ZC,C7r),e(gt,w7r),e(gt,e3),e(e3,$5e),e($5e,A7r),e(e3,L7r),e(e3,aZ),e(aZ,y7r),e(e3,x7r),e(gt,$7r),e(gt,o3),e(o3,k5e),e(k5e,k7r),e(o3,S7r),e(o3,nZ),e(nZ,R7r),e(o3,P7r),e(gt,B7r),e(gt,r3),e(r3,S5e),e(S5e,I7r),e(r3,N7r),e(r3,sZ),e(sZ,q7r),e(r3,j7r),e(Co,D7r),e(Co,t3),e(t3,G7r),e(t3,R5e),e(R5e,O7r),e(t3,V7r),e(t3,P5e),e(P5e,X7r),e(Co,z7r),M(a3,Co,null),b(m,tZe,_),b(m,jc,_),e(jc,n3),e(n3,B5e),M(bk,B5e,null),e(jc,Q7r),e(jc,I5e),e(I5e,W7r),b(m,aZe,_),b(m,nr,_),M(vk,nr,null),e(nr,U7r),e(nr,Dc),e(Dc,H7r),e(Dc,lZ),e(lZ,J7r),e(Dc,Y7r),e(Dc,iZ),e(iZ,K7r),e(Dc,Z7r),e(nr,eLr),e(nr,Fk),e(Fk,oLr),e(Fk,N5e),e(N5e,rLr),e(Fk,tLr),e(nr,aLr),e(nr,Vt),M(Tk,Vt,null),e(Vt,nLr),e(Vt,q5e),e(q5e,sLr),e(Vt,lLr),e(Vt,Gc),e(Gc,iLr),e(Gc,j5e),e(j5e,dLr),e(Gc,cLr),e(Gc,dZ),e(dZ,mLr),e(Gc,fLr),e(Vt,gLr),M(s3,Vt,null),e(nr,hLr),e(nr,wo),M(Mk,wo,null),e(wo,uLr),e(wo,D5e),e(D5e,pLr),e(wo,_Lr),e(wo,En),e(En,bLr),e(En,G5e),e(G5e,vLr),e(En,FLr),e(En,O5e),e(O5e,TLr),e(En,MLr),e(En,V5e),e(V5e,ELr),e(En,CLr),e(wo,wLr),e(wo,X5e),e(X5e,l3),e(l3,z5e),e(z5e,ALr),e(l3,LLr),e(l3,cZ),e(cZ,yLr),e(l3,xLr),e(wo,$Lr),e(wo,i3),e(i3,kLr),e(i3,Q5e),e(Q5e,SLr),e(i3,RLr),e(i3,W5e),e(W5e,PLr),e(wo,BLr),M(d3,wo,null),b(m,nZe,_),b(m,Oc,_),e(Oc,c3),e(c3,U5e),M(Ek,U5e,null),e(Oc,ILr),e(Oc,H5e),e(H5e,NLr),b(m,sZe,_),b(m,sr,_),M(Ck,sr,null),e(sr,qLr),e(sr,Vc),e(Vc,jLr),e(Vc,mZ),e(mZ,DLr),e(Vc,GLr),e(Vc,fZ),e(fZ,OLr),e(Vc,VLr),e(sr,XLr),e(sr,wk),e(wk,zLr),e(wk,J5e),e(J5e,QLr),e(wk,WLr),e(sr,ULr),e(sr,Xt),M(Ak,Xt,null),e(Xt,HLr),e(Xt,Y5e),e(Y5e,JLr),e(Xt,YLr),e(Xt,Xc),e(Xc,KLr),e(Xc,K5e),e(K5e,ZLr),e(Xc,eyr),e(Xc,gZ),e(gZ,oyr),e(Xc,ryr),e(Xt,tyr),M(m3,Xt,null),e(sr,ayr),e(sr,Ir),M(Lk,Ir,null),e(Ir,nyr),e(Ir,Z5e),e(Z5e,syr),e(Ir,lyr),e(Ir,Cn),e(Cn,iyr),e(Cn,e0e),e(e0e,dyr),e(Cn,cyr),e(Cn,o0e),e(o0e,myr),e(Cn,fyr),e(Cn,r0e),e(r0e,gyr),e(Cn,hyr),e(Ir,uyr),e(Ir,N),e(N,f3),e(f3,t0e),e(t0e,pyr),e(f3,_yr),e(f3,hZ),e(hZ,byr),e(f3,vyr),e(N,Fyr),e(N,g3),e(g3,a0e),e(a0e,Tyr),e(g3,Myr),e(g3,uZ),e(uZ,Eyr),e(g3,Cyr),e(N,wyr),e(N,h3),e(h3,n0e),e(n0e,Ayr),e(h3,Lyr),e(h3,pZ),e(pZ,yyr),e(h3,xyr),e(N,$yr),e(N,u3),e(u3,s0e),e(s0e,kyr),e(u3,Syr),e(u3,_Z),e(_Z,Ryr),e(u3,Pyr),e(N,Byr),e(N,p3),e(p3,l0e),e(l0e,Iyr),e(p3,Nyr),e(p3,bZ),e(bZ,qyr),e(p3,jyr),e(N,Dyr),e(N,_3),e(_3,i0e),e(i0e,Gyr),e(_3,Oyr),e(_3,vZ),e(vZ,Vyr),e(_3,Xyr),e(N,zyr),e(N,b3),e(b3,d0e),e(d0e,Qyr),e(b3,Wyr),e(b3,FZ),e(FZ,Uyr),e(b3,Hyr),e(N,Jyr),e(N,v3),e(v3,c0e),e(c0e,Yyr),e(v3,Kyr),e(v3,TZ),e(TZ,Zyr),e(v3,e8r),e(N,o8r),e(N,F3),e(F3,m0e),e(m0e,r8r),e(F3,t8r),e(F3,MZ),e(MZ,a8r),e(F3,n8r),e(N,s8r),e(N,T3),e(T3,f0e),e(f0e,l8r),e(T3,i8r),e(T3,EZ),e(EZ,d8r),e(T3,c8r),e(N,m8r),e(N,M3),e(M3,g0e),e(g0e,f8r),e(M3,g8r),e(M3,CZ),e(CZ,h8r),e(M3,u8r),e(N,p8r),e(N,E3),e(E3,h0e),e(h0e,_8r),e(E3,b8r),e(E3,wZ),e(wZ,v8r),e(E3,F8r),e(N,T8r),e(N,C3),e(C3,u0e),e(u0e,M8r),e(C3,E8r),e(C3,AZ),e(AZ,C8r),e(C3,w8r),e(N,A8r),e(N,w3),e(w3,p0e),e(p0e,L8r),e(w3,y8r),e(w3,LZ),e(LZ,x8r),e(w3,$8r),e(N,k8r),e(N,A3),e(A3,_0e),e(_0e,S8r),e(A3,R8r),e(A3,yZ),e(yZ,P8r),e(A3,B8r),e(N,I8r),e(N,L3),e(L3,b0e),e(b0e,N8r),e(L3,q8r),e(L3,xZ),e(xZ,j8r),e(L3,D8r),e(N,G8r),e(N,y3),e(y3,v0e),e(v0e,O8r),e(y3,V8r),e(y3,$Z),e($Z,X8r),e(y3,z8r),e(N,Q8r),e(N,x3),e(x3,F0e),e(F0e,W8r),e(x3,U8r),e(x3,kZ),e(kZ,H8r),e(x3,J8r),e(N,Y8r),e(N,vl),e(vl,T0e),e(T0e,K8r),e(vl,Z8r),e(vl,SZ),e(SZ,e9r),e(vl,o9r),e(vl,RZ),e(RZ,r9r),e(vl,t9r),e(N,a9r),e(N,$3),e($3,M0e),e(M0e,n9r),e($3,s9r),e($3,PZ),e(PZ,l9r),e($3,i9r),e(N,d9r),e(N,k3),e(k3,E0e),e(E0e,c9r),e(k3,m9r),e(k3,BZ),e(BZ,f9r),e(k3,g9r),e(N,h9r),e(N,S3),e(S3,C0e),e(C0e,u9r),e(S3,p9r),e(S3,IZ),e(IZ,_9r),e(S3,b9r),e(N,v9r),e(N,R3),e(R3,w0e),e(w0e,F9r),e(R3,T9r),e(R3,NZ),e(NZ,M9r),e(R3,E9r),e(N,C9r),e(N,P3),e(P3,A0e),e(A0e,w9r),e(P3,A9r),e(P3,qZ),e(qZ,L9r),e(P3,y9r),e(N,x9r),e(N,B3),e(B3,L0e),e(L0e,$9r),e(B3,k9r),e(B3,jZ),e(jZ,S9r),e(B3,R9r),e(N,P9r),e(N,I3),e(I3,y0e),e(y0e,B9r),e(I3,I9r),e(I3,DZ),e(DZ,N9r),e(I3,q9r),e(N,j9r),e(N,N3),e(N3,x0e),e(x0e,D9r),e(N3,G9r),e(N3,GZ),e(GZ,O9r),e(N3,V9r),e(N,X9r),e(N,q3),e(q3,$0e),e($0e,z9r),e(q3,Q9r),e(q3,OZ),e(OZ,W9r),e(q3,U9r),e(N,H9r),e(N,j3),e(j3,k0e),e(k0e,J9r),e(j3,Y9r),e(j3,VZ),e(VZ,K9r),e(j3,Z9r),e(N,exr),e(N,D3),e(D3,S0e),e(S0e,oxr),e(D3,rxr),e(D3,XZ),e(XZ,txr),e(D3,axr),e(N,nxr),e(N,G3),e(G3,R0e),e(R0e,sxr),e(G3,lxr),e(G3,zZ),e(zZ,ixr),e(G3,dxr),e(N,cxr),e(N,O3),e(O3,P0e),e(P0e,mxr),e(O3,fxr),e(O3,QZ),e(QZ,gxr),e(O3,hxr),e(N,uxr),e(N,V3),e(V3,B0e),e(B0e,pxr),e(V3,_xr),e(V3,WZ),e(WZ,bxr),e(V3,vxr),e(N,Fxr),e(N,X3),e(X3,I0e),e(I0e,Txr),e(X3,Mxr),e(X3,UZ),e(UZ,Exr),e(X3,Cxr),e(N,wxr),e(N,z3),e(z3,N0e),e(N0e,Axr),e(z3,Lxr),e(z3,HZ),e(HZ,yxr),e(z3,xxr),e(N,$xr),e(N,Q3),e(Q3,q0e),e(q0e,kxr),e(Q3,Sxr),e(Q3,JZ),e(JZ,Rxr),e(Q3,Pxr),e(N,Bxr),e(N,W3),e(W3,j0e),e(j0e,Ixr),e(W3,Nxr),e(W3,YZ),e(YZ,qxr),e(W3,jxr),e(N,Dxr),e(N,U3),e(U3,D0e),e(D0e,Gxr),e(U3,Oxr),e(U3,KZ),e(KZ,Vxr),e(U3,Xxr),e(N,zxr),e(N,H3),e(H3,G0e),e(G0e,Qxr),e(H3,Wxr),e(H3,ZZ),e(ZZ,Uxr),e(H3,Hxr),e(N,Jxr),e(N,J3),e(J3,O0e),e(O0e,Yxr),e(J3,Kxr),e(J3,eee),e(eee,Zxr),e(J3,e$r),e(N,o$r),e(N,Y3),e(Y3,V0e),e(V0e,r$r),e(Y3,t$r),e(Y3,oee),e(oee,a$r),e(Y3,n$r),e(N,s$r),e(N,K3),e(K3,X0e),e(X0e,l$r),e(K3,i$r),e(K3,ree),e(ree,d$r),e(K3,c$r),e(N,m$r),e(N,Z3),e(Z3,z0e),e(z0e,f$r),e(Z3,g$r),e(Z3,tee),e(tee,h$r),e(Z3,u$r),e(N,p$r),e(N,e5),e(e5,Q0e),e(Q0e,_$r),e(e5,b$r),e(e5,aee),e(aee,v$r),e(e5,F$r),e(N,T$r),e(N,o5),e(o5,W0e),e(W0e,M$r),e(o5,E$r),e(o5,nee),e(nee,C$r),e(o5,w$r),e(N,A$r),e(N,r5),e(r5,U0e),e(U0e,L$r),e(r5,y$r),e(r5,see),e(see,x$r),e(r5,$$r),e(N,k$r),e(N,t5),e(t5,H0e),e(H0e,S$r),e(t5,R$r),e(t5,lee),e(lee,P$r),e(t5,B$r),e(N,I$r),e(N,a5),e(a5,J0e),e(J0e,N$r),e(a5,q$r),e(a5,iee),e(iee,j$r),e(a5,D$r),e(N,G$r),e(N,n5),e(n5,Y0e),e(Y0e,O$r),e(n5,V$r),e(n5,dee),e(dee,X$r),e(n5,z$r),e(N,Q$r),e(N,s5),e(s5,K0e),e(K0e,W$r),e(s5,U$r),e(s5,cee),e(cee,H$r),e(s5,J$r),e(N,Y$r),e(N,l5),e(l5,Z0e),e(Z0e,K$r),e(l5,Z$r),e(l5,mee),e(mee,ekr),e(l5,okr),e(N,rkr),e(N,i5),e(i5,ewe),e(ewe,tkr),e(i5,akr),e(i5,fee),e(fee,nkr),e(i5,skr),e(N,lkr),e(N,d5),e(d5,owe),e(owe,ikr),e(d5,dkr),e(d5,gee),e(gee,ckr),e(d5,mkr),e(N,fkr),e(N,c5),e(c5,rwe),e(rwe,gkr),e(c5,hkr),e(c5,hee),e(hee,ukr),e(c5,pkr),e(Ir,_kr),M(m5,Ir,null),b(m,lZe,_),b(m,zc,_),e(zc,f5),e(f5,twe),M(yk,twe,null),e(zc,bkr),e(zc,awe),e(awe,vkr),b(m,iZe,_),b(m,lr,_),M(xk,lr,null),e(lr,Fkr),e(lr,Qc),e(Qc,Tkr),e(Qc,uee),e(uee,Mkr),e(Qc,Ekr),e(Qc,pee),e(pee,Ckr),e(Qc,wkr),e(lr,Akr),e(lr,$k),e($k,Lkr),e($k,nwe),e(nwe,ykr),e($k,xkr),e(lr,$kr),e(lr,zt),M(kk,zt,null),e(zt,kkr),e(zt,swe),e(swe,Skr),e(zt,Rkr),e(zt,Wc),e(Wc,Pkr),e(Wc,lwe),e(lwe,Bkr),e(Wc,Ikr),e(Wc,_ee),e(_ee,Nkr),e(Wc,qkr),e(zt,jkr),M(g5,zt,null),e(lr,Dkr),e(lr,Nr),M(Sk,Nr,null),e(Nr,Gkr),e(Nr,iwe),e(iwe,Okr),e(Nr,Vkr),e(Nr,wn),e(wn,Xkr),e(wn,dwe),e(dwe,zkr),e(wn,Qkr),e(wn,cwe),e(cwe,Wkr),e(wn,Ukr),e(wn,mwe),e(mwe,Hkr),e(wn,Jkr),e(Nr,Ykr),e(Nr,se),e(se,h5),e(h5,fwe),e(fwe,Kkr),e(h5,Zkr),e(h5,bee),e(bee,eSr),e(h5,oSr),e(se,rSr),e(se,u5),e(u5,gwe),e(gwe,tSr),e(u5,aSr),e(u5,vee),e(vee,nSr),e(u5,sSr),e(se,lSr),e(se,p5),e(p5,hwe),e(hwe,iSr),e(p5,dSr),e(p5,Fee),e(Fee,cSr),e(p5,mSr),e(se,fSr),e(se,_5),e(_5,uwe),e(uwe,gSr),e(_5,hSr),e(_5,Tee),e(Tee,uSr),e(_5,pSr),e(se,_Sr),e(se,b5),e(b5,pwe),e(pwe,bSr),e(b5,vSr),e(b5,Mee),e(Mee,FSr),e(b5,TSr),e(se,MSr),e(se,v5),e(v5,_we),e(_we,ESr),e(v5,CSr),e(v5,Eee),e(Eee,wSr),e(v5,ASr),e(se,LSr),e(se,F5),e(F5,bwe),e(bwe,ySr),e(F5,xSr),e(F5,Cee),e(Cee,$Sr),e(F5,kSr),e(se,SSr),e(se,T5),e(T5,vwe),e(vwe,RSr),e(T5,PSr),e(T5,wee),e(wee,BSr),e(T5,ISr),e(se,NSr),e(se,M5),e(M5,Fwe),e(Fwe,qSr),e(M5,jSr),e(M5,Aee),e(Aee,DSr),e(M5,GSr),e(se,OSr),e(se,E5),e(E5,Twe),e(Twe,VSr),e(E5,XSr),e(E5,Lee),e(Lee,zSr),e(E5,QSr),e(se,WSr),e(se,C5),e(C5,Mwe),e(Mwe,USr),e(C5,HSr),e(C5,yee),e(yee,JSr),e(C5,YSr),e(se,KSr),e(se,w5),e(w5,Ewe),e(Ewe,ZSr),e(w5,eRr),e(w5,xee),e(xee,oRr),e(w5,rRr),e(se,tRr),e(se,A5),e(A5,Cwe),e(Cwe,aRr),e(A5,nRr),e(A5,$ee),e($ee,sRr),e(A5,lRr),e(se,iRr),e(se,L5),e(L5,wwe),e(wwe,dRr),e(L5,cRr),e(L5,kee),e(kee,mRr),e(L5,fRr),e(se,gRr),e(se,y5),e(y5,Awe),e(Awe,hRr),e(y5,uRr),e(y5,See),e(See,pRr),e(y5,_Rr),e(se,bRr),e(se,x5),e(x5,Lwe),e(Lwe,vRr),e(x5,FRr),e(x5,Ree),e(Ree,TRr),e(x5,MRr),e(se,ERr),e(se,$5),e($5,ywe),e(ywe,CRr),e($5,wRr),e($5,Pee),e(Pee,ARr),e($5,LRr),e(se,yRr),e(se,k5),e(k5,xwe),e(xwe,xRr),e(k5,$Rr),e(k5,Bee),e(Bee,kRr),e(k5,SRr),e(se,RRr),e(se,S5),e(S5,$we),e($we,PRr),e(S5,BRr),e(S5,Iee),e(Iee,IRr),e(S5,NRr),e(se,qRr),e(se,R5),e(R5,kwe),e(kwe,jRr),e(R5,DRr),e(R5,Nee),e(Nee,GRr),e(R5,ORr),e(se,VRr),e(se,P5),e(P5,Swe),e(Swe,XRr),e(P5,zRr),e(P5,qee),e(qee,QRr),e(P5,WRr),e(se,URr),e(se,B5),e(B5,Rwe),e(Rwe,HRr),e(B5,JRr),e(B5,jee),e(jee,YRr),e(B5,KRr),e(se,ZRr),e(se,I5),e(I5,Pwe),e(Pwe,ePr),e(I5,oPr),e(I5,Dee),e(Dee,rPr),e(I5,tPr),e(Nr,aPr),M(N5,Nr,null),b(m,dZe,_),b(m,Uc,_),e(Uc,q5),e(q5,Bwe),M(Rk,Bwe,null),e(Uc,nPr),e(Uc,Iwe),e(Iwe,sPr),b(m,cZe,_),b(m,ir,_),M(Pk,ir,null),e(ir,lPr),e(ir,Hc),e(Hc,iPr),e(Hc,Gee),e(Gee,dPr),e(Hc,cPr),e(Hc,Oee),e(Oee,mPr),e(Hc,fPr),e(ir,gPr),e(ir,Bk),e(Bk,hPr),e(Bk,Nwe),e(Nwe,uPr),e(Bk,pPr),e(ir,_Pr),e(ir,Qt),M(Ik,Qt,null),e(Qt,bPr),e(Qt,qwe),e(qwe,vPr),e(Qt,FPr),e(Qt,Jc),e(Jc,TPr),e(Jc,jwe),e(jwe,MPr),e(Jc,EPr),e(Jc,Vee),e(Vee,CPr),e(Jc,wPr),e(Qt,APr),M(j5,Qt,null),e(ir,LPr),e(ir,qr),M(Nk,qr,null),e(qr,yPr),e(qr,Dwe),e(Dwe,xPr),e(qr,$Pr),e(qr,An),e(An,kPr),e(An,Gwe),e(Gwe,SPr),e(An,RPr),e(An,Owe),e(Owe,PPr),e(An,BPr),e(An,Vwe),e(Vwe,IPr),e(An,NPr),e(qr,qPr),e(qr,Me),e(Me,D5),e(D5,Xwe),e(Xwe,jPr),e(D5,DPr),e(D5,Xee),e(Xee,GPr),e(D5,OPr),e(Me,VPr),e(Me,G5),e(G5,zwe),e(zwe,XPr),e(G5,zPr),e(G5,zee),e(zee,QPr),e(G5,WPr),e(Me,UPr),e(Me,O5),e(O5,Qwe),e(Qwe,HPr),e(O5,JPr),e(O5,Qee),e(Qee,YPr),e(O5,KPr),e(Me,ZPr),e(Me,V5),e(V5,Wwe),e(Wwe,eBr),e(V5,oBr),e(V5,Wee),e(Wee,rBr),e(V5,tBr),e(Me,aBr),e(Me,X5),e(X5,Uwe),e(Uwe,nBr),e(X5,sBr),e(X5,Uee),e(Uee,lBr),e(X5,iBr),e(Me,dBr),e(Me,z5),e(z5,Hwe),e(Hwe,cBr),e(z5,mBr),e(z5,Hee),e(Hee,fBr),e(z5,gBr),e(Me,hBr),e(Me,Q5),e(Q5,Jwe),e(Jwe,uBr),e(Q5,pBr),e(Q5,Jee),e(Jee,_Br),e(Q5,bBr),e(Me,vBr),e(Me,W5),e(W5,Ywe),e(Ywe,FBr),e(W5,TBr),e(W5,Yee),e(Yee,MBr),e(W5,EBr),e(Me,CBr),e(Me,U5),e(U5,Kwe),e(Kwe,wBr),e(U5,ABr),e(U5,Kee),e(Kee,LBr),e(U5,yBr),e(Me,xBr),e(Me,H5),e(H5,Zwe),e(Zwe,$Br),e(H5,kBr),e(H5,Zee),e(Zee,SBr),e(H5,RBr),e(Me,PBr),e(Me,J5),e(J5,eAe),e(eAe,BBr),e(J5,IBr),e(J5,eoe),e(eoe,NBr),e(J5,qBr),e(Me,jBr),e(Me,Y5),e(Y5,oAe),e(oAe,DBr),e(Y5,GBr),e(Y5,ooe),e(ooe,OBr),e(Y5,VBr),e(Me,XBr),e(Me,K5),e(K5,rAe),e(rAe,zBr),e(K5,QBr),e(K5,roe),e(roe,WBr),e(K5,UBr),e(Me,HBr),e(Me,Z5),e(Z5,tAe),e(tAe,JBr),e(Z5,YBr),e(Z5,toe),e(toe,KBr),e(Z5,ZBr),e(qr,eIr),M(e0,qr,null),b(m,mZe,_),b(m,Yc,_),e(Yc,o0),e(o0,aAe),M(qk,aAe,null),e(Yc,oIr),e(Yc,nAe),e(nAe,rIr),b(m,fZe,_),b(m,dr,_),M(jk,dr,null),e(dr,tIr),e(dr,Kc),e(Kc,aIr),e(Kc,aoe),e(aoe,nIr),e(Kc,sIr),e(Kc,noe),e(noe,lIr),e(Kc,iIr),e(dr,dIr),e(dr,Dk),e(Dk,cIr),e(Dk,sAe),e(sAe,mIr),e(Dk,fIr),e(dr,gIr),e(dr,Wt),M(Gk,Wt,null),e(Wt,hIr),e(Wt,lAe),e(lAe,uIr),e(Wt,pIr),e(Wt,Zc),e(Zc,_Ir),e(Zc,iAe),e(iAe,bIr),e(Zc,vIr),e(Zc,soe),e(soe,FIr),e(Zc,TIr),e(Wt,MIr),M(r0,Wt,null),e(dr,EIr),e(dr,jr),M(Ok,jr,null),e(jr,CIr),e(jr,dAe),e(dAe,wIr),e(jr,AIr),e(jr,Ln),e(Ln,LIr),e(Ln,cAe),e(cAe,yIr),e(Ln,xIr),e(Ln,mAe),e(mAe,$Ir),e(Ln,kIr),e(Ln,fAe),e(fAe,SIr),e(Ln,RIr),e(jr,PIr),e(jr,Be),e(Be,t0),e(t0,gAe),e(gAe,BIr),e(t0,IIr),e(t0,loe),e(loe,NIr),e(t0,qIr),e(Be,jIr),e(Be,a0),e(a0,hAe),e(hAe,DIr),e(a0,GIr),e(a0,ioe),e(ioe,OIr),e(a0,VIr),e(Be,XIr),e(Be,Fl),e(Fl,uAe),e(uAe,zIr),e(Fl,QIr),e(Fl,doe),e(doe,WIr),e(Fl,UIr),e(Fl,coe),e(coe,HIr),e(Fl,JIr),e(Be,YIr),e(Be,n0),e(n0,pAe),e(pAe,KIr),e(n0,ZIr),e(n0,moe),e(moe,eNr),e(n0,oNr),e(Be,rNr),e(Be,s0),e(s0,_Ae),e(_Ae,tNr),e(s0,aNr),e(s0,foe),e(foe,nNr),e(s0,sNr),e(Be,lNr),e(Be,l0),e(l0,bAe),e(bAe,iNr),e(l0,dNr),e(l0,goe),e(goe,cNr),e(l0,mNr),e(Be,fNr),e(Be,i0),e(i0,vAe),e(vAe,gNr),e(i0,hNr),e(i0,hoe),e(hoe,uNr),e(i0,pNr),e(Be,_Nr),e(Be,d0),e(d0,FAe),e(FAe,bNr),e(d0,vNr),e(d0,uoe),e(uoe,FNr),e(d0,TNr),e(Be,MNr),e(Be,c0),e(c0,TAe),e(TAe,ENr),e(c0,CNr),e(c0,poe),e(poe,wNr),e(c0,ANr),e(jr,LNr),M(m0,jr,null),b(m,gZe,_),b(m,em,_),e(em,f0),e(f0,MAe),M(Vk,MAe,null),e(em,yNr),e(em,EAe),e(EAe,xNr),b(m,hZe,_),b(m,cr,_),M(Xk,cr,null),e(cr,$Nr),e(cr,om),e(om,kNr),e(om,_oe),e(_oe,SNr),e(om,RNr),e(om,boe),e(boe,PNr),e(om,BNr),e(cr,INr),e(cr,zk),e(zk,NNr),e(zk,CAe),e(CAe,qNr),e(zk,jNr),e(cr,DNr),e(cr,Ut),M(Qk,Ut,null),e(Ut,GNr),e(Ut,wAe),e(wAe,ONr),e(Ut,VNr),e(Ut,rm),e(rm,XNr),e(rm,AAe),e(AAe,zNr),e(rm,QNr),e(rm,voe),e(voe,WNr),e(rm,UNr),e(Ut,HNr),M(g0,Ut,null),e(cr,JNr),e(cr,Dr),M(Wk,Dr,null),e(Dr,YNr),e(Dr,LAe),e(LAe,KNr),e(Dr,ZNr),e(Dr,yn),e(yn,eqr),e(yn,yAe),e(yAe,oqr),e(yn,rqr),e(yn,xAe),e(xAe,tqr),e(yn,aqr),e(yn,$Ae),e($Ae,nqr),e(yn,sqr),e(Dr,lqr),e(Dr,tm),e(tm,h0),e(h0,kAe),e(kAe,iqr),e(h0,dqr),e(h0,Foe),e(Foe,cqr),e(h0,mqr),e(tm,fqr),e(tm,u0),e(u0,SAe),e(SAe,gqr),e(u0,hqr),e(u0,Toe),e(Toe,uqr),e(u0,pqr),e(tm,_qr),e(tm,p0),e(p0,RAe),e(RAe,bqr),e(p0,vqr),e(p0,Moe),e(Moe,Fqr),e(p0,Tqr),e(Dr,Mqr),M(_0,Dr,null),b(m,uZe,_),b(m,am,_),e(am,b0),e(b0,PAe),M(Uk,PAe,null),e(am,Eqr),e(am,BAe),e(BAe,Cqr),b(m,pZe,_),b(m,mr,_),M(Hk,mr,null),e(mr,wqr),e(mr,nm),e(nm,Aqr),e(nm,Eoe),e(Eoe,Lqr),e(nm,yqr),e(nm,Coe),e(Coe,xqr),e(nm,$qr),e(mr,kqr),e(mr,Jk),e(Jk,Sqr),e(Jk,IAe),e(IAe,Rqr),e(Jk,Pqr),e(mr,Bqr),e(mr,Ht),M(Yk,Ht,null),e(Ht,Iqr),e(Ht,NAe),e(NAe,Nqr),e(Ht,qqr),e(Ht,sm),e(sm,jqr),e(sm,qAe),e(qAe,Dqr),e(sm,Gqr),e(sm,woe),e(woe,Oqr),e(sm,Vqr),e(Ht,Xqr),M(v0,Ht,null),e(mr,zqr),e(mr,Gr),M(Kk,Gr,null),e(Gr,Qqr),e(Gr,jAe),e(jAe,Wqr),e(Gr,Uqr),e(Gr,xn),e(xn,Hqr),e(xn,DAe),e(DAe,Jqr),e(xn,Yqr),e(xn,GAe),e(GAe,Kqr),e(xn,Zqr),e(xn,OAe),e(OAe,ejr),e(xn,ojr),e(Gr,rjr),e(Gr,fe),e(fe,F0),e(F0,VAe),e(VAe,tjr),e(F0,ajr),e(F0,Aoe),e(Aoe,njr),e(F0,sjr),e(fe,ljr),e(fe,T0),e(T0,XAe),e(XAe,ijr),e(T0,djr),e(T0,Loe),e(Loe,cjr),e(T0,mjr),e(fe,fjr),e(fe,M0),e(M0,zAe),e(zAe,gjr),e(M0,hjr),e(M0,yoe),e(yoe,ujr),e(M0,pjr),e(fe,_jr),e(fe,E0),e(E0,QAe),e(QAe,bjr),e(E0,vjr),e(E0,xoe),e(xoe,Fjr),e(E0,Tjr),e(fe,Mjr),e(fe,C0),e(C0,WAe),e(WAe,Ejr),e(C0,Cjr),e(C0,$oe),e($oe,wjr),e(C0,Ajr),e(fe,Ljr),e(fe,w0),e(w0,UAe),e(UAe,yjr),e(w0,xjr),e(w0,koe),e(koe,$jr),e(w0,kjr),e(fe,Sjr),e(fe,A0),e(A0,HAe),e(HAe,Rjr),e(A0,Pjr),e(A0,Soe),e(Soe,Bjr),e(A0,Ijr),e(fe,Njr),e(fe,L0),e(L0,JAe),e(JAe,qjr),e(L0,jjr),e(L0,Roe),e(Roe,Djr),e(L0,Gjr),e(fe,Ojr),e(fe,y0),e(y0,YAe),e(YAe,Vjr),e(y0,Xjr),e(y0,Poe),e(Poe,zjr),e(y0,Qjr),e(fe,Wjr),e(fe,x0),e(x0,KAe),e(KAe,Ujr),e(x0,Hjr),e(x0,Boe),e(Boe,Jjr),e(x0,Yjr),e(fe,Kjr),e(fe,$0),e($0,ZAe),e(ZAe,Zjr),e($0,eDr),e($0,Ioe),e(Ioe,oDr),e($0,rDr),e(fe,tDr),e(fe,k0),e(k0,e6e),e(e6e,aDr),e(k0,nDr),e(k0,Noe),e(Noe,sDr),e(k0,lDr),e(fe,iDr),e(fe,S0),e(S0,o6e),e(o6e,dDr),e(S0,cDr),e(S0,qoe),e(qoe,mDr),e(S0,fDr),e(fe,gDr),e(fe,R0),e(R0,r6e),e(r6e,hDr),e(R0,uDr),e(R0,joe),e(joe,pDr),e(R0,_Dr),e(fe,bDr),e(fe,P0),e(P0,t6e),e(t6e,vDr),e(P0,FDr),e(P0,Doe),e(Doe,TDr),e(P0,MDr),e(fe,EDr),e(fe,B0),e(B0,a6e),e(a6e,CDr),e(B0,wDr),e(B0,Goe),e(Goe,ADr),e(B0,LDr),e(fe,yDr),e(fe,I0),e(I0,n6e),e(n6e,xDr),e(I0,$Dr),e(I0,Ooe),e(Ooe,kDr),e(I0,SDr),e(fe,RDr),e(fe,N0),e(N0,s6e),e(s6e,PDr),e(N0,BDr),e(N0,Voe),e(Voe,IDr),e(N0,NDr),e(fe,qDr),e(fe,q0),e(q0,l6e),e(l6e,jDr),e(q0,DDr),e(q0,Xoe),e(Xoe,GDr),e(q0,ODr),e(fe,VDr),e(fe,j0),e(j0,i6e),e(i6e,XDr),e(j0,zDr),e(j0,zoe),e(zoe,QDr),e(j0,WDr),e(Gr,UDr),M(D0,Gr,null),b(m,_Ze,_),b(m,lm,_),e(lm,G0),e(G0,d6e),M(Zk,d6e,null),e(lm,HDr),e(lm,c6e),e(c6e,JDr),b(m,bZe,_),b(m,fr,_),M(eS,fr,null),e(fr,YDr),e(fr,im),e(im,KDr),e(im,Qoe),e(Qoe,ZDr),e(im,eGr),e(im,Woe),e(Woe,oGr),e(im,rGr),e(fr,tGr),e(fr,oS),e(oS,aGr),e(oS,m6e),e(m6e,nGr),e(oS,sGr),e(fr,lGr),e(fr,Jt),M(rS,Jt,null),e(Jt,iGr),e(Jt,f6e),e(f6e,dGr),e(Jt,cGr),e(Jt,dm),e(dm,mGr),e(dm,g6e),e(g6e,fGr),e(dm,gGr),e(dm,Uoe),e(Uoe,hGr),e(dm,uGr),e(Jt,pGr),M(O0,Jt,null),e(fr,_Gr),e(fr,Or),M(tS,Or,null),e(Or,bGr),e(Or,h6e),e(h6e,vGr),e(Or,FGr),e(Or,$n),e($n,TGr),e($n,u6e),e(u6e,MGr),e($n,EGr),e($n,p6e),e(p6e,CGr),e($n,wGr),e($n,_6e),e(_6e,AGr),e($n,LGr),e(Or,yGr),e(Or,ye),e(ye,V0),e(V0,b6e),e(b6e,xGr),e(V0,$Gr),e(V0,Hoe),e(Hoe,kGr),e(V0,SGr),e(ye,RGr),e(ye,X0),e(X0,v6e),e(v6e,PGr),e(X0,BGr),e(X0,Joe),e(Joe,IGr),e(X0,NGr),e(ye,qGr),e(ye,z0),e(z0,F6e),e(F6e,jGr),e(z0,DGr),e(z0,Yoe),e(Yoe,GGr),e(z0,OGr),e(ye,VGr),e(ye,Q0),e(Q0,T6e),e(T6e,XGr),e(Q0,zGr),e(Q0,Koe),e(Koe,QGr),e(Q0,WGr),e(ye,UGr),e(ye,W0),e(W0,M6e),e(M6e,HGr),e(W0,JGr),e(W0,Zoe),e(Zoe,YGr),e(W0,KGr),e(ye,ZGr),e(ye,U0),e(U0,E6e),e(E6e,eOr),e(U0,oOr),e(U0,ere),e(ere,rOr),e(U0,tOr),e(ye,aOr),e(ye,H0),e(H0,C6e),e(C6e,nOr),e(H0,sOr),e(H0,ore),e(ore,lOr),e(H0,iOr),e(ye,dOr),e(ye,J0),e(J0,w6e),e(w6e,cOr),e(J0,mOr),e(J0,rre),e(rre,fOr),e(J0,gOr),e(ye,hOr),e(ye,Y0),e(Y0,A6e),e(A6e,uOr),e(Y0,pOr),e(Y0,tre),e(tre,_Or),e(Y0,bOr),e(ye,vOr),e(ye,K0),e(K0,L6e),e(L6e,FOr),e(K0,TOr),e(K0,are),e(are,MOr),e(K0,EOr),e(Or,COr),M(Z0,Or,null),b(m,vZe,_),b(m,cm,_),e(cm,ew),e(ew,y6e),M(aS,y6e,null),e(cm,wOr),e(cm,x6e),e(x6e,AOr),b(m,FZe,_),b(m,gr,_),M(nS,gr,null),e(gr,LOr),e(gr,mm),e(mm,yOr),e(mm,nre),e(nre,xOr),e(mm,$Or),e(mm,sre),e(sre,kOr),e(mm,SOr),e(gr,ROr),e(gr,sS),e(sS,POr),e(sS,$6e),e($6e,BOr),e(sS,IOr),e(gr,NOr),e(gr,Yt),M(lS,Yt,null),e(Yt,qOr),e(Yt,k6e),e(k6e,jOr),e(Yt,DOr),e(Yt,fm),e(fm,GOr),e(fm,S6e),e(S6e,OOr),e(fm,VOr),e(fm,lre),e(lre,XOr),e(fm,zOr),e(Yt,QOr),M(ow,Yt,null),e(gr,WOr),e(gr,Vr),M(iS,Vr,null),e(Vr,UOr),e(Vr,R6e),e(R6e,HOr),e(Vr,JOr),e(Vr,kn),e(kn,YOr),e(kn,P6e),e(P6e,KOr),e(kn,ZOr),e(kn,B6e),e(B6e,eVr),e(kn,oVr),e(kn,I6e),e(I6e,rVr),e(kn,tVr),e(Vr,aVr),e(Vr,re),e(re,rw),e(rw,N6e),e(N6e,nVr),e(rw,sVr),e(rw,ire),e(ire,lVr),e(rw,iVr),e(re,dVr),e(re,tw),e(tw,q6e),e(q6e,cVr),e(tw,mVr),e(tw,dre),e(dre,fVr),e(tw,gVr),e(re,hVr),e(re,aw),e(aw,j6e),e(j6e,uVr),e(aw,pVr),e(aw,cre),e(cre,_Vr),e(aw,bVr),e(re,vVr),e(re,nw),e(nw,D6e),e(D6e,FVr),e(nw,TVr),e(nw,mre),e(mre,MVr),e(nw,EVr),e(re,CVr),e(re,sw),e(sw,G6e),e(G6e,wVr),e(sw,AVr),e(sw,fre),e(fre,LVr),e(sw,yVr),e(re,xVr),e(re,lw),e(lw,O6e),e(O6e,$Vr),e(lw,kVr),e(lw,gre),e(gre,SVr),e(lw,RVr),e(re,PVr),e(re,iw),e(iw,V6e),e(V6e,BVr),e(iw,IVr),e(iw,hre),e(hre,NVr),e(iw,qVr),e(re,jVr),e(re,dw),e(dw,X6e),e(X6e,DVr),e(dw,GVr),e(dw,ure),e(ure,OVr),e(dw,VVr),e(re,XVr),e(re,cw),e(cw,z6e),e(z6e,zVr),e(cw,QVr),e(cw,pre),e(pre,WVr),e(cw,UVr),e(re,HVr),e(re,mw),e(mw,Q6e),e(Q6e,JVr),e(mw,YVr),e(mw,_re),e(_re,KVr),e(mw,ZVr),e(re,eXr),e(re,fw),e(fw,W6e),e(W6e,oXr),e(fw,rXr),e(fw,bre),e(bre,tXr),e(fw,aXr),e(re,nXr),e(re,gw),e(gw,U6e),e(U6e,sXr),e(gw,lXr),e(gw,vre),e(vre,iXr),e(gw,dXr),e(re,cXr),e(re,hw),e(hw,H6e),e(H6e,mXr),e(hw,fXr),e(hw,Fre),e(Fre,gXr),e(hw,hXr),e(re,uXr),e(re,uw),e(uw,J6e),e(J6e,pXr),e(uw,_Xr),e(uw,Tre),e(Tre,bXr),e(uw,vXr),e(re,FXr),e(re,pw),e(pw,Y6e),e(Y6e,TXr),e(pw,MXr),e(pw,Mre),e(Mre,EXr),e(pw,CXr),e(re,wXr),e(re,_w),e(_w,K6e),e(K6e,AXr),e(_w,LXr),e(_w,Ere),e(Ere,yXr),e(_w,xXr),e(re,$Xr),e(re,bw),e(bw,Z6e),e(Z6e,kXr),e(bw,SXr),e(bw,Cre),e(Cre,RXr),e(bw,PXr),e(re,BXr),e(re,vw),e(vw,e7e),e(e7e,IXr),e(vw,NXr),e(vw,wre),e(wre,qXr),e(vw,jXr),e(re,DXr),e(re,Fw),e(Fw,o7e),e(o7e,GXr),e(Fw,OXr),e(Fw,Are),e(Are,VXr),e(Fw,XXr),e(re,zXr),e(re,Tw),e(Tw,r7e),e(r7e,QXr),e(Tw,WXr),e(Tw,Lre),e(Lre,UXr),e(Tw,HXr),e(re,JXr),e(re,Mw),e(Mw,t7e),e(t7e,YXr),e(Mw,KXr),e(Mw,yre),e(yre,ZXr),e(Mw,ezr),e(re,ozr),e(re,Ew),e(Ew,a7e),e(a7e,rzr),e(Ew,tzr),e(Ew,xre),e(xre,azr),e(Ew,nzr),e(re,szr),e(re,Cw),e(Cw,n7e),e(n7e,lzr),e(Cw,izr),e(Cw,$re),e($re,dzr),e(Cw,czr),e(re,mzr),e(re,ww),e(ww,s7e),e(s7e,fzr),e(ww,gzr),e(ww,kre),e(kre,hzr),e(ww,uzr),e(re,pzr),e(re,Aw),e(Aw,l7e),e(l7e,_zr),e(Aw,bzr),e(Aw,Sre),e(Sre,vzr),e(Aw,Fzr),e(re,Tzr),e(re,Lw),e(Lw,i7e),e(i7e,Mzr),e(Lw,Ezr),e(Lw,Rre),e(Rre,Czr),e(Lw,wzr),e(re,Azr),e(re,yw),e(yw,d7e),e(d7e,Lzr),e(yw,yzr),e(yw,Pre),e(Pre,xzr),e(yw,$zr),e(Vr,kzr),M(xw,Vr,null),b(m,TZe,_),b(m,gm,_),e(gm,$w),e($w,c7e),M(dS,c7e,null),e(gm,Szr),e(gm,m7e),e(m7e,Rzr),b(m,MZe,_),b(m,hr,_),M(cS,hr,null),e(hr,Pzr),e(hr,hm),e(hm,Bzr),e(hm,Bre),e(Bre,Izr),e(hm,Nzr),e(hm,Ire),e(Ire,qzr),e(hm,jzr),e(hr,Dzr),e(hr,mS),e(mS,Gzr),e(mS,f7e),e(f7e,Ozr),e(mS,Vzr),e(hr,Xzr),e(hr,Kt),M(fS,Kt,null),e(Kt,zzr),e(Kt,g7e),e(g7e,Qzr),e(Kt,Wzr),e(Kt,um),e(um,Uzr),e(um,h7e),e(h7e,Hzr),e(um,Jzr),e(um,Nre),e(Nre,Yzr),e(um,Kzr),e(Kt,Zzr),M(kw,Kt,null),e(hr,eQr),e(hr,Xr),M(gS,Xr,null),e(Xr,oQr),e(Xr,u7e),e(u7e,rQr),e(Xr,tQr),e(Xr,Sn),e(Sn,aQr),e(Sn,p7e),e(p7e,nQr),e(Sn,sQr),e(Sn,_7e),e(_7e,lQr),e(Sn,iQr),e(Sn,b7e),e(b7e,dQr),e(Sn,cQr),e(Xr,mQr),e(Xr,ve),e(ve,Sw),e(Sw,v7e),e(v7e,fQr),e(Sw,gQr),e(Sw,qre),e(qre,hQr),e(Sw,uQr),e(ve,pQr),e(ve,Rw),e(Rw,F7e),e(F7e,_Qr),e(Rw,bQr),e(Rw,jre),e(jre,vQr),e(Rw,FQr),e(ve,TQr),e(ve,Pw),e(Pw,T7e),e(T7e,MQr),e(Pw,EQr),e(Pw,Dre),e(Dre,CQr),e(Pw,wQr),e(ve,AQr),e(ve,Bw),e(Bw,M7e),e(M7e,LQr),e(Bw,yQr),e(Bw,Gre),e(Gre,xQr),e(Bw,$Qr),e(ve,kQr),e(ve,Iw),e(Iw,E7e),e(E7e,SQr),e(Iw,RQr),e(Iw,Ore),e(Ore,PQr),e(Iw,BQr),e(ve,IQr),e(ve,Nw),e(Nw,C7e),e(C7e,NQr),e(Nw,qQr),e(Nw,Vre),e(Vre,jQr),e(Nw,DQr),e(ve,GQr),e(ve,qw),e(qw,w7e),e(w7e,OQr),e(qw,VQr),e(qw,Xre),e(Xre,XQr),e(qw,zQr),e(ve,QQr),e(ve,jw),e(jw,A7e),e(A7e,WQr),e(jw,UQr),e(jw,zre),e(zre,HQr),e(jw,JQr),e(ve,YQr),e(ve,Dw),e(Dw,L7e),e(L7e,KQr),e(Dw,ZQr),e(Dw,Qre),e(Qre,eWr),e(Dw,oWr),e(ve,rWr),e(ve,Gw),e(Gw,y7e),e(y7e,tWr),e(Gw,aWr),e(Gw,Wre),e(Wre,nWr),e(Gw,sWr),e(ve,lWr),e(ve,Ow),e(Ow,x7e),e(x7e,iWr),e(Ow,dWr),e(Ow,Ure),e(Ure,cWr),e(Ow,mWr),e(ve,fWr),e(ve,Vw),e(Vw,$7e),e($7e,gWr),e(Vw,hWr),e(Vw,Hre),e(Hre,uWr),e(Vw,pWr),e(ve,_Wr),e(ve,Xw),e(Xw,k7e),e(k7e,bWr),e(Xw,vWr),e(Xw,Jre),e(Jre,FWr),e(Xw,TWr),e(ve,MWr),e(ve,zw),e(zw,S7e),e(S7e,EWr),e(zw,CWr),e(zw,Yre),e(Yre,wWr),e(zw,AWr),e(ve,LWr),e(ve,Qw),e(Qw,R7e),e(R7e,yWr),e(Qw,xWr),e(Qw,Kre),e(Kre,$Wr),e(Qw,kWr),e(ve,SWr),e(ve,Ww),e(Ww,P7e),e(P7e,RWr),e(Ww,PWr),e(Ww,Zre),e(Zre,BWr),e(Ww,IWr),e(ve,NWr),e(ve,Uw),e(Uw,B7e),e(B7e,qWr),e(Uw,jWr),e(Uw,ete),e(ete,DWr),e(Uw,GWr),e(Xr,OWr),M(Hw,Xr,null),b(m,EZe,_),b(m,pm,_),e(pm,Jw),e(Jw,I7e),M(hS,I7e,null),e(pm,VWr),e(pm,N7e),e(N7e,XWr),b(m,CZe,_),b(m,ur,_),M(uS,ur,null),e(ur,zWr),e(ur,_m),e(_m,QWr),e(_m,ote),e(ote,WWr),e(_m,UWr),e(_m,rte),e(rte,HWr),e(_m,JWr),e(ur,YWr),e(ur,pS),e(pS,KWr),e(pS,q7e),e(q7e,ZWr),e(pS,eUr),e(ur,oUr),e(ur,Zt),M(_S,Zt,null),e(Zt,rUr),e(Zt,j7e),e(j7e,tUr),e(Zt,aUr),e(Zt,bm),e(bm,nUr),e(bm,D7e),e(D7e,sUr),e(bm,lUr),e(bm,tte),e(tte,iUr),e(bm,dUr),e(Zt,cUr),M(Yw,Zt,null),e(ur,mUr),e(ur,zr),M(bS,zr,null),e(zr,fUr),e(zr,G7e),e(G7e,gUr),e(zr,hUr),e(zr,Rn),e(Rn,uUr),e(Rn,O7e),e(O7e,pUr),e(Rn,_Ur),e(Rn,V7e),e(V7e,bUr),e(Rn,vUr),e(Rn,X7e),e(X7e,FUr),e(Rn,TUr),e(zr,MUr),e(zr,vS),e(vS,Kw),e(Kw,z7e),e(z7e,EUr),e(Kw,CUr),e(Kw,ate),e(ate,wUr),e(Kw,AUr),e(vS,LUr),e(vS,Zw),e(Zw,Q7e),e(Q7e,yUr),e(Zw,xUr),e(Zw,nte),e(nte,$Ur),e(Zw,kUr),e(zr,SUr),M(eA,zr,null),b(m,wZe,_),b(m,vm,_),e(vm,oA),e(oA,W7e),M(FS,W7e,null),e(vm,RUr),e(vm,U7e),e(U7e,PUr),b(m,AZe,_),b(m,pr,_),M(TS,pr,null),e(pr,BUr),e(pr,Fm),e(Fm,IUr),e(Fm,ste),e(ste,NUr),e(Fm,qUr),e(Fm,lte),e(lte,jUr),e(Fm,DUr),e(pr,GUr),e(pr,MS),e(MS,OUr),e(MS,H7e),e(H7e,VUr),e(MS,XUr),e(pr,zUr),e(pr,ea),M(ES,ea,null),e(ea,QUr),e(ea,J7e),e(J7e,WUr),e(ea,UUr),e(ea,Tm),e(Tm,HUr),e(Tm,Y7e),e(Y7e,JUr),e(Tm,YUr),e(Tm,ite),e(ite,KUr),e(Tm,ZUr),e(ea,eHr),M(rA,ea,null),e(pr,oHr),e(pr,Qr),M(CS,Qr,null),e(Qr,rHr),e(Qr,K7e),e(K7e,tHr),e(Qr,aHr),e(Qr,Pn),e(Pn,nHr),e(Pn,Z7e),e(Z7e,sHr),e(Pn,lHr),e(Pn,eLe),e(eLe,iHr),e(Pn,dHr),e(Pn,oLe),e(oLe,cHr),e(Pn,mHr),e(Qr,fHr),e(Qr,rLe),e(rLe,tA),e(tA,tLe),e(tLe,gHr),e(tA,hHr),e(tA,dte),e(dte,uHr),e(tA,pHr),e(Qr,_Hr),M(aA,Qr,null),b(m,LZe,_),b(m,Mm,_),e(Mm,nA),e(nA,aLe),M(wS,aLe,null),e(Mm,bHr),e(Mm,nLe),e(nLe,vHr),b(m,yZe,_),b(m,_r,_),M(AS,_r,null),e(_r,FHr),e(_r,Em),e(Em,THr),e(Em,cte),e(cte,MHr),e(Em,EHr),e(Em,mte),e(mte,CHr),e(Em,wHr),e(_r,AHr),e(_r,LS),e(LS,LHr),e(LS,sLe),e(sLe,yHr),e(LS,xHr),e(_r,$Hr),e(_r,oa),M(yS,oa,null),e(oa,kHr),e(oa,lLe),e(lLe,SHr),e(oa,RHr),e(oa,Cm),e(Cm,PHr),e(Cm,iLe),e(iLe,BHr),e(Cm,IHr),e(Cm,fte),e(fte,NHr),e(Cm,qHr),e(oa,jHr),M(sA,oa,null),e(_r,DHr),e(_r,Wr),M(xS,Wr,null),e(Wr,GHr),e(Wr,dLe),e(dLe,OHr),e(Wr,VHr),e(Wr,Bn),e(Bn,XHr),e(Bn,cLe),e(cLe,zHr),e(Bn,QHr),e(Bn,mLe),e(mLe,WHr),e(Bn,UHr),e(Bn,fLe),e(fLe,HHr),e(Bn,JHr),e(Wr,YHr),e(Wr,gLe),e(gLe,lA),e(lA,hLe),e(hLe,KHr),e(lA,ZHr),e(lA,gte),e(gte,eJr),e(lA,oJr),e(Wr,rJr),M(iA,Wr,null),b(m,xZe,_),b(m,wm,_),e(wm,dA),e(dA,uLe),M($S,uLe,null),e(wm,tJr),e(wm,pLe),e(pLe,aJr),b(m,$Ze,_),b(m,br,_),M(kS,br,null),e(br,nJr),e(br,Am),e(Am,sJr),e(Am,hte),e(hte,lJr),e(Am,iJr),e(Am,ute),e(ute,dJr),e(Am,cJr),e(br,mJr),e(br,SS),e(SS,fJr),e(SS,_Le),e(_Le,gJr),e(SS,hJr),e(br,uJr),e(br,ra),M(RS,ra,null),e(ra,pJr),e(ra,bLe),e(bLe,_Jr),e(ra,bJr),e(ra,Lm),e(Lm,vJr),e(Lm,vLe),e(vLe,FJr),e(Lm,TJr),e(Lm,pte),e(pte,MJr),e(Lm,EJr),e(ra,CJr),M(cA,ra,null),e(br,wJr),e(br,Ur),M(PS,Ur,null),e(Ur,AJr),e(Ur,FLe),e(FLe,LJr),e(Ur,yJr),e(Ur,In),e(In,xJr),e(In,TLe),e(TLe,$Jr),e(In,kJr),e(In,MLe),e(MLe,SJr),e(In,RJr),e(In,ELe),e(ELe,PJr),e(In,BJr),e(Ur,IJr),e(Ur,de),e(de,mA),e(mA,CLe),e(CLe,NJr),e(mA,qJr),e(mA,_te),e(_te,jJr),e(mA,DJr),e(de,GJr),e(de,fA),e(fA,wLe),e(wLe,OJr),e(fA,VJr),e(fA,bte),e(bte,XJr),e(fA,zJr),e(de,QJr),e(de,gA),e(gA,ALe),e(ALe,WJr),e(gA,UJr),e(gA,vte),e(vte,HJr),e(gA,JJr),e(de,YJr),e(de,hA),e(hA,LLe),e(LLe,KJr),e(hA,ZJr),e(hA,Fte),e(Fte,eYr),e(hA,oYr),e(de,rYr),e(de,uA),e(uA,yLe),e(yLe,tYr),e(uA,aYr),e(uA,Tte),e(Tte,nYr),e(uA,sYr),e(de,lYr),e(de,pA),e(pA,xLe),e(xLe,iYr),e(pA,dYr),e(pA,Mte),e(Mte,cYr),e(pA,mYr),e(de,fYr),e(de,_A),e(_A,$Le),e($Le,gYr),e(_A,hYr),e(_A,Ete),e(Ete,uYr),e(_A,pYr),e(de,_Yr),e(de,bA),e(bA,kLe),e(kLe,bYr),e(bA,vYr),e(bA,Cte),e(Cte,FYr),e(bA,TYr),e(de,MYr),e(de,vA),e(vA,SLe),e(SLe,EYr),e(vA,CYr),e(vA,wte),e(wte,wYr),e(vA,AYr),e(de,LYr),e(de,FA),e(FA,RLe),e(RLe,yYr),e(FA,xYr),e(FA,Ate),e(Ate,$Yr),e(FA,kYr),e(de,SYr),e(de,TA),e(TA,PLe),e(PLe,RYr),e(TA,PYr),e(TA,Lte),e(Lte,BYr),e(TA,IYr),e(de,NYr),e(de,MA),e(MA,BLe),e(BLe,qYr),e(MA,jYr),e(MA,yte),e(yte,DYr),e(MA,GYr),e(de,OYr),e(de,EA),e(EA,ILe),e(ILe,VYr),e(EA,XYr),e(EA,xte),e(xte,zYr),e(EA,QYr),e(de,WYr),e(de,CA),e(CA,NLe),e(NLe,UYr),e(CA,HYr),e(CA,$te),e($te,JYr),e(CA,YYr),e(de,KYr),e(de,wA),e(wA,qLe),e(qLe,ZYr),e(wA,eKr),e(wA,kte),e(kte,oKr),e(wA,rKr),e(de,tKr),e(de,AA),e(AA,jLe),e(jLe,aKr),e(AA,nKr),e(AA,Ste),e(Ste,sKr),e(AA,lKr),e(de,iKr),e(de,LA),e(LA,DLe),e(DLe,dKr),e(LA,cKr),e(LA,Rte),e(Rte,mKr),e(LA,fKr),e(de,gKr),e(de,yA),e(yA,GLe),e(GLe,hKr),e(yA,uKr),e(yA,Pte),e(Pte,pKr),e(yA,_Kr),e(de,bKr),e(de,xA),e(xA,OLe),e(OLe,vKr),e(xA,FKr),e(xA,Bte),e(Bte,TKr),e(xA,MKr),e(de,EKr),e(de,$A),e($A,VLe),e(VLe,CKr),e($A,wKr),e($A,Ite),e(Ite,AKr),e($A,LKr),e(de,yKr),e(de,kA),e(kA,XLe),e(XLe,xKr),e(kA,$Kr),e(kA,Nte),e(Nte,kKr),e(kA,SKr),e(Ur,RKr),M(SA,Ur,null),b(m,kZe,_),b(m,ym,_),e(ym,RA),e(RA,zLe),M(BS,zLe,null),e(ym,PKr),e(ym,QLe),e(QLe,BKr),b(m,SZe,_),b(m,vr,_),M(IS,vr,null),e(vr,IKr),e(vr,xm),e(xm,NKr),e(xm,qte),e(qte,qKr),e(xm,jKr),e(xm,jte),e(jte,DKr),e(xm,GKr),e(vr,OKr),e(vr,NS),e(NS,VKr),e(NS,WLe),e(WLe,XKr),e(NS,zKr),e(vr,QKr),e(vr,ta),M(qS,ta,null),e(ta,WKr),e(ta,ULe),e(ULe,UKr),e(ta,HKr),e(ta,$m),e($m,JKr),e($m,HLe),e(HLe,YKr),e($m,KKr),e($m,Dte),e(Dte,ZKr),e($m,eZr),e(ta,oZr),M(PA,ta,null),e(vr,rZr),e(vr,Hr),M(jS,Hr,null),e(Hr,tZr),e(Hr,JLe),e(JLe,aZr),e(Hr,nZr),e(Hr,Nn),e(Nn,sZr),e(Nn,YLe),e(YLe,lZr),e(Nn,iZr),e(Nn,KLe),e(KLe,dZr),e(Nn,cZr),e(Nn,ZLe),e(ZLe,mZr),e(Nn,fZr),e(Hr,gZr),e(Hr,ce),e(ce,BA),e(BA,eye),e(eye,hZr),e(BA,uZr),e(BA,Gte),e(Gte,pZr),e(BA,_Zr),e(ce,bZr),e(ce,IA),e(IA,oye),e(oye,vZr),e(IA,FZr),e(IA,Ote),e(Ote,TZr),e(IA,MZr),e(ce,EZr),e(ce,NA),e(NA,rye),e(rye,CZr),e(NA,wZr),e(NA,Vte),e(Vte,AZr),e(NA,LZr),e(ce,yZr),e(ce,qA),e(qA,tye),e(tye,xZr),e(qA,$Zr),e(qA,Xte),e(Xte,kZr),e(qA,SZr),e(ce,RZr),e(ce,jA),e(jA,aye),e(aye,PZr),e(jA,BZr),e(jA,zte),e(zte,IZr),e(jA,NZr),e(ce,qZr),e(ce,DA),e(DA,nye),e(nye,jZr),e(DA,DZr),e(DA,Qte),e(Qte,GZr),e(DA,OZr),e(ce,VZr),e(ce,GA),e(GA,sye),e(sye,XZr),e(GA,zZr),e(GA,Wte),e(Wte,QZr),e(GA,WZr),e(ce,UZr),e(ce,OA),e(OA,lye),e(lye,HZr),e(OA,JZr),e(OA,Ute),e(Ute,YZr),e(OA,KZr),e(ce,ZZr),e(ce,VA),e(VA,iye),e(iye,eet),e(VA,oet),e(VA,Hte),e(Hte,ret),e(VA,tet),e(ce,aet),e(ce,XA),e(XA,dye),e(dye,net),e(XA,set),e(XA,Jte),e(Jte,iet),e(XA,det),e(ce,cet),e(ce,zA),e(zA,cye),e(cye,met),e(zA,fet),e(zA,Yte),e(Yte,get),e(zA,het),e(ce,uet),e(ce,QA),e(QA,mye),e(mye,pet),e(QA,_et),e(QA,Kte),e(Kte,bet),e(QA,vet),e(ce,Fet),e(ce,WA),e(WA,fye),e(fye,Tet),e(WA,Met),e(WA,Zte),e(Zte,Eet),e(WA,Cet),e(ce,wet),e(ce,UA),e(UA,gye),e(gye,Aet),e(UA,Let),e(UA,eae),e(eae,yet),e(UA,xet),e(ce,$et),e(ce,HA),e(HA,hye),e(hye,ket),e(HA,Set),e(HA,oae),e(oae,Ret),e(HA,Pet),e(ce,Bet),e(ce,JA),e(JA,uye),e(uye,Iet),e(JA,Net),e(JA,rae),e(rae,qet),e(JA,jet),e(ce,Det),e(ce,YA),e(YA,pye),e(pye,Get),e(YA,Oet),e(YA,tae),e(tae,Vet),e(YA,Xet),e(ce,zet),e(ce,KA),e(KA,_ye),e(_ye,Qet),e(KA,Wet),e(KA,aae),e(aae,Uet),e(KA,Het),e(ce,Jet),e(ce,ZA),e(ZA,bye),e(bye,Yet),e(ZA,Ket),e(ZA,nae),e(nae,Zet),e(ZA,eot),e(ce,oot),e(ce,e6),e(e6,vye),e(vye,rot),e(e6,tot),e(e6,sae),e(sae,aot),e(e6,not),e(ce,sot),e(ce,o6),e(o6,Fye),e(Fye,lot),e(o6,iot),e(o6,lae),e(lae,dot),e(o6,cot),e(Hr,mot),M(r6,Hr,null),b(m,RZe,_),b(m,km,_),e(km,t6),e(t6,Tye),M(DS,Tye,null),e(km,fot),e(km,Mye),e(Mye,got),b(m,PZe,_),b(m,Fr,_),M(GS,Fr,null),e(Fr,hot),e(Fr,Sm),e(Sm,uot),e(Sm,iae),e(iae,pot),e(Sm,_ot),e(Sm,dae),e(dae,bot),e(Sm,vot),e(Fr,Fot),e(Fr,OS),e(OS,Tot),e(OS,Eye),e(Eye,Mot),e(OS,Eot),e(Fr,Cot),e(Fr,aa),M(VS,aa,null),e(aa,wot),e(aa,Cye),e(Cye,Aot),e(aa,Lot),e(aa,Rm),e(Rm,yot),e(Rm,wye),e(wye,xot),e(Rm,$ot),e(Rm,cae),e(cae,kot),e(Rm,Sot),e(aa,Rot),M(a6,aa,null),e(Fr,Pot),e(Fr,Jr),M(XS,Jr,null),e(Jr,Bot),e(Jr,Aye),e(Aye,Iot),e(Jr,Not),e(Jr,qn),e(qn,qot),e(qn,Lye),e(Lye,jot),e(qn,Dot),e(qn,yye),e(yye,Got),e(qn,Oot),e(qn,xye),e(xye,Vot),e(qn,Xot),e(Jr,zot),e(Jr,$ye),e($ye,n6),e(n6,kye),e(kye,Qot),e(n6,Wot),e(n6,mae),e(mae,Uot),e(n6,Hot),e(Jr,Jot),M(s6,Jr,null),b(m,BZe,_),b(m,Pm,_),e(Pm,l6),e(l6,Sye),M(zS,Sye,null),e(Pm,Yot),e(Pm,Rye),e(Rye,Kot),b(m,IZe,_),b(m,Tr,_),M(QS,Tr,null),e(Tr,Zot),e(Tr,Bm),e(Bm,ert),e(Bm,fae),e(fae,ort),e(Bm,rrt),e(Bm,gae),e(gae,trt),e(Bm,art),e(Tr,nrt),e(Tr,WS),e(WS,srt),e(WS,Pye),e(Pye,lrt),e(WS,irt),e(Tr,drt),e(Tr,na),M(US,na,null),e(na,crt),e(na,Bye),e(Bye,mrt),e(na,frt),e(na,Im),e(Im,grt),e(Im,Iye),e(Iye,hrt),e(Im,urt),e(Im,hae),e(hae,prt),e(Im,_rt),e(na,brt),M(i6,na,null),e(Tr,vrt),e(Tr,Yr),M(HS,Yr,null),e(Yr,Frt),e(Yr,Nye),e(Nye,Trt),e(Yr,Mrt),e(Yr,jn),e(jn,Ert),e(jn,qye),e(qye,Crt),e(jn,wrt),e(jn,jye),e(jye,Art),e(jn,Lrt),e(jn,Dye),e(Dye,yrt),e(jn,xrt),e(Yr,$rt),e(Yr,Gye),e(Gye,d6),e(d6,Oye),e(Oye,krt),e(d6,Srt),e(d6,uae),e(uae,Rrt),e(d6,Prt),e(Yr,Brt),M(c6,Yr,null),b(m,NZe,_),b(m,Nm,_),e(Nm,m6),e(m6,Vye),M(JS,Vye,null),e(Nm,Irt),e(Nm,Xye),e(Xye,Nrt),b(m,qZe,_),b(m,Mr,_),M(YS,Mr,null),e(Mr,qrt),e(Mr,qm),e(qm,jrt),e(qm,pae),e(pae,Drt),e(qm,Grt),e(qm,_ae),e(_ae,Ort),e(qm,Vrt),e(Mr,Xrt),e(Mr,KS),e(KS,zrt),e(KS,zye),e(zye,Qrt),e(KS,Wrt),e(Mr,Urt),e(Mr,sa),M(ZS,sa,null),e(sa,Hrt),e(sa,Qye),e(Qye,Jrt),e(sa,Yrt),e(sa,jm),e(jm,Krt),e(jm,Wye),e(Wye,Zrt),e(jm,ett),e(jm,bae),e(bae,ott),e(jm,rtt),e(sa,ttt),M(f6,sa,null),e(Mr,att),e(Mr,Kr),M(eR,Kr,null),e(Kr,ntt),e(Kr,Uye),e(Uye,stt),e(Kr,ltt),e(Kr,Dn),e(Dn,itt),e(Dn,Hye),e(Hye,dtt),e(Dn,ctt),e(Dn,Jye),e(Jye,mtt),e(Dn,ftt),e(Dn,Yye),e(Yye,gtt),e(Dn,htt),e(Kr,utt),e(Kr,te),e(te,g6),e(g6,Kye),e(Kye,ptt),e(g6,_tt),e(g6,vae),e(vae,btt),e(g6,vtt),e(te,Ftt),e(te,h6),e(h6,Zye),e(Zye,Ttt),e(h6,Mtt),e(h6,Fae),e(Fae,Ett),e(h6,Ctt),e(te,wtt),e(te,u6),e(u6,e8e),e(e8e,Att),e(u6,Ltt),e(u6,Tae),e(Tae,ytt),e(u6,xtt),e(te,$tt),e(te,p6),e(p6,o8e),e(o8e,ktt),e(p6,Stt),e(p6,Mae),e(Mae,Rtt),e(p6,Ptt),e(te,Btt),e(te,_6),e(_6,r8e),e(r8e,Itt),e(_6,Ntt),e(_6,Eae),e(Eae,qtt),e(_6,jtt),e(te,Dtt),e(te,b6),e(b6,t8e),e(t8e,Gtt),e(b6,Ott),e(b6,Cae),e(Cae,Vtt),e(b6,Xtt),e(te,ztt),e(te,v6),e(v6,a8e),e(a8e,Qtt),e(v6,Wtt),e(v6,wae),e(wae,Utt),e(v6,Htt),e(te,Jtt),e(te,F6),e(F6,n8e),e(n8e,Ytt),e(F6,Ktt),e(F6,Aae),e(Aae,Ztt),e(F6,eat),e(te,oat),e(te,T6),e(T6,s8e),e(s8e,rat),e(T6,tat),e(T6,Lae),e(Lae,aat),e(T6,nat),e(te,sat),e(te,M6),e(M6,l8e),e(l8e,lat),e(M6,iat),e(M6,yae),e(yae,dat),e(M6,cat),e(te,mat),e(te,E6),e(E6,i8e),e(i8e,fat),e(E6,gat),e(E6,xae),e(xae,hat),e(E6,uat),e(te,pat),e(te,C6),e(C6,d8e),e(d8e,_at),e(C6,bat),e(C6,$ae),e($ae,vat),e(C6,Fat),e(te,Tat),e(te,w6),e(w6,c8e),e(c8e,Mat),e(w6,Eat),e(w6,kae),e(kae,Cat),e(w6,wat),e(te,Aat),e(te,A6),e(A6,m8e),e(m8e,Lat),e(A6,yat),e(A6,Sae),e(Sae,xat),e(A6,$at),e(te,kat),e(te,L6),e(L6,f8e),e(f8e,Sat),e(L6,Rat),e(L6,Rae),e(Rae,Pat),e(L6,Bat),e(te,Iat),e(te,y6),e(y6,g8e),e(g8e,Nat),e(y6,qat),e(y6,Pae),e(Pae,jat),e(y6,Dat),e(te,Gat),e(te,x6),e(x6,h8e),e(h8e,Oat),e(x6,Vat),e(x6,Bae),e(Bae,Xat),e(x6,zat),e(te,Qat),e(te,$6),e($6,u8e),e(u8e,Wat),e($6,Uat),e($6,Iae),e(Iae,Hat),e($6,Jat),e(te,Yat),e(te,k6),e(k6,p8e),e(p8e,Kat),e(k6,Zat),e(k6,Nae),e(Nae,ent),e(k6,ont),e(te,rnt),e(te,S6),e(S6,_8e),e(_8e,tnt),e(S6,ant),e(S6,qae),e(qae,nnt),e(S6,snt),e(te,lnt),e(te,R6),e(R6,b8e),e(b8e,int),e(R6,dnt),e(R6,jae),e(jae,cnt),e(R6,mnt),e(te,fnt),e(te,P6),e(P6,v8e),e(v8e,gnt),e(P6,hnt),e(P6,Dae),e(Dae,unt),e(P6,pnt),e(te,_nt),e(te,B6),e(B6,F8e),e(F8e,bnt),e(B6,vnt),e(B6,Gae),e(Gae,Fnt),e(B6,Tnt),e(te,Mnt),e(te,I6),e(I6,T8e),e(T8e,Ent),e(I6,Cnt),e(I6,Oae),e(Oae,wnt),e(I6,Ant),e(te,Lnt),e(te,N6),e(N6,M8e),e(M8e,ynt),e(N6,xnt),e(N6,Vae),e(Vae,$nt),e(N6,knt),e(te,Snt),e(te,q6),e(q6,E8e),e(E8e,Rnt),e(q6,Pnt),e(q6,Xae),e(Xae,Bnt),e(q6,Int),e(te,Nnt),e(te,j6),e(j6,C8e),e(C8e,qnt),e(j6,jnt),e(j6,zae),e(zae,Dnt),e(j6,Gnt),e(Kr,Ont),M(D6,Kr,null),b(m,jZe,_),b(m,Dm,_),e(Dm,G6),e(G6,w8e),M(oR,w8e,null),e(Dm,Vnt),e(Dm,A8e),e(A8e,Xnt),b(m,DZe,_),b(m,Er,_),M(rR,Er,null),e(Er,znt),e(Er,Gm),e(Gm,Qnt),e(Gm,Qae),e(Qae,Wnt),e(Gm,Unt),e(Gm,Wae),e(Wae,Hnt),e(Gm,Jnt),e(Er,Ynt),e(Er,tR),e(tR,Knt),e(tR,L8e),e(L8e,Znt),e(tR,est),e(Er,ost),e(Er,la),M(aR,la,null),e(la,rst),e(la,y8e),e(y8e,tst),e(la,ast),e(la,Om),e(Om,nst),e(Om,x8e),e(x8e,sst),e(Om,lst),e(Om,Uae),e(Uae,ist),e(Om,dst),e(la,cst),M(O6,la,null),e(Er,mst),e(Er,Zr),M(nR,Zr,null),e(Zr,fst),e(Zr,$8e),e($8e,gst),e(Zr,hst),e(Zr,Gn),e(Gn,ust),e(Gn,k8e),e(k8e,pst),e(Gn,_st),e(Gn,S8e),e(S8e,bst),e(Gn,vst),e(Gn,R8e),e(R8e,Fst),e(Gn,Tst),e(Zr,Mst),e(Zr,xe),e(xe,V6),e(V6,P8e),e(P8e,Est),e(V6,Cst),e(V6,Hae),e(Hae,wst),e(V6,Ast),e(xe,Lst),e(xe,X6),e(X6,B8e),e(B8e,yst),e(X6,xst),e(X6,Jae),e(Jae,$st),e(X6,kst),e(xe,Sst),e(xe,z6),e(z6,I8e),e(I8e,Rst),e(z6,Pst),e(z6,Yae),e(Yae,Bst),e(z6,Ist),e(xe,Nst),e(xe,Q6),e(Q6,N8e),e(N8e,qst),e(Q6,jst),e(Q6,Kae),e(Kae,Dst),e(Q6,Gst),e(xe,Ost),e(xe,W6),e(W6,q8e),e(q8e,Vst),e(W6,Xst),e(W6,Zae),e(Zae,zst),e(W6,Qst),e(xe,Wst),e(xe,U6),e(U6,j8e),e(j8e,Ust),e(U6,Hst),e(U6,ene),e(ene,Jst),e(U6,Yst),e(xe,Kst),e(xe,H6),e(H6,D8e),e(D8e,Zst),e(H6,elt),e(H6,one),e(one,olt),e(H6,rlt),e(xe,tlt),e(xe,J6),e(J6,G8e),e(G8e,alt),e(J6,nlt),e(J6,rne),e(rne,slt),e(J6,llt),e(xe,ilt),e(xe,Y6),e(Y6,O8e),e(O8e,dlt),e(Y6,clt),e(Y6,tne),e(tne,mlt),e(Y6,flt),e(xe,glt),e(xe,K6),e(K6,V8e),e(V8e,hlt),e(K6,ult),e(K6,ane),e(ane,plt),e(K6,_lt),e(Zr,blt),M(Z6,Zr,null),b(m,GZe,_),b(m,Vm,_),e(Vm,e7),e(e7,X8e),M(sR,X8e,null),e(Vm,vlt),e(Vm,z8e),e(z8e,Flt),b(m,OZe,_),b(m,Cr,_),M(lR,Cr,null),e(Cr,Tlt),e(Cr,Xm),e(Xm,Mlt),e(Xm,nne),e(nne,Elt),e(Xm,Clt),e(Xm,sne),e(sne,wlt),e(Xm,Alt),e(Cr,Llt),e(Cr,iR),e(iR,ylt),e(iR,Q8e),e(Q8e,xlt),e(iR,$lt),e(Cr,klt),e(Cr,ia),M(dR,ia,null),e(ia,Slt),e(ia,W8e),e(W8e,Rlt),e(ia,Plt),e(ia,zm),e(zm,Blt),e(zm,U8e),e(U8e,Ilt),e(zm,Nlt),e(zm,lne),e(lne,qlt),e(zm,jlt),e(ia,Dlt),M(o7,ia,null),e(Cr,Glt),e(Cr,et),M(cR,et,null),e(et,Olt),e(et,H8e),e(H8e,Vlt),e(et,Xlt),e(et,On),e(On,zlt),e(On,J8e),e(J8e,Qlt),e(On,Wlt),e(On,Y8e),e(Y8e,Ult),e(On,Hlt),e(On,K8e),e(K8e,Jlt),e(On,Ylt),e(et,Klt),e(et,Ee),e(Ee,r7),e(r7,Z8e),e(Z8e,Zlt),e(r7,eit),e(r7,ine),e(ine,oit),e(r7,rit),e(Ee,tit),e(Ee,t7),e(t7,e9e),e(e9e,ait),e(t7,nit),e(t7,dne),e(dne,sit),e(t7,lit),e(Ee,iit),e(Ee,a7),e(a7,o9e),e(o9e,dit),e(a7,cit),e(a7,cne),e(cne,mit),e(a7,fit),e(Ee,git),e(Ee,n7),e(n7,r9e),e(r9e,hit),e(n7,uit),e(n7,mne),e(mne,pit),e(n7,_it),e(Ee,bit),e(Ee,s7),e(s7,t9e),e(t9e,vit),e(s7,Fit),e(s7,fne),e(fne,Tit),e(s7,Mit),e(Ee,Eit),e(Ee,l7),e(l7,a9e),e(a9e,Cit),e(l7,wit),e(l7,gne),e(gne,Ait),e(l7,Lit),e(Ee,yit),e(Ee,i7),e(i7,n9e),e(n9e,xit),e(i7,$it),e(i7,hne),e(hne,kit),e(i7,Sit),e(Ee,Rit),e(Ee,d7),e(d7,s9e),e(s9e,Pit),e(d7,Bit),e(d7,une),e(une,Iit),e(d7,Nit),e(Ee,qit),e(Ee,c7),e(c7,l9e),e(l9e,jit),e(c7,Dit),e(c7,pne),e(pne,Git),e(c7,Oit),e(Ee,Vit),e(Ee,m7),e(m7,i9e),e(i9e,Xit),e(m7,zit),e(m7,_ne),e(_ne,Qit),e(m7,Wit),e(Ee,Uit),e(Ee,f7),e(f7,d9e),e(d9e,Hit),e(f7,Jit),e(f7,bne),e(bne,Yit),e(f7,Kit),e(Ee,Zit),e(Ee,g7),e(g7,c9e),e(c9e,edt),e(g7,odt),e(g7,vne),e(vne,rdt),e(g7,tdt),e(Ee,adt),e(Ee,h7),e(h7,m9e),e(m9e,ndt),e(h7,sdt),e(h7,Fne),e(Fne,ldt),e(h7,idt),e(et,ddt),M(u7,et,null),b(m,VZe,_),b(m,Qm,_),e(Qm,p7),e(p7,f9e),M(mR,f9e,null),e(Qm,cdt),e(Qm,g9e),e(g9e,mdt),b(m,XZe,_),b(m,wr,_),M(fR,wr,null),e(wr,fdt),e(wr,Wm),e(Wm,gdt),e(Wm,Tne),e(Tne,hdt),e(Wm,udt),e(Wm,Mne),e(Mne,pdt),e(Wm,_dt),e(wr,bdt),e(wr,gR),e(gR,vdt),e(gR,h9e),e(h9e,Fdt),e(gR,Tdt),e(wr,Mdt),e(wr,da),M(hR,da,null),e(da,Edt),e(da,u9e),e(u9e,Cdt),e(da,wdt),e(da,Um),e(Um,Adt),e(Um,p9e),e(p9e,Ldt),e(Um,ydt),e(Um,Ene),e(Ene,xdt),e(Um,$dt),e(da,kdt),M(_7,da,null),e(wr,Sdt),e(wr,ot),M(uR,ot,null),e(ot,Rdt),e(ot,_9e),e(_9e,Pdt),e(ot,Bdt),e(ot,Vn),e(Vn,Idt),e(Vn,b9e),e(b9e,Ndt),e(Vn,qdt),e(Vn,v9e),e(v9e,jdt),e(Vn,Ddt),e(Vn,F9e),e(F9e,Gdt),e(Vn,Odt),e(ot,Vdt),e(ot,$e),e($e,b7),e(b7,T9e),e(T9e,Xdt),e(b7,zdt),e(b7,Cne),e(Cne,Qdt),e(b7,Wdt),e($e,Udt),e($e,v7),e(v7,M9e),e(M9e,Hdt),e(v7,Jdt),e(v7,wne),e(wne,Ydt),e(v7,Kdt),e($e,Zdt),e($e,F7),e(F7,E9e),e(E9e,ect),e(F7,oct),e(F7,Ane),e(Ane,rct),e(F7,tct),e($e,act),e($e,T7),e(T7,C9e),e(C9e,nct),e(T7,sct),e(T7,Lne),e(Lne,lct),e(T7,ict),e($e,dct),e($e,M7),e(M7,w9e),e(w9e,cct),e(M7,mct),e(M7,yne),e(yne,fct),e(M7,gct),e($e,hct),e($e,E7),e(E7,A9e),e(A9e,uct),e(E7,pct),e(E7,xne),e(xne,_ct),e(E7,bct),e($e,vct),e($e,C7),e(C7,L9e),e(L9e,Fct),e(C7,Tct),e(C7,$ne),e($ne,Mct),e(C7,Ect),e($e,Cct),e($e,w7),e(w7,y9e),e(y9e,wct),e(w7,Act),e(w7,kne),e(kne,Lct),e(w7,yct),e($e,xct),e($e,A7),e(A7,x9e),e(x9e,$ct),e(A7,kct),e(A7,Sne),e(Sne,Sct),e(A7,Rct),e($e,Pct),e($e,L7),e(L7,$9e),e($9e,Bct),e(L7,Ict),e(L7,Rne),e(Rne,Nct),e(L7,qct),e(ot,jct),M(y7,ot,null),b(m,zZe,_),b(m,Hm,_),e(Hm,x7),e(x7,k9e),M(pR,k9e,null),e(Hm,Dct),e(Hm,S9e),e(S9e,Gct),b(m,QZe,_),b(m,Ar,_),M(_R,Ar,null),e(Ar,Oct),e(Ar,Jm),e(Jm,Vct),e(Jm,Pne),e(Pne,Xct),e(Jm,zct),e(Jm,Bne),e(Bne,Qct),e(Jm,Wct),e(Ar,Uct),e(Ar,bR),e(bR,Hct),e(bR,R9e),e(R9e,Jct),e(bR,Yct),e(Ar,Kct),e(Ar,ca),M(vR,ca,null),e(ca,Zct),e(ca,P9e),e(P9e,emt),e(ca,omt),e(ca,Ym),e(Ym,rmt),e(Ym,B9e),e(B9e,tmt),e(Ym,amt),e(Ym,Ine),e(Ine,nmt),e(Ym,smt),e(ca,lmt),M($7,ca,null),e(Ar,imt),e(Ar,rt),M(FR,rt,null),e(rt,dmt),e(rt,I9e),e(I9e,cmt),e(rt,mmt),e(rt,Xn),e(Xn,fmt),e(Xn,N9e),e(N9e,gmt),e(Xn,hmt),e(Xn,q9e),e(q9e,umt),e(Xn,pmt),e(Xn,j9e),e(j9e,_mt),e(Xn,bmt),e(rt,vmt),e(rt,ke),e(ke,k7),e(k7,D9e),e(D9e,Fmt),e(k7,Tmt),e(k7,Nne),e(Nne,Mmt),e(k7,Emt),e(ke,Cmt),e(ke,S7),e(S7,G9e),e(G9e,wmt),e(S7,Amt),e(S7,qne),e(qne,Lmt),e(S7,ymt),e(ke,xmt),e(ke,R7),e(R7,O9e),e(O9e,$mt),e(R7,kmt),e(R7,jne),e(jne,Smt),e(R7,Rmt),e(ke,Pmt),e(ke,P7),e(P7,V9e),e(V9e,Bmt),e(P7,Imt),e(P7,Dne),e(Dne,Nmt),e(P7,qmt),e(ke,jmt),e(ke,B7),e(B7,X9e),e(X9e,Dmt),e(B7,Gmt),e(B7,Gne),e(Gne,Omt),e(B7,Vmt),e(ke,Xmt),e(ke,I7),e(I7,z9e),e(z9e,zmt),e(I7,Qmt),e(I7,One),e(One,Wmt),e(I7,Umt),e(ke,Hmt),e(ke,N7),e(N7,Q9e),e(Q9e,Jmt),e(N7,Ymt),e(N7,Vne),e(Vne,Kmt),e(N7,Zmt),e(ke,eft),e(ke,q7),e(q7,W9e),e(W9e,oft),e(q7,rft),e(q7,Xne),e(Xne,tft),e(q7,aft),e(ke,nft),e(ke,j7),e(j7,U9e),e(U9e,sft),e(j7,lft),e(j7,zne),e(zne,ift),e(j7,dft),e(ke,cft),e(ke,D7),e(D7,H9e),e(H9e,mft),e(D7,fft),e(D7,Qne),e(Qne,gft),e(D7,hft),e(rt,uft),M(G7,rt,null),b(m,WZe,_),b(m,Km,_),e(Km,O7),e(O7,J9e),M(TR,J9e,null),e(Km,pft),e(Km,Y9e),e(Y9e,_ft),b(m,UZe,_),b(m,Lr,_),M(MR,Lr,null),e(Lr,bft),e(Lr,Zm),e(Zm,vft),e(Zm,Wne),e(Wne,Fft),e(Zm,Tft),e(Zm,Une),e(Une,Mft),e(Zm,Eft),e(Lr,Cft),e(Lr,ER),e(ER,wft),e(ER,K9e),e(K9e,Aft),e(ER,Lft),e(Lr,yft),e(Lr,ma),M(CR,ma,null),e(ma,xft),e(ma,Z9e),e(Z9e,$ft),e(ma,kft),e(ma,ef),e(ef,Sft),e(ef,exe),e(exe,Rft),e(ef,Pft),e(ef,Hne),e(Hne,Bft),e(ef,Ift),e(ma,Nft),M(V7,ma,null),e(Lr,qft),e(Lr,tt),M(wR,tt,null),e(tt,jft),e(tt,oxe),e(oxe,Dft),e(tt,Gft),e(tt,zn),e(zn,Oft),e(zn,rxe),e(rxe,Vft),e(zn,Xft),e(zn,txe),e(txe,zft),e(zn,Qft),e(zn,axe),e(axe,Wft),e(zn,Uft),e(tt,Hft),e(tt,Se),e(Se,X7),e(X7,nxe),e(nxe,Jft),e(X7,Yft),e(X7,Jne),e(Jne,Kft),e(X7,Zft),e(Se,egt),e(Se,z7),e(z7,sxe),e(sxe,ogt),e(z7,rgt),e(z7,Yne),e(Yne,tgt),e(z7,agt),e(Se,ngt),e(Se,Q7),e(Q7,lxe),e(lxe,sgt),e(Q7,lgt),e(Q7,Kne),e(Kne,igt),e(Q7,dgt),e(Se,cgt),e(Se,W7),e(W7,ixe),e(ixe,mgt),e(W7,fgt),e(W7,Zne),e(Zne,ggt),e(W7,hgt),e(Se,ugt),e(Se,U7),e(U7,dxe),e(dxe,pgt),e(U7,_gt),e(U7,ese),e(ese,bgt),e(U7,vgt),e(Se,Fgt),e(Se,H7),e(H7,cxe),e(cxe,Tgt),e(H7,Mgt),e(H7,ose),e(ose,Egt),e(H7,Cgt),e(Se,wgt),e(Se,J7),e(J7,mxe),e(mxe,Agt),e(J7,Lgt),e(J7,rse),e(rse,ygt),e(J7,xgt),e(Se,$gt),e(Se,Y7),e(Y7,fxe),e(fxe,kgt),e(Y7,Sgt),e(Y7,tse),e(tse,Rgt),e(Y7,Pgt),e(Se,Bgt),e(Se,K7),e(K7,gxe),e(gxe,Igt),e(K7,Ngt),e(K7,ase),e(ase,qgt),e(K7,jgt),e(Se,Dgt),e(Se,Z7),e(Z7,hxe),e(hxe,Ggt),e(Z7,Ogt),e(Z7,nse),e(nse,Vgt),e(Z7,Xgt),e(tt,zgt),M(eL,tt,null),b(m,HZe,_),b(m,of,_),e(of,oL),e(oL,uxe),M(AR,uxe,null),e(of,Qgt),e(of,pxe),e(pxe,Wgt),b(m,JZe,_),b(m,yr,_),M(LR,yr,null),e(yr,Ugt),e(yr,rf),e(rf,Hgt),e(rf,sse),e(sse,Jgt),e(rf,Ygt),e(rf,lse),e(lse,Kgt),e(rf,Zgt),e(yr,eht),e(yr,yR),e(yR,oht),e(yR,_xe),e(_xe,rht),e(yR,tht),e(yr,aht),e(yr,fa),M(xR,fa,null),e(fa,nht),e(fa,bxe),e(bxe,sht),e(fa,lht),e(fa,tf),e(tf,iht),e(tf,vxe),e(vxe,dht),e(tf,cht),e(tf,ise),e(ise,mht),e(tf,fht),e(fa,ght),M(rL,fa,null),e(yr,hht),e(yr,at),M($R,at,null),e(at,uht),e(at,Fxe),e(Fxe,pht),e(at,_ht),e(at,Qn),e(Qn,bht),e(Qn,Txe),e(Txe,vht),e(Qn,Fht),e(Qn,Mxe),e(Mxe,Tht),e(Qn,Mht),e(Qn,Exe),e(Exe,Eht),e(Qn,Cht),e(at,wht),e(at,Re),e(Re,tL),e(tL,Cxe),e(Cxe,Aht),e(tL,Lht),e(tL,dse),e(dse,yht),e(tL,xht),e(Re,$ht),e(Re,aL),e(aL,wxe),e(wxe,kht),e(aL,Sht),e(aL,cse),e(cse,Rht),e(aL,Pht),e(Re,Bht),e(Re,nL),e(nL,Axe),e(Axe,Iht),e(nL,Nht),e(nL,mse),e(mse,qht),e(nL,jht),e(Re,Dht),e(Re,sL),e(sL,Lxe),e(Lxe,Ght),e(sL,Oht),e(sL,fse),e(fse,Vht),e(sL,Xht),e(Re,zht),e(Re,lL),e(lL,yxe),e(yxe,Qht),e(lL,Wht),e(lL,gse),e(gse,Uht),e(lL,Hht),e(Re,Jht),e(Re,iL),e(iL,xxe),e(xxe,Yht),e(iL,Kht),e(iL,hse),e(hse,Zht),e(iL,eut),e(Re,out),e(Re,dL),e(dL,$xe),e($xe,rut),e(dL,tut),e(dL,use),e(use,aut),e(dL,nut),e(Re,sut),e(Re,cL),e(cL,kxe),e(kxe,lut),e(cL,iut),e(cL,pse),e(pse,dut),e(cL,cut),e(Re,mut),e(Re,mL),e(mL,Sxe),e(Sxe,fut),e(mL,gut),e(mL,_se),e(_se,hut),e(mL,uut),e(Re,put),e(Re,fL),e(fL,Rxe),e(Rxe,_ut),e(fL,but),e(fL,bse),e(bse,vut),e(fL,Fut),e(at,Tut),M(gL,at,null),b(m,YZe,_),b(m,af,_),e(af,hL),e(hL,Pxe),M(kR,Pxe,null),e(af,Mut),e(af,Bxe),e(Bxe,Eut),b(m,KZe,_),b(m,xr,_),M(SR,xr,null),e(xr,Cut),e(xr,nf),e(nf,wut),e(nf,vse),e(vse,Aut),e(nf,Lut),e(nf,Fse),e(Fse,yut),e(nf,xut),e(xr,$ut),e(xr,RR),e(RR,kut),e(RR,Ixe),e(Ixe,Sut),e(RR,Rut),e(xr,Put),e(xr,ga),M(PR,ga,null),e(ga,But),e(ga,Nxe),e(Nxe,Iut),e(ga,Nut),e(ga,sf),e(sf,qut),e(sf,qxe),e(qxe,jut),e(sf,Dut),e(sf,Tse),e(Tse,Gut),e(sf,Out),e(ga,Vut),M(uL,ga,null),e(xr,Xut),e(xr,nt),M(BR,nt,null),e(nt,zut),e(nt,jxe),e(jxe,Qut),e(nt,Wut),e(nt,Wn),e(Wn,Uut),e(Wn,Dxe),e(Dxe,Hut),e(Wn,Jut),e(Wn,Gxe),e(Gxe,Yut),e(Wn,Kut),e(Wn,Oxe),e(Oxe,Zut),e(Wn,ept),e(nt,opt),e(nt,Xe),e(Xe,pL),e(pL,Vxe),e(Vxe,rpt),e(pL,tpt),e(pL,Mse),e(Mse,apt),e(pL,npt),e(Xe,spt),e(Xe,_L),e(_L,Xxe),e(Xxe,lpt),e(_L,ipt),e(_L,Ese),e(Ese,dpt),e(_L,cpt),e(Xe,mpt),e(Xe,bL),e(bL,zxe),e(zxe,fpt),e(bL,gpt),e(bL,Cse),e(Cse,hpt),e(bL,upt),e(Xe,ppt),e(Xe,vL),e(vL,Qxe),e(Qxe,_pt),e(vL,bpt),e(vL,wse),e(wse,vpt),e(vL,Fpt),e(Xe,Tpt),e(Xe,FL),e(FL,Wxe),e(Wxe,Mpt),e(FL,Ept),e(FL,Ase),e(Ase,Cpt),e(FL,wpt),e(Xe,Apt),e(Xe,TL),e(TL,Uxe),e(Uxe,Lpt),e(TL,ypt),e(TL,Lse),e(Lse,xpt),e(TL,$pt),e(Xe,kpt),e(Xe,ML),e(ML,Hxe),e(Hxe,Spt),e(ML,Rpt),e(ML,yse),e(yse,Ppt),e(ML,Bpt),e(Xe,Ipt),e(Xe,EL),e(EL,Jxe),e(Jxe,Npt),e(EL,qpt),e(EL,xse),e(xse,jpt),e(EL,Dpt),e(nt,Gpt),M(CL,nt,null),b(m,ZZe,_),b(m,lf,_),e(lf,wL),e(wL,Yxe),M(IR,Yxe,null),e(lf,Opt),e(lf,Kxe),e(Kxe,Vpt),b(m,eeo,_),b(m,$r,_),M(NR,$r,null),e($r,Xpt),e($r,df),e(df,zpt),e(df,$se),e($se,Qpt),e(df,Wpt),e(df,kse),e(kse,Upt),e(df,Hpt),e($r,Jpt),e($r,qR),e(qR,Ypt),e(qR,Zxe),e(Zxe,Kpt),e(qR,Zpt),e($r,e_t),e($r,ha),M(jR,ha,null),e(ha,o_t),e(ha,e$e),e(e$e,r_t),e(ha,t_t),e(ha,cf),e(cf,a_t),e(cf,o$e),e(o$e,n_t),e(cf,s_t),e(cf,Sse),e(Sse,l_t),e(cf,i_t),e(ha,d_t),M(AL,ha,null),e($r,c_t),e($r,st),M(DR,st,null),e(st,m_t),e(st,r$e),e(r$e,f_t),e(st,g_t),e(st,Un),e(Un,h_t),e(Un,t$e),e(t$e,u_t),e(Un,p_t),e(Un,a$e),e(a$e,__t),e(Un,b_t),e(Un,n$e),e(n$e,v_t),e(Un,F_t),e(st,T_t),e(st,ze),e(ze,LL),e(LL,s$e),e(s$e,M_t),e(LL,E_t),e(LL,Rse),e(Rse,C_t),e(LL,w_t),e(ze,A_t),e(ze,yL),e(yL,l$e),e(l$e,L_t),e(yL,y_t),e(yL,Pse),e(Pse,x_t),e(yL,$_t),e(ze,k_t),e(ze,xL),e(xL,i$e),e(i$e,S_t),e(xL,R_t),e(xL,Bse),e(Bse,P_t),e(xL,B_t),e(ze,I_t),e(ze,$L),e($L,d$e),e(d$e,N_t),e($L,q_t),e($L,Ise),e(Ise,j_t),e($L,D_t),e(ze,G_t),e(ze,kL),e(kL,c$e),e(c$e,O_t),e(kL,V_t),e(kL,Nse),e(Nse,X_t),e(kL,z_t),e(ze,Q_t),e(ze,SL),e(SL,m$e),e(m$e,W_t),e(SL,U_t),e(SL,qse),e(qse,H_t),e(SL,J_t),e(ze,Y_t),e(ze,RL),e(RL,f$e),e(f$e,K_t),e(RL,Z_t),e(RL,jse),e(jse,ebt),e(RL,obt),e(ze,rbt),e(ze,PL),e(PL,g$e),e(g$e,tbt),e(PL,abt),e(PL,Dse),e(Dse,nbt),e(PL,sbt),e(st,lbt),M(BL,st,null),b(m,oeo,_),b(m,mf,_),e(mf,IL),e(IL,h$e),M(GR,h$e,null),e(mf,ibt),e(mf,u$e),e(u$e,dbt),b(m,reo,_),b(m,kr,_),M(OR,kr,null),e(kr,cbt),e(kr,ff),e(ff,mbt),e(ff,Gse),e(Gse,fbt),e(ff,gbt),e(ff,Ose),e(Ose,hbt),e(ff,ubt),e(kr,pbt),e(kr,VR),e(VR,_bt),e(VR,p$e),e(p$e,bbt),e(VR,vbt),e(kr,Fbt),e(kr,ua),M(XR,ua,null),e(ua,Tbt),e(ua,_$e),e(_$e,Mbt),e(ua,Ebt),e(ua,gf),e(gf,Cbt),e(gf,b$e),e(b$e,wbt),e(gf,Abt),e(gf,Vse),e(Vse,Lbt),e(gf,ybt),e(ua,xbt),M(NL,ua,null),e(kr,$bt),e(kr,lt),M(zR,lt,null),e(lt,kbt),e(lt,v$e),e(v$e,Sbt),e(lt,Rbt),e(lt,Hn),e(Hn,Pbt),e(Hn,F$e),e(F$e,Bbt),e(Hn,Ibt),e(Hn,T$e),e(T$e,Nbt),e(Hn,qbt),e(Hn,M$e),e(M$e,jbt),e(Hn,Dbt),e(lt,Gbt),e(lt,E$e),e(E$e,qL),e(qL,C$e),e(C$e,Obt),e(qL,Vbt),e(qL,Xse),e(Xse,Xbt),e(qL,zbt),e(lt,Qbt),M(jL,lt,null),b(m,teo,_),b(m,hf,_),e(hf,DL),e(DL,w$e),M(QR,w$e,null),e(hf,Wbt),e(hf,A$e),e(A$e,Ubt),b(m,aeo,_),b(m,Sr,_),M(WR,Sr,null),e(Sr,Hbt),e(Sr,uf),e(uf,Jbt),e(uf,zse),e(zse,Ybt),e(uf,Kbt),e(uf,Qse),e(Qse,Zbt),e(uf,e2t),e(Sr,o2t),e(Sr,UR),e(UR,r2t),e(UR,L$e),e(L$e,t2t),e(UR,a2t),e(Sr,n2t),e(Sr,pa),M(HR,pa,null),e(pa,s2t),e(pa,y$e),e(y$e,l2t),e(pa,i2t),e(pa,pf),e(pf,d2t),e(pf,x$e),e(x$e,c2t),e(pf,m2t),e(pf,Wse),e(Wse,f2t),e(pf,g2t),e(pa,h2t),M(GL,pa,null),e(Sr,u2t),e(Sr,it),M(JR,it,null),e(it,p2t),e(it,$$e),e($$e,_2t),e(it,b2t),e(it,Jn),e(Jn,v2t),e(Jn,k$e),e(k$e,F2t),e(Jn,T2t),e(Jn,S$e),e(S$e,M2t),e(Jn,E2t),e(Jn,R$e),e(R$e,C2t),e(Jn,w2t),e(it,A2t),e(it,YR),e(YR,OL),e(OL,P$e),e(P$e,L2t),e(OL,y2t),e(OL,Use),e(Use,x2t),e(OL,$2t),e(YR,k2t),e(YR,VL),e(VL,B$e),e(B$e,S2t),e(VL,R2t),e(VL,Hse),e(Hse,P2t),e(VL,B2t),e(it,I2t),M(XL,it,null),b(m,neo,_),b(m,_f,_),e(_f,zL),e(zL,I$e),M(KR,I$e,null),e(_f,N2t),e(_f,N$e),e(N$e,q2t),b(m,seo,_),b(m,Rr,_),M(ZR,Rr,null),e(Rr,j2t),e(Rr,bf),e(bf,D2t),e(bf,Jse),e(Jse,G2t),e(bf,O2t),e(bf,Yse),e(Yse,V2t),e(bf,X2t),e(Rr,z2t),e(Rr,eP),e(eP,Q2t),e(eP,q$e),e(q$e,W2t),e(eP,U2t),e(Rr,H2t),e(Rr,_a),M(oP,_a,null),e(_a,J2t),e(_a,j$e),e(j$e,Y2t),e(_a,K2t),e(_a,vf),e(vf,Z2t),e(vf,D$e),e(D$e,e1t),e(vf,o1t),e(vf,Kse),e(Kse,r1t),e(vf,t1t),e(_a,a1t),M(QL,_a,null),e(Rr,n1t),e(Rr,dt),M(rP,dt,null),e(dt,s1t),e(dt,G$e),e(G$e,l1t),e(dt,i1t),e(dt,Yn),e(Yn,d1t),e(Yn,O$e),e(O$e,c1t),e(Yn,m1t),e(Yn,V$e),e(V$e,f1t),e(Yn,g1t),e(Yn,X$e),e(X$e,h1t),e(Yn,u1t),e(dt,p1t),e(dt,z$e),e(z$e,WL),e(WL,Q$e),e(Q$e,_1t),e(WL,b1t),e(WL,Zse),e(Zse,v1t),e(WL,F1t),e(dt,T1t),M(UL,dt,null),leo=!0},p(m,[_]){const tP={};_&2&&(tP.$$scope={dirty:_,ctx:m}),yf.$set(tP);const W$e={};_&2&&(W$e.$$scope={dirty:_,ctx:m}),Uh.$set(W$e);const U$e={};_&2&&(U$e.$$scope={dirty:_,ctx:m}),$u.$set(U$e);const H$e={};_&2&&(H$e.$$scope={dirty:_,ctx:m}),vp.$set(H$e);const aP={};_&2&&(aP.$$scope={dirty:_,ctx:m}),Fp.$set(aP);const J$e={};_&2&&(J$e.$$scope={dirty:_,ctx:m}),Xp.$set(J$e);const Kn={};_&2&&(Kn.$$scope={dirty:_,ctx:m}),zp.$set(Kn);const Y$e={};_&2&&(Y$e.$$scope={dirty:_,ctx:m}),Up.$set(Y$e);const K$e={};_&2&&(K$e.$$scope={dirty:_,ctx:m}),l2.$set(K$e);const Z$e={};_&2&&(Z$e.$$scope={dirty:_,ctx:m}),d2.$set(Z$e);const nP={};_&2&&(nP.$$scope={dirty:_,ctx:m}),n1.$set(nP);const eke={};_&2&&(eke.$$scope={dirty:_,ctx:m}),l1.$set(eke);const sP={};_&2&&(sP.$$scope={dirty:_,ctx:m}),J1.$set(sP);const oke={};_&2&&(oke.$$scope={dirty:_,ctx:m}),K1.$set(oke);const lP={};_&2&&(lP.$$scope={dirty:_,ctx:m}),jv.$set(lP);const rke={};_&2&&(rke.$$scope={dirty:_,ctx:m}),Gv.$set(rke);const tke={};_&2&&(tke.$$scope={dirty:_,ctx:m}),dF.$set(tke);const ake={};_&2&&(ake.$$scope={dirty:_,ctx:m}),mF.$set(ake);const Ff={};_&2&&(Ff.$$scope={dirty:_,ctx:m}),fT.$set(Ff);const nke={};_&2&&(nke.$$scope={dirty:_,ctx:m}),hT.$set(nke);const ske={};_&2&&(ske.$$scope={dirty:_,ctx:m}),UT.$set(ske);const lke={};_&2&&(lke.$$scope={dirty:_,ctx:m}),JT.$set(lke);const iP={};_&2&&(iP.$$scope={dirty:_,ctx:m}),nM.$set(iP);const ike={};_&2&&(ike.$$scope={dirty:_,ctx:m}),lM.$set(ike);const dke={};_&2&&(dke.$$scope={dirty:_,ctx:m}),WM.$set(dke);const cke={};_&2&&(cke.$$scope={dirty:_,ctx:m}),HM.$set(cke);const ht={};_&2&&(ht.$$scope={dirty:_,ctx:m}),GE.$set(ht);const dP={};_&2&&(dP.$$scope={dirty:_,ctx:m}),VE.$set(dP);const mke={};_&2&&(mke.$$scope={dirty:_,ctx:m}),QE.$set(mke);const cP={};_&2&&(cP.$$scope={dirty:_,ctx:m}),UE.$set(cP);const fke={};_&2&&(fke.$$scope={dirty:_,ctx:m}),ZE.$set(fke);const ut={};_&2&&(ut.$$scope={dirty:_,ctx:m}),o4.$set(ut);const gke={};_&2&&(gke.$$scope={dirty:_,ctx:m}),_4.$set(gke);const Tf={};_&2&&(Tf.$$scope={dirty:_,ctx:m}),v4.$set(Tf);const hke={};_&2&&(hke.$$scope={dirty:_,ctx:m}),M4.$set(hke);const uke={};_&2&&(uke.$$scope={dirty:_,ctx:m}),C4.$set(uke);const L={};_&2&&(L.$$scope={dirty:_,ctx:m}),L4.$set(L);const HL={};_&2&&(HL.$$scope={dirty:_,ctx:m}),x4.$set(HL);const pke={};_&2&&(pke.$$scope={dirty:_,ctx:m}),S4.$set(pke);const _ke={};_&2&&(_ke.$$scope={dirty:_,ctx:m}),P4.$set(_ke);const JL={};_&2&&(JL.$$scope={dirty:_,ctx:m}),z4.$set(JL);const bke={};_&2&&(bke.$$scope={dirty:_,ctx:m}),W4.$set(bke);const vke={};_&2&&(vke.$$scope={dirty:_,ctx:m}),eC.$set(vke);const YL={};_&2&&(YL.$$scope={dirty:_,ctx:m}),rC.$set(YL);const Fke={};_&2&&(Fke.$$scope={dirty:_,ctx:m}),hC.$set(Fke);const Tke={};_&2&&(Tke.$$scope={dirty:_,ctx:m}),pC.$set(Tke);const KL={};_&2&&(KL.$$scope={dirty:_,ctx:m}),FC.$set(KL);const Mke={};_&2&&(Mke.$$scope={dirty:_,ctx:m}),MC.$set(Mke);const Eke={};_&2&&(Eke.$$scope={dirty:_,ctx:m}),xC.$set(Eke);const ZL={};_&2&&(ZL.$$scope={dirty:_,ctx:m}),kC.$set(ZL);const Cke={};_&2&&(Cke.$$scope={dirty:_,ctx:m}),NC.$set(Cke);const wke={};_&2&&(wke.$$scope={dirty:_,ctx:m}),jC.$set(wke);const ey={};_&2&&(ey.$$scope={dirty:_,ctx:m}),XC.$set(ey);const Ake={};_&2&&(Ake.$$scope={dirty:_,ctx:m}),QC.$set(Ake);const Lke={};_&2&&(Lke.$$scope={dirty:_,ctx:m}),HC.$set(Lke);const oy={};_&2&&(oy.$$scope={dirty:_,ctx:m}),YC.$set(oy);const yke={};_&2&&(yke.$$scope={dirty:_,ctx:m}),a3.$set(yke);const xke={};_&2&&(xke.$$scope={dirty:_,ctx:m}),s3.$set(xke);const ry={};_&2&&(ry.$$scope={dirty:_,ctx:m}),d3.$set(ry);const $ke={};_&2&&($ke.$$scope={dirty:_,ctx:m}),m3.$set($ke);const kke={};_&2&&(kke.$$scope={dirty:_,ctx:m}),m5.$set(kke);const ty={};_&2&&(ty.$$scope={dirty:_,ctx:m}),g5.$set(ty);const Ske={};_&2&&(Ske.$$scope={dirty:_,ctx:m}),N5.$set(Ske);const Rke={};_&2&&(Rke.$$scope={dirty:_,ctx:m}),j5.$set(Rke);const ay={};_&2&&(ay.$$scope={dirty:_,ctx:m}),e0.$set(ay);const Pke={};_&2&&(Pke.$$scope={dirty:_,ctx:m}),r0.$set(Pke);const Bke={};_&2&&(Bke.$$scope={dirty:_,ctx:m}),m0.$set(Bke);const ny={};_&2&&(ny.$$scope={dirty:_,ctx:m}),g0.$set(ny);const Ike={};_&2&&(Ike.$$scope={dirty:_,ctx:m}),_0.$set(Ike);const Nke={};_&2&&(Nke.$$scope={dirty:_,ctx:m}),v0.$set(Nke);const sy={};_&2&&(sy.$$scope={dirty:_,ctx:m}),D0.$set(sy);const qke={};_&2&&(qke.$$scope={dirty:_,ctx:m}),O0.$set(qke);const jke={};_&2&&(jke.$$scope={dirty:_,ctx:m}),Z0.$set(jke);const ly={};_&2&&(ly.$$scope={dirty:_,ctx:m}),ow.$set(ly);const Dke={};_&2&&(Dke.$$scope={dirty:_,ctx:m}),xw.$set(Dke);const Gke={};_&2&&(Gke.$$scope={dirty:_,ctx:m}),kw.$set(Gke);const iy={};_&2&&(iy.$$scope={dirty:_,ctx:m}),Hw.$set(iy);const Oke={};_&2&&(Oke.$$scope={dirty:_,ctx:m}),Yw.$set(Oke);const Vke={};_&2&&(Vke.$$scope={dirty:_,ctx:m}),eA.$set(Vke);const dy={};_&2&&(dy.$$scope={dirty:_,ctx:m}),rA.$set(dy);const Xke={};_&2&&(Xke.$$scope={dirty:_,ctx:m}),aA.$set(Xke);const zke={};_&2&&(zke.$$scope={dirty:_,ctx:m}),sA.$set(zke);const cy={};_&2&&(cy.$$scope={dirty:_,ctx:m}),iA.$set(cy);const Qke={};_&2&&(Qke.$$scope={dirty:_,ctx:m}),cA.$set(Qke);const Wke={};_&2&&(Wke.$$scope={dirty:_,ctx:m}),SA.$set(Wke);const my={};_&2&&(my.$$scope={dirty:_,ctx:m}),PA.$set(my);const Uke={};_&2&&(Uke.$$scope={dirty:_,ctx:m}),r6.$set(Uke);const Hke={};_&2&&(Hke.$$scope={dirty:_,ctx:m}),a6.$set(Hke);const fy={};_&2&&(fy.$$scope={dirty:_,ctx:m}),s6.$set(fy);const Jke={};_&2&&(Jke.$$scope={dirty:_,ctx:m}),i6.$set(Jke);const Yke={};_&2&&(Yke.$$scope={dirty:_,ctx:m}),c6.$set(Yke);const gy={};_&2&&(gy.$$scope={dirty:_,ctx:m}),f6.$set(gy);const Kke={};_&2&&(Kke.$$scope={dirty:_,ctx:m}),D6.$set(Kke);const Zke={};_&2&&(Zke.$$scope={dirty:_,ctx:m}),O6.$set(Zke);const hy={};_&2&&(hy.$$scope={dirty:_,ctx:m}),Z6.$set(hy);const eSe={};_&2&&(eSe.$$scope={dirty:_,ctx:m}),o7.$set(eSe);const oSe={};_&2&&(oSe.$$scope={dirty:_,ctx:m}),u7.$set(oSe);const uy={};_&2&&(uy.$$scope={dirty:_,ctx:m}),_7.$set(uy);const rSe={};_&2&&(rSe.$$scope={dirty:_,ctx:m}),y7.$set(rSe);const tSe={};_&2&&(tSe.$$scope={dirty:_,ctx:m}),$7.$set(tSe);const py={};_&2&&(py.$$scope={dirty:_,ctx:m}),G7.$set(py);const aSe={};_&2&&(aSe.$$scope={dirty:_,ctx:m}),V7.$set(aSe);const nSe={};_&2&&(nSe.$$scope={dirty:_,ctx:m}),eL.$set(nSe);const _y={};_&2&&(_y.$$scope={dirty:_,ctx:m}),rL.$set(_y);const sSe={};_&2&&(sSe.$$scope={dirty:_,ctx:m}),gL.$set(sSe);const lSe={};_&2&&(lSe.$$scope={dirty:_,ctx:m}),uL.$set(lSe);const by={};_&2&&(by.$$scope={dirty:_,ctx:m}),CL.$set(by);const iSe={};_&2&&(iSe.$$scope={dirty:_,ctx:m}),AL.$set(iSe);const dSe={};_&2&&(dSe.$$scope={dirty:_,ctx:m}),BL.$set(dSe);const vy={};_&2&&(vy.$$scope={dirty:_,ctx:m}),NL.$set(vy);const cSe={};_&2&&(cSe.$$scope={dirty:_,ctx:m}),jL.$set(cSe);const mSe={};_&2&&(mSe.$$scope={dirty:_,ctx:m}),GL.$set(mSe);const Fy={};_&2&&(Fy.$$scope={dirty:_,ctx:m}),XL.$set(Fy);const fSe={};_&2&&(fSe.$$scope={dirty:_,ctx:m}),QL.$set(fSe);const gSe={};_&2&&(gSe.$$scope={dirty:_,ctx:m}),UL.$set(gSe)},i(m){leo||(E(d.$$.fragment,m),E(Qa.$$.fragment,m),E(y9.$$.fragment,m),E(x9.$$.fragment,m),E(yf.$$.fragment,m),E($9.$$.fragment,m),E(k9.$$.fragment,m),E(P9.$$.fragment,m),E(Uh.$$.fragment,m),E(B9.$$.fragment,m),E(I9.$$.fragment,m),E(N9.$$.fragment,m),E(D9.$$.fragment,m),E($u.$$.fragment,m),E(G9.$$.fragment,m),E(O9.$$.fragment,m),E(V9.$$.fragment,m),E(Q9.$$.fragment,m),E(vp.$$.fragment,m),E(Fp.$$.fragment,m),E(W9.$$.fragment,m),E(U9.$$.fragment,m),E(H9.$$.fragment,m),E(K9.$$.fragment,m),E(Xp.$$.fragment,m),E(zp.$$.fragment,m),E(Z9.$$.fragment,m),E(ex.$$.fragment,m),E(ox.$$.fragment,m),E(tx.$$.fragment,m),E(Up.$$.fragment,m),E(ax.$$.fragment,m),E(l2.$$.fragment,m),E(nx.$$.fragment,m),E(sx.$$.fragment,m),E(ix.$$.fragment,m),E(d2.$$.fragment,m),E(dx.$$.fragment,m),E(n1.$$.fragment,m),E(cx.$$.fragment,m),E(mx.$$.fragment,m),E(gx.$$.fragment,m),E(l1.$$.fragment,m),E(hx.$$.fragment,m),E(J1.$$.fragment,m),E(ux.$$.fragment,m),E(px.$$.fragment,m),E(bx.$$.fragment,m),E(K1.$$.fragment,m),E(vx.$$.fragment,m),E(jv.$$.fragment,m),E(Fx.$$.fragment,m),E(Tx.$$.fragment,m),E(Ex.$$.fragment,m),E(Gv.$$.fragment,m),E(Cx.$$.fragment,m),E(dF.$$.fragment,m),E(wx.$$.fragment,m),E(Ax.$$.fragment,m),E(yx.$$.fragment,m),E(mF.$$.fragment,m),E(xx.$$.fragment,m),E(fT.$$.fragment,m),E($x.$$.fragment,m),E(kx.$$.fragment,m),E(Rx.$$.fragment,m),E(hT.$$.fragment,m),E(Px.$$.fragment,m),E(UT.$$.fragment,m),E(Bx.$$.fragment,m),E(Ix.$$.fragment,m),E(qx.$$.fragment,m),E(JT.$$.fragment,m),E(jx.$$.fragment,m),E(nM.$$.fragment,m),E(Dx.$$.fragment,m),E(Gx.$$.fragment,m),E(Vx.$$.fragment,m),E(lM.$$.fragment,m),E(Xx.$$.fragment,m),E(WM.$$.fragment,m),E(zx.$$.fragment,m),E(Qx.$$.fragment,m),E(Ux.$$.fragment,m),E(HM.$$.fragment,m),E(Hx.$$.fragment,m),E(GE.$$.fragment,m),E(Jx.$$.fragment,m),E(Yx.$$.fragment,m),E(Zx.$$.fragment,m),E(VE.$$.fragment,m),E(e$.$$.fragment,m),E(QE.$$.fragment,m),E(o$.$$.fragment,m),E(r$.$$.fragment,m),E(a$.$$.fragment,m),E(UE.$$.fragment,m),E(n$.$$.fragment,m),E(ZE.$$.fragment,m),E(s$.$$.fragment,m),E(l$.$$.fragment,m),E(d$.$$.fragment,m),E(o4.$$.fragment,m),E(c$.$$.fragment,m),E(_4.$$.fragment,m),E(m$.$$.fragment,m),E(f$.$$.fragment,m),E(h$.$$.fragment,m),E(v4.$$.fragment,m),E(u$.$$.fragment,m),E(M4.$$.fragment,m),E(p$.$$.fragment,m),E(_$.$$.fragment,m),E(v$.$$.fragment,m),E(C4.$$.fragment,m),E(F$.$$.fragment,m),E(L4.$$.fragment,m),E(T$.$$.fragment,m),E(M$.$$.fragment,m),E(C$.$$.fragment,m),E(x4.$$.fragment,m),E(w$.$$.fragment,m),E(S4.$$.fragment,m),E(A$.$$.fragment,m),E(L$.$$.fragment,m),E(x$.$$.fragment,m),E(P4.$$.fragment,m),E($$.$$.fragment,m),E(z4.$$.fragment,m),E(k$.$$.fragment,m),E(S$.$$.fragment,m),E(P$.$$.fragment,m),E(W4.$$.fragment,m),E(B$.$$.fragment,m),E(eC.$$.fragment,m),E(I$.$$.fragment,m),E(N$.$$.fragment,m),E(j$.$$.fragment,m),E(rC.$$.fragment,m),E(D$.$$.fragment,m),E(hC.$$.fragment,m),E(G$.$$.fragment,m),E(O$.$$.fragment,m),E(X$.$$.fragment,m),E(pC.$$.fragment,m),E(z$.$$.fragment,m),E(FC.$$.fragment,m),E(W$.$$.fragment,m),E(U$.$$.fragment,m),E(J$.$$.fragment,m),E(MC.$$.fragment,m),E(Y$.$$.fragment,m),E(xC.$$.fragment,m),E(K$.$$.fragment,m),E(Z$.$$.fragment,m),E(ok.$$.fragment,m),E(kC.$$.fragment,m),E(rk.$$.fragment,m),E(NC.$$.fragment,m),E(tk.$$.fragment,m),E(ak.$$.fragment,m),E(sk.$$.fragment,m),E(jC.$$.fragment,m),E(lk.$$.fragment,m),E(XC.$$.fragment,m),E(ik.$$.fragment,m),E(dk.$$.fragment,m),E(mk.$$.fragment,m),E(QC.$$.fragment,m),E(fk.$$.fragment,m),E(HC.$$.fragment,m),E(gk.$$.fragment,m),E(hk.$$.fragment,m),E(pk.$$.fragment,m),E(YC.$$.fragment,m),E(_k.$$.fragment,m),E(a3.$$.fragment,m),E(bk.$$.fragment,m),E(vk.$$.fragment,m),E(Tk.$$.fragment,m),E(s3.$$.fragment,m),E(Mk.$$.fragment,m),E(d3.$$.fragment,m),E(Ek.$$.fragment,m),E(Ck.$$.fragment,m),E(Ak.$$.fragment,m),E(m3.$$.fragment,m),E(Lk.$$.fragment,m),E(m5.$$.fragment,m),E(yk.$$.fragment,m),E(xk.$$.fragment,m),E(kk.$$.fragment,m),E(g5.$$.fragment,m),E(Sk.$$.fragment,m),E(N5.$$.fragment,m),E(Rk.$$.fragment,m),E(Pk.$$.fragment,m),E(Ik.$$.fragment,m),E(j5.$$.fragment,m),E(Nk.$$.fragment,m),E(e0.$$.fragment,m),E(qk.$$.fragment,m),E(jk.$$.fragment,m),E(Gk.$$.fragment,m),E(r0.$$.fragment,m),E(Ok.$$.fragment,m),E(m0.$$.fragment,m),E(Vk.$$.fragment,m),E(Xk.$$.fragment,m),E(Qk.$$.fragment,m),E(g0.$$.fragment,m),E(Wk.$$.fragment,m),E(_0.$$.fragment,m),E(Uk.$$.fragment,m),E(Hk.$$.fragment,m),E(Yk.$$.fragment,m),E(v0.$$.fragment,m),E(Kk.$$.fragment,m),E(D0.$$.fragment,m),E(Zk.$$.fragment,m),E(eS.$$.fragment,m),E(rS.$$.fragment,m),E(O0.$$.fragment,m),E(tS.$$.fragment,m),E(Z0.$$.fragment,m),E(aS.$$.fragment,m),E(nS.$$.fragment,m),E(lS.$$.fragment,m),E(ow.$$.fragment,m),E(iS.$$.fragment,m),E(xw.$$.fragment,m),E(dS.$$.fragment,m),E(cS.$$.fragment,m),E(fS.$$.fragment,m),E(kw.$$.fragment,m),E(gS.$$.fragment,m),E(Hw.$$.fragment,m),E(hS.$$.fragment,m),E(uS.$$.fragment,m),E(_S.$$.fragment,m),E(Yw.$$.fragment,m),E(bS.$$.fragment,m),E(eA.$$.fragment,m),E(FS.$$.fragment,m),E(TS.$$.fragment,m),E(ES.$$.fragment,m),E(rA.$$.fragment,m),E(CS.$$.fragment,m),E(aA.$$.fragment,m),E(wS.$$.fragment,m),E(AS.$$.fragment,m),E(yS.$$.fragment,m),E(sA.$$.fragment,m),E(xS.$$.fragment,m),E(iA.$$.fragment,m),E($S.$$.fragment,m),E(kS.$$.fragment,m),E(RS.$$.fragment,m),E(cA.$$.fragment,m),E(PS.$$.fragment,m),E(SA.$$.fragment,m),E(BS.$$.fragment,m),E(IS.$$.fragment,m),E(qS.$$.fragment,m),E(PA.$$.fragment,m),E(jS.$$.fragment,m),E(r6.$$.fragment,m),E(DS.$$.fragment,m),E(GS.$$.fragment,m),E(VS.$$.fragment,m),E(a6.$$.fragment,m),E(XS.$$.fragment,m),E(s6.$$.fragment,m),E(zS.$$.fragment,m),E(QS.$$.fragment,m),E(US.$$.fragment,m),E(i6.$$.fragment,m),E(HS.$$.fragment,m),E(c6.$$.fragment,m),E(JS.$$.fragment,m),E(YS.$$.fragment,m),E(ZS.$$.fragment,m),E(f6.$$.fragment,m),E(eR.$$.fragment,m),E(D6.$$.fragment,m),E(oR.$$.fragment,m),E(rR.$$.fragment,m),E(aR.$$.fragment,m),E(O6.$$.fragment,m),E(nR.$$.fragment,m),E(Z6.$$.fragment,m),E(sR.$$.fragment,m),E(lR.$$.fragment,m),E(dR.$$.fragment,m),E(o7.$$.fragment,m),E(cR.$$.fragment,m),E(u7.$$.fragment,m),E(mR.$$.fragment,m),E(fR.$$.fragment,m),E(hR.$$.fragment,m),E(_7.$$.fragment,m),E(uR.$$.fragment,m),E(y7.$$.fragment,m),E(pR.$$.fragment,m),E(_R.$$.fragment,m),E(vR.$$.fragment,m),E($7.$$.fragment,m),E(FR.$$.fragment,m),E(G7.$$.fragment,m),E(TR.$$.fragment,m),E(MR.$$.fragment,m),E(CR.$$.fragment,m),E(V7.$$.fragment,m),E(wR.$$.fragment,m),E(eL.$$.fragment,m),E(AR.$$.fragment,m),E(LR.$$.fragment,m),E(xR.$$.fragment,m),E(rL.$$.fragment,m),E($R.$$.fragment,m),E(gL.$$.fragment,m),E(kR.$$.fragment,m),E(SR.$$.fragment,m),E(PR.$$.fragment,m),E(uL.$$.fragment,m),E(BR.$$.fragment,m),E(CL.$$.fragment,m),E(IR.$$.fragment,m),E(NR.$$.fragment,m),E(jR.$$.fragment,m),E(AL.$$.fragment,m),E(DR.$$.fragment,m),E(BL.$$.fragment,m),E(GR.$$.fragment,m),E(OR.$$.fragment,m),E(XR.$$.fragment,m),E(NL.$$.fragment,m),E(zR.$$.fragment,m),E(jL.$$.fragment,m),E(QR.$$.fragment,m),E(WR.$$.fragment,m),E(HR.$$.fragment,m),E(GL.$$.fragment,m),E(JR.$$.fragment,m),E(XL.$$.fragment,m),E(KR.$$.fragment,m),E(ZR.$$.fragment,m),E(oP.$$.fragment,m),E(QL.$$.fragment,m),E(rP.$$.fragment,m),E(UL.$$.fragment,m),leo=!0)},o(m){C(d.$$.fragment,m),C(Qa.$$.fragment,m),C(y9.$$.fragment,m),C(x9.$$.fragment,m),C(yf.$$.fragment,m),C($9.$$.fragment,m),C(k9.$$.fragment,m),C(P9.$$.fragment,m),C(Uh.$$.fragment,m),C(B9.$$.fragment,m),C(I9.$$.fragment,m),C(N9.$$.fragment,m),C(D9.$$.fragment,m),C($u.$$.fragment,m),C(G9.$$.fragment,m),C(O9.$$.fragment,m),C(V9.$$.fragment,m),C(Q9.$$.fragment,m),C(vp.$$.fragment,m),C(Fp.$$.fragment,m),C(W9.$$.fragment,m),C(U9.$$.fragment,m),C(H9.$$.fragment,m),C(K9.$$.fragment,m),C(Xp.$$.fragment,m),C(zp.$$.fragment,m),C(Z9.$$.fragment,m),C(ex.$$.fragment,m),C(ox.$$.fragment,m),C(tx.$$.fragment,m),C(Up.$$.fragment,m),C(ax.$$.fragment,m),C(l2.$$.fragment,m),C(nx.$$.fragment,m),C(sx.$$.fragment,m),C(ix.$$.fragment,m),C(d2.$$.fragment,m),C(dx.$$.fragment,m),C(n1.$$.fragment,m),C(cx.$$.fragment,m),C(mx.$$.fragment,m),C(gx.$$.fragment,m),C(l1.$$.fragment,m),C(hx.$$.fragment,m),C(J1.$$.fragment,m),C(ux.$$.fragment,m),C(px.$$.fragment,m),C(bx.$$.fragment,m),C(K1.$$.fragment,m),C(vx.$$.fragment,m),C(jv.$$.fragment,m),C(Fx.$$.fragment,m),C(Tx.$$.fragment,m),C(Ex.$$.fragment,m),C(Gv.$$.fragment,m),C(Cx.$$.fragment,m),C(dF.$$.fragment,m),C(wx.$$.fragment,m),C(Ax.$$.fragment,m),C(yx.$$.fragment,m),C(mF.$$.fragment,m),C(xx.$$.fragment,m),C(fT.$$.fragment,m),C($x.$$.fragment,m),C(kx.$$.fragment,m),C(Rx.$$.fragment,m),C(hT.$$.fragment,m),C(Px.$$.fragment,m),C(UT.$$.fragment,m),C(Bx.$$.fragment,m),C(Ix.$$.fragment,m),C(qx.$$.fragment,m),C(JT.$$.fragment,m),C(jx.$$.fragment,m),C(nM.$$.fragment,m),C(Dx.$$.fragment,m),C(Gx.$$.fragment,m),C(Vx.$$.fragment,m),C(lM.$$.fragment,m),C(Xx.$$.fragment,m),C(WM.$$.fragment,m),C(zx.$$.fragment,m),C(Qx.$$.fragment,m),C(Ux.$$.fragment,m),C(HM.$$.fragment,m),C(Hx.$$.fragment,m),C(GE.$$.fragment,m),C(Jx.$$.fragment,m),C(Yx.$$.fragment,m),C(Zx.$$.fragment,m),C(VE.$$.fragment,m),C(e$.$$.fragment,m),C(QE.$$.fragment,m),C(o$.$$.fragment,m),C(r$.$$.fragment,m),C(a$.$$.fragment,m),C(UE.$$.fragment,m),C(n$.$$.fragment,m),C(ZE.$$.fragment,m),C(s$.$$.fragment,m),C(l$.$$.fragment,m),C(d$.$$.fragment,m),C(o4.$$.fragment,m),C(c$.$$.fragment,m),C(_4.$$.fragment,m),C(m$.$$.fragment,m),C(f$.$$.fragment,m),C(h$.$$.fragment,m),C(v4.$$.fragment,m),C(u$.$$.fragment,m),C(M4.$$.fragment,m),C(p$.$$.fragment,m),C(_$.$$.fragment,m),C(v$.$$.fragment,m),C(C4.$$.fragment,m),C(F$.$$.fragment,m),C(L4.$$.fragment,m),C(T$.$$.fragment,m),C(M$.$$.fragment,m),C(C$.$$.fragment,m),C(x4.$$.fragment,m),C(w$.$$.fragment,m),C(S4.$$.fragment,m),C(A$.$$.fragment,m),C(L$.$$.fragment,m),C(x$.$$.fragment,m),C(P4.$$.fragment,m),C($$.$$.fragment,m),C(z4.$$.fragment,m),C(k$.$$.fragment,m),C(S$.$$.fragment,m),C(P$.$$.fragment,m),C(W4.$$.fragment,m),C(B$.$$.fragment,m),C(eC.$$.fragment,m),C(I$.$$.fragment,m),C(N$.$$.fragment,m),C(j$.$$.fragment,m),C(rC.$$.fragment,m),C(D$.$$.fragment,m),C(hC.$$.fragment,m),C(G$.$$.fragment,m),C(O$.$$.fragment,m),C(X$.$$.fragment,m),C(pC.$$.fragment,m),C(z$.$$.fragment,m),C(FC.$$.fragment,m),C(W$.$$.fragment,m),C(U$.$$.fragment,m),C(J$.$$.fragment,m),C(MC.$$.fragment,m),C(Y$.$$.fragment,m),C(xC.$$.fragment,m),C(K$.$$.fragment,m),C(Z$.$$.fragment,m),C(ok.$$.fragment,m),C(kC.$$.fragment,m),C(rk.$$.fragment,m),C(NC.$$.fragment,m),C(tk.$$.fragment,m),C(ak.$$.fragment,m),C(sk.$$.fragment,m),C(jC.$$.fragment,m),C(lk.$$.fragment,m),C(XC.$$.fragment,m),C(ik.$$.fragment,m),C(dk.$$.fragment,m),C(mk.$$.fragment,m),C(QC.$$.fragment,m),C(fk.$$.fragment,m),C(HC.$$.fragment,m),C(gk.$$.fragment,m),C(hk.$$.fragment,m),C(pk.$$.fragment,m),C(YC.$$.fragment,m),C(_k.$$.fragment,m),C(a3.$$.fragment,m),C(bk.$$.fragment,m),C(vk.$$.fragment,m),C(Tk.$$.fragment,m),C(s3.$$.fragment,m),C(Mk.$$.fragment,m),C(d3.$$.fragment,m),C(Ek.$$.fragment,m),C(Ck.$$.fragment,m),C(Ak.$$.fragment,m),C(m3.$$.fragment,m),C(Lk.$$.fragment,m),C(m5.$$.fragment,m),C(yk.$$.fragment,m),C(xk.$$.fragment,m),C(kk.$$.fragment,m),C(g5.$$.fragment,m),C(Sk.$$.fragment,m),C(N5.$$.fragment,m),C(Rk.$$.fragment,m),C(Pk.$$.fragment,m),C(Ik.$$.fragment,m),C(j5.$$.fragment,m),C(Nk.$$.fragment,m),C(e0.$$.fragment,m),C(qk.$$.fragment,m),C(jk.$$.fragment,m),C(Gk.$$.fragment,m),C(r0.$$.fragment,m),C(Ok.$$.fragment,m),C(m0.$$.fragment,m),C(Vk.$$.fragment,m),C(Xk.$$.fragment,m),C(Qk.$$.fragment,m),C(g0.$$.fragment,m),C(Wk.$$.fragment,m),C(_0.$$.fragment,m),C(Uk.$$.fragment,m),C(Hk.$$.fragment,m),C(Yk.$$.fragment,m),C(v0.$$.fragment,m),C(Kk.$$.fragment,m),C(D0.$$.fragment,m),C(Zk.$$.fragment,m),C(eS.$$.fragment,m),C(rS.$$.fragment,m),C(O0.$$.fragment,m),C(tS.$$.fragment,m),C(Z0.$$.fragment,m),C(aS.$$.fragment,m),C(nS.$$.fragment,m),C(lS.$$.fragment,m),C(ow.$$.fragment,m),C(iS.$$.fragment,m),C(xw.$$.fragment,m),C(dS.$$.fragment,m),C(cS.$$.fragment,m),C(fS.$$.fragment,m),C(kw.$$.fragment,m),C(gS.$$.fragment,m),C(Hw.$$.fragment,m),C(hS.$$.fragment,m),C(uS.$$.fragment,m),C(_S.$$.fragment,m),C(Yw.$$.fragment,m),C(bS.$$.fragment,m),C(eA.$$.fragment,m),C(FS.$$.fragment,m),C(TS.$$.fragment,m),C(ES.$$.fragment,m),C(rA.$$.fragment,m),C(CS.$$.fragment,m),C(aA.$$.fragment,m),C(wS.$$.fragment,m),C(AS.$$.fragment,m),C(yS.$$.fragment,m),C(sA.$$.fragment,m),C(xS.$$.fragment,m),C(iA.$$.fragment,m),C($S.$$.fragment,m),C(kS.$$.fragment,m),C(RS.$$.fragment,m),C(cA.$$.fragment,m),C(PS.$$.fragment,m),C(SA.$$.fragment,m),C(BS.$$.fragment,m),C(IS.$$.fragment,m),C(qS.$$.fragment,m),C(PA.$$.fragment,m),C(jS.$$.fragment,m),C(r6.$$.fragment,m),C(DS.$$.fragment,m),C(GS.$$.fragment,m),C(VS.$$.fragment,m),C(a6.$$.fragment,m),C(XS.$$.fragment,m),C(s6.$$.fragment,m),C(zS.$$.fragment,m),C(QS.$$.fragment,m),C(US.$$.fragment,m),C(i6.$$.fragment,m),C(HS.$$.fragment,m),C(c6.$$.fragment,m),C(JS.$$.fragment,m),C(YS.$$.fragment,m),C(ZS.$$.fragment,m),C(f6.$$.fragment,m),C(eR.$$.fragment,m),C(D6.$$.fragment,m),C(oR.$$.fragment,m),C(rR.$$.fragment,m),C(aR.$$.fragment,m),C(O6.$$.fragment,m),C(nR.$$.fragment,m),C(Z6.$$.fragment,m),C(sR.$$.fragment,m),C(lR.$$.fragment,m),C(dR.$$.fragment,m),C(o7.$$.fragment,m),C(cR.$$.fragment,m),C(u7.$$.fragment,m),C(mR.$$.fragment,m),C(fR.$$.fragment,m),C(hR.$$.fragment,m),C(_7.$$.fragment,m),C(uR.$$.fragment,m),C(y7.$$.fragment,m),C(pR.$$.fragment,m),C(_R.$$.fragment,m),C(vR.$$.fragment,m),C($7.$$.fragment,m),C(FR.$$.fragment,m),C(G7.$$.fragment,m),C(TR.$$.fragment,m),C(MR.$$.fragment,m),C(CR.$$.fragment,m),C(V7.$$.fragment,m),C(wR.$$.fragment,m),C(eL.$$.fragment,m),C(AR.$$.fragment,m),C(LR.$$.fragment,m),C(xR.$$.fragment,m),C(rL.$$.fragment,m),C($R.$$.fragment,m),C(gL.$$.fragment,m),C(kR.$$.fragment,m),C(SR.$$.fragment,m),C(PR.$$.fragment,m),C(uL.$$.fragment,m),C(BR.$$.fragment,m),C(CL.$$.fragment,m),C(IR.$$.fragment,m),C(NR.$$.fragment,m),C(jR.$$.fragment,m),C(AL.$$.fragment,m),C(DR.$$.fragment,m),C(BL.$$.fragment,m),C(GR.$$.fragment,m),C(OR.$$.fragment,m),C(XR.$$.fragment,m),C(NL.$$.fragment,m),C(zR.$$.fragment,m),C(jL.$$.fragment,m),C(QR.$$.fragment,m),C(WR.$$.fragment,m),C(HR.$$.fragment,m),C(GL.$$.fragment,m),C(JR.$$.fragment,m),C(XL.$$.fragment,m),C(KR.$$.fragment,m),C(ZR.$$.fragment,m),C(oP.$$.fragment,m),C(QL.$$.fragment,m),C(rP.$$.fragment,m),C(UL.$$.fragment,m),leo=!1},d(m){t(g),m&&t(v),m&&t(u),w(d),m&&t(Ef),m&&t(pt),m&&t(Ve),m&&t(He),m&&t(wf),w(Qa,m),m&&t(Je),m&&t(Ae),m&&t(xo),m&&t(Wa),m&&t(UYe),m&&t(dd),w(y9),m&&t(HYe),m&&t(ts),m&&t(JYe),w(x9,m),m&&t(YYe),m&&t(RB),m&&t(KYe),w(yf,m),m&&t(ZYe),m&&t(cd),w($9),m&&t(eKe),m&&t($o),w(k9),w(P9),w(Uh),w(B9),m&&t(oKe),m&&t(fd),w(I9),m&&t(rKe),m&&t(ko),w(N9),w(D9),w($u),w(G9),m&&t(tKe),m&&t(gd),w(O9),m&&t(aKe),m&&t(So),w(V9),w(Q9),w(vp),w(Fp),w(W9),m&&t(nKe),m&&t(hd),w(U9),m&&t(sKe),m&&t(Ro),w(H9),w(K9),w(Xp),w(zp),w(Z9),m&&t(lKe),m&&t(pd),w(ex),m&&t(iKe),m&&t(Po),w(ox),w(tx),w(Up),w(ax),w(l2),m&&t(dKe),m&&t(vd),w(nx),m&&t(cKe),m&&t(Bo),w(sx),w(ix),w(d2),w(dx),w(n1),m&&t(mKe),m&&t(Md),w(cx),m&&t(fKe),m&&t(Io),w(mx),w(gx),w(l1),w(hx),w(J1),m&&t(gKe),m&&t(wd),w(ux),m&&t(hKe),m&&t(No),w(px),w(bx),w(K1),w(vx),w(jv),m&&t(uKe),m&&t(yd),w(Fx),m&&t(pKe),m&&t(qo),w(Tx),w(Ex),w(Gv),w(Cx),w(dF),m&&t(_Ke),m&&t(kd),w(wx),m&&t(bKe),m&&t(jo),w(Ax),w(yx),w(mF),w(xx),w(fT),m&&t(vKe),m&&t(Pd),w($x),m&&t(FKe),m&&t(Do),w(kx),w(Rx),w(hT),w(Px),w(UT),m&&t(TKe),m&&t(Nd),w(Bx),m&&t(MKe),m&&t(Go),w(Ix),w(qx),w(JT),w(jx),w(nM),m&&t(EKe),m&&t(Dd),w(Dx),m&&t(CKe),m&&t(Oo),w(Gx),w(Vx),w(lM),w(Xx),w(WM),m&&t(wKe),m&&t(Vd),w(zx),m&&t(AKe),m&&t(Vo),w(Qx),w(Ux),w(HM),w(Hx),w(GE),m&&t(LKe),m&&t(Qd),w(Jx),m&&t(yKe),m&&t(Xo),w(Yx),w(Zx),w(VE),w(e$),w(QE),m&&t(xKe),m&&t(Hd),w(o$),m&&t($Ke),m&&t(zo),w(r$),w(a$),w(UE),w(n$),w(ZE),m&&t(kKe),m&&t(Zd),w(s$),m&&t(SKe),m&&t(Qo),w(l$),w(d$),w(o4),w(c$),w(_4),m&&t(RKe),m&&t(rc),w(m$),m&&t(PKe),m&&t(Wo),w(f$),w(h$),w(v4),w(u$),w(M4),m&&t(BKe),m&&t(nc),w(p$),m&&t(IKe),m&&t(Uo),w(_$),w(v$),w(C4),w(F$),w(L4),m&&t(NKe),m&&t(ic),w(T$),m&&t(qKe),m&&t(Ho),w(M$),w(C$),w(x4),w(w$),w(S4),m&&t(jKe),m&&t(mc),w(A$),m&&t(DKe),m&&t(Jo),w(L$),w(x$),w(P4),w($$),w(z4),m&&t(GKe),m&&t(hc),w(k$),m&&t(OKe),m&&t(Yo),w(S$),w(P$),w(W4),w(B$),w(eC),m&&t(VKe),m&&t(_c),w(I$),m&&t(XKe),m&&t(Ko),w(N$),w(j$),w(rC),w(D$),w(hC),m&&t(zKe),m&&t(Fc),w(G$),m&&t(QKe),m&&t(Zo),w(O$),w(X$),w(pC),w(z$),w(FC),m&&t(WKe),m&&t(Ec),w(W$),m&&t(UKe),m&&t(er),w(U$),w(J$),w(MC),w(Y$),w(xC),m&&t(HKe),m&&t(Ac),w(K$),m&&t(JKe),m&&t(or),w(Z$),w(ok),w(kC),w(rk),w(NC),m&&t(YKe),m&&t(xc),w(tk),m&&t(KKe),m&&t(rr),w(ak),w(sk),w(jC),w(lk),w(XC),m&&t(ZKe),m&&t(Rc),w(ik),m&&t(eZe),m&&t(tr),w(dk),w(mk),w(QC),w(fk),w(HC),m&&t(oZe),m&&t(Ic),w(gk),m&&t(rZe),m&&t(ar),w(hk),w(pk),w(YC),w(_k),w(a3),m&&t(tZe),m&&t(jc),w(bk),m&&t(aZe),m&&t(nr),w(vk),w(Tk),w(s3),w(Mk),w(d3),m&&t(nZe),m&&t(Oc),w(Ek),m&&t(sZe),m&&t(sr),w(Ck),w(Ak),w(m3),w(Lk),w(m5),m&&t(lZe),m&&t(zc),w(yk),m&&t(iZe),m&&t(lr),w(xk),w(kk),w(g5),w(Sk),w(N5),m&&t(dZe),m&&t(Uc),w(Rk),m&&t(cZe),m&&t(ir),w(Pk),w(Ik),w(j5),w(Nk),w(e0),m&&t(mZe),m&&t(Yc),w(qk),m&&t(fZe),m&&t(dr),w(jk),w(Gk),w(r0),w(Ok),w(m0),m&&t(gZe),m&&t(em),w(Vk),m&&t(hZe),m&&t(cr),w(Xk),w(Qk),w(g0),w(Wk),w(_0),m&&t(uZe),m&&t(am),w(Uk),m&&t(pZe),m&&t(mr),w(Hk),w(Yk),w(v0),w(Kk),w(D0),m&&t(_Ze),m&&t(lm),w(Zk),m&&t(bZe),m&&t(fr),w(eS),w(rS),w(O0),w(tS),w(Z0),m&&t(vZe),m&&t(cm),w(aS),m&&t(FZe),m&&t(gr),w(nS),w(lS),w(ow),w(iS),w(xw),m&&t(TZe),m&&t(gm),w(dS),m&&t(MZe),m&&t(hr),w(cS),w(fS),w(kw),w(gS),w(Hw),m&&t(EZe),m&&t(pm),w(hS),m&&t(CZe),m&&t(ur),w(uS),w(_S),w(Yw),w(bS),w(eA),m&&t(wZe),m&&t(vm),w(FS),m&&t(AZe),m&&t(pr),w(TS),w(ES),w(rA),w(CS),w(aA),m&&t(LZe),m&&t(Mm),w(wS),m&&t(yZe),m&&t(_r),w(AS),w(yS),w(sA),w(xS),w(iA),m&&t(xZe),m&&t(wm),w($S),m&&t($Ze),m&&t(br),w(kS),w(RS),w(cA),w(PS),w(SA),m&&t(kZe),m&&t(ym),w(BS),m&&t(SZe),m&&t(vr),w(IS),w(qS),w(PA),w(jS),w(r6),m&&t(RZe),m&&t(km),w(DS),m&&t(PZe),m&&t(Fr),w(GS),w(VS),w(a6),w(XS),w(s6),m&&t(BZe),m&&t(Pm),w(zS),m&&t(IZe),m&&t(Tr),w(QS),w(US),w(i6),w(HS),w(c6),m&&t(NZe),m&&t(Nm),w(JS),m&&t(qZe),m&&t(Mr),w(YS),w(ZS),w(f6),w(eR),w(D6),m&&t(jZe),m&&t(Dm),w(oR),m&&t(DZe),m&&t(Er),w(rR),w(aR),w(O6),w(nR),w(Z6),m&&t(GZe),m&&t(Vm),w(sR),m&&t(OZe),m&&t(Cr),w(lR),w(dR),w(o7),w(cR),w(u7),m&&t(VZe),m&&t(Qm),w(mR),m&&t(XZe),m&&t(wr),w(fR),w(hR),w(_7),w(uR),w(y7),m&&t(zZe),m&&t(Hm),w(pR),m&&t(QZe),m&&t(Ar),w(_R),w(vR),w($7),w(FR),w(G7),m&&t(WZe),m&&t(Km),w(TR),m&&t(UZe),m&&t(Lr),w(MR),w(CR),w(V7),w(wR),w(eL),m&&t(HZe),m&&t(of),w(AR),m&&t(JZe),m&&t(yr),w(LR),w(xR),w(rL),w($R),w(gL),m&&t(YZe),m&&t(af),w(kR),m&&t(KZe),m&&t(xr),w(SR),w(PR),w(uL),w(BR),w(CL),m&&t(ZZe),m&&t(lf),w(IR),m&&t(eeo),m&&t($r),w(NR),w(jR),w(AL),w(DR),w(BL),m&&t(oeo),m&&t(mf),w(GR),m&&t(reo),m&&t(kr),w(OR),w(XR),w(NL),w(zR),w(jL),m&&t(teo),m&&t(hf),w(QR),m&&t(aeo),m&&t(Sr),w(WR),w(HR),w(GL),w(JR),w(XL),m&&t(neo),m&&t(_f),w(KR),m&&t(seo),m&&t(Rr),w(ZR),w(oP),w(QL),w(rP),w(UL)}}}const jua={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function Dua($){return $ga(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Wua extends Aga{constructor(g){super();Lga(this,g,Dua,qua,yga,{})}}export{Wua as default,jua as metadata};
