import{S as eba,i as oba,s as rba,e as a,k as l,w as F,t as o,M as tba,c as n,d as t,m as i,a as s,x as T,h as r,b as d,G as e,g as b,y as M,q as E,o as C,B as w,v as aba,L as q}from"../../chunks/vendor-hf-doc-builder.js";import{T as DEt}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as N}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function nba($){let g,v,u,f,p,m,h,yo,td,Cf,pt,ad,nd,ax,wf,Ve,He,sd,es,nx,os,rs,sx,ld,ts,lx,id,Af,Qa;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),m=a("code"),h=o("PretrainedConfig"),yo=o(`, make sure its
`),td=a("code"),Cf=o("model_type"),pt=o(" attribute is set to the same key you use when registering the config (here "),ad=a("code"),nd=o('"new-model"'),ax=o(")."),wf=l(),Ve=a("p"),He=o("Likewise, if your "),sd=a("code"),es=o("NewModel"),nx=o(" is a subclass of "),os=a("a"),rs=o("PreTrainedModel"),sx=o(`, make sure its
`),ld=a("code"),ts=o("config_class"),lx=o(` attribute is set to the same class you use when registering the model (here
`),id=a("code"),Af=o("NewModelConfig"),Qa=o(")."),this.h()},l(Je){g=n(Je,"P",{});var Ae=s(g);v=r(Ae,"If your "),u=n(Ae,"CODE",{});var lI=s(u);f=r(lI,"NewModelConfig"),lI.forEach(t),p=r(Ae," is a subclass of "),m=n(Ae,"CODE",{});var dd=s(m);h=r(dd,"PretrainedConfig"),dd.forEach(t),yo=r(Ae,`, make sure its
`),td=n(Ae,"CODE",{});var iI=s(td);Cf=r(iI,"model_type"),iI.forEach(t),pt=r(Ae," attribute is set to the same key you use when registering the config (here "),ad=n(Ae,"CODE",{});var dI=s(ad);nd=r(dI,'"new-model"'),dI.forEach(t),ax=r(Ae,")."),Ae.forEach(t),wf=i(Je),Ve=n(Je,"P",{});var xo=s(Ve);He=r(xo,"Likewise, if your "),sd=n(xo,"CODE",{});var Wa=s(sd);es=r(Wa,"NewModel"),Wa.forEach(t),nx=r(xo," is a subclass of "),os=n(xo,"A",{href:!0});var mI=s(os);rs=r(mI,"PreTrainedModel"),mI.forEach(t),sx=r(xo,`, make sure its
`),ld=n(xo,"CODE",{});var Lf=s(ld);ts=r(Lf,"config_class"),Lf.forEach(t),lx=r(xo,` attribute is set to the same class you use when registering the model (here
`),id=n(xo,"CODE",{});var cI=s(id);Af=r(cI,"NewModelConfig"),cI.forEach(t),Qa=r(xo,")."),xo.forEach(t),this.h()},h(){d(os,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Je,Ae){b(Je,g,Ae),e(g,v),e(g,u),e(u,f),e(g,p),e(g,m),e(m,h),e(g,yo),e(g,td),e(td,Cf),e(g,pt),e(g,ad),e(ad,nd),e(g,ax),b(Je,wf,Ae),b(Je,Ve,Ae),e(Ve,He),e(Ve,sd),e(sd,es),e(Ve,nx),e(Ve,os),e(os,rs),e(Ve,sx),e(Ve,ld),e(ld,ts),e(Ve,lx),e(Ve,id),e(id,Af),e(Ve,Qa)},d(Je){Je&&t(g),Je&&t(wf),Je&&t(Ve)}}}function sba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function lba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function iba($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var yo=s(u);f=r(yo,"use_auth_token=True"),yo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(m,h){b(m,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(m){m&&t(g)}}}function dba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function mba($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var yo=s(u);f=r(yo,"use_auth_token=True"),yo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(m,h){b(m,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(m){m&&t(g)}}}function cba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function fba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function gba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function hba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function uba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function pba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function _ba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function bba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function vba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Fba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Tba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Mba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Eba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Cba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function wba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Aba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Lba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function yba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function xba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function $ba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function kba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Sba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Rba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Pba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Bba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Iba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Nba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function qba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function jba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Dba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Gba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Oba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Vba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Xba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function zba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Qba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Wba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Uba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Hba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Jba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Yba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Kba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Zba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function eva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function ova($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function rva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function tva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function ava($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function nva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function sva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function lva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function iva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function dva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function mva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function cva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function fva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function gva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function hva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function uva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function pva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function _va($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function bva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function vva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Fva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Tva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Mva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Eva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Cva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function wva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Ava($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Lva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function yva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function xva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function $va($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function kva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Sva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Rva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Pva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Bva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Iva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Nva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function qva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function jva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Dva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Gva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Ova($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Vva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Xva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function zva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Qva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Wva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Uva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Hva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Jva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Yva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Kva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Zva($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function eFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function oFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function rFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function tFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function aFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function nFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function sFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function lFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function iFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function dFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function mFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function cFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function fFa($){let g,v,u,f,p,m,h,yo,td,Cf,pt,ad,nd,ax,wf,Ve,He,sd,es,nx,os,rs,sx,ld,ts,lx,id,Af,Qa,Je,Ae,lI,dd,iI,dI,xo,Wa,mI,Lf,cI,Xao,ueo,md,yf,ume,ix,zao,pme,Qao,peo,as,Wao,_me,Uao,Hao,bme,Jao,Yao,_eo,dx,beo,fI,Kao,veo,xf,Feo,cd,$f,vme,mx,Zao,Fme,eno,Teo,$o,cx,ono,fx,rno,gI,tno,ano,nno,gx,sno,Tme,lno,ino,dno,Pr,hx,mno,Mme,cno,fno,fd,gno,Eme,hno,uno,Cme,pno,_no,bno,A,kf,wme,vno,Fno,hI,Tno,Mno,Eno,Sf,Ame,Cno,wno,uI,Ano,Lno,yno,Rf,Lme,xno,$no,pI,kno,Sno,Rno,Pf,yme,Pno,Bno,_I,Ino,Nno,qno,Bf,xme,jno,Dno,bI,Gno,Ono,Vno,If,$me,Xno,zno,vI,Qno,Wno,Uno,Nf,kme,Hno,Jno,FI,Yno,Kno,Zno,qf,Sme,eso,oso,TI,rso,tso,aso,jf,Rme,nso,sso,MI,lso,iso,dso,Df,Pme,mso,cso,EI,fso,gso,hso,Gf,Bme,uso,pso,CI,_so,bso,vso,Of,Ime,Fso,Tso,wI,Mso,Eso,Cso,Vf,Nme,wso,Aso,AI,Lso,yso,xso,Xf,qme,$so,kso,LI,Sso,Rso,Pso,zf,jme,Bso,Iso,yI,Nso,qso,jso,Qf,Dme,Dso,Gso,xI,Oso,Vso,Xso,Wf,Gme,zso,Qso,$I,Wso,Uso,Hso,Uf,Ome,Jso,Yso,kI,Kso,Zso,elo,Hf,Vme,olo,rlo,SI,tlo,alo,nlo,Jf,Xme,slo,llo,RI,ilo,dlo,mlo,Yf,zme,clo,flo,PI,glo,hlo,ulo,Kf,Qme,plo,_lo,BI,blo,vlo,Flo,Zf,Wme,Tlo,Mlo,II,Elo,Clo,wlo,eg,Ume,Alo,Llo,NI,ylo,xlo,$lo,og,Hme,klo,Slo,qI,Rlo,Plo,Blo,rg,Jme,Ilo,Nlo,jI,qlo,jlo,Dlo,tg,Yme,Glo,Olo,DI,Vlo,Xlo,zlo,ag,Kme,Qlo,Wlo,GI,Ulo,Hlo,Jlo,ng,Zme,Ylo,Klo,OI,Zlo,eio,oio,sg,ece,rio,tio,VI,aio,nio,sio,lg,oce,lio,iio,XI,dio,mio,cio,ig,rce,fio,gio,zI,hio,uio,pio,dg,tce,_io,bio,QI,vio,Fio,Tio,mg,ace,Mio,Eio,WI,Cio,wio,Aio,cg,nce,Lio,yio,UI,xio,$io,kio,fg,sce,Sio,Rio,HI,Pio,Bio,Iio,gg,lce,Nio,qio,JI,jio,Dio,Gio,hg,ice,Oio,Vio,YI,Xio,zio,Qio,ug,dce,Wio,Uio,KI,Hio,Jio,Yio,pg,mce,Kio,Zio,ZI,edo,odo,rdo,_g,cce,tdo,ado,eN,ndo,sdo,ldo,bg,fce,ido,ddo,oN,mdo,cdo,fdo,vg,gce,gdo,hdo,rN,udo,pdo,_do,Fg,hce,bdo,vdo,tN,Fdo,Tdo,Mdo,Tg,uce,Edo,Cdo,aN,wdo,Ado,Ldo,Mg,pce,ydo,xdo,nN,$do,kdo,Sdo,Eg,_ce,Rdo,Pdo,sN,Bdo,Ido,Ndo,Cg,bce,qdo,jdo,lN,Ddo,Gdo,Odo,wg,vce,Vdo,Xdo,iN,zdo,Qdo,Wdo,Ag,Fce,Udo,Hdo,dN,Jdo,Ydo,Kdo,Lg,Tce,Zdo,emo,mN,omo,rmo,tmo,yg,Mce,amo,nmo,cN,smo,lmo,imo,xg,Ece,dmo,mmo,fN,cmo,fmo,gmo,$g,Cce,hmo,umo,gN,pmo,_mo,bmo,kg,wce,vmo,Fmo,hN,Tmo,Mmo,Emo,Sg,Ace,Cmo,wmo,uN,Amo,Lmo,ymo,Rg,Lce,xmo,$mo,pN,kmo,Smo,Rmo,Pg,yce,Pmo,Bmo,_N,Imo,Nmo,qmo,Bg,xce,jmo,Dmo,bN,Gmo,Omo,Vmo,Ig,$ce,Xmo,zmo,vN,Qmo,Wmo,Umo,Ng,kce,Hmo,Jmo,FN,Ymo,Kmo,Zmo,qg,Sce,eco,oco,TN,rco,tco,aco,jg,Rce,nco,sco,MN,lco,ico,dco,Dg,Pce,mco,cco,EN,fco,gco,hco,Gg,Bce,uco,pco,CN,_co,bco,vco,Og,Ice,Fco,Tco,wN,Mco,Eco,Cco,Vg,Nce,wco,Aco,AN,Lco,yco,xco,Xg,qce,$co,kco,LN,Sco,Rco,Pco,zg,jce,Bco,Ico,yN,Nco,qco,jco,Qg,Dce,Dco,Gco,xN,Oco,Vco,Xco,Wg,Gce,zco,Qco,$N,Wco,Uco,Hco,Ug,Oce,Jco,Yco,kN,Kco,Zco,efo,Hg,Vce,ofo,rfo,SN,tfo,afo,nfo,Jg,Xce,sfo,lfo,RN,ifo,dfo,mfo,Yg,zce,cfo,ffo,PN,gfo,hfo,ufo,Kg,Qce,pfo,_fo,BN,bfo,vfo,Ffo,Zg,Wce,Tfo,Mfo,IN,Efo,Cfo,wfo,eh,Uce,Afo,Lfo,NN,yfo,xfo,$fo,oh,Hce,kfo,Sfo,qN,Rfo,Pfo,Bfo,rh,Jce,Ifo,Nfo,jN,qfo,jfo,Dfo,th,Yce,Gfo,Ofo,DN,Vfo,Xfo,zfo,ah,Kce,Qfo,Wfo,GN,Ufo,Hfo,Jfo,nh,Zce,Yfo,Kfo,ON,Zfo,ego,ogo,sh,efe,rgo,tgo,VN,ago,ngo,sgo,lh,ofe,lgo,igo,XN,dgo,mgo,cgo,ih,rfe,fgo,ggo,zN,hgo,ugo,pgo,dh,tfe,_go,bgo,QN,vgo,Fgo,Tgo,mh,afe,Mgo,Ego,WN,Cgo,wgo,Ago,ch,nfe,Lgo,ygo,UN,xgo,$go,kgo,fh,sfe,Sgo,Rgo,HN,Pgo,Bgo,Igo,gh,lfe,Ngo,qgo,JN,jgo,Dgo,Ggo,hh,ife,Ogo,Vgo,YN,Xgo,zgo,Qgo,uh,dfe,Wgo,Ugo,KN,Hgo,Jgo,Ygo,ph,mfe,Kgo,Zgo,ZN,eho,oho,rho,_h,cfe,tho,aho,eq,nho,sho,lho,bh,ffe,iho,dho,oq,mho,cho,fho,vh,gfe,gho,hho,rq,uho,pho,_ho,Fh,hfe,bho,vho,tq,Fho,Tho,Mho,Th,ufe,Eho,Cho,aq,who,Aho,Lho,Mh,pfe,yho,xho,nq,$ho,kho,Sho,Eh,_fe,Rho,Pho,sq,Bho,Iho,Nho,Ch,bfe,qho,jho,lq,Dho,Gho,Oho,wh,vfe,Vho,Xho,iq,zho,Qho,Who,Ah,Ffe,Uho,Hho,dq,Jho,Yho,Kho,Lh,Tfe,Zho,euo,mq,ouo,ruo,tuo,yh,Mfe,auo,nuo,cq,suo,luo,iuo,xh,Efe,duo,muo,fq,cuo,fuo,guo,$h,Cfe,huo,uuo,gq,puo,_uo,buo,kh,wfe,vuo,Fuo,hq,Tuo,Muo,Euo,Sh,Afe,Cuo,wuo,uq,Auo,Luo,yuo,Rh,Lfe,xuo,$uo,pq,kuo,Suo,Ruo,Ph,yfe,Puo,Buo,_q,Iuo,Nuo,quo,Bh,xfe,juo,Duo,bq,Guo,Ouo,Vuo,Ih,$fe,Xuo,zuo,vq,Quo,Wuo,Uuo,Nh,kfe,Huo,Juo,Fq,Yuo,Kuo,Zuo,qh,Sfe,epo,opo,Tq,rpo,tpo,apo,jh,Rfe,npo,spo,Mq,lpo,ipo,dpo,Dh,Pfe,mpo,cpo,Eq,fpo,gpo,hpo,Gh,Bfe,upo,ppo,Cq,_po,bpo,vpo,Oh,Ife,Fpo,Tpo,wq,Mpo,Epo,Cpo,Vh,Nfe,wpo,Apo,Aq,Lpo,ypo,xpo,Xh,qfe,$po,kpo,Lq,Spo,Rpo,Ppo,zh,jfe,Bpo,Ipo,yq,Npo,qpo,jpo,Qh,Dfe,Dpo,Gpo,xq,Opo,Vpo,Xpo,Wh,Gfe,zpo,Qpo,$q,Wpo,Upo,Hpo,Uh,Ofe,Jpo,Ypo,kq,Kpo,Zpo,e_o,Hh,Vfe,o_o,r_o,Sq,t_o,a_o,n_o,Jh,Xfe,s_o,l_o,Rq,i_o,d_o,m_o,Yh,zfe,c_o,f_o,Pq,g_o,h_o,u_o,Kh,Qfe,p_o,__o,Bq,b_o,v_o,F_o,Zh,Wfe,T_o,M_o,Iq,E_o,C_o,w_o,eu,Ufe,A_o,L_o,Nq,y_o,x_o,$_o,ou,Hfe,k_o,S_o,qq,R_o,P_o,B_o,ru,I_o,tu,ux,N_o,Jfe,q_o,Meo,gd,au,Yfe,px,j_o,Kfe,D_o,Eeo,ko,_x,G_o,bx,O_o,jq,V_o,X_o,z_o,vx,Q_o,Zfe,W_o,U_o,H_o,Br,Fx,J_o,ege,Y_o,K_o,Ua,Z_o,oge,e1o,o1o,rge,r1o,t1o,tge,a1o,n1o,s1o,k,ns,age,l1o,i1o,Dq,d1o,m1o,Gq,c1o,f1o,g1o,ss,nge,h1o,u1o,Oq,p1o,_1o,Vq,b1o,v1o,F1o,ls,sge,T1o,M1o,Xq,E1o,C1o,zq,w1o,A1o,L1o,nu,lge,y1o,x1o,Qq,$1o,k1o,S1o,is,ige,R1o,P1o,Wq,B1o,I1o,Uq,N1o,q1o,j1o,su,dge,D1o,G1o,Hq,O1o,V1o,X1o,lu,mge,z1o,Q1o,Jq,W1o,U1o,H1o,iu,cge,J1o,Y1o,Yq,K1o,Z1o,e2o,ds,fge,o2o,r2o,Kq,t2o,a2o,Zq,n2o,s2o,l2o,ms,gge,i2o,d2o,ej,m2o,c2o,oj,f2o,g2o,h2o,cs,hge,u2o,p2o,rj,_2o,b2o,tj,v2o,F2o,T2o,du,uge,M2o,E2o,aj,C2o,w2o,A2o,mu,pge,L2o,y2o,nj,x2o,$2o,k2o,cu,_ge,S2o,R2o,sj,P2o,B2o,I2o,fs,bge,N2o,q2o,lj,j2o,D2o,ij,G2o,O2o,V2o,fu,vge,X2o,z2o,dj,Q2o,W2o,U2o,gs,Fge,H2o,J2o,mj,Y2o,K2o,cj,Z2o,ebo,obo,hs,Tge,rbo,tbo,fj,abo,nbo,gj,sbo,lbo,ibo,us,Mge,dbo,mbo,hj,cbo,fbo,uj,gbo,hbo,ubo,ps,Ege,pbo,_bo,pj,bbo,vbo,_j,Fbo,Tbo,Mbo,gu,Cge,Ebo,Cbo,bj,wbo,Abo,Lbo,_s,wge,ybo,xbo,vj,$bo,kbo,Fj,Sbo,Rbo,Pbo,bs,Age,Bbo,Ibo,Tj,Nbo,qbo,Mj,jbo,Dbo,Gbo,vs,Lge,Obo,Vbo,Ej,Xbo,zbo,Cj,Qbo,Wbo,Ubo,Fs,yge,Hbo,Jbo,wj,Ybo,Kbo,Aj,Zbo,evo,ovo,Ts,xge,rvo,tvo,Lj,avo,nvo,yj,svo,lvo,ivo,Ms,$ge,dvo,mvo,xj,cvo,fvo,$j,gvo,hvo,uvo,Es,kge,pvo,_vo,kj,bvo,vvo,Sj,Fvo,Tvo,Mvo,hu,Sge,Evo,Cvo,Rj,wvo,Avo,Lvo,Cs,Rge,yvo,xvo,Pj,$vo,kvo,Bj,Svo,Rvo,Pvo,uu,Pge,Bvo,Ivo,Ij,Nvo,qvo,jvo,ws,Bge,Dvo,Gvo,Nj,Ovo,Vvo,qj,Xvo,zvo,Qvo,As,Ige,Wvo,Uvo,jj,Hvo,Jvo,Dj,Yvo,Kvo,Zvo,Ls,Nge,eFo,oFo,Gj,rFo,tFo,Oj,aFo,nFo,sFo,pu,qge,lFo,iFo,Vj,dFo,mFo,cFo,_u,jge,fFo,gFo,Xj,hFo,uFo,pFo,ys,Dge,_Fo,bFo,zj,vFo,FFo,Qj,TFo,MFo,EFo,xs,Gge,CFo,wFo,Wj,AFo,LFo,Uj,yFo,xFo,$Fo,$s,Oge,kFo,SFo,Hj,RFo,PFo,Jj,BFo,IFo,NFo,bu,Vge,qFo,jFo,Yj,DFo,GFo,OFo,ks,Xge,VFo,XFo,Kj,zFo,QFo,Zj,WFo,UFo,HFo,Ss,zge,JFo,YFo,eD,KFo,ZFo,oD,eTo,oTo,rTo,Rs,Qge,tTo,aTo,rD,nTo,sTo,tD,lTo,iTo,dTo,Ps,Wge,mTo,cTo,aD,fTo,gTo,nD,hTo,uTo,pTo,Bs,Uge,_To,bTo,sD,vTo,FTo,lD,TTo,MTo,ETo,Is,Hge,CTo,wTo,iD,ATo,LTo,dD,yTo,xTo,$To,Ns,Jge,kTo,STo,mD,RTo,PTo,cD,BTo,ITo,NTo,qs,Yge,qTo,jTo,fD,DTo,GTo,gD,OTo,VTo,XTo,vu,Kge,zTo,QTo,hD,WTo,UTo,HTo,js,Zge,JTo,YTo,uD,KTo,ZTo,pD,eMo,oMo,rMo,Fu,ehe,tMo,aMo,_D,nMo,sMo,lMo,Tu,ohe,iMo,dMo,bD,mMo,cMo,fMo,Ds,rhe,gMo,hMo,vD,uMo,pMo,FD,_Mo,bMo,vMo,Gs,the,FMo,TMo,TD,MMo,EMo,MD,CMo,wMo,AMo,Os,ahe,LMo,yMo,ED,xMo,$Mo,CD,kMo,SMo,RMo,Mu,nhe,PMo,BMo,wD,IMo,NMo,qMo,Vs,she,jMo,DMo,AD,GMo,OMo,LD,VMo,XMo,zMo,Xs,lhe,QMo,WMo,yD,UMo,HMo,xD,JMo,YMo,KMo,zs,ihe,ZMo,eEo,$D,oEo,rEo,kD,tEo,aEo,nEo,Qs,dhe,sEo,lEo,SD,iEo,dEo,RD,mEo,cEo,fEo,Ws,mhe,gEo,hEo,PD,uEo,pEo,BD,_Eo,bEo,vEo,Us,che,FEo,TEo,ID,MEo,EEo,ND,CEo,wEo,AEo,Hs,fhe,LEo,yEo,qD,xEo,$Eo,jD,kEo,SEo,REo,Js,ghe,PEo,BEo,DD,IEo,NEo,GD,qEo,jEo,DEo,Eu,hhe,GEo,OEo,OD,VEo,XEo,zEo,Ys,uhe,QEo,WEo,VD,UEo,HEo,XD,JEo,YEo,KEo,Ks,phe,ZEo,e4o,zD,o4o,r4o,QD,t4o,a4o,n4o,Cu,_he,s4o,l4o,WD,i4o,d4o,m4o,wu,bhe,c4o,f4o,UD,g4o,h4o,u4o,Au,vhe,p4o,_4o,HD,b4o,v4o,F4o,Lu,Fhe,T4o,M4o,JD,E4o,C4o,w4o,Zs,The,A4o,L4o,YD,y4o,x4o,KD,$4o,k4o,S4o,yu,Mhe,R4o,P4o,ZD,B4o,I4o,N4o,el,Ehe,q4o,j4o,eG,D4o,G4o,oG,O4o,V4o,X4o,ol,Che,z4o,Q4o,rG,W4o,U4o,tG,H4o,J4o,Y4o,rl,whe,K4o,Z4o,aG,eCo,oCo,nG,rCo,tCo,aCo,tl,Ahe,nCo,sCo,sG,lCo,iCo,lG,dCo,mCo,cCo,al,Lhe,fCo,gCo,iG,hCo,uCo,dG,pCo,_Co,bCo,nl,yhe,vCo,FCo,mG,TCo,MCo,cG,ECo,CCo,wCo,xu,xhe,ACo,LCo,fG,yCo,xCo,$Co,$u,$he,kCo,SCo,gG,RCo,PCo,BCo,sl,khe,ICo,NCo,hG,qCo,jCo,uG,DCo,GCo,OCo,ll,She,VCo,XCo,pG,zCo,QCo,_G,WCo,UCo,HCo,il,Rhe,JCo,YCo,bG,KCo,ZCo,vG,e3o,o3o,r3o,ku,Phe,t3o,a3o,FG,n3o,s3o,l3o,Su,Bhe,i3o,d3o,TG,m3o,c3o,f3o,Ru,Ihe,g3o,h3o,MG,u3o,p3o,_3o,dl,Nhe,b3o,v3o,EG,F3o,T3o,CG,M3o,E3o,C3o,ml,qhe,w3o,A3o,wG,L3o,y3o,AG,x3o,$3o,k3o,Pu,jhe,S3o,R3o,LG,P3o,B3o,I3o,Bu,Dhe,N3o,q3o,yG,j3o,D3o,G3o,Iu,Ghe,O3o,V3o,xG,X3o,z3o,Q3o,Nu,Ohe,W3o,U3o,$G,H3o,J3o,Y3o,cl,Vhe,K3o,Z3o,kG,e5o,o5o,SG,r5o,t5o,a5o,fl,Xhe,n5o,s5o,RG,l5o,i5o,PG,d5o,m5o,c5o,qu,zhe,f5o,g5o,BG,h5o,u5o,p5o,ju,Qhe,_5o,b5o,IG,v5o,F5o,T5o,gl,Whe,M5o,E5o,NG,C5o,w5o,qG,A5o,L5o,y5o,hl,Uhe,x5o,$5o,jG,k5o,S5o,DG,R5o,P5o,B5o,ul,Hhe,I5o,N5o,GG,q5o,j5o,OG,D5o,G5o,O5o,pl,Jhe,V5o,X5o,VG,z5o,Q5o,XG,W5o,U5o,H5o,Du,J5o,Gu,Tx,Y5o,Yhe,K5o,Ceo,hd,Ou,Khe,Mx,Z5o,Zhe,e0o,weo,So,Ex,o0o,Cx,r0o,zG,t0o,a0o,n0o,wx,s0o,eue,l0o,i0o,d0o,Ye,Ax,m0o,oue,c0o,f0o,Ha,g0o,rue,h0o,u0o,tue,p0o,_0o,aue,b0o,v0o,F0o,z,Vu,nue,T0o,M0o,QG,E0o,C0o,w0o,Xu,sue,A0o,L0o,WG,y0o,x0o,$0o,zu,lue,k0o,S0o,UG,R0o,P0o,B0o,Qu,iue,I0o,N0o,HG,q0o,j0o,D0o,Wu,due,G0o,O0o,JG,V0o,X0o,z0o,Uu,mue,Q0o,W0o,YG,U0o,H0o,J0o,Hu,cue,Y0o,K0o,KG,Z0o,ewo,owo,Ju,fue,rwo,two,ZG,awo,nwo,swo,Yu,gue,lwo,iwo,eO,dwo,mwo,cwo,Ku,hue,fwo,gwo,oO,hwo,uwo,pwo,Zu,uue,_wo,bwo,rO,vwo,Fwo,Two,ep,pue,Mwo,Ewo,tO,Cwo,wwo,Awo,op,_ue,Lwo,ywo,aO,xwo,$wo,kwo,rp,bue,Swo,Rwo,nO,Pwo,Bwo,Iwo,tp,vue,Nwo,qwo,sO,jwo,Dwo,Gwo,ap,Fue,Owo,Vwo,lO,Xwo,zwo,Qwo,np,Tue,Wwo,Uwo,iO,Hwo,Jwo,Ywo,sp,Mue,Kwo,Zwo,dO,eAo,oAo,rAo,lp,Eue,tAo,aAo,mO,nAo,sAo,lAo,ip,Cue,iAo,dAo,cO,mAo,cAo,fAo,dp,wue,gAo,hAo,fO,uAo,pAo,_Ao,mp,Aue,bAo,vAo,gO,FAo,TAo,MAo,cp,Lue,EAo,CAo,hO,wAo,AAo,LAo,fp,yue,yAo,xAo,uO,$Ao,kAo,SAo,gp,xue,RAo,PAo,pO,BAo,IAo,NAo,hp,$ue,qAo,jAo,_O,DAo,GAo,OAo,up,kue,VAo,XAo,bO,zAo,QAo,WAo,pp,Sue,UAo,HAo,vO,JAo,YAo,KAo,_p,Rue,ZAo,e6o,FO,o6o,r6o,t6o,bp,Pue,a6o,n6o,TO,s6o,l6o,i6o,vp,Bue,d6o,m6o,MO,c6o,f6o,g6o,Fp,Iue,h6o,u6o,EO,p6o,_6o,b6o,Tp,Nue,v6o,F6o,CO,T6o,M6o,E6o,Mp,que,C6o,w6o,wO,A6o,L6o,y6o,Ep,jue,x6o,$6o,AO,k6o,S6o,R6o,Cp,Due,P6o,B6o,LO,I6o,N6o,q6o,wp,Gue,j6o,D6o,yO,G6o,O6o,V6o,Ap,Oue,X6o,z6o,xO,Q6o,W6o,U6o,Lp,Vue,H6o,J6o,$O,Y6o,K6o,Z6o,yp,Xue,e7o,o7o,kO,r7o,t7o,a7o,xp,zue,n7o,s7o,SO,l7o,i7o,d7o,$p,Que,m7o,c7o,RO,f7o,g7o,h7o,kp,Wue,u7o,p7o,PO,_7o,b7o,v7o,Sp,F7o,Rp,T7o,Pp,Lx,M7o,Uue,E7o,Aeo,ud,Bp,Hue,yx,C7o,Jue,w7o,Leo,Ro,xx,A7o,$x,L7o,BO,y7o,x7o,$7o,kx,k7o,Yue,S7o,R7o,P7o,Ke,Sx,B7o,Kue,I7o,N7o,pd,q7o,Zue,j7o,D7o,epe,G7o,O7o,V7o,se,Ip,ope,X7o,z7o,IO,Q7o,W7o,U7o,Np,rpe,H7o,J7o,NO,Y7o,K7o,Z7o,qp,tpe,eLo,oLo,qO,rLo,tLo,aLo,jp,ape,nLo,sLo,jO,lLo,iLo,dLo,Dp,npe,mLo,cLo,DO,fLo,gLo,hLo,Gp,spe,uLo,pLo,GO,_Lo,bLo,vLo,Op,lpe,FLo,TLo,OO,MLo,ELo,CLo,Vp,ipe,wLo,ALo,VO,LLo,yLo,xLo,Xp,dpe,$Lo,kLo,XO,SLo,RLo,PLo,zp,mpe,BLo,ILo,zO,NLo,qLo,jLo,Qp,cpe,DLo,GLo,QO,OLo,VLo,XLo,Wp,fpe,zLo,QLo,WO,WLo,ULo,HLo,Up,gpe,JLo,YLo,UO,KLo,ZLo,eyo,Hp,hpe,oyo,ryo,HO,tyo,ayo,nyo,Jp,upe,syo,lyo,JO,iyo,dyo,myo,Yp,ppe,cyo,fyo,YO,gyo,hyo,uyo,Kp,_pe,pyo,_yo,KO,byo,vyo,Fyo,Zp,bpe,Tyo,Myo,ZO,Eyo,Cyo,wyo,e_,vpe,Ayo,Lyo,eV,yyo,xyo,$yo,o_,Fpe,kyo,Syo,oV,Ryo,Pyo,Byo,r_,Tpe,Iyo,Nyo,rV,qyo,jyo,Dyo,t_,Mpe,Gyo,Oyo,tV,Vyo,Xyo,zyo,a_,Epe,Qyo,Wyo,aV,Uyo,Hyo,Jyo,n_,Yyo,s_,Kyo,l_,Rx,Zyo,Cpe,e8o,yeo,_d,i_,wpe,Px,o8o,Ape,r8o,xeo,Po,Bx,t8o,bd,a8o,nV,n8o,s8o,sV,l8o,i8o,d8o,Ix,m8o,Lpe,c8o,f8o,g8o,_t,Nx,h8o,ype,u8o,p8o,vd,_8o,xpe,b8o,v8o,lV,F8o,T8o,M8o,d_,E8o,Ze,qx,C8o,$pe,w8o,A8o,Ja,L8o,kpe,y8o,x8o,Spe,$8o,k8o,Rpe,S8o,R8o,P8o,y,m_,Ppe,B8o,I8o,iV,N8o,q8o,j8o,c_,Bpe,D8o,G8o,dV,O8o,V8o,X8o,f_,Ipe,z8o,Q8o,mV,W8o,U8o,H8o,g_,Npe,J8o,Y8o,cV,K8o,Z8o,e9o,h_,qpe,o9o,r9o,fV,t9o,a9o,n9o,u_,jpe,s9o,l9o,gV,i9o,d9o,m9o,p_,Dpe,c9o,f9o,hV,g9o,h9o,u9o,__,Gpe,p9o,_9o,uV,b9o,v9o,F9o,b_,Ope,T9o,M9o,pV,E9o,C9o,w9o,v_,Vpe,A9o,L9o,_V,y9o,x9o,$9o,F_,Xpe,k9o,S9o,bV,R9o,P9o,B9o,T_,zpe,I9o,N9o,vV,q9o,j9o,D9o,M_,Qpe,G9o,O9o,FV,V9o,X9o,z9o,E_,Wpe,Q9o,W9o,TV,U9o,H9o,J9o,C_,Upe,Y9o,K9o,MV,Z9o,exo,oxo,w_,Hpe,rxo,txo,EV,axo,nxo,sxo,A_,Jpe,lxo,ixo,CV,dxo,mxo,cxo,L_,Ype,fxo,gxo,wV,hxo,uxo,pxo,y_,Kpe,_xo,bxo,AV,vxo,Fxo,Txo,x_,Zpe,Mxo,Exo,LV,Cxo,wxo,Axo,$_,e_e,Lxo,yxo,yV,xxo,$xo,kxo,k_,o_e,Sxo,Rxo,xV,Pxo,Bxo,Ixo,S_,r_e,Nxo,qxo,$V,jxo,Dxo,Gxo,R_,t_e,Oxo,Vxo,kV,Xxo,zxo,Qxo,P_,a_e,Wxo,Uxo,SV,Hxo,Jxo,Yxo,B_,n_e,Kxo,Zxo,RV,e$o,o$o,r$o,I_,s_e,t$o,a$o,PV,n$o,s$o,l$o,N_,l_e,i$o,d$o,BV,m$o,c$o,f$o,q_,i_e,g$o,h$o,IV,u$o,p$o,_$o,j_,d_e,b$o,v$o,NV,F$o,T$o,M$o,D_,m_e,E$o,C$o,qV,w$o,A$o,L$o,G_,c_e,y$o,x$o,jV,$$o,k$o,S$o,O_,f_e,R$o,P$o,DV,B$o,I$o,N$o,V_,g_e,q$o,j$o,GV,D$o,G$o,O$o,X_,h_e,V$o,X$o,OV,z$o,Q$o,W$o,z_,u_e,U$o,H$o,VV,J$o,Y$o,K$o,Q_,p_e,Z$o,eko,XV,oko,rko,tko,W_,__e,ako,nko,zV,sko,lko,iko,U_,b_e,dko,mko,QV,cko,fko,gko,_l,v_e,hko,uko,WV,pko,_ko,UV,bko,vko,Fko,H_,F_e,Tko,Mko,HV,Eko,Cko,wko,J_,T_e,Ako,Lko,JV,yko,xko,$ko,Y_,M_e,kko,Sko,YV,Rko,Pko,Bko,K_,E_e,Iko,Nko,KV,qko,jko,Dko,Z_,C_e,Gko,Oko,ZV,Vko,Xko,zko,e1,w_e,Qko,Wko,eX,Uko,Hko,Jko,o1,A_e,Yko,Kko,oX,Zko,eSo,oSo,r1,L_e,rSo,tSo,rX,aSo,nSo,sSo,t1,y_e,lSo,iSo,tX,dSo,mSo,cSo,a1,x_e,fSo,gSo,aX,hSo,uSo,pSo,n1,$_e,_So,bSo,nX,vSo,FSo,TSo,s1,k_e,MSo,ESo,sX,CSo,wSo,ASo,l1,S_e,LSo,ySo,lX,xSo,$So,kSo,i1,R_e,SSo,RSo,iX,PSo,BSo,ISo,d1,P_e,NSo,qSo,dX,jSo,DSo,GSo,m1,B_e,OSo,VSo,mX,XSo,zSo,QSo,c1,I_e,WSo,USo,cX,HSo,JSo,YSo,f1,N_e,KSo,ZSo,fX,eRo,oRo,rRo,g1,q_e,tRo,aRo,gX,nRo,sRo,lRo,h1,j_e,iRo,dRo,hX,mRo,cRo,fRo,u1,D_e,gRo,hRo,uX,uRo,pRo,_Ro,p1,G_e,bRo,vRo,pX,FRo,TRo,MRo,_1,O_e,ERo,CRo,_X,wRo,ARo,LRo,b1,V_e,yRo,xRo,bX,$Ro,kRo,SRo,v1,X_e,RRo,PRo,vX,BRo,IRo,NRo,F1,z_e,qRo,jRo,FX,DRo,GRo,ORo,T1,Q_e,VRo,XRo,TX,zRo,QRo,WRo,M1,W_e,URo,HRo,MX,JRo,YRo,KRo,E1,U_e,ZRo,ePo,EX,oPo,rPo,tPo,C1,H_e,aPo,nPo,CX,sPo,lPo,iPo,w1,J_e,dPo,mPo,wX,cPo,fPo,gPo,A1,Y_e,hPo,uPo,AX,pPo,_Po,bPo,L1,K_e,vPo,FPo,LX,TPo,MPo,EPo,y1,Z_e,CPo,wPo,yX,APo,LPo,yPo,x1,e1e,xPo,$Po,xX,kPo,SPo,RPo,$1,o1e,PPo,BPo,$X,IPo,NPo,qPo,k1,r1e,jPo,DPo,kX,GPo,OPo,VPo,S1,t1e,XPo,zPo,SX,QPo,WPo,UPo,R1,a1e,HPo,JPo,RX,YPo,KPo,ZPo,P1,n1e,eBo,oBo,PX,rBo,tBo,aBo,B1,s1e,nBo,sBo,BX,lBo,iBo,dBo,I1,l1e,mBo,cBo,IX,fBo,gBo,hBo,N1,i1e,uBo,pBo,NX,_Bo,bBo,vBo,q1,d1e,FBo,TBo,qX,MBo,EBo,CBo,j1,m1e,wBo,ABo,jX,LBo,yBo,xBo,D1,c1e,$Bo,kBo,DX,SBo,RBo,PBo,G1,f1e,BBo,IBo,GX,NBo,qBo,jBo,O1,g1e,DBo,GBo,OX,OBo,VBo,XBo,V1,h1e,zBo,QBo,VX,WBo,UBo,HBo,X1,u1e,JBo,YBo,XX,KBo,ZBo,eIo,z1,p1e,oIo,rIo,zX,tIo,aIo,nIo,Q1,_1e,sIo,lIo,QX,iIo,dIo,mIo,W1,b1e,cIo,fIo,WX,gIo,hIo,uIo,U1,v1e,pIo,_Io,UX,bIo,vIo,FIo,H1,F1e,TIo,MIo,HX,EIo,CIo,wIo,J1,T1e,AIo,LIo,JX,yIo,xIo,$Io,Y1,M1e,kIo,SIo,YX,RIo,PIo,BIo,K1,E1e,IIo,NIo,KX,qIo,jIo,DIo,Z1,C1e,GIo,OIo,ZX,VIo,XIo,zIo,e2,w1e,QIo,WIo,ez,UIo,HIo,JIo,o2,A1e,YIo,KIo,oz,ZIo,eNo,oNo,r2,L1e,rNo,tNo,rz,aNo,nNo,sNo,t2,y1e,lNo,iNo,tz,dNo,mNo,cNo,a2,x1e,fNo,gNo,az,hNo,uNo,pNo,n2,$1e,_No,bNo,nz,vNo,FNo,TNo,s2,k1e,MNo,ENo,sz,CNo,wNo,ANo,l2,S1e,LNo,yNo,lz,xNo,$No,kNo,i2,R1e,SNo,RNo,iz,PNo,BNo,INo,d2,P1e,NNo,qNo,dz,jNo,DNo,GNo,m2,B1e,ONo,VNo,mz,XNo,zNo,QNo,c2,I1e,WNo,UNo,cz,HNo,JNo,YNo,f2,N1e,KNo,ZNo,fz,eqo,oqo,rqo,g2,q1e,tqo,aqo,gz,nqo,sqo,lqo,h2,j1e,iqo,dqo,hz,mqo,cqo,fqo,u2,D1e,gqo,hqo,uz,uqo,pqo,_qo,p2,G1e,bqo,vqo,pz,Fqo,Tqo,Mqo,_2,O1e,Eqo,Cqo,_z,wqo,Aqo,Lqo,b2,V1e,yqo,xqo,bz,$qo,kqo,Sqo,v2,X1e,Rqo,Pqo,vz,Bqo,Iqo,Nqo,F2,z1e,qqo,jqo,Fz,Dqo,Gqo,Oqo,T2,Q1e,Vqo,Xqo,Tz,zqo,Qqo,Wqo,M2,W1e,Uqo,Hqo,Mz,Jqo,Yqo,Kqo,E2,U1e,Zqo,ejo,Ez,ojo,rjo,tjo,C2,H1e,ajo,njo,Cz,sjo,ljo,ijo,w2,J1e,djo,mjo,wz,cjo,fjo,gjo,A2,Y1e,hjo,ujo,Az,pjo,_jo,bjo,L2,K1e,vjo,Fjo,Lz,Tjo,Mjo,Ejo,y2,Cjo,Z1e,wjo,Ajo,e2e,Ljo,yjo,x2,$eo,Fd,$2,o2e,jx,xjo,r2e,$jo,keo,Bo,Dx,kjo,Td,Sjo,yz,Rjo,Pjo,xz,Bjo,Ijo,Njo,Gx,qjo,t2e,jjo,Djo,Gjo,bt,Ox,Ojo,a2e,Vjo,Xjo,Md,zjo,n2e,Qjo,Wjo,$z,Ujo,Hjo,Jjo,k2,Yjo,eo,Vx,Kjo,s2e,Zjo,eDo,Ya,oDo,l2e,rDo,tDo,i2e,aDo,nDo,d2e,sDo,lDo,iDo,G,S2,m2e,dDo,mDo,kz,cDo,fDo,gDo,R2,c2e,hDo,uDo,Sz,pDo,_Do,bDo,P2,f2e,vDo,FDo,Rz,TDo,MDo,EDo,B2,g2e,CDo,wDo,Pz,ADo,LDo,yDo,I2,h2e,xDo,$Do,Bz,kDo,SDo,RDo,N2,u2e,PDo,BDo,Iz,IDo,NDo,qDo,q2,p2e,jDo,DDo,Nz,GDo,ODo,VDo,j2,_2e,XDo,zDo,qz,QDo,WDo,UDo,D2,b2e,HDo,JDo,jz,YDo,KDo,ZDo,G2,v2e,eGo,oGo,Dz,rGo,tGo,aGo,O2,F2e,nGo,sGo,Gz,lGo,iGo,dGo,V2,T2e,mGo,cGo,Oz,fGo,gGo,hGo,X2,M2e,uGo,pGo,Vz,_Go,bGo,vGo,z2,E2e,FGo,TGo,Xz,MGo,EGo,CGo,Q2,C2e,wGo,AGo,zz,LGo,yGo,xGo,W2,w2e,$Go,kGo,Qz,SGo,RGo,PGo,U2,A2e,BGo,IGo,Wz,NGo,qGo,jGo,H2,L2e,DGo,GGo,Uz,OGo,VGo,XGo,J2,y2e,zGo,QGo,Hz,WGo,UGo,HGo,Y2,x2e,JGo,YGo,Jz,KGo,ZGo,eOo,K2,$2e,oOo,rOo,Yz,tOo,aOo,nOo,Z2,k2e,sOo,lOo,Kz,iOo,dOo,mOo,eb,S2e,cOo,fOo,Zz,gOo,hOo,uOo,ob,R2e,pOo,_Oo,eQ,bOo,vOo,FOo,rb,P2e,TOo,MOo,oQ,EOo,COo,wOo,tb,B2e,AOo,LOo,rQ,yOo,xOo,$Oo,ab,I2e,kOo,SOo,tQ,ROo,POo,BOo,nb,N2e,IOo,NOo,aQ,qOo,jOo,DOo,sb,q2e,GOo,OOo,nQ,VOo,XOo,zOo,lb,j2e,QOo,WOo,sQ,UOo,HOo,JOo,ib,D2e,YOo,KOo,lQ,ZOo,eVo,oVo,db,G2e,rVo,tVo,iQ,aVo,nVo,sVo,mb,O2e,lVo,iVo,dQ,dVo,mVo,cVo,cb,V2e,fVo,gVo,mQ,hVo,uVo,pVo,fb,X2e,_Vo,bVo,cQ,vVo,FVo,TVo,gb,z2e,MVo,EVo,fQ,CVo,wVo,AVo,hb,Q2e,LVo,yVo,gQ,xVo,$Vo,kVo,ub,W2e,SVo,RVo,hQ,PVo,BVo,IVo,pb,U2e,NVo,qVo,uQ,jVo,DVo,GVo,_b,H2e,OVo,VVo,pQ,XVo,zVo,QVo,bb,J2e,WVo,UVo,_Q,HVo,JVo,YVo,vb,Y2e,KVo,ZVo,bQ,eXo,oXo,rXo,Fb,K2e,tXo,aXo,vQ,nXo,sXo,lXo,Tb,Z2e,iXo,dXo,FQ,mXo,cXo,fXo,Mb,ebe,gXo,hXo,TQ,uXo,pXo,_Xo,Eb,obe,bXo,vXo,MQ,FXo,TXo,MXo,Cb,rbe,EXo,CXo,EQ,wXo,AXo,LXo,wb,tbe,yXo,xXo,CQ,$Xo,kXo,SXo,Ab,RXo,abe,PXo,BXo,nbe,IXo,NXo,Lb,Seo,Ed,yb,sbe,Xx,qXo,lbe,jXo,Reo,Io,zx,DXo,Cd,GXo,wQ,OXo,VXo,AQ,XXo,zXo,QXo,Qx,WXo,ibe,UXo,HXo,JXo,vt,Wx,YXo,dbe,KXo,ZXo,wd,ezo,mbe,ozo,rzo,LQ,tzo,azo,nzo,xb,szo,oo,Ux,lzo,cbe,izo,dzo,Ka,mzo,fbe,czo,fzo,gbe,gzo,hzo,hbe,uzo,pzo,_zo,Q,$b,ube,bzo,vzo,yQ,Fzo,Tzo,Mzo,kb,pbe,Ezo,Czo,xQ,wzo,Azo,Lzo,Sb,_be,yzo,xzo,$Q,$zo,kzo,Szo,Rb,bbe,Rzo,Pzo,kQ,Bzo,Izo,Nzo,Pb,vbe,qzo,jzo,SQ,Dzo,Gzo,Ozo,Bb,Fbe,Vzo,Xzo,RQ,zzo,Qzo,Wzo,Ib,Tbe,Uzo,Hzo,PQ,Jzo,Yzo,Kzo,Nb,Mbe,Zzo,eQo,BQ,oQo,rQo,tQo,qb,Ebe,aQo,nQo,IQ,sQo,lQo,iQo,jb,Cbe,dQo,mQo,NQ,cQo,fQo,gQo,Db,wbe,hQo,uQo,qQ,pQo,_Qo,bQo,Gb,Abe,vQo,FQo,jQ,TQo,MQo,EQo,Ob,Lbe,CQo,wQo,DQ,AQo,LQo,yQo,Vb,ybe,xQo,$Qo,GQ,kQo,SQo,RQo,Xb,xbe,PQo,BQo,OQ,IQo,NQo,qQo,zb,$be,jQo,DQo,VQ,GQo,OQo,VQo,Qb,kbe,XQo,zQo,XQ,QQo,WQo,UQo,Wb,Sbe,HQo,JQo,zQ,YQo,KQo,ZQo,Ub,Rbe,eWo,oWo,QQ,rWo,tWo,aWo,Hb,Pbe,nWo,sWo,WQ,lWo,iWo,dWo,Jb,Bbe,mWo,cWo,UQ,fWo,gWo,hWo,Yb,Ibe,uWo,pWo,HQ,_Wo,bWo,vWo,Kb,Nbe,FWo,TWo,JQ,MWo,EWo,CWo,Zb,qbe,wWo,AWo,YQ,LWo,yWo,xWo,ev,jbe,$Wo,kWo,KQ,SWo,RWo,PWo,ov,Dbe,BWo,IWo,ZQ,NWo,qWo,jWo,rv,Gbe,DWo,GWo,eW,OWo,VWo,XWo,tv,Obe,zWo,QWo,oW,WWo,UWo,HWo,av,Vbe,JWo,YWo,rW,KWo,ZWo,eUo,nv,Xbe,oUo,rUo,tW,tUo,aUo,nUo,sv,zbe,sUo,lUo,aW,iUo,dUo,mUo,lv,Qbe,cUo,fUo,nW,gUo,hUo,uUo,iv,Wbe,pUo,_Uo,sW,bUo,vUo,FUo,dv,Ube,TUo,MUo,lW,EUo,CUo,wUo,mv,Hbe,AUo,LUo,iW,yUo,xUo,$Uo,cv,Jbe,kUo,SUo,dW,RUo,PUo,BUo,fv,Ybe,IUo,NUo,mW,qUo,jUo,DUo,gv,Kbe,GUo,OUo,cW,VUo,XUo,zUo,hv,Zbe,QUo,WUo,fW,UUo,HUo,JUo,uv,eve,YUo,KUo,gW,ZUo,eHo,oHo,pv,ove,rHo,tHo,hW,aHo,nHo,sHo,_v,rve,lHo,iHo,uW,dHo,mHo,cHo,bv,fHo,tve,gHo,hHo,ave,uHo,pHo,vv,Peo,Ad,Fv,nve,Hx,_Ho,sve,bHo,Beo,No,Jx,vHo,Ld,FHo,pW,THo,MHo,_W,EHo,CHo,wHo,Yx,AHo,lve,LHo,yHo,xHo,Ft,Kx,$Ho,ive,kHo,SHo,yd,RHo,dve,PHo,BHo,bW,IHo,NHo,qHo,Tv,jHo,ro,Zx,DHo,mve,GHo,OHo,Za,VHo,cve,XHo,zHo,fve,QHo,WHo,gve,UHo,HHo,JHo,J,Mv,hve,YHo,KHo,vW,ZHo,eJo,oJo,Ev,uve,rJo,tJo,FW,aJo,nJo,sJo,Cv,pve,lJo,iJo,TW,dJo,mJo,cJo,wv,_ve,fJo,gJo,MW,hJo,uJo,pJo,Av,bve,_Jo,bJo,EW,vJo,FJo,TJo,Lv,vve,MJo,EJo,CW,CJo,wJo,AJo,yv,Fve,LJo,yJo,wW,xJo,$Jo,kJo,xv,Tve,SJo,RJo,AW,PJo,BJo,IJo,$v,Mve,NJo,qJo,LW,jJo,DJo,GJo,kv,Eve,OJo,VJo,yW,XJo,zJo,QJo,Sv,Cve,WJo,UJo,xW,HJo,JJo,YJo,Rv,wve,KJo,ZJo,$W,eYo,oYo,rYo,Pv,Ave,tYo,aYo,kW,nYo,sYo,lYo,Bv,Lve,iYo,dYo,SW,mYo,cYo,fYo,Iv,yve,gYo,hYo,RW,uYo,pYo,_Yo,Nv,xve,bYo,vYo,PW,FYo,TYo,MYo,qv,$ve,EYo,CYo,BW,wYo,AYo,LYo,jv,kve,yYo,xYo,IW,$Yo,kYo,SYo,Dv,Sve,RYo,PYo,NW,BYo,IYo,NYo,Gv,Rve,qYo,jYo,qW,DYo,GYo,OYo,Ov,Pve,VYo,XYo,jW,zYo,QYo,WYo,Vv,Bve,UYo,HYo,DW,JYo,YYo,KYo,Xv,Ive,ZYo,eKo,GW,oKo,rKo,tKo,zv,Nve,aKo,nKo,OW,sKo,lKo,iKo,Qv,qve,dKo,mKo,VW,cKo,fKo,gKo,Wv,jve,hKo,uKo,XW,pKo,_Ko,bKo,Uv,Dve,vKo,FKo,zW,TKo,MKo,EKo,Hv,Gve,CKo,wKo,QW,AKo,LKo,yKo,Jv,Ove,xKo,$Ko,WW,kKo,SKo,RKo,Yv,Vve,PKo,BKo,UW,IKo,NKo,qKo,Kv,Xve,jKo,DKo,HW,GKo,OKo,VKo,Zv,zve,XKo,zKo,JW,QKo,WKo,UKo,eF,Qve,HKo,JKo,YW,YKo,KKo,ZKo,oF,Wve,eZo,oZo,KW,rZo,tZo,aZo,rF,Uve,nZo,sZo,Hve,lZo,iZo,dZo,tF,Jve,mZo,cZo,ZW,fZo,gZo,hZo,aF,Yve,uZo,pZo,eU,_Zo,bZo,vZo,nF,Kve,FZo,TZo,oU,MZo,EZo,CZo,sF,Zve,wZo,AZo,rU,LZo,yZo,xZo,lF,$Zo,eFe,kZo,SZo,oFe,RZo,PZo,iF,Ieo,xd,dF,rFe,e$,BZo,tFe,IZo,Neo,qo,o$,NZo,$d,qZo,tU,jZo,DZo,aU,GZo,OZo,VZo,r$,XZo,aFe,zZo,QZo,WZo,Tt,t$,UZo,nFe,HZo,JZo,kd,YZo,sFe,KZo,ZZo,nU,eer,oer,rer,mF,ter,to,a$,aer,lFe,ner,ser,en,ler,iFe,ier,der,dFe,mer,cer,mFe,fer,ger,her,fe,cF,cFe,uer,per,sU,_er,ber,ver,fF,fFe,Fer,Ter,lU,Mer,Eer,Cer,gF,gFe,wer,Aer,iU,Ler,yer,xer,hF,hFe,$er,ker,dU,Ser,Rer,Per,uF,uFe,Ber,Ier,mU,Ner,qer,jer,pF,pFe,Der,Ger,cU,Oer,Ver,Xer,_F,_Fe,zer,Qer,fU,Wer,Uer,Her,bF,bFe,Jer,Yer,gU,Ker,Zer,eor,vF,vFe,oor,ror,hU,tor,aor,nor,FF,FFe,sor,lor,uU,ior,dor,mor,TF,TFe,cor,gor,pU,hor,uor,por,MF,MFe,_or,bor,_U,vor,For,Tor,EF,EFe,Mor,Eor,bU,Cor,wor,Aor,CF,CFe,Lor,yor,vU,xor,$or,kor,wF,wFe,Sor,Ror,FU,Por,Bor,Ior,AF,AFe,Nor,qor,TU,jor,Dor,Gor,LF,LFe,Oor,Vor,MU,Xor,zor,Qor,yF,yFe,Wor,Uor,EU,Hor,Jor,Yor,xF,xFe,Kor,Zor,CU,err,orr,rrr,$F,$Fe,trr,arr,wU,nrr,srr,lrr,kF,irr,kFe,drr,mrr,SFe,crr,frr,SF,qeo,Sd,RF,RFe,n$,grr,PFe,hrr,jeo,jo,s$,urr,Rd,prr,AU,_rr,brr,LU,vrr,Frr,Trr,l$,Mrr,BFe,Err,Crr,wrr,Mt,i$,Arr,IFe,Lrr,yrr,Pd,xrr,NFe,$rr,krr,yU,Srr,Rrr,Prr,PF,Brr,ao,d$,Irr,qFe,Nrr,qrr,on,jrr,jFe,Drr,Grr,DFe,Orr,Vrr,GFe,Xrr,zrr,Qrr,B,BF,OFe,Wrr,Urr,xU,Hrr,Jrr,Yrr,IF,VFe,Krr,Zrr,$U,etr,otr,rtr,NF,XFe,ttr,atr,kU,ntr,str,ltr,qF,zFe,itr,dtr,SU,mtr,ctr,ftr,jF,QFe,gtr,htr,RU,utr,ptr,_tr,DF,WFe,btr,vtr,PU,Ftr,Ttr,Mtr,GF,UFe,Etr,Ctr,BU,wtr,Atr,Ltr,OF,HFe,ytr,xtr,IU,$tr,ktr,Str,VF,JFe,Rtr,Ptr,NU,Btr,Itr,Ntr,XF,YFe,qtr,jtr,qU,Dtr,Gtr,Otr,zF,KFe,Vtr,Xtr,jU,ztr,Qtr,Wtr,QF,ZFe,Utr,Htr,DU,Jtr,Ytr,Ktr,WF,eTe,Ztr,ear,GU,oar,rar,tar,UF,oTe,aar,nar,OU,sar,lar,iar,HF,rTe,dar,mar,VU,car,far,gar,JF,tTe,har,uar,XU,par,_ar,bar,YF,aTe,Far,Tar,zU,Mar,Ear,Car,KF,nTe,war,Aar,QU,Lar,yar,xar,ZF,sTe,$ar,kar,WU,Sar,Rar,Par,eT,lTe,Bar,Iar,UU,Nar,qar,jar,oT,iTe,Dar,Gar,HU,Oar,Var,Xar,rT,dTe,zar,Qar,JU,War,Uar,Har,tT,mTe,Jar,Yar,YU,Kar,Zar,enr,aT,cTe,onr,rnr,KU,tnr,anr,nnr,nT,fTe,snr,lnr,ZU,inr,dnr,mnr,sT,gTe,cnr,fnr,eH,gnr,hnr,unr,lT,hTe,pnr,_nr,oH,bnr,vnr,Fnr,iT,uTe,Tnr,Mnr,rH,Enr,Cnr,wnr,dT,pTe,Anr,Lnr,tH,ynr,xnr,$nr,mT,_Te,knr,Snr,aH,Rnr,Pnr,Bnr,cT,bTe,Inr,Nnr,nH,qnr,jnr,Dnr,fT,vTe,Gnr,Onr,sH,Vnr,Xnr,znr,gT,FTe,Qnr,Wnr,lH,Unr,Hnr,Jnr,hT,TTe,Ynr,Knr,iH,Znr,esr,osr,uT,MTe,rsr,tsr,dH,asr,nsr,ssr,pT,ETe,lsr,isr,mH,dsr,msr,csr,_T,CTe,fsr,gsr,cH,hsr,usr,psr,bT,wTe,_sr,bsr,fH,vsr,Fsr,Tsr,vT,ATe,Msr,Esr,gH,Csr,wsr,Asr,FT,LTe,Lsr,ysr,hH,xsr,$sr,ksr,TT,yTe,Ssr,Rsr,uH,Psr,Bsr,Isr,MT,xTe,Nsr,qsr,pH,jsr,Dsr,Gsr,ET,$Te,Osr,Vsr,_H,Xsr,zsr,Qsr,CT,kTe,Wsr,Usr,bH,Hsr,Jsr,Ysr,wT,STe,Ksr,Zsr,vH,elr,olr,rlr,AT,RTe,tlr,alr,FH,nlr,slr,llr,LT,PTe,ilr,dlr,TH,mlr,clr,flr,yT,BTe,glr,hlr,MH,ulr,plr,_lr,xT,ITe,blr,vlr,EH,Flr,Tlr,Mlr,$T,NTe,Elr,Clr,CH,wlr,Alr,Llr,kT,qTe,ylr,xlr,wH,$lr,klr,Slr,ST,jTe,Rlr,Plr,AH,Blr,Ilr,Nlr,RT,DTe,qlr,jlr,LH,Dlr,Glr,Olr,PT,GTe,Vlr,Xlr,yH,zlr,Qlr,Wlr,BT,OTe,Ulr,Hlr,xH,Jlr,Ylr,Klr,IT,Zlr,VTe,eir,oir,XTe,rir,tir,NT,Deo,Bd,qT,zTe,m$,air,QTe,nir,Geo,Do,c$,sir,Id,lir,$H,iir,dir,kH,mir,cir,fir,f$,gir,WTe,hir,uir,pir,Et,g$,_ir,UTe,bir,vir,Nd,Fir,HTe,Tir,Mir,SH,Eir,Cir,wir,jT,Air,no,h$,Lir,JTe,yir,xir,rn,$ir,YTe,kir,Sir,KTe,Rir,Pir,ZTe,Bir,Iir,Nir,Z,DT,eMe,qir,jir,RH,Dir,Gir,Oir,GT,oMe,Vir,Xir,PH,zir,Qir,Wir,OT,rMe,Uir,Hir,BH,Jir,Yir,Kir,VT,tMe,Zir,edr,IH,odr,rdr,tdr,XT,aMe,adr,ndr,NH,sdr,ldr,idr,zT,nMe,ddr,mdr,qH,cdr,fdr,gdr,QT,sMe,hdr,udr,jH,pdr,_dr,bdr,WT,lMe,vdr,Fdr,DH,Tdr,Mdr,Edr,UT,iMe,Cdr,wdr,GH,Adr,Ldr,ydr,HT,dMe,xdr,$dr,OH,kdr,Sdr,Rdr,JT,mMe,Pdr,Bdr,VH,Idr,Ndr,qdr,YT,cMe,jdr,Ddr,XH,Gdr,Odr,Vdr,KT,fMe,Xdr,zdr,zH,Qdr,Wdr,Udr,ZT,gMe,Hdr,Jdr,QH,Ydr,Kdr,Zdr,eM,hMe,emr,omr,WH,rmr,tmr,amr,oM,uMe,nmr,smr,UH,lmr,imr,dmr,rM,pMe,mmr,cmr,HH,fmr,gmr,hmr,tM,_Me,umr,pmr,JH,_mr,bmr,vmr,aM,bMe,Fmr,Tmr,YH,Mmr,Emr,Cmr,nM,vMe,wmr,Amr,KH,Lmr,ymr,xmr,sM,FMe,$mr,kmr,ZH,Smr,Rmr,Pmr,lM,TMe,Bmr,Imr,eJ,Nmr,qmr,jmr,iM,MMe,Dmr,Gmr,oJ,Omr,Vmr,Xmr,dM,EMe,zmr,Qmr,rJ,Wmr,Umr,Hmr,mM,CMe,Jmr,Ymr,tJ,Kmr,Zmr,ecr,cM,wMe,ocr,rcr,aJ,tcr,acr,ncr,fM,AMe,scr,lcr,nJ,icr,dcr,mcr,gM,LMe,ccr,fcr,sJ,gcr,hcr,ucr,hM,yMe,pcr,_cr,lJ,bcr,vcr,Fcr,uM,xMe,Tcr,Mcr,iJ,Ecr,Ccr,wcr,pM,$Me,Acr,Lcr,dJ,ycr,xcr,$cr,_M,kMe,kcr,Scr,mJ,Rcr,Pcr,Bcr,bM,Icr,SMe,Ncr,qcr,RMe,jcr,Dcr,vM,Oeo,qd,FM,PMe,u$,Gcr,BMe,Ocr,Veo,Go,p$,Vcr,jd,Xcr,cJ,zcr,Qcr,fJ,Wcr,Ucr,Hcr,_$,Jcr,IMe,Ycr,Kcr,Zcr,Ct,b$,efr,NMe,ofr,rfr,Dd,tfr,qMe,afr,nfr,gJ,sfr,lfr,ifr,TM,dfr,so,v$,mfr,jMe,cfr,ffr,tn,gfr,DMe,hfr,ufr,GMe,pfr,_fr,OMe,bfr,vfr,Ffr,Ue,MM,VMe,Tfr,Mfr,hJ,Efr,Cfr,wfr,EM,XMe,Afr,Lfr,uJ,yfr,xfr,$fr,CM,zMe,kfr,Sfr,pJ,Rfr,Pfr,Bfr,wM,QMe,Ifr,Nfr,_J,qfr,jfr,Dfr,AM,WMe,Gfr,Ofr,bJ,Vfr,Xfr,zfr,LM,UMe,Qfr,Wfr,vJ,Ufr,Hfr,Jfr,yM,HMe,Yfr,Kfr,FJ,Zfr,egr,ogr,xM,rgr,JMe,tgr,agr,YMe,ngr,sgr,$M,Xeo,Gd,kM,KMe,F$,lgr,ZMe,igr,zeo,Oo,T$,dgr,Od,mgr,TJ,cgr,fgr,MJ,ggr,hgr,ugr,M$,pgr,eEe,_gr,bgr,vgr,wt,E$,Fgr,oEe,Tgr,Mgr,Vd,Egr,rEe,Cgr,wgr,EJ,Agr,Lgr,ygr,SM,xgr,lo,C$,$gr,tEe,kgr,Sgr,an,Rgr,aEe,Pgr,Bgr,nEe,Igr,Ngr,sEe,qgr,jgr,Dgr,H,RM,lEe,Ggr,Ogr,CJ,Vgr,Xgr,zgr,PM,iEe,Qgr,Wgr,wJ,Ugr,Hgr,Jgr,BM,dEe,Ygr,Kgr,AJ,Zgr,ehr,ohr,IM,mEe,rhr,thr,LJ,ahr,nhr,shr,NM,cEe,lhr,ihr,yJ,dhr,mhr,chr,qM,fEe,fhr,ghr,xJ,hhr,uhr,phr,jM,gEe,_hr,bhr,$J,vhr,Fhr,Thr,DM,hEe,Mhr,Ehr,kJ,Chr,whr,Ahr,GM,uEe,Lhr,yhr,SJ,xhr,$hr,khr,OM,pEe,Shr,Rhr,RJ,Phr,Bhr,Ihr,VM,_Ee,Nhr,qhr,PJ,jhr,Dhr,Ghr,XM,bEe,Ohr,Vhr,BJ,Xhr,zhr,Qhr,zM,vEe,Whr,Uhr,IJ,Hhr,Jhr,Yhr,QM,FEe,Khr,Zhr,NJ,eur,our,rur,WM,TEe,tur,aur,qJ,nur,sur,lur,UM,MEe,iur,dur,jJ,mur,cur,fur,HM,EEe,gur,hur,DJ,uur,pur,_ur,JM,CEe,bur,vur,GJ,Fur,Tur,Mur,YM,wEe,Eur,Cur,OJ,wur,Aur,Lur,KM,AEe,yur,xur,VJ,$ur,kur,Sur,ZM,LEe,Rur,Pur,XJ,Bur,Iur,Nur,eE,yEe,qur,jur,zJ,Dur,Gur,Our,oE,xEe,Vur,Xur,QJ,zur,Qur,Wur,rE,$Ee,Uur,Hur,WJ,Jur,Yur,Kur,tE,kEe,Zur,epr,UJ,opr,rpr,tpr,aE,SEe,apr,npr,HJ,spr,lpr,ipr,nE,REe,dpr,mpr,JJ,cpr,fpr,gpr,sE,PEe,hpr,upr,YJ,ppr,_pr,bpr,lE,BEe,vpr,Fpr,KJ,Tpr,Mpr,Epr,iE,IEe,Cpr,wpr,ZJ,Apr,Lpr,ypr,dE,NEe,xpr,$pr,eY,kpr,Spr,Rpr,mE,qEe,Ppr,Bpr,oY,Ipr,Npr,qpr,cE,jEe,jpr,Dpr,rY,Gpr,Opr,Vpr,fE,DEe,Xpr,zpr,tY,Qpr,Wpr,Upr,gE,GEe,Hpr,Jpr,aY,Ypr,Kpr,Zpr,hE,OEe,e_r,o_r,nY,r_r,t_r,a_r,uE,VEe,n_r,s_r,sY,l_r,i_r,d_r,pE,XEe,m_r,c_r,lY,f_r,g_r,h_r,_E,zEe,u_r,p_r,iY,__r,b_r,v_r,bE,QEe,F_r,T_r,dY,M_r,E_r,C_r,vE,w_r,WEe,A_r,L_r,UEe,y_r,x_r,FE,Qeo,Xd,TE,HEe,w$,$_r,JEe,k_r,Weo,Vo,A$,S_r,zd,R_r,mY,P_r,B_r,cY,I_r,N_r,q_r,L$,j_r,YEe,D_r,G_r,O_r,At,y$,V_r,KEe,X_r,z_r,Qd,Q_r,ZEe,W_r,U_r,fY,H_r,J_r,Y_r,ME,K_r,io,x$,Z_r,e4e,e1r,o1r,nn,r1r,o4e,t1r,a1r,r4e,n1r,s1r,t4e,l1r,i1r,d1r,V,EE,a4e,m1r,c1r,gY,f1r,g1r,h1r,CE,n4e,u1r,p1r,hY,_1r,b1r,v1r,wE,s4e,F1r,T1r,uY,M1r,E1r,C1r,AE,l4e,w1r,A1r,pY,L1r,y1r,x1r,LE,i4e,$1r,k1r,_Y,S1r,R1r,P1r,yE,d4e,B1r,I1r,bY,N1r,q1r,j1r,xE,m4e,D1r,G1r,vY,O1r,V1r,X1r,$E,c4e,z1r,Q1r,FY,W1r,U1r,H1r,kE,f4e,J1r,Y1r,TY,K1r,Z1r,e2r,SE,g4e,o2r,r2r,MY,t2r,a2r,n2r,RE,h4e,s2r,l2r,EY,i2r,d2r,m2r,PE,u4e,c2r,f2r,CY,g2r,h2r,u2r,BE,p4e,p2r,_2r,wY,b2r,v2r,F2r,IE,_4e,T2r,M2r,AY,E2r,C2r,w2r,NE,b4e,A2r,L2r,LY,y2r,x2r,$2r,qE,v4e,k2r,S2r,yY,R2r,P2r,B2r,jE,F4e,I2r,N2r,xY,q2r,j2r,D2r,DE,T4e,G2r,O2r,$Y,V2r,X2r,z2r,GE,M4e,Q2r,W2r,kY,U2r,H2r,J2r,OE,E4e,Y2r,K2r,SY,Z2r,ebr,obr,VE,C4e,rbr,tbr,RY,abr,nbr,sbr,XE,w4e,lbr,ibr,PY,dbr,mbr,cbr,zE,A4e,fbr,gbr,BY,hbr,ubr,pbr,QE,L4e,_br,bbr,IY,vbr,Fbr,Tbr,WE,y4e,Mbr,Ebr,NY,Cbr,wbr,Abr,UE,x4e,Lbr,ybr,qY,xbr,$br,kbr,HE,$4e,Sbr,Rbr,jY,Pbr,Bbr,Ibr,JE,k4e,Nbr,qbr,DY,jbr,Dbr,Gbr,YE,S4e,Obr,Vbr,GY,Xbr,zbr,Qbr,KE,R4e,Wbr,Ubr,OY,Hbr,Jbr,Ybr,ZE,P4e,Kbr,Zbr,VY,evr,ovr,rvr,e4,B4e,tvr,avr,XY,nvr,svr,lvr,o4,I4e,ivr,dvr,zY,mvr,cvr,fvr,r4,N4e,gvr,hvr,QY,uvr,pvr,_vr,t4,q4e,bvr,vvr,WY,Fvr,Tvr,Mvr,a4,j4e,Evr,Cvr,UY,wvr,Avr,Lvr,n4,D4e,yvr,xvr,HY,$vr,kvr,Svr,s4,G4e,Rvr,Pvr,JY,Bvr,Ivr,Nvr,l4,O4e,qvr,jvr,YY,Dvr,Gvr,Ovr,i4,V4e,Vvr,Xvr,KY,zvr,Qvr,Wvr,d4,X4e,Uvr,Hvr,ZY,Jvr,Yvr,Kvr,m4,z4e,Zvr,eFr,eK,oFr,rFr,tFr,c4,Q4e,aFr,nFr,oK,sFr,lFr,iFr,f4,W4e,dFr,mFr,rK,cFr,fFr,gFr,g4,U4e,hFr,uFr,tK,pFr,_Fr,bFr,h4,H4e,vFr,FFr,aK,TFr,MFr,EFr,u4,CFr,J4e,wFr,AFr,Y4e,LFr,yFr,p4,Ueo,Wd,_4,K4e,$$,xFr,Z4e,$Fr,Heo,Xo,k$,kFr,Ud,SFr,nK,RFr,PFr,sK,BFr,IFr,NFr,S$,qFr,eCe,jFr,DFr,GFr,Lt,R$,OFr,oCe,VFr,XFr,Hd,zFr,rCe,QFr,WFr,lK,UFr,HFr,JFr,b4,YFr,mo,P$,KFr,tCe,ZFr,eTr,sn,oTr,aCe,rTr,tTr,nCe,aTr,nTr,sCe,sTr,lTr,iTr,lCe,v4,iCe,dTr,mTr,iK,cTr,fTr,gTr,F4,hTr,dCe,uTr,pTr,mCe,_Tr,bTr,T4,Jeo,Jd,M4,cCe,B$,vTr,fCe,FTr,Yeo,zo,I$,TTr,Yd,MTr,dK,ETr,CTr,mK,wTr,ATr,LTr,N$,yTr,gCe,xTr,$Tr,kTr,yt,q$,STr,hCe,RTr,PTr,Kd,BTr,uCe,ITr,NTr,cK,qTr,jTr,DTr,E4,GTr,co,j$,OTr,pCe,VTr,XTr,ln,zTr,_Ce,QTr,WTr,bCe,UTr,HTr,vCe,JTr,YTr,KTr,Zd,C4,FCe,ZTr,eMr,fK,oMr,rMr,tMr,w4,TCe,aMr,nMr,gK,sMr,lMr,iMr,A4,MCe,dMr,mMr,hK,cMr,fMr,gMr,L4,hMr,ECe,uMr,pMr,CCe,_Mr,bMr,y4,Keo,em,x4,wCe,D$,vMr,ACe,FMr,Zeo,Qo,G$,TMr,om,MMr,uK,EMr,CMr,pK,wMr,AMr,LMr,O$,yMr,LCe,xMr,$Mr,kMr,xt,V$,SMr,yCe,RMr,PMr,rm,BMr,xCe,IMr,NMr,_K,qMr,jMr,DMr,$4,GMr,fo,X$,OMr,$Ce,VMr,XMr,dn,zMr,kCe,QMr,WMr,SCe,UMr,HMr,RCe,JMr,YMr,KMr,be,k4,PCe,ZMr,eEr,bK,oEr,rEr,tEr,S4,BCe,aEr,nEr,vK,sEr,lEr,iEr,R4,ICe,dEr,mEr,FK,cEr,fEr,gEr,P4,NCe,hEr,uEr,TK,pEr,_Er,bEr,bl,qCe,vEr,FEr,MK,TEr,MEr,EK,EEr,CEr,wEr,B4,jCe,AEr,LEr,CK,yEr,xEr,$Er,vl,DCe,kEr,SEr,wK,REr,PEr,AK,BEr,IEr,NEr,I4,GCe,qEr,jEr,LK,DEr,GEr,OEr,$t,OCe,VEr,XEr,yK,zEr,QEr,xK,WEr,UEr,$K,HEr,JEr,YEr,N4,VCe,KEr,ZEr,kK,e4r,o4r,r4r,q4,XCe,t4r,a4r,SK,n4r,s4r,l4r,j4,zCe,i4r,d4r,RK,m4r,c4r,f4r,D4,QCe,g4r,h4r,PK,u4r,p4r,_4r,G4,WCe,b4r,v4r,BK,F4r,T4r,M4r,O4,UCe,E4r,C4r,IK,w4r,A4r,L4r,V4,HCe,y4r,x4r,NK,$4r,k4r,S4r,X4,JCe,R4r,P4r,qK,B4r,I4r,N4r,z4,YCe,q4r,j4r,jK,D4r,G4r,O4r,Q4,V4r,KCe,X4r,z4r,ZCe,Q4r,W4r,W4,eoo,tm,U4,e3e,z$,U4r,o3e,H4r,ooo,Wo,Q$,J4r,am,Y4r,DK,K4r,Z4r,GK,eCr,oCr,rCr,W$,tCr,r3e,aCr,nCr,sCr,kt,U$,lCr,t3e,iCr,dCr,nm,mCr,a3e,cCr,fCr,OK,gCr,hCr,uCr,H4,pCr,go,H$,_Cr,n3e,bCr,vCr,mn,FCr,s3e,TCr,MCr,l3e,ECr,CCr,i3e,wCr,ACr,LCr,d3e,J4,m3e,yCr,xCr,VK,$Cr,kCr,SCr,Y4,RCr,c3e,PCr,BCr,f3e,ICr,NCr,K4,roo,sm,Z4,g3e,J$,qCr,h3e,jCr,too,Uo,Y$,DCr,lm,GCr,XK,OCr,VCr,zK,XCr,zCr,QCr,K$,WCr,u3e,UCr,HCr,JCr,St,Z$,YCr,p3e,KCr,ZCr,im,e3r,_3e,o3r,r3r,QK,t3r,a3r,n3r,eC,s3r,ho,ek,l3r,b3e,i3r,d3r,cn,m3r,v3e,c3r,f3r,F3e,g3r,h3r,T3e,u3r,p3r,_3r,M3e,oC,E3e,b3r,v3r,WK,F3r,T3r,M3r,rC,E3r,C3e,C3r,w3r,w3e,A3r,L3r,tC,aoo,dm,aC,A3e,ok,y3r,L3e,x3r,noo,Ho,rk,$3r,mm,k3r,UK,S3r,R3r,HK,P3r,B3r,I3r,tk,N3r,y3e,q3r,j3r,D3r,Rt,ak,G3r,x3e,O3r,V3r,cm,X3r,$3e,z3r,Q3r,JK,W3r,U3r,H3r,nC,J3r,uo,nk,Y3r,k3e,K3r,Z3r,fn,e5r,S3e,o5r,r5r,R3e,t5r,a5r,P3e,n5r,s5r,l5r,B3e,sC,I3e,i5r,d5r,YK,m5r,c5r,f5r,lC,g5r,N3e,h5r,u5r,q3e,p5r,_5r,iC,soo,fm,dC,j3e,sk,b5r,D3e,v5r,loo,Jo,lk,F5r,gm,T5r,KK,M5r,E5r,ZK,C5r,w5r,A5r,ik,L5r,G3e,y5r,x5r,$5r,Pt,dk,k5r,O3e,S5r,R5r,hm,P5r,V3e,B5r,I5r,eZ,N5r,q5r,j5r,mC,D5r,po,mk,G5r,X3e,O5r,V5r,gn,X5r,z3e,z5r,Q5r,Q3e,W5r,U5r,W3e,H5r,J5r,Y5r,Pe,cC,U3e,K5r,Z5r,oZ,e0r,o0r,r0r,fC,H3e,t0r,a0r,rZ,n0r,s0r,l0r,gC,J3e,i0r,d0r,tZ,m0r,c0r,f0r,hC,Y3e,g0r,h0r,aZ,u0r,p0r,_0r,uC,K3e,b0r,v0r,nZ,F0r,T0r,M0r,pC,Z3e,E0r,C0r,sZ,w0r,A0r,L0r,_C,e5e,y0r,x0r,lZ,$0r,k0r,S0r,bC,o5e,R0r,P0r,iZ,B0r,I0r,N0r,vC,r5e,q0r,j0r,dZ,D0r,G0r,O0r,FC,V0r,t5e,X0r,z0r,a5e,Q0r,W0r,TC,ioo,um,MC,n5e,ck,U0r,s5e,H0r,doo,Yo,fk,J0r,pm,Y0r,mZ,K0r,Z0r,cZ,ewr,owr,rwr,gk,twr,l5e,awr,nwr,swr,Bt,hk,lwr,i5e,iwr,dwr,_m,mwr,d5e,cwr,fwr,fZ,gwr,hwr,uwr,EC,pwr,_o,uk,_wr,m5e,bwr,vwr,hn,Fwr,c5e,Twr,Mwr,f5e,Ewr,Cwr,g5e,wwr,Awr,Lwr,ct,CC,h5e,ywr,xwr,gZ,$wr,kwr,Swr,wC,u5e,Rwr,Pwr,hZ,Bwr,Iwr,Nwr,AC,p5e,qwr,jwr,uZ,Dwr,Gwr,Owr,LC,_5e,Vwr,Xwr,pZ,zwr,Qwr,Wwr,yC,b5e,Uwr,Hwr,_Z,Jwr,Ywr,Kwr,xC,Zwr,v5e,eAr,oAr,F5e,rAr,tAr,$C,moo,bm,kC,T5e,pk,aAr,M5e,nAr,coo,Ko,_k,sAr,vm,lAr,bZ,iAr,dAr,vZ,mAr,cAr,fAr,bk,gAr,E5e,hAr,uAr,pAr,It,vk,_Ar,C5e,bAr,vAr,Fm,FAr,w5e,TAr,MAr,FZ,EAr,CAr,wAr,SC,AAr,bo,Fk,LAr,A5e,yAr,xAr,un,$Ar,L5e,kAr,SAr,y5e,RAr,PAr,x5e,BAr,IAr,NAr,Le,RC,$5e,qAr,jAr,TZ,DAr,GAr,OAr,PC,k5e,VAr,XAr,MZ,zAr,QAr,WAr,BC,S5e,UAr,HAr,EZ,JAr,YAr,KAr,IC,R5e,ZAr,e6r,CZ,o6r,r6r,t6r,NC,P5e,a6r,n6r,wZ,s6r,l6r,i6r,qC,B5e,d6r,m6r,AZ,c6r,f6r,g6r,jC,I5e,h6r,u6r,LZ,p6r,_6r,b6r,DC,N5e,v6r,F6r,yZ,T6r,M6r,E6r,GC,q5e,C6r,w6r,xZ,A6r,L6r,y6r,OC,j5e,x6r,$6r,$Z,k6r,S6r,R6r,VC,P6r,D5e,B6r,I6r,G5e,N6r,q6r,XC,foo,Tm,zC,O5e,Tk,j6r,V5e,D6r,goo,Zo,Mk,G6r,Mm,O6r,kZ,V6r,X6r,SZ,z6r,Q6r,W6r,Ek,U6r,X5e,H6r,J6r,Y6r,Nt,Ck,K6r,z5e,Z6r,e7r,Em,o7r,Q5e,r7r,t7r,RZ,a7r,n7r,s7r,QC,l7r,vo,wk,i7r,W5e,d7r,m7r,pn,c7r,U5e,f7r,g7r,H5e,h7r,u7r,J5e,p7r,_7r,b7r,Cm,WC,Y5e,v7r,F7r,PZ,T7r,M7r,E7r,UC,K5e,C7r,w7r,BZ,A7r,L7r,y7r,HC,Z5e,x7r,$7r,IZ,k7r,S7r,R7r,JC,P7r,e0e,B7r,I7r,o0e,N7r,q7r,YC,hoo,wm,KC,r0e,Ak,j7r,t0e,D7r,uoo,er,Lk,G7r,Am,O7r,NZ,V7r,X7r,qZ,z7r,Q7r,W7r,yk,U7r,a0e,H7r,J7r,Y7r,qt,xk,K7r,n0e,Z7r,eLr,Lm,oLr,s0e,rLr,tLr,jZ,aLr,nLr,sLr,ZC,lLr,Fo,$k,iLr,l0e,dLr,mLr,_n,cLr,i0e,fLr,gLr,d0e,hLr,uLr,m0e,pLr,_Lr,bLr,ft,e3,c0e,vLr,FLr,DZ,TLr,MLr,ELr,o3,f0e,CLr,wLr,GZ,ALr,LLr,yLr,r3,g0e,xLr,$Lr,OZ,kLr,SLr,RLr,t3,h0e,PLr,BLr,VZ,ILr,NLr,qLr,a3,u0e,jLr,DLr,XZ,GLr,OLr,VLr,n3,XLr,p0e,zLr,QLr,_0e,WLr,ULr,s3,poo,ym,l3,b0e,kk,HLr,v0e,JLr,_oo,or,Sk,YLr,xm,KLr,zZ,ZLr,eyr,QZ,oyr,ryr,tyr,Rk,ayr,F0e,nyr,syr,lyr,jt,Pk,iyr,T0e,dyr,myr,$m,cyr,M0e,fyr,gyr,WZ,hyr,uyr,pyr,i3,_yr,To,Bk,byr,E0e,vyr,Fyr,bn,Tyr,C0e,Myr,Eyr,w0e,Cyr,wyr,A0e,Ayr,Lyr,yyr,vn,d3,L0e,xyr,$yr,UZ,kyr,Syr,Ryr,m3,y0e,Pyr,Byr,HZ,Iyr,Nyr,qyr,c3,x0e,jyr,Dyr,JZ,Gyr,Oyr,Vyr,f3,$0e,Xyr,zyr,YZ,Qyr,Wyr,Uyr,g3,Hyr,k0e,Jyr,Yyr,S0e,Kyr,Zyr,h3,boo,km,u3,R0e,Ik,e8r,P0e,o8r,voo,rr,Nk,r8r,Sm,t8r,KZ,a8r,n8r,ZZ,s8r,l8r,i8r,qk,d8r,B0e,m8r,c8r,f8r,Dt,jk,g8r,I0e,h8r,u8r,Rm,p8r,N0e,_8r,b8r,eee,v8r,F8r,T8r,p3,M8r,Mo,Dk,E8r,q0e,C8r,w8r,Fn,A8r,j0e,L8r,y8r,D0e,x8r,$8r,G0e,k8r,S8r,R8r,Tn,_3,O0e,P8r,B8r,oee,I8r,N8r,q8r,b3,V0e,j8r,D8r,ree,G8r,O8r,V8r,v3,X0e,X8r,z8r,tee,Q8r,W8r,U8r,F3,z0e,H8r,J8r,aee,Y8r,K8r,Z8r,T3,e9r,Q0e,o9r,r9r,W0e,t9r,a9r,M3,Foo,Pm,E3,U0e,Gk,n9r,H0e,s9r,Too,tr,Ok,l9r,Bm,i9r,nee,d9r,m9r,see,c9r,f9r,g9r,Vk,h9r,J0e,u9r,p9r,_9r,Gt,Xk,b9r,Y0e,v9r,F9r,Im,T9r,K0e,M9r,E9r,lee,C9r,w9r,A9r,C3,L9r,Eo,zk,y9r,Z0e,x9r,$9r,Mn,k9r,ewe,S9r,R9r,owe,P9r,B9r,rwe,I9r,N9r,q9r,twe,w3,awe,j9r,D9r,iee,G9r,O9r,V9r,A3,X9r,nwe,z9r,Q9r,swe,W9r,U9r,L3,Moo,Nm,y3,lwe,Qk,H9r,iwe,J9r,Eoo,ar,Wk,Y9r,qm,K9r,dee,Z9r,exr,mee,oxr,rxr,txr,Uk,axr,dwe,nxr,sxr,lxr,Ot,Hk,ixr,mwe,dxr,mxr,jm,cxr,cwe,fxr,gxr,cee,hxr,uxr,pxr,x3,_xr,Co,Jk,bxr,fwe,vxr,Fxr,En,Txr,gwe,Mxr,Exr,hwe,Cxr,wxr,uwe,Axr,Lxr,yxr,gt,$3,pwe,xxr,$xr,fee,kxr,Sxr,Rxr,k3,_we,Pxr,Bxr,gee,Ixr,Nxr,qxr,S3,bwe,jxr,Dxr,hee,Gxr,Oxr,Vxr,R3,vwe,Xxr,zxr,uee,Qxr,Wxr,Uxr,P3,Fwe,Hxr,Jxr,pee,Yxr,Kxr,Zxr,B3,e$r,Twe,o$r,r$r,Mwe,t$r,a$r,I3,Coo,Dm,N3,Ewe,Yk,n$r,Cwe,s$r,woo,nr,Kk,l$r,Gm,i$r,_ee,d$r,m$r,bee,c$r,f$r,g$r,Zk,h$r,wwe,u$r,p$r,_$r,Vt,eS,b$r,Awe,v$r,F$r,Om,T$r,Lwe,M$r,E$r,vee,C$r,w$r,A$r,q3,L$r,wo,oS,y$r,ywe,x$r,$$r,Cn,k$r,xwe,S$r,R$r,$we,P$r,B$r,kwe,I$r,N$r,q$r,Swe,j3,Rwe,j$r,D$r,Fee,G$r,O$r,V$r,D3,X$r,Pwe,z$r,Q$r,Bwe,W$r,U$r,G3,Aoo,Vm,O3,Iwe,rS,H$r,Nwe,J$r,Loo,sr,tS,Y$r,Xm,K$r,Tee,Z$r,ekr,Mee,okr,rkr,tkr,aS,akr,qwe,nkr,skr,lkr,Xt,nS,ikr,jwe,dkr,mkr,zm,ckr,Dwe,fkr,gkr,Eee,hkr,ukr,pkr,V3,_kr,Ir,sS,bkr,Gwe,vkr,Fkr,wn,Tkr,Owe,Mkr,Ekr,Vwe,Ckr,wkr,Xwe,Akr,Lkr,ykr,I,X3,zwe,xkr,$kr,Cee,kkr,Skr,Rkr,z3,Qwe,Pkr,Bkr,wee,Ikr,Nkr,qkr,Q3,Wwe,jkr,Dkr,Aee,Gkr,Okr,Vkr,W3,Uwe,Xkr,zkr,Lee,Qkr,Wkr,Ukr,U3,Hwe,Hkr,Jkr,yee,Ykr,Kkr,Zkr,H3,Jwe,eSr,oSr,xee,rSr,tSr,aSr,J3,Ywe,nSr,sSr,$ee,lSr,iSr,dSr,Y3,Kwe,mSr,cSr,kee,fSr,gSr,hSr,K3,Zwe,uSr,pSr,See,_Sr,bSr,vSr,Z3,eAe,FSr,TSr,Ree,MSr,ESr,CSr,e5,oAe,wSr,ASr,Pee,LSr,ySr,xSr,o5,rAe,$Sr,kSr,Bee,SSr,RSr,PSr,r5,tAe,BSr,ISr,Iee,NSr,qSr,jSr,t5,aAe,DSr,GSr,Nee,OSr,VSr,XSr,a5,nAe,zSr,QSr,qee,WSr,USr,HSr,n5,sAe,JSr,YSr,jee,KSr,ZSr,eRr,s5,lAe,oRr,rRr,Dee,tRr,aRr,nRr,l5,iAe,sRr,lRr,Gee,iRr,dRr,mRr,Fl,dAe,cRr,fRr,Oee,gRr,hRr,Vee,uRr,pRr,_Rr,i5,mAe,bRr,vRr,Xee,FRr,TRr,MRr,d5,cAe,ERr,CRr,zee,wRr,ARr,LRr,m5,fAe,yRr,xRr,Qee,$Rr,kRr,SRr,c5,gAe,RRr,PRr,Wee,BRr,IRr,NRr,f5,hAe,qRr,jRr,Uee,DRr,GRr,ORr,g5,uAe,VRr,XRr,Hee,zRr,QRr,WRr,h5,pAe,URr,HRr,Jee,JRr,YRr,KRr,u5,_Ae,ZRr,ePr,Yee,oPr,rPr,tPr,p5,bAe,aPr,nPr,Kee,sPr,lPr,iPr,_5,vAe,dPr,mPr,Zee,cPr,fPr,gPr,b5,FAe,hPr,uPr,eoe,pPr,_Pr,bPr,v5,TAe,vPr,FPr,ooe,TPr,MPr,EPr,F5,MAe,CPr,wPr,roe,APr,LPr,yPr,T5,EAe,xPr,$Pr,toe,kPr,SPr,RPr,M5,CAe,PPr,BPr,aoe,IPr,NPr,qPr,E5,wAe,jPr,DPr,noe,GPr,OPr,VPr,C5,AAe,XPr,zPr,soe,QPr,WPr,UPr,w5,LAe,HPr,JPr,loe,YPr,KPr,ZPr,A5,yAe,eBr,oBr,ioe,rBr,tBr,aBr,L5,xAe,nBr,sBr,doe,lBr,iBr,dBr,y5,$Ae,mBr,cBr,moe,fBr,gBr,hBr,x5,kAe,uBr,pBr,coe,_Br,bBr,vBr,$5,SAe,FBr,TBr,foe,MBr,EBr,CBr,k5,RAe,wBr,ABr,goe,LBr,yBr,xBr,S5,PAe,$Br,kBr,hoe,SBr,RBr,PBr,R5,BAe,BBr,IBr,uoe,NBr,qBr,jBr,P5,IAe,DBr,GBr,poe,OBr,VBr,XBr,B5,NAe,zBr,QBr,_oe,WBr,UBr,HBr,I5,qAe,JBr,YBr,boe,KBr,ZBr,eIr,N5,jAe,oIr,rIr,voe,tIr,aIr,nIr,q5,DAe,sIr,lIr,Foe,iIr,dIr,mIr,j5,GAe,cIr,fIr,Toe,gIr,hIr,uIr,D5,OAe,pIr,_Ir,Moe,bIr,vIr,FIr,G5,VAe,TIr,MIr,Eoe,EIr,CIr,wIr,O5,XAe,AIr,LIr,Coe,yIr,xIr,$Ir,V5,zAe,kIr,SIr,woe,RIr,PIr,BIr,X5,yoo,Qm,z5,QAe,lS,IIr,WAe,NIr,xoo,lr,iS,qIr,Wm,jIr,Aoe,DIr,GIr,Loe,OIr,VIr,XIr,dS,zIr,UAe,QIr,WIr,UIr,zt,mS,HIr,HAe,JIr,YIr,Um,KIr,JAe,ZIr,eNr,yoe,oNr,rNr,tNr,Q5,aNr,Nr,cS,nNr,YAe,sNr,lNr,An,iNr,KAe,dNr,mNr,ZAe,cNr,fNr,e6e,gNr,hNr,uNr,le,W5,o6e,pNr,_Nr,xoe,bNr,vNr,FNr,U5,r6e,TNr,MNr,$oe,ENr,CNr,wNr,H5,t6e,ANr,LNr,koe,yNr,xNr,$Nr,J5,a6e,kNr,SNr,Soe,RNr,PNr,BNr,Y5,n6e,INr,NNr,Roe,qNr,jNr,DNr,K5,s6e,GNr,ONr,Poe,VNr,XNr,zNr,Z5,l6e,QNr,WNr,Boe,UNr,HNr,JNr,e0,i6e,YNr,KNr,Ioe,ZNr,eqr,oqr,o0,d6e,rqr,tqr,Noe,aqr,nqr,sqr,r0,m6e,lqr,iqr,qoe,dqr,mqr,cqr,t0,c6e,fqr,gqr,joe,hqr,uqr,pqr,a0,f6e,_qr,bqr,Doe,vqr,Fqr,Tqr,n0,g6e,Mqr,Eqr,Goe,Cqr,wqr,Aqr,s0,h6e,Lqr,yqr,Ooe,xqr,$qr,kqr,l0,u6e,Sqr,Rqr,Voe,Pqr,Bqr,Iqr,i0,p6e,Nqr,qqr,Xoe,jqr,Dqr,Gqr,d0,_6e,Oqr,Vqr,zoe,Xqr,zqr,Qqr,m0,b6e,Wqr,Uqr,Qoe,Hqr,Jqr,Yqr,c0,v6e,Kqr,Zqr,Woe,ejr,ojr,rjr,f0,F6e,tjr,ajr,Uoe,njr,sjr,ljr,g0,T6e,ijr,djr,Hoe,mjr,cjr,fjr,h0,M6e,gjr,hjr,Joe,ujr,pjr,_jr,u0,E6e,bjr,vjr,Yoe,Fjr,Tjr,Mjr,p0,$oo,Hm,_0,C6e,fS,Ejr,w6e,Cjr,koo,ir,gS,wjr,Jm,Ajr,Koe,Ljr,yjr,Zoe,xjr,$jr,kjr,hS,Sjr,A6e,Rjr,Pjr,Bjr,Qt,uS,Ijr,L6e,Njr,qjr,Ym,jjr,y6e,Djr,Gjr,ere,Ojr,Vjr,Xjr,b0,zjr,qr,pS,Qjr,x6e,Wjr,Ujr,Ln,Hjr,$6e,Jjr,Yjr,k6e,Kjr,Zjr,S6e,eDr,oDr,rDr,Me,v0,R6e,tDr,aDr,ore,nDr,sDr,lDr,F0,P6e,iDr,dDr,rre,mDr,cDr,fDr,T0,B6e,gDr,hDr,tre,uDr,pDr,_Dr,M0,I6e,bDr,vDr,are,FDr,TDr,MDr,E0,N6e,EDr,CDr,nre,wDr,ADr,LDr,C0,q6e,yDr,xDr,sre,$Dr,kDr,SDr,w0,j6e,RDr,PDr,lre,BDr,IDr,NDr,A0,D6e,qDr,jDr,ire,DDr,GDr,ODr,L0,G6e,VDr,XDr,dre,zDr,QDr,WDr,y0,O6e,UDr,HDr,mre,JDr,YDr,KDr,x0,V6e,ZDr,eGr,cre,oGr,rGr,tGr,$0,X6e,aGr,nGr,fre,sGr,lGr,iGr,k0,z6e,dGr,mGr,gre,cGr,fGr,gGr,S0,Q6e,hGr,uGr,hre,pGr,_Gr,bGr,R0,Soo,Km,P0,W6e,_S,vGr,U6e,FGr,Roo,dr,bS,TGr,Zm,MGr,ure,EGr,CGr,pre,wGr,AGr,LGr,vS,yGr,H6e,xGr,$Gr,kGr,Wt,FS,SGr,J6e,RGr,PGr,ec,BGr,Y6e,IGr,NGr,_re,qGr,jGr,DGr,B0,GGr,jr,TS,OGr,K6e,VGr,XGr,yn,zGr,Z6e,QGr,WGr,e7e,UGr,HGr,o7e,JGr,YGr,KGr,Be,I0,r7e,ZGr,eOr,bre,oOr,rOr,tOr,N0,t7e,aOr,nOr,vre,sOr,lOr,iOr,Tl,a7e,dOr,mOr,Fre,cOr,fOr,Tre,gOr,hOr,uOr,q0,n7e,pOr,_Or,Mre,bOr,vOr,FOr,j0,s7e,TOr,MOr,Ere,EOr,COr,wOr,D0,l7e,AOr,LOr,Cre,yOr,xOr,$Or,G0,i7e,kOr,SOr,wre,ROr,POr,BOr,O0,d7e,IOr,NOr,Are,qOr,jOr,DOr,V0,m7e,GOr,OOr,Lre,VOr,XOr,zOr,X0,Poo,oc,z0,c7e,MS,QOr,f7e,WOr,Boo,mr,ES,UOr,rc,HOr,yre,JOr,YOr,xre,KOr,ZOr,eVr,CS,oVr,g7e,rVr,tVr,aVr,Ut,wS,nVr,h7e,sVr,lVr,tc,iVr,u7e,dVr,mVr,$re,cVr,fVr,gVr,Q0,hVr,Dr,AS,uVr,p7e,pVr,_Vr,xn,bVr,_7e,vVr,FVr,b7e,TVr,MVr,v7e,EVr,CVr,wVr,ac,W0,F7e,AVr,LVr,kre,yVr,xVr,$Vr,U0,T7e,kVr,SVr,Sre,RVr,PVr,BVr,H0,M7e,IVr,NVr,Rre,qVr,jVr,DVr,J0,Ioo,nc,Y0,E7e,LS,GVr,C7e,OVr,Noo,cr,yS,VVr,sc,XVr,Pre,zVr,QVr,Bre,WVr,UVr,HVr,xS,JVr,w7e,YVr,KVr,ZVr,Ht,$S,eXr,A7e,oXr,rXr,lc,tXr,L7e,aXr,nXr,Ire,sXr,lXr,iXr,K0,dXr,Gr,kS,mXr,y7e,cXr,fXr,$n,gXr,x7e,hXr,uXr,$7e,pXr,_Xr,k7e,bXr,vXr,FXr,ge,Z0,S7e,TXr,MXr,Nre,EXr,CXr,wXr,ew,R7e,AXr,LXr,qre,yXr,xXr,$Xr,ow,P7e,kXr,SXr,jre,RXr,PXr,BXr,rw,B7e,IXr,NXr,Dre,qXr,jXr,DXr,tw,I7e,GXr,OXr,Gre,VXr,XXr,zXr,aw,N7e,QXr,WXr,Ore,UXr,HXr,JXr,nw,q7e,YXr,KXr,Vre,ZXr,ezr,ozr,sw,j7e,rzr,tzr,Xre,azr,nzr,szr,lw,D7e,lzr,izr,zre,dzr,mzr,czr,iw,G7e,fzr,gzr,Qre,hzr,uzr,pzr,dw,O7e,_zr,bzr,Wre,vzr,Fzr,Tzr,mw,V7e,Mzr,Ezr,Ure,Czr,wzr,Azr,cw,X7e,Lzr,yzr,Hre,xzr,$zr,kzr,fw,z7e,Szr,Rzr,Jre,Pzr,Bzr,Izr,gw,Q7e,Nzr,qzr,Yre,jzr,Dzr,Gzr,hw,W7e,Ozr,Vzr,Kre,Xzr,zzr,Qzr,uw,U7e,Wzr,Uzr,Zre,Hzr,Jzr,Yzr,pw,H7e,Kzr,Zzr,ete,eQr,oQr,rQr,_w,J7e,tQr,aQr,ote,nQr,sQr,lQr,bw,Y7e,iQr,dQr,rte,mQr,cQr,fQr,vw,qoo,ic,Fw,K7e,SS,gQr,Z7e,hQr,joo,fr,RS,uQr,dc,pQr,tte,_Qr,bQr,ate,vQr,FQr,TQr,PS,MQr,eLe,EQr,CQr,wQr,Jt,BS,AQr,oLe,LQr,yQr,mc,xQr,rLe,$Qr,kQr,nte,SQr,RQr,PQr,Tw,BQr,Or,IS,IQr,tLe,NQr,qQr,kn,jQr,aLe,DQr,GQr,nLe,OQr,VQr,sLe,XQr,zQr,QQr,ye,Mw,lLe,WQr,UQr,ste,HQr,JQr,YQr,Ew,iLe,KQr,ZQr,lte,eWr,oWr,rWr,Cw,dLe,tWr,aWr,ite,nWr,sWr,lWr,ww,mLe,iWr,dWr,dte,mWr,cWr,fWr,Aw,cLe,gWr,hWr,mte,uWr,pWr,_Wr,Lw,fLe,bWr,vWr,cte,FWr,TWr,MWr,yw,gLe,EWr,CWr,fte,wWr,AWr,LWr,xw,hLe,yWr,xWr,gte,$Wr,kWr,SWr,$w,uLe,RWr,PWr,hte,BWr,IWr,NWr,kw,pLe,qWr,jWr,ute,DWr,GWr,OWr,Sw,Doo,cc,Rw,_Le,NS,VWr,bLe,XWr,Goo,gr,qS,zWr,fc,QWr,pte,WWr,UWr,_te,HWr,JWr,YWr,jS,KWr,vLe,ZWr,eUr,oUr,Yt,DS,rUr,FLe,tUr,aUr,gc,nUr,TLe,sUr,lUr,bte,iUr,dUr,mUr,Pw,cUr,Vr,GS,fUr,MLe,gUr,hUr,Sn,uUr,ELe,pUr,_Ur,CLe,bUr,vUr,wLe,FUr,TUr,MUr,re,Bw,ALe,EUr,CUr,vte,wUr,AUr,LUr,Iw,LLe,yUr,xUr,Fte,$Ur,kUr,SUr,Nw,yLe,RUr,PUr,Tte,BUr,IUr,NUr,qw,xLe,qUr,jUr,Mte,DUr,GUr,OUr,jw,$Le,VUr,XUr,Ete,zUr,QUr,WUr,Dw,kLe,UUr,HUr,Cte,JUr,YUr,KUr,Gw,SLe,ZUr,eHr,wte,oHr,rHr,tHr,Ow,RLe,aHr,nHr,Ate,sHr,lHr,iHr,Vw,PLe,dHr,mHr,Lte,cHr,fHr,gHr,Xw,BLe,hHr,uHr,yte,pHr,_Hr,bHr,zw,ILe,vHr,FHr,xte,THr,MHr,EHr,Qw,NLe,CHr,wHr,$te,AHr,LHr,yHr,Ww,qLe,xHr,$Hr,kte,kHr,SHr,RHr,Uw,jLe,PHr,BHr,Ste,IHr,NHr,qHr,Hw,DLe,jHr,DHr,Rte,GHr,OHr,VHr,Jw,GLe,XHr,zHr,Pte,QHr,WHr,UHr,Yw,OLe,HHr,JHr,Bte,YHr,KHr,ZHr,Kw,VLe,eJr,oJr,Ite,rJr,tJr,aJr,Zw,XLe,nJr,sJr,Nte,lJr,iJr,dJr,eA,zLe,mJr,cJr,qte,fJr,gJr,hJr,oA,QLe,uJr,pJr,jte,_Jr,bJr,vJr,rA,WLe,FJr,TJr,Dte,MJr,EJr,CJr,tA,ULe,wJr,AJr,Gte,LJr,yJr,xJr,aA,HLe,$Jr,kJr,Ote,SJr,RJr,PJr,nA,JLe,BJr,IJr,Vte,NJr,qJr,jJr,sA,YLe,DJr,GJr,Xte,OJr,VJr,XJr,lA,KLe,zJr,QJr,zte,WJr,UJr,HJr,iA,Ooo,hc,dA,ZLe,OS,JJr,eye,YJr,Voo,hr,VS,KJr,uc,ZJr,Qte,eYr,oYr,Wte,rYr,tYr,aYr,XS,nYr,oye,sYr,lYr,iYr,Kt,zS,dYr,rye,mYr,cYr,pc,fYr,tye,gYr,hYr,Ute,uYr,pYr,_Yr,mA,bYr,Xr,QS,vYr,aye,FYr,TYr,Rn,MYr,nye,EYr,CYr,sye,wYr,AYr,lye,LYr,yYr,xYr,ve,cA,iye,$Yr,kYr,Hte,SYr,RYr,PYr,fA,dye,BYr,IYr,Jte,NYr,qYr,jYr,gA,mye,DYr,GYr,Yte,OYr,VYr,XYr,hA,cye,zYr,QYr,Kte,WYr,UYr,HYr,uA,fye,JYr,YYr,Zte,KYr,ZYr,eKr,pA,gye,oKr,rKr,eae,tKr,aKr,nKr,_A,hye,sKr,lKr,oae,iKr,dKr,mKr,bA,uye,cKr,fKr,rae,gKr,hKr,uKr,vA,pye,pKr,_Kr,tae,bKr,vKr,FKr,FA,_ye,TKr,MKr,aae,EKr,CKr,wKr,TA,bye,AKr,LKr,nae,yKr,xKr,$Kr,MA,vye,kKr,SKr,sae,RKr,PKr,BKr,EA,Fye,IKr,NKr,lae,qKr,jKr,DKr,CA,Tye,GKr,OKr,iae,VKr,XKr,zKr,wA,Mye,QKr,WKr,dae,UKr,HKr,JKr,AA,Eye,YKr,KKr,mae,ZKr,eZr,oZr,LA,Cye,rZr,tZr,cae,aZr,nZr,sZr,yA,Xoo,_c,xA,wye,WS,lZr,Aye,iZr,zoo,ur,US,dZr,bc,mZr,fae,cZr,fZr,gae,gZr,hZr,uZr,HS,pZr,Lye,_Zr,bZr,vZr,Zt,JS,FZr,yye,TZr,MZr,vc,EZr,xye,CZr,wZr,hae,AZr,LZr,yZr,$A,xZr,zr,YS,$Zr,$ye,kZr,SZr,Pn,RZr,kye,PZr,BZr,Sye,IZr,NZr,Rye,qZr,jZr,DZr,KS,kA,Pye,GZr,OZr,uae,VZr,XZr,zZr,SA,Bye,QZr,WZr,pae,UZr,HZr,JZr,RA,Qoo,Fc,PA,Iye,ZS,YZr,Nye,KZr,Woo,pr,eR,ZZr,Tc,eet,_ae,oet,ret,bae,tet,aet,net,oR,set,qye,iet,det,met,ea,rR,cet,jye,fet,get,Mc,het,Dye,uet,pet,vae,_et,bet,vet,BA,Fet,Qr,tR,Tet,Gye,Met,Eet,Bn,Cet,Oye,wet,Aet,Vye,Let,yet,Xye,xet,$et,ket,zye,IA,Qye,Set,Ret,Fae,Pet,Bet,Iet,NA,Uoo,Ec,qA,Wye,aR,Net,Uye,qet,Hoo,_r,nR,jet,Cc,Det,Tae,Get,Oet,Mae,Vet,Xet,zet,sR,Qet,Hye,Wet,Uet,Het,oa,lR,Jet,Jye,Yet,Ket,wc,Zet,Yye,eot,oot,Eae,rot,tot,aot,jA,not,Wr,iR,sot,Kye,lot,iot,In,dot,Zye,mot,cot,e8e,fot,got,o8e,hot,uot,pot,r8e,DA,t8e,_ot,bot,Cae,vot,Fot,Tot,GA,Joo,Ac,OA,a8e,dR,Mot,n8e,Eot,Yoo,br,mR,Cot,Lc,wot,wae,Aot,Lot,Aae,yot,xot,$ot,cR,kot,s8e,Sot,Rot,Pot,ra,fR,Bot,l8e,Iot,Not,yc,qot,i8e,jot,Dot,Lae,Got,Oot,Vot,VA,Xot,Ur,gR,zot,d8e,Qot,Wot,Nn,Uot,m8e,Hot,Jot,c8e,Yot,Kot,f8e,Zot,ert,ort,me,XA,g8e,rrt,trt,yae,art,nrt,srt,zA,h8e,lrt,irt,xae,drt,mrt,crt,QA,u8e,frt,grt,$ae,hrt,urt,prt,WA,p8e,_rt,brt,kae,vrt,Frt,Trt,UA,_8e,Mrt,Ert,Sae,Crt,wrt,Art,HA,b8e,Lrt,yrt,Rae,xrt,$rt,krt,JA,v8e,Srt,Rrt,Pae,Prt,Brt,Irt,YA,F8e,Nrt,qrt,Bae,jrt,Drt,Grt,KA,T8e,Ort,Vrt,Iae,Xrt,zrt,Qrt,ZA,M8e,Wrt,Urt,Nae,Hrt,Jrt,Yrt,e6,E8e,Krt,Zrt,qae,ett,ott,rtt,o6,C8e,ttt,att,jae,ntt,stt,ltt,r6,w8e,itt,dtt,Dae,mtt,ctt,ftt,t6,A8e,gtt,htt,Gae,utt,ptt,_tt,a6,L8e,btt,vtt,Oae,Ftt,Ttt,Mtt,n6,y8e,Ett,Ctt,Vae,wtt,Att,Ltt,s6,x8e,ytt,xtt,Xae,$tt,ktt,Stt,l6,$8e,Rtt,Ptt,zae,Btt,Itt,Ntt,i6,k8e,qtt,jtt,Qae,Dtt,Gtt,Ott,d6,S8e,Vtt,Xtt,Wae,ztt,Qtt,Wtt,m6,R8e,Utt,Htt,Uae,Jtt,Ytt,Ktt,c6,Koo,xc,f6,P8e,hR,Ztt,B8e,eat,Zoo,vr,uR,oat,$c,rat,Hae,tat,aat,Jae,nat,sat,lat,pR,iat,I8e,dat,mat,cat,ta,_R,fat,N8e,gat,hat,kc,uat,q8e,pat,_at,Yae,bat,vat,Fat,g6,Tat,Hr,bR,Mat,j8e,Eat,Cat,qn,wat,D8e,Aat,Lat,G8e,yat,xat,O8e,$at,kat,Sat,ce,h6,V8e,Rat,Pat,Kae,Bat,Iat,Nat,u6,X8e,qat,jat,Zae,Dat,Gat,Oat,p6,z8e,Vat,Xat,ene,zat,Qat,Wat,_6,Q8e,Uat,Hat,one,Jat,Yat,Kat,b6,W8e,Zat,ent,rne,ont,rnt,tnt,v6,U8e,ant,nnt,tne,snt,lnt,int,F6,H8e,dnt,mnt,ane,cnt,fnt,gnt,T6,J8e,hnt,unt,nne,pnt,_nt,bnt,M6,Y8e,vnt,Fnt,sne,Tnt,Mnt,Ent,E6,K8e,Cnt,wnt,lne,Ant,Lnt,ynt,C6,Z8e,xnt,$nt,ine,knt,Snt,Rnt,w6,e9e,Pnt,Bnt,dne,Int,Nnt,qnt,A6,o9e,jnt,Dnt,mne,Gnt,Ont,Vnt,L6,r9e,Xnt,znt,cne,Qnt,Wnt,Unt,y6,t9e,Hnt,Jnt,fne,Ynt,Knt,Znt,x6,a9e,est,ost,gne,rst,tst,ast,$6,n9e,nst,sst,hne,lst,ist,dst,k6,s9e,mst,cst,une,fst,gst,hst,S6,l9e,ust,pst,pne,_st,bst,vst,R6,i9e,Fst,Tst,_ne,Mst,Est,Cst,P6,d9e,wst,Ast,bne,Lst,yst,xst,B6,ero,Sc,I6,m9e,vR,$st,c9e,kst,oro,Fr,FR,Sst,Rc,Rst,vne,Pst,Bst,Fne,Ist,Nst,qst,TR,jst,f9e,Dst,Gst,Ost,aa,MR,Vst,g9e,Xst,zst,Pc,Qst,h9e,Wst,Ust,Tne,Hst,Jst,Yst,N6,Kst,Jr,ER,Zst,u9e,elt,olt,jn,rlt,p9e,tlt,alt,_9e,nlt,slt,b9e,llt,ilt,dlt,v9e,q6,F9e,mlt,clt,Mne,flt,glt,hlt,j6,rro,Bc,D6,T9e,CR,ult,M9e,plt,tro,Tr,wR,_lt,Ic,blt,Ene,vlt,Flt,Cne,Tlt,Mlt,Elt,AR,Clt,E9e,wlt,Alt,Llt,na,LR,ylt,C9e,xlt,$lt,Nc,klt,w9e,Slt,Rlt,wne,Plt,Blt,Ilt,G6,Nlt,Yr,yR,qlt,A9e,jlt,Dlt,Dn,Glt,L9e,Olt,Vlt,y9e,Xlt,zlt,x9e,Qlt,Wlt,Ult,$9e,O6,k9e,Hlt,Jlt,Ane,Ylt,Klt,Zlt,V6,aro,qc,X6,S9e,xR,eit,R9e,oit,nro,Mr,$R,rit,jc,tit,Lne,ait,nit,yne,sit,lit,iit,kR,dit,P9e,mit,cit,fit,sa,SR,git,B9e,hit,uit,Dc,pit,I9e,_it,bit,xne,vit,Fit,Tit,z6,Mit,Kr,RR,Eit,N9e,Cit,wit,Gn,Ait,q9e,Lit,yit,j9e,xit,$it,D9e,kit,Sit,Rit,te,Q6,G9e,Pit,Bit,$ne,Iit,Nit,qit,W6,O9e,jit,Dit,kne,Git,Oit,Vit,U6,V9e,Xit,zit,Sne,Qit,Wit,Uit,H6,X9e,Hit,Jit,Rne,Yit,Kit,Zit,J6,z9e,edt,odt,Pne,rdt,tdt,adt,Y6,Q9e,ndt,sdt,Bne,ldt,idt,ddt,K6,W9e,mdt,cdt,Ine,fdt,gdt,hdt,Z6,U9e,udt,pdt,Nne,_dt,bdt,vdt,e7,H9e,Fdt,Tdt,qne,Mdt,Edt,Cdt,o7,J9e,wdt,Adt,jne,Ldt,ydt,xdt,r7,Y9e,$dt,kdt,Dne,Sdt,Rdt,Pdt,t7,K9e,Bdt,Idt,Gne,Ndt,qdt,jdt,a7,Z9e,Ddt,Gdt,One,Odt,Vdt,Xdt,n7,exe,zdt,Qdt,Vne,Wdt,Udt,Hdt,s7,oxe,Jdt,Ydt,Xne,Kdt,Zdt,emt,l7,rxe,omt,rmt,zne,tmt,amt,nmt,i7,txe,smt,lmt,Qne,imt,dmt,mmt,d7,axe,cmt,fmt,Wne,gmt,hmt,umt,m7,nxe,pmt,_mt,Une,bmt,vmt,Fmt,c7,sxe,Tmt,Mmt,Hne,Emt,Cmt,wmt,f7,lxe,Amt,Lmt,Jne,ymt,xmt,$mt,g7,ixe,kmt,Smt,Yne,Rmt,Pmt,Bmt,h7,dxe,Imt,Nmt,Kne,qmt,jmt,Dmt,u7,mxe,Gmt,Omt,Zne,Vmt,Xmt,zmt,p7,cxe,Qmt,Wmt,ese,Umt,Hmt,Jmt,_7,fxe,Ymt,Kmt,ose,Zmt,ect,oct,b7,gxe,rct,tct,rse,act,nct,sct,v7,sro,Gc,F7,hxe,PR,lct,uxe,ict,lro,Er,BR,dct,Oc,mct,tse,cct,fct,ase,gct,hct,uct,IR,pct,pxe,_ct,bct,vct,la,NR,Fct,_xe,Tct,Mct,Vc,Ect,bxe,Cct,wct,nse,Act,Lct,yct,T7,xct,Zr,qR,$ct,vxe,kct,Sct,On,Rct,Fxe,Pct,Bct,Txe,Ict,Nct,Mxe,qct,jct,Dct,xe,M7,Exe,Gct,Oct,sse,Vct,Xct,zct,E7,Cxe,Qct,Wct,lse,Uct,Hct,Jct,C7,wxe,Yct,Kct,ise,Zct,eft,oft,w7,Axe,rft,tft,dse,aft,nft,sft,A7,Lxe,lft,ift,mse,dft,mft,cft,L7,yxe,fft,gft,cse,hft,uft,pft,y7,xxe,_ft,bft,fse,vft,Fft,Tft,x7,$xe,Mft,Eft,gse,Cft,wft,Aft,$7,kxe,Lft,yft,hse,xft,$ft,kft,k7,Sxe,Sft,Rft,use,Pft,Bft,Ift,S7,iro,Xc,R7,Rxe,jR,Nft,Pxe,qft,dro,Cr,DR,jft,zc,Dft,pse,Gft,Oft,_se,Vft,Xft,zft,GR,Qft,Bxe,Wft,Uft,Hft,ia,OR,Jft,Ixe,Yft,Kft,Qc,Zft,Nxe,egt,ogt,bse,rgt,tgt,agt,P7,ngt,et,VR,sgt,qxe,lgt,igt,Vn,dgt,jxe,mgt,cgt,Dxe,fgt,ggt,Gxe,hgt,ugt,pgt,Ee,B7,Oxe,_gt,bgt,vse,vgt,Fgt,Tgt,I7,Vxe,Mgt,Egt,Fse,Cgt,wgt,Agt,N7,Xxe,Lgt,ygt,Tse,xgt,$gt,kgt,q7,zxe,Sgt,Rgt,Mse,Pgt,Bgt,Igt,j7,Qxe,Ngt,qgt,Ese,jgt,Dgt,Ggt,D7,Wxe,Ogt,Vgt,Cse,Xgt,zgt,Qgt,G7,Uxe,Wgt,Ugt,wse,Hgt,Jgt,Ygt,O7,Hxe,Kgt,Zgt,Ase,eht,oht,rht,V7,Jxe,tht,aht,Lse,nht,sht,lht,X7,Yxe,iht,dht,yse,mht,cht,fht,z7,Kxe,ght,hht,xse,uht,pht,_ht,Q7,Zxe,bht,vht,$se,Fht,Tht,Mht,W7,e$e,Eht,Cht,kse,wht,Aht,Lht,U7,mro,Wc,H7,o$e,XR,yht,r$e,xht,cro,wr,zR,$ht,Uc,kht,Sse,Sht,Rht,Rse,Pht,Bht,Iht,QR,Nht,t$e,qht,jht,Dht,da,WR,Ght,a$e,Oht,Vht,Hc,Xht,n$e,zht,Qht,Pse,Wht,Uht,Hht,J7,Jht,ot,UR,Yht,s$e,Kht,Zht,Xn,eut,l$e,out,rut,i$e,tut,aut,d$e,nut,sut,lut,$e,Y7,m$e,iut,dut,Bse,mut,cut,fut,K7,c$e,gut,hut,Ise,uut,put,_ut,Z7,f$e,but,vut,Nse,Fut,Tut,Mut,eL,g$e,Eut,Cut,qse,wut,Aut,Lut,oL,h$e,yut,xut,jse,$ut,kut,Sut,rL,u$e,Rut,Put,Dse,But,Iut,Nut,tL,p$e,qut,jut,Gse,Dut,Gut,Out,aL,_$e,Vut,Xut,Ose,zut,Qut,Wut,nL,b$e,Uut,Hut,Vse,Jut,Yut,Kut,sL,v$e,Zut,ept,Xse,opt,rpt,tpt,lL,fro,Jc,iL,F$e,HR,apt,T$e,npt,gro,Ar,JR,spt,Yc,lpt,zse,ipt,dpt,Qse,mpt,cpt,fpt,YR,gpt,M$e,hpt,upt,ppt,ma,KR,_pt,E$e,bpt,vpt,Kc,Fpt,C$e,Tpt,Mpt,Wse,Ept,Cpt,wpt,dL,Apt,rt,ZR,Lpt,w$e,ypt,xpt,zn,$pt,A$e,kpt,Spt,L$e,Rpt,Ppt,y$e,Bpt,Ipt,Npt,ke,mL,x$e,qpt,jpt,Use,Dpt,Gpt,Opt,cL,$$e,Vpt,Xpt,Hse,zpt,Qpt,Wpt,fL,k$e,Upt,Hpt,Jse,Jpt,Ypt,Kpt,gL,S$e,Zpt,e_t,Yse,o_t,r_t,t_t,hL,R$e,a_t,n_t,Kse,s_t,l_t,i_t,uL,P$e,d_t,m_t,Zse,c_t,f_t,g_t,pL,B$e,h_t,u_t,ele,p_t,__t,b_t,_L,I$e,v_t,F_t,ole,T_t,M_t,E_t,bL,N$e,C_t,w_t,rle,A_t,L_t,y_t,vL,q$e,x_t,$_t,tle,k_t,S_t,R_t,FL,hro,Zc,TL,j$e,eP,P_t,D$e,B_t,uro,Lr,oP,I_t,ef,N_t,ale,q_t,j_t,nle,D_t,G_t,O_t,rP,V_t,G$e,X_t,z_t,Q_t,ca,tP,W_t,O$e,U_t,H_t,of,J_t,V$e,Y_t,K_t,sle,Z_t,e1t,o1t,ML,r1t,tt,aP,t1t,X$e,a1t,n1t,Qn,s1t,z$e,l1t,i1t,Q$e,d1t,m1t,W$e,c1t,f1t,g1t,Se,EL,U$e,h1t,u1t,lle,p1t,_1t,b1t,CL,H$e,v1t,F1t,ile,T1t,M1t,E1t,wL,J$e,C1t,w1t,dle,A1t,L1t,y1t,AL,Y$e,x1t,$1t,mle,k1t,S1t,R1t,LL,K$e,P1t,B1t,cle,I1t,N1t,q1t,yL,Z$e,j1t,D1t,fle,G1t,O1t,V1t,xL,eke,X1t,z1t,gle,Q1t,W1t,U1t,$L,oke,H1t,J1t,hle,Y1t,K1t,Z1t,kL,rke,e2t,o2t,ule,r2t,t2t,a2t,SL,tke,n2t,s2t,ple,l2t,i2t,d2t,RL,pro,rf,PL,ake,nP,m2t,nke,c2t,_ro,yr,sP,f2t,tf,g2t,_le,h2t,u2t,ble,p2t,_2t,b2t,lP,v2t,ske,F2t,T2t,M2t,fa,iP,E2t,lke,C2t,w2t,af,A2t,ike,L2t,y2t,vle,x2t,$2t,k2t,BL,S2t,at,dP,R2t,dke,P2t,B2t,Wn,I2t,mke,N2t,q2t,cke,j2t,D2t,fke,G2t,O2t,V2t,Re,IL,gke,X2t,z2t,Fle,Q2t,W2t,U2t,NL,hke,H2t,J2t,Tle,Y2t,K2t,Z2t,qL,uke,ebt,obt,Mle,rbt,tbt,abt,jL,pke,nbt,sbt,Ele,lbt,ibt,dbt,DL,_ke,mbt,cbt,Cle,fbt,gbt,hbt,GL,bke,ubt,pbt,wle,_bt,bbt,vbt,OL,vke,Fbt,Tbt,Ale,Mbt,Ebt,Cbt,VL,Fke,wbt,Abt,Lle,Lbt,ybt,xbt,XL,Tke,$bt,kbt,yle,Sbt,Rbt,Pbt,zL,Mke,Bbt,Ibt,xle,Nbt,qbt,jbt,QL,bro,nf,WL,Eke,mP,Dbt,Cke,Gbt,vro,xr,cP,Obt,sf,Vbt,$le,Xbt,zbt,kle,Qbt,Wbt,Ubt,fP,Hbt,wke,Jbt,Ybt,Kbt,ga,gP,Zbt,Ake,evt,ovt,lf,rvt,Lke,tvt,avt,Sle,nvt,svt,lvt,UL,ivt,nt,hP,dvt,yke,mvt,cvt,Un,fvt,xke,gvt,hvt,$ke,uvt,pvt,kke,_vt,bvt,vvt,Xe,HL,Ske,Fvt,Tvt,Rle,Mvt,Evt,Cvt,JL,Rke,wvt,Avt,Ple,Lvt,yvt,xvt,YL,Pke,$vt,kvt,Ble,Svt,Rvt,Pvt,KL,Bke,Bvt,Ivt,Ile,Nvt,qvt,jvt,ZL,Ike,Dvt,Gvt,Nle,Ovt,Vvt,Xvt,ey,Nke,zvt,Qvt,qle,Wvt,Uvt,Hvt,oy,qke,Jvt,Yvt,jle,Kvt,Zvt,eFt,ry,jke,oFt,rFt,Dle,tFt,aFt,nFt,ty,Fro,df,ay,Dke,uP,sFt,Gke,lFt,Tro,$r,pP,iFt,mf,dFt,Gle,mFt,cFt,Ole,fFt,gFt,hFt,_P,uFt,Oke,pFt,_Ft,bFt,ha,bP,vFt,Vke,FFt,TFt,cf,MFt,Xke,EFt,CFt,Vle,wFt,AFt,LFt,ny,yFt,st,vP,xFt,zke,$Ft,kFt,Hn,SFt,Qke,RFt,PFt,Wke,BFt,IFt,Uke,NFt,qFt,jFt,ze,sy,Hke,DFt,GFt,Xle,OFt,VFt,XFt,ly,Jke,zFt,QFt,zle,WFt,UFt,HFt,iy,Yke,JFt,YFt,Qle,KFt,ZFt,eTt,dy,Kke,oTt,rTt,Wle,tTt,aTt,nTt,my,Zke,sTt,lTt,Ule,iTt,dTt,mTt,cy,eSe,cTt,fTt,Hle,gTt,hTt,uTt,fy,oSe,pTt,_Tt,Jle,bTt,vTt,FTt,gy,rSe,TTt,MTt,Yle,ETt,CTt,wTt,hy,Mro,ff,uy,tSe,FP,ATt,aSe,LTt,Ero,kr,TP,yTt,gf,xTt,Kle,$Tt,kTt,Zle,STt,RTt,PTt,MP,BTt,nSe,ITt,NTt,qTt,ua,EP,jTt,sSe,DTt,GTt,hf,OTt,lSe,VTt,XTt,eie,zTt,QTt,WTt,py,UTt,lt,CP,HTt,iSe,JTt,YTt,Jn,KTt,dSe,ZTt,eMt,mSe,oMt,rMt,cSe,tMt,aMt,nMt,fSe,_y,gSe,sMt,lMt,oie,iMt,dMt,mMt,by,Cro,uf,vy,hSe,wP,cMt,uSe,fMt,wro,Sr,AP,gMt,pf,hMt,rie,uMt,pMt,tie,_Mt,bMt,vMt,LP,FMt,pSe,TMt,MMt,EMt,pa,yP,CMt,_Se,wMt,AMt,_f,LMt,bSe,yMt,xMt,aie,$Mt,kMt,SMt,Fy,RMt,it,xP,PMt,vSe,BMt,IMt,Yn,NMt,FSe,qMt,jMt,TSe,DMt,GMt,MSe,OMt,VMt,XMt,$P,Ty,ESe,zMt,QMt,nie,WMt,UMt,HMt,My,CSe,JMt,YMt,sie,KMt,ZMt,eEt,Ey,Aro,bf,Cy,wSe,kP,oEt,ASe,rEt,Lro,Rr,SP,tEt,vf,aEt,lie,nEt,sEt,iie,lEt,iEt,dEt,RP,mEt,LSe,cEt,fEt,gEt,_a,PP,hEt,ySe,uEt,pEt,Ff,_Et,xSe,bEt,vEt,die,FEt,TEt,MEt,wy,EEt,dt,BP,CEt,$Se,wEt,AEt,Kn,LEt,kSe,yEt,xEt,SSe,$Et,kEt,RSe,SEt,REt,PEt,PSe,Ay,BSe,BEt,IEt,mie,NEt,qEt,jEt,Ly,yro;return m=new oe({}),Qa=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),ix=new oe({}),dx=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),xf=new DEt({props:{warning:!0,$$slots:{default:[nba]},$$scope:{ctx:$}}}),mx=new oe({}),cx=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L659"}}),hx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L682"}}),ru=new N({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[sba]},$$scope:{ctx:$}}}),ux=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L805"}}),px=new oe({}),_x=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L428"}}),Fx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L442"}}),Du=new N({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[lba]},$$scope:{ctx:$}}}),Tx=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L643"}}),Mx=new oe({}),Ex=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L203"}}),Ax=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L217"}}),Sp=new DEt({props:{$$slots:{default:[iba]},$$scope:{ctx:$}}}),Rp=new N({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[dba]},$$scope:{ctx:$}}}),Lx=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L344"}}),yx=new oe({}),xx=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L96"}}),Sx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L110"}}),n_=new DEt({props:{$$slots:{default:[mba]},$$scope:{ctx:$}}}),s_=new N({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[cba]},$$scope:{ctx:$}}}),Rx=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L277"}}),Px=new oe({}),Bx=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L863"}}),Nx=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel">ConditionalDetrModel</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmModel">EsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel">GPTNeoXJapaneseModel</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel">MarkupLMModel</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig">TimeSeriesTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel">TimeSeriesTransformerModel</a> (Time Series Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel">ViTMSNModel</a> (ViTMSN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel">WhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),d_=new N({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[fba]},$$scope:{ctx:$}}}),qx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),x2=new N({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[gba]},$$scope:{ctx:$}}}),jx=new oe({}),Dx=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L870"}}),Ox=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),k2=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[hba]},$$scope:{ctx:$}}}),Vx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Lb=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[uba]},$$scope:{ctx:$}}}),Xx=new oe({}),zx=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L885"}}),Wx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM">GPTNeoXJapaneseForCausalLM</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),xb=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[pba]},$$scope:{ctx:$}}}),Ux=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),vv=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[_ba]},$$scope:{ctx:$}}}),Hx=new oe({}),Jx=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L892"}}),Kx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Tv=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[bba]},$$scope:{ctx:$}}}),Zx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iF=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[vba]},$$scope:{ctx:$}}}),e$=new oe({}),o$=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L899"}}),t$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),mF=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Fba]},$$scope:{ctx:$}}}),a$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),SF=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Tba]},$$scope:{ctx:$}}}),n$=new oe({}),s$=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L908"}}),i$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification">EsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification">MarkupLMForSequenceClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),PF=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[Mba]},$$scope:{ctx:$}}}),d$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),NT=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Eba]},$$scope:{ctx:$}}}),m$=new oe({}),c$=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L964"}}),g$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),jT=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[Cba]},$$scope:{ctx:$}}}),h$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),vM=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[wba]},$$scope:{ctx:$}}}),u$=new oe({}),p$=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L971"}}),b$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),TM=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Aba]},$$scope:{ctx:$}}}),v$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$M=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Lba]},$$scope:{ctx:$}}}),F$=new oe({}),T$=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L957"}}),E$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification">EsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification">MarkupLMForTokenClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),SM=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[yba]},$$scope:{ctx:$}}}),C$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),FE=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[xba]},$$scope:{ctx:$}}}),w$=new oe({}),A$=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L917"}}),y$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering">BloomForQuestionAnswering</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering">MarkupLMForQuestionAnswering</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ME=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[$ba]},$$scope:{ctx:$}}}),x$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),p4=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[kba]},$$scope:{ctx:$}}}),$$=new oe({}),k$=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L924"}}),R$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),b4=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Sba]},$$scope:{ctx:$}}}),P$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),T4=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[Rba]},$$scope:{ctx:$}}}),B$=new oe({}),I$=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L946"}}),q$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),E4=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[Pba]},$$scope:{ctx:$}}}),j$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),y4=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[Bba]},$$scope:{ctx:$}}}),D$=new oe({}),G$=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L980"}}),V$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification">ViTMSNForImageClassification</a> (ViTMSN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$4=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[Iba]},$$scope:{ctx:$}}}),X$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),W4=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Nba]},$$scope:{ctx:$}}}),z$=new oe({}),Q$=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1019"}}),U$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),H4=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[qba]},$$scope:{ctx:$}}}),H$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),K4=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[jba]},$$scope:{ctx:$}}}),J$=new oe({}),Y$=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1026"}}),Z$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),eC=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[Dba]},$$scope:{ctx:$}}}),ek=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),tC=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Gba]},$$scope:{ctx:$}}}),ok=new oe({}),rk=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L935"}}),ak=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),nC=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[Oba]},$$scope:{ctx:$}}}),nk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iC=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[Vba]},$$scope:{ctx:$}}}),sk=new oe({}),lk=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1033"}}),dk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),mC=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[Xba]},$$scope:{ctx:$}}}),mk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),TC=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[zba]},$$scope:{ctx:$}}}),ck=new oe({}),fk=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1056"}}),hk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),EC=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[Qba]},$$scope:{ctx:$}}}),uk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$C=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[Wba]},$$scope:{ctx:$}}}),pk=new oe({}),_k=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1040"}}),vk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),SC=new N({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[Uba]},$$scope:{ctx:$}}}),Fk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),XC=new N({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[Hba]},$$scope:{ctx:$}}}),Tk=new oe({}),Mk=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1047"}}),Ck=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration">WhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),QC=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Jba]},$$scope:{ctx:$}}}),wk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),YC=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Yba]},$$scope:{ctx:$}}}),Ak=new oe({}),Lk=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1065"}}),xk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ZC=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[Kba]},$$scope:{ctx:$}}}),$k=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),s3=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[Zba]},$$scope:{ctx:$}}}),kk=new oe({}),Sk=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1072"}}),Pk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),i3=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[eva]},$$scope:{ctx:$}}}),Bk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),h3=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[ova]},$$scope:{ctx:$}}}),Ik=new oe({}),Nk=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1012"}}),jk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection">ConditionalDetrForObjectDetection</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),p3=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[rva]},$$scope:{ctx:$}}}),Dk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),M3=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[tva]},$$scope:{ctx:$}}}),Gk=new oe({}),Ok=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L987"}}),Xk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),C3=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[ava]},$$scope:{ctx:$}}}),zk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),L3=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[nva]},$$scope:{ctx:$}}}),Qk=new oe({}),Wk=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L994"}}),Hk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),x3=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[sva]},$$scope:{ctx:$}}}),Jk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),I3=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[lva]},$$scope:{ctx:$}}}),Yk=new oe({}),Kk=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1003"}}),eS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),q3=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[iva]},$$scope:{ctx:$}}}),oS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),G3=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[dva]},$$scope:{ctx:$}}}),rS=new oe({}),tS=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L434"}}),nS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel">TFGroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),V3=new N({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[mva]},$$scope:{ctx:$}}}),sS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),X5=new N({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[cva]},$$scope:{ctx:$}}}),lS=new oe({}),iS=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L441"}}),mS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Q5=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[fva]},$$scope:{ctx:$}}}),cS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),p0=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[gva]},$$scope:{ctx:$}}}),fS=new oe({}),gS=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L456"}}),uS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),b0=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[hva]},$$scope:{ctx:$}}}),pS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),R0=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[uva]},$$scope:{ctx:$}}}),_S=new oe({}),bS=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L472"}}),FS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),B0=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[pva]},$$scope:{ctx:$}}}),TS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),X0=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[_va]},$$scope:{ctx:$}}}),MS=new oe({}),ES=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L481"}}),wS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Q0=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[bva]},$$scope:{ctx:$}}}),AS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),J0=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[vva]},$$scope:{ctx:$}}}),LS=new oe({}),yS=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L497"}}),$S=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),K0=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[Fva]},$$scope:{ctx:$}}}),kS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),vw=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Tva]},$$scope:{ctx:$}}}),SS=new oe({}),RS=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L504"}}),BS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Tw=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Mva]},$$scope:{ctx:$}}}),IS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Sw=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Eva]},$$scope:{ctx:$}}}),NS=new oe({}),qS=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L513"}}),DS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Pw=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Cva]},$$scope:{ctx:$}}}),GS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iA=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[wva]},$$scope:{ctx:$}}}),OS=new oe({}),VS=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L560"}}),zS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),mA=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Ava]},$$scope:{ctx:$}}}),QS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),yA=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Lva]},$$scope:{ctx:$}}}),WS=new oe({}),US=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L567"}}),JS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$A=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[yva]},$$scope:{ctx:$}}}),YS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),RA=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[xva]},$$scope:{ctx:$}}}),ZS=new oe({}),eR=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L540"}}),rR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),BA=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[$va]},$$scope:{ctx:$}}}),tR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),NA=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[kva]},$$scope:{ctx:$}}}),aR=new oe({}),nR=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L529"}}),lR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),jA=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[Sva]},$$scope:{ctx:$}}}),iR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),GA=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[Rva]},$$scope:{ctx:$}}}),dR=new oe({}),mR=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L551"}}),fR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),VA=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[Pva]},$$scope:{ctx:$}}}),gR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),c6=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Bva]},$$scope:{ctx:$}}}),hR=new oe({}),uR=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L522"}}),_R=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),g6=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Iva]},$$scope:{ctx:$}}}),bR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),B6=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Nva]},$$scope:{ctx:$}}}),vR=new oe({}),FR=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L490"}}),MR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),N6=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[qva]},$$scope:{ctx:$}}}),ER=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),j6=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[jva]},$$scope:{ctx:$}}}),CR=new oe({}),wR=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L576"}}),LR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),G6=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Dva]},$$scope:{ctx:$}}}),yR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),V6=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Gva]},$$scope:{ctx:$}}}),xR=new oe({}),$R=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),SR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),z6=new N({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[Ova]},$$scope:{ctx:$}}}),RR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),v7=new N({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[Vva]},$$scope:{ctx:$}}}),PR=new oe({}),BR=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),NR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),T7=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[Xva]},$$scope:{ctx:$}}}),qR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),S7=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[zva]},$$scope:{ctx:$}}}),jR=new oe({}),DR=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),OR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),P7=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[Qva]},$$scope:{ctx:$}}}),VR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),U7=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Wva]},$$scope:{ctx:$}}}),XR=new oe({}),zR=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),WR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),J7=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[Uva]},$$scope:{ctx:$}}}),UR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),lL=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Hva]},$$scope:{ctx:$}}}),HR=new oe({}),JR=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),KR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),dL=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Jva]},$$scope:{ctx:$}}}),ZR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),FL=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Yva]},$$scope:{ctx:$}}}),eP=new oe({}),oP=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),tP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ML=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Kva]},$$scope:{ctx:$}}}),aP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),RL=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Zva]},$$scope:{ctx:$}}}),nP=new oe({}),sP=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),iP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),BL=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[eFa]},$$scope:{ctx:$}}}),dP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),QL=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[oFa]},$$scope:{ctx:$}}}),mP=new oe({}),cP=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),gP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),UL=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[rFa]},$$scope:{ctx:$}}}),hP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ty=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[tFa]},$$scope:{ctx:$}}}),uP=new oe({}),pP=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),bP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ny=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[aFa]},$$scope:{ctx:$}}}),vP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),hy=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[nFa]},$$scope:{ctx:$}}}),FP=new oe({}),TP=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),EP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),py=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[sFa]},$$scope:{ctx:$}}}),CP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),by=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[lFa]},$$scope:{ctx:$}}}),wP=new oe({}),AP=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),yP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Fy=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[iFa]},$$scope:{ctx:$}}}),xP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Ey=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[dFa]},$$scope:{ctx:$}}}),kP=new oe({}),SP=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),PP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),wy=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[mFa]},$$scope:{ctx:$}}}),BP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Ly=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[cFa]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(m.$$.fragment),h=l(),yo=a("span"),td=o("Auto Classes"),Cf=l(),pt=a("p"),ad=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),nd=a("code"),ax=o("from_pretrained()"),wf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Ve=l(),He=a("p"),sd=o("Instantiating one of "),es=a("a"),nx=o("AutoConfig"),os=o(", "),rs=a("a"),sx=o("AutoModel"),ld=o(`, and
`),ts=a("a"),lx=o("AutoTokenizer"),id=o(" will directly create a class of the relevant architecture. For instance"),Af=l(),F(Qa.$$.fragment),Je=l(),Ae=a("p"),lI=o("will create a model that is an instance of "),dd=a("a"),iI=o("BertModel"),dI=o("."),xo=l(),Wa=a("p"),mI=o("There is one class of "),Lf=a("code"),cI=o("AutoModel"),Xao=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),ueo=l(),md=a("h2"),yf=a("a"),ume=a("span"),F(ix.$$.fragment),zao=l(),pme=a("span"),Qao=o("Extending the Auto Classes"),peo=l(),as=a("p"),Wao=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),_me=a("code"),Uao=o("NewModel"),Hao=o(", make sure you have a "),bme=a("code"),Jao=o("NewModelConfig"),Yao=o(` then you can add those to the auto
classes like this:`),_eo=l(),F(dx.$$.fragment),beo=l(),fI=a("p"),Kao=o("You will then be able to use the auto classes like you would usually do!"),veo=l(),F(xf.$$.fragment),Feo=l(),cd=a("h2"),$f=a("a"),vme=a("span"),F(mx.$$.fragment),Zao=l(),Fme=a("span"),eno=o("AutoConfig"),Teo=l(),$o=a("div"),F(cx.$$.fragment),ono=l(),fx=a("p"),rno=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),gI=a("a"),tno=o("from_pretrained()"),ano=o(" class method."),nno=l(),gx=a("p"),sno=o("This class cannot be instantiated directly using "),Tme=a("code"),lno=o("__init__()"),ino=o(" (throws an error)."),dno=l(),Pr=a("div"),F(hx.$$.fragment),mno=l(),Mme=a("p"),cno=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),fno=l(),fd=a("p"),gno=o("The configuration class to instantiate is selected based on the "),Eme=a("code"),hno=o("model_type"),uno=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Cme=a("code"),pno=o("pretrained_model_name_or_path"),_no=o(":"),bno=l(),A=a("ul"),kf=a("li"),wme=a("strong"),vno=o("albert"),Fno=o(" \u2014 "),hI=a("a"),Tno=o("AlbertConfig"),Mno=o(" (ALBERT model)"),Eno=l(),Sf=a("li"),Ame=a("strong"),Cno=o("bart"),wno=o(" \u2014 "),uI=a("a"),Ano=o("BartConfig"),Lno=o(" (BART model)"),yno=l(),Rf=a("li"),Lme=a("strong"),xno=o("beit"),$no=o(" \u2014 "),pI=a("a"),kno=o("BeitConfig"),Sno=o(" (BEiT model)"),Rno=l(),Pf=a("li"),yme=a("strong"),Pno=o("bert"),Bno=o(" \u2014 "),_I=a("a"),Ino=o("BertConfig"),Nno=o(" (BERT model)"),qno=l(),Bf=a("li"),xme=a("strong"),jno=o("bert-generation"),Dno=o(" \u2014 "),bI=a("a"),Gno=o("BertGenerationConfig"),Ono=o(" (Bert Generation model)"),Vno=l(),If=a("li"),$me=a("strong"),Xno=o("big_bird"),zno=o(" \u2014 "),vI=a("a"),Qno=o("BigBirdConfig"),Wno=o(" (BigBird model)"),Uno=l(),Nf=a("li"),kme=a("strong"),Hno=o("bigbird_pegasus"),Jno=o(" \u2014 "),FI=a("a"),Yno=o("BigBirdPegasusConfig"),Kno=o(" (BigBird-Pegasus model)"),Zno=l(),qf=a("li"),Sme=a("strong"),eso=o("blenderbot"),oso=o(" \u2014 "),TI=a("a"),rso=o("BlenderbotConfig"),tso=o(" (Blenderbot model)"),aso=l(),jf=a("li"),Rme=a("strong"),nso=o("blenderbot-small"),sso=o(" \u2014 "),MI=a("a"),lso=o("BlenderbotSmallConfig"),iso=o(" (BlenderbotSmall model)"),dso=l(),Df=a("li"),Pme=a("strong"),mso=o("bloom"),cso=o(" \u2014 "),EI=a("a"),fso=o("BloomConfig"),gso=o(" (BLOOM model)"),hso=l(),Gf=a("li"),Bme=a("strong"),uso=o("camembert"),pso=o(" \u2014 "),CI=a("a"),_so=o("CamembertConfig"),bso=o(" (CamemBERT model)"),vso=l(),Of=a("li"),Ime=a("strong"),Fso=o("canine"),Tso=o(" \u2014 "),wI=a("a"),Mso=o("CanineConfig"),Eso=o(" (CANINE model)"),Cso=l(),Vf=a("li"),Nme=a("strong"),wso=o("clip"),Aso=o(" \u2014 "),AI=a("a"),Lso=o("CLIPConfig"),yso=o(" (CLIP model)"),xso=l(),Xf=a("li"),qme=a("strong"),$so=o("codegen"),kso=o(" \u2014 "),LI=a("a"),Sso=o("CodeGenConfig"),Rso=o(" (CodeGen model)"),Pso=l(),zf=a("li"),jme=a("strong"),Bso=o("conditional_detr"),Iso=o(" \u2014 "),yI=a("a"),Nso=o("ConditionalDetrConfig"),qso=o(" (Conditional DETR model)"),jso=l(),Qf=a("li"),Dme=a("strong"),Dso=o("convbert"),Gso=o(" \u2014 "),xI=a("a"),Oso=o("ConvBertConfig"),Vso=o(" (ConvBERT model)"),Xso=l(),Wf=a("li"),Gme=a("strong"),zso=o("convnext"),Qso=o(" \u2014 "),$I=a("a"),Wso=o("ConvNextConfig"),Uso=o(" (ConvNeXT model)"),Hso=l(),Uf=a("li"),Ome=a("strong"),Jso=o("ctrl"),Yso=o(" \u2014 "),kI=a("a"),Kso=o("CTRLConfig"),Zso=o(" (CTRL model)"),elo=l(),Hf=a("li"),Vme=a("strong"),olo=o("cvt"),rlo=o(" \u2014 "),SI=a("a"),tlo=o("CvtConfig"),alo=o(" (CvT model)"),nlo=l(),Jf=a("li"),Xme=a("strong"),slo=o("data2vec-audio"),llo=o(" \u2014 "),RI=a("a"),ilo=o("Data2VecAudioConfig"),dlo=o(" (Data2VecAudio model)"),mlo=l(),Yf=a("li"),zme=a("strong"),clo=o("data2vec-text"),flo=o(" \u2014 "),PI=a("a"),glo=o("Data2VecTextConfig"),hlo=o(" (Data2VecText model)"),ulo=l(),Kf=a("li"),Qme=a("strong"),plo=o("data2vec-vision"),_lo=o(" \u2014 "),BI=a("a"),blo=o("Data2VecVisionConfig"),vlo=o(" (Data2VecVision model)"),Flo=l(),Zf=a("li"),Wme=a("strong"),Tlo=o("deberta"),Mlo=o(" \u2014 "),II=a("a"),Elo=o("DebertaConfig"),Clo=o(" (DeBERTa model)"),wlo=l(),eg=a("li"),Ume=a("strong"),Alo=o("deberta-v2"),Llo=o(" \u2014 "),NI=a("a"),ylo=o("DebertaV2Config"),xlo=o(" (DeBERTa-v2 model)"),$lo=l(),og=a("li"),Hme=a("strong"),klo=o("decision_transformer"),Slo=o(" \u2014 "),qI=a("a"),Rlo=o("DecisionTransformerConfig"),Plo=o(" (Decision Transformer model)"),Blo=l(),rg=a("li"),Jme=a("strong"),Ilo=o("deformable_detr"),Nlo=o(" \u2014 "),jI=a("a"),qlo=o("DeformableDetrConfig"),jlo=o(" (Deformable DETR model)"),Dlo=l(),tg=a("li"),Yme=a("strong"),Glo=o("deit"),Olo=o(" \u2014 "),DI=a("a"),Vlo=o("DeiTConfig"),Xlo=o(" (DeiT model)"),zlo=l(),ag=a("li"),Kme=a("strong"),Qlo=o("detr"),Wlo=o(" \u2014 "),GI=a("a"),Ulo=o("DetrConfig"),Hlo=o(" (DETR model)"),Jlo=l(),ng=a("li"),Zme=a("strong"),Ylo=o("distilbert"),Klo=o(" \u2014 "),OI=a("a"),Zlo=o("DistilBertConfig"),eio=o(" (DistilBERT model)"),oio=l(),sg=a("li"),ece=a("strong"),rio=o("donut-swin"),tio=o(" \u2014 "),VI=a("a"),aio=o("DonutSwinConfig"),nio=o(" (DonutSwin model)"),sio=l(),lg=a("li"),oce=a("strong"),lio=o("dpr"),iio=o(" \u2014 "),XI=a("a"),dio=o("DPRConfig"),mio=o(" (DPR model)"),cio=l(),ig=a("li"),rce=a("strong"),fio=o("dpt"),gio=o(" \u2014 "),zI=a("a"),hio=o("DPTConfig"),uio=o(" (DPT model)"),pio=l(),dg=a("li"),tce=a("strong"),_io=o("electra"),bio=o(" \u2014 "),QI=a("a"),vio=o("ElectraConfig"),Fio=o(" (ELECTRA model)"),Tio=l(),mg=a("li"),ace=a("strong"),Mio=o("encoder-decoder"),Eio=o(" \u2014 "),WI=a("a"),Cio=o("EncoderDecoderConfig"),wio=o(" (Encoder decoder model)"),Aio=l(),cg=a("li"),nce=a("strong"),Lio=o("ernie"),yio=o(" \u2014 "),UI=a("a"),xio=o("ErnieConfig"),$io=o(" (ERNIE model)"),kio=l(),fg=a("li"),sce=a("strong"),Sio=o("esm"),Rio=o(" \u2014 "),HI=a("a"),Pio=o("EsmConfig"),Bio=o(" (ESM model)"),Iio=l(),gg=a("li"),lce=a("strong"),Nio=o("flaubert"),qio=o(" \u2014 "),JI=a("a"),jio=o("FlaubertConfig"),Dio=o(" (FlauBERT model)"),Gio=l(),hg=a("li"),ice=a("strong"),Oio=o("flava"),Vio=o(" \u2014 "),YI=a("a"),Xio=o("FlavaConfig"),zio=o(" (FLAVA model)"),Qio=l(),ug=a("li"),dce=a("strong"),Wio=o("fnet"),Uio=o(" \u2014 "),KI=a("a"),Hio=o("FNetConfig"),Jio=o(" (FNet model)"),Yio=l(),pg=a("li"),mce=a("strong"),Kio=o("fsmt"),Zio=o(" \u2014 "),ZI=a("a"),edo=o("FSMTConfig"),odo=o(" (FairSeq Machine-Translation model)"),rdo=l(),_g=a("li"),cce=a("strong"),tdo=o("funnel"),ado=o(" \u2014 "),eN=a("a"),ndo=o("FunnelConfig"),sdo=o(" (Funnel Transformer model)"),ldo=l(),bg=a("li"),fce=a("strong"),ido=o("glpn"),ddo=o(" \u2014 "),oN=a("a"),mdo=o("GLPNConfig"),cdo=o(" (GLPN model)"),fdo=l(),vg=a("li"),gce=a("strong"),gdo=o("gpt2"),hdo=o(" \u2014 "),rN=a("a"),udo=o("GPT2Config"),pdo=o(" (OpenAI GPT-2 model)"),_do=l(),Fg=a("li"),hce=a("strong"),bdo=o("gpt_neo"),vdo=o(" \u2014 "),tN=a("a"),Fdo=o("GPTNeoConfig"),Tdo=o(" (GPT Neo model)"),Mdo=l(),Tg=a("li"),uce=a("strong"),Edo=o("gpt_neox"),Cdo=o(" \u2014 "),aN=a("a"),wdo=o("GPTNeoXConfig"),Ado=o(" (GPT NeoX model)"),Ldo=l(),Mg=a("li"),pce=a("strong"),ydo=o("gpt_neox_japanese"),xdo=o(" \u2014 "),nN=a("a"),$do=o("GPTNeoXJapaneseConfig"),kdo=o(" (GPT NeoX Japanese model)"),Sdo=l(),Eg=a("li"),_ce=a("strong"),Rdo=o("gptj"),Pdo=o(" \u2014 "),sN=a("a"),Bdo=o("GPTJConfig"),Ido=o(" (GPT-J model)"),Ndo=l(),Cg=a("li"),bce=a("strong"),qdo=o("groupvit"),jdo=o(" \u2014 "),lN=a("a"),Ddo=o("GroupViTConfig"),Gdo=o(" (GroupViT model)"),Odo=l(),wg=a("li"),vce=a("strong"),Vdo=o("hubert"),Xdo=o(" \u2014 "),iN=a("a"),zdo=o("HubertConfig"),Qdo=o(" (Hubert model)"),Wdo=l(),Ag=a("li"),Fce=a("strong"),Udo=o("ibert"),Hdo=o(" \u2014 "),dN=a("a"),Jdo=o("IBertConfig"),Ydo=o(" (I-BERT model)"),Kdo=l(),Lg=a("li"),Tce=a("strong"),Zdo=o("imagegpt"),emo=o(" \u2014 "),mN=a("a"),omo=o("ImageGPTConfig"),rmo=o(" (ImageGPT model)"),tmo=l(),yg=a("li"),Mce=a("strong"),amo=o("layoutlm"),nmo=o(" \u2014 "),cN=a("a"),smo=o("LayoutLMConfig"),lmo=o(" (LayoutLM model)"),imo=l(),xg=a("li"),Ece=a("strong"),dmo=o("layoutlmv2"),mmo=o(" \u2014 "),fN=a("a"),cmo=o("LayoutLMv2Config"),fmo=o(" (LayoutLMv2 model)"),gmo=l(),$g=a("li"),Cce=a("strong"),hmo=o("layoutlmv3"),umo=o(" \u2014 "),gN=a("a"),pmo=o("LayoutLMv3Config"),_mo=o(" (LayoutLMv3 model)"),bmo=l(),kg=a("li"),wce=a("strong"),vmo=o("led"),Fmo=o(" \u2014 "),hN=a("a"),Tmo=o("LEDConfig"),Mmo=o(" (LED model)"),Emo=l(),Sg=a("li"),Ace=a("strong"),Cmo=o("levit"),wmo=o(" \u2014 "),uN=a("a"),Amo=o("LevitConfig"),Lmo=o(" (LeViT model)"),ymo=l(),Rg=a("li"),Lce=a("strong"),xmo=o("longformer"),$mo=o(" \u2014 "),pN=a("a"),kmo=o("LongformerConfig"),Smo=o(" (Longformer model)"),Rmo=l(),Pg=a("li"),yce=a("strong"),Pmo=o("longt5"),Bmo=o(" \u2014 "),_N=a("a"),Imo=o("LongT5Config"),Nmo=o(" (LongT5 model)"),qmo=l(),Bg=a("li"),xce=a("strong"),jmo=o("luke"),Dmo=o(" \u2014 "),bN=a("a"),Gmo=o("LukeConfig"),Omo=o(" (LUKE model)"),Vmo=l(),Ig=a("li"),$ce=a("strong"),Xmo=o("lxmert"),zmo=o(" \u2014 "),vN=a("a"),Qmo=o("LxmertConfig"),Wmo=o(" (LXMERT model)"),Umo=l(),Ng=a("li"),kce=a("strong"),Hmo=o("m2m_100"),Jmo=o(" \u2014 "),FN=a("a"),Ymo=o("M2M100Config"),Kmo=o(" (M2M100 model)"),Zmo=l(),qg=a("li"),Sce=a("strong"),eco=o("marian"),oco=o(" \u2014 "),TN=a("a"),rco=o("MarianConfig"),tco=o(" (Marian model)"),aco=l(),jg=a("li"),Rce=a("strong"),nco=o("markuplm"),sco=o(" \u2014 "),MN=a("a"),lco=o("MarkupLMConfig"),ico=o(" (MarkupLM model)"),dco=l(),Dg=a("li"),Pce=a("strong"),mco=o("maskformer"),cco=o(" \u2014 "),EN=a("a"),fco=o("MaskFormerConfig"),gco=o(" (MaskFormer model)"),hco=l(),Gg=a("li"),Bce=a("strong"),uco=o("mbart"),pco=o(" \u2014 "),CN=a("a"),_co=o("MBartConfig"),bco=o(" (mBART model)"),vco=l(),Og=a("li"),Ice=a("strong"),Fco=o("mctct"),Tco=o(" \u2014 "),wN=a("a"),Mco=o("MCTCTConfig"),Eco=o(" (M-CTC-T model)"),Cco=l(),Vg=a("li"),Nce=a("strong"),wco=o("megatron-bert"),Aco=o(" \u2014 "),AN=a("a"),Lco=o("MegatronBertConfig"),yco=o(" (Megatron-BERT model)"),xco=l(),Xg=a("li"),qce=a("strong"),$co=o("mobilebert"),kco=o(" \u2014 "),LN=a("a"),Sco=o("MobileBertConfig"),Rco=o(" (MobileBERT model)"),Pco=l(),zg=a("li"),jce=a("strong"),Bco=o("mobilevit"),Ico=o(" \u2014 "),yN=a("a"),Nco=o("MobileViTConfig"),qco=o(" (MobileViT model)"),jco=l(),Qg=a("li"),Dce=a("strong"),Dco=o("mpnet"),Gco=o(" \u2014 "),xN=a("a"),Oco=o("MPNetConfig"),Vco=o(" (MPNet model)"),Xco=l(),Wg=a("li"),Gce=a("strong"),zco=o("mt5"),Qco=o(" \u2014 "),$N=a("a"),Wco=o("MT5Config"),Uco=o(" (MT5 model)"),Hco=l(),Ug=a("li"),Oce=a("strong"),Jco=o("mvp"),Yco=o(" \u2014 "),kN=a("a"),Kco=o("MvpConfig"),Zco=o(" (MVP model)"),efo=l(),Hg=a("li"),Vce=a("strong"),ofo=o("nezha"),rfo=o(" \u2014 "),SN=a("a"),tfo=o("NezhaConfig"),afo=o(" (Nezha model)"),nfo=l(),Jg=a("li"),Xce=a("strong"),sfo=o("nystromformer"),lfo=o(" \u2014 "),RN=a("a"),ifo=o("NystromformerConfig"),dfo=o(" (Nystr\xF6mformer model)"),mfo=l(),Yg=a("li"),zce=a("strong"),cfo=o("openai-gpt"),ffo=o(" \u2014 "),PN=a("a"),gfo=o("OpenAIGPTConfig"),hfo=o(" (OpenAI GPT model)"),ufo=l(),Kg=a("li"),Qce=a("strong"),pfo=o("opt"),_fo=o(" \u2014 "),BN=a("a"),bfo=o("OPTConfig"),vfo=o(" (OPT model)"),Ffo=l(),Zg=a("li"),Wce=a("strong"),Tfo=o("owlvit"),Mfo=o(" \u2014 "),IN=a("a"),Efo=o("OwlViTConfig"),Cfo=o(" (OWL-ViT model)"),wfo=l(),eh=a("li"),Uce=a("strong"),Afo=o("pegasus"),Lfo=o(" \u2014 "),NN=a("a"),yfo=o("PegasusConfig"),xfo=o(" (Pegasus model)"),$fo=l(),oh=a("li"),Hce=a("strong"),kfo=o("pegasus_x"),Sfo=o(" \u2014 "),qN=a("a"),Rfo=o("PegasusXConfig"),Pfo=o(" (PEGASUS-X model)"),Bfo=l(),rh=a("li"),Jce=a("strong"),Ifo=o("perceiver"),Nfo=o(" \u2014 "),jN=a("a"),qfo=o("PerceiverConfig"),jfo=o(" (Perceiver model)"),Dfo=l(),th=a("li"),Yce=a("strong"),Gfo=o("plbart"),Ofo=o(" \u2014 "),DN=a("a"),Vfo=o("PLBartConfig"),Xfo=o(" (PLBart model)"),zfo=l(),ah=a("li"),Kce=a("strong"),Qfo=o("poolformer"),Wfo=o(" \u2014 "),GN=a("a"),Ufo=o("PoolFormerConfig"),Hfo=o(" (PoolFormer model)"),Jfo=l(),nh=a("li"),Zce=a("strong"),Yfo=o("prophetnet"),Kfo=o(" \u2014 "),ON=a("a"),Zfo=o("ProphetNetConfig"),ego=o(" (ProphetNet model)"),ogo=l(),sh=a("li"),efe=a("strong"),rgo=o("qdqbert"),tgo=o(" \u2014 "),VN=a("a"),ago=o("QDQBertConfig"),ngo=o(" (QDQBert model)"),sgo=l(),lh=a("li"),ofe=a("strong"),lgo=o("rag"),igo=o(" \u2014 "),XN=a("a"),dgo=o("RagConfig"),mgo=o(" (RAG model)"),cgo=l(),ih=a("li"),rfe=a("strong"),fgo=o("realm"),ggo=o(" \u2014 "),zN=a("a"),hgo=o("RealmConfig"),ugo=o(" (REALM model)"),pgo=l(),dh=a("li"),tfe=a("strong"),_go=o("reformer"),bgo=o(" \u2014 "),QN=a("a"),vgo=o("ReformerConfig"),Fgo=o(" (Reformer model)"),Tgo=l(),mh=a("li"),afe=a("strong"),Mgo=o("regnet"),Ego=o(" \u2014 "),WN=a("a"),Cgo=o("RegNetConfig"),wgo=o(" (RegNet model)"),Ago=l(),ch=a("li"),nfe=a("strong"),Lgo=o("rembert"),ygo=o(" \u2014 "),UN=a("a"),xgo=o("RemBertConfig"),$go=o(" (RemBERT model)"),kgo=l(),fh=a("li"),sfe=a("strong"),Sgo=o("resnet"),Rgo=o(" \u2014 "),HN=a("a"),Pgo=o("ResNetConfig"),Bgo=o(" (ResNet model)"),Igo=l(),gh=a("li"),lfe=a("strong"),Ngo=o("retribert"),qgo=o(" \u2014 "),JN=a("a"),jgo=o("RetriBertConfig"),Dgo=o(" (RetriBERT model)"),Ggo=l(),hh=a("li"),ife=a("strong"),Ogo=o("roberta"),Vgo=o(" \u2014 "),YN=a("a"),Xgo=o("RobertaConfig"),zgo=o(" (RoBERTa model)"),Qgo=l(),uh=a("li"),dfe=a("strong"),Wgo=o("roformer"),Ugo=o(" \u2014 "),KN=a("a"),Hgo=o("RoFormerConfig"),Jgo=o(" (RoFormer model)"),Ygo=l(),ph=a("li"),mfe=a("strong"),Kgo=o("segformer"),Zgo=o(" \u2014 "),ZN=a("a"),eho=o("SegformerConfig"),oho=o(" (SegFormer model)"),rho=l(),_h=a("li"),cfe=a("strong"),tho=o("sew"),aho=o(" \u2014 "),eq=a("a"),nho=o("SEWConfig"),sho=o(" (SEW model)"),lho=l(),bh=a("li"),ffe=a("strong"),iho=o("sew-d"),dho=o(" \u2014 "),oq=a("a"),mho=o("SEWDConfig"),cho=o(" (SEW-D model)"),fho=l(),vh=a("li"),gfe=a("strong"),gho=o("speech-encoder-decoder"),hho=o(" \u2014 "),rq=a("a"),uho=o("SpeechEncoderDecoderConfig"),pho=o(" (Speech Encoder decoder model)"),_ho=l(),Fh=a("li"),hfe=a("strong"),bho=o("speech_to_text"),vho=o(" \u2014 "),tq=a("a"),Fho=o("Speech2TextConfig"),Tho=o(" (Speech2Text model)"),Mho=l(),Th=a("li"),ufe=a("strong"),Eho=o("speech_to_text_2"),Cho=o(" \u2014 "),aq=a("a"),who=o("Speech2Text2Config"),Aho=o(" (Speech2Text2 model)"),Lho=l(),Mh=a("li"),pfe=a("strong"),yho=o("splinter"),xho=o(" \u2014 "),nq=a("a"),$ho=o("SplinterConfig"),kho=o(" (Splinter model)"),Sho=l(),Eh=a("li"),_fe=a("strong"),Rho=o("squeezebert"),Pho=o(" \u2014 "),sq=a("a"),Bho=o("SqueezeBertConfig"),Iho=o(" (SqueezeBERT model)"),Nho=l(),Ch=a("li"),bfe=a("strong"),qho=o("swin"),jho=o(" \u2014 "),lq=a("a"),Dho=o("SwinConfig"),Gho=o(" (Swin Transformer model)"),Oho=l(),wh=a("li"),vfe=a("strong"),Vho=o("swinv2"),Xho=o(" \u2014 "),iq=a("a"),zho=o("Swinv2Config"),Qho=o(" (Swin Transformer V2 model)"),Who=l(),Ah=a("li"),Ffe=a("strong"),Uho=o("t5"),Hho=o(" \u2014 "),dq=a("a"),Jho=o("T5Config"),Yho=o(" (T5 model)"),Kho=l(),Lh=a("li"),Tfe=a("strong"),Zho=o("tapas"),euo=o(" \u2014 "),mq=a("a"),ouo=o("TapasConfig"),ruo=o(" (TAPAS model)"),tuo=l(),yh=a("li"),Mfe=a("strong"),auo=o("time_series_transformer"),nuo=o(" \u2014 "),cq=a("a"),suo=o("TimeSeriesTransformerConfig"),luo=o(" (Time Series Transformer model)"),iuo=l(),xh=a("li"),Efe=a("strong"),duo=o("trajectory_transformer"),muo=o(" \u2014 "),fq=a("a"),cuo=o("TrajectoryTransformerConfig"),fuo=o(" (Trajectory Transformer model)"),guo=l(),$h=a("li"),Cfe=a("strong"),huo=o("transfo-xl"),uuo=o(" \u2014 "),gq=a("a"),puo=o("TransfoXLConfig"),_uo=o(" (Transformer-XL model)"),buo=l(),kh=a("li"),wfe=a("strong"),vuo=o("trocr"),Fuo=o(" \u2014 "),hq=a("a"),Tuo=o("TrOCRConfig"),Muo=o(" (TrOCR model)"),Euo=l(),Sh=a("li"),Afe=a("strong"),Cuo=o("unispeech"),wuo=o(" \u2014 "),uq=a("a"),Auo=o("UniSpeechConfig"),Luo=o(" (UniSpeech model)"),yuo=l(),Rh=a("li"),Lfe=a("strong"),xuo=o("unispeech-sat"),$uo=o(" \u2014 "),pq=a("a"),kuo=o("UniSpeechSatConfig"),Suo=o(" (UniSpeechSat model)"),Ruo=l(),Ph=a("li"),yfe=a("strong"),Puo=o("van"),Buo=o(" \u2014 "),_q=a("a"),Iuo=o("VanConfig"),Nuo=o(" (VAN model)"),quo=l(),Bh=a("li"),xfe=a("strong"),juo=o("videomae"),Duo=o(" \u2014 "),bq=a("a"),Guo=o("VideoMAEConfig"),Ouo=o(" (VideoMAE model)"),Vuo=l(),Ih=a("li"),$fe=a("strong"),Xuo=o("vilt"),zuo=o(" \u2014 "),vq=a("a"),Quo=o("ViltConfig"),Wuo=o(" (ViLT model)"),Uuo=l(),Nh=a("li"),kfe=a("strong"),Huo=o("vision-encoder-decoder"),Juo=o(" \u2014 "),Fq=a("a"),Yuo=o("VisionEncoderDecoderConfig"),Kuo=o(" (Vision Encoder decoder model)"),Zuo=l(),qh=a("li"),Sfe=a("strong"),epo=o("vision-text-dual-encoder"),opo=o(" \u2014 "),Tq=a("a"),rpo=o("VisionTextDualEncoderConfig"),tpo=o(" (VisionTextDualEncoder model)"),apo=l(),jh=a("li"),Rfe=a("strong"),npo=o("visual_bert"),spo=o(" \u2014 "),Mq=a("a"),lpo=o("VisualBertConfig"),ipo=o(" (VisualBERT model)"),dpo=l(),Dh=a("li"),Pfe=a("strong"),mpo=o("vit"),cpo=o(" \u2014 "),Eq=a("a"),fpo=o("ViTConfig"),gpo=o(" (ViT model)"),hpo=l(),Gh=a("li"),Bfe=a("strong"),upo=o("vit_mae"),ppo=o(" \u2014 "),Cq=a("a"),_po=o("ViTMAEConfig"),bpo=o(" (ViTMAE model)"),vpo=l(),Oh=a("li"),Ife=a("strong"),Fpo=o("vit_msn"),Tpo=o(" \u2014 "),wq=a("a"),Mpo=o("ViTMSNConfig"),Epo=o(" (ViTMSN model)"),Cpo=l(),Vh=a("li"),Nfe=a("strong"),wpo=o("wav2vec2"),Apo=o(" \u2014 "),Aq=a("a"),Lpo=o("Wav2Vec2Config"),ypo=o(" (Wav2Vec2 model)"),xpo=l(),Xh=a("li"),qfe=a("strong"),$po=o("wav2vec2-conformer"),kpo=o(" \u2014 "),Lq=a("a"),Spo=o("Wav2Vec2ConformerConfig"),Rpo=o(" (Wav2Vec2-Conformer model)"),Ppo=l(),zh=a("li"),jfe=a("strong"),Bpo=o("wavlm"),Ipo=o(" \u2014 "),yq=a("a"),Npo=o("WavLMConfig"),qpo=o(" (WavLM model)"),jpo=l(),Qh=a("li"),Dfe=a("strong"),Dpo=o("whisper"),Gpo=o(" \u2014 "),xq=a("a"),Opo=o("WhisperConfig"),Vpo=o(" (Whisper model)"),Xpo=l(),Wh=a("li"),Gfe=a("strong"),zpo=o("xclip"),Qpo=o(" \u2014 "),$q=a("a"),Wpo=o("XCLIPConfig"),Upo=o(" (X-CLIP model)"),Hpo=l(),Uh=a("li"),Ofe=a("strong"),Jpo=o("xglm"),Ypo=o(" \u2014 "),kq=a("a"),Kpo=o("XGLMConfig"),Zpo=o(" (XGLM model)"),e_o=l(),Hh=a("li"),Vfe=a("strong"),o_o=o("xlm"),r_o=o(" \u2014 "),Sq=a("a"),t_o=o("XLMConfig"),a_o=o(" (XLM model)"),n_o=l(),Jh=a("li"),Xfe=a("strong"),s_o=o("xlm-prophetnet"),l_o=o(" \u2014 "),Rq=a("a"),i_o=o("XLMProphetNetConfig"),d_o=o(" (XLM-ProphetNet model)"),m_o=l(),Yh=a("li"),zfe=a("strong"),c_o=o("xlm-roberta"),f_o=o(" \u2014 "),Pq=a("a"),g_o=o("XLMRobertaConfig"),h_o=o(" (XLM-RoBERTa model)"),u_o=l(),Kh=a("li"),Qfe=a("strong"),p_o=o("xlm-roberta-xl"),__o=o(" \u2014 "),Bq=a("a"),b_o=o("XLMRobertaXLConfig"),v_o=o(" (XLM-RoBERTa-XL model)"),F_o=l(),Zh=a("li"),Wfe=a("strong"),T_o=o("xlnet"),M_o=o(" \u2014 "),Iq=a("a"),E_o=o("XLNetConfig"),C_o=o(" (XLNet model)"),w_o=l(),eu=a("li"),Ufe=a("strong"),A_o=o("yolos"),L_o=o(" \u2014 "),Nq=a("a"),y_o=o("YolosConfig"),x_o=o(" (YOLOS model)"),$_o=l(),ou=a("li"),Hfe=a("strong"),k_o=o("yoso"),S_o=o(" \u2014 "),qq=a("a"),R_o=o("YosoConfig"),P_o=o(" (YOSO model)"),B_o=l(),F(ru.$$.fragment),I_o=l(),tu=a("div"),F(ux.$$.fragment),N_o=l(),Jfe=a("p"),q_o=o("Register a new configuration for this class."),Meo=l(),gd=a("h2"),au=a("a"),Yfe=a("span"),F(px.$$.fragment),j_o=l(),Kfe=a("span"),D_o=o("AutoTokenizer"),Eeo=l(),ko=a("div"),F(_x.$$.fragment),G_o=l(),bx=a("p"),O_o=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),jq=a("a"),V_o=o("AutoTokenizer.from_pretrained()"),X_o=o(" class method."),z_o=l(),vx=a("p"),Q_o=o("This class cannot be instantiated directly using "),Zfe=a("code"),W_o=o("__init__()"),U_o=o(" (throws an error)."),H_o=l(),Br=a("div"),F(Fx.$$.fragment),J_o=l(),ege=a("p"),Y_o=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),K_o=l(),Ua=a("p"),Z_o=o("The tokenizer class to instantiate is selected based on the "),oge=a("code"),e1o=o("model_type"),o1o=o(` property of the config object (either
passed as an argument or loaded from `),rge=a("code"),r1o=o("pretrained_model_name_or_path"),t1o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tge=a("code"),a1o=o("pretrained_model_name_or_path"),n1o=o(":"),s1o=l(),k=a("ul"),ns=a("li"),age=a("strong"),l1o=o("albert"),i1o=o(" \u2014 "),Dq=a("a"),d1o=o("AlbertTokenizer"),m1o=o(" or "),Gq=a("a"),c1o=o("AlbertTokenizerFast"),f1o=o(" (ALBERT model)"),g1o=l(),ss=a("li"),nge=a("strong"),h1o=o("bart"),u1o=o(" \u2014 "),Oq=a("a"),p1o=o("BartTokenizer"),_1o=o(" or "),Vq=a("a"),b1o=o("BartTokenizerFast"),v1o=o(" (BART model)"),F1o=l(),ls=a("li"),sge=a("strong"),T1o=o("barthez"),M1o=o(" \u2014 "),Xq=a("a"),E1o=o("BarthezTokenizer"),C1o=o(" or "),zq=a("a"),w1o=o("BarthezTokenizerFast"),A1o=o(" (BARThez model)"),L1o=l(),nu=a("li"),lge=a("strong"),y1o=o("bartpho"),x1o=o(" \u2014 "),Qq=a("a"),$1o=o("BartphoTokenizer"),k1o=o(" (BARTpho model)"),S1o=l(),is=a("li"),ige=a("strong"),R1o=o("bert"),P1o=o(" \u2014 "),Wq=a("a"),B1o=o("BertTokenizer"),I1o=o(" or "),Uq=a("a"),N1o=o("BertTokenizerFast"),q1o=o(" (BERT model)"),j1o=l(),su=a("li"),dge=a("strong"),D1o=o("bert-generation"),G1o=o(" \u2014 "),Hq=a("a"),O1o=o("BertGenerationTokenizer"),V1o=o(" (Bert Generation model)"),X1o=l(),lu=a("li"),mge=a("strong"),z1o=o("bert-japanese"),Q1o=o(" \u2014 "),Jq=a("a"),W1o=o("BertJapaneseTokenizer"),U1o=o(" (BertJapanese model)"),H1o=l(),iu=a("li"),cge=a("strong"),J1o=o("bertweet"),Y1o=o(" \u2014 "),Yq=a("a"),K1o=o("BertweetTokenizer"),Z1o=o(" (BERTweet model)"),e2o=l(),ds=a("li"),fge=a("strong"),o2o=o("big_bird"),r2o=o(" \u2014 "),Kq=a("a"),t2o=o("BigBirdTokenizer"),a2o=o(" or "),Zq=a("a"),n2o=o("BigBirdTokenizerFast"),s2o=o(" (BigBird model)"),l2o=l(),ms=a("li"),gge=a("strong"),i2o=o("bigbird_pegasus"),d2o=o(" \u2014 "),ej=a("a"),m2o=o("PegasusTokenizer"),c2o=o(" or "),oj=a("a"),f2o=o("PegasusTokenizerFast"),g2o=o(" (BigBird-Pegasus model)"),h2o=l(),cs=a("li"),hge=a("strong"),u2o=o("blenderbot"),p2o=o(" \u2014 "),rj=a("a"),_2o=o("BlenderbotTokenizer"),b2o=o(" or "),tj=a("a"),v2o=o("BlenderbotTokenizerFast"),F2o=o(" (Blenderbot model)"),T2o=l(),du=a("li"),uge=a("strong"),M2o=o("blenderbot-small"),E2o=o(" \u2014 "),aj=a("a"),C2o=o("BlenderbotSmallTokenizer"),w2o=o(" (BlenderbotSmall model)"),A2o=l(),mu=a("li"),pge=a("strong"),L2o=o("bloom"),y2o=o(" \u2014 "),nj=a("a"),x2o=o("BloomTokenizerFast"),$2o=o(" (BLOOM model)"),k2o=l(),cu=a("li"),_ge=a("strong"),S2o=o("byt5"),R2o=o(" \u2014 "),sj=a("a"),P2o=o("ByT5Tokenizer"),B2o=o(" (ByT5 model)"),I2o=l(),fs=a("li"),bge=a("strong"),N2o=o("camembert"),q2o=o(" \u2014 "),lj=a("a"),j2o=o("CamembertTokenizer"),D2o=o(" or "),ij=a("a"),G2o=o("CamembertTokenizerFast"),O2o=o(" (CamemBERT model)"),V2o=l(),fu=a("li"),vge=a("strong"),X2o=o("canine"),z2o=o(" \u2014 "),dj=a("a"),Q2o=o("CanineTokenizer"),W2o=o(" (CANINE model)"),U2o=l(),gs=a("li"),Fge=a("strong"),H2o=o("clip"),J2o=o(" \u2014 "),mj=a("a"),Y2o=o("CLIPTokenizer"),K2o=o(" or "),cj=a("a"),Z2o=o("CLIPTokenizerFast"),ebo=o(" (CLIP model)"),obo=l(),hs=a("li"),Tge=a("strong"),rbo=o("codegen"),tbo=o(" \u2014 "),fj=a("a"),abo=o("CodeGenTokenizer"),nbo=o(" or "),gj=a("a"),sbo=o("CodeGenTokenizerFast"),lbo=o(" (CodeGen model)"),ibo=l(),us=a("li"),Mge=a("strong"),dbo=o("convbert"),mbo=o(" \u2014 "),hj=a("a"),cbo=o("ConvBertTokenizer"),fbo=o(" or "),uj=a("a"),gbo=o("ConvBertTokenizerFast"),hbo=o(" (ConvBERT model)"),ubo=l(),ps=a("li"),Ege=a("strong"),pbo=o("cpm"),_bo=o(" \u2014 "),pj=a("a"),bbo=o("CpmTokenizer"),vbo=o(" or "),_j=a("a"),Fbo=o("CpmTokenizerFast"),Tbo=o(" (CPM model)"),Mbo=l(),gu=a("li"),Cge=a("strong"),Ebo=o("ctrl"),Cbo=o(" \u2014 "),bj=a("a"),wbo=o("CTRLTokenizer"),Abo=o(" (CTRL model)"),Lbo=l(),_s=a("li"),wge=a("strong"),ybo=o("data2vec-text"),xbo=o(" \u2014 "),vj=a("a"),$bo=o("RobertaTokenizer"),kbo=o(" or "),Fj=a("a"),Sbo=o("RobertaTokenizerFast"),Rbo=o(" (Data2VecText model)"),Pbo=l(),bs=a("li"),Age=a("strong"),Bbo=o("deberta"),Ibo=o(" \u2014 "),Tj=a("a"),Nbo=o("DebertaTokenizer"),qbo=o(" or "),Mj=a("a"),jbo=o("DebertaTokenizerFast"),Dbo=o(" (DeBERTa model)"),Gbo=l(),vs=a("li"),Lge=a("strong"),Obo=o("deberta-v2"),Vbo=o(" \u2014 "),Ej=a("a"),Xbo=o("DebertaV2Tokenizer"),zbo=o(" or "),Cj=a("a"),Qbo=o("DebertaV2TokenizerFast"),Wbo=o(" (DeBERTa-v2 model)"),Ubo=l(),Fs=a("li"),yge=a("strong"),Hbo=o("distilbert"),Jbo=o(" \u2014 "),wj=a("a"),Ybo=o("DistilBertTokenizer"),Kbo=o(" or "),Aj=a("a"),Zbo=o("DistilBertTokenizerFast"),evo=o(" (DistilBERT model)"),ovo=l(),Ts=a("li"),xge=a("strong"),rvo=o("dpr"),tvo=o(" \u2014 "),Lj=a("a"),avo=o("DPRQuestionEncoderTokenizer"),nvo=o(" or "),yj=a("a"),svo=o("DPRQuestionEncoderTokenizerFast"),lvo=o(" (DPR model)"),ivo=l(),Ms=a("li"),$ge=a("strong"),dvo=o("electra"),mvo=o(" \u2014 "),xj=a("a"),cvo=o("ElectraTokenizer"),fvo=o(" or "),$j=a("a"),gvo=o("ElectraTokenizerFast"),hvo=o(" (ELECTRA model)"),uvo=l(),Es=a("li"),kge=a("strong"),pvo=o("ernie"),_vo=o(" \u2014 "),kj=a("a"),bvo=o("BertTokenizer"),vvo=o(" or "),Sj=a("a"),Fvo=o("BertTokenizerFast"),Tvo=o(" (ERNIE model)"),Mvo=l(),hu=a("li"),Sge=a("strong"),Evo=o("flaubert"),Cvo=o(" \u2014 "),Rj=a("a"),wvo=o("FlaubertTokenizer"),Avo=o(" (FlauBERT model)"),Lvo=l(),Cs=a("li"),Rge=a("strong"),yvo=o("fnet"),xvo=o(" \u2014 "),Pj=a("a"),$vo=o("FNetTokenizer"),kvo=o(" or "),Bj=a("a"),Svo=o("FNetTokenizerFast"),Rvo=o(" (FNet model)"),Pvo=l(),uu=a("li"),Pge=a("strong"),Bvo=o("fsmt"),Ivo=o(" \u2014 "),Ij=a("a"),Nvo=o("FSMTTokenizer"),qvo=o(" (FairSeq Machine-Translation model)"),jvo=l(),ws=a("li"),Bge=a("strong"),Dvo=o("funnel"),Gvo=o(" \u2014 "),Nj=a("a"),Ovo=o("FunnelTokenizer"),Vvo=o(" or "),qj=a("a"),Xvo=o("FunnelTokenizerFast"),zvo=o(" (Funnel Transformer model)"),Qvo=l(),As=a("li"),Ige=a("strong"),Wvo=o("gpt2"),Uvo=o(" \u2014 "),jj=a("a"),Hvo=o("GPT2Tokenizer"),Jvo=o(" or "),Dj=a("a"),Yvo=o("GPT2TokenizerFast"),Kvo=o(" (OpenAI GPT-2 model)"),Zvo=l(),Ls=a("li"),Nge=a("strong"),eFo=o("gpt_neo"),oFo=o(" \u2014 "),Gj=a("a"),rFo=o("GPT2Tokenizer"),tFo=o(" or "),Oj=a("a"),aFo=o("GPT2TokenizerFast"),nFo=o(" (GPT Neo model)"),sFo=l(),pu=a("li"),qge=a("strong"),lFo=o("gpt_neox"),iFo=o(" \u2014 "),Vj=a("a"),dFo=o("GPTNeoXTokenizerFast"),mFo=o(" (GPT NeoX model)"),cFo=l(),_u=a("li"),jge=a("strong"),fFo=o("gpt_neox_japanese"),gFo=o(" \u2014 "),Xj=a("a"),hFo=o("GPTNeoXJapaneseTokenizer"),uFo=o(" (GPT NeoX Japanese model)"),pFo=l(),ys=a("li"),Dge=a("strong"),_Fo=o("gptj"),bFo=o(" \u2014 "),zj=a("a"),vFo=o("GPT2Tokenizer"),FFo=o(" or "),Qj=a("a"),TFo=o("GPT2TokenizerFast"),MFo=o(" (GPT-J model)"),EFo=l(),xs=a("li"),Gge=a("strong"),CFo=o("groupvit"),wFo=o(" \u2014 "),Wj=a("a"),AFo=o("CLIPTokenizer"),LFo=o(" or "),Uj=a("a"),yFo=o("CLIPTokenizerFast"),xFo=o(" (GroupViT model)"),$Fo=l(),$s=a("li"),Oge=a("strong"),kFo=o("herbert"),SFo=o(" \u2014 "),Hj=a("a"),RFo=o("HerbertTokenizer"),PFo=o(" or "),Jj=a("a"),BFo=o("HerbertTokenizerFast"),IFo=o(" (HerBERT model)"),NFo=l(),bu=a("li"),Vge=a("strong"),qFo=o("hubert"),jFo=o(" \u2014 "),Yj=a("a"),DFo=o("Wav2Vec2CTCTokenizer"),GFo=o(" (Hubert model)"),OFo=l(),ks=a("li"),Xge=a("strong"),VFo=o("ibert"),XFo=o(" \u2014 "),Kj=a("a"),zFo=o("RobertaTokenizer"),QFo=o(" or "),Zj=a("a"),WFo=o("RobertaTokenizerFast"),UFo=o(" (I-BERT model)"),HFo=l(),Ss=a("li"),zge=a("strong"),JFo=o("layoutlm"),YFo=o(" \u2014 "),eD=a("a"),KFo=o("LayoutLMTokenizer"),ZFo=o(" or "),oD=a("a"),eTo=o("LayoutLMTokenizerFast"),oTo=o(" (LayoutLM model)"),rTo=l(),Rs=a("li"),Qge=a("strong"),tTo=o("layoutlmv2"),aTo=o(" \u2014 "),rD=a("a"),nTo=o("LayoutLMv2Tokenizer"),sTo=o(" or "),tD=a("a"),lTo=o("LayoutLMv2TokenizerFast"),iTo=o(" (LayoutLMv2 model)"),dTo=l(),Ps=a("li"),Wge=a("strong"),mTo=o("layoutlmv3"),cTo=o(" \u2014 "),aD=a("a"),fTo=o("LayoutLMv3Tokenizer"),gTo=o(" or "),nD=a("a"),hTo=o("LayoutLMv3TokenizerFast"),uTo=o(" (LayoutLMv3 model)"),pTo=l(),Bs=a("li"),Uge=a("strong"),_To=o("layoutxlm"),bTo=o(" \u2014 "),sD=a("a"),vTo=o("LayoutXLMTokenizer"),FTo=o(" or "),lD=a("a"),TTo=o("LayoutXLMTokenizerFast"),MTo=o(" (LayoutXLM model)"),ETo=l(),Is=a("li"),Hge=a("strong"),CTo=o("led"),wTo=o(" \u2014 "),iD=a("a"),ATo=o("LEDTokenizer"),LTo=o(" or "),dD=a("a"),yTo=o("LEDTokenizerFast"),xTo=o(" (LED model)"),$To=l(),Ns=a("li"),Jge=a("strong"),kTo=o("longformer"),STo=o(" \u2014 "),mD=a("a"),RTo=o("LongformerTokenizer"),PTo=o(" or "),cD=a("a"),BTo=o("LongformerTokenizerFast"),ITo=o(" (Longformer model)"),NTo=l(),qs=a("li"),Yge=a("strong"),qTo=o("longt5"),jTo=o(" \u2014 "),fD=a("a"),DTo=o("T5Tokenizer"),GTo=o(" or "),gD=a("a"),OTo=o("T5TokenizerFast"),VTo=o(" (LongT5 model)"),XTo=l(),vu=a("li"),Kge=a("strong"),zTo=o("luke"),QTo=o(" \u2014 "),hD=a("a"),WTo=o("LukeTokenizer"),UTo=o(" (LUKE model)"),HTo=l(),js=a("li"),Zge=a("strong"),JTo=o("lxmert"),YTo=o(" \u2014 "),uD=a("a"),KTo=o("LxmertTokenizer"),ZTo=o(" or "),pD=a("a"),eMo=o("LxmertTokenizerFast"),oMo=o(" (LXMERT model)"),rMo=l(),Fu=a("li"),ehe=a("strong"),tMo=o("m2m_100"),aMo=o(" \u2014 "),_D=a("a"),nMo=o("M2M100Tokenizer"),sMo=o(" (M2M100 model)"),lMo=l(),Tu=a("li"),ohe=a("strong"),iMo=o("marian"),dMo=o(" \u2014 "),bD=a("a"),mMo=o("MarianTokenizer"),cMo=o(" (Marian model)"),fMo=l(),Ds=a("li"),rhe=a("strong"),gMo=o("mbart"),hMo=o(" \u2014 "),vD=a("a"),uMo=o("MBartTokenizer"),pMo=o(" or "),FD=a("a"),_Mo=o("MBartTokenizerFast"),bMo=o(" (mBART model)"),vMo=l(),Gs=a("li"),the=a("strong"),FMo=o("mbart50"),TMo=o(" \u2014 "),TD=a("a"),MMo=o("MBart50Tokenizer"),EMo=o(" or "),MD=a("a"),CMo=o("MBart50TokenizerFast"),wMo=o(" (mBART-50 model)"),AMo=l(),Os=a("li"),ahe=a("strong"),LMo=o("megatron-bert"),yMo=o(" \u2014 "),ED=a("a"),xMo=o("BertTokenizer"),$Mo=o(" or "),CD=a("a"),kMo=o("BertTokenizerFast"),SMo=o(" (Megatron-BERT model)"),RMo=l(),Mu=a("li"),nhe=a("strong"),PMo=o("mluke"),BMo=o(" \u2014 "),wD=a("a"),IMo=o("MLukeTokenizer"),NMo=o(" (mLUKE model)"),qMo=l(),Vs=a("li"),she=a("strong"),jMo=o("mobilebert"),DMo=o(" \u2014 "),AD=a("a"),GMo=o("MobileBertTokenizer"),OMo=o(" or "),LD=a("a"),VMo=o("MobileBertTokenizerFast"),XMo=o(" (MobileBERT model)"),zMo=l(),Xs=a("li"),lhe=a("strong"),QMo=o("mpnet"),WMo=o(" \u2014 "),yD=a("a"),UMo=o("MPNetTokenizer"),HMo=o(" or "),xD=a("a"),JMo=o("MPNetTokenizerFast"),YMo=o(" (MPNet model)"),KMo=l(),zs=a("li"),ihe=a("strong"),ZMo=o("mt5"),eEo=o(" \u2014 "),$D=a("a"),oEo=o("MT5Tokenizer"),rEo=o(" or "),kD=a("a"),tEo=o("MT5TokenizerFast"),aEo=o(" (MT5 model)"),nEo=l(),Qs=a("li"),dhe=a("strong"),sEo=o("mvp"),lEo=o(" \u2014 "),SD=a("a"),iEo=o("MvpTokenizer"),dEo=o(" or "),RD=a("a"),mEo=o("MvpTokenizerFast"),cEo=o(" (MVP model)"),fEo=l(),Ws=a("li"),mhe=a("strong"),gEo=o("nezha"),hEo=o(" \u2014 "),PD=a("a"),uEo=o("BertTokenizer"),pEo=o(" or "),BD=a("a"),_Eo=o("BertTokenizerFast"),bEo=o(" (Nezha model)"),vEo=l(),Us=a("li"),che=a("strong"),FEo=o("nllb"),TEo=o(" \u2014 "),ID=a("a"),MEo=o("NllbTokenizer"),EEo=o(" or "),ND=a("a"),CEo=o("NllbTokenizerFast"),wEo=o(" (NLLB model)"),AEo=l(),Hs=a("li"),fhe=a("strong"),LEo=o("nystromformer"),yEo=o(" \u2014 "),qD=a("a"),xEo=o("AlbertTokenizer"),$Eo=o(" or "),jD=a("a"),kEo=o("AlbertTokenizerFast"),SEo=o(" (Nystr\xF6mformer model)"),REo=l(),Js=a("li"),ghe=a("strong"),PEo=o("openai-gpt"),BEo=o(" \u2014 "),DD=a("a"),IEo=o("OpenAIGPTTokenizer"),NEo=o(" or "),GD=a("a"),qEo=o("OpenAIGPTTokenizerFast"),jEo=o(" (OpenAI GPT model)"),DEo=l(),Eu=a("li"),hhe=a("strong"),GEo=o("opt"),OEo=o(" \u2014 "),OD=a("a"),VEo=o("GPT2Tokenizer"),XEo=o(" (OPT model)"),zEo=l(),Ys=a("li"),uhe=a("strong"),QEo=o("owlvit"),WEo=o(" \u2014 "),VD=a("a"),UEo=o("CLIPTokenizer"),HEo=o(" or "),XD=a("a"),JEo=o("CLIPTokenizerFast"),YEo=o(" (OWL-ViT model)"),KEo=l(),Ks=a("li"),phe=a("strong"),ZEo=o("pegasus"),e4o=o(" \u2014 "),zD=a("a"),o4o=o("PegasusTokenizer"),r4o=o(" or "),QD=a("a"),t4o=o("PegasusTokenizerFast"),a4o=o(" (Pegasus model)"),n4o=l(),Cu=a("li"),_he=a("strong"),s4o=o("perceiver"),l4o=o(" \u2014 "),WD=a("a"),i4o=o("PerceiverTokenizer"),d4o=o(" (Perceiver model)"),m4o=l(),wu=a("li"),bhe=a("strong"),c4o=o("phobert"),f4o=o(" \u2014 "),UD=a("a"),g4o=o("PhobertTokenizer"),h4o=o(" (PhoBERT model)"),u4o=l(),Au=a("li"),vhe=a("strong"),p4o=o("plbart"),_4o=o(" \u2014 "),HD=a("a"),b4o=o("PLBartTokenizer"),v4o=o(" (PLBart model)"),F4o=l(),Lu=a("li"),Fhe=a("strong"),T4o=o("prophetnet"),M4o=o(" \u2014 "),JD=a("a"),E4o=o("ProphetNetTokenizer"),C4o=o(" (ProphetNet model)"),w4o=l(),Zs=a("li"),The=a("strong"),A4o=o("qdqbert"),L4o=o(" \u2014 "),YD=a("a"),y4o=o("BertTokenizer"),x4o=o(" or "),KD=a("a"),$4o=o("BertTokenizerFast"),k4o=o(" (QDQBert model)"),S4o=l(),yu=a("li"),Mhe=a("strong"),R4o=o("rag"),P4o=o(" \u2014 "),ZD=a("a"),B4o=o("RagTokenizer"),I4o=o(" (RAG model)"),N4o=l(),el=a("li"),Ehe=a("strong"),q4o=o("realm"),j4o=o(" \u2014 "),eG=a("a"),D4o=o("RealmTokenizer"),G4o=o(" or "),oG=a("a"),O4o=o("RealmTokenizerFast"),V4o=o(" (REALM model)"),X4o=l(),ol=a("li"),Che=a("strong"),z4o=o("reformer"),Q4o=o(" \u2014 "),rG=a("a"),W4o=o("ReformerTokenizer"),U4o=o(" or "),tG=a("a"),H4o=o("ReformerTokenizerFast"),J4o=o(" (Reformer model)"),Y4o=l(),rl=a("li"),whe=a("strong"),K4o=o("rembert"),Z4o=o(" \u2014 "),aG=a("a"),eCo=o("RemBertTokenizer"),oCo=o(" or "),nG=a("a"),rCo=o("RemBertTokenizerFast"),tCo=o(" (RemBERT model)"),aCo=l(),tl=a("li"),Ahe=a("strong"),nCo=o("retribert"),sCo=o(" \u2014 "),sG=a("a"),lCo=o("RetriBertTokenizer"),iCo=o(" or "),lG=a("a"),dCo=o("RetriBertTokenizerFast"),mCo=o(" (RetriBERT model)"),cCo=l(),al=a("li"),Lhe=a("strong"),fCo=o("roberta"),gCo=o(" \u2014 "),iG=a("a"),hCo=o("RobertaTokenizer"),uCo=o(" or "),dG=a("a"),pCo=o("RobertaTokenizerFast"),_Co=o(" (RoBERTa model)"),bCo=l(),nl=a("li"),yhe=a("strong"),vCo=o("roformer"),FCo=o(" \u2014 "),mG=a("a"),TCo=o("RoFormerTokenizer"),MCo=o(" or "),cG=a("a"),ECo=o("RoFormerTokenizerFast"),CCo=o(" (RoFormer model)"),wCo=l(),xu=a("li"),xhe=a("strong"),ACo=o("speech_to_text"),LCo=o(" \u2014 "),fG=a("a"),yCo=o("Speech2TextTokenizer"),xCo=o(" (Speech2Text model)"),$Co=l(),$u=a("li"),$he=a("strong"),kCo=o("speech_to_text_2"),SCo=o(" \u2014 "),gG=a("a"),RCo=o("Speech2Text2Tokenizer"),PCo=o(" (Speech2Text2 model)"),BCo=l(),sl=a("li"),khe=a("strong"),ICo=o("splinter"),NCo=o(" \u2014 "),hG=a("a"),qCo=o("SplinterTokenizer"),jCo=o(" or "),uG=a("a"),DCo=o("SplinterTokenizerFast"),GCo=o(" (Splinter model)"),OCo=l(),ll=a("li"),She=a("strong"),VCo=o("squeezebert"),XCo=o(" \u2014 "),pG=a("a"),zCo=o("SqueezeBertTokenizer"),QCo=o(" or "),_G=a("a"),WCo=o("SqueezeBertTokenizerFast"),UCo=o(" (SqueezeBERT model)"),HCo=l(),il=a("li"),Rhe=a("strong"),JCo=o("t5"),YCo=o(" \u2014 "),bG=a("a"),KCo=o("T5Tokenizer"),ZCo=o(" or "),vG=a("a"),e3o=o("T5TokenizerFast"),o3o=o(" (T5 model)"),r3o=l(),ku=a("li"),Phe=a("strong"),t3o=o("tapas"),a3o=o(" \u2014 "),FG=a("a"),n3o=o("TapasTokenizer"),s3o=o(" (TAPAS model)"),l3o=l(),Su=a("li"),Bhe=a("strong"),i3o=o("tapex"),d3o=o(" \u2014 "),TG=a("a"),m3o=o("TapexTokenizer"),c3o=o(" (TAPEX model)"),f3o=l(),Ru=a("li"),Ihe=a("strong"),g3o=o("transfo-xl"),h3o=o(" \u2014 "),MG=a("a"),u3o=o("TransfoXLTokenizer"),p3o=o(" (Transformer-XL model)"),_3o=l(),dl=a("li"),Nhe=a("strong"),b3o=o("vilt"),v3o=o(" \u2014 "),EG=a("a"),F3o=o("BertTokenizer"),T3o=o(" or "),CG=a("a"),M3o=o("BertTokenizerFast"),E3o=o(" (ViLT model)"),C3o=l(),ml=a("li"),qhe=a("strong"),w3o=o("visual_bert"),A3o=o(" \u2014 "),wG=a("a"),L3o=o("BertTokenizer"),y3o=o(" or "),AG=a("a"),x3o=o("BertTokenizerFast"),$3o=o(" (VisualBERT model)"),k3o=l(),Pu=a("li"),jhe=a("strong"),S3o=o("wav2vec2"),R3o=o(" \u2014 "),LG=a("a"),P3o=o("Wav2Vec2CTCTokenizer"),B3o=o(" (Wav2Vec2 model)"),I3o=l(),Bu=a("li"),Dhe=a("strong"),N3o=o("wav2vec2-conformer"),q3o=o(" \u2014 "),yG=a("a"),j3o=o("Wav2Vec2CTCTokenizer"),D3o=o(" (Wav2Vec2-Conformer model)"),G3o=l(),Iu=a("li"),Ghe=a("strong"),O3o=o("wav2vec2_phoneme"),V3o=o(" \u2014 "),xG=a("a"),X3o=o("Wav2Vec2PhonemeCTCTokenizer"),z3o=o(" (Wav2Vec2Phoneme model)"),Q3o=l(),Nu=a("li"),Ohe=a("strong"),W3o=o("whisper"),U3o=o(" \u2014 "),$G=a("a"),H3o=o("WhisperTokenizer"),J3o=o(" (Whisper model)"),Y3o=l(),cl=a("li"),Vhe=a("strong"),K3o=o("xclip"),Z3o=o(" \u2014 "),kG=a("a"),e5o=o("CLIPTokenizer"),o5o=o(" or "),SG=a("a"),r5o=o("CLIPTokenizerFast"),t5o=o(" (X-CLIP model)"),a5o=l(),fl=a("li"),Xhe=a("strong"),n5o=o("xglm"),s5o=o(" \u2014 "),RG=a("a"),l5o=o("XGLMTokenizer"),i5o=o(" or "),PG=a("a"),d5o=o("XGLMTokenizerFast"),m5o=o(" (XGLM model)"),c5o=l(),qu=a("li"),zhe=a("strong"),f5o=o("xlm"),g5o=o(" \u2014 "),BG=a("a"),h5o=o("XLMTokenizer"),u5o=o(" (XLM model)"),p5o=l(),ju=a("li"),Qhe=a("strong"),_5o=o("xlm-prophetnet"),b5o=o(" \u2014 "),IG=a("a"),v5o=o("XLMProphetNetTokenizer"),F5o=o(" (XLM-ProphetNet model)"),T5o=l(),gl=a("li"),Whe=a("strong"),M5o=o("xlm-roberta"),E5o=o(" \u2014 "),NG=a("a"),C5o=o("XLMRobertaTokenizer"),w5o=o(" or "),qG=a("a"),A5o=o("XLMRobertaTokenizerFast"),L5o=o(" (XLM-RoBERTa model)"),y5o=l(),hl=a("li"),Uhe=a("strong"),x5o=o("xlm-roberta-xl"),$5o=o(" \u2014 "),jG=a("a"),k5o=o("XLMRobertaTokenizer"),S5o=o(" or "),DG=a("a"),R5o=o("XLMRobertaTokenizerFast"),P5o=o(" (XLM-RoBERTa-XL model)"),B5o=l(),ul=a("li"),Hhe=a("strong"),I5o=o("xlnet"),N5o=o(" \u2014 "),GG=a("a"),q5o=o("XLNetTokenizer"),j5o=o(" or "),OG=a("a"),D5o=o("XLNetTokenizerFast"),G5o=o(" (XLNet model)"),O5o=l(),pl=a("li"),Jhe=a("strong"),V5o=o("yoso"),X5o=o(" \u2014 "),VG=a("a"),z5o=o("AlbertTokenizer"),Q5o=o(" or "),XG=a("a"),W5o=o("AlbertTokenizerFast"),U5o=o(" (YOSO model)"),H5o=l(),F(Du.$$.fragment),J5o=l(),Gu=a("div"),F(Tx.$$.fragment),Y5o=l(),Yhe=a("p"),K5o=o("Register a new tokenizer in this mapping."),Ceo=l(),hd=a("h2"),Ou=a("a"),Khe=a("span"),F(Mx.$$.fragment),Z5o=l(),Zhe=a("span"),e0o=o("AutoFeatureExtractor"),weo=l(),So=a("div"),F(Ex.$$.fragment),o0o=l(),Cx=a("p"),r0o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),zG=a("a"),t0o=o("AutoFeatureExtractor.from_pretrained()"),a0o=o(" class method."),n0o=l(),wx=a("p"),s0o=o("This class cannot be instantiated directly using "),eue=a("code"),l0o=o("__init__()"),i0o=o(" (throws an error)."),d0o=l(),Ye=a("div"),F(Ax.$$.fragment),m0o=l(),oue=a("p"),c0o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),f0o=l(),Ha=a("p"),g0o=o("The feature extractor class to instantiate is selected based on the "),rue=a("code"),h0o=o("model_type"),u0o=o(` property of the config object
(either passed as an argument or loaded from `),tue=a("code"),p0o=o("pretrained_model_name_or_path"),_0o=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),aue=a("code"),b0o=o("pretrained_model_name_or_path"),v0o=o(":"),F0o=l(),z=a("ul"),Vu=a("li"),nue=a("strong"),T0o=o("beit"),M0o=o(" \u2014 "),QG=a("a"),E0o=o("BeitFeatureExtractor"),C0o=o(" (BEiT model)"),w0o=l(),Xu=a("li"),sue=a("strong"),A0o=o("clip"),L0o=o(" \u2014 "),WG=a("a"),y0o=o("CLIPFeatureExtractor"),x0o=o(" (CLIP model)"),$0o=l(),zu=a("li"),lue=a("strong"),k0o=o("conditional_detr"),S0o=o(" \u2014 "),UG=a("a"),R0o=o("ConditionalDetrFeatureExtractor"),P0o=o(" (Conditional DETR model)"),B0o=l(),Qu=a("li"),iue=a("strong"),I0o=o("convnext"),N0o=o(" \u2014 "),HG=a("a"),q0o=o("ConvNextFeatureExtractor"),j0o=o(" (ConvNeXT model)"),D0o=l(),Wu=a("li"),due=a("strong"),G0o=o("cvt"),O0o=o(" \u2014 "),JG=a("a"),V0o=o("ConvNextFeatureExtractor"),X0o=o(" (CvT model)"),z0o=l(),Uu=a("li"),mue=a("strong"),Q0o=o("data2vec-audio"),W0o=o(" \u2014 "),YG=a("a"),U0o=o("Wav2Vec2FeatureExtractor"),H0o=o(" (Data2VecAudio model)"),J0o=l(),Hu=a("li"),cue=a("strong"),Y0o=o("data2vec-vision"),K0o=o(" \u2014 "),KG=a("a"),Z0o=o("BeitFeatureExtractor"),ewo=o(" (Data2VecVision model)"),owo=l(),Ju=a("li"),fue=a("strong"),rwo=o("deformable_detr"),two=o(" \u2014 "),ZG=a("a"),awo=o("DeformableDetrFeatureExtractor"),nwo=o(" (Deformable DETR model)"),swo=l(),Yu=a("li"),gue=a("strong"),lwo=o("deit"),iwo=o(" \u2014 "),eO=a("a"),dwo=o("DeiTFeatureExtractor"),mwo=o(" (DeiT model)"),cwo=l(),Ku=a("li"),hue=a("strong"),fwo=o("detr"),gwo=o(" \u2014 "),oO=a("a"),hwo=o("DetrFeatureExtractor"),uwo=o(" (DETR model)"),pwo=l(),Zu=a("li"),uue=a("strong"),_wo=o("donut"),bwo=o(" \u2014 "),rO=a("a"),vwo=o("DonutFeatureExtractor"),Fwo=o(" (Donut model)"),Two=l(),ep=a("li"),pue=a("strong"),Mwo=o("dpt"),Ewo=o(" \u2014 "),tO=a("a"),Cwo=o("DPTFeatureExtractor"),wwo=o(" (DPT model)"),Awo=l(),op=a("li"),_ue=a("strong"),Lwo=o("flava"),ywo=o(" \u2014 "),aO=a("a"),xwo=o("FlavaFeatureExtractor"),$wo=o(" (FLAVA model)"),kwo=l(),rp=a("li"),bue=a("strong"),Swo=o("glpn"),Rwo=o(" \u2014 "),nO=a("a"),Pwo=o("GLPNFeatureExtractor"),Bwo=o(" (GLPN model)"),Iwo=l(),tp=a("li"),vue=a("strong"),Nwo=o("groupvit"),qwo=o(" \u2014 "),sO=a("a"),jwo=o("CLIPFeatureExtractor"),Dwo=o(" (GroupViT model)"),Gwo=l(),ap=a("li"),Fue=a("strong"),Owo=o("hubert"),Vwo=o(" \u2014 "),lO=a("a"),Xwo=o("Wav2Vec2FeatureExtractor"),zwo=o(" (Hubert model)"),Qwo=l(),np=a("li"),Tue=a("strong"),Wwo=o("imagegpt"),Uwo=o(" \u2014 "),iO=a("a"),Hwo=o("ImageGPTFeatureExtractor"),Jwo=o(" (ImageGPT model)"),Ywo=l(),sp=a("li"),Mue=a("strong"),Kwo=o("layoutlmv2"),Zwo=o(" \u2014 "),dO=a("a"),eAo=o("LayoutLMv2FeatureExtractor"),oAo=o(" (LayoutLMv2 model)"),rAo=l(),lp=a("li"),Eue=a("strong"),tAo=o("layoutlmv3"),aAo=o(" \u2014 "),mO=a("a"),nAo=o("LayoutLMv3FeatureExtractor"),sAo=o(" (LayoutLMv3 model)"),lAo=l(),ip=a("li"),Cue=a("strong"),iAo=o("levit"),dAo=o(" \u2014 "),cO=a("a"),mAo=o("LevitFeatureExtractor"),cAo=o(" (LeViT model)"),fAo=l(),dp=a("li"),wue=a("strong"),gAo=o("maskformer"),hAo=o(" \u2014 "),fO=a("a"),uAo=o("MaskFormerFeatureExtractor"),pAo=o(" (MaskFormer model)"),_Ao=l(),mp=a("li"),Aue=a("strong"),bAo=o("mctct"),vAo=o(" \u2014 "),gO=a("a"),FAo=o("MCTCTFeatureExtractor"),TAo=o(" (M-CTC-T model)"),MAo=l(),cp=a("li"),Lue=a("strong"),EAo=o("mobilevit"),CAo=o(" \u2014 "),hO=a("a"),wAo=o("MobileViTFeatureExtractor"),AAo=o(" (MobileViT model)"),LAo=l(),fp=a("li"),yue=a("strong"),yAo=o("owlvit"),xAo=o(" \u2014 "),uO=a("a"),$Ao=o("OwlViTFeatureExtractor"),kAo=o(" (OWL-ViT model)"),SAo=l(),gp=a("li"),xue=a("strong"),RAo=o("perceiver"),PAo=o(" \u2014 "),pO=a("a"),BAo=o("PerceiverFeatureExtractor"),IAo=o(" (Perceiver model)"),NAo=l(),hp=a("li"),$ue=a("strong"),qAo=o("poolformer"),jAo=o(" \u2014 "),_O=a("a"),DAo=o("PoolFormerFeatureExtractor"),GAo=o(" (PoolFormer model)"),OAo=l(),up=a("li"),kue=a("strong"),VAo=o("regnet"),XAo=o(" \u2014 "),bO=a("a"),zAo=o("ConvNextFeatureExtractor"),QAo=o(" (RegNet model)"),WAo=l(),pp=a("li"),Sue=a("strong"),UAo=o("resnet"),HAo=o(" \u2014 "),vO=a("a"),JAo=o("ConvNextFeatureExtractor"),YAo=o(" (ResNet model)"),KAo=l(),_p=a("li"),Rue=a("strong"),ZAo=o("segformer"),e6o=o(" \u2014 "),FO=a("a"),o6o=o("SegformerFeatureExtractor"),r6o=o(" (SegFormer model)"),t6o=l(),bp=a("li"),Pue=a("strong"),a6o=o("speech_to_text"),n6o=o(" \u2014 "),TO=a("a"),s6o=o("Speech2TextFeatureExtractor"),l6o=o(" (Speech2Text model)"),i6o=l(),vp=a("li"),Bue=a("strong"),d6o=o("swin"),m6o=o(" \u2014 "),MO=a("a"),c6o=o("ViTFeatureExtractor"),f6o=o(" (Swin Transformer model)"),g6o=l(),Fp=a("li"),Iue=a("strong"),h6o=o("swinv2"),u6o=o(" \u2014 "),EO=a("a"),p6o=o("ViTFeatureExtractor"),_6o=o(" (Swin Transformer V2 model)"),b6o=l(),Tp=a("li"),Nue=a("strong"),v6o=o("van"),F6o=o(" \u2014 "),CO=a("a"),T6o=o("ConvNextFeatureExtractor"),M6o=o(" (VAN model)"),E6o=l(),Mp=a("li"),que=a("strong"),C6o=o("videomae"),w6o=o(" \u2014 "),wO=a("a"),A6o=o("VideoMAEFeatureExtractor"),L6o=o(" (VideoMAE model)"),y6o=l(),Ep=a("li"),jue=a("strong"),x6o=o("vilt"),$6o=o(" \u2014 "),AO=a("a"),k6o=o("ViltFeatureExtractor"),S6o=o(" (ViLT model)"),R6o=l(),Cp=a("li"),Due=a("strong"),P6o=o("vit"),B6o=o(" \u2014 "),LO=a("a"),I6o=o("ViTFeatureExtractor"),N6o=o(" (ViT model)"),q6o=l(),wp=a("li"),Gue=a("strong"),j6o=o("vit_mae"),D6o=o(" \u2014 "),yO=a("a"),G6o=o("ViTFeatureExtractor"),O6o=o(" (ViTMAE model)"),V6o=l(),Ap=a("li"),Oue=a("strong"),X6o=o("vit_msn"),z6o=o(" \u2014 "),xO=a("a"),Q6o=o("ViTFeatureExtractor"),W6o=o(" (ViTMSN model)"),U6o=l(),Lp=a("li"),Vue=a("strong"),H6o=o("wav2vec2"),J6o=o(" \u2014 "),$O=a("a"),Y6o=o("Wav2Vec2FeatureExtractor"),K6o=o(" (Wav2Vec2 model)"),Z6o=l(),yp=a("li"),Xue=a("strong"),e7o=o("wav2vec2-conformer"),o7o=o(" \u2014 "),kO=a("a"),r7o=o("Wav2Vec2FeatureExtractor"),t7o=o(" (Wav2Vec2-Conformer model)"),a7o=l(),xp=a("li"),zue=a("strong"),n7o=o("whisper"),s7o=o(" \u2014 "),SO=a("a"),l7o=o("WhisperFeatureExtractor"),i7o=o(" (Whisper model)"),d7o=l(),$p=a("li"),Que=a("strong"),m7o=o("xclip"),c7o=o(" \u2014 "),RO=a("a"),f7o=o("CLIPFeatureExtractor"),g7o=o(" (X-CLIP model)"),h7o=l(),kp=a("li"),Wue=a("strong"),u7o=o("yolos"),p7o=o(" \u2014 "),PO=a("a"),_7o=o("YolosFeatureExtractor"),b7o=o(" (YOLOS model)"),v7o=l(),F(Sp.$$.fragment),F7o=l(),F(Rp.$$.fragment),T7o=l(),Pp=a("div"),F(Lx.$$.fragment),M7o=l(),Uue=a("p"),E7o=o("Register a new feature extractor for this class."),Aeo=l(),ud=a("h2"),Bp=a("a"),Hue=a("span"),F(yx.$$.fragment),C7o=l(),Jue=a("span"),w7o=o("AutoProcessor"),Leo=l(),Ro=a("div"),F(xx.$$.fragment),A7o=l(),$x=a("p"),L7o=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),BO=a("a"),y7o=o("AutoProcessor.from_pretrained()"),x7o=o(" class method."),$7o=l(),kx=a("p"),k7o=o("This class cannot be instantiated directly using "),Yue=a("code"),S7o=o("__init__()"),R7o=o(" (throws an error)."),P7o=l(),Ke=a("div"),F(Sx.$$.fragment),B7o=l(),Kue=a("p"),I7o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),N7o=l(),pd=a("p"),q7o=o("The processor class to instantiate is selected based on the "),Zue=a("code"),j7o=o("model_type"),D7o=o(` property of the config object (either
passed as an argument or loaded from `),epe=a("code"),G7o=o("pretrained_model_name_or_path"),O7o=o(" if possible):"),V7o=l(),se=a("ul"),Ip=a("li"),ope=a("strong"),X7o=o("clip"),z7o=o(" \u2014 "),IO=a("a"),Q7o=o("CLIPProcessor"),W7o=o(" (CLIP model)"),U7o=l(),Np=a("li"),rpe=a("strong"),H7o=o("donut"),J7o=o(" \u2014 "),NO=a("a"),Y7o=o("DonutProcessor"),K7o=o(" (Donut model)"),Z7o=l(),qp=a("li"),tpe=a("strong"),eLo=o("flava"),oLo=o(" \u2014 "),qO=a("a"),rLo=o("FlavaProcessor"),tLo=o(" (FLAVA model)"),aLo=l(),jp=a("li"),ape=a("strong"),nLo=o("groupvit"),sLo=o(" \u2014 "),jO=a("a"),lLo=o("CLIPProcessor"),iLo=o(" (GroupViT model)"),dLo=l(),Dp=a("li"),npe=a("strong"),mLo=o("layoutlmv2"),cLo=o(" \u2014 "),DO=a("a"),fLo=o("LayoutLMv2Processor"),gLo=o(" (LayoutLMv2 model)"),hLo=l(),Gp=a("li"),spe=a("strong"),uLo=o("layoutlmv3"),pLo=o(" \u2014 "),GO=a("a"),_Lo=o("LayoutLMv3Processor"),bLo=o(" (LayoutLMv3 model)"),vLo=l(),Op=a("li"),lpe=a("strong"),FLo=o("layoutxlm"),TLo=o(" \u2014 "),OO=a("a"),MLo=o("LayoutXLMProcessor"),ELo=o(" (LayoutXLM model)"),CLo=l(),Vp=a("li"),ipe=a("strong"),wLo=o("markuplm"),ALo=o(" \u2014 "),VO=a("a"),LLo=o("MarkupLMProcessor"),yLo=o(" (MarkupLM model)"),xLo=l(),Xp=a("li"),dpe=a("strong"),$Lo=o("owlvit"),kLo=o(" \u2014 "),XO=a("a"),SLo=o("OwlViTProcessor"),RLo=o(" (OWL-ViT model)"),PLo=l(),zp=a("li"),mpe=a("strong"),BLo=o("sew"),ILo=o(" \u2014 "),zO=a("a"),NLo=o("Wav2Vec2Processor"),qLo=o(" (SEW model)"),jLo=l(),Qp=a("li"),cpe=a("strong"),DLo=o("sew-d"),GLo=o(" \u2014 "),QO=a("a"),OLo=o("Wav2Vec2Processor"),VLo=o(" (SEW-D model)"),XLo=l(),Wp=a("li"),fpe=a("strong"),zLo=o("speech_to_text"),QLo=o(" \u2014 "),WO=a("a"),WLo=o("Speech2TextProcessor"),ULo=o(" (Speech2Text model)"),HLo=l(),Up=a("li"),gpe=a("strong"),JLo=o("speech_to_text_2"),YLo=o(" \u2014 "),UO=a("a"),KLo=o("Speech2Text2Processor"),ZLo=o(" (Speech2Text2 model)"),eyo=l(),Hp=a("li"),hpe=a("strong"),oyo=o("trocr"),ryo=o(" \u2014 "),HO=a("a"),tyo=o("TrOCRProcessor"),ayo=o(" (TrOCR model)"),nyo=l(),Jp=a("li"),upe=a("strong"),syo=o("unispeech"),lyo=o(" \u2014 "),JO=a("a"),iyo=o("Wav2Vec2Processor"),dyo=o(" (UniSpeech model)"),myo=l(),Yp=a("li"),ppe=a("strong"),cyo=o("unispeech-sat"),fyo=o(" \u2014 "),YO=a("a"),gyo=o("Wav2Vec2Processor"),hyo=o(" (UniSpeechSat model)"),uyo=l(),Kp=a("li"),_pe=a("strong"),pyo=o("vilt"),_yo=o(" \u2014 "),KO=a("a"),byo=o("ViltProcessor"),vyo=o(" (ViLT model)"),Fyo=l(),Zp=a("li"),bpe=a("strong"),Tyo=o("vision-text-dual-encoder"),Myo=o(" \u2014 "),ZO=a("a"),Eyo=o("VisionTextDualEncoderProcessor"),Cyo=o(" (VisionTextDualEncoder model)"),wyo=l(),e_=a("li"),vpe=a("strong"),Ayo=o("wav2vec2"),Lyo=o(" \u2014 "),eV=a("a"),yyo=o("Wav2Vec2Processor"),xyo=o(" (Wav2Vec2 model)"),$yo=l(),o_=a("li"),Fpe=a("strong"),kyo=o("wav2vec2-conformer"),Syo=o(" \u2014 "),oV=a("a"),Ryo=o("Wav2Vec2Processor"),Pyo=o(" (Wav2Vec2-Conformer model)"),Byo=l(),r_=a("li"),Tpe=a("strong"),Iyo=o("wavlm"),Nyo=o(" \u2014 "),rV=a("a"),qyo=o("Wav2Vec2Processor"),jyo=o(" (WavLM model)"),Dyo=l(),t_=a("li"),Mpe=a("strong"),Gyo=o("whisper"),Oyo=o(" \u2014 "),tV=a("a"),Vyo=o("WhisperProcessor"),Xyo=o(" (Whisper model)"),zyo=l(),a_=a("li"),Epe=a("strong"),Qyo=o("xclip"),Wyo=o(" \u2014 "),aV=a("a"),Uyo=o("CLIPProcessor"),Hyo=o(" (X-CLIP model)"),Jyo=l(),F(n_.$$.fragment),Yyo=l(),F(s_.$$.fragment),Kyo=l(),l_=a("div"),F(Rx.$$.fragment),Zyo=l(),Cpe=a("p"),e8o=o("Register a new processor for this class."),yeo=l(),_d=a("h2"),i_=a("a"),wpe=a("span"),F(Px.$$.fragment),o8o=l(),Ape=a("span"),r8o=o("AutoModel"),xeo=l(),Po=a("div"),F(Bx.$$.fragment),t8o=l(),bd=a("p"),a8o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),nV=a("a"),n8o=o("from_pretrained()"),s8o=o(" class method or the "),sV=a("a"),l8o=o("from_config()"),i8o=o(` class
method.`),d8o=l(),Ix=a("p"),m8o=o("This class cannot be instantiated directly using "),Lpe=a("code"),c8o=o("__init__()"),f8o=o(" (throws an error)."),g8o=l(),_t=a("div"),F(Nx.$$.fragment),h8o=l(),ype=a("p"),u8o=o("Instantiates one of the base model classes of the library from a configuration."),p8o=l(),vd=a("p"),_8o=o(`Note:
Loading a model from its configuration file does `),xpe=a("strong"),b8o=o("not"),v8o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lV=a("a"),F8o=o("from_pretrained()"),T8o=o(" to load the model weights."),M8o=l(),F(d_.$$.fragment),E8o=l(),Ze=a("div"),F(qx.$$.fragment),C8o=l(),$pe=a("p"),w8o=o("Instantiate one of the base model classes of the library from a pretrained model."),A8o=l(),Ja=a("p"),L8o=o("The model class to instantiate is selected based on the "),kpe=a("code"),y8o=o("model_type"),x8o=o(` property of the config object (either
passed as an argument or loaded from `),Spe=a("code"),$8o=o("pretrained_model_name_or_path"),k8o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rpe=a("code"),S8o=o("pretrained_model_name_or_path"),R8o=o(":"),P8o=l(),y=a("ul"),m_=a("li"),Ppe=a("strong"),B8o=o("albert"),I8o=o(" \u2014 "),iV=a("a"),N8o=o("AlbertModel"),q8o=o(" (ALBERT model)"),j8o=l(),c_=a("li"),Bpe=a("strong"),D8o=o("bart"),G8o=o(" \u2014 "),dV=a("a"),O8o=o("BartModel"),V8o=o(" (BART model)"),X8o=l(),f_=a("li"),Ipe=a("strong"),z8o=o("beit"),Q8o=o(" \u2014 "),mV=a("a"),W8o=o("BeitModel"),U8o=o(" (BEiT model)"),H8o=l(),g_=a("li"),Npe=a("strong"),J8o=o("bert"),Y8o=o(" \u2014 "),cV=a("a"),K8o=o("BertModel"),Z8o=o(" (BERT model)"),e9o=l(),h_=a("li"),qpe=a("strong"),o9o=o("bert-generation"),r9o=o(" \u2014 "),fV=a("a"),t9o=o("BertGenerationEncoder"),a9o=o(" (Bert Generation model)"),n9o=l(),u_=a("li"),jpe=a("strong"),s9o=o("big_bird"),l9o=o(" \u2014 "),gV=a("a"),i9o=o("BigBirdModel"),d9o=o(" (BigBird model)"),m9o=l(),p_=a("li"),Dpe=a("strong"),c9o=o("bigbird_pegasus"),f9o=o(" \u2014 "),hV=a("a"),g9o=o("BigBirdPegasusModel"),h9o=o(" (BigBird-Pegasus model)"),u9o=l(),__=a("li"),Gpe=a("strong"),p9o=o("blenderbot"),_9o=o(" \u2014 "),uV=a("a"),b9o=o("BlenderbotModel"),v9o=o(" (Blenderbot model)"),F9o=l(),b_=a("li"),Ope=a("strong"),T9o=o("blenderbot-small"),M9o=o(" \u2014 "),pV=a("a"),E9o=o("BlenderbotSmallModel"),C9o=o(" (BlenderbotSmall model)"),w9o=l(),v_=a("li"),Vpe=a("strong"),A9o=o("bloom"),L9o=o(" \u2014 "),_V=a("a"),y9o=o("BloomModel"),x9o=o(" (BLOOM model)"),$9o=l(),F_=a("li"),Xpe=a("strong"),k9o=o("camembert"),S9o=o(" \u2014 "),bV=a("a"),R9o=o("CamembertModel"),P9o=o(" (CamemBERT model)"),B9o=l(),T_=a("li"),zpe=a("strong"),I9o=o("canine"),N9o=o(" \u2014 "),vV=a("a"),q9o=o("CanineModel"),j9o=o(" (CANINE model)"),D9o=l(),M_=a("li"),Qpe=a("strong"),G9o=o("clip"),O9o=o(" \u2014 "),FV=a("a"),V9o=o("CLIPModel"),X9o=o(" (CLIP model)"),z9o=l(),E_=a("li"),Wpe=a("strong"),Q9o=o("codegen"),W9o=o(" \u2014 "),TV=a("a"),U9o=o("CodeGenModel"),H9o=o(" (CodeGen model)"),J9o=l(),C_=a("li"),Upe=a("strong"),Y9o=o("conditional_detr"),K9o=o(" \u2014 "),MV=a("a"),Z9o=o("ConditionalDetrModel"),exo=o(" (Conditional DETR model)"),oxo=l(),w_=a("li"),Hpe=a("strong"),rxo=o("convbert"),txo=o(" \u2014 "),EV=a("a"),axo=o("ConvBertModel"),nxo=o(" (ConvBERT model)"),sxo=l(),A_=a("li"),Jpe=a("strong"),lxo=o("convnext"),ixo=o(" \u2014 "),CV=a("a"),dxo=o("ConvNextModel"),mxo=o(" (ConvNeXT model)"),cxo=l(),L_=a("li"),Ype=a("strong"),fxo=o("ctrl"),gxo=o(" \u2014 "),wV=a("a"),hxo=o("CTRLModel"),uxo=o(" (CTRL model)"),pxo=l(),y_=a("li"),Kpe=a("strong"),_xo=o("cvt"),bxo=o(" \u2014 "),AV=a("a"),vxo=o("CvtModel"),Fxo=o(" (CvT model)"),Txo=l(),x_=a("li"),Zpe=a("strong"),Mxo=o("data2vec-audio"),Exo=o(" \u2014 "),LV=a("a"),Cxo=o("Data2VecAudioModel"),wxo=o(" (Data2VecAudio model)"),Axo=l(),$_=a("li"),e_e=a("strong"),Lxo=o("data2vec-text"),yxo=o(" \u2014 "),yV=a("a"),xxo=o("Data2VecTextModel"),$xo=o(" (Data2VecText model)"),kxo=l(),k_=a("li"),o_e=a("strong"),Sxo=o("data2vec-vision"),Rxo=o(" \u2014 "),xV=a("a"),Pxo=o("Data2VecVisionModel"),Bxo=o(" (Data2VecVision model)"),Ixo=l(),S_=a("li"),r_e=a("strong"),Nxo=o("deberta"),qxo=o(" \u2014 "),$V=a("a"),jxo=o("DebertaModel"),Dxo=o(" (DeBERTa model)"),Gxo=l(),R_=a("li"),t_e=a("strong"),Oxo=o("deberta-v2"),Vxo=o(" \u2014 "),kV=a("a"),Xxo=o("DebertaV2Model"),zxo=o(" (DeBERTa-v2 model)"),Qxo=l(),P_=a("li"),a_e=a("strong"),Wxo=o("decision_transformer"),Uxo=o(" \u2014 "),SV=a("a"),Hxo=o("DecisionTransformerModel"),Jxo=o(" (Decision Transformer model)"),Yxo=l(),B_=a("li"),n_e=a("strong"),Kxo=o("deformable_detr"),Zxo=o(" \u2014 "),RV=a("a"),e$o=o("DeformableDetrModel"),o$o=o(" (Deformable DETR model)"),r$o=l(),I_=a("li"),s_e=a("strong"),t$o=o("deit"),a$o=o(" \u2014 "),PV=a("a"),n$o=o("DeiTModel"),s$o=o(" (DeiT model)"),l$o=l(),N_=a("li"),l_e=a("strong"),i$o=o("detr"),d$o=o(" \u2014 "),BV=a("a"),m$o=o("DetrModel"),c$o=o(" (DETR model)"),f$o=l(),q_=a("li"),i_e=a("strong"),g$o=o("distilbert"),h$o=o(" \u2014 "),IV=a("a"),u$o=o("DistilBertModel"),p$o=o(" (DistilBERT model)"),_$o=l(),j_=a("li"),d_e=a("strong"),b$o=o("donut-swin"),v$o=o(" \u2014 "),NV=a("a"),F$o=o("DonutSwinModel"),T$o=o(" (DonutSwin model)"),M$o=l(),D_=a("li"),m_e=a("strong"),E$o=o("dpr"),C$o=o(" \u2014 "),qV=a("a"),w$o=o("DPRQuestionEncoder"),A$o=o(" (DPR model)"),L$o=l(),G_=a("li"),c_e=a("strong"),y$o=o("dpt"),x$o=o(" \u2014 "),jV=a("a"),$$o=o("DPTModel"),k$o=o(" (DPT model)"),S$o=l(),O_=a("li"),f_e=a("strong"),R$o=o("electra"),P$o=o(" \u2014 "),DV=a("a"),B$o=o("ElectraModel"),I$o=o(" (ELECTRA model)"),N$o=l(),V_=a("li"),g_e=a("strong"),q$o=o("ernie"),j$o=o(" \u2014 "),GV=a("a"),D$o=o("ErnieModel"),G$o=o(" (ERNIE model)"),O$o=l(),X_=a("li"),h_e=a("strong"),V$o=o("esm"),X$o=o(" \u2014 "),OV=a("a"),z$o=o("EsmModel"),Q$o=o(" (ESM model)"),W$o=l(),z_=a("li"),u_e=a("strong"),U$o=o("flaubert"),H$o=o(" \u2014 "),VV=a("a"),J$o=o("FlaubertModel"),Y$o=o(" (FlauBERT model)"),K$o=l(),Q_=a("li"),p_e=a("strong"),Z$o=o("flava"),eko=o(" \u2014 "),XV=a("a"),oko=o("FlavaModel"),rko=o(" (FLAVA model)"),tko=l(),W_=a("li"),__e=a("strong"),ako=o("fnet"),nko=o(" \u2014 "),zV=a("a"),sko=o("FNetModel"),lko=o(" (FNet model)"),iko=l(),U_=a("li"),b_e=a("strong"),dko=o("fsmt"),mko=o(" \u2014 "),QV=a("a"),cko=o("FSMTModel"),fko=o(" (FairSeq Machine-Translation model)"),gko=l(),_l=a("li"),v_e=a("strong"),hko=o("funnel"),uko=o(" \u2014 "),WV=a("a"),pko=o("FunnelModel"),_ko=o(" or "),UV=a("a"),bko=o("FunnelBaseModel"),vko=o(" (Funnel Transformer model)"),Fko=l(),H_=a("li"),F_e=a("strong"),Tko=o("glpn"),Mko=o(" \u2014 "),HV=a("a"),Eko=o("GLPNModel"),Cko=o(" (GLPN model)"),wko=l(),J_=a("li"),T_e=a("strong"),Ako=o("gpt2"),Lko=o(" \u2014 "),JV=a("a"),yko=o("GPT2Model"),xko=o(" (OpenAI GPT-2 model)"),$ko=l(),Y_=a("li"),M_e=a("strong"),kko=o("gpt_neo"),Sko=o(" \u2014 "),YV=a("a"),Rko=o("GPTNeoModel"),Pko=o(" (GPT Neo model)"),Bko=l(),K_=a("li"),E_e=a("strong"),Iko=o("gpt_neox"),Nko=o(" \u2014 "),KV=a("a"),qko=o("GPTNeoXModel"),jko=o(" (GPT NeoX model)"),Dko=l(),Z_=a("li"),C_e=a("strong"),Gko=o("gpt_neox_japanese"),Oko=o(" \u2014 "),ZV=a("a"),Vko=o("GPTNeoXJapaneseModel"),Xko=o(" (GPT NeoX Japanese model)"),zko=l(),e1=a("li"),w_e=a("strong"),Qko=o("gptj"),Wko=o(" \u2014 "),eX=a("a"),Uko=o("GPTJModel"),Hko=o(" (GPT-J model)"),Jko=l(),o1=a("li"),A_e=a("strong"),Yko=o("groupvit"),Kko=o(" \u2014 "),oX=a("a"),Zko=o("GroupViTModel"),eSo=o(" (GroupViT model)"),oSo=l(),r1=a("li"),L_e=a("strong"),rSo=o("hubert"),tSo=o(" \u2014 "),rX=a("a"),aSo=o("HubertModel"),nSo=o(" (Hubert model)"),sSo=l(),t1=a("li"),y_e=a("strong"),lSo=o("ibert"),iSo=o(" \u2014 "),tX=a("a"),dSo=o("IBertModel"),mSo=o(" (I-BERT model)"),cSo=l(),a1=a("li"),x_e=a("strong"),fSo=o("imagegpt"),gSo=o(" \u2014 "),aX=a("a"),hSo=o("ImageGPTModel"),uSo=o(" (ImageGPT model)"),pSo=l(),n1=a("li"),$_e=a("strong"),_So=o("layoutlm"),bSo=o(" \u2014 "),nX=a("a"),vSo=o("LayoutLMModel"),FSo=o(" (LayoutLM model)"),TSo=l(),s1=a("li"),k_e=a("strong"),MSo=o("layoutlmv2"),ESo=o(" \u2014 "),sX=a("a"),CSo=o("LayoutLMv2Model"),wSo=o(" (LayoutLMv2 model)"),ASo=l(),l1=a("li"),S_e=a("strong"),LSo=o("layoutlmv3"),ySo=o(" \u2014 "),lX=a("a"),xSo=o("LayoutLMv3Model"),$So=o(" (LayoutLMv3 model)"),kSo=l(),i1=a("li"),R_e=a("strong"),SSo=o("led"),RSo=o(" \u2014 "),iX=a("a"),PSo=o("LEDModel"),BSo=o(" (LED model)"),ISo=l(),d1=a("li"),P_e=a("strong"),NSo=o("levit"),qSo=o(" \u2014 "),dX=a("a"),jSo=o("LevitModel"),DSo=o(" (LeViT model)"),GSo=l(),m1=a("li"),B_e=a("strong"),OSo=o("longformer"),VSo=o(" \u2014 "),mX=a("a"),XSo=o("LongformerModel"),zSo=o(" (Longformer model)"),QSo=l(),c1=a("li"),I_e=a("strong"),WSo=o("longt5"),USo=o(" \u2014 "),cX=a("a"),HSo=o("LongT5Model"),JSo=o(" (LongT5 model)"),YSo=l(),f1=a("li"),N_e=a("strong"),KSo=o("luke"),ZSo=o(" \u2014 "),fX=a("a"),eRo=o("LukeModel"),oRo=o(" (LUKE model)"),rRo=l(),g1=a("li"),q_e=a("strong"),tRo=o("lxmert"),aRo=o(" \u2014 "),gX=a("a"),nRo=o("LxmertModel"),sRo=o(" (LXMERT model)"),lRo=l(),h1=a("li"),j_e=a("strong"),iRo=o("m2m_100"),dRo=o(" \u2014 "),hX=a("a"),mRo=o("M2M100Model"),cRo=o(" (M2M100 model)"),fRo=l(),u1=a("li"),D_e=a("strong"),gRo=o("marian"),hRo=o(" \u2014 "),uX=a("a"),uRo=o("MarianModel"),pRo=o(" (Marian model)"),_Ro=l(),p1=a("li"),G_e=a("strong"),bRo=o("markuplm"),vRo=o(" \u2014 "),pX=a("a"),FRo=o("MarkupLMModel"),TRo=o(" (MarkupLM model)"),MRo=l(),_1=a("li"),O_e=a("strong"),ERo=o("maskformer"),CRo=o(" \u2014 "),_X=a("a"),wRo=o("MaskFormerModel"),ARo=o(" (MaskFormer model)"),LRo=l(),b1=a("li"),V_e=a("strong"),yRo=o("mbart"),xRo=o(" \u2014 "),bX=a("a"),$Ro=o("MBartModel"),kRo=o(" (mBART model)"),SRo=l(),v1=a("li"),X_e=a("strong"),RRo=o("mctct"),PRo=o(" \u2014 "),vX=a("a"),BRo=o("MCTCTModel"),IRo=o(" (M-CTC-T model)"),NRo=l(),F1=a("li"),z_e=a("strong"),qRo=o("megatron-bert"),jRo=o(" \u2014 "),FX=a("a"),DRo=o("MegatronBertModel"),GRo=o(" (Megatron-BERT model)"),ORo=l(),T1=a("li"),Q_e=a("strong"),VRo=o("mobilebert"),XRo=o(" \u2014 "),TX=a("a"),zRo=o("MobileBertModel"),QRo=o(" (MobileBERT model)"),WRo=l(),M1=a("li"),W_e=a("strong"),URo=o("mobilevit"),HRo=o(" \u2014 "),MX=a("a"),JRo=o("MobileViTModel"),YRo=o(" (MobileViT model)"),KRo=l(),E1=a("li"),U_e=a("strong"),ZRo=o("mpnet"),ePo=o(" \u2014 "),EX=a("a"),oPo=o("MPNetModel"),rPo=o(" (MPNet model)"),tPo=l(),C1=a("li"),H_e=a("strong"),aPo=o("mt5"),nPo=o(" \u2014 "),CX=a("a"),sPo=o("MT5Model"),lPo=o(" (MT5 model)"),iPo=l(),w1=a("li"),J_e=a("strong"),dPo=o("mvp"),mPo=o(" \u2014 "),wX=a("a"),cPo=o("MvpModel"),fPo=o(" (MVP model)"),gPo=l(),A1=a("li"),Y_e=a("strong"),hPo=o("nezha"),uPo=o(" \u2014 "),AX=a("a"),pPo=o("NezhaModel"),_Po=o(" (Nezha model)"),bPo=l(),L1=a("li"),K_e=a("strong"),vPo=o("nllb"),FPo=o(" \u2014 "),LX=a("a"),TPo=o("M2M100Model"),MPo=o(" (NLLB model)"),EPo=l(),y1=a("li"),Z_e=a("strong"),CPo=o("nystromformer"),wPo=o(" \u2014 "),yX=a("a"),APo=o("NystromformerModel"),LPo=o(" (Nystr\xF6mformer model)"),yPo=l(),x1=a("li"),e1e=a("strong"),xPo=o("openai-gpt"),$Po=o(" \u2014 "),xX=a("a"),kPo=o("OpenAIGPTModel"),SPo=o(" (OpenAI GPT model)"),RPo=l(),$1=a("li"),o1e=a("strong"),PPo=o("opt"),BPo=o(" \u2014 "),$X=a("a"),IPo=o("OPTModel"),NPo=o(" (OPT model)"),qPo=l(),k1=a("li"),r1e=a("strong"),jPo=o("owlvit"),DPo=o(" \u2014 "),kX=a("a"),GPo=o("OwlViTModel"),OPo=o(" (OWL-ViT model)"),VPo=l(),S1=a("li"),t1e=a("strong"),XPo=o("pegasus"),zPo=o(" \u2014 "),SX=a("a"),QPo=o("PegasusModel"),WPo=o(" (Pegasus model)"),UPo=l(),R1=a("li"),a1e=a("strong"),HPo=o("pegasus_x"),JPo=o(" \u2014 "),RX=a("a"),YPo=o("PegasusXModel"),KPo=o(" (PEGASUS-X model)"),ZPo=l(),P1=a("li"),n1e=a("strong"),eBo=o("perceiver"),oBo=o(" \u2014 "),PX=a("a"),rBo=o("PerceiverModel"),tBo=o(" (Perceiver model)"),aBo=l(),B1=a("li"),s1e=a("strong"),nBo=o("plbart"),sBo=o(" \u2014 "),BX=a("a"),lBo=o("PLBartModel"),iBo=o(" (PLBart model)"),dBo=l(),I1=a("li"),l1e=a("strong"),mBo=o("poolformer"),cBo=o(" \u2014 "),IX=a("a"),fBo=o("PoolFormerModel"),gBo=o(" (PoolFormer model)"),hBo=l(),N1=a("li"),i1e=a("strong"),uBo=o("prophetnet"),pBo=o(" \u2014 "),NX=a("a"),_Bo=o("ProphetNetModel"),bBo=o(" (ProphetNet model)"),vBo=l(),q1=a("li"),d1e=a("strong"),FBo=o("qdqbert"),TBo=o(" \u2014 "),qX=a("a"),MBo=o("QDQBertModel"),EBo=o(" (QDQBert model)"),CBo=l(),j1=a("li"),m1e=a("strong"),wBo=o("reformer"),ABo=o(" \u2014 "),jX=a("a"),LBo=o("ReformerModel"),yBo=o(" (Reformer model)"),xBo=l(),D1=a("li"),c1e=a("strong"),$Bo=o("regnet"),kBo=o(" \u2014 "),DX=a("a"),SBo=o("RegNetModel"),RBo=o(" (RegNet model)"),PBo=l(),G1=a("li"),f1e=a("strong"),BBo=o("rembert"),IBo=o(" \u2014 "),GX=a("a"),NBo=o("RemBertModel"),qBo=o(" (RemBERT model)"),jBo=l(),O1=a("li"),g1e=a("strong"),DBo=o("resnet"),GBo=o(" \u2014 "),OX=a("a"),OBo=o("ResNetModel"),VBo=o(" (ResNet model)"),XBo=l(),V1=a("li"),h1e=a("strong"),zBo=o("retribert"),QBo=o(" \u2014 "),VX=a("a"),WBo=o("RetriBertModel"),UBo=o(" (RetriBERT model)"),HBo=l(),X1=a("li"),u1e=a("strong"),JBo=o("roberta"),YBo=o(" \u2014 "),XX=a("a"),KBo=o("RobertaModel"),ZBo=o(" (RoBERTa model)"),eIo=l(),z1=a("li"),p1e=a("strong"),oIo=o("roformer"),rIo=o(" \u2014 "),zX=a("a"),tIo=o("RoFormerModel"),aIo=o(" (RoFormer model)"),nIo=l(),Q1=a("li"),_1e=a("strong"),sIo=o("segformer"),lIo=o(" \u2014 "),QX=a("a"),iIo=o("SegformerModel"),dIo=o(" (SegFormer model)"),mIo=l(),W1=a("li"),b1e=a("strong"),cIo=o("sew"),fIo=o(" \u2014 "),WX=a("a"),gIo=o("SEWModel"),hIo=o(" (SEW model)"),uIo=l(),U1=a("li"),v1e=a("strong"),pIo=o("sew-d"),_Io=o(" \u2014 "),UX=a("a"),bIo=o("SEWDModel"),vIo=o(" (SEW-D model)"),FIo=l(),H1=a("li"),F1e=a("strong"),TIo=o("speech_to_text"),MIo=o(" \u2014 "),HX=a("a"),EIo=o("Speech2TextModel"),CIo=o(" (Speech2Text model)"),wIo=l(),J1=a("li"),T1e=a("strong"),AIo=o("splinter"),LIo=o(" \u2014 "),JX=a("a"),yIo=o("SplinterModel"),xIo=o(" (Splinter model)"),$Io=l(),Y1=a("li"),M1e=a("strong"),kIo=o("squeezebert"),SIo=o(" \u2014 "),YX=a("a"),RIo=o("SqueezeBertModel"),PIo=o(" (SqueezeBERT model)"),BIo=l(),K1=a("li"),E1e=a("strong"),IIo=o("swin"),NIo=o(" \u2014 "),KX=a("a"),qIo=o("SwinModel"),jIo=o(" (Swin Transformer model)"),DIo=l(),Z1=a("li"),C1e=a("strong"),GIo=o("swinv2"),OIo=o(" \u2014 "),ZX=a("a"),VIo=o("Swinv2Model"),XIo=o(" (Swin Transformer V2 model)"),zIo=l(),e2=a("li"),w1e=a("strong"),QIo=o("t5"),WIo=o(" \u2014 "),ez=a("a"),UIo=o("T5Model"),HIo=o(" (T5 model)"),JIo=l(),o2=a("li"),A1e=a("strong"),YIo=o("tapas"),KIo=o(" \u2014 "),oz=a("a"),ZIo=o("TapasModel"),eNo=o(" (TAPAS model)"),oNo=l(),r2=a("li"),L1e=a("strong"),rNo=o("time_series_transformer"),tNo=o(" \u2014 "),rz=a("a"),aNo=o("TimeSeriesTransformerModel"),nNo=o(" (Time Series Transformer model)"),sNo=l(),t2=a("li"),y1e=a("strong"),lNo=o("trajectory_transformer"),iNo=o(" \u2014 "),tz=a("a"),dNo=o("TrajectoryTransformerModel"),mNo=o(" (Trajectory Transformer model)"),cNo=l(),a2=a("li"),x1e=a("strong"),fNo=o("transfo-xl"),gNo=o(" \u2014 "),az=a("a"),hNo=o("TransfoXLModel"),uNo=o(" (Transformer-XL model)"),pNo=l(),n2=a("li"),$1e=a("strong"),_No=o("unispeech"),bNo=o(" \u2014 "),nz=a("a"),vNo=o("UniSpeechModel"),FNo=o(" (UniSpeech model)"),TNo=l(),s2=a("li"),k1e=a("strong"),MNo=o("unispeech-sat"),ENo=o(" \u2014 "),sz=a("a"),CNo=o("UniSpeechSatModel"),wNo=o(" (UniSpeechSat model)"),ANo=l(),l2=a("li"),S1e=a("strong"),LNo=o("van"),yNo=o(" \u2014 "),lz=a("a"),xNo=o("VanModel"),$No=o(" (VAN model)"),kNo=l(),i2=a("li"),R1e=a("strong"),SNo=o("videomae"),RNo=o(" \u2014 "),iz=a("a"),PNo=o("VideoMAEModel"),BNo=o(" (VideoMAE model)"),INo=l(),d2=a("li"),P1e=a("strong"),NNo=o("vilt"),qNo=o(" \u2014 "),dz=a("a"),jNo=o("ViltModel"),DNo=o(" (ViLT model)"),GNo=l(),m2=a("li"),B1e=a("strong"),ONo=o("vision-text-dual-encoder"),VNo=o(" \u2014 "),mz=a("a"),XNo=o("VisionTextDualEncoderModel"),zNo=o(" (VisionTextDualEncoder model)"),QNo=l(),c2=a("li"),I1e=a("strong"),WNo=o("visual_bert"),UNo=o(" \u2014 "),cz=a("a"),HNo=o("VisualBertModel"),JNo=o(" (VisualBERT model)"),YNo=l(),f2=a("li"),N1e=a("strong"),KNo=o("vit"),ZNo=o(" \u2014 "),fz=a("a"),eqo=o("ViTModel"),oqo=o(" (ViT model)"),rqo=l(),g2=a("li"),q1e=a("strong"),tqo=o("vit_mae"),aqo=o(" \u2014 "),gz=a("a"),nqo=o("ViTMAEModel"),sqo=o(" (ViTMAE model)"),lqo=l(),h2=a("li"),j1e=a("strong"),iqo=o("vit_msn"),dqo=o(" \u2014 "),hz=a("a"),mqo=o("ViTMSNModel"),cqo=o(" (ViTMSN model)"),fqo=l(),u2=a("li"),D1e=a("strong"),gqo=o("wav2vec2"),hqo=o(" \u2014 "),uz=a("a"),uqo=o("Wav2Vec2Model"),pqo=o(" (Wav2Vec2 model)"),_qo=l(),p2=a("li"),G1e=a("strong"),bqo=o("wav2vec2-conformer"),vqo=o(" \u2014 "),pz=a("a"),Fqo=o("Wav2Vec2ConformerModel"),Tqo=o(" (Wav2Vec2-Conformer model)"),Mqo=l(),_2=a("li"),O1e=a("strong"),Eqo=o("wavlm"),Cqo=o(" \u2014 "),_z=a("a"),wqo=o("WavLMModel"),Aqo=o(" (WavLM model)"),Lqo=l(),b2=a("li"),V1e=a("strong"),yqo=o("whisper"),xqo=o(" \u2014 "),bz=a("a"),$qo=o("WhisperModel"),kqo=o(" (Whisper model)"),Sqo=l(),v2=a("li"),X1e=a("strong"),Rqo=o("xclip"),Pqo=o(" \u2014 "),vz=a("a"),Bqo=o("XCLIPModel"),Iqo=o(" (X-CLIP model)"),Nqo=l(),F2=a("li"),z1e=a("strong"),qqo=o("xglm"),jqo=o(" \u2014 "),Fz=a("a"),Dqo=o("XGLMModel"),Gqo=o(" (XGLM model)"),Oqo=l(),T2=a("li"),Q1e=a("strong"),Vqo=o("xlm"),Xqo=o(" \u2014 "),Tz=a("a"),zqo=o("XLMModel"),Qqo=o(" (XLM model)"),Wqo=l(),M2=a("li"),W1e=a("strong"),Uqo=o("xlm-prophetnet"),Hqo=o(" \u2014 "),Mz=a("a"),Jqo=o("XLMProphetNetModel"),Yqo=o(" (XLM-ProphetNet model)"),Kqo=l(),E2=a("li"),U1e=a("strong"),Zqo=o("xlm-roberta"),ejo=o(" \u2014 "),Ez=a("a"),ojo=o("XLMRobertaModel"),rjo=o(" (XLM-RoBERTa model)"),tjo=l(),C2=a("li"),H1e=a("strong"),ajo=o("xlm-roberta-xl"),njo=o(" \u2014 "),Cz=a("a"),sjo=o("XLMRobertaXLModel"),ljo=o(" (XLM-RoBERTa-XL model)"),ijo=l(),w2=a("li"),J1e=a("strong"),djo=o("xlnet"),mjo=o(" \u2014 "),wz=a("a"),cjo=o("XLNetModel"),fjo=o(" (XLNet model)"),gjo=l(),A2=a("li"),Y1e=a("strong"),hjo=o("yolos"),ujo=o(" \u2014 "),Az=a("a"),pjo=o("YolosModel"),_jo=o(" (YOLOS model)"),bjo=l(),L2=a("li"),K1e=a("strong"),vjo=o("yoso"),Fjo=o(" \u2014 "),Lz=a("a"),Tjo=o("YosoModel"),Mjo=o(" (YOSO model)"),Ejo=l(),y2=a("p"),Cjo=o("The model is set in evaluation mode by default using "),Z1e=a("code"),wjo=o("model.eval()"),Ajo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),e2e=a("code"),Ljo=o("model.train()"),yjo=l(),F(x2.$$.fragment),$eo=l(),Fd=a("h2"),$2=a("a"),o2e=a("span"),F(jx.$$.fragment),xjo=l(),r2e=a("span"),$jo=o("AutoModelForPreTraining"),keo=l(),Bo=a("div"),F(Dx.$$.fragment),kjo=l(),Td=a("p"),Sjo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),yz=a("a"),Rjo=o("from_pretrained()"),Pjo=o(" class method or the "),xz=a("a"),Bjo=o("from_config()"),Ijo=o(` class
method.`),Njo=l(),Gx=a("p"),qjo=o("This class cannot be instantiated directly using "),t2e=a("code"),jjo=o("__init__()"),Djo=o(" (throws an error)."),Gjo=l(),bt=a("div"),F(Ox.$$.fragment),Ojo=l(),a2e=a("p"),Vjo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Xjo=l(),Md=a("p"),zjo=o(`Note:
Loading a model from its configuration file does `),n2e=a("strong"),Qjo=o("not"),Wjo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$z=a("a"),Ujo=o("from_pretrained()"),Hjo=o(" to load the model weights."),Jjo=l(),F(k2.$$.fragment),Yjo=l(),eo=a("div"),F(Vx.$$.fragment),Kjo=l(),s2e=a("p"),Zjo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),eDo=l(),Ya=a("p"),oDo=o("The model class to instantiate is selected based on the "),l2e=a("code"),rDo=o("model_type"),tDo=o(` property of the config object (either
passed as an argument or loaded from `),i2e=a("code"),aDo=o("pretrained_model_name_or_path"),nDo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d2e=a("code"),sDo=o("pretrained_model_name_or_path"),lDo=o(":"),iDo=l(),G=a("ul"),S2=a("li"),m2e=a("strong"),dDo=o("albert"),mDo=o(" \u2014 "),kz=a("a"),cDo=o("AlbertForPreTraining"),fDo=o(" (ALBERT model)"),gDo=l(),R2=a("li"),c2e=a("strong"),hDo=o("bart"),uDo=o(" \u2014 "),Sz=a("a"),pDo=o("BartForConditionalGeneration"),_Do=o(" (BART model)"),bDo=l(),P2=a("li"),f2e=a("strong"),vDo=o("bert"),FDo=o(" \u2014 "),Rz=a("a"),TDo=o("BertForPreTraining"),MDo=o(" (BERT model)"),EDo=l(),B2=a("li"),g2e=a("strong"),CDo=o("big_bird"),wDo=o(" \u2014 "),Pz=a("a"),ADo=o("BigBirdForPreTraining"),LDo=o(" (BigBird model)"),yDo=l(),I2=a("li"),h2e=a("strong"),xDo=o("bloom"),$Do=o(" \u2014 "),Bz=a("a"),kDo=o("BloomForCausalLM"),SDo=o(" (BLOOM model)"),RDo=l(),N2=a("li"),u2e=a("strong"),PDo=o("camembert"),BDo=o(" \u2014 "),Iz=a("a"),IDo=o("CamembertForMaskedLM"),NDo=o(" (CamemBERT model)"),qDo=l(),q2=a("li"),p2e=a("strong"),jDo=o("ctrl"),DDo=o(" \u2014 "),Nz=a("a"),GDo=o("CTRLLMHeadModel"),ODo=o(" (CTRL model)"),VDo=l(),j2=a("li"),_2e=a("strong"),XDo=o("data2vec-text"),zDo=o(" \u2014 "),qz=a("a"),QDo=o("Data2VecTextForMaskedLM"),WDo=o(" (Data2VecText model)"),UDo=l(),D2=a("li"),b2e=a("strong"),HDo=o("deberta"),JDo=o(" \u2014 "),jz=a("a"),YDo=o("DebertaForMaskedLM"),KDo=o(" (DeBERTa model)"),ZDo=l(),G2=a("li"),v2e=a("strong"),eGo=o("deberta-v2"),oGo=o(" \u2014 "),Dz=a("a"),rGo=o("DebertaV2ForMaskedLM"),tGo=o(" (DeBERTa-v2 model)"),aGo=l(),O2=a("li"),F2e=a("strong"),nGo=o("distilbert"),sGo=o(" \u2014 "),Gz=a("a"),lGo=o("DistilBertForMaskedLM"),iGo=o(" (DistilBERT model)"),dGo=l(),V2=a("li"),T2e=a("strong"),mGo=o("electra"),cGo=o(" \u2014 "),Oz=a("a"),fGo=o("ElectraForPreTraining"),gGo=o(" (ELECTRA model)"),hGo=l(),X2=a("li"),M2e=a("strong"),uGo=o("ernie"),pGo=o(" \u2014 "),Vz=a("a"),_Go=o("ErnieForPreTraining"),bGo=o(" (ERNIE model)"),vGo=l(),z2=a("li"),E2e=a("strong"),FGo=o("flaubert"),TGo=o(" \u2014 "),Xz=a("a"),MGo=o("FlaubertWithLMHeadModel"),EGo=o(" (FlauBERT model)"),CGo=l(),Q2=a("li"),C2e=a("strong"),wGo=o("flava"),AGo=o(" \u2014 "),zz=a("a"),LGo=o("FlavaForPreTraining"),yGo=o(" (FLAVA model)"),xGo=l(),W2=a("li"),w2e=a("strong"),$Go=o("fnet"),kGo=o(" \u2014 "),Qz=a("a"),SGo=o("FNetForPreTraining"),RGo=o(" (FNet model)"),PGo=l(),U2=a("li"),A2e=a("strong"),BGo=o("fsmt"),IGo=o(" \u2014 "),Wz=a("a"),NGo=o("FSMTForConditionalGeneration"),qGo=o(" (FairSeq Machine-Translation model)"),jGo=l(),H2=a("li"),L2e=a("strong"),DGo=o("funnel"),GGo=o(" \u2014 "),Uz=a("a"),OGo=o("FunnelForPreTraining"),VGo=o(" (Funnel Transformer model)"),XGo=l(),J2=a("li"),y2e=a("strong"),zGo=o("gpt2"),QGo=o(" \u2014 "),Hz=a("a"),WGo=o("GPT2LMHeadModel"),UGo=o(" (OpenAI GPT-2 model)"),HGo=l(),Y2=a("li"),x2e=a("strong"),JGo=o("ibert"),YGo=o(" \u2014 "),Jz=a("a"),KGo=o("IBertForMaskedLM"),ZGo=o(" (I-BERT model)"),eOo=l(),K2=a("li"),$2e=a("strong"),oOo=o("layoutlm"),rOo=o(" \u2014 "),Yz=a("a"),tOo=o("LayoutLMForMaskedLM"),aOo=o(" (LayoutLM model)"),nOo=l(),Z2=a("li"),k2e=a("strong"),sOo=o("longformer"),lOo=o(" \u2014 "),Kz=a("a"),iOo=o("LongformerForMaskedLM"),dOo=o(" (Longformer model)"),mOo=l(),eb=a("li"),S2e=a("strong"),cOo=o("luke"),fOo=o(" \u2014 "),Zz=a("a"),gOo=o("LukeForMaskedLM"),hOo=o(" (LUKE model)"),uOo=l(),ob=a("li"),R2e=a("strong"),pOo=o("lxmert"),_Oo=o(" \u2014 "),eQ=a("a"),bOo=o("LxmertForPreTraining"),vOo=o(" (LXMERT model)"),FOo=l(),rb=a("li"),P2e=a("strong"),TOo=o("megatron-bert"),MOo=o(" \u2014 "),oQ=a("a"),EOo=o("MegatronBertForPreTraining"),COo=o(" (Megatron-BERT model)"),wOo=l(),tb=a("li"),B2e=a("strong"),AOo=o("mobilebert"),LOo=o(" \u2014 "),rQ=a("a"),yOo=o("MobileBertForPreTraining"),xOo=o(" (MobileBERT model)"),$Oo=l(),ab=a("li"),I2e=a("strong"),kOo=o("mpnet"),SOo=o(" \u2014 "),tQ=a("a"),ROo=o("MPNetForMaskedLM"),POo=o(" (MPNet model)"),BOo=l(),nb=a("li"),N2e=a("strong"),IOo=o("mvp"),NOo=o(" \u2014 "),aQ=a("a"),qOo=o("MvpForConditionalGeneration"),jOo=o(" (MVP model)"),DOo=l(),sb=a("li"),q2e=a("strong"),GOo=o("nezha"),OOo=o(" \u2014 "),nQ=a("a"),VOo=o("NezhaForPreTraining"),XOo=o(" (Nezha model)"),zOo=l(),lb=a("li"),j2e=a("strong"),QOo=o("openai-gpt"),WOo=o(" \u2014 "),sQ=a("a"),UOo=o("OpenAIGPTLMHeadModel"),HOo=o(" (OpenAI GPT model)"),JOo=l(),ib=a("li"),D2e=a("strong"),YOo=o("retribert"),KOo=o(" \u2014 "),lQ=a("a"),ZOo=o("RetriBertModel"),eVo=o(" (RetriBERT model)"),oVo=l(),db=a("li"),G2e=a("strong"),rVo=o("roberta"),tVo=o(" \u2014 "),iQ=a("a"),aVo=o("RobertaForMaskedLM"),nVo=o(" (RoBERTa model)"),sVo=l(),mb=a("li"),O2e=a("strong"),lVo=o("splinter"),iVo=o(" \u2014 "),dQ=a("a"),dVo=o("SplinterForPreTraining"),mVo=o(" (Splinter model)"),cVo=l(),cb=a("li"),V2e=a("strong"),fVo=o("squeezebert"),gVo=o(" \u2014 "),mQ=a("a"),hVo=o("SqueezeBertForMaskedLM"),uVo=o(" (SqueezeBERT model)"),pVo=l(),fb=a("li"),X2e=a("strong"),_Vo=o("t5"),bVo=o(" \u2014 "),cQ=a("a"),vVo=o("T5ForConditionalGeneration"),FVo=o(" (T5 model)"),TVo=l(),gb=a("li"),z2e=a("strong"),MVo=o("tapas"),EVo=o(" \u2014 "),fQ=a("a"),CVo=o("TapasForMaskedLM"),wVo=o(" (TAPAS model)"),AVo=l(),hb=a("li"),Q2e=a("strong"),LVo=o("transfo-xl"),yVo=o(" \u2014 "),gQ=a("a"),xVo=o("TransfoXLLMHeadModel"),$Vo=o(" (Transformer-XL model)"),kVo=l(),ub=a("li"),W2e=a("strong"),SVo=o("unispeech"),RVo=o(" \u2014 "),hQ=a("a"),PVo=o("UniSpeechForPreTraining"),BVo=o(" (UniSpeech model)"),IVo=l(),pb=a("li"),U2e=a("strong"),NVo=o("unispeech-sat"),qVo=o(" \u2014 "),uQ=a("a"),jVo=o("UniSpeechSatForPreTraining"),DVo=o(" (UniSpeechSat model)"),GVo=l(),_b=a("li"),H2e=a("strong"),OVo=o("videomae"),VVo=o(" \u2014 "),pQ=a("a"),XVo=o("VideoMAEForPreTraining"),zVo=o(" (VideoMAE model)"),QVo=l(),bb=a("li"),J2e=a("strong"),WVo=o("visual_bert"),UVo=o(" \u2014 "),_Q=a("a"),HVo=o("VisualBertForPreTraining"),JVo=o(" (VisualBERT model)"),YVo=l(),vb=a("li"),Y2e=a("strong"),KVo=o("vit_mae"),ZVo=o(" \u2014 "),bQ=a("a"),eXo=o("ViTMAEForPreTraining"),oXo=o(" (ViTMAE model)"),rXo=l(),Fb=a("li"),K2e=a("strong"),tXo=o("wav2vec2"),aXo=o(" \u2014 "),vQ=a("a"),nXo=o("Wav2Vec2ForPreTraining"),sXo=o(" (Wav2Vec2 model)"),lXo=l(),Tb=a("li"),Z2e=a("strong"),iXo=o("wav2vec2-conformer"),dXo=o(" \u2014 "),FQ=a("a"),mXo=o("Wav2Vec2ConformerForPreTraining"),cXo=o(" (Wav2Vec2-Conformer model)"),fXo=l(),Mb=a("li"),ebe=a("strong"),gXo=o("xlm"),hXo=o(" \u2014 "),TQ=a("a"),uXo=o("XLMWithLMHeadModel"),pXo=o(" (XLM model)"),_Xo=l(),Eb=a("li"),obe=a("strong"),bXo=o("xlm-roberta"),vXo=o(" \u2014 "),MQ=a("a"),FXo=o("XLMRobertaForMaskedLM"),TXo=o(" (XLM-RoBERTa model)"),MXo=l(),Cb=a("li"),rbe=a("strong"),EXo=o("xlm-roberta-xl"),CXo=o(" \u2014 "),EQ=a("a"),wXo=o("XLMRobertaXLForMaskedLM"),AXo=o(" (XLM-RoBERTa-XL model)"),LXo=l(),wb=a("li"),tbe=a("strong"),yXo=o("xlnet"),xXo=o(" \u2014 "),CQ=a("a"),$Xo=o("XLNetLMHeadModel"),kXo=o(" (XLNet model)"),SXo=l(),Ab=a("p"),RXo=o("The model is set in evaluation mode by default using "),abe=a("code"),PXo=o("model.eval()"),BXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nbe=a("code"),IXo=o("model.train()"),NXo=l(),F(Lb.$$.fragment),Seo=l(),Ed=a("h2"),yb=a("a"),sbe=a("span"),F(Xx.$$.fragment),qXo=l(),lbe=a("span"),jXo=o("AutoModelForCausalLM"),Reo=l(),Io=a("div"),F(zx.$$.fragment),DXo=l(),Cd=a("p"),GXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wQ=a("a"),OXo=o("from_pretrained()"),VXo=o(" class method or the "),AQ=a("a"),XXo=o("from_config()"),zXo=o(` class
method.`),QXo=l(),Qx=a("p"),WXo=o("This class cannot be instantiated directly using "),ibe=a("code"),UXo=o("__init__()"),HXo=o(" (throws an error)."),JXo=l(),vt=a("div"),F(Wx.$$.fragment),YXo=l(),dbe=a("p"),KXo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ZXo=l(),wd=a("p"),ezo=o(`Note:
Loading a model from its configuration file does `),mbe=a("strong"),ozo=o("not"),rzo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LQ=a("a"),tzo=o("from_pretrained()"),azo=o(" to load the model weights."),nzo=l(),F(xb.$$.fragment),szo=l(),oo=a("div"),F(Ux.$$.fragment),lzo=l(),cbe=a("p"),izo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),dzo=l(),Ka=a("p"),mzo=o("The model class to instantiate is selected based on the "),fbe=a("code"),czo=o("model_type"),fzo=o(` property of the config object (either
passed as an argument or loaded from `),gbe=a("code"),gzo=o("pretrained_model_name_or_path"),hzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hbe=a("code"),uzo=o("pretrained_model_name_or_path"),pzo=o(":"),_zo=l(),Q=a("ul"),$b=a("li"),ube=a("strong"),bzo=o("bart"),vzo=o(" \u2014 "),yQ=a("a"),Fzo=o("BartForCausalLM"),Tzo=o(" (BART model)"),Mzo=l(),kb=a("li"),pbe=a("strong"),Ezo=o("bert"),Czo=o(" \u2014 "),xQ=a("a"),wzo=o("BertLMHeadModel"),Azo=o(" (BERT model)"),Lzo=l(),Sb=a("li"),_be=a("strong"),yzo=o("bert-generation"),xzo=o(" \u2014 "),$Q=a("a"),$zo=o("BertGenerationDecoder"),kzo=o(" (Bert Generation model)"),Szo=l(),Rb=a("li"),bbe=a("strong"),Rzo=o("big_bird"),Pzo=o(" \u2014 "),kQ=a("a"),Bzo=o("BigBirdForCausalLM"),Izo=o(" (BigBird model)"),Nzo=l(),Pb=a("li"),vbe=a("strong"),qzo=o("bigbird_pegasus"),jzo=o(" \u2014 "),SQ=a("a"),Dzo=o("BigBirdPegasusForCausalLM"),Gzo=o(" (BigBird-Pegasus model)"),Ozo=l(),Bb=a("li"),Fbe=a("strong"),Vzo=o("blenderbot"),Xzo=o(" \u2014 "),RQ=a("a"),zzo=o("BlenderbotForCausalLM"),Qzo=o(" (Blenderbot model)"),Wzo=l(),Ib=a("li"),Tbe=a("strong"),Uzo=o("blenderbot-small"),Hzo=o(" \u2014 "),PQ=a("a"),Jzo=o("BlenderbotSmallForCausalLM"),Yzo=o(" (BlenderbotSmall model)"),Kzo=l(),Nb=a("li"),Mbe=a("strong"),Zzo=o("bloom"),eQo=o(" \u2014 "),BQ=a("a"),oQo=o("BloomForCausalLM"),rQo=o(" (BLOOM model)"),tQo=l(),qb=a("li"),Ebe=a("strong"),aQo=o("camembert"),nQo=o(" \u2014 "),IQ=a("a"),sQo=o("CamembertForCausalLM"),lQo=o(" (CamemBERT model)"),iQo=l(),jb=a("li"),Cbe=a("strong"),dQo=o("codegen"),mQo=o(" \u2014 "),NQ=a("a"),cQo=o("CodeGenForCausalLM"),fQo=o(" (CodeGen model)"),gQo=l(),Db=a("li"),wbe=a("strong"),hQo=o("ctrl"),uQo=o(" \u2014 "),qQ=a("a"),pQo=o("CTRLLMHeadModel"),_Qo=o(" (CTRL model)"),bQo=l(),Gb=a("li"),Abe=a("strong"),vQo=o("data2vec-text"),FQo=o(" \u2014 "),jQ=a("a"),TQo=o("Data2VecTextForCausalLM"),MQo=o(" (Data2VecText model)"),EQo=l(),Ob=a("li"),Lbe=a("strong"),CQo=o("electra"),wQo=o(" \u2014 "),DQ=a("a"),AQo=o("ElectraForCausalLM"),LQo=o(" (ELECTRA model)"),yQo=l(),Vb=a("li"),ybe=a("strong"),xQo=o("ernie"),$Qo=o(" \u2014 "),GQ=a("a"),kQo=o("ErnieForCausalLM"),SQo=o(" (ERNIE model)"),RQo=l(),Xb=a("li"),xbe=a("strong"),PQo=o("gpt2"),BQo=o(" \u2014 "),OQ=a("a"),IQo=o("GPT2LMHeadModel"),NQo=o(" (OpenAI GPT-2 model)"),qQo=l(),zb=a("li"),$be=a("strong"),jQo=o("gpt_neo"),DQo=o(" \u2014 "),VQ=a("a"),GQo=o("GPTNeoForCausalLM"),OQo=o(" (GPT Neo model)"),VQo=l(),Qb=a("li"),kbe=a("strong"),XQo=o("gpt_neox"),zQo=o(" \u2014 "),XQ=a("a"),QQo=o("GPTNeoXForCausalLM"),WQo=o(" (GPT NeoX model)"),UQo=l(),Wb=a("li"),Sbe=a("strong"),HQo=o("gpt_neox_japanese"),JQo=o(" \u2014 "),zQ=a("a"),YQo=o("GPTNeoXJapaneseForCausalLM"),KQo=o(" (GPT NeoX Japanese model)"),ZQo=l(),Ub=a("li"),Rbe=a("strong"),eWo=o("gptj"),oWo=o(" \u2014 "),QQ=a("a"),rWo=o("GPTJForCausalLM"),tWo=o(" (GPT-J model)"),aWo=l(),Hb=a("li"),Pbe=a("strong"),nWo=o("marian"),sWo=o(" \u2014 "),WQ=a("a"),lWo=o("MarianForCausalLM"),iWo=o(" (Marian model)"),dWo=l(),Jb=a("li"),Bbe=a("strong"),mWo=o("mbart"),cWo=o(" \u2014 "),UQ=a("a"),fWo=o("MBartForCausalLM"),gWo=o(" (mBART model)"),hWo=l(),Yb=a("li"),Ibe=a("strong"),uWo=o("megatron-bert"),pWo=o(" \u2014 "),HQ=a("a"),_Wo=o("MegatronBertForCausalLM"),bWo=o(" (Megatron-BERT model)"),vWo=l(),Kb=a("li"),Nbe=a("strong"),FWo=o("mvp"),TWo=o(" \u2014 "),JQ=a("a"),MWo=o("MvpForCausalLM"),EWo=o(" (MVP model)"),CWo=l(),Zb=a("li"),qbe=a("strong"),wWo=o("openai-gpt"),AWo=o(" \u2014 "),YQ=a("a"),LWo=o("OpenAIGPTLMHeadModel"),yWo=o(" (OpenAI GPT model)"),xWo=l(),ev=a("li"),jbe=a("strong"),$Wo=o("opt"),kWo=o(" \u2014 "),KQ=a("a"),SWo=o("OPTForCausalLM"),RWo=o(" (OPT model)"),PWo=l(),ov=a("li"),Dbe=a("strong"),BWo=o("pegasus"),IWo=o(" \u2014 "),ZQ=a("a"),NWo=o("PegasusForCausalLM"),qWo=o(" (Pegasus model)"),jWo=l(),rv=a("li"),Gbe=a("strong"),DWo=o("plbart"),GWo=o(" \u2014 "),eW=a("a"),OWo=o("PLBartForCausalLM"),VWo=o(" (PLBart model)"),XWo=l(),tv=a("li"),Obe=a("strong"),zWo=o("prophetnet"),QWo=o(" \u2014 "),oW=a("a"),WWo=o("ProphetNetForCausalLM"),UWo=o(" (ProphetNet model)"),HWo=l(),av=a("li"),Vbe=a("strong"),JWo=o("qdqbert"),YWo=o(" \u2014 "),rW=a("a"),KWo=o("QDQBertLMHeadModel"),ZWo=o(" (QDQBert model)"),eUo=l(),nv=a("li"),Xbe=a("strong"),oUo=o("reformer"),rUo=o(" \u2014 "),tW=a("a"),tUo=o("ReformerModelWithLMHead"),aUo=o(" (Reformer model)"),nUo=l(),sv=a("li"),zbe=a("strong"),sUo=o("rembert"),lUo=o(" \u2014 "),aW=a("a"),iUo=o("RemBertForCausalLM"),dUo=o(" (RemBERT model)"),mUo=l(),lv=a("li"),Qbe=a("strong"),cUo=o("roberta"),fUo=o(" \u2014 "),nW=a("a"),gUo=o("RobertaForCausalLM"),hUo=o(" (RoBERTa model)"),uUo=l(),iv=a("li"),Wbe=a("strong"),pUo=o("roformer"),_Uo=o(" \u2014 "),sW=a("a"),bUo=o("RoFormerForCausalLM"),vUo=o(" (RoFormer model)"),FUo=l(),dv=a("li"),Ube=a("strong"),TUo=o("speech_to_text_2"),MUo=o(" \u2014 "),lW=a("a"),EUo=o("Speech2Text2ForCausalLM"),CUo=o(" (Speech2Text2 model)"),wUo=l(),mv=a("li"),Hbe=a("strong"),AUo=o("transfo-xl"),LUo=o(" \u2014 "),iW=a("a"),yUo=o("TransfoXLLMHeadModel"),xUo=o(" (Transformer-XL model)"),$Uo=l(),cv=a("li"),Jbe=a("strong"),kUo=o("trocr"),SUo=o(" \u2014 "),dW=a("a"),RUo=o("TrOCRForCausalLM"),PUo=o(" (TrOCR model)"),BUo=l(),fv=a("li"),Ybe=a("strong"),IUo=o("xglm"),NUo=o(" \u2014 "),mW=a("a"),qUo=o("XGLMForCausalLM"),jUo=o(" (XGLM model)"),DUo=l(),gv=a("li"),Kbe=a("strong"),GUo=o("xlm"),OUo=o(" \u2014 "),cW=a("a"),VUo=o("XLMWithLMHeadModel"),XUo=o(" (XLM model)"),zUo=l(),hv=a("li"),Zbe=a("strong"),QUo=o("xlm-prophetnet"),WUo=o(" \u2014 "),fW=a("a"),UUo=o("XLMProphetNetForCausalLM"),HUo=o(" (XLM-ProphetNet model)"),JUo=l(),uv=a("li"),eve=a("strong"),YUo=o("xlm-roberta"),KUo=o(" \u2014 "),gW=a("a"),ZUo=o("XLMRobertaForCausalLM"),eHo=o(" (XLM-RoBERTa model)"),oHo=l(),pv=a("li"),ove=a("strong"),rHo=o("xlm-roberta-xl"),tHo=o(" \u2014 "),hW=a("a"),aHo=o("XLMRobertaXLForCausalLM"),nHo=o(" (XLM-RoBERTa-XL model)"),sHo=l(),_v=a("li"),rve=a("strong"),lHo=o("xlnet"),iHo=o(" \u2014 "),uW=a("a"),dHo=o("XLNetLMHeadModel"),mHo=o(" (XLNet model)"),cHo=l(),bv=a("p"),fHo=o("The model is set in evaluation mode by default using "),tve=a("code"),gHo=o("model.eval()"),hHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ave=a("code"),uHo=o("model.train()"),pHo=l(),F(vv.$$.fragment),Peo=l(),Ad=a("h2"),Fv=a("a"),nve=a("span"),F(Hx.$$.fragment),_Ho=l(),sve=a("span"),bHo=o("AutoModelForMaskedLM"),Beo=l(),No=a("div"),F(Jx.$$.fragment),vHo=l(),Ld=a("p"),FHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),pW=a("a"),THo=o("from_pretrained()"),MHo=o(" class method or the "),_W=a("a"),EHo=o("from_config()"),CHo=o(` class
method.`),wHo=l(),Yx=a("p"),AHo=o("This class cannot be instantiated directly using "),lve=a("code"),LHo=o("__init__()"),yHo=o(" (throws an error)."),xHo=l(),Ft=a("div"),F(Kx.$$.fragment),$Ho=l(),ive=a("p"),kHo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),SHo=l(),yd=a("p"),RHo=o(`Note:
Loading a model from its configuration file does `),dve=a("strong"),PHo=o("not"),BHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bW=a("a"),IHo=o("from_pretrained()"),NHo=o(" to load the model weights."),qHo=l(),F(Tv.$$.fragment),jHo=l(),ro=a("div"),F(Zx.$$.fragment),DHo=l(),mve=a("p"),GHo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),OHo=l(),Za=a("p"),VHo=o("The model class to instantiate is selected based on the "),cve=a("code"),XHo=o("model_type"),zHo=o(` property of the config object (either
passed as an argument or loaded from `),fve=a("code"),QHo=o("pretrained_model_name_or_path"),WHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gve=a("code"),UHo=o("pretrained_model_name_or_path"),HHo=o(":"),JHo=l(),J=a("ul"),Mv=a("li"),hve=a("strong"),YHo=o("albert"),KHo=o(" \u2014 "),vW=a("a"),ZHo=o("AlbertForMaskedLM"),eJo=o(" (ALBERT model)"),oJo=l(),Ev=a("li"),uve=a("strong"),rJo=o("bart"),tJo=o(" \u2014 "),FW=a("a"),aJo=o("BartForConditionalGeneration"),nJo=o(" (BART model)"),sJo=l(),Cv=a("li"),pve=a("strong"),lJo=o("bert"),iJo=o(" \u2014 "),TW=a("a"),dJo=o("BertForMaskedLM"),mJo=o(" (BERT model)"),cJo=l(),wv=a("li"),_ve=a("strong"),fJo=o("big_bird"),gJo=o(" \u2014 "),MW=a("a"),hJo=o("BigBirdForMaskedLM"),uJo=o(" (BigBird model)"),pJo=l(),Av=a("li"),bve=a("strong"),_Jo=o("camembert"),bJo=o(" \u2014 "),EW=a("a"),vJo=o("CamembertForMaskedLM"),FJo=o(" (CamemBERT model)"),TJo=l(),Lv=a("li"),vve=a("strong"),MJo=o("convbert"),EJo=o(" \u2014 "),CW=a("a"),CJo=o("ConvBertForMaskedLM"),wJo=o(" (ConvBERT model)"),AJo=l(),yv=a("li"),Fve=a("strong"),LJo=o("data2vec-text"),yJo=o(" \u2014 "),wW=a("a"),xJo=o("Data2VecTextForMaskedLM"),$Jo=o(" (Data2VecText model)"),kJo=l(),xv=a("li"),Tve=a("strong"),SJo=o("deberta"),RJo=o(" \u2014 "),AW=a("a"),PJo=o("DebertaForMaskedLM"),BJo=o(" (DeBERTa model)"),IJo=l(),$v=a("li"),Mve=a("strong"),NJo=o("deberta-v2"),qJo=o(" \u2014 "),LW=a("a"),jJo=o("DebertaV2ForMaskedLM"),DJo=o(" (DeBERTa-v2 model)"),GJo=l(),kv=a("li"),Eve=a("strong"),OJo=o("distilbert"),VJo=o(" \u2014 "),yW=a("a"),XJo=o("DistilBertForMaskedLM"),zJo=o(" (DistilBERT model)"),QJo=l(),Sv=a("li"),Cve=a("strong"),WJo=o("electra"),UJo=o(" \u2014 "),xW=a("a"),HJo=o("ElectraForMaskedLM"),JJo=o(" (ELECTRA model)"),YJo=l(),Rv=a("li"),wve=a("strong"),KJo=o("ernie"),ZJo=o(" \u2014 "),$W=a("a"),eYo=o("ErnieForMaskedLM"),oYo=o(" (ERNIE model)"),rYo=l(),Pv=a("li"),Ave=a("strong"),tYo=o("flaubert"),aYo=o(" \u2014 "),kW=a("a"),nYo=o("FlaubertWithLMHeadModel"),sYo=o(" (FlauBERT model)"),lYo=l(),Bv=a("li"),Lve=a("strong"),iYo=o("fnet"),dYo=o(" \u2014 "),SW=a("a"),mYo=o("FNetForMaskedLM"),cYo=o(" (FNet model)"),fYo=l(),Iv=a("li"),yve=a("strong"),gYo=o("funnel"),hYo=o(" \u2014 "),RW=a("a"),uYo=o("FunnelForMaskedLM"),pYo=o(" (Funnel Transformer model)"),_Yo=l(),Nv=a("li"),xve=a("strong"),bYo=o("ibert"),vYo=o(" \u2014 "),PW=a("a"),FYo=o("IBertForMaskedLM"),TYo=o(" (I-BERT model)"),MYo=l(),qv=a("li"),$ve=a("strong"),EYo=o("layoutlm"),CYo=o(" \u2014 "),BW=a("a"),wYo=o("LayoutLMForMaskedLM"),AYo=o(" (LayoutLM model)"),LYo=l(),jv=a("li"),kve=a("strong"),yYo=o("longformer"),xYo=o(" \u2014 "),IW=a("a"),$Yo=o("LongformerForMaskedLM"),kYo=o(" (Longformer model)"),SYo=l(),Dv=a("li"),Sve=a("strong"),RYo=o("luke"),PYo=o(" \u2014 "),NW=a("a"),BYo=o("LukeForMaskedLM"),IYo=o(" (LUKE model)"),NYo=l(),Gv=a("li"),Rve=a("strong"),qYo=o("mbart"),jYo=o(" \u2014 "),qW=a("a"),DYo=o("MBartForConditionalGeneration"),GYo=o(" (mBART model)"),OYo=l(),Ov=a("li"),Pve=a("strong"),VYo=o("megatron-bert"),XYo=o(" \u2014 "),jW=a("a"),zYo=o("MegatronBertForMaskedLM"),QYo=o(" (Megatron-BERT model)"),WYo=l(),Vv=a("li"),Bve=a("strong"),UYo=o("mobilebert"),HYo=o(" \u2014 "),DW=a("a"),JYo=o("MobileBertForMaskedLM"),YYo=o(" (MobileBERT model)"),KYo=l(),Xv=a("li"),Ive=a("strong"),ZYo=o("mpnet"),eKo=o(" \u2014 "),GW=a("a"),oKo=o("MPNetForMaskedLM"),rKo=o(" (MPNet model)"),tKo=l(),zv=a("li"),Nve=a("strong"),aKo=o("mvp"),nKo=o(" \u2014 "),OW=a("a"),sKo=o("MvpForConditionalGeneration"),lKo=o(" (MVP model)"),iKo=l(),Qv=a("li"),qve=a("strong"),dKo=o("nezha"),mKo=o(" \u2014 "),VW=a("a"),cKo=o("NezhaForMaskedLM"),fKo=o(" (Nezha model)"),gKo=l(),Wv=a("li"),jve=a("strong"),hKo=o("nystromformer"),uKo=o(" \u2014 "),XW=a("a"),pKo=o("NystromformerForMaskedLM"),_Ko=o(" (Nystr\xF6mformer model)"),bKo=l(),Uv=a("li"),Dve=a("strong"),vKo=o("perceiver"),FKo=o(" \u2014 "),zW=a("a"),TKo=o("PerceiverForMaskedLM"),MKo=o(" (Perceiver model)"),EKo=l(),Hv=a("li"),Gve=a("strong"),CKo=o("qdqbert"),wKo=o(" \u2014 "),QW=a("a"),AKo=o("QDQBertForMaskedLM"),LKo=o(" (QDQBert model)"),yKo=l(),Jv=a("li"),Ove=a("strong"),xKo=o("reformer"),$Ko=o(" \u2014 "),WW=a("a"),kKo=o("ReformerForMaskedLM"),SKo=o(" (Reformer model)"),RKo=l(),Yv=a("li"),Vve=a("strong"),PKo=o("rembert"),BKo=o(" \u2014 "),UW=a("a"),IKo=o("RemBertForMaskedLM"),NKo=o(" (RemBERT model)"),qKo=l(),Kv=a("li"),Xve=a("strong"),jKo=o("roberta"),DKo=o(" \u2014 "),HW=a("a"),GKo=o("RobertaForMaskedLM"),OKo=o(" (RoBERTa model)"),VKo=l(),Zv=a("li"),zve=a("strong"),XKo=o("roformer"),zKo=o(" \u2014 "),JW=a("a"),QKo=o("RoFormerForMaskedLM"),WKo=o(" (RoFormer model)"),UKo=l(),eF=a("li"),Qve=a("strong"),HKo=o("squeezebert"),JKo=o(" \u2014 "),YW=a("a"),YKo=o("SqueezeBertForMaskedLM"),KKo=o(" (SqueezeBERT model)"),ZKo=l(),oF=a("li"),Wve=a("strong"),eZo=o("tapas"),oZo=o(" \u2014 "),KW=a("a"),rZo=o("TapasForMaskedLM"),tZo=o(" (TAPAS model)"),aZo=l(),rF=a("li"),Uve=a("strong"),nZo=o("wav2vec2"),sZo=o(" \u2014 "),Hve=a("code"),lZo=o("Wav2Vec2ForMaskedLM"),iZo=o(" (Wav2Vec2 model)"),dZo=l(),tF=a("li"),Jve=a("strong"),mZo=o("xlm"),cZo=o(" \u2014 "),ZW=a("a"),fZo=o("XLMWithLMHeadModel"),gZo=o(" (XLM model)"),hZo=l(),aF=a("li"),Yve=a("strong"),uZo=o("xlm-roberta"),pZo=o(" \u2014 "),eU=a("a"),_Zo=o("XLMRobertaForMaskedLM"),bZo=o(" (XLM-RoBERTa model)"),vZo=l(),nF=a("li"),Kve=a("strong"),FZo=o("xlm-roberta-xl"),TZo=o(" \u2014 "),oU=a("a"),MZo=o("XLMRobertaXLForMaskedLM"),EZo=o(" (XLM-RoBERTa-XL model)"),CZo=l(),sF=a("li"),Zve=a("strong"),wZo=o("yoso"),AZo=o(" \u2014 "),rU=a("a"),LZo=o("YosoForMaskedLM"),yZo=o(" (YOSO model)"),xZo=l(),lF=a("p"),$Zo=o("The model is set in evaluation mode by default using "),eFe=a("code"),kZo=o("model.eval()"),SZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),oFe=a("code"),RZo=o("model.train()"),PZo=l(),F(iF.$$.fragment),Ieo=l(),xd=a("h2"),dF=a("a"),rFe=a("span"),F(e$.$$.fragment),BZo=l(),tFe=a("span"),IZo=o("AutoModelForSeq2SeqLM"),Neo=l(),qo=a("div"),F(o$.$$.fragment),NZo=l(),$d=a("p"),qZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),tU=a("a"),jZo=o("from_pretrained()"),DZo=o(" class method or the "),aU=a("a"),GZo=o("from_config()"),OZo=o(` class
method.`),VZo=l(),r$=a("p"),XZo=o("This class cannot be instantiated directly using "),aFe=a("code"),zZo=o("__init__()"),QZo=o(" (throws an error)."),WZo=l(),Tt=a("div"),F(t$.$$.fragment),UZo=l(),nFe=a("p"),HZo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),JZo=l(),kd=a("p"),YZo=o(`Note:
Loading a model from its configuration file does `),sFe=a("strong"),KZo=o("not"),ZZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nU=a("a"),eer=o("from_pretrained()"),oer=o(" to load the model weights."),rer=l(),F(mF.$$.fragment),ter=l(),to=a("div"),F(a$.$$.fragment),aer=l(),lFe=a("p"),ner=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),ser=l(),en=a("p"),ler=o("The model class to instantiate is selected based on the "),iFe=a("code"),ier=o("model_type"),der=o(` property of the config object (either
passed as an argument or loaded from `),dFe=a("code"),mer=o("pretrained_model_name_or_path"),cer=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mFe=a("code"),fer=o("pretrained_model_name_or_path"),ger=o(":"),her=l(),fe=a("ul"),cF=a("li"),cFe=a("strong"),uer=o("bart"),per=o(" \u2014 "),sU=a("a"),_er=o("BartForConditionalGeneration"),ber=o(" (BART model)"),ver=l(),fF=a("li"),fFe=a("strong"),Fer=o("bigbird_pegasus"),Ter=o(" \u2014 "),lU=a("a"),Mer=o("BigBirdPegasusForConditionalGeneration"),Eer=o(" (BigBird-Pegasus model)"),Cer=l(),gF=a("li"),gFe=a("strong"),wer=o("blenderbot"),Aer=o(" \u2014 "),iU=a("a"),Ler=o("BlenderbotForConditionalGeneration"),yer=o(" (Blenderbot model)"),xer=l(),hF=a("li"),hFe=a("strong"),$er=o("blenderbot-small"),ker=o(" \u2014 "),dU=a("a"),Ser=o("BlenderbotSmallForConditionalGeneration"),Rer=o(" (BlenderbotSmall model)"),Per=l(),uF=a("li"),uFe=a("strong"),Ber=o("encoder-decoder"),Ier=o(" \u2014 "),mU=a("a"),Ner=o("EncoderDecoderModel"),qer=o(" (Encoder decoder model)"),jer=l(),pF=a("li"),pFe=a("strong"),Der=o("fsmt"),Ger=o(" \u2014 "),cU=a("a"),Oer=o("FSMTForConditionalGeneration"),Ver=o(" (FairSeq Machine-Translation model)"),Xer=l(),_F=a("li"),_Fe=a("strong"),zer=o("led"),Qer=o(" \u2014 "),fU=a("a"),Wer=o("LEDForConditionalGeneration"),Uer=o(" (LED model)"),Her=l(),bF=a("li"),bFe=a("strong"),Jer=o("longt5"),Yer=o(" \u2014 "),gU=a("a"),Ker=o("LongT5ForConditionalGeneration"),Zer=o(" (LongT5 model)"),eor=l(),vF=a("li"),vFe=a("strong"),oor=o("m2m_100"),ror=o(" \u2014 "),hU=a("a"),tor=o("M2M100ForConditionalGeneration"),aor=o(" (M2M100 model)"),nor=l(),FF=a("li"),FFe=a("strong"),sor=o("marian"),lor=o(" \u2014 "),uU=a("a"),ior=o("MarianMTModel"),dor=o(" (Marian model)"),mor=l(),TF=a("li"),TFe=a("strong"),cor=o("mbart"),gor=o(" \u2014 "),pU=a("a"),hor=o("MBartForConditionalGeneration"),uor=o(" (mBART model)"),por=l(),MF=a("li"),MFe=a("strong"),_or=o("mt5"),bor=o(" \u2014 "),_U=a("a"),vor=o("MT5ForConditionalGeneration"),For=o(" (MT5 model)"),Tor=l(),EF=a("li"),EFe=a("strong"),Mor=o("mvp"),Eor=o(" \u2014 "),bU=a("a"),Cor=o("MvpForConditionalGeneration"),wor=o(" (MVP model)"),Aor=l(),CF=a("li"),CFe=a("strong"),Lor=o("nllb"),yor=o(" \u2014 "),vU=a("a"),xor=o("M2M100ForConditionalGeneration"),$or=o(" (NLLB model)"),kor=l(),wF=a("li"),wFe=a("strong"),Sor=o("pegasus"),Ror=o(" \u2014 "),FU=a("a"),Por=o("PegasusForConditionalGeneration"),Bor=o(" (Pegasus model)"),Ior=l(),AF=a("li"),AFe=a("strong"),Nor=o("pegasus_x"),qor=o(" \u2014 "),TU=a("a"),jor=o("PegasusXForConditionalGeneration"),Dor=o(" (PEGASUS-X model)"),Gor=l(),LF=a("li"),LFe=a("strong"),Oor=o("plbart"),Vor=o(" \u2014 "),MU=a("a"),Xor=o("PLBartForConditionalGeneration"),zor=o(" (PLBart model)"),Qor=l(),yF=a("li"),yFe=a("strong"),Wor=o("prophetnet"),Uor=o(" \u2014 "),EU=a("a"),Hor=o("ProphetNetForConditionalGeneration"),Jor=o(" (ProphetNet model)"),Yor=l(),xF=a("li"),xFe=a("strong"),Kor=o("t5"),Zor=o(" \u2014 "),CU=a("a"),err=o("T5ForConditionalGeneration"),orr=o(" (T5 model)"),rrr=l(),$F=a("li"),$Fe=a("strong"),trr=o("xlm-prophetnet"),arr=o(" \u2014 "),wU=a("a"),nrr=o("XLMProphetNetForConditionalGeneration"),srr=o(" (XLM-ProphetNet model)"),lrr=l(),kF=a("p"),irr=o("The model is set in evaluation mode by default using "),kFe=a("code"),drr=o("model.eval()"),mrr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),SFe=a("code"),crr=o("model.train()"),frr=l(),F(SF.$$.fragment),qeo=l(),Sd=a("h2"),RF=a("a"),RFe=a("span"),F(n$.$$.fragment),grr=l(),PFe=a("span"),hrr=o("AutoModelForSequenceClassification"),jeo=l(),jo=a("div"),F(s$.$$.fragment),urr=l(),Rd=a("p"),prr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),AU=a("a"),_rr=o("from_pretrained()"),brr=o(" class method or the "),LU=a("a"),vrr=o("from_config()"),Frr=o(` class
method.`),Trr=l(),l$=a("p"),Mrr=o("This class cannot be instantiated directly using "),BFe=a("code"),Err=o("__init__()"),Crr=o(" (throws an error)."),wrr=l(),Mt=a("div"),F(i$.$$.fragment),Arr=l(),IFe=a("p"),Lrr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),yrr=l(),Pd=a("p"),xrr=o(`Note:
Loading a model from its configuration file does `),NFe=a("strong"),$rr=o("not"),krr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yU=a("a"),Srr=o("from_pretrained()"),Rrr=o(" to load the model weights."),Prr=l(),F(PF.$$.fragment),Brr=l(),ao=a("div"),F(d$.$$.fragment),Irr=l(),qFe=a("p"),Nrr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),qrr=l(),on=a("p"),jrr=o("The model class to instantiate is selected based on the "),jFe=a("code"),Drr=o("model_type"),Grr=o(` property of the config object (either
passed as an argument or loaded from `),DFe=a("code"),Orr=o("pretrained_model_name_or_path"),Vrr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),GFe=a("code"),Xrr=o("pretrained_model_name_or_path"),zrr=o(":"),Qrr=l(),B=a("ul"),BF=a("li"),OFe=a("strong"),Wrr=o("albert"),Urr=o(" \u2014 "),xU=a("a"),Hrr=o("AlbertForSequenceClassification"),Jrr=o(" (ALBERT model)"),Yrr=l(),IF=a("li"),VFe=a("strong"),Krr=o("bart"),Zrr=o(" \u2014 "),$U=a("a"),etr=o("BartForSequenceClassification"),otr=o(" (BART model)"),rtr=l(),NF=a("li"),XFe=a("strong"),ttr=o("bert"),atr=o(" \u2014 "),kU=a("a"),ntr=o("BertForSequenceClassification"),str=o(" (BERT model)"),ltr=l(),qF=a("li"),zFe=a("strong"),itr=o("big_bird"),dtr=o(" \u2014 "),SU=a("a"),mtr=o("BigBirdForSequenceClassification"),ctr=o(" (BigBird model)"),ftr=l(),jF=a("li"),QFe=a("strong"),gtr=o("bigbird_pegasus"),htr=o(" \u2014 "),RU=a("a"),utr=o("BigBirdPegasusForSequenceClassification"),ptr=o(" (BigBird-Pegasus model)"),_tr=l(),DF=a("li"),WFe=a("strong"),btr=o("bloom"),vtr=o(" \u2014 "),PU=a("a"),Ftr=o("BloomForSequenceClassification"),Ttr=o(" (BLOOM model)"),Mtr=l(),GF=a("li"),UFe=a("strong"),Etr=o("camembert"),Ctr=o(" \u2014 "),BU=a("a"),wtr=o("CamembertForSequenceClassification"),Atr=o(" (CamemBERT model)"),Ltr=l(),OF=a("li"),HFe=a("strong"),ytr=o("canine"),xtr=o(" \u2014 "),IU=a("a"),$tr=o("CanineForSequenceClassification"),ktr=o(" (CANINE model)"),Str=l(),VF=a("li"),JFe=a("strong"),Rtr=o("convbert"),Ptr=o(" \u2014 "),NU=a("a"),Btr=o("ConvBertForSequenceClassification"),Itr=o(" (ConvBERT model)"),Ntr=l(),XF=a("li"),YFe=a("strong"),qtr=o("ctrl"),jtr=o(" \u2014 "),qU=a("a"),Dtr=o("CTRLForSequenceClassification"),Gtr=o(" (CTRL model)"),Otr=l(),zF=a("li"),KFe=a("strong"),Vtr=o("data2vec-text"),Xtr=o(" \u2014 "),jU=a("a"),ztr=o("Data2VecTextForSequenceClassification"),Qtr=o(" (Data2VecText model)"),Wtr=l(),QF=a("li"),ZFe=a("strong"),Utr=o("deberta"),Htr=o(" \u2014 "),DU=a("a"),Jtr=o("DebertaForSequenceClassification"),Ytr=o(" (DeBERTa model)"),Ktr=l(),WF=a("li"),eTe=a("strong"),Ztr=o("deberta-v2"),ear=o(" \u2014 "),GU=a("a"),oar=o("DebertaV2ForSequenceClassification"),rar=o(" (DeBERTa-v2 model)"),tar=l(),UF=a("li"),oTe=a("strong"),aar=o("distilbert"),nar=o(" \u2014 "),OU=a("a"),sar=o("DistilBertForSequenceClassification"),lar=o(" (DistilBERT model)"),iar=l(),HF=a("li"),rTe=a("strong"),dar=o("electra"),mar=o(" \u2014 "),VU=a("a"),car=o("ElectraForSequenceClassification"),far=o(" (ELECTRA model)"),gar=l(),JF=a("li"),tTe=a("strong"),har=o("ernie"),uar=o(" \u2014 "),XU=a("a"),par=o("ErnieForSequenceClassification"),_ar=o(" (ERNIE model)"),bar=l(),YF=a("li"),aTe=a("strong"),Far=o("esm"),Tar=o(" \u2014 "),zU=a("a"),Mar=o("EsmForSequenceClassification"),Ear=o(" (ESM model)"),Car=l(),KF=a("li"),nTe=a("strong"),war=o("flaubert"),Aar=o(" \u2014 "),QU=a("a"),Lar=o("FlaubertForSequenceClassification"),yar=o(" (FlauBERT model)"),xar=l(),ZF=a("li"),sTe=a("strong"),$ar=o("fnet"),kar=o(" \u2014 "),WU=a("a"),Sar=o("FNetForSequenceClassification"),Rar=o(" (FNet model)"),Par=l(),eT=a("li"),lTe=a("strong"),Bar=o("funnel"),Iar=o(" \u2014 "),UU=a("a"),Nar=o("FunnelForSequenceClassification"),qar=o(" (Funnel Transformer model)"),jar=l(),oT=a("li"),iTe=a("strong"),Dar=o("gpt2"),Gar=o(" \u2014 "),HU=a("a"),Oar=o("GPT2ForSequenceClassification"),Var=o(" (OpenAI GPT-2 model)"),Xar=l(),rT=a("li"),dTe=a("strong"),zar=o("gpt_neo"),Qar=o(" \u2014 "),JU=a("a"),War=o("GPTNeoForSequenceClassification"),Uar=o(" (GPT Neo model)"),Har=l(),tT=a("li"),mTe=a("strong"),Jar=o("gptj"),Yar=o(" \u2014 "),YU=a("a"),Kar=o("GPTJForSequenceClassification"),Zar=o(" (GPT-J model)"),enr=l(),aT=a("li"),cTe=a("strong"),onr=o("ibert"),rnr=o(" \u2014 "),KU=a("a"),tnr=o("IBertForSequenceClassification"),anr=o(" (I-BERT model)"),nnr=l(),nT=a("li"),fTe=a("strong"),snr=o("layoutlm"),lnr=o(" \u2014 "),ZU=a("a"),inr=o("LayoutLMForSequenceClassification"),dnr=o(" (LayoutLM model)"),mnr=l(),sT=a("li"),gTe=a("strong"),cnr=o("layoutlmv2"),fnr=o(" \u2014 "),eH=a("a"),gnr=o("LayoutLMv2ForSequenceClassification"),hnr=o(" (LayoutLMv2 model)"),unr=l(),lT=a("li"),hTe=a("strong"),pnr=o("layoutlmv3"),_nr=o(" \u2014 "),oH=a("a"),bnr=o("LayoutLMv3ForSequenceClassification"),vnr=o(" (LayoutLMv3 model)"),Fnr=l(),iT=a("li"),uTe=a("strong"),Tnr=o("led"),Mnr=o(" \u2014 "),rH=a("a"),Enr=o("LEDForSequenceClassification"),Cnr=o(" (LED model)"),wnr=l(),dT=a("li"),pTe=a("strong"),Anr=o("longformer"),Lnr=o(" \u2014 "),tH=a("a"),ynr=o("LongformerForSequenceClassification"),xnr=o(" (Longformer model)"),$nr=l(),mT=a("li"),_Te=a("strong"),knr=o("luke"),Snr=o(" \u2014 "),aH=a("a"),Rnr=o("LukeForSequenceClassification"),Pnr=o(" (LUKE model)"),Bnr=l(),cT=a("li"),bTe=a("strong"),Inr=o("markuplm"),Nnr=o(" \u2014 "),nH=a("a"),qnr=o("MarkupLMForSequenceClassification"),jnr=o(" (MarkupLM model)"),Dnr=l(),fT=a("li"),vTe=a("strong"),Gnr=o("mbart"),Onr=o(" \u2014 "),sH=a("a"),Vnr=o("MBartForSequenceClassification"),Xnr=o(" (mBART model)"),znr=l(),gT=a("li"),FTe=a("strong"),Qnr=o("megatron-bert"),Wnr=o(" \u2014 "),lH=a("a"),Unr=o("MegatronBertForSequenceClassification"),Hnr=o(" (Megatron-BERT model)"),Jnr=l(),hT=a("li"),TTe=a("strong"),Ynr=o("mobilebert"),Knr=o(" \u2014 "),iH=a("a"),Znr=o("MobileBertForSequenceClassification"),esr=o(" (MobileBERT model)"),osr=l(),uT=a("li"),MTe=a("strong"),rsr=o("mpnet"),tsr=o(" \u2014 "),dH=a("a"),asr=o("MPNetForSequenceClassification"),nsr=o(" (MPNet model)"),ssr=l(),pT=a("li"),ETe=a("strong"),lsr=o("mvp"),isr=o(" \u2014 "),mH=a("a"),dsr=o("MvpForSequenceClassification"),msr=o(" (MVP model)"),csr=l(),_T=a("li"),CTe=a("strong"),fsr=o("nezha"),gsr=o(" \u2014 "),cH=a("a"),hsr=o("NezhaForSequenceClassification"),usr=o(" (Nezha model)"),psr=l(),bT=a("li"),wTe=a("strong"),_sr=o("nystromformer"),bsr=o(" \u2014 "),fH=a("a"),vsr=o("NystromformerForSequenceClassification"),Fsr=o(" (Nystr\xF6mformer model)"),Tsr=l(),vT=a("li"),ATe=a("strong"),Msr=o("openai-gpt"),Esr=o(" \u2014 "),gH=a("a"),Csr=o("OpenAIGPTForSequenceClassification"),wsr=o(" (OpenAI GPT model)"),Asr=l(),FT=a("li"),LTe=a("strong"),Lsr=o("opt"),ysr=o(" \u2014 "),hH=a("a"),xsr=o("OPTForSequenceClassification"),$sr=o(" (OPT model)"),ksr=l(),TT=a("li"),yTe=a("strong"),Ssr=o("perceiver"),Rsr=o(" \u2014 "),uH=a("a"),Psr=o("PerceiverForSequenceClassification"),Bsr=o(" (Perceiver model)"),Isr=l(),MT=a("li"),xTe=a("strong"),Nsr=o("plbart"),qsr=o(" \u2014 "),pH=a("a"),jsr=o("PLBartForSequenceClassification"),Dsr=o(" (PLBart model)"),Gsr=l(),ET=a("li"),$Te=a("strong"),Osr=o("qdqbert"),Vsr=o(" \u2014 "),_H=a("a"),Xsr=o("QDQBertForSequenceClassification"),zsr=o(" (QDQBert model)"),Qsr=l(),CT=a("li"),kTe=a("strong"),Wsr=o("reformer"),Usr=o(" \u2014 "),bH=a("a"),Hsr=o("ReformerForSequenceClassification"),Jsr=o(" (Reformer model)"),Ysr=l(),wT=a("li"),STe=a("strong"),Ksr=o("rembert"),Zsr=o(" \u2014 "),vH=a("a"),elr=o("RemBertForSequenceClassification"),olr=o(" (RemBERT model)"),rlr=l(),AT=a("li"),RTe=a("strong"),tlr=o("roberta"),alr=o(" \u2014 "),FH=a("a"),nlr=o("RobertaForSequenceClassification"),slr=o(" (RoBERTa model)"),llr=l(),LT=a("li"),PTe=a("strong"),ilr=o("roformer"),dlr=o(" \u2014 "),TH=a("a"),mlr=o("RoFormerForSequenceClassification"),clr=o(" (RoFormer model)"),flr=l(),yT=a("li"),BTe=a("strong"),glr=o("squeezebert"),hlr=o(" \u2014 "),MH=a("a"),ulr=o("SqueezeBertForSequenceClassification"),plr=o(" (SqueezeBERT model)"),_lr=l(),xT=a("li"),ITe=a("strong"),blr=o("tapas"),vlr=o(" \u2014 "),EH=a("a"),Flr=o("TapasForSequenceClassification"),Tlr=o(" (TAPAS model)"),Mlr=l(),$T=a("li"),NTe=a("strong"),Elr=o("transfo-xl"),Clr=o(" \u2014 "),CH=a("a"),wlr=o("TransfoXLForSequenceClassification"),Alr=o(" (Transformer-XL model)"),Llr=l(),kT=a("li"),qTe=a("strong"),ylr=o("xlm"),xlr=o(" \u2014 "),wH=a("a"),$lr=o("XLMForSequenceClassification"),klr=o(" (XLM model)"),Slr=l(),ST=a("li"),jTe=a("strong"),Rlr=o("xlm-roberta"),Plr=o(" \u2014 "),AH=a("a"),Blr=o("XLMRobertaForSequenceClassification"),Ilr=o(" (XLM-RoBERTa model)"),Nlr=l(),RT=a("li"),DTe=a("strong"),qlr=o("xlm-roberta-xl"),jlr=o(" \u2014 "),LH=a("a"),Dlr=o("XLMRobertaXLForSequenceClassification"),Glr=o(" (XLM-RoBERTa-XL model)"),Olr=l(),PT=a("li"),GTe=a("strong"),Vlr=o("xlnet"),Xlr=o(" \u2014 "),yH=a("a"),zlr=o("XLNetForSequenceClassification"),Qlr=o(" (XLNet model)"),Wlr=l(),BT=a("li"),OTe=a("strong"),Ulr=o("yoso"),Hlr=o(" \u2014 "),xH=a("a"),Jlr=o("YosoForSequenceClassification"),Ylr=o(" (YOSO model)"),Klr=l(),IT=a("p"),Zlr=o("The model is set in evaluation mode by default using "),VTe=a("code"),eir=o("model.eval()"),oir=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),XTe=a("code"),rir=o("model.train()"),tir=l(),F(NT.$$.fragment),Deo=l(),Bd=a("h2"),qT=a("a"),zTe=a("span"),F(m$.$$.fragment),air=l(),QTe=a("span"),nir=o("AutoModelForMultipleChoice"),Geo=l(),Do=a("div"),F(c$.$$.fragment),sir=l(),Id=a("p"),lir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),$H=a("a"),iir=o("from_pretrained()"),dir=o(" class method or the "),kH=a("a"),mir=o("from_config()"),cir=o(` class
method.`),fir=l(),f$=a("p"),gir=o("This class cannot be instantiated directly using "),WTe=a("code"),hir=o("__init__()"),uir=o(" (throws an error)."),pir=l(),Et=a("div"),F(g$.$$.fragment),_ir=l(),UTe=a("p"),bir=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),vir=l(),Nd=a("p"),Fir=o(`Note:
Loading a model from its configuration file does `),HTe=a("strong"),Tir=o("not"),Mir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SH=a("a"),Eir=o("from_pretrained()"),Cir=o(" to load the model weights."),wir=l(),F(jT.$$.fragment),Air=l(),no=a("div"),F(h$.$$.fragment),Lir=l(),JTe=a("p"),yir=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),xir=l(),rn=a("p"),$ir=o("The model class to instantiate is selected based on the "),YTe=a("code"),kir=o("model_type"),Sir=o(` property of the config object (either
passed as an argument or loaded from `),KTe=a("code"),Rir=o("pretrained_model_name_or_path"),Pir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZTe=a("code"),Bir=o("pretrained_model_name_or_path"),Iir=o(":"),Nir=l(),Z=a("ul"),DT=a("li"),eMe=a("strong"),qir=o("albert"),jir=o(" \u2014 "),RH=a("a"),Dir=o("AlbertForMultipleChoice"),Gir=o(" (ALBERT model)"),Oir=l(),GT=a("li"),oMe=a("strong"),Vir=o("bert"),Xir=o(" \u2014 "),PH=a("a"),zir=o("BertForMultipleChoice"),Qir=o(" (BERT model)"),Wir=l(),OT=a("li"),rMe=a("strong"),Uir=o("big_bird"),Hir=o(" \u2014 "),BH=a("a"),Jir=o("BigBirdForMultipleChoice"),Yir=o(" (BigBird model)"),Kir=l(),VT=a("li"),tMe=a("strong"),Zir=o("camembert"),edr=o(" \u2014 "),IH=a("a"),odr=o("CamembertForMultipleChoice"),rdr=o(" (CamemBERT model)"),tdr=l(),XT=a("li"),aMe=a("strong"),adr=o("canine"),ndr=o(" \u2014 "),NH=a("a"),sdr=o("CanineForMultipleChoice"),ldr=o(" (CANINE model)"),idr=l(),zT=a("li"),nMe=a("strong"),ddr=o("convbert"),mdr=o(" \u2014 "),qH=a("a"),cdr=o("ConvBertForMultipleChoice"),fdr=o(" (ConvBERT model)"),gdr=l(),QT=a("li"),sMe=a("strong"),hdr=o("data2vec-text"),udr=o(" \u2014 "),jH=a("a"),pdr=o("Data2VecTextForMultipleChoice"),_dr=o(" (Data2VecText model)"),bdr=l(),WT=a("li"),lMe=a("strong"),vdr=o("deberta-v2"),Fdr=o(" \u2014 "),DH=a("a"),Tdr=o("DebertaV2ForMultipleChoice"),Mdr=o(" (DeBERTa-v2 model)"),Edr=l(),UT=a("li"),iMe=a("strong"),Cdr=o("distilbert"),wdr=o(" \u2014 "),GH=a("a"),Adr=o("DistilBertForMultipleChoice"),Ldr=o(" (DistilBERT model)"),ydr=l(),HT=a("li"),dMe=a("strong"),xdr=o("electra"),$dr=o(" \u2014 "),OH=a("a"),kdr=o("ElectraForMultipleChoice"),Sdr=o(" (ELECTRA model)"),Rdr=l(),JT=a("li"),mMe=a("strong"),Pdr=o("ernie"),Bdr=o(" \u2014 "),VH=a("a"),Idr=o("ErnieForMultipleChoice"),Ndr=o(" (ERNIE model)"),qdr=l(),YT=a("li"),cMe=a("strong"),jdr=o("flaubert"),Ddr=o(" \u2014 "),XH=a("a"),Gdr=o("FlaubertForMultipleChoice"),Odr=o(" (FlauBERT model)"),Vdr=l(),KT=a("li"),fMe=a("strong"),Xdr=o("fnet"),zdr=o(" \u2014 "),zH=a("a"),Qdr=o("FNetForMultipleChoice"),Wdr=o(" (FNet model)"),Udr=l(),ZT=a("li"),gMe=a("strong"),Hdr=o("funnel"),Jdr=o(" \u2014 "),QH=a("a"),Ydr=o("FunnelForMultipleChoice"),Kdr=o(" (Funnel Transformer model)"),Zdr=l(),eM=a("li"),hMe=a("strong"),emr=o("ibert"),omr=o(" \u2014 "),WH=a("a"),rmr=o("IBertForMultipleChoice"),tmr=o(" (I-BERT model)"),amr=l(),oM=a("li"),uMe=a("strong"),nmr=o("longformer"),smr=o(" \u2014 "),UH=a("a"),lmr=o("LongformerForMultipleChoice"),imr=o(" (Longformer model)"),dmr=l(),rM=a("li"),pMe=a("strong"),mmr=o("luke"),cmr=o(" \u2014 "),HH=a("a"),fmr=o("LukeForMultipleChoice"),gmr=o(" (LUKE model)"),hmr=l(),tM=a("li"),_Me=a("strong"),umr=o("megatron-bert"),pmr=o(" \u2014 "),JH=a("a"),_mr=o("MegatronBertForMultipleChoice"),bmr=o(" (Megatron-BERT model)"),vmr=l(),aM=a("li"),bMe=a("strong"),Fmr=o("mobilebert"),Tmr=o(" \u2014 "),YH=a("a"),Mmr=o("MobileBertForMultipleChoice"),Emr=o(" (MobileBERT model)"),Cmr=l(),nM=a("li"),vMe=a("strong"),wmr=o("mpnet"),Amr=o(" \u2014 "),KH=a("a"),Lmr=o("MPNetForMultipleChoice"),ymr=o(" (MPNet model)"),xmr=l(),sM=a("li"),FMe=a("strong"),$mr=o("nezha"),kmr=o(" \u2014 "),ZH=a("a"),Smr=o("NezhaForMultipleChoice"),Rmr=o(" (Nezha model)"),Pmr=l(),lM=a("li"),TMe=a("strong"),Bmr=o("nystromformer"),Imr=o(" \u2014 "),eJ=a("a"),Nmr=o("NystromformerForMultipleChoice"),qmr=o(" (Nystr\xF6mformer model)"),jmr=l(),iM=a("li"),MMe=a("strong"),Dmr=o("qdqbert"),Gmr=o(" \u2014 "),oJ=a("a"),Omr=o("QDQBertForMultipleChoice"),Vmr=o(" (QDQBert model)"),Xmr=l(),dM=a("li"),EMe=a("strong"),zmr=o("rembert"),Qmr=o(" \u2014 "),rJ=a("a"),Wmr=o("RemBertForMultipleChoice"),Umr=o(" (RemBERT model)"),Hmr=l(),mM=a("li"),CMe=a("strong"),Jmr=o("roberta"),Ymr=o(" \u2014 "),tJ=a("a"),Kmr=o("RobertaForMultipleChoice"),Zmr=o(" (RoBERTa model)"),ecr=l(),cM=a("li"),wMe=a("strong"),ocr=o("roformer"),rcr=o(" \u2014 "),aJ=a("a"),tcr=o("RoFormerForMultipleChoice"),acr=o(" (RoFormer model)"),ncr=l(),fM=a("li"),AMe=a("strong"),scr=o("squeezebert"),lcr=o(" \u2014 "),nJ=a("a"),icr=o("SqueezeBertForMultipleChoice"),dcr=o(" (SqueezeBERT model)"),mcr=l(),gM=a("li"),LMe=a("strong"),ccr=o("xlm"),fcr=o(" \u2014 "),sJ=a("a"),gcr=o("XLMForMultipleChoice"),hcr=o(" (XLM model)"),ucr=l(),hM=a("li"),yMe=a("strong"),pcr=o("xlm-roberta"),_cr=o(" \u2014 "),lJ=a("a"),bcr=o("XLMRobertaForMultipleChoice"),vcr=o(" (XLM-RoBERTa model)"),Fcr=l(),uM=a("li"),xMe=a("strong"),Tcr=o("xlm-roberta-xl"),Mcr=o(" \u2014 "),iJ=a("a"),Ecr=o("XLMRobertaXLForMultipleChoice"),Ccr=o(" (XLM-RoBERTa-XL model)"),wcr=l(),pM=a("li"),$Me=a("strong"),Acr=o("xlnet"),Lcr=o(" \u2014 "),dJ=a("a"),ycr=o("XLNetForMultipleChoice"),xcr=o(" (XLNet model)"),$cr=l(),_M=a("li"),kMe=a("strong"),kcr=o("yoso"),Scr=o(" \u2014 "),mJ=a("a"),Rcr=o("YosoForMultipleChoice"),Pcr=o(" (YOSO model)"),Bcr=l(),bM=a("p"),Icr=o("The model is set in evaluation mode by default using "),SMe=a("code"),Ncr=o("model.eval()"),qcr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),RMe=a("code"),jcr=o("model.train()"),Dcr=l(),F(vM.$$.fragment),Oeo=l(),qd=a("h2"),FM=a("a"),PMe=a("span"),F(u$.$$.fragment),Gcr=l(),BMe=a("span"),Ocr=o("AutoModelForNextSentencePrediction"),Veo=l(),Go=a("div"),F(p$.$$.fragment),Vcr=l(),jd=a("p"),Xcr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),cJ=a("a"),zcr=o("from_pretrained()"),Qcr=o(" class method or the "),fJ=a("a"),Wcr=o("from_config()"),Ucr=o(` class
method.`),Hcr=l(),_$=a("p"),Jcr=o("This class cannot be instantiated directly using "),IMe=a("code"),Ycr=o("__init__()"),Kcr=o(" (throws an error)."),Zcr=l(),Ct=a("div"),F(b$.$$.fragment),efr=l(),NMe=a("p"),ofr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),rfr=l(),Dd=a("p"),tfr=o(`Note:
Loading a model from its configuration file does `),qMe=a("strong"),afr=o("not"),nfr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gJ=a("a"),sfr=o("from_pretrained()"),lfr=o(" to load the model weights."),ifr=l(),F(TM.$$.fragment),dfr=l(),so=a("div"),F(v$.$$.fragment),mfr=l(),jMe=a("p"),cfr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),ffr=l(),tn=a("p"),gfr=o("The model class to instantiate is selected based on the "),DMe=a("code"),hfr=o("model_type"),ufr=o(` property of the config object (either
passed as an argument or loaded from `),GMe=a("code"),pfr=o("pretrained_model_name_or_path"),_fr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),OMe=a("code"),bfr=o("pretrained_model_name_or_path"),vfr=o(":"),Ffr=l(),Ue=a("ul"),MM=a("li"),VMe=a("strong"),Tfr=o("bert"),Mfr=o(" \u2014 "),hJ=a("a"),Efr=o("BertForNextSentencePrediction"),Cfr=o(" (BERT model)"),wfr=l(),EM=a("li"),XMe=a("strong"),Afr=o("ernie"),Lfr=o(" \u2014 "),uJ=a("a"),yfr=o("ErnieForNextSentencePrediction"),xfr=o(" (ERNIE model)"),$fr=l(),CM=a("li"),zMe=a("strong"),kfr=o("fnet"),Sfr=o(" \u2014 "),pJ=a("a"),Rfr=o("FNetForNextSentencePrediction"),Pfr=o(" (FNet model)"),Bfr=l(),wM=a("li"),QMe=a("strong"),Ifr=o("megatron-bert"),Nfr=o(" \u2014 "),_J=a("a"),qfr=o("MegatronBertForNextSentencePrediction"),jfr=o(" (Megatron-BERT model)"),Dfr=l(),AM=a("li"),WMe=a("strong"),Gfr=o("mobilebert"),Ofr=o(" \u2014 "),bJ=a("a"),Vfr=o("MobileBertForNextSentencePrediction"),Xfr=o(" (MobileBERT model)"),zfr=l(),LM=a("li"),UMe=a("strong"),Qfr=o("nezha"),Wfr=o(" \u2014 "),vJ=a("a"),Ufr=o("NezhaForNextSentencePrediction"),Hfr=o(" (Nezha model)"),Jfr=l(),yM=a("li"),HMe=a("strong"),Yfr=o("qdqbert"),Kfr=o(" \u2014 "),FJ=a("a"),Zfr=o("QDQBertForNextSentencePrediction"),egr=o(" (QDQBert model)"),ogr=l(),xM=a("p"),rgr=o("The model is set in evaluation mode by default using "),JMe=a("code"),tgr=o("model.eval()"),agr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),YMe=a("code"),ngr=o("model.train()"),sgr=l(),F($M.$$.fragment),Xeo=l(),Gd=a("h2"),kM=a("a"),KMe=a("span"),F(F$.$$.fragment),lgr=l(),ZMe=a("span"),igr=o("AutoModelForTokenClassification"),zeo=l(),Oo=a("div"),F(T$.$$.fragment),dgr=l(),Od=a("p"),mgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),TJ=a("a"),cgr=o("from_pretrained()"),fgr=o(" class method or the "),MJ=a("a"),ggr=o("from_config()"),hgr=o(` class
method.`),ugr=l(),M$=a("p"),pgr=o("This class cannot be instantiated directly using "),eEe=a("code"),_gr=o("__init__()"),bgr=o(" (throws an error)."),vgr=l(),wt=a("div"),F(E$.$$.fragment),Fgr=l(),oEe=a("p"),Tgr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Mgr=l(),Vd=a("p"),Egr=o(`Note:
Loading a model from its configuration file does `),rEe=a("strong"),Cgr=o("not"),wgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EJ=a("a"),Agr=o("from_pretrained()"),Lgr=o(" to load the model weights."),ygr=l(),F(SM.$$.fragment),xgr=l(),lo=a("div"),F(C$.$$.fragment),$gr=l(),tEe=a("p"),kgr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Sgr=l(),an=a("p"),Rgr=o("The model class to instantiate is selected based on the "),aEe=a("code"),Pgr=o("model_type"),Bgr=o(` property of the config object (either
passed as an argument or loaded from `),nEe=a("code"),Igr=o("pretrained_model_name_or_path"),Ngr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sEe=a("code"),qgr=o("pretrained_model_name_or_path"),jgr=o(":"),Dgr=l(),H=a("ul"),RM=a("li"),lEe=a("strong"),Ggr=o("albert"),Ogr=o(" \u2014 "),CJ=a("a"),Vgr=o("AlbertForTokenClassification"),Xgr=o(" (ALBERT model)"),zgr=l(),PM=a("li"),iEe=a("strong"),Qgr=o("bert"),Wgr=o(" \u2014 "),wJ=a("a"),Ugr=o("BertForTokenClassification"),Hgr=o(" (BERT model)"),Jgr=l(),BM=a("li"),dEe=a("strong"),Ygr=o("big_bird"),Kgr=o(" \u2014 "),AJ=a("a"),Zgr=o("BigBirdForTokenClassification"),ehr=o(" (BigBird model)"),ohr=l(),IM=a("li"),mEe=a("strong"),rhr=o("bloom"),thr=o(" \u2014 "),LJ=a("a"),ahr=o("BloomForTokenClassification"),nhr=o(" (BLOOM model)"),shr=l(),NM=a("li"),cEe=a("strong"),lhr=o("camembert"),ihr=o(" \u2014 "),yJ=a("a"),dhr=o("CamembertForTokenClassification"),mhr=o(" (CamemBERT model)"),chr=l(),qM=a("li"),fEe=a("strong"),fhr=o("canine"),ghr=o(" \u2014 "),xJ=a("a"),hhr=o("CanineForTokenClassification"),uhr=o(" (CANINE model)"),phr=l(),jM=a("li"),gEe=a("strong"),_hr=o("convbert"),bhr=o(" \u2014 "),$J=a("a"),vhr=o("ConvBertForTokenClassification"),Fhr=o(" (ConvBERT model)"),Thr=l(),DM=a("li"),hEe=a("strong"),Mhr=o("data2vec-text"),Ehr=o(" \u2014 "),kJ=a("a"),Chr=o("Data2VecTextForTokenClassification"),whr=o(" (Data2VecText model)"),Ahr=l(),GM=a("li"),uEe=a("strong"),Lhr=o("deberta"),yhr=o(" \u2014 "),SJ=a("a"),xhr=o("DebertaForTokenClassification"),$hr=o(" (DeBERTa model)"),khr=l(),OM=a("li"),pEe=a("strong"),Shr=o("deberta-v2"),Rhr=o(" \u2014 "),RJ=a("a"),Phr=o("DebertaV2ForTokenClassification"),Bhr=o(" (DeBERTa-v2 model)"),Ihr=l(),VM=a("li"),_Ee=a("strong"),Nhr=o("distilbert"),qhr=o(" \u2014 "),PJ=a("a"),jhr=o("DistilBertForTokenClassification"),Dhr=o(" (DistilBERT model)"),Ghr=l(),XM=a("li"),bEe=a("strong"),Ohr=o("electra"),Vhr=o(" \u2014 "),BJ=a("a"),Xhr=o("ElectraForTokenClassification"),zhr=o(" (ELECTRA model)"),Qhr=l(),zM=a("li"),vEe=a("strong"),Whr=o("ernie"),Uhr=o(" \u2014 "),IJ=a("a"),Hhr=o("ErnieForTokenClassification"),Jhr=o(" (ERNIE model)"),Yhr=l(),QM=a("li"),FEe=a("strong"),Khr=o("esm"),Zhr=o(" \u2014 "),NJ=a("a"),eur=o("EsmForTokenClassification"),our=o(" (ESM model)"),rur=l(),WM=a("li"),TEe=a("strong"),tur=o("flaubert"),aur=o(" \u2014 "),qJ=a("a"),nur=o("FlaubertForTokenClassification"),sur=o(" (FlauBERT model)"),lur=l(),UM=a("li"),MEe=a("strong"),iur=o("fnet"),dur=o(" \u2014 "),jJ=a("a"),mur=o("FNetForTokenClassification"),cur=o(" (FNet model)"),fur=l(),HM=a("li"),EEe=a("strong"),gur=o("funnel"),hur=o(" \u2014 "),DJ=a("a"),uur=o("FunnelForTokenClassification"),pur=o(" (Funnel Transformer model)"),_ur=l(),JM=a("li"),CEe=a("strong"),bur=o("gpt2"),vur=o(" \u2014 "),GJ=a("a"),Fur=o("GPT2ForTokenClassification"),Tur=o(" (OpenAI GPT-2 model)"),Mur=l(),YM=a("li"),wEe=a("strong"),Eur=o("ibert"),Cur=o(" \u2014 "),OJ=a("a"),wur=o("IBertForTokenClassification"),Aur=o(" (I-BERT model)"),Lur=l(),KM=a("li"),AEe=a("strong"),yur=o("layoutlm"),xur=o(" \u2014 "),VJ=a("a"),$ur=o("LayoutLMForTokenClassification"),kur=o(" (LayoutLM model)"),Sur=l(),ZM=a("li"),LEe=a("strong"),Rur=o("layoutlmv2"),Pur=o(" \u2014 "),XJ=a("a"),Bur=o("LayoutLMv2ForTokenClassification"),Iur=o(" (LayoutLMv2 model)"),Nur=l(),eE=a("li"),yEe=a("strong"),qur=o("layoutlmv3"),jur=o(" \u2014 "),zJ=a("a"),Dur=o("LayoutLMv3ForTokenClassification"),Gur=o(" (LayoutLMv3 model)"),Our=l(),oE=a("li"),xEe=a("strong"),Vur=o("longformer"),Xur=o(" \u2014 "),QJ=a("a"),zur=o("LongformerForTokenClassification"),Qur=o(" (Longformer model)"),Wur=l(),rE=a("li"),$Ee=a("strong"),Uur=o("luke"),Hur=o(" \u2014 "),WJ=a("a"),Jur=o("LukeForTokenClassification"),Yur=o(" (LUKE model)"),Kur=l(),tE=a("li"),kEe=a("strong"),Zur=o("markuplm"),epr=o(" \u2014 "),UJ=a("a"),opr=o("MarkupLMForTokenClassification"),rpr=o(" (MarkupLM model)"),tpr=l(),aE=a("li"),SEe=a("strong"),apr=o("megatron-bert"),npr=o(" \u2014 "),HJ=a("a"),spr=o("MegatronBertForTokenClassification"),lpr=o(" (Megatron-BERT model)"),ipr=l(),nE=a("li"),REe=a("strong"),dpr=o("mobilebert"),mpr=o(" \u2014 "),JJ=a("a"),cpr=o("MobileBertForTokenClassification"),fpr=o(" (MobileBERT model)"),gpr=l(),sE=a("li"),PEe=a("strong"),hpr=o("mpnet"),upr=o(" \u2014 "),YJ=a("a"),ppr=o("MPNetForTokenClassification"),_pr=o(" (MPNet model)"),bpr=l(),lE=a("li"),BEe=a("strong"),vpr=o("nezha"),Fpr=o(" \u2014 "),KJ=a("a"),Tpr=o("NezhaForTokenClassification"),Mpr=o(" (Nezha model)"),Epr=l(),iE=a("li"),IEe=a("strong"),Cpr=o("nystromformer"),wpr=o(" \u2014 "),ZJ=a("a"),Apr=o("NystromformerForTokenClassification"),Lpr=o(" (Nystr\xF6mformer model)"),ypr=l(),dE=a("li"),NEe=a("strong"),xpr=o("qdqbert"),$pr=o(" \u2014 "),eY=a("a"),kpr=o("QDQBertForTokenClassification"),Spr=o(" (QDQBert model)"),Rpr=l(),mE=a("li"),qEe=a("strong"),Ppr=o("rembert"),Bpr=o(" \u2014 "),oY=a("a"),Ipr=o("RemBertForTokenClassification"),Npr=o(" (RemBERT model)"),qpr=l(),cE=a("li"),jEe=a("strong"),jpr=o("roberta"),Dpr=o(" \u2014 "),rY=a("a"),Gpr=o("RobertaForTokenClassification"),Opr=o(" (RoBERTa model)"),Vpr=l(),fE=a("li"),DEe=a("strong"),Xpr=o("roformer"),zpr=o(" \u2014 "),tY=a("a"),Qpr=o("RoFormerForTokenClassification"),Wpr=o(" (RoFormer model)"),Upr=l(),gE=a("li"),GEe=a("strong"),Hpr=o("squeezebert"),Jpr=o(" \u2014 "),aY=a("a"),Ypr=o("SqueezeBertForTokenClassification"),Kpr=o(" (SqueezeBERT model)"),Zpr=l(),hE=a("li"),OEe=a("strong"),e_r=o("xlm"),o_r=o(" \u2014 "),nY=a("a"),r_r=o("XLMForTokenClassification"),t_r=o(" (XLM model)"),a_r=l(),uE=a("li"),VEe=a("strong"),n_r=o("xlm-roberta"),s_r=o(" \u2014 "),sY=a("a"),l_r=o("XLMRobertaForTokenClassification"),i_r=o(" (XLM-RoBERTa model)"),d_r=l(),pE=a("li"),XEe=a("strong"),m_r=o("xlm-roberta-xl"),c_r=o(" \u2014 "),lY=a("a"),f_r=o("XLMRobertaXLForTokenClassification"),g_r=o(" (XLM-RoBERTa-XL model)"),h_r=l(),_E=a("li"),zEe=a("strong"),u_r=o("xlnet"),p_r=o(" \u2014 "),iY=a("a"),__r=o("XLNetForTokenClassification"),b_r=o(" (XLNet model)"),v_r=l(),bE=a("li"),QEe=a("strong"),F_r=o("yoso"),T_r=o(" \u2014 "),dY=a("a"),M_r=o("YosoForTokenClassification"),E_r=o(" (YOSO model)"),C_r=l(),vE=a("p"),w_r=o("The model is set in evaluation mode by default using "),WEe=a("code"),A_r=o("model.eval()"),L_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),UEe=a("code"),y_r=o("model.train()"),x_r=l(),F(FE.$$.fragment),Qeo=l(),Xd=a("h2"),TE=a("a"),HEe=a("span"),F(w$.$$.fragment),$_r=l(),JEe=a("span"),k_r=o("AutoModelForQuestionAnswering"),Weo=l(),Vo=a("div"),F(A$.$$.fragment),S_r=l(),zd=a("p"),R_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),mY=a("a"),P_r=o("from_pretrained()"),B_r=o(" class method or the "),cY=a("a"),I_r=o("from_config()"),N_r=o(` class
method.`),q_r=l(),L$=a("p"),j_r=o("This class cannot be instantiated directly using "),YEe=a("code"),D_r=o("__init__()"),G_r=o(" (throws an error)."),O_r=l(),At=a("div"),F(y$.$$.fragment),V_r=l(),KEe=a("p"),X_r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),z_r=l(),Qd=a("p"),Q_r=o(`Note:
Loading a model from its configuration file does `),ZEe=a("strong"),W_r=o("not"),U_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fY=a("a"),H_r=o("from_pretrained()"),J_r=o(" to load the model weights."),Y_r=l(),F(ME.$$.fragment),K_r=l(),io=a("div"),F(x$.$$.fragment),Z_r=l(),e4e=a("p"),e1r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),o1r=l(),nn=a("p"),r1r=o("The model class to instantiate is selected based on the "),o4e=a("code"),t1r=o("model_type"),a1r=o(` property of the config object (either
passed as an argument or loaded from `),r4e=a("code"),n1r=o("pretrained_model_name_or_path"),s1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t4e=a("code"),l1r=o("pretrained_model_name_or_path"),i1r=o(":"),d1r=l(),V=a("ul"),EE=a("li"),a4e=a("strong"),m1r=o("albert"),c1r=o(" \u2014 "),gY=a("a"),f1r=o("AlbertForQuestionAnswering"),g1r=o(" (ALBERT model)"),h1r=l(),CE=a("li"),n4e=a("strong"),u1r=o("bart"),p1r=o(" \u2014 "),hY=a("a"),_1r=o("BartForQuestionAnswering"),b1r=o(" (BART model)"),v1r=l(),wE=a("li"),s4e=a("strong"),F1r=o("bert"),T1r=o(" \u2014 "),uY=a("a"),M1r=o("BertForQuestionAnswering"),E1r=o(" (BERT model)"),C1r=l(),AE=a("li"),l4e=a("strong"),w1r=o("big_bird"),A1r=o(" \u2014 "),pY=a("a"),L1r=o("BigBirdForQuestionAnswering"),y1r=o(" (BigBird model)"),x1r=l(),LE=a("li"),i4e=a("strong"),$1r=o("bigbird_pegasus"),k1r=o(" \u2014 "),_Y=a("a"),S1r=o("BigBirdPegasusForQuestionAnswering"),R1r=o(" (BigBird-Pegasus model)"),P1r=l(),yE=a("li"),d4e=a("strong"),B1r=o("bloom"),I1r=o(" \u2014 "),bY=a("a"),N1r=o("BloomForQuestionAnswering"),q1r=o(" (BLOOM model)"),j1r=l(),xE=a("li"),m4e=a("strong"),D1r=o("camembert"),G1r=o(" \u2014 "),vY=a("a"),O1r=o("CamembertForQuestionAnswering"),V1r=o(" (CamemBERT model)"),X1r=l(),$E=a("li"),c4e=a("strong"),z1r=o("canine"),Q1r=o(" \u2014 "),FY=a("a"),W1r=o("CanineForQuestionAnswering"),U1r=o(" (CANINE model)"),H1r=l(),kE=a("li"),f4e=a("strong"),J1r=o("convbert"),Y1r=o(" \u2014 "),TY=a("a"),K1r=o("ConvBertForQuestionAnswering"),Z1r=o(" (ConvBERT model)"),e2r=l(),SE=a("li"),g4e=a("strong"),o2r=o("data2vec-text"),r2r=o(" \u2014 "),MY=a("a"),t2r=o("Data2VecTextForQuestionAnswering"),a2r=o(" (Data2VecText model)"),n2r=l(),RE=a("li"),h4e=a("strong"),s2r=o("deberta"),l2r=o(" \u2014 "),EY=a("a"),i2r=o("DebertaForQuestionAnswering"),d2r=o(" (DeBERTa model)"),m2r=l(),PE=a("li"),u4e=a("strong"),c2r=o("deberta-v2"),f2r=o(" \u2014 "),CY=a("a"),g2r=o("DebertaV2ForQuestionAnswering"),h2r=o(" (DeBERTa-v2 model)"),u2r=l(),BE=a("li"),p4e=a("strong"),p2r=o("distilbert"),_2r=o(" \u2014 "),wY=a("a"),b2r=o("DistilBertForQuestionAnswering"),v2r=o(" (DistilBERT model)"),F2r=l(),IE=a("li"),_4e=a("strong"),T2r=o("electra"),M2r=o(" \u2014 "),AY=a("a"),E2r=o("ElectraForQuestionAnswering"),C2r=o(" (ELECTRA model)"),w2r=l(),NE=a("li"),b4e=a("strong"),A2r=o("ernie"),L2r=o(" \u2014 "),LY=a("a"),y2r=o("ErnieForQuestionAnswering"),x2r=o(" (ERNIE model)"),$2r=l(),qE=a("li"),v4e=a("strong"),k2r=o("flaubert"),S2r=o(" \u2014 "),yY=a("a"),R2r=o("FlaubertForQuestionAnsweringSimple"),P2r=o(" (FlauBERT model)"),B2r=l(),jE=a("li"),F4e=a("strong"),I2r=o("fnet"),N2r=o(" \u2014 "),xY=a("a"),q2r=o("FNetForQuestionAnswering"),j2r=o(" (FNet model)"),D2r=l(),DE=a("li"),T4e=a("strong"),G2r=o("funnel"),O2r=o(" \u2014 "),$Y=a("a"),V2r=o("FunnelForQuestionAnswering"),X2r=o(" (Funnel Transformer model)"),z2r=l(),GE=a("li"),M4e=a("strong"),Q2r=o("gptj"),W2r=o(" \u2014 "),kY=a("a"),U2r=o("GPTJForQuestionAnswering"),H2r=o(" (GPT-J model)"),J2r=l(),OE=a("li"),E4e=a("strong"),Y2r=o("ibert"),K2r=o(" \u2014 "),SY=a("a"),Z2r=o("IBertForQuestionAnswering"),ebr=o(" (I-BERT model)"),obr=l(),VE=a("li"),C4e=a("strong"),rbr=o("layoutlmv2"),tbr=o(" \u2014 "),RY=a("a"),abr=o("LayoutLMv2ForQuestionAnswering"),nbr=o(" (LayoutLMv2 model)"),sbr=l(),XE=a("li"),w4e=a("strong"),lbr=o("layoutlmv3"),ibr=o(" \u2014 "),PY=a("a"),dbr=o("LayoutLMv3ForQuestionAnswering"),mbr=o(" (LayoutLMv3 model)"),cbr=l(),zE=a("li"),A4e=a("strong"),fbr=o("led"),gbr=o(" \u2014 "),BY=a("a"),hbr=o("LEDForQuestionAnswering"),ubr=o(" (LED model)"),pbr=l(),QE=a("li"),L4e=a("strong"),_br=o("longformer"),bbr=o(" \u2014 "),IY=a("a"),vbr=o("LongformerForQuestionAnswering"),Fbr=o(" (Longformer model)"),Tbr=l(),WE=a("li"),y4e=a("strong"),Mbr=o("luke"),Ebr=o(" \u2014 "),NY=a("a"),Cbr=o("LukeForQuestionAnswering"),wbr=o(" (LUKE model)"),Abr=l(),UE=a("li"),x4e=a("strong"),Lbr=o("lxmert"),ybr=o(" \u2014 "),qY=a("a"),xbr=o("LxmertForQuestionAnswering"),$br=o(" (LXMERT model)"),kbr=l(),HE=a("li"),$4e=a("strong"),Sbr=o("markuplm"),Rbr=o(" \u2014 "),jY=a("a"),Pbr=o("MarkupLMForQuestionAnswering"),Bbr=o(" (MarkupLM model)"),Ibr=l(),JE=a("li"),k4e=a("strong"),Nbr=o("mbart"),qbr=o(" \u2014 "),DY=a("a"),jbr=o("MBartForQuestionAnswering"),Dbr=o(" (mBART model)"),Gbr=l(),YE=a("li"),S4e=a("strong"),Obr=o("megatron-bert"),Vbr=o(" \u2014 "),GY=a("a"),Xbr=o("MegatronBertForQuestionAnswering"),zbr=o(" (Megatron-BERT model)"),Qbr=l(),KE=a("li"),R4e=a("strong"),Wbr=o("mobilebert"),Ubr=o(" \u2014 "),OY=a("a"),Hbr=o("MobileBertForQuestionAnswering"),Jbr=o(" (MobileBERT model)"),Ybr=l(),ZE=a("li"),P4e=a("strong"),Kbr=o("mpnet"),Zbr=o(" \u2014 "),VY=a("a"),evr=o("MPNetForQuestionAnswering"),ovr=o(" (MPNet model)"),rvr=l(),e4=a("li"),B4e=a("strong"),tvr=o("mvp"),avr=o(" \u2014 "),XY=a("a"),nvr=o("MvpForQuestionAnswering"),svr=o(" (MVP model)"),lvr=l(),o4=a("li"),I4e=a("strong"),ivr=o("nezha"),dvr=o(" \u2014 "),zY=a("a"),mvr=o("NezhaForQuestionAnswering"),cvr=o(" (Nezha model)"),fvr=l(),r4=a("li"),N4e=a("strong"),gvr=o("nystromformer"),hvr=o(" \u2014 "),QY=a("a"),uvr=o("NystromformerForQuestionAnswering"),pvr=o(" (Nystr\xF6mformer model)"),_vr=l(),t4=a("li"),q4e=a("strong"),bvr=o("qdqbert"),vvr=o(" \u2014 "),WY=a("a"),Fvr=o("QDQBertForQuestionAnswering"),Tvr=o(" (QDQBert model)"),Mvr=l(),a4=a("li"),j4e=a("strong"),Evr=o("reformer"),Cvr=o(" \u2014 "),UY=a("a"),wvr=o("ReformerForQuestionAnswering"),Avr=o(" (Reformer model)"),Lvr=l(),n4=a("li"),D4e=a("strong"),yvr=o("rembert"),xvr=o(" \u2014 "),HY=a("a"),$vr=o("RemBertForQuestionAnswering"),kvr=o(" (RemBERT model)"),Svr=l(),s4=a("li"),G4e=a("strong"),Rvr=o("roberta"),Pvr=o(" \u2014 "),JY=a("a"),Bvr=o("RobertaForQuestionAnswering"),Ivr=o(" (RoBERTa model)"),Nvr=l(),l4=a("li"),O4e=a("strong"),qvr=o("roformer"),jvr=o(" \u2014 "),YY=a("a"),Dvr=o("RoFormerForQuestionAnswering"),Gvr=o(" (RoFormer model)"),Ovr=l(),i4=a("li"),V4e=a("strong"),Vvr=o("splinter"),Xvr=o(" \u2014 "),KY=a("a"),zvr=o("SplinterForQuestionAnswering"),Qvr=o(" (Splinter model)"),Wvr=l(),d4=a("li"),X4e=a("strong"),Uvr=o("squeezebert"),Hvr=o(" \u2014 "),ZY=a("a"),Jvr=o("SqueezeBertForQuestionAnswering"),Yvr=o(" (SqueezeBERT model)"),Kvr=l(),m4=a("li"),z4e=a("strong"),Zvr=o("xlm"),eFr=o(" \u2014 "),eK=a("a"),oFr=o("XLMForQuestionAnsweringSimple"),rFr=o(" (XLM model)"),tFr=l(),c4=a("li"),Q4e=a("strong"),aFr=o("xlm-roberta"),nFr=o(" \u2014 "),oK=a("a"),sFr=o("XLMRobertaForQuestionAnswering"),lFr=o(" (XLM-RoBERTa model)"),iFr=l(),f4=a("li"),W4e=a("strong"),dFr=o("xlm-roberta-xl"),mFr=o(" \u2014 "),rK=a("a"),cFr=o("XLMRobertaXLForQuestionAnswering"),fFr=o(" (XLM-RoBERTa-XL model)"),gFr=l(),g4=a("li"),U4e=a("strong"),hFr=o("xlnet"),uFr=o(" \u2014 "),tK=a("a"),pFr=o("XLNetForQuestionAnsweringSimple"),_Fr=o(" (XLNet model)"),bFr=l(),h4=a("li"),H4e=a("strong"),vFr=o("yoso"),FFr=o(" \u2014 "),aK=a("a"),TFr=o("YosoForQuestionAnswering"),MFr=o(" (YOSO model)"),EFr=l(),u4=a("p"),CFr=o("The model is set in evaluation mode by default using "),J4e=a("code"),wFr=o("model.eval()"),AFr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Y4e=a("code"),LFr=o("model.train()"),yFr=l(),F(p4.$$.fragment),Ueo=l(),Wd=a("h2"),_4=a("a"),K4e=a("span"),F($$.$$.fragment),xFr=l(),Z4e=a("span"),$Fr=o("AutoModelForTableQuestionAnswering"),Heo=l(),Xo=a("div"),F(k$.$$.fragment),kFr=l(),Ud=a("p"),SFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),nK=a("a"),RFr=o("from_pretrained()"),PFr=o(" class method or the "),sK=a("a"),BFr=o("from_config()"),IFr=o(` class
method.`),NFr=l(),S$=a("p"),qFr=o("This class cannot be instantiated directly using "),eCe=a("code"),jFr=o("__init__()"),DFr=o(" (throws an error)."),GFr=l(),Lt=a("div"),F(R$.$$.fragment),OFr=l(),oCe=a("p"),VFr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),XFr=l(),Hd=a("p"),zFr=o(`Note:
Loading a model from its configuration file does `),rCe=a("strong"),QFr=o("not"),WFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lK=a("a"),UFr=o("from_pretrained()"),HFr=o(" to load the model weights."),JFr=l(),F(b4.$$.fragment),YFr=l(),mo=a("div"),F(P$.$$.fragment),KFr=l(),tCe=a("p"),ZFr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),eTr=l(),sn=a("p"),oTr=o("The model class to instantiate is selected based on the "),aCe=a("code"),rTr=o("model_type"),tTr=o(` property of the config object (either
passed as an argument or loaded from `),nCe=a("code"),aTr=o("pretrained_model_name_or_path"),nTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sCe=a("code"),sTr=o("pretrained_model_name_or_path"),lTr=o(":"),iTr=l(),lCe=a("ul"),v4=a("li"),iCe=a("strong"),dTr=o("tapas"),mTr=o(" \u2014 "),iK=a("a"),cTr=o("TapasForQuestionAnswering"),fTr=o(" (TAPAS model)"),gTr=l(),F4=a("p"),hTr=o("The model is set in evaluation mode by default using "),dCe=a("code"),uTr=o("model.eval()"),pTr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mCe=a("code"),_Tr=o("model.train()"),bTr=l(),F(T4.$$.fragment),Jeo=l(),Jd=a("h2"),M4=a("a"),cCe=a("span"),F(B$.$$.fragment),vTr=l(),fCe=a("span"),FTr=o("AutoModelForDocumentQuestionAnswering"),Yeo=l(),zo=a("div"),F(I$.$$.fragment),TTr=l(),Yd=a("p"),MTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),dK=a("a"),ETr=o("from_pretrained()"),CTr=o(" class method or the "),mK=a("a"),wTr=o("from_config()"),ATr=o(` class
method.`),LTr=l(),N$=a("p"),yTr=o("This class cannot be instantiated directly using "),gCe=a("code"),xTr=o("__init__()"),$Tr=o(" (throws an error)."),kTr=l(),yt=a("div"),F(q$.$$.fragment),STr=l(),hCe=a("p"),RTr=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),PTr=l(),Kd=a("p"),BTr=o(`Note:
Loading a model from its configuration file does `),uCe=a("strong"),ITr=o("not"),NTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cK=a("a"),qTr=o("from_pretrained()"),jTr=o(" to load the model weights."),DTr=l(),F(E4.$$.fragment),GTr=l(),co=a("div"),F(j$.$$.fragment),OTr=l(),pCe=a("p"),VTr=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),XTr=l(),ln=a("p"),zTr=o("The model class to instantiate is selected based on the "),_Ce=a("code"),QTr=o("model_type"),WTr=o(` property of the config object (either
passed as an argument or loaded from `),bCe=a("code"),UTr=o("pretrained_model_name_or_path"),HTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vCe=a("code"),JTr=o("pretrained_model_name_or_path"),YTr=o(":"),KTr=l(),Zd=a("ul"),C4=a("li"),FCe=a("strong"),ZTr=o("layoutlm"),eMr=o(" \u2014 "),fK=a("a"),oMr=o("LayoutLMForQuestionAnswering"),rMr=o(" (LayoutLM model)"),tMr=l(),w4=a("li"),TCe=a("strong"),aMr=o("layoutlmv2"),nMr=o(" \u2014 "),gK=a("a"),sMr=o("LayoutLMv2ForQuestionAnswering"),lMr=o(" (LayoutLMv2 model)"),iMr=l(),A4=a("li"),MCe=a("strong"),dMr=o("layoutlmv3"),mMr=o(" \u2014 "),hK=a("a"),cMr=o("LayoutLMv3ForQuestionAnswering"),fMr=o(" (LayoutLMv3 model)"),gMr=l(),L4=a("p"),hMr=o("The model is set in evaluation mode by default using "),ECe=a("code"),uMr=o("model.eval()"),pMr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CCe=a("code"),_Mr=o("model.train()"),bMr=l(),F(y4.$$.fragment),Keo=l(),em=a("h2"),x4=a("a"),wCe=a("span"),F(D$.$$.fragment),vMr=l(),ACe=a("span"),FMr=o("AutoModelForImageClassification"),Zeo=l(),Qo=a("div"),F(G$.$$.fragment),TMr=l(),om=a("p"),MMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),uK=a("a"),EMr=o("from_pretrained()"),CMr=o(" class method or the "),pK=a("a"),wMr=o("from_config()"),AMr=o(` class
method.`),LMr=l(),O$=a("p"),yMr=o("This class cannot be instantiated directly using "),LCe=a("code"),xMr=o("__init__()"),$Mr=o(" (throws an error)."),kMr=l(),xt=a("div"),F(V$.$$.fragment),SMr=l(),yCe=a("p"),RMr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),PMr=l(),rm=a("p"),BMr=o(`Note:
Loading a model from its configuration file does `),xCe=a("strong"),IMr=o("not"),NMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_K=a("a"),qMr=o("from_pretrained()"),jMr=o(" to load the model weights."),DMr=l(),F($4.$$.fragment),GMr=l(),fo=a("div"),F(X$.$$.fragment),OMr=l(),$Ce=a("p"),VMr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),XMr=l(),dn=a("p"),zMr=o("The model class to instantiate is selected based on the "),kCe=a("code"),QMr=o("model_type"),WMr=o(` property of the config object (either
passed as an argument or loaded from `),SCe=a("code"),UMr=o("pretrained_model_name_or_path"),HMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RCe=a("code"),JMr=o("pretrained_model_name_or_path"),YMr=o(":"),KMr=l(),be=a("ul"),k4=a("li"),PCe=a("strong"),ZMr=o("beit"),eEr=o(" \u2014 "),bK=a("a"),oEr=o("BeitForImageClassification"),rEr=o(" (BEiT model)"),tEr=l(),S4=a("li"),BCe=a("strong"),aEr=o("convnext"),nEr=o(" \u2014 "),vK=a("a"),sEr=o("ConvNextForImageClassification"),lEr=o(" (ConvNeXT model)"),iEr=l(),R4=a("li"),ICe=a("strong"),dEr=o("cvt"),mEr=o(" \u2014 "),FK=a("a"),cEr=o("CvtForImageClassification"),fEr=o(" (CvT model)"),gEr=l(),P4=a("li"),NCe=a("strong"),hEr=o("data2vec-vision"),uEr=o(" \u2014 "),TK=a("a"),pEr=o("Data2VecVisionForImageClassification"),_Er=o(" (Data2VecVision model)"),bEr=l(),bl=a("li"),qCe=a("strong"),vEr=o("deit"),FEr=o(" \u2014 "),MK=a("a"),TEr=o("DeiTForImageClassification"),MEr=o(" or "),EK=a("a"),EEr=o("DeiTForImageClassificationWithTeacher"),CEr=o(" (DeiT model)"),wEr=l(),B4=a("li"),jCe=a("strong"),AEr=o("imagegpt"),LEr=o(" \u2014 "),CK=a("a"),yEr=o("ImageGPTForImageClassification"),xEr=o(" (ImageGPT model)"),$Er=l(),vl=a("li"),DCe=a("strong"),kEr=o("levit"),SEr=o(" \u2014 "),wK=a("a"),REr=o("LevitForImageClassification"),PEr=o(" or "),AK=a("a"),BEr=o("LevitForImageClassificationWithTeacher"),IEr=o(" (LeViT model)"),NEr=l(),I4=a("li"),GCe=a("strong"),qEr=o("mobilevit"),jEr=o(" \u2014 "),LK=a("a"),DEr=o("MobileViTForImageClassification"),GEr=o(" (MobileViT model)"),OEr=l(),$t=a("li"),OCe=a("strong"),VEr=o("perceiver"),XEr=o(" \u2014 "),yK=a("a"),zEr=o("PerceiverForImageClassificationLearned"),QEr=o(" or "),xK=a("a"),WEr=o("PerceiverForImageClassificationFourier"),UEr=o(" or "),$K=a("a"),HEr=o("PerceiverForImageClassificationConvProcessing"),JEr=o(" (Perceiver model)"),YEr=l(),N4=a("li"),VCe=a("strong"),KEr=o("poolformer"),ZEr=o(" \u2014 "),kK=a("a"),e4r=o("PoolFormerForImageClassification"),o4r=o(" (PoolFormer model)"),r4r=l(),q4=a("li"),XCe=a("strong"),t4r=o("regnet"),a4r=o(" \u2014 "),SK=a("a"),n4r=o("RegNetForImageClassification"),s4r=o(" (RegNet model)"),l4r=l(),j4=a("li"),zCe=a("strong"),i4r=o("resnet"),d4r=o(" \u2014 "),RK=a("a"),m4r=o("ResNetForImageClassification"),c4r=o(" (ResNet model)"),f4r=l(),D4=a("li"),QCe=a("strong"),g4r=o("segformer"),h4r=o(" \u2014 "),PK=a("a"),u4r=o("SegformerForImageClassification"),p4r=o(" (SegFormer model)"),_4r=l(),G4=a("li"),WCe=a("strong"),b4r=o("swin"),v4r=o(" \u2014 "),BK=a("a"),F4r=o("SwinForImageClassification"),T4r=o(" (Swin Transformer model)"),M4r=l(),O4=a("li"),UCe=a("strong"),E4r=o("swinv2"),C4r=o(" \u2014 "),IK=a("a"),w4r=o("Swinv2ForImageClassification"),A4r=o(" (Swin Transformer V2 model)"),L4r=l(),V4=a("li"),HCe=a("strong"),y4r=o("van"),x4r=o(" \u2014 "),NK=a("a"),$4r=o("VanForImageClassification"),k4r=o(" (VAN model)"),S4r=l(),X4=a("li"),JCe=a("strong"),R4r=o("vit"),P4r=o(" \u2014 "),qK=a("a"),B4r=o("ViTForImageClassification"),I4r=o(" (ViT model)"),N4r=l(),z4=a("li"),YCe=a("strong"),q4r=o("vit_msn"),j4r=o(" \u2014 "),jK=a("a"),D4r=o("ViTMSNForImageClassification"),G4r=o(" (ViTMSN model)"),O4r=l(),Q4=a("p"),V4r=o("The model is set in evaluation mode by default using "),KCe=a("code"),X4r=o("model.eval()"),z4r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ZCe=a("code"),Q4r=o("model.train()"),W4r=l(),F(W4.$$.fragment),eoo=l(),tm=a("h2"),U4=a("a"),e3e=a("span"),F(z$.$$.fragment),U4r=l(),o3e=a("span"),H4r=o("AutoModelForVideoClassification"),ooo=l(),Wo=a("div"),F(Q$.$$.fragment),J4r=l(),am=a("p"),Y4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),DK=a("a"),K4r=o("from_pretrained()"),Z4r=o(" class method or the "),GK=a("a"),eCr=o("from_config()"),oCr=o(` class
method.`),rCr=l(),W$=a("p"),tCr=o("This class cannot be instantiated directly using "),r3e=a("code"),aCr=o("__init__()"),nCr=o(" (throws an error)."),sCr=l(),kt=a("div"),F(U$.$$.fragment),lCr=l(),t3e=a("p"),iCr=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),dCr=l(),nm=a("p"),mCr=o(`Note:
Loading a model from its configuration file does `),a3e=a("strong"),cCr=o("not"),fCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OK=a("a"),gCr=o("from_pretrained()"),hCr=o(" to load the model weights."),uCr=l(),F(H4.$$.fragment),pCr=l(),go=a("div"),F(H$.$$.fragment),_Cr=l(),n3e=a("p"),bCr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),vCr=l(),mn=a("p"),FCr=o("The model class to instantiate is selected based on the "),s3e=a("code"),TCr=o("model_type"),MCr=o(` property of the config object (either
passed as an argument or loaded from `),l3e=a("code"),ECr=o("pretrained_model_name_or_path"),CCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i3e=a("code"),wCr=o("pretrained_model_name_or_path"),ACr=o(":"),LCr=l(),d3e=a("ul"),J4=a("li"),m3e=a("strong"),yCr=o("videomae"),xCr=o(" \u2014 "),VK=a("a"),$Cr=o("VideoMAEForVideoClassification"),kCr=o(" (VideoMAE model)"),SCr=l(),Y4=a("p"),RCr=o("The model is set in evaluation mode by default using "),c3e=a("code"),PCr=o("model.eval()"),BCr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f3e=a("code"),ICr=o("model.train()"),NCr=l(),F(K4.$$.fragment),roo=l(),sm=a("h2"),Z4=a("a"),g3e=a("span"),F(J$.$$.fragment),qCr=l(),h3e=a("span"),jCr=o("AutoModelForVision2Seq"),too=l(),Uo=a("div"),F(Y$.$$.fragment),DCr=l(),lm=a("p"),GCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),XK=a("a"),OCr=o("from_pretrained()"),VCr=o(" class method or the "),zK=a("a"),XCr=o("from_config()"),zCr=o(` class
method.`),QCr=l(),K$=a("p"),WCr=o("This class cannot be instantiated directly using "),u3e=a("code"),UCr=o("__init__()"),HCr=o(" (throws an error)."),JCr=l(),St=a("div"),F(Z$.$$.fragment),YCr=l(),p3e=a("p"),KCr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),ZCr=l(),im=a("p"),e3r=o(`Note:
Loading a model from its configuration file does `),_3e=a("strong"),o3r=o("not"),r3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QK=a("a"),t3r=o("from_pretrained()"),a3r=o(" to load the model weights."),n3r=l(),F(eC.$$.fragment),s3r=l(),ho=a("div"),F(ek.$$.fragment),l3r=l(),b3e=a("p"),i3r=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),d3r=l(),cn=a("p"),m3r=o("The model class to instantiate is selected based on the "),v3e=a("code"),c3r=o("model_type"),f3r=o(` property of the config object (either
passed as an argument or loaded from `),F3e=a("code"),g3r=o("pretrained_model_name_or_path"),h3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T3e=a("code"),u3r=o("pretrained_model_name_or_path"),p3r=o(":"),_3r=l(),M3e=a("ul"),oC=a("li"),E3e=a("strong"),b3r=o("vision-encoder-decoder"),v3r=o(" \u2014 "),WK=a("a"),F3r=o("VisionEncoderDecoderModel"),T3r=o(" (Vision Encoder decoder model)"),M3r=l(),rC=a("p"),E3r=o("The model is set in evaluation mode by default using "),C3e=a("code"),C3r=o("model.eval()"),w3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w3e=a("code"),A3r=o("model.train()"),L3r=l(),F(tC.$$.fragment),aoo=l(),dm=a("h2"),aC=a("a"),A3e=a("span"),F(ok.$$.fragment),y3r=l(),L3e=a("span"),x3r=o("AutoModelForVisualQuestionAnswering"),noo=l(),Ho=a("div"),F(rk.$$.fragment),$3r=l(),mm=a("p"),k3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),UK=a("a"),S3r=o("from_pretrained()"),R3r=o(" class method or the "),HK=a("a"),P3r=o("from_config()"),B3r=o(` class
method.`),I3r=l(),tk=a("p"),N3r=o("This class cannot be instantiated directly using "),y3e=a("code"),q3r=o("__init__()"),j3r=o(" (throws an error)."),D3r=l(),Rt=a("div"),F(ak.$$.fragment),G3r=l(),x3e=a("p"),O3r=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),V3r=l(),cm=a("p"),X3r=o(`Note:
Loading a model from its configuration file does `),$3e=a("strong"),z3r=o("not"),Q3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JK=a("a"),W3r=o("from_pretrained()"),U3r=o(" to load the model weights."),H3r=l(),F(nC.$$.fragment),J3r=l(),uo=a("div"),F(nk.$$.fragment),Y3r=l(),k3e=a("p"),K3r=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Z3r=l(),fn=a("p"),e5r=o("The model class to instantiate is selected based on the "),S3e=a("code"),o5r=o("model_type"),r5r=o(` property of the config object (either
passed as an argument or loaded from `),R3e=a("code"),t5r=o("pretrained_model_name_or_path"),a5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P3e=a("code"),n5r=o("pretrained_model_name_or_path"),s5r=o(":"),l5r=l(),B3e=a("ul"),sC=a("li"),I3e=a("strong"),i5r=o("vilt"),d5r=o(" \u2014 "),YK=a("a"),m5r=o("ViltForQuestionAnswering"),c5r=o(" (ViLT model)"),f5r=l(),lC=a("p"),g5r=o("The model is set in evaluation mode by default using "),N3e=a("code"),h5r=o("model.eval()"),u5r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q3e=a("code"),p5r=o("model.train()"),_5r=l(),F(iC.$$.fragment),soo=l(),fm=a("h2"),dC=a("a"),j3e=a("span"),F(sk.$$.fragment),b5r=l(),D3e=a("span"),v5r=o("AutoModelForAudioClassification"),loo=l(),Jo=a("div"),F(lk.$$.fragment),F5r=l(),gm=a("p"),T5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),KK=a("a"),M5r=o("from_pretrained()"),E5r=o(" class method or the "),ZK=a("a"),C5r=o("from_config()"),w5r=o(` class
method.`),A5r=l(),ik=a("p"),L5r=o("This class cannot be instantiated directly using "),G3e=a("code"),y5r=o("__init__()"),x5r=o(" (throws an error)."),$5r=l(),Pt=a("div"),F(dk.$$.fragment),k5r=l(),O3e=a("p"),S5r=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),R5r=l(),hm=a("p"),P5r=o(`Note:
Loading a model from its configuration file does `),V3e=a("strong"),B5r=o("not"),I5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eZ=a("a"),N5r=o("from_pretrained()"),q5r=o(" to load the model weights."),j5r=l(),F(mC.$$.fragment),D5r=l(),po=a("div"),F(mk.$$.fragment),G5r=l(),X3e=a("p"),O5r=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),V5r=l(),gn=a("p"),X5r=o("The model class to instantiate is selected based on the "),z3e=a("code"),z5r=o("model_type"),Q5r=o(` property of the config object (either
passed as an argument or loaded from `),Q3e=a("code"),W5r=o("pretrained_model_name_or_path"),U5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W3e=a("code"),H5r=o("pretrained_model_name_or_path"),J5r=o(":"),Y5r=l(),Pe=a("ul"),cC=a("li"),U3e=a("strong"),K5r=o("data2vec-audio"),Z5r=o(" \u2014 "),oZ=a("a"),e0r=o("Data2VecAudioForSequenceClassification"),o0r=o(" (Data2VecAudio model)"),r0r=l(),fC=a("li"),H3e=a("strong"),t0r=o("hubert"),a0r=o(" \u2014 "),rZ=a("a"),n0r=o("HubertForSequenceClassification"),s0r=o(" (Hubert model)"),l0r=l(),gC=a("li"),J3e=a("strong"),i0r=o("sew"),d0r=o(" \u2014 "),tZ=a("a"),m0r=o("SEWForSequenceClassification"),c0r=o(" (SEW model)"),f0r=l(),hC=a("li"),Y3e=a("strong"),g0r=o("sew-d"),h0r=o(" \u2014 "),aZ=a("a"),u0r=o("SEWDForSequenceClassification"),p0r=o(" (SEW-D model)"),_0r=l(),uC=a("li"),K3e=a("strong"),b0r=o("unispeech"),v0r=o(" \u2014 "),nZ=a("a"),F0r=o("UniSpeechForSequenceClassification"),T0r=o(" (UniSpeech model)"),M0r=l(),pC=a("li"),Z3e=a("strong"),E0r=o("unispeech-sat"),C0r=o(" \u2014 "),sZ=a("a"),w0r=o("UniSpeechSatForSequenceClassification"),A0r=o(" (UniSpeechSat model)"),L0r=l(),_C=a("li"),e5e=a("strong"),y0r=o("wav2vec2"),x0r=o(" \u2014 "),lZ=a("a"),$0r=o("Wav2Vec2ForSequenceClassification"),k0r=o(" (Wav2Vec2 model)"),S0r=l(),bC=a("li"),o5e=a("strong"),R0r=o("wav2vec2-conformer"),P0r=o(" \u2014 "),iZ=a("a"),B0r=o("Wav2Vec2ConformerForSequenceClassification"),I0r=o(" (Wav2Vec2-Conformer model)"),N0r=l(),vC=a("li"),r5e=a("strong"),q0r=o("wavlm"),j0r=o(" \u2014 "),dZ=a("a"),D0r=o("WavLMForSequenceClassification"),G0r=o(" (WavLM model)"),O0r=l(),FC=a("p"),V0r=o("The model is set in evaluation mode by default using "),t5e=a("code"),X0r=o("model.eval()"),z0r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a5e=a("code"),Q0r=o("model.train()"),W0r=l(),F(TC.$$.fragment),ioo=l(),um=a("h2"),MC=a("a"),n5e=a("span"),F(ck.$$.fragment),U0r=l(),s5e=a("span"),H0r=o("AutoModelForAudioFrameClassification"),doo=l(),Yo=a("div"),F(fk.$$.fragment),J0r=l(),pm=a("p"),Y0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),mZ=a("a"),K0r=o("from_pretrained()"),Z0r=o(" class method or the "),cZ=a("a"),ewr=o("from_config()"),owr=o(` class
method.`),rwr=l(),gk=a("p"),twr=o("This class cannot be instantiated directly using "),l5e=a("code"),awr=o("__init__()"),nwr=o(" (throws an error)."),swr=l(),Bt=a("div"),F(hk.$$.fragment),lwr=l(),i5e=a("p"),iwr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),dwr=l(),_m=a("p"),mwr=o(`Note:
Loading a model from its configuration file does `),d5e=a("strong"),cwr=o("not"),fwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fZ=a("a"),gwr=o("from_pretrained()"),hwr=o(" to load the model weights."),uwr=l(),F(EC.$$.fragment),pwr=l(),_o=a("div"),F(uk.$$.fragment),_wr=l(),m5e=a("p"),bwr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),vwr=l(),hn=a("p"),Fwr=o("The model class to instantiate is selected based on the "),c5e=a("code"),Twr=o("model_type"),Mwr=o(` property of the config object (either
passed as an argument or loaded from `),f5e=a("code"),Ewr=o("pretrained_model_name_or_path"),Cwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g5e=a("code"),wwr=o("pretrained_model_name_or_path"),Awr=o(":"),Lwr=l(),ct=a("ul"),CC=a("li"),h5e=a("strong"),ywr=o("data2vec-audio"),xwr=o(" \u2014 "),gZ=a("a"),$wr=o("Data2VecAudioForAudioFrameClassification"),kwr=o(" (Data2VecAudio model)"),Swr=l(),wC=a("li"),u5e=a("strong"),Rwr=o("unispeech-sat"),Pwr=o(" \u2014 "),hZ=a("a"),Bwr=o("UniSpeechSatForAudioFrameClassification"),Iwr=o(" (UniSpeechSat model)"),Nwr=l(),AC=a("li"),p5e=a("strong"),qwr=o("wav2vec2"),jwr=o(" \u2014 "),uZ=a("a"),Dwr=o("Wav2Vec2ForAudioFrameClassification"),Gwr=o(" (Wav2Vec2 model)"),Owr=l(),LC=a("li"),_5e=a("strong"),Vwr=o("wav2vec2-conformer"),Xwr=o(" \u2014 "),pZ=a("a"),zwr=o("Wav2Vec2ConformerForAudioFrameClassification"),Qwr=o(" (Wav2Vec2-Conformer model)"),Wwr=l(),yC=a("li"),b5e=a("strong"),Uwr=o("wavlm"),Hwr=o(" \u2014 "),_Z=a("a"),Jwr=o("WavLMForAudioFrameClassification"),Ywr=o(" (WavLM model)"),Kwr=l(),xC=a("p"),Zwr=o("The model is set in evaluation mode by default using "),v5e=a("code"),eAr=o("model.eval()"),oAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F5e=a("code"),rAr=o("model.train()"),tAr=l(),F($C.$$.fragment),moo=l(),bm=a("h2"),kC=a("a"),T5e=a("span"),F(pk.$$.fragment),aAr=l(),M5e=a("span"),nAr=o("AutoModelForCTC"),coo=l(),Ko=a("div"),F(_k.$$.fragment),sAr=l(),vm=a("p"),lAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),bZ=a("a"),iAr=o("from_pretrained()"),dAr=o(" class method or the "),vZ=a("a"),mAr=o("from_config()"),cAr=o(` class
method.`),fAr=l(),bk=a("p"),gAr=o("This class cannot be instantiated directly using "),E5e=a("code"),hAr=o("__init__()"),uAr=o(" (throws an error)."),pAr=l(),It=a("div"),F(vk.$$.fragment),_Ar=l(),C5e=a("p"),bAr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),vAr=l(),Fm=a("p"),FAr=o(`Note:
Loading a model from its configuration file does `),w5e=a("strong"),TAr=o("not"),MAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FZ=a("a"),EAr=o("from_pretrained()"),CAr=o(" to load the model weights."),wAr=l(),F(SC.$$.fragment),AAr=l(),bo=a("div"),F(Fk.$$.fragment),LAr=l(),A5e=a("p"),yAr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),xAr=l(),un=a("p"),$Ar=o("The model class to instantiate is selected based on the "),L5e=a("code"),kAr=o("model_type"),SAr=o(` property of the config object (either
passed as an argument or loaded from `),y5e=a("code"),RAr=o("pretrained_model_name_or_path"),PAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x5e=a("code"),BAr=o("pretrained_model_name_or_path"),IAr=o(":"),NAr=l(),Le=a("ul"),RC=a("li"),$5e=a("strong"),qAr=o("data2vec-audio"),jAr=o(" \u2014 "),TZ=a("a"),DAr=o("Data2VecAudioForCTC"),GAr=o(" (Data2VecAudio model)"),OAr=l(),PC=a("li"),k5e=a("strong"),VAr=o("hubert"),XAr=o(" \u2014 "),MZ=a("a"),zAr=o("HubertForCTC"),QAr=o(" (Hubert model)"),WAr=l(),BC=a("li"),S5e=a("strong"),UAr=o("mctct"),HAr=o(" \u2014 "),EZ=a("a"),JAr=o("MCTCTForCTC"),YAr=o(" (M-CTC-T model)"),KAr=l(),IC=a("li"),R5e=a("strong"),ZAr=o("sew"),e6r=o(" \u2014 "),CZ=a("a"),o6r=o("SEWForCTC"),r6r=o(" (SEW model)"),t6r=l(),NC=a("li"),P5e=a("strong"),a6r=o("sew-d"),n6r=o(" \u2014 "),wZ=a("a"),s6r=o("SEWDForCTC"),l6r=o(" (SEW-D model)"),i6r=l(),qC=a("li"),B5e=a("strong"),d6r=o("unispeech"),m6r=o(" \u2014 "),AZ=a("a"),c6r=o("UniSpeechForCTC"),f6r=o(" (UniSpeech model)"),g6r=l(),jC=a("li"),I5e=a("strong"),h6r=o("unispeech-sat"),u6r=o(" \u2014 "),LZ=a("a"),p6r=o("UniSpeechSatForCTC"),_6r=o(" (UniSpeechSat model)"),b6r=l(),DC=a("li"),N5e=a("strong"),v6r=o("wav2vec2"),F6r=o(" \u2014 "),yZ=a("a"),T6r=o("Wav2Vec2ForCTC"),M6r=o(" (Wav2Vec2 model)"),E6r=l(),GC=a("li"),q5e=a("strong"),C6r=o("wav2vec2-conformer"),w6r=o(" \u2014 "),xZ=a("a"),A6r=o("Wav2Vec2ConformerForCTC"),L6r=o(" (Wav2Vec2-Conformer model)"),y6r=l(),OC=a("li"),j5e=a("strong"),x6r=o("wavlm"),$6r=o(" \u2014 "),$Z=a("a"),k6r=o("WavLMForCTC"),S6r=o(" (WavLM model)"),R6r=l(),VC=a("p"),P6r=o("The model is set in evaluation mode by default using "),D5e=a("code"),B6r=o("model.eval()"),I6r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),G5e=a("code"),N6r=o("model.train()"),q6r=l(),F(XC.$$.fragment),foo=l(),Tm=a("h2"),zC=a("a"),O5e=a("span"),F(Tk.$$.fragment),j6r=l(),V5e=a("span"),D6r=o("AutoModelForSpeechSeq2Seq"),goo=l(),Zo=a("div"),F(Mk.$$.fragment),G6r=l(),Mm=a("p"),O6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),kZ=a("a"),V6r=o("from_pretrained()"),X6r=o(" class method or the "),SZ=a("a"),z6r=o("from_config()"),Q6r=o(` class
method.`),W6r=l(),Ek=a("p"),U6r=o("This class cannot be instantiated directly using "),X5e=a("code"),H6r=o("__init__()"),J6r=o(" (throws an error)."),Y6r=l(),Nt=a("div"),F(Ck.$$.fragment),K6r=l(),z5e=a("p"),Z6r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),e7r=l(),Em=a("p"),o7r=o(`Note:
Loading a model from its configuration file does `),Q5e=a("strong"),r7r=o("not"),t7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RZ=a("a"),a7r=o("from_pretrained()"),n7r=o(" to load the model weights."),s7r=l(),F(QC.$$.fragment),l7r=l(),vo=a("div"),F(wk.$$.fragment),i7r=l(),W5e=a("p"),d7r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),m7r=l(),pn=a("p"),c7r=o("The model class to instantiate is selected based on the "),U5e=a("code"),f7r=o("model_type"),g7r=o(` property of the config object (either
passed as an argument or loaded from `),H5e=a("code"),h7r=o("pretrained_model_name_or_path"),u7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J5e=a("code"),p7r=o("pretrained_model_name_or_path"),_7r=o(":"),b7r=l(),Cm=a("ul"),WC=a("li"),Y5e=a("strong"),v7r=o("speech-encoder-decoder"),F7r=o(" \u2014 "),PZ=a("a"),T7r=o("SpeechEncoderDecoderModel"),M7r=o(" (Speech Encoder decoder model)"),E7r=l(),UC=a("li"),K5e=a("strong"),C7r=o("speech_to_text"),w7r=o(" \u2014 "),BZ=a("a"),A7r=o("Speech2TextForConditionalGeneration"),L7r=o(" (Speech2Text model)"),y7r=l(),HC=a("li"),Z5e=a("strong"),x7r=o("whisper"),$7r=o(" \u2014 "),IZ=a("a"),k7r=o("WhisperForConditionalGeneration"),S7r=o(" (Whisper model)"),R7r=l(),JC=a("p"),P7r=o("The model is set in evaluation mode by default using "),e0e=a("code"),B7r=o("model.eval()"),I7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o0e=a("code"),N7r=o("model.train()"),q7r=l(),F(YC.$$.fragment),hoo=l(),wm=a("h2"),KC=a("a"),r0e=a("span"),F(Ak.$$.fragment),j7r=l(),t0e=a("span"),D7r=o("AutoModelForAudioXVector"),uoo=l(),er=a("div"),F(Lk.$$.fragment),G7r=l(),Am=a("p"),O7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),NZ=a("a"),V7r=o("from_pretrained()"),X7r=o(" class method or the "),qZ=a("a"),z7r=o("from_config()"),Q7r=o(` class
method.`),W7r=l(),yk=a("p"),U7r=o("This class cannot be instantiated directly using "),a0e=a("code"),H7r=o("__init__()"),J7r=o(" (throws an error)."),Y7r=l(),qt=a("div"),F(xk.$$.fragment),K7r=l(),n0e=a("p"),Z7r=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),eLr=l(),Lm=a("p"),oLr=o(`Note:
Loading a model from its configuration file does `),s0e=a("strong"),rLr=o("not"),tLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jZ=a("a"),aLr=o("from_pretrained()"),nLr=o(" to load the model weights."),sLr=l(),F(ZC.$$.fragment),lLr=l(),Fo=a("div"),F($k.$$.fragment),iLr=l(),l0e=a("p"),dLr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),mLr=l(),_n=a("p"),cLr=o("The model class to instantiate is selected based on the "),i0e=a("code"),fLr=o("model_type"),gLr=o(` property of the config object (either
passed as an argument or loaded from `),d0e=a("code"),hLr=o("pretrained_model_name_or_path"),uLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m0e=a("code"),pLr=o("pretrained_model_name_or_path"),_Lr=o(":"),bLr=l(),ft=a("ul"),e3=a("li"),c0e=a("strong"),vLr=o("data2vec-audio"),FLr=o(" \u2014 "),DZ=a("a"),TLr=o("Data2VecAudioForXVector"),MLr=o(" (Data2VecAudio model)"),ELr=l(),o3=a("li"),f0e=a("strong"),CLr=o("unispeech-sat"),wLr=o(" \u2014 "),GZ=a("a"),ALr=o("UniSpeechSatForXVector"),LLr=o(" (UniSpeechSat model)"),yLr=l(),r3=a("li"),g0e=a("strong"),xLr=o("wav2vec2"),$Lr=o(" \u2014 "),OZ=a("a"),kLr=o("Wav2Vec2ForXVector"),SLr=o(" (Wav2Vec2 model)"),RLr=l(),t3=a("li"),h0e=a("strong"),PLr=o("wav2vec2-conformer"),BLr=o(" \u2014 "),VZ=a("a"),ILr=o("Wav2Vec2ConformerForXVector"),NLr=o(" (Wav2Vec2-Conformer model)"),qLr=l(),a3=a("li"),u0e=a("strong"),jLr=o("wavlm"),DLr=o(" \u2014 "),XZ=a("a"),GLr=o("WavLMForXVector"),OLr=o(" (WavLM model)"),VLr=l(),n3=a("p"),XLr=o("The model is set in evaluation mode by default using "),p0e=a("code"),zLr=o("model.eval()"),QLr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_0e=a("code"),WLr=o("model.train()"),ULr=l(),F(s3.$$.fragment),poo=l(),ym=a("h2"),l3=a("a"),b0e=a("span"),F(kk.$$.fragment),HLr=l(),v0e=a("span"),JLr=o("AutoModelForMaskedImageModeling"),_oo=l(),or=a("div"),F(Sk.$$.fragment),YLr=l(),xm=a("p"),KLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),zZ=a("a"),ZLr=o("from_pretrained()"),eyr=o(" class method or the "),QZ=a("a"),oyr=o("from_config()"),ryr=o(` class
method.`),tyr=l(),Rk=a("p"),ayr=o("This class cannot be instantiated directly using "),F0e=a("code"),nyr=o("__init__()"),syr=o(" (throws an error)."),lyr=l(),jt=a("div"),F(Pk.$$.fragment),iyr=l(),T0e=a("p"),dyr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),myr=l(),$m=a("p"),cyr=o(`Note:
Loading a model from its configuration file does `),M0e=a("strong"),fyr=o("not"),gyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WZ=a("a"),hyr=o("from_pretrained()"),uyr=o(" to load the model weights."),pyr=l(),F(i3.$$.fragment),_yr=l(),To=a("div"),F(Bk.$$.fragment),byr=l(),E0e=a("p"),vyr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Fyr=l(),bn=a("p"),Tyr=o("The model class to instantiate is selected based on the "),C0e=a("code"),Myr=o("model_type"),Eyr=o(` property of the config object (either
passed as an argument or loaded from `),w0e=a("code"),Cyr=o("pretrained_model_name_or_path"),wyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A0e=a("code"),Ayr=o("pretrained_model_name_or_path"),Lyr=o(":"),yyr=l(),vn=a("ul"),d3=a("li"),L0e=a("strong"),xyr=o("deit"),$yr=o(" \u2014 "),UZ=a("a"),kyr=o("DeiTForMaskedImageModeling"),Syr=o(" (DeiT model)"),Ryr=l(),m3=a("li"),y0e=a("strong"),Pyr=o("swin"),Byr=o(" \u2014 "),HZ=a("a"),Iyr=o("SwinForMaskedImageModeling"),Nyr=o(" (Swin Transformer model)"),qyr=l(),c3=a("li"),x0e=a("strong"),jyr=o("swinv2"),Dyr=o(" \u2014 "),JZ=a("a"),Gyr=o("Swinv2ForMaskedImageModeling"),Oyr=o(" (Swin Transformer V2 model)"),Vyr=l(),f3=a("li"),$0e=a("strong"),Xyr=o("vit"),zyr=o(" \u2014 "),YZ=a("a"),Qyr=o("ViTForMaskedImageModeling"),Wyr=o(" (ViT model)"),Uyr=l(),g3=a("p"),Hyr=o("The model is set in evaluation mode by default using "),k0e=a("code"),Jyr=o("model.eval()"),Yyr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S0e=a("code"),Kyr=o("model.train()"),Zyr=l(),F(h3.$$.fragment),boo=l(),km=a("h2"),u3=a("a"),R0e=a("span"),F(Ik.$$.fragment),e8r=l(),P0e=a("span"),o8r=o("AutoModelForObjectDetection"),voo=l(),rr=a("div"),F(Nk.$$.fragment),r8r=l(),Sm=a("p"),t8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),KZ=a("a"),a8r=o("from_pretrained()"),n8r=o(" class method or the "),ZZ=a("a"),s8r=o("from_config()"),l8r=o(` class
method.`),i8r=l(),qk=a("p"),d8r=o("This class cannot be instantiated directly using "),B0e=a("code"),m8r=o("__init__()"),c8r=o(" (throws an error)."),f8r=l(),Dt=a("div"),F(jk.$$.fragment),g8r=l(),I0e=a("p"),h8r=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),u8r=l(),Rm=a("p"),p8r=o(`Note:
Loading a model from its configuration file does `),N0e=a("strong"),_8r=o("not"),b8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eee=a("a"),v8r=o("from_pretrained()"),F8r=o(" to load the model weights."),T8r=l(),F(p3.$$.fragment),M8r=l(),Mo=a("div"),F(Dk.$$.fragment),E8r=l(),q0e=a("p"),C8r=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),w8r=l(),Fn=a("p"),A8r=o("The model class to instantiate is selected based on the "),j0e=a("code"),L8r=o("model_type"),y8r=o(` property of the config object (either
passed as an argument or loaded from `),D0e=a("code"),x8r=o("pretrained_model_name_or_path"),$8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G0e=a("code"),k8r=o("pretrained_model_name_or_path"),S8r=o(":"),R8r=l(),Tn=a("ul"),_3=a("li"),O0e=a("strong"),P8r=o("conditional_detr"),B8r=o(" \u2014 "),oee=a("a"),I8r=o("ConditionalDetrForObjectDetection"),N8r=o(" (Conditional DETR model)"),q8r=l(),b3=a("li"),V0e=a("strong"),j8r=o("deformable_detr"),D8r=o(" \u2014 "),ree=a("a"),G8r=o("DeformableDetrForObjectDetection"),O8r=o(" (Deformable DETR model)"),V8r=l(),v3=a("li"),X0e=a("strong"),X8r=o("detr"),z8r=o(" \u2014 "),tee=a("a"),Q8r=o("DetrForObjectDetection"),W8r=o(" (DETR model)"),U8r=l(),F3=a("li"),z0e=a("strong"),H8r=o("yolos"),J8r=o(" \u2014 "),aee=a("a"),Y8r=o("YolosForObjectDetection"),K8r=o(" (YOLOS model)"),Z8r=l(),T3=a("p"),e9r=o("The model is set in evaluation mode by default using "),Q0e=a("code"),o9r=o("model.eval()"),r9r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W0e=a("code"),t9r=o("model.train()"),a9r=l(),F(M3.$$.fragment),Foo=l(),Pm=a("h2"),E3=a("a"),U0e=a("span"),F(Gk.$$.fragment),n9r=l(),H0e=a("span"),s9r=o("AutoModelForImageSegmentation"),Too=l(),tr=a("div"),F(Ok.$$.fragment),l9r=l(),Bm=a("p"),i9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),nee=a("a"),d9r=o("from_pretrained()"),m9r=o(" class method or the "),see=a("a"),c9r=o("from_config()"),f9r=o(` class
method.`),g9r=l(),Vk=a("p"),h9r=o("This class cannot be instantiated directly using "),J0e=a("code"),u9r=o("__init__()"),p9r=o(" (throws an error)."),_9r=l(),Gt=a("div"),F(Xk.$$.fragment),b9r=l(),Y0e=a("p"),v9r=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),F9r=l(),Im=a("p"),T9r=o(`Note:
Loading a model from its configuration file does `),K0e=a("strong"),M9r=o("not"),E9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lee=a("a"),C9r=o("from_pretrained()"),w9r=o(" to load the model weights."),A9r=l(),F(C3.$$.fragment),L9r=l(),Eo=a("div"),F(zk.$$.fragment),y9r=l(),Z0e=a("p"),x9r=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),$9r=l(),Mn=a("p"),k9r=o("The model class to instantiate is selected based on the "),ewe=a("code"),S9r=o("model_type"),R9r=o(` property of the config object (either
passed as an argument or loaded from `),owe=a("code"),P9r=o("pretrained_model_name_or_path"),B9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rwe=a("code"),I9r=o("pretrained_model_name_or_path"),N9r=o(":"),q9r=l(),twe=a("ul"),w3=a("li"),awe=a("strong"),j9r=o("detr"),D9r=o(" \u2014 "),iee=a("a"),G9r=o("DetrForSegmentation"),O9r=o(" (DETR model)"),V9r=l(),A3=a("p"),X9r=o("The model is set in evaluation mode by default using "),nwe=a("code"),z9r=o("model.eval()"),Q9r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),swe=a("code"),W9r=o("model.train()"),U9r=l(),F(L3.$$.fragment),Moo=l(),Nm=a("h2"),y3=a("a"),lwe=a("span"),F(Qk.$$.fragment),H9r=l(),iwe=a("span"),J9r=o("AutoModelForSemanticSegmentation"),Eoo=l(),ar=a("div"),F(Wk.$$.fragment),Y9r=l(),qm=a("p"),K9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),dee=a("a"),Z9r=o("from_pretrained()"),exr=o(" class method or the "),mee=a("a"),oxr=o("from_config()"),rxr=o(` class
method.`),txr=l(),Uk=a("p"),axr=o("This class cannot be instantiated directly using "),dwe=a("code"),nxr=o("__init__()"),sxr=o(" (throws an error)."),lxr=l(),Ot=a("div"),F(Hk.$$.fragment),ixr=l(),mwe=a("p"),dxr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),mxr=l(),jm=a("p"),cxr=o(`Note:
Loading a model from its configuration file does `),cwe=a("strong"),fxr=o("not"),gxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cee=a("a"),hxr=o("from_pretrained()"),uxr=o(" to load the model weights."),pxr=l(),F(x3.$$.fragment),_xr=l(),Co=a("div"),F(Jk.$$.fragment),bxr=l(),fwe=a("p"),vxr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Fxr=l(),En=a("p"),Txr=o("The model class to instantiate is selected based on the "),gwe=a("code"),Mxr=o("model_type"),Exr=o(` property of the config object (either
passed as an argument or loaded from `),hwe=a("code"),Cxr=o("pretrained_model_name_or_path"),wxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uwe=a("code"),Axr=o("pretrained_model_name_or_path"),Lxr=o(":"),yxr=l(),gt=a("ul"),$3=a("li"),pwe=a("strong"),xxr=o("beit"),$xr=o(" \u2014 "),fee=a("a"),kxr=o("BeitForSemanticSegmentation"),Sxr=o(" (BEiT model)"),Rxr=l(),k3=a("li"),_we=a("strong"),Pxr=o("data2vec-vision"),Bxr=o(" \u2014 "),gee=a("a"),Ixr=o("Data2VecVisionForSemanticSegmentation"),Nxr=o(" (Data2VecVision model)"),qxr=l(),S3=a("li"),bwe=a("strong"),jxr=o("dpt"),Dxr=o(" \u2014 "),hee=a("a"),Gxr=o("DPTForSemanticSegmentation"),Oxr=o(" (DPT model)"),Vxr=l(),R3=a("li"),vwe=a("strong"),Xxr=o("mobilevit"),zxr=o(" \u2014 "),uee=a("a"),Qxr=o("MobileViTForSemanticSegmentation"),Wxr=o(" (MobileViT model)"),Uxr=l(),P3=a("li"),Fwe=a("strong"),Hxr=o("segformer"),Jxr=o(" \u2014 "),pee=a("a"),Yxr=o("SegformerForSemanticSegmentation"),Kxr=o(" (SegFormer model)"),Zxr=l(),B3=a("p"),e$r=o("The model is set in evaluation mode by default using "),Twe=a("code"),o$r=o("model.eval()"),r$r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mwe=a("code"),t$r=o("model.train()"),a$r=l(),F(I3.$$.fragment),Coo=l(),Dm=a("h2"),N3=a("a"),Ewe=a("span"),F(Yk.$$.fragment),n$r=l(),Cwe=a("span"),s$r=o("AutoModelForInstanceSegmentation"),woo=l(),nr=a("div"),F(Kk.$$.fragment),l$r=l(),Gm=a("p"),i$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),_ee=a("a"),d$r=o("from_pretrained()"),m$r=o(" class method or the "),bee=a("a"),c$r=o("from_config()"),f$r=o(` class
method.`),g$r=l(),Zk=a("p"),h$r=o("This class cannot be instantiated directly using "),wwe=a("code"),u$r=o("__init__()"),p$r=o(" (throws an error)."),_$r=l(),Vt=a("div"),F(eS.$$.fragment),b$r=l(),Awe=a("p"),v$r=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),F$r=l(),Om=a("p"),T$r=o(`Note:
Loading a model from its configuration file does `),Lwe=a("strong"),M$r=o("not"),E$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vee=a("a"),C$r=o("from_pretrained()"),w$r=o(" to load the model weights."),A$r=l(),F(q3.$$.fragment),L$r=l(),wo=a("div"),F(oS.$$.fragment),y$r=l(),ywe=a("p"),x$r=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),$$r=l(),Cn=a("p"),k$r=o("The model class to instantiate is selected based on the "),xwe=a("code"),S$r=o("model_type"),R$r=o(` property of the config object (either
passed as an argument or loaded from `),$we=a("code"),P$r=o("pretrained_model_name_or_path"),B$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kwe=a("code"),I$r=o("pretrained_model_name_or_path"),N$r=o(":"),q$r=l(),Swe=a("ul"),j3=a("li"),Rwe=a("strong"),j$r=o("maskformer"),D$r=o(" \u2014 "),Fee=a("a"),G$r=o("MaskFormerForInstanceSegmentation"),O$r=o(" (MaskFormer model)"),V$r=l(),D3=a("p"),X$r=o("The model is set in evaluation mode by default using "),Pwe=a("code"),z$r=o("model.eval()"),Q$r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Bwe=a("code"),W$r=o("model.train()"),U$r=l(),F(G3.$$.fragment),Aoo=l(),Vm=a("h2"),O3=a("a"),Iwe=a("span"),F(rS.$$.fragment),H$r=l(),Nwe=a("span"),J$r=o("TFAutoModel"),Loo=l(),sr=a("div"),F(tS.$$.fragment),Y$r=l(),Xm=a("p"),K$r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Tee=a("a"),Z$r=o("from_pretrained()"),ekr=o(" class method or the "),Mee=a("a"),okr=o("from_config()"),rkr=o(` class
method.`),tkr=l(),aS=a("p"),akr=o("This class cannot be instantiated directly using "),qwe=a("code"),nkr=o("__init__()"),skr=o(" (throws an error)."),lkr=l(),Xt=a("div"),F(nS.$$.fragment),ikr=l(),jwe=a("p"),dkr=o("Instantiates one of the base model classes of the library from a configuration."),mkr=l(),zm=a("p"),ckr=o(`Note:
Loading a model from its configuration file does `),Dwe=a("strong"),fkr=o("not"),gkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Eee=a("a"),hkr=o("from_pretrained()"),ukr=o(" to load the model weights."),pkr=l(),F(V3.$$.fragment),_kr=l(),Ir=a("div"),F(sS.$$.fragment),bkr=l(),Gwe=a("p"),vkr=o("Instantiate one of the base model classes of the library from a pretrained model."),Fkr=l(),wn=a("p"),Tkr=o("The model class to instantiate is selected based on the "),Owe=a("code"),Mkr=o("model_type"),Ekr=o(` property of the config object (either
passed as an argument or loaded from `),Vwe=a("code"),Ckr=o("pretrained_model_name_or_path"),wkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xwe=a("code"),Akr=o("pretrained_model_name_or_path"),Lkr=o(":"),ykr=l(),I=a("ul"),X3=a("li"),zwe=a("strong"),xkr=o("albert"),$kr=o(" \u2014 "),Cee=a("a"),kkr=o("TFAlbertModel"),Skr=o(" (ALBERT model)"),Rkr=l(),z3=a("li"),Qwe=a("strong"),Pkr=o("bart"),Bkr=o(" \u2014 "),wee=a("a"),Ikr=o("TFBartModel"),Nkr=o(" (BART model)"),qkr=l(),Q3=a("li"),Wwe=a("strong"),jkr=o("bert"),Dkr=o(" \u2014 "),Aee=a("a"),Gkr=o("TFBertModel"),Okr=o(" (BERT model)"),Vkr=l(),W3=a("li"),Uwe=a("strong"),Xkr=o("blenderbot"),zkr=o(" \u2014 "),Lee=a("a"),Qkr=o("TFBlenderbotModel"),Wkr=o(" (Blenderbot model)"),Ukr=l(),U3=a("li"),Hwe=a("strong"),Hkr=o("blenderbot-small"),Jkr=o(" \u2014 "),yee=a("a"),Ykr=o("TFBlenderbotSmallModel"),Kkr=o(" (BlenderbotSmall model)"),Zkr=l(),H3=a("li"),Jwe=a("strong"),eSr=o("camembert"),oSr=o(" \u2014 "),xee=a("a"),rSr=o("TFCamembertModel"),tSr=o(" (CamemBERT model)"),aSr=l(),J3=a("li"),Ywe=a("strong"),nSr=o("clip"),sSr=o(" \u2014 "),$ee=a("a"),lSr=o("TFCLIPModel"),iSr=o(" (CLIP model)"),dSr=l(),Y3=a("li"),Kwe=a("strong"),mSr=o("convbert"),cSr=o(" \u2014 "),kee=a("a"),fSr=o("TFConvBertModel"),gSr=o(" (ConvBERT model)"),hSr=l(),K3=a("li"),Zwe=a("strong"),uSr=o("convnext"),pSr=o(" \u2014 "),See=a("a"),_Sr=o("TFConvNextModel"),bSr=o(" (ConvNeXT model)"),vSr=l(),Z3=a("li"),eAe=a("strong"),FSr=o("ctrl"),TSr=o(" \u2014 "),Ree=a("a"),MSr=o("TFCTRLModel"),ESr=o(" (CTRL model)"),CSr=l(),e5=a("li"),oAe=a("strong"),wSr=o("data2vec-vision"),ASr=o(" \u2014 "),Pee=a("a"),LSr=o("TFData2VecVisionModel"),ySr=o(" (Data2VecVision model)"),xSr=l(),o5=a("li"),rAe=a("strong"),$Sr=o("deberta"),kSr=o(" \u2014 "),Bee=a("a"),SSr=o("TFDebertaModel"),RSr=o(" (DeBERTa model)"),PSr=l(),r5=a("li"),tAe=a("strong"),BSr=o("deberta-v2"),ISr=o(" \u2014 "),Iee=a("a"),NSr=o("TFDebertaV2Model"),qSr=o(" (DeBERTa-v2 model)"),jSr=l(),t5=a("li"),aAe=a("strong"),DSr=o("deit"),GSr=o(" \u2014 "),Nee=a("a"),OSr=o("TFDeiTModel"),VSr=o(" (DeiT model)"),XSr=l(),a5=a("li"),nAe=a("strong"),zSr=o("distilbert"),QSr=o(" \u2014 "),qee=a("a"),WSr=o("TFDistilBertModel"),USr=o(" (DistilBERT model)"),HSr=l(),n5=a("li"),sAe=a("strong"),JSr=o("dpr"),YSr=o(" \u2014 "),jee=a("a"),KSr=o("TFDPRQuestionEncoder"),ZSr=o(" (DPR model)"),eRr=l(),s5=a("li"),lAe=a("strong"),oRr=o("electra"),rRr=o(" \u2014 "),Dee=a("a"),tRr=o("TFElectraModel"),aRr=o(" (ELECTRA model)"),nRr=l(),l5=a("li"),iAe=a("strong"),sRr=o("flaubert"),lRr=o(" \u2014 "),Gee=a("a"),iRr=o("TFFlaubertModel"),dRr=o(" (FlauBERT model)"),mRr=l(),Fl=a("li"),dAe=a("strong"),cRr=o("funnel"),fRr=o(" \u2014 "),Oee=a("a"),gRr=o("TFFunnelModel"),hRr=o(" or "),Vee=a("a"),uRr=o("TFFunnelBaseModel"),pRr=o(" (Funnel Transformer model)"),_Rr=l(),i5=a("li"),mAe=a("strong"),bRr=o("gpt2"),vRr=o(" \u2014 "),Xee=a("a"),FRr=o("TFGPT2Model"),TRr=o(" (OpenAI GPT-2 model)"),MRr=l(),d5=a("li"),cAe=a("strong"),ERr=o("gptj"),CRr=o(" \u2014 "),zee=a("a"),wRr=o("TFGPTJModel"),ARr=o(" (GPT-J model)"),LRr=l(),m5=a("li"),fAe=a("strong"),yRr=o("groupvit"),xRr=o(" \u2014 "),Qee=a("a"),$Rr=o("TFGroupViTModel"),kRr=o(" (GroupViT model)"),SRr=l(),c5=a("li"),gAe=a("strong"),RRr=o("hubert"),PRr=o(" \u2014 "),Wee=a("a"),BRr=o("TFHubertModel"),IRr=o(" (Hubert model)"),NRr=l(),f5=a("li"),hAe=a("strong"),qRr=o("layoutlm"),jRr=o(" \u2014 "),Uee=a("a"),DRr=o("TFLayoutLMModel"),GRr=o(" (LayoutLM model)"),ORr=l(),g5=a("li"),uAe=a("strong"),VRr=o("layoutlmv3"),XRr=o(" \u2014 "),Hee=a("a"),zRr=o("TFLayoutLMv3Model"),QRr=o(" (LayoutLMv3 model)"),WRr=l(),h5=a("li"),pAe=a("strong"),URr=o("led"),HRr=o(" \u2014 "),Jee=a("a"),JRr=o("TFLEDModel"),YRr=o(" (LED model)"),KRr=l(),u5=a("li"),_Ae=a("strong"),ZRr=o("longformer"),ePr=o(" \u2014 "),Yee=a("a"),oPr=o("TFLongformerModel"),rPr=o(" (Longformer model)"),tPr=l(),p5=a("li"),bAe=a("strong"),aPr=o("lxmert"),nPr=o(" \u2014 "),Kee=a("a"),sPr=o("TFLxmertModel"),lPr=o(" (LXMERT model)"),iPr=l(),_5=a("li"),vAe=a("strong"),dPr=o("marian"),mPr=o(" \u2014 "),Zee=a("a"),cPr=o("TFMarianModel"),fPr=o(" (Marian model)"),gPr=l(),b5=a("li"),FAe=a("strong"),hPr=o("mbart"),uPr=o(" \u2014 "),eoe=a("a"),pPr=o("TFMBartModel"),_Pr=o(" (mBART model)"),bPr=l(),v5=a("li"),TAe=a("strong"),vPr=o("mobilebert"),FPr=o(" \u2014 "),ooe=a("a"),TPr=o("TFMobileBertModel"),MPr=o(" (MobileBERT model)"),EPr=l(),F5=a("li"),MAe=a("strong"),CPr=o("mobilevit"),wPr=o(" \u2014 "),roe=a("a"),APr=o("TFMobileViTModel"),LPr=o(" (MobileViT model)"),yPr=l(),T5=a("li"),EAe=a("strong"),xPr=o("mpnet"),$Pr=o(" \u2014 "),toe=a("a"),kPr=o("TFMPNetModel"),SPr=o(" (MPNet model)"),RPr=l(),M5=a("li"),CAe=a("strong"),PPr=o("mt5"),BPr=o(" \u2014 "),aoe=a("a"),IPr=o("TFMT5Model"),NPr=o(" (MT5 model)"),qPr=l(),E5=a("li"),wAe=a("strong"),jPr=o("openai-gpt"),DPr=o(" \u2014 "),noe=a("a"),GPr=o("TFOpenAIGPTModel"),OPr=o(" (OpenAI GPT model)"),VPr=l(),C5=a("li"),AAe=a("strong"),XPr=o("opt"),zPr=o(" \u2014 "),soe=a("a"),QPr=o("TFOPTModel"),WPr=o(" (OPT model)"),UPr=l(),w5=a("li"),LAe=a("strong"),HPr=o("pegasus"),JPr=o(" \u2014 "),loe=a("a"),YPr=o("TFPegasusModel"),KPr=o(" (Pegasus model)"),ZPr=l(),A5=a("li"),yAe=a("strong"),eBr=o("regnet"),oBr=o(" \u2014 "),ioe=a("a"),rBr=o("TFRegNetModel"),tBr=o(" (RegNet model)"),aBr=l(),L5=a("li"),xAe=a("strong"),nBr=o("rembert"),sBr=o(" \u2014 "),doe=a("a"),lBr=o("TFRemBertModel"),iBr=o(" (RemBERT model)"),dBr=l(),y5=a("li"),$Ae=a("strong"),mBr=o("resnet"),cBr=o(" \u2014 "),moe=a("a"),fBr=o("TFResNetModel"),gBr=o(" (ResNet model)"),hBr=l(),x5=a("li"),kAe=a("strong"),uBr=o("roberta"),pBr=o(" \u2014 "),coe=a("a"),_Br=o("TFRobertaModel"),bBr=o(" (RoBERTa model)"),vBr=l(),$5=a("li"),SAe=a("strong"),FBr=o("roformer"),TBr=o(" \u2014 "),foe=a("a"),MBr=o("TFRoFormerModel"),EBr=o(" (RoFormer model)"),CBr=l(),k5=a("li"),RAe=a("strong"),wBr=o("segformer"),ABr=o(" \u2014 "),goe=a("a"),LBr=o("TFSegformerModel"),yBr=o(" (SegFormer model)"),xBr=l(),S5=a("li"),PAe=a("strong"),$Br=o("speech_to_text"),kBr=o(" \u2014 "),hoe=a("a"),SBr=o("TFSpeech2TextModel"),RBr=o(" (Speech2Text model)"),PBr=l(),R5=a("li"),BAe=a("strong"),BBr=o("swin"),IBr=o(" \u2014 "),uoe=a("a"),NBr=o("TFSwinModel"),qBr=o(" (Swin Transformer model)"),jBr=l(),P5=a("li"),IAe=a("strong"),DBr=o("t5"),GBr=o(" \u2014 "),poe=a("a"),OBr=o("TFT5Model"),VBr=o(" (T5 model)"),XBr=l(),B5=a("li"),NAe=a("strong"),zBr=o("tapas"),QBr=o(" \u2014 "),_oe=a("a"),WBr=o("TFTapasModel"),UBr=o(" (TAPAS model)"),HBr=l(),I5=a("li"),qAe=a("strong"),JBr=o("transfo-xl"),YBr=o(" \u2014 "),boe=a("a"),KBr=o("TFTransfoXLModel"),ZBr=o(" (Transformer-XL model)"),eIr=l(),N5=a("li"),jAe=a("strong"),oIr=o("vit"),rIr=o(" \u2014 "),voe=a("a"),tIr=o("TFViTModel"),aIr=o(" (ViT model)"),nIr=l(),q5=a("li"),DAe=a("strong"),sIr=o("vit_mae"),lIr=o(" \u2014 "),Foe=a("a"),iIr=o("TFViTMAEModel"),dIr=o(" (ViTMAE model)"),mIr=l(),j5=a("li"),GAe=a("strong"),cIr=o("wav2vec2"),fIr=o(" \u2014 "),Toe=a("a"),gIr=o("TFWav2Vec2Model"),hIr=o(" (Wav2Vec2 model)"),uIr=l(),D5=a("li"),OAe=a("strong"),pIr=o("xglm"),_Ir=o(" \u2014 "),Moe=a("a"),bIr=o("TFXGLMModel"),vIr=o(" (XGLM model)"),FIr=l(),G5=a("li"),VAe=a("strong"),TIr=o("xlm"),MIr=o(" \u2014 "),Eoe=a("a"),EIr=o("TFXLMModel"),CIr=o(" (XLM model)"),wIr=l(),O5=a("li"),XAe=a("strong"),AIr=o("xlm-roberta"),LIr=o(" \u2014 "),Coe=a("a"),yIr=o("TFXLMRobertaModel"),xIr=o(" (XLM-RoBERTa model)"),$Ir=l(),V5=a("li"),zAe=a("strong"),kIr=o("xlnet"),SIr=o(" \u2014 "),woe=a("a"),RIr=o("TFXLNetModel"),PIr=o(" (XLNet model)"),BIr=l(),F(X5.$$.fragment),yoo=l(),Qm=a("h2"),z5=a("a"),QAe=a("span"),F(lS.$$.fragment),IIr=l(),WAe=a("span"),NIr=o("TFAutoModelForPreTraining"),xoo=l(),lr=a("div"),F(iS.$$.fragment),qIr=l(),Wm=a("p"),jIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Aoe=a("a"),DIr=o("from_pretrained()"),GIr=o(" class method or the "),Loe=a("a"),OIr=o("from_config()"),VIr=o(` class
method.`),XIr=l(),dS=a("p"),zIr=o("This class cannot be instantiated directly using "),UAe=a("code"),QIr=o("__init__()"),WIr=o(" (throws an error)."),UIr=l(),zt=a("div"),F(mS.$$.fragment),HIr=l(),HAe=a("p"),JIr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),YIr=l(),Um=a("p"),KIr=o(`Note:
Loading a model from its configuration file does `),JAe=a("strong"),ZIr=o("not"),eNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yoe=a("a"),oNr=o("from_pretrained()"),rNr=o(" to load the model weights."),tNr=l(),F(Q5.$$.fragment),aNr=l(),Nr=a("div"),F(cS.$$.fragment),nNr=l(),YAe=a("p"),sNr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),lNr=l(),An=a("p"),iNr=o("The model class to instantiate is selected based on the "),KAe=a("code"),dNr=o("model_type"),mNr=o(` property of the config object (either
passed as an argument or loaded from `),ZAe=a("code"),cNr=o("pretrained_model_name_or_path"),fNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e6e=a("code"),gNr=o("pretrained_model_name_or_path"),hNr=o(":"),uNr=l(),le=a("ul"),W5=a("li"),o6e=a("strong"),pNr=o("albert"),_Nr=o(" \u2014 "),xoe=a("a"),bNr=o("TFAlbertForPreTraining"),vNr=o(" (ALBERT model)"),FNr=l(),U5=a("li"),r6e=a("strong"),TNr=o("bart"),MNr=o(" \u2014 "),$oe=a("a"),ENr=o("TFBartForConditionalGeneration"),CNr=o(" (BART model)"),wNr=l(),H5=a("li"),t6e=a("strong"),ANr=o("bert"),LNr=o(" \u2014 "),koe=a("a"),yNr=o("TFBertForPreTraining"),xNr=o(" (BERT model)"),$Nr=l(),J5=a("li"),a6e=a("strong"),kNr=o("camembert"),SNr=o(" \u2014 "),Soe=a("a"),RNr=o("TFCamembertForMaskedLM"),PNr=o(" (CamemBERT model)"),BNr=l(),Y5=a("li"),n6e=a("strong"),INr=o("ctrl"),NNr=o(" \u2014 "),Roe=a("a"),qNr=o("TFCTRLLMHeadModel"),jNr=o(" (CTRL model)"),DNr=l(),K5=a("li"),s6e=a("strong"),GNr=o("distilbert"),ONr=o(" \u2014 "),Poe=a("a"),VNr=o("TFDistilBertForMaskedLM"),XNr=o(" (DistilBERT model)"),zNr=l(),Z5=a("li"),l6e=a("strong"),QNr=o("electra"),WNr=o(" \u2014 "),Boe=a("a"),UNr=o("TFElectraForPreTraining"),HNr=o(" (ELECTRA model)"),JNr=l(),e0=a("li"),i6e=a("strong"),YNr=o("flaubert"),KNr=o(" \u2014 "),Ioe=a("a"),ZNr=o("TFFlaubertWithLMHeadModel"),eqr=o(" (FlauBERT model)"),oqr=l(),o0=a("li"),d6e=a("strong"),rqr=o("funnel"),tqr=o(" \u2014 "),Noe=a("a"),aqr=o("TFFunnelForPreTraining"),nqr=o(" (Funnel Transformer model)"),sqr=l(),r0=a("li"),m6e=a("strong"),lqr=o("gpt2"),iqr=o(" \u2014 "),qoe=a("a"),dqr=o("TFGPT2LMHeadModel"),mqr=o(" (OpenAI GPT-2 model)"),cqr=l(),t0=a("li"),c6e=a("strong"),fqr=o("layoutlm"),gqr=o(" \u2014 "),joe=a("a"),hqr=o("TFLayoutLMForMaskedLM"),uqr=o(" (LayoutLM model)"),pqr=l(),a0=a("li"),f6e=a("strong"),_qr=o("lxmert"),bqr=o(" \u2014 "),Doe=a("a"),vqr=o("TFLxmertForPreTraining"),Fqr=o(" (LXMERT model)"),Tqr=l(),n0=a("li"),g6e=a("strong"),Mqr=o("mobilebert"),Eqr=o(" \u2014 "),Goe=a("a"),Cqr=o("TFMobileBertForPreTraining"),wqr=o(" (MobileBERT model)"),Aqr=l(),s0=a("li"),h6e=a("strong"),Lqr=o("mpnet"),yqr=o(" \u2014 "),Ooe=a("a"),xqr=o("TFMPNetForMaskedLM"),$qr=o(" (MPNet model)"),kqr=l(),l0=a("li"),u6e=a("strong"),Sqr=o("openai-gpt"),Rqr=o(" \u2014 "),Voe=a("a"),Pqr=o("TFOpenAIGPTLMHeadModel"),Bqr=o(" (OpenAI GPT model)"),Iqr=l(),i0=a("li"),p6e=a("strong"),Nqr=o("roberta"),qqr=o(" \u2014 "),Xoe=a("a"),jqr=o("TFRobertaForMaskedLM"),Dqr=o(" (RoBERTa model)"),Gqr=l(),d0=a("li"),_6e=a("strong"),Oqr=o("t5"),Vqr=o(" \u2014 "),zoe=a("a"),Xqr=o("TFT5ForConditionalGeneration"),zqr=o(" (T5 model)"),Qqr=l(),m0=a("li"),b6e=a("strong"),Wqr=o("tapas"),Uqr=o(" \u2014 "),Qoe=a("a"),Hqr=o("TFTapasForMaskedLM"),Jqr=o(" (TAPAS model)"),Yqr=l(),c0=a("li"),v6e=a("strong"),Kqr=o("transfo-xl"),Zqr=o(" \u2014 "),Woe=a("a"),ejr=o("TFTransfoXLLMHeadModel"),ojr=o(" (Transformer-XL model)"),rjr=l(),f0=a("li"),F6e=a("strong"),tjr=o("vit_mae"),ajr=o(" \u2014 "),Uoe=a("a"),njr=o("TFViTMAEForPreTraining"),sjr=o(" (ViTMAE model)"),ljr=l(),g0=a("li"),T6e=a("strong"),ijr=o("xlm"),djr=o(" \u2014 "),Hoe=a("a"),mjr=o("TFXLMWithLMHeadModel"),cjr=o(" (XLM model)"),fjr=l(),h0=a("li"),M6e=a("strong"),gjr=o("xlm-roberta"),hjr=o(" \u2014 "),Joe=a("a"),ujr=o("TFXLMRobertaForMaskedLM"),pjr=o(" (XLM-RoBERTa model)"),_jr=l(),u0=a("li"),E6e=a("strong"),bjr=o("xlnet"),vjr=o(" \u2014 "),Yoe=a("a"),Fjr=o("TFXLNetLMHeadModel"),Tjr=o(" (XLNet model)"),Mjr=l(),F(p0.$$.fragment),$oo=l(),Hm=a("h2"),_0=a("a"),C6e=a("span"),F(fS.$$.fragment),Ejr=l(),w6e=a("span"),Cjr=o("TFAutoModelForCausalLM"),koo=l(),ir=a("div"),F(gS.$$.fragment),wjr=l(),Jm=a("p"),Ajr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Koe=a("a"),Ljr=o("from_pretrained()"),yjr=o(" class method or the "),Zoe=a("a"),xjr=o("from_config()"),$jr=o(` class
method.`),kjr=l(),hS=a("p"),Sjr=o("This class cannot be instantiated directly using "),A6e=a("code"),Rjr=o("__init__()"),Pjr=o(" (throws an error)."),Bjr=l(),Qt=a("div"),F(uS.$$.fragment),Ijr=l(),L6e=a("p"),Njr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),qjr=l(),Ym=a("p"),jjr=o(`Note:
Loading a model from its configuration file does `),y6e=a("strong"),Djr=o("not"),Gjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ere=a("a"),Ojr=o("from_pretrained()"),Vjr=o(" to load the model weights."),Xjr=l(),F(b0.$$.fragment),zjr=l(),qr=a("div"),F(pS.$$.fragment),Qjr=l(),x6e=a("p"),Wjr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Ujr=l(),Ln=a("p"),Hjr=o("The model class to instantiate is selected based on the "),$6e=a("code"),Jjr=o("model_type"),Yjr=o(` property of the config object (either
passed as an argument or loaded from `),k6e=a("code"),Kjr=o("pretrained_model_name_or_path"),Zjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S6e=a("code"),eDr=o("pretrained_model_name_or_path"),oDr=o(":"),rDr=l(),Me=a("ul"),v0=a("li"),R6e=a("strong"),tDr=o("bert"),aDr=o(" \u2014 "),ore=a("a"),nDr=o("TFBertLMHeadModel"),sDr=o(" (BERT model)"),lDr=l(),F0=a("li"),P6e=a("strong"),iDr=o("camembert"),dDr=o(" \u2014 "),rre=a("a"),mDr=o("TFCamembertForCausalLM"),cDr=o(" (CamemBERT model)"),fDr=l(),T0=a("li"),B6e=a("strong"),gDr=o("ctrl"),hDr=o(" \u2014 "),tre=a("a"),uDr=o("TFCTRLLMHeadModel"),pDr=o(" (CTRL model)"),_Dr=l(),M0=a("li"),I6e=a("strong"),bDr=o("gpt2"),vDr=o(" \u2014 "),are=a("a"),FDr=o("TFGPT2LMHeadModel"),TDr=o(" (OpenAI GPT-2 model)"),MDr=l(),E0=a("li"),N6e=a("strong"),EDr=o("gptj"),CDr=o(" \u2014 "),nre=a("a"),wDr=o("TFGPTJForCausalLM"),ADr=o(" (GPT-J model)"),LDr=l(),C0=a("li"),q6e=a("strong"),yDr=o("openai-gpt"),xDr=o(" \u2014 "),sre=a("a"),$Dr=o("TFOpenAIGPTLMHeadModel"),kDr=o(" (OpenAI GPT model)"),SDr=l(),w0=a("li"),j6e=a("strong"),RDr=o("opt"),PDr=o(" \u2014 "),lre=a("a"),BDr=o("TFOPTForCausalLM"),IDr=o(" (OPT model)"),NDr=l(),A0=a("li"),D6e=a("strong"),qDr=o("rembert"),jDr=o(" \u2014 "),ire=a("a"),DDr=o("TFRemBertForCausalLM"),GDr=o(" (RemBERT model)"),ODr=l(),L0=a("li"),G6e=a("strong"),VDr=o("roberta"),XDr=o(" \u2014 "),dre=a("a"),zDr=o("TFRobertaForCausalLM"),QDr=o(" (RoBERTa model)"),WDr=l(),y0=a("li"),O6e=a("strong"),UDr=o("roformer"),HDr=o(" \u2014 "),mre=a("a"),JDr=o("TFRoFormerForCausalLM"),YDr=o(" (RoFormer model)"),KDr=l(),x0=a("li"),V6e=a("strong"),ZDr=o("transfo-xl"),eGr=o(" \u2014 "),cre=a("a"),oGr=o("TFTransfoXLLMHeadModel"),rGr=o(" (Transformer-XL model)"),tGr=l(),$0=a("li"),X6e=a("strong"),aGr=o("xglm"),nGr=o(" \u2014 "),fre=a("a"),sGr=o("TFXGLMForCausalLM"),lGr=o(" (XGLM model)"),iGr=l(),k0=a("li"),z6e=a("strong"),dGr=o("xlm"),mGr=o(" \u2014 "),gre=a("a"),cGr=o("TFXLMWithLMHeadModel"),fGr=o(" (XLM model)"),gGr=l(),S0=a("li"),Q6e=a("strong"),hGr=o("xlnet"),uGr=o(" \u2014 "),hre=a("a"),pGr=o("TFXLNetLMHeadModel"),_Gr=o(" (XLNet model)"),bGr=l(),F(R0.$$.fragment),Soo=l(),Km=a("h2"),P0=a("a"),W6e=a("span"),F(_S.$$.fragment),vGr=l(),U6e=a("span"),FGr=o("TFAutoModelForImageClassification"),Roo=l(),dr=a("div"),F(bS.$$.fragment),TGr=l(),Zm=a("p"),MGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),ure=a("a"),EGr=o("from_pretrained()"),CGr=o(" class method or the "),pre=a("a"),wGr=o("from_config()"),AGr=o(` class
method.`),LGr=l(),vS=a("p"),yGr=o("This class cannot be instantiated directly using "),H6e=a("code"),xGr=o("__init__()"),$Gr=o(" (throws an error)."),kGr=l(),Wt=a("div"),F(FS.$$.fragment),SGr=l(),J6e=a("p"),RGr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),PGr=l(),ec=a("p"),BGr=o(`Note:
Loading a model from its configuration file does `),Y6e=a("strong"),IGr=o("not"),NGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_re=a("a"),qGr=o("from_pretrained()"),jGr=o(" to load the model weights."),DGr=l(),F(B0.$$.fragment),GGr=l(),jr=a("div"),F(TS.$$.fragment),OGr=l(),K6e=a("p"),VGr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),XGr=l(),yn=a("p"),zGr=o("The model class to instantiate is selected based on the "),Z6e=a("code"),QGr=o("model_type"),WGr=o(` property of the config object (either
passed as an argument or loaded from `),e7e=a("code"),UGr=o("pretrained_model_name_or_path"),HGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o7e=a("code"),JGr=o("pretrained_model_name_or_path"),YGr=o(":"),KGr=l(),Be=a("ul"),I0=a("li"),r7e=a("strong"),ZGr=o("convnext"),eOr=o(" \u2014 "),bre=a("a"),oOr=o("TFConvNextForImageClassification"),rOr=o(" (ConvNeXT model)"),tOr=l(),N0=a("li"),t7e=a("strong"),aOr=o("data2vec-vision"),nOr=o(" \u2014 "),vre=a("a"),sOr=o("TFData2VecVisionForImageClassification"),lOr=o(" (Data2VecVision model)"),iOr=l(),Tl=a("li"),a7e=a("strong"),dOr=o("deit"),mOr=o(" \u2014 "),Fre=a("a"),cOr=o("TFDeiTForImageClassification"),fOr=o(" or "),Tre=a("a"),gOr=o("TFDeiTForImageClassificationWithTeacher"),hOr=o(" (DeiT model)"),uOr=l(),q0=a("li"),n7e=a("strong"),pOr=o("mobilevit"),_Or=o(" \u2014 "),Mre=a("a"),bOr=o("TFMobileViTForImageClassification"),vOr=o(" (MobileViT model)"),FOr=l(),j0=a("li"),s7e=a("strong"),TOr=o("regnet"),MOr=o(" \u2014 "),Ere=a("a"),EOr=o("TFRegNetForImageClassification"),COr=o(" (RegNet model)"),wOr=l(),D0=a("li"),l7e=a("strong"),AOr=o("resnet"),LOr=o(" \u2014 "),Cre=a("a"),yOr=o("TFResNetForImageClassification"),xOr=o(" (ResNet model)"),$Or=l(),G0=a("li"),i7e=a("strong"),kOr=o("segformer"),SOr=o(" \u2014 "),wre=a("a"),ROr=o("TFSegformerForImageClassification"),POr=o(" (SegFormer model)"),BOr=l(),O0=a("li"),d7e=a("strong"),IOr=o("swin"),NOr=o(" \u2014 "),Are=a("a"),qOr=o("TFSwinForImageClassification"),jOr=o(" (Swin Transformer model)"),DOr=l(),V0=a("li"),m7e=a("strong"),GOr=o("vit"),OOr=o(" \u2014 "),Lre=a("a"),VOr=o("TFViTForImageClassification"),XOr=o(" (ViT model)"),zOr=l(),F(X0.$$.fragment),Poo=l(),oc=a("h2"),z0=a("a"),c7e=a("span"),F(MS.$$.fragment),QOr=l(),f7e=a("span"),WOr=o("TFAutoModelForSemanticSegmentation"),Boo=l(),mr=a("div"),F(ES.$$.fragment),UOr=l(),rc=a("p"),HOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),yre=a("a"),JOr=o("from_pretrained()"),YOr=o(" class method or the "),xre=a("a"),KOr=o("from_config()"),ZOr=o(` class
method.`),eVr=l(),CS=a("p"),oVr=o("This class cannot be instantiated directly using "),g7e=a("code"),rVr=o("__init__()"),tVr=o(" (throws an error)."),aVr=l(),Ut=a("div"),F(wS.$$.fragment),nVr=l(),h7e=a("p"),sVr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),lVr=l(),tc=a("p"),iVr=o(`Note:
Loading a model from its configuration file does `),u7e=a("strong"),dVr=o("not"),mVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$re=a("a"),cVr=o("from_pretrained()"),fVr=o(" to load the model weights."),gVr=l(),F(Q0.$$.fragment),hVr=l(),Dr=a("div"),F(AS.$$.fragment),uVr=l(),p7e=a("p"),pVr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),_Vr=l(),xn=a("p"),bVr=o("The model class to instantiate is selected based on the "),_7e=a("code"),vVr=o("model_type"),FVr=o(` property of the config object (either
passed as an argument or loaded from `),b7e=a("code"),TVr=o("pretrained_model_name_or_path"),MVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v7e=a("code"),EVr=o("pretrained_model_name_or_path"),CVr=o(":"),wVr=l(),ac=a("ul"),W0=a("li"),F7e=a("strong"),AVr=o("data2vec-vision"),LVr=o(" \u2014 "),kre=a("a"),yVr=o("TFData2VecVisionForSemanticSegmentation"),xVr=o(" (Data2VecVision model)"),$Vr=l(),U0=a("li"),T7e=a("strong"),kVr=o("mobilevit"),SVr=o(" \u2014 "),Sre=a("a"),RVr=o("TFMobileViTForSemanticSegmentation"),PVr=o(" (MobileViT model)"),BVr=l(),H0=a("li"),M7e=a("strong"),IVr=o("segformer"),NVr=o(" \u2014 "),Rre=a("a"),qVr=o("TFSegformerForSemanticSegmentation"),jVr=o(" (SegFormer model)"),DVr=l(),F(J0.$$.fragment),Ioo=l(),nc=a("h2"),Y0=a("a"),E7e=a("span"),F(LS.$$.fragment),GVr=l(),C7e=a("span"),OVr=o("TFAutoModelForMaskedLM"),Noo=l(),cr=a("div"),F(yS.$$.fragment),VVr=l(),sc=a("p"),XVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Pre=a("a"),zVr=o("from_pretrained()"),QVr=o(" class method or the "),Bre=a("a"),WVr=o("from_config()"),UVr=o(` class
method.`),HVr=l(),xS=a("p"),JVr=o("This class cannot be instantiated directly using "),w7e=a("code"),YVr=o("__init__()"),KVr=o(" (throws an error)."),ZVr=l(),Ht=a("div"),F($S.$$.fragment),eXr=l(),A7e=a("p"),oXr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),rXr=l(),lc=a("p"),tXr=o(`Note:
Loading a model from its configuration file does `),L7e=a("strong"),aXr=o("not"),nXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ire=a("a"),sXr=o("from_pretrained()"),lXr=o(" to load the model weights."),iXr=l(),F(K0.$$.fragment),dXr=l(),Gr=a("div"),F(kS.$$.fragment),mXr=l(),y7e=a("p"),cXr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),fXr=l(),$n=a("p"),gXr=o("The model class to instantiate is selected based on the "),x7e=a("code"),hXr=o("model_type"),uXr=o(` property of the config object (either
passed as an argument or loaded from `),$7e=a("code"),pXr=o("pretrained_model_name_or_path"),_Xr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k7e=a("code"),bXr=o("pretrained_model_name_or_path"),vXr=o(":"),FXr=l(),ge=a("ul"),Z0=a("li"),S7e=a("strong"),TXr=o("albert"),MXr=o(" \u2014 "),Nre=a("a"),EXr=o("TFAlbertForMaskedLM"),CXr=o(" (ALBERT model)"),wXr=l(),ew=a("li"),R7e=a("strong"),AXr=o("bert"),LXr=o(" \u2014 "),qre=a("a"),yXr=o("TFBertForMaskedLM"),xXr=o(" (BERT model)"),$Xr=l(),ow=a("li"),P7e=a("strong"),kXr=o("camembert"),SXr=o(" \u2014 "),jre=a("a"),RXr=o("TFCamembertForMaskedLM"),PXr=o(" (CamemBERT model)"),BXr=l(),rw=a("li"),B7e=a("strong"),IXr=o("convbert"),NXr=o(" \u2014 "),Dre=a("a"),qXr=o("TFConvBertForMaskedLM"),jXr=o(" (ConvBERT model)"),DXr=l(),tw=a("li"),I7e=a("strong"),GXr=o("deberta"),OXr=o(" \u2014 "),Gre=a("a"),VXr=o("TFDebertaForMaskedLM"),XXr=o(" (DeBERTa model)"),zXr=l(),aw=a("li"),N7e=a("strong"),QXr=o("deberta-v2"),WXr=o(" \u2014 "),Ore=a("a"),UXr=o("TFDebertaV2ForMaskedLM"),HXr=o(" (DeBERTa-v2 model)"),JXr=l(),nw=a("li"),q7e=a("strong"),YXr=o("distilbert"),KXr=o(" \u2014 "),Vre=a("a"),ZXr=o("TFDistilBertForMaskedLM"),ezr=o(" (DistilBERT model)"),ozr=l(),sw=a("li"),j7e=a("strong"),rzr=o("electra"),tzr=o(" \u2014 "),Xre=a("a"),azr=o("TFElectraForMaskedLM"),nzr=o(" (ELECTRA model)"),szr=l(),lw=a("li"),D7e=a("strong"),lzr=o("flaubert"),izr=o(" \u2014 "),zre=a("a"),dzr=o("TFFlaubertWithLMHeadModel"),mzr=o(" (FlauBERT model)"),czr=l(),iw=a("li"),G7e=a("strong"),fzr=o("funnel"),gzr=o(" \u2014 "),Qre=a("a"),hzr=o("TFFunnelForMaskedLM"),uzr=o(" (Funnel Transformer model)"),pzr=l(),dw=a("li"),O7e=a("strong"),_zr=o("layoutlm"),bzr=o(" \u2014 "),Wre=a("a"),vzr=o("TFLayoutLMForMaskedLM"),Fzr=o(" (LayoutLM model)"),Tzr=l(),mw=a("li"),V7e=a("strong"),Mzr=o("longformer"),Ezr=o(" \u2014 "),Ure=a("a"),Czr=o("TFLongformerForMaskedLM"),wzr=o(" (Longformer model)"),Azr=l(),cw=a("li"),X7e=a("strong"),Lzr=o("mobilebert"),yzr=o(" \u2014 "),Hre=a("a"),xzr=o("TFMobileBertForMaskedLM"),$zr=o(" (MobileBERT model)"),kzr=l(),fw=a("li"),z7e=a("strong"),Szr=o("mpnet"),Rzr=o(" \u2014 "),Jre=a("a"),Pzr=o("TFMPNetForMaskedLM"),Bzr=o(" (MPNet model)"),Izr=l(),gw=a("li"),Q7e=a("strong"),Nzr=o("rembert"),qzr=o(" \u2014 "),Yre=a("a"),jzr=o("TFRemBertForMaskedLM"),Dzr=o(" (RemBERT model)"),Gzr=l(),hw=a("li"),W7e=a("strong"),Ozr=o("roberta"),Vzr=o(" \u2014 "),Kre=a("a"),Xzr=o("TFRobertaForMaskedLM"),zzr=o(" (RoBERTa model)"),Qzr=l(),uw=a("li"),U7e=a("strong"),Wzr=o("roformer"),Uzr=o(" \u2014 "),Zre=a("a"),Hzr=o("TFRoFormerForMaskedLM"),Jzr=o(" (RoFormer model)"),Yzr=l(),pw=a("li"),H7e=a("strong"),Kzr=o("tapas"),Zzr=o(" \u2014 "),ete=a("a"),eQr=o("TFTapasForMaskedLM"),oQr=o(" (TAPAS model)"),rQr=l(),_w=a("li"),J7e=a("strong"),tQr=o("xlm"),aQr=o(" \u2014 "),ote=a("a"),nQr=o("TFXLMWithLMHeadModel"),sQr=o(" (XLM model)"),lQr=l(),bw=a("li"),Y7e=a("strong"),iQr=o("xlm-roberta"),dQr=o(" \u2014 "),rte=a("a"),mQr=o("TFXLMRobertaForMaskedLM"),cQr=o(" (XLM-RoBERTa model)"),fQr=l(),F(vw.$$.fragment),qoo=l(),ic=a("h2"),Fw=a("a"),K7e=a("span"),F(SS.$$.fragment),gQr=l(),Z7e=a("span"),hQr=o("TFAutoModelForSeq2SeqLM"),joo=l(),fr=a("div"),F(RS.$$.fragment),uQr=l(),dc=a("p"),pQr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),tte=a("a"),_Qr=o("from_pretrained()"),bQr=o(" class method or the "),ate=a("a"),vQr=o("from_config()"),FQr=o(` class
method.`),TQr=l(),PS=a("p"),MQr=o("This class cannot be instantiated directly using "),eLe=a("code"),EQr=o("__init__()"),CQr=o(" (throws an error)."),wQr=l(),Jt=a("div"),F(BS.$$.fragment),AQr=l(),oLe=a("p"),LQr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),yQr=l(),mc=a("p"),xQr=o(`Note:
Loading a model from its configuration file does `),rLe=a("strong"),$Qr=o("not"),kQr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nte=a("a"),SQr=o("from_pretrained()"),RQr=o(" to load the model weights."),PQr=l(),F(Tw.$$.fragment),BQr=l(),Or=a("div"),F(IS.$$.fragment),IQr=l(),tLe=a("p"),NQr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),qQr=l(),kn=a("p"),jQr=o("The model class to instantiate is selected based on the "),aLe=a("code"),DQr=o("model_type"),GQr=o(` property of the config object (either
passed as an argument or loaded from `),nLe=a("code"),OQr=o("pretrained_model_name_or_path"),VQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sLe=a("code"),XQr=o("pretrained_model_name_or_path"),zQr=o(":"),QQr=l(),ye=a("ul"),Mw=a("li"),lLe=a("strong"),WQr=o("bart"),UQr=o(" \u2014 "),ste=a("a"),HQr=o("TFBartForConditionalGeneration"),JQr=o(" (BART model)"),YQr=l(),Ew=a("li"),iLe=a("strong"),KQr=o("blenderbot"),ZQr=o(" \u2014 "),lte=a("a"),eWr=o("TFBlenderbotForConditionalGeneration"),oWr=o(" (Blenderbot model)"),rWr=l(),Cw=a("li"),dLe=a("strong"),tWr=o("blenderbot-small"),aWr=o(" \u2014 "),ite=a("a"),nWr=o("TFBlenderbotSmallForConditionalGeneration"),sWr=o(" (BlenderbotSmall model)"),lWr=l(),ww=a("li"),mLe=a("strong"),iWr=o("encoder-decoder"),dWr=o(" \u2014 "),dte=a("a"),mWr=o("TFEncoderDecoderModel"),cWr=o(" (Encoder decoder model)"),fWr=l(),Aw=a("li"),cLe=a("strong"),gWr=o("led"),hWr=o(" \u2014 "),mte=a("a"),uWr=o("TFLEDForConditionalGeneration"),pWr=o(" (LED model)"),_Wr=l(),Lw=a("li"),fLe=a("strong"),bWr=o("marian"),vWr=o(" \u2014 "),cte=a("a"),FWr=o("TFMarianMTModel"),TWr=o(" (Marian model)"),MWr=l(),yw=a("li"),gLe=a("strong"),EWr=o("mbart"),CWr=o(" \u2014 "),fte=a("a"),wWr=o("TFMBartForConditionalGeneration"),AWr=o(" (mBART model)"),LWr=l(),xw=a("li"),hLe=a("strong"),yWr=o("mt5"),xWr=o(" \u2014 "),gte=a("a"),$Wr=o("TFMT5ForConditionalGeneration"),kWr=o(" (MT5 model)"),SWr=l(),$w=a("li"),uLe=a("strong"),RWr=o("pegasus"),PWr=o(" \u2014 "),hte=a("a"),BWr=o("TFPegasusForConditionalGeneration"),IWr=o(" (Pegasus model)"),NWr=l(),kw=a("li"),pLe=a("strong"),qWr=o("t5"),jWr=o(" \u2014 "),ute=a("a"),DWr=o("TFT5ForConditionalGeneration"),GWr=o(" (T5 model)"),OWr=l(),F(Sw.$$.fragment),Doo=l(),cc=a("h2"),Rw=a("a"),_Le=a("span"),F(NS.$$.fragment),VWr=l(),bLe=a("span"),XWr=o("TFAutoModelForSequenceClassification"),Goo=l(),gr=a("div"),F(qS.$$.fragment),zWr=l(),fc=a("p"),QWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),pte=a("a"),WWr=o("from_pretrained()"),UWr=o(" class method or the "),_te=a("a"),HWr=o("from_config()"),JWr=o(` class
method.`),YWr=l(),jS=a("p"),KWr=o("This class cannot be instantiated directly using "),vLe=a("code"),ZWr=o("__init__()"),eUr=o(" (throws an error)."),oUr=l(),Yt=a("div"),F(DS.$$.fragment),rUr=l(),FLe=a("p"),tUr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),aUr=l(),gc=a("p"),nUr=o(`Note:
Loading a model from its configuration file does `),TLe=a("strong"),sUr=o("not"),lUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bte=a("a"),iUr=o("from_pretrained()"),dUr=o(" to load the model weights."),mUr=l(),F(Pw.$$.fragment),cUr=l(),Vr=a("div"),F(GS.$$.fragment),fUr=l(),MLe=a("p"),gUr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),hUr=l(),Sn=a("p"),uUr=o("The model class to instantiate is selected based on the "),ELe=a("code"),pUr=o("model_type"),_Ur=o(` property of the config object (either
passed as an argument or loaded from `),CLe=a("code"),bUr=o("pretrained_model_name_or_path"),vUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wLe=a("code"),FUr=o("pretrained_model_name_or_path"),TUr=o(":"),MUr=l(),re=a("ul"),Bw=a("li"),ALe=a("strong"),EUr=o("albert"),CUr=o(" \u2014 "),vte=a("a"),wUr=o("TFAlbertForSequenceClassification"),AUr=o(" (ALBERT model)"),LUr=l(),Iw=a("li"),LLe=a("strong"),yUr=o("bert"),xUr=o(" \u2014 "),Fte=a("a"),$Ur=o("TFBertForSequenceClassification"),kUr=o(" (BERT model)"),SUr=l(),Nw=a("li"),yLe=a("strong"),RUr=o("camembert"),PUr=o(" \u2014 "),Tte=a("a"),BUr=o("TFCamembertForSequenceClassification"),IUr=o(" (CamemBERT model)"),NUr=l(),qw=a("li"),xLe=a("strong"),qUr=o("convbert"),jUr=o(" \u2014 "),Mte=a("a"),DUr=o("TFConvBertForSequenceClassification"),GUr=o(" (ConvBERT model)"),OUr=l(),jw=a("li"),$Le=a("strong"),VUr=o("ctrl"),XUr=o(" \u2014 "),Ete=a("a"),zUr=o("TFCTRLForSequenceClassification"),QUr=o(" (CTRL model)"),WUr=l(),Dw=a("li"),kLe=a("strong"),UUr=o("deberta"),HUr=o(" \u2014 "),Cte=a("a"),JUr=o("TFDebertaForSequenceClassification"),YUr=o(" (DeBERTa model)"),KUr=l(),Gw=a("li"),SLe=a("strong"),ZUr=o("deberta-v2"),eHr=o(" \u2014 "),wte=a("a"),oHr=o("TFDebertaV2ForSequenceClassification"),rHr=o(" (DeBERTa-v2 model)"),tHr=l(),Ow=a("li"),RLe=a("strong"),aHr=o("distilbert"),nHr=o(" \u2014 "),Ate=a("a"),sHr=o("TFDistilBertForSequenceClassification"),lHr=o(" (DistilBERT model)"),iHr=l(),Vw=a("li"),PLe=a("strong"),dHr=o("electra"),mHr=o(" \u2014 "),Lte=a("a"),cHr=o("TFElectraForSequenceClassification"),fHr=o(" (ELECTRA model)"),gHr=l(),Xw=a("li"),BLe=a("strong"),hHr=o("flaubert"),uHr=o(" \u2014 "),yte=a("a"),pHr=o("TFFlaubertForSequenceClassification"),_Hr=o(" (FlauBERT model)"),bHr=l(),zw=a("li"),ILe=a("strong"),vHr=o("funnel"),FHr=o(" \u2014 "),xte=a("a"),THr=o("TFFunnelForSequenceClassification"),MHr=o(" (Funnel Transformer model)"),EHr=l(),Qw=a("li"),NLe=a("strong"),CHr=o("gpt2"),wHr=o(" \u2014 "),$te=a("a"),AHr=o("TFGPT2ForSequenceClassification"),LHr=o(" (OpenAI GPT-2 model)"),yHr=l(),Ww=a("li"),qLe=a("strong"),xHr=o("gptj"),$Hr=o(" \u2014 "),kte=a("a"),kHr=o("TFGPTJForSequenceClassification"),SHr=o(" (GPT-J model)"),RHr=l(),Uw=a("li"),jLe=a("strong"),PHr=o("layoutlm"),BHr=o(" \u2014 "),Ste=a("a"),IHr=o("TFLayoutLMForSequenceClassification"),NHr=o(" (LayoutLM model)"),qHr=l(),Hw=a("li"),DLe=a("strong"),jHr=o("layoutlmv3"),DHr=o(" \u2014 "),Rte=a("a"),GHr=o("TFLayoutLMv3ForSequenceClassification"),OHr=o(" (LayoutLMv3 model)"),VHr=l(),Jw=a("li"),GLe=a("strong"),XHr=o("longformer"),zHr=o(" \u2014 "),Pte=a("a"),QHr=o("TFLongformerForSequenceClassification"),WHr=o(" (Longformer model)"),UHr=l(),Yw=a("li"),OLe=a("strong"),HHr=o("mobilebert"),JHr=o(" \u2014 "),Bte=a("a"),YHr=o("TFMobileBertForSequenceClassification"),KHr=o(" (MobileBERT model)"),ZHr=l(),Kw=a("li"),VLe=a("strong"),eJr=o("mpnet"),oJr=o(" \u2014 "),Ite=a("a"),rJr=o("TFMPNetForSequenceClassification"),tJr=o(" (MPNet model)"),aJr=l(),Zw=a("li"),XLe=a("strong"),nJr=o("openai-gpt"),sJr=o(" \u2014 "),Nte=a("a"),lJr=o("TFOpenAIGPTForSequenceClassification"),iJr=o(" (OpenAI GPT model)"),dJr=l(),eA=a("li"),zLe=a("strong"),mJr=o("rembert"),cJr=o(" \u2014 "),qte=a("a"),fJr=o("TFRemBertForSequenceClassification"),gJr=o(" (RemBERT model)"),hJr=l(),oA=a("li"),QLe=a("strong"),uJr=o("roberta"),pJr=o(" \u2014 "),jte=a("a"),_Jr=o("TFRobertaForSequenceClassification"),bJr=o(" (RoBERTa model)"),vJr=l(),rA=a("li"),WLe=a("strong"),FJr=o("roformer"),TJr=o(" \u2014 "),Dte=a("a"),MJr=o("TFRoFormerForSequenceClassification"),EJr=o(" (RoFormer model)"),CJr=l(),tA=a("li"),ULe=a("strong"),wJr=o("tapas"),AJr=o(" \u2014 "),Gte=a("a"),LJr=o("TFTapasForSequenceClassification"),yJr=o(" (TAPAS model)"),xJr=l(),aA=a("li"),HLe=a("strong"),$Jr=o("transfo-xl"),kJr=o(" \u2014 "),Ote=a("a"),SJr=o("TFTransfoXLForSequenceClassification"),RJr=o(" (Transformer-XL model)"),PJr=l(),nA=a("li"),JLe=a("strong"),BJr=o("xlm"),IJr=o(" \u2014 "),Vte=a("a"),NJr=o("TFXLMForSequenceClassification"),qJr=o(" (XLM model)"),jJr=l(),sA=a("li"),YLe=a("strong"),DJr=o("xlm-roberta"),GJr=o(" \u2014 "),Xte=a("a"),OJr=o("TFXLMRobertaForSequenceClassification"),VJr=o(" (XLM-RoBERTa model)"),XJr=l(),lA=a("li"),KLe=a("strong"),zJr=o("xlnet"),QJr=o(" \u2014 "),zte=a("a"),WJr=o("TFXLNetForSequenceClassification"),UJr=o(" (XLNet model)"),HJr=l(),F(iA.$$.fragment),Ooo=l(),hc=a("h2"),dA=a("a"),ZLe=a("span"),F(OS.$$.fragment),JJr=l(),eye=a("span"),YJr=o("TFAutoModelForMultipleChoice"),Voo=l(),hr=a("div"),F(VS.$$.fragment),KJr=l(),uc=a("p"),ZJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Qte=a("a"),eYr=o("from_pretrained()"),oYr=o(" class method or the "),Wte=a("a"),rYr=o("from_config()"),tYr=o(` class
method.`),aYr=l(),XS=a("p"),nYr=o("This class cannot be instantiated directly using "),oye=a("code"),sYr=o("__init__()"),lYr=o(" (throws an error)."),iYr=l(),Kt=a("div"),F(zS.$$.fragment),dYr=l(),rye=a("p"),mYr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),cYr=l(),pc=a("p"),fYr=o(`Note:
Loading a model from its configuration file does `),tye=a("strong"),gYr=o("not"),hYr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ute=a("a"),uYr=o("from_pretrained()"),pYr=o(" to load the model weights."),_Yr=l(),F(mA.$$.fragment),bYr=l(),Xr=a("div"),F(QS.$$.fragment),vYr=l(),aye=a("p"),FYr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),TYr=l(),Rn=a("p"),MYr=o("The model class to instantiate is selected based on the "),nye=a("code"),EYr=o("model_type"),CYr=o(` property of the config object (either
passed as an argument or loaded from `),sye=a("code"),wYr=o("pretrained_model_name_or_path"),AYr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lye=a("code"),LYr=o("pretrained_model_name_or_path"),yYr=o(":"),xYr=l(),ve=a("ul"),cA=a("li"),iye=a("strong"),$Yr=o("albert"),kYr=o(" \u2014 "),Hte=a("a"),SYr=o("TFAlbertForMultipleChoice"),RYr=o(" (ALBERT model)"),PYr=l(),fA=a("li"),dye=a("strong"),BYr=o("bert"),IYr=o(" \u2014 "),Jte=a("a"),NYr=o("TFBertForMultipleChoice"),qYr=o(" (BERT model)"),jYr=l(),gA=a("li"),mye=a("strong"),DYr=o("camembert"),GYr=o(" \u2014 "),Yte=a("a"),OYr=o("TFCamembertForMultipleChoice"),VYr=o(" (CamemBERT model)"),XYr=l(),hA=a("li"),cye=a("strong"),zYr=o("convbert"),QYr=o(" \u2014 "),Kte=a("a"),WYr=o("TFConvBertForMultipleChoice"),UYr=o(" (ConvBERT model)"),HYr=l(),uA=a("li"),fye=a("strong"),JYr=o("distilbert"),YYr=o(" \u2014 "),Zte=a("a"),KYr=o("TFDistilBertForMultipleChoice"),ZYr=o(" (DistilBERT model)"),eKr=l(),pA=a("li"),gye=a("strong"),oKr=o("electra"),rKr=o(" \u2014 "),eae=a("a"),tKr=o("TFElectraForMultipleChoice"),aKr=o(" (ELECTRA model)"),nKr=l(),_A=a("li"),hye=a("strong"),sKr=o("flaubert"),lKr=o(" \u2014 "),oae=a("a"),iKr=o("TFFlaubertForMultipleChoice"),dKr=o(" (FlauBERT model)"),mKr=l(),bA=a("li"),uye=a("strong"),cKr=o("funnel"),fKr=o(" \u2014 "),rae=a("a"),gKr=o("TFFunnelForMultipleChoice"),hKr=o(" (Funnel Transformer model)"),uKr=l(),vA=a("li"),pye=a("strong"),pKr=o("longformer"),_Kr=o(" \u2014 "),tae=a("a"),bKr=o("TFLongformerForMultipleChoice"),vKr=o(" (Longformer model)"),FKr=l(),FA=a("li"),_ye=a("strong"),TKr=o("mobilebert"),MKr=o(" \u2014 "),aae=a("a"),EKr=o("TFMobileBertForMultipleChoice"),CKr=o(" (MobileBERT model)"),wKr=l(),TA=a("li"),bye=a("strong"),AKr=o("mpnet"),LKr=o(" \u2014 "),nae=a("a"),yKr=o("TFMPNetForMultipleChoice"),xKr=o(" (MPNet model)"),$Kr=l(),MA=a("li"),vye=a("strong"),kKr=o("rembert"),SKr=o(" \u2014 "),sae=a("a"),RKr=o("TFRemBertForMultipleChoice"),PKr=o(" (RemBERT model)"),BKr=l(),EA=a("li"),Fye=a("strong"),IKr=o("roberta"),NKr=o(" \u2014 "),lae=a("a"),qKr=o("TFRobertaForMultipleChoice"),jKr=o(" (RoBERTa model)"),DKr=l(),CA=a("li"),Tye=a("strong"),GKr=o("roformer"),OKr=o(" \u2014 "),iae=a("a"),VKr=o("TFRoFormerForMultipleChoice"),XKr=o(" (RoFormer model)"),zKr=l(),wA=a("li"),Mye=a("strong"),QKr=o("xlm"),WKr=o(" \u2014 "),dae=a("a"),UKr=o("TFXLMForMultipleChoice"),HKr=o(" (XLM model)"),JKr=l(),AA=a("li"),Eye=a("strong"),YKr=o("xlm-roberta"),KKr=o(" \u2014 "),mae=a("a"),ZKr=o("TFXLMRobertaForMultipleChoice"),eZr=o(" (XLM-RoBERTa model)"),oZr=l(),LA=a("li"),Cye=a("strong"),rZr=o("xlnet"),tZr=o(" \u2014 "),cae=a("a"),aZr=o("TFXLNetForMultipleChoice"),nZr=o(" (XLNet model)"),sZr=l(),F(yA.$$.fragment),Xoo=l(),_c=a("h2"),xA=a("a"),wye=a("span"),F(WS.$$.fragment),lZr=l(),Aye=a("span"),iZr=o("TFAutoModelForNextSentencePrediction"),zoo=l(),ur=a("div"),F(US.$$.fragment),dZr=l(),bc=a("p"),mZr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),fae=a("a"),cZr=o("from_pretrained()"),fZr=o(" class method or the "),gae=a("a"),gZr=o("from_config()"),hZr=o(` class
method.`),uZr=l(),HS=a("p"),pZr=o("This class cannot be instantiated directly using "),Lye=a("code"),_Zr=o("__init__()"),bZr=o(" (throws an error)."),vZr=l(),Zt=a("div"),F(JS.$$.fragment),FZr=l(),yye=a("p"),TZr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),MZr=l(),vc=a("p"),EZr=o(`Note:
Loading a model from its configuration file does `),xye=a("strong"),CZr=o("not"),wZr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hae=a("a"),AZr=o("from_pretrained()"),LZr=o(" to load the model weights."),yZr=l(),F($A.$$.fragment),xZr=l(),zr=a("div"),F(YS.$$.fragment),$Zr=l(),$ye=a("p"),kZr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),SZr=l(),Pn=a("p"),RZr=o("The model class to instantiate is selected based on the "),kye=a("code"),PZr=o("model_type"),BZr=o(` property of the config object (either
passed as an argument or loaded from `),Sye=a("code"),IZr=o("pretrained_model_name_or_path"),NZr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rye=a("code"),qZr=o("pretrained_model_name_or_path"),jZr=o(":"),DZr=l(),KS=a("ul"),kA=a("li"),Pye=a("strong"),GZr=o("bert"),OZr=o(" \u2014 "),uae=a("a"),VZr=o("TFBertForNextSentencePrediction"),XZr=o(" (BERT model)"),zZr=l(),SA=a("li"),Bye=a("strong"),QZr=o("mobilebert"),WZr=o(" \u2014 "),pae=a("a"),UZr=o("TFMobileBertForNextSentencePrediction"),HZr=o(" (MobileBERT model)"),JZr=l(),F(RA.$$.fragment),Qoo=l(),Fc=a("h2"),PA=a("a"),Iye=a("span"),F(ZS.$$.fragment),YZr=l(),Nye=a("span"),KZr=o("TFAutoModelForTableQuestionAnswering"),Woo=l(),pr=a("div"),F(eR.$$.fragment),ZZr=l(),Tc=a("p"),eet=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),_ae=a("a"),oet=o("from_pretrained()"),ret=o(" class method or the "),bae=a("a"),tet=o("from_config()"),aet=o(` class
method.`),net=l(),oR=a("p"),set=o("This class cannot be instantiated directly using "),qye=a("code"),iet=o("__init__()"),det=o(" (throws an error)."),met=l(),ea=a("div"),F(rR.$$.fragment),cet=l(),jye=a("p"),fet=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),get=l(),Mc=a("p"),het=o(`Note:
Loading a model from its configuration file does `),Dye=a("strong"),uet=o("not"),pet=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vae=a("a"),_et=o("from_pretrained()"),bet=o(" to load the model weights."),vet=l(),F(BA.$$.fragment),Fet=l(),Qr=a("div"),F(tR.$$.fragment),Tet=l(),Gye=a("p"),Met=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Eet=l(),Bn=a("p"),Cet=o("The model class to instantiate is selected based on the "),Oye=a("code"),wet=o("model_type"),Aet=o(` property of the config object (either
passed as an argument or loaded from `),Vye=a("code"),Let=o("pretrained_model_name_or_path"),yet=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xye=a("code"),xet=o("pretrained_model_name_or_path"),$et=o(":"),ket=l(),zye=a("ul"),IA=a("li"),Qye=a("strong"),Set=o("tapas"),Ret=o(" \u2014 "),Fae=a("a"),Pet=o("TFTapasForQuestionAnswering"),Bet=o(" (TAPAS model)"),Iet=l(),F(NA.$$.fragment),Uoo=l(),Ec=a("h2"),qA=a("a"),Wye=a("span"),F(aR.$$.fragment),Net=l(),Uye=a("span"),qet=o("TFAutoModelForDocumentQuestionAnswering"),Hoo=l(),_r=a("div"),F(nR.$$.fragment),jet=l(),Cc=a("p"),Det=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Tae=a("a"),Get=o("from_pretrained()"),Oet=o(" class method or the "),Mae=a("a"),Vet=o("from_config()"),Xet=o(` class
method.`),zet=l(),sR=a("p"),Qet=o("This class cannot be instantiated directly using "),Hye=a("code"),Wet=o("__init__()"),Uet=o(" (throws an error)."),Het=l(),oa=a("div"),F(lR.$$.fragment),Jet=l(),Jye=a("p"),Yet=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Ket=l(),wc=a("p"),Zet=o(`Note:
Loading a model from its configuration file does `),Yye=a("strong"),eot=o("not"),oot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Eae=a("a"),rot=o("from_pretrained()"),tot=o(" to load the model weights."),aot=l(),F(jA.$$.fragment),not=l(),Wr=a("div"),F(iR.$$.fragment),sot=l(),Kye=a("p"),lot=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),iot=l(),In=a("p"),dot=o("The model class to instantiate is selected based on the "),Zye=a("code"),mot=o("model_type"),cot=o(` property of the config object (either
passed as an argument or loaded from `),e8e=a("code"),fot=o("pretrained_model_name_or_path"),got=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o8e=a("code"),hot=o("pretrained_model_name_or_path"),uot=o(":"),pot=l(),r8e=a("ul"),DA=a("li"),t8e=a("strong"),_ot=o("layoutlm"),bot=o(" \u2014 "),Cae=a("a"),vot=o("TFLayoutLMForQuestionAnswering"),Fot=o(" (LayoutLM model)"),Tot=l(),F(GA.$$.fragment),Joo=l(),Ac=a("h2"),OA=a("a"),a8e=a("span"),F(dR.$$.fragment),Mot=l(),n8e=a("span"),Eot=o("TFAutoModelForTokenClassification"),Yoo=l(),br=a("div"),F(mR.$$.fragment),Cot=l(),Lc=a("p"),wot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),wae=a("a"),Aot=o("from_pretrained()"),Lot=o(" class method or the "),Aae=a("a"),yot=o("from_config()"),xot=o(` class
method.`),$ot=l(),cR=a("p"),kot=o("This class cannot be instantiated directly using "),s8e=a("code"),Sot=o("__init__()"),Rot=o(" (throws an error)."),Pot=l(),ra=a("div"),F(fR.$$.fragment),Bot=l(),l8e=a("p"),Iot=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Not=l(),yc=a("p"),qot=o(`Note:
Loading a model from its configuration file does `),i8e=a("strong"),jot=o("not"),Dot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lae=a("a"),Got=o("from_pretrained()"),Oot=o(" to load the model weights."),Vot=l(),F(VA.$$.fragment),Xot=l(),Ur=a("div"),F(gR.$$.fragment),zot=l(),d8e=a("p"),Qot=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Wot=l(),Nn=a("p"),Uot=o("The model class to instantiate is selected based on the "),m8e=a("code"),Hot=o("model_type"),Jot=o(` property of the config object (either
passed as an argument or loaded from `),c8e=a("code"),Yot=o("pretrained_model_name_or_path"),Kot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f8e=a("code"),Zot=o("pretrained_model_name_or_path"),ert=o(":"),ort=l(),me=a("ul"),XA=a("li"),g8e=a("strong"),rrt=o("albert"),trt=o(" \u2014 "),yae=a("a"),art=o("TFAlbertForTokenClassification"),nrt=o(" (ALBERT model)"),srt=l(),zA=a("li"),h8e=a("strong"),lrt=o("bert"),irt=o(" \u2014 "),xae=a("a"),drt=o("TFBertForTokenClassification"),mrt=o(" (BERT model)"),crt=l(),QA=a("li"),u8e=a("strong"),frt=o("camembert"),grt=o(" \u2014 "),$ae=a("a"),hrt=o("TFCamembertForTokenClassification"),urt=o(" (CamemBERT model)"),prt=l(),WA=a("li"),p8e=a("strong"),_rt=o("convbert"),brt=o(" \u2014 "),kae=a("a"),vrt=o("TFConvBertForTokenClassification"),Frt=o(" (ConvBERT model)"),Trt=l(),UA=a("li"),_8e=a("strong"),Mrt=o("deberta"),Ert=o(" \u2014 "),Sae=a("a"),Crt=o("TFDebertaForTokenClassification"),wrt=o(" (DeBERTa model)"),Art=l(),HA=a("li"),b8e=a("strong"),Lrt=o("deberta-v2"),yrt=o(" \u2014 "),Rae=a("a"),xrt=o("TFDebertaV2ForTokenClassification"),$rt=o(" (DeBERTa-v2 model)"),krt=l(),JA=a("li"),v8e=a("strong"),Srt=o("distilbert"),Rrt=o(" \u2014 "),Pae=a("a"),Prt=o("TFDistilBertForTokenClassification"),Brt=o(" (DistilBERT model)"),Irt=l(),YA=a("li"),F8e=a("strong"),Nrt=o("electra"),qrt=o(" \u2014 "),Bae=a("a"),jrt=o("TFElectraForTokenClassification"),Drt=o(" (ELECTRA model)"),Grt=l(),KA=a("li"),T8e=a("strong"),Ort=o("flaubert"),Vrt=o(" \u2014 "),Iae=a("a"),Xrt=o("TFFlaubertForTokenClassification"),zrt=o(" (FlauBERT model)"),Qrt=l(),ZA=a("li"),M8e=a("strong"),Wrt=o("funnel"),Urt=o(" \u2014 "),Nae=a("a"),Hrt=o("TFFunnelForTokenClassification"),Jrt=o(" (Funnel Transformer model)"),Yrt=l(),e6=a("li"),E8e=a("strong"),Krt=o("layoutlm"),Zrt=o(" \u2014 "),qae=a("a"),ett=o("TFLayoutLMForTokenClassification"),ott=o(" (LayoutLM model)"),rtt=l(),o6=a("li"),C8e=a("strong"),ttt=o("layoutlmv3"),att=o(" \u2014 "),jae=a("a"),ntt=o("TFLayoutLMv3ForTokenClassification"),stt=o(" (LayoutLMv3 model)"),ltt=l(),r6=a("li"),w8e=a("strong"),itt=o("longformer"),dtt=o(" \u2014 "),Dae=a("a"),mtt=o("TFLongformerForTokenClassification"),ctt=o(" (Longformer model)"),ftt=l(),t6=a("li"),A8e=a("strong"),gtt=o("mobilebert"),htt=o(" \u2014 "),Gae=a("a"),utt=o("TFMobileBertForTokenClassification"),ptt=o(" (MobileBERT model)"),_tt=l(),a6=a("li"),L8e=a("strong"),btt=o("mpnet"),vtt=o(" \u2014 "),Oae=a("a"),Ftt=o("TFMPNetForTokenClassification"),Ttt=o(" (MPNet model)"),Mtt=l(),n6=a("li"),y8e=a("strong"),Ett=o("rembert"),Ctt=o(" \u2014 "),Vae=a("a"),wtt=o("TFRemBertForTokenClassification"),Att=o(" (RemBERT model)"),Ltt=l(),s6=a("li"),x8e=a("strong"),ytt=o("roberta"),xtt=o(" \u2014 "),Xae=a("a"),$tt=o("TFRobertaForTokenClassification"),ktt=o(" (RoBERTa model)"),Stt=l(),l6=a("li"),$8e=a("strong"),Rtt=o("roformer"),Ptt=o(" \u2014 "),zae=a("a"),Btt=o("TFRoFormerForTokenClassification"),Itt=o(" (RoFormer model)"),Ntt=l(),i6=a("li"),k8e=a("strong"),qtt=o("xlm"),jtt=o(" \u2014 "),Qae=a("a"),Dtt=o("TFXLMForTokenClassification"),Gtt=o(" (XLM model)"),Ott=l(),d6=a("li"),S8e=a("strong"),Vtt=o("xlm-roberta"),Xtt=o(" \u2014 "),Wae=a("a"),ztt=o("TFXLMRobertaForTokenClassification"),Qtt=o(" (XLM-RoBERTa model)"),Wtt=l(),m6=a("li"),R8e=a("strong"),Utt=o("xlnet"),Htt=o(" \u2014 "),Uae=a("a"),Jtt=o("TFXLNetForTokenClassification"),Ytt=o(" (XLNet model)"),Ktt=l(),F(c6.$$.fragment),Koo=l(),xc=a("h2"),f6=a("a"),P8e=a("span"),F(hR.$$.fragment),Ztt=l(),B8e=a("span"),eat=o("TFAutoModelForQuestionAnswering"),Zoo=l(),vr=a("div"),F(uR.$$.fragment),oat=l(),$c=a("p"),rat=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Hae=a("a"),tat=o("from_pretrained()"),aat=o(" class method or the "),Jae=a("a"),nat=o("from_config()"),sat=o(` class
method.`),lat=l(),pR=a("p"),iat=o("This class cannot be instantiated directly using "),I8e=a("code"),dat=o("__init__()"),mat=o(" (throws an error)."),cat=l(),ta=a("div"),F(_R.$$.fragment),fat=l(),N8e=a("p"),gat=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),hat=l(),kc=a("p"),uat=o(`Note:
Loading a model from its configuration file does `),q8e=a("strong"),pat=o("not"),_at=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yae=a("a"),bat=o("from_pretrained()"),vat=o(" to load the model weights."),Fat=l(),F(g6.$$.fragment),Tat=l(),Hr=a("div"),F(bR.$$.fragment),Mat=l(),j8e=a("p"),Eat=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Cat=l(),qn=a("p"),wat=o("The model class to instantiate is selected based on the "),D8e=a("code"),Aat=o("model_type"),Lat=o(` property of the config object (either
passed as an argument or loaded from `),G8e=a("code"),yat=o("pretrained_model_name_or_path"),xat=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O8e=a("code"),$at=o("pretrained_model_name_or_path"),kat=o(":"),Sat=l(),ce=a("ul"),h6=a("li"),V8e=a("strong"),Rat=o("albert"),Pat=o(" \u2014 "),Kae=a("a"),Bat=o("TFAlbertForQuestionAnswering"),Iat=o(" (ALBERT model)"),Nat=l(),u6=a("li"),X8e=a("strong"),qat=o("bert"),jat=o(" \u2014 "),Zae=a("a"),Dat=o("TFBertForQuestionAnswering"),Gat=o(" (BERT model)"),Oat=l(),p6=a("li"),z8e=a("strong"),Vat=o("camembert"),Xat=o(" \u2014 "),ene=a("a"),zat=o("TFCamembertForQuestionAnswering"),Qat=o(" (CamemBERT model)"),Wat=l(),_6=a("li"),Q8e=a("strong"),Uat=o("convbert"),Hat=o(" \u2014 "),one=a("a"),Jat=o("TFConvBertForQuestionAnswering"),Yat=o(" (ConvBERT model)"),Kat=l(),b6=a("li"),W8e=a("strong"),Zat=o("deberta"),ent=o(" \u2014 "),rne=a("a"),ont=o("TFDebertaForQuestionAnswering"),rnt=o(" (DeBERTa model)"),tnt=l(),v6=a("li"),U8e=a("strong"),ant=o("deberta-v2"),nnt=o(" \u2014 "),tne=a("a"),snt=o("TFDebertaV2ForQuestionAnswering"),lnt=o(" (DeBERTa-v2 model)"),int=l(),F6=a("li"),H8e=a("strong"),dnt=o("distilbert"),mnt=o(" \u2014 "),ane=a("a"),cnt=o("TFDistilBertForQuestionAnswering"),fnt=o(" (DistilBERT model)"),gnt=l(),T6=a("li"),J8e=a("strong"),hnt=o("electra"),unt=o(" \u2014 "),nne=a("a"),pnt=o("TFElectraForQuestionAnswering"),_nt=o(" (ELECTRA model)"),bnt=l(),M6=a("li"),Y8e=a("strong"),vnt=o("flaubert"),Fnt=o(" \u2014 "),sne=a("a"),Tnt=o("TFFlaubertForQuestionAnsweringSimple"),Mnt=o(" (FlauBERT model)"),Ent=l(),E6=a("li"),K8e=a("strong"),Cnt=o("funnel"),wnt=o(" \u2014 "),lne=a("a"),Ant=o("TFFunnelForQuestionAnswering"),Lnt=o(" (Funnel Transformer model)"),ynt=l(),C6=a("li"),Z8e=a("strong"),xnt=o("gptj"),$nt=o(" \u2014 "),ine=a("a"),knt=o("TFGPTJForQuestionAnswering"),Snt=o(" (GPT-J model)"),Rnt=l(),w6=a("li"),e9e=a("strong"),Pnt=o("layoutlmv3"),Bnt=o(" \u2014 "),dne=a("a"),Int=o("TFLayoutLMv3ForQuestionAnswering"),Nnt=o(" (LayoutLMv3 model)"),qnt=l(),A6=a("li"),o9e=a("strong"),jnt=o("longformer"),Dnt=o(" \u2014 "),mne=a("a"),Gnt=o("TFLongformerForQuestionAnswering"),Ont=o(" (Longformer model)"),Vnt=l(),L6=a("li"),r9e=a("strong"),Xnt=o("mobilebert"),znt=o(" \u2014 "),cne=a("a"),Qnt=o("TFMobileBertForQuestionAnswering"),Wnt=o(" (MobileBERT model)"),Unt=l(),y6=a("li"),t9e=a("strong"),Hnt=o("mpnet"),Jnt=o(" \u2014 "),fne=a("a"),Ynt=o("TFMPNetForQuestionAnswering"),Knt=o(" (MPNet model)"),Znt=l(),x6=a("li"),a9e=a("strong"),est=o("rembert"),ost=o(" \u2014 "),gne=a("a"),rst=o("TFRemBertForQuestionAnswering"),tst=o(" (RemBERT model)"),ast=l(),$6=a("li"),n9e=a("strong"),nst=o("roberta"),sst=o(" \u2014 "),hne=a("a"),lst=o("TFRobertaForQuestionAnswering"),ist=o(" (RoBERTa model)"),dst=l(),k6=a("li"),s9e=a("strong"),mst=o("roformer"),cst=o(" \u2014 "),une=a("a"),fst=o("TFRoFormerForQuestionAnswering"),gst=o(" (RoFormer model)"),hst=l(),S6=a("li"),l9e=a("strong"),ust=o("xlm"),pst=o(" \u2014 "),pne=a("a"),_st=o("TFXLMForQuestionAnsweringSimple"),bst=o(" (XLM model)"),vst=l(),R6=a("li"),i9e=a("strong"),Fst=o("xlm-roberta"),Tst=o(" \u2014 "),_ne=a("a"),Mst=o("TFXLMRobertaForQuestionAnswering"),Est=o(" (XLM-RoBERTa model)"),Cst=l(),P6=a("li"),d9e=a("strong"),wst=o("xlnet"),Ast=o(" \u2014 "),bne=a("a"),Lst=o("TFXLNetForQuestionAnsweringSimple"),yst=o(" (XLNet model)"),xst=l(),F(B6.$$.fragment),ero=l(),Sc=a("h2"),I6=a("a"),m9e=a("span"),F(vR.$$.fragment),$st=l(),c9e=a("span"),kst=o("TFAutoModelForVision2Seq"),oro=l(),Fr=a("div"),F(FR.$$.fragment),Sst=l(),Rc=a("p"),Rst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),vne=a("a"),Pst=o("from_pretrained()"),Bst=o(" class method or the "),Fne=a("a"),Ist=o("from_config()"),Nst=o(` class
method.`),qst=l(),TR=a("p"),jst=o("This class cannot be instantiated directly using "),f9e=a("code"),Dst=o("__init__()"),Gst=o(" (throws an error)."),Ost=l(),aa=a("div"),F(MR.$$.fragment),Vst=l(),g9e=a("p"),Xst=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),zst=l(),Pc=a("p"),Qst=o(`Note:
Loading a model from its configuration file does `),h9e=a("strong"),Wst=o("not"),Ust=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tne=a("a"),Hst=o("from_pretrained()"),Jst=o(" to load the model weights."),Yst=l(),F(N6.$$.fragment),Kst=l(),Jr=a("div"),F(ER.$$.fragment),Zst=l(),u9e=a("p"),elt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),olt=l(),jn=a("p"),rlt=o("The model class to instantiate is selected based on the "),p9e=a("code"),tlt=o("model_type"),alt=o(` property of the config object (either
passed as an argument or loaded from `),_9e=a("code"),nlt=o("pretrained_model_name_or_path"),slt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b9e=a("code"),llt=o("pretrained_model_name_or_path"),ilt=o(":"),dlt=l(),v9e=a("ul"),q6=a("li"),F9e=a("strong"),mlt=o("vision-encoder-decoder"),clt=o(" \u2014 "),Mne=a("a"),flt=o("TFVisionEncoderDecoderModel"),glt=o(" (Vision Encoder decoder model)"),hlt=l(),F(j6.$$.fragment),rro=l(),Bc=a("h2"),D6=a("a"),T9e=a("span"),F(CR.$$.fragment),ult=l(),M9e=a("span"),plt=o("TFAutoModelForSpeechSeq2Seq"),tro=l(),Tr=a("div"),F(wR.$$.fragment),_lt=l(),Ic=a("p"),blt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Ene=a("a"),vlt=o("from_pretrained()"),Flt=o(" class method or the "),Cne=a("a"),Tlt=o("from_config()"),Mlt=o(` class
method.`),Elt=l(),AR=a("p"),Clt=o("This class cannot be instantiated directly using "),E9e=a("code"),wlt=o("__init__()"),Alt=o(" (throws an error)."),Llt=l(),na=a("div"),F(LR.$$.fragment),ylt=l(),C9e=a("p"),xlt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),$lt=l(),Nc=a("p"),klt=o(`Note:
Loading a model from its configuration file does `),w9e=a("strong"),Slt=o("not"),Rlt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wne=a("a"),Plt=o("from_pretrained()"),Blt=o(" to load the model weights."),Ilt=l(),F(G6.$$.fragment),Nlt=l(),Yr=a("div"),F(yR.$$.fragment),qlt=l(),A9e=a("p"),jlt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Dlt=l(),Dn=a("p"),Glt=o("The model class to instantiate is selected based on the "),L9e=a("code"),Olt=o("model_type"),Vlt=o(` property of the config object (either
passed as an argument or loaded from `),y9e=a("code"),Xlt=o("pretrained_model_name_or_path"),zlt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x9e=a("code"),Qlt=o("pretrained_model_name_or_path"),Wlt=o(":"),Ult=l(),$9e=a("ul"),O6=a("li"),k9e=a("strong"),Hlt=o("speech_to_text"),Jlt=o(" \u2014 "),Ane=a("a"),Ylt=o("TFSpeech2TextForConditionalGeneration"),Klt=o(" (Speech2Text model)"),Zlt=l(),F(V6.$$.fragment),aro=l(),qc=a("h2"),X6=a("a"),S9e=a("span"),F(xR.$$.fragment),eit=l(),R9e=a("span"),oit=o("FlaxAutoModel"),nro=l(),Mr=a("div"),F($R.$$.fragment),rit=l(),jc=a("p"),tit=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Lne=a("a"),ait=o("from_pretrained()"),nit=o(" class method or the "),yne=a("a"),sit=o("from_config()"),lit=o(` class
method.`),iit=l(),kR=a("p"),dit=o("This class cannot be instantiated directly using "),P9e=a("code"),mit=o("__init__()"),cit=o(" (throws an error)."),fit=l(),sa=a("div"),F(SR.$$.fragment),git=l(),B9e=a("p"),hit=o("Instantiates one of the base model classes of the library from a configuration."),uit=l(),Dc=a("p"),pit=o(`Note:
Loading a model from its configuration file does `),I9e=a("strong"),_it=o("not"),bit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xne=a("a"),vit=o("from_pretrained()"),Fit=o(" to load the model weights."),Tit=l(),F(z6.$$.fragment),Mit=l(),Kr=a("div"),F(RR.$$.fragment),Eit=l(),N9e=a("p"),Cit=o("Instantiate one of the base model classes of the library from a pretrained model."),wit=l(),Gn=a("p"),Ait=o("The model class to instantiate is selected based on the "),q9e=a("code"),Lit=o("model_type"),yit=o(` property of the config object (either
passed as an argument or loaded from `),j9e=a("code"),xit=o("pretrained_model_name_or_path"),$it=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D9e=a("code"),kit=o("pretrained_model_name_or_path"),Sit=o(":"),Rit=l(),te=a("ul"),Q6=a("li"),G9e=a("strong"),Pit=o("albert"),Bit=o(" \u2014 "),$ne=a("a"),Iit=o("FlaxAlbertModel"),Nit=o(" (ALBERT model)"),qit=l(),W6=a("li"),O9e=a("strong"),jit=o("bart"),Dit=o(" \u2014 "),kne=a("a"),Git=o("FlaxBartModel"),Oit=o(" (BART model)"),Vit=l(),U6=a("li"),V9e=a("strong"),Xit=o("beit"),zit=o(" \u2014 "),Sne=a("a"),Qit=o("FlaxBeitModel"),Wit=o(" (BEiT model)"),Uit=l(),H6=a("li"),X9e=a("strong"),Hit=o("bert"),Jit=o(" \u2014 "),Rne=a("a"),Yit=o("FlaxBertModel"),Kit=o(" (BERT model)"),Zit=l(),J6=a("li"),z9e=a("strong"),edt=o("big_bird"),odt=o(" \u2014 "),Pne=a("a"),rdt=o("FlaxBigBirdModel"),tdt=o(" (BigBird model)"),adt=l(),Y6=a("li"),Q9e=a("strong"),ndt=o("blenderbot"),sdt=o(" \u2014 "),Bne=a("a"),ldt=o("FlaxBlenderbotModel"),idt=o(" (Blenderbot model)"),ddt=l(),K6=a("li"),W9e=a("strong"),mdt=o("blenderbot-small"),cdt=o(" \u2014 "),Ine=a("a"),fdt=o("FlaxBlenderbotSmallModel"),gdt=o(" (BlenderbotSmall model)"),hdt=l(),Z6=a("li"),U9e=a("strong"),udt=o("clip"),pdt=o(" \u2014 "),Nne=a("a"),_dt=o("FlaxCLIPModel"),bdt=o(" (CLIP model)"),vdt=l(),e7=a("li"),H9e=a("strong"),Fdt=o("distilbert"),Tdt=o(" \u2014 "),qne=a("a"),Mdt=o("FlaxDistilBertModel"),Edt=o(" (DistilBERT model)"),Cdt=l(),o7=a("li"),J9e=a("strong"),wdt=o("electra"),Adt=o(" \u2014 "),jne=a("a"),Ldt=o("FlaxElectraModel"),ydt=o(" (ELECTRA model)"),xdt=l(),r7=a("li"),Y9e=a("strong"),$dt=o("gpt2"),kdt=o(" \u2014 "),Dne=a("a"),Sdt=o("FlaxGPT2Model"),Rdt=o(" (OpenAI GPT-2 model)"),Pdt=l(),t7=a("li"),K9e=a("strong"),Bdt=o("gpt_neo"),Idt=o(" \u2014 "),Gne=a("a"),Ndt=o("FlaxGPTNeoModel"),qdt=o(" (GPT Neo model)"),jdt=l(),a7=a("li"),Z9e=a("strong"),Ddt=o("gptj"),Gdt=o(" \u2014 "),One=a("a"),Odt=o("FlaxGPTJModel"),Vdt=o(" (GPT-J model)"),Xdt=l(),n7=a("li"),exe=a("strong"),zdt=o("longt5"),Qdt=o(" \u2014 "),Vne=a("a"),Wdt=o("FlaxLongT5Model"),Udt=o(" (LongT5 model)"),Hdt=l(),s7=a("li"),oxe=a("strong"),Jdt=o("marian"),Ydt=o(" \u2014 "),Xne=a("a"),Kdt=o("FlaxMarianModel"),Zdt=o(" (Marian model)"),emt=l(),l7=a("li"),rxe=a("strong"),omt=o("mbart"),rmt=o(" \u2014 "),zne=a("a"),tmt=o("FlaxMBartModel"),amt=o(" (mBART model)"),nmt=l(),i7=a("li"),txe=a("strong"),smt=o("mt5"),lmt=o(" \u2014 "),Qne=a("a"),imt=o("FlaxMT5Model"),dmt=o(" (MT5 model)"),mmt=l(),d7=a("li"),axe=a("strong"),cmt=o("opt"),fmt=o(" \u2014 "),Wne=a("a"),gmt=o("FlaxOPTModel"),hmt=o(" (OPT model)"),umt=l(),m7=a("li"),nxe=a("strong"),pmt=o("pegasus"),_mt=o(" \u2014 "),Une=a("a"),bmt=o("FlaxPegasusModel"),vmt=o(" (Pegasus model)"),Fmt=l(),c7=a("li"),sxe=a("strong"),Tmt=o("roberta"),Mmt=o(" \u2014 "),Hne=a("a"),Emt=o("FlaxRobertaModel"),Cmt=o(" (RoBERTa model)"),wmt=l(),f7=a("li"),lxe=a("strong"),Amt=o("roformer"),Lmt=o(" \u2014 "),Jne=a("a"),ymt=o("FlaxRoFormerModel"),xmt=o(" (RoFormer model)"),$mt=l(),g7=a("li"),ixe=a("strong"),kmt=o("t5"),Smt=o(" \u2014 "),Yne=a("a"),Rmt=o("FlaxT5Model"),Pmt=o(" (T5 model)"),Bmt=l(),h7=a("li"),dxe=a("strong"),Imt=o("vision-text-dual-encoder"),Nmt=o(" \u2014 "),Kne=a("a"),qmt=o("FlaxVisionTextDualEncoderModel"),jmt=o(" (VisionTextDualEncoder model)"),Dmt=l(),u7=a("li"),mxe=a("strong"),Gmt=o("vit"),Omt=o(" \u2014 "),Zne=a("a"),Vmt=o("FlaxViTModel"),Xmt=o(" (ViT model)"),zmt=l(),p7=a("li"),cxe=a("strong"),Qmt=o("wav2vec2"),Wmt=o(" \u2014 "),ese=a("a"),Umt=o("FlaxWav2Vec2Model"),Hmt=o(" (Wav2Vec2 model)"),Jmt=l(),_7=a("li"),fxe=a("strong"),Ymt=o("xglm"),Kmt=o(" \u2014 "),ose=a("a"),Zmt=o("FlaxXGLMModel"),ect=o(" (XGLM model)"),oct=l(),b7=a("li"),gxe=a("strong"),rct=o("xlm-roberta"),tct=o(" \u2014 "),rse=a("a"),act=o("FlaxXLMRobertaModel"),nct=o(" (XLM-RoBERTa model)"),sct=l(),F(v7.$$.fragment),sro=l(),Gc=a("h2"),F7=a("a"),hxe=a("span"),F(PR.$$.fragment),lct=l(),uxe=a("span"),ict=o("FlaxAutoModelForCausalLM"),lro=l(),Er=a("div"),F(BR.$$.fragment),dct=l(),Oc=a("p"),mct=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),tse=a("a"),cct=o("from_pretrained()"),fct=o(" class method or the "),ase=a("a"),gct=o("from_config()"),hct=o(` class
method.`),uct=l(),IR=a("p"),pct=o("This class cannot be instantiated directly using "),pxe=a("code"),_ct=o("__init__()"),bct=o(" (throws an error)."),vct=l(),la=a("div"),F(NR.$$.fragment),Fct=l(),_xe=a("p"),Tct=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Mct=l(),Vc=a("p"),Ect=o(`Note:
Loading a model from its configuration file does `),bxe=a("strong"),Cct=o("not"),wct=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nse=a("a"),Act=o("from_pretrained()"),Lct=o(" to load the model weights."),yct=l(),F(T7.$$.fragment),xct=l(),Zr=a("div"),F(qR.$$.fragment),$ct=l(),vxe=a("p"),kct=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Sct=l(),On=a("p"),Rct=o("The model class to instantiate is selected based on the "),Fxe=a("code"),Pct=o("model_type"),Bct=o(` property of the config object (either
passed as an argument or loaded from `),Txe=a("code"),Ict=o("pretrained_model_name_or_path"),Nct=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mxe=a("code"),qct=o("pretrained_model_name_or_path"),jct=o(":"),Dct=l(),xe=a("ul"),M7=a("li"),Exe=a("strong"),Gct=o("bart"),Oct=o(" \u2014 "),sse=a("a"),Vct=o("FlaxBartForCausalLM"),Xct=o(" (BART model)"),zct=l(),E7=a("li"),Cxe=a("strong"),Qct=o("bert"),Wct=o(" \u2014 "),lse=a("a"),Uct=o("FlaxBertForCausalLM"),Hct=o(" (BERT model)"),Jct=l(),C7=a("li"),wxe=a("strong"),Yct=o("big_bird"),Kct=o(" \u2014 "),ise=a("a"),Zct=o("FlaxBigBirdForCausalLM"),eft=o(" (BigBird model)"),oft=l(),w7=a("li"),Axe=a("strong"),rft=o("electra"),tft=o(" \u2014 "),dse=a("a"),aft=o("FlaxElectraForCausalLM"),nft=o(" (ELECTRA model)"),sft=l(),A7=a("li"),Lxe=a("strong"),lft=o("gpt2"),ift=o(" \u2014 "),mse=a("a"),dft=o("FlaxGPT2LMHeadModel"),mft=o(" (OpenAI GPT-2 model)"),cft=l(),L7=a("li"),yxe=a("strong"),fft=o("gpt_neo"),gft=o(" \u2014 "),cse=a("a"),hft=o("FlaxGPTNeoForCausalLM"),uft=o(" (GPT Neo model)"),pft=l(),y7=a("li"),xxe=a("strong"),_ft=o("gptj"),bft=o(" \u2014 "),fse=a("a"),vft=o("FlaxGPTJForCausalLM"),Fft=o(" (GPT-J model)"),Tft=l(),x7=a("li"),$xe=a("strong"),Mft=o("opt"),Eft=o(" \u2014 "),gse=a("a"),Cft=o("FlaxOPTForCausalLM"),wft=o(" (OPT model)"),Aft=l(),$7=a("li"),kxe=a("strong"),Lft=o("roberta"),yft=o(" \u2014 "),hse=a("a"),xft=o("FlaxRobertaForCausalLM"),$ft=o(" (RoBERTa model)"),kft=l(),k7=a("li"),Sxe=a("strong"),Sft=o("xglm"),Rft=o(" \u2014 "),use=a("a"),Pft=o("FlaxXGLMForCausalLM"),Bft=o(" (XGLM model)"),Ift=l(),F(S7.$$.fragment),iro=l(),Xc=a("h2"),R7=a("a"),Rxe=a("span"),F(jR.$$.fragment),Nft=l(),Pxe=a("span"),qft=o("FlaxAutoModelForPreTraining"),dro=l(),Cr=a("div"),F(DR.$$.fragment),jft=l(),zc=a("p"),Dft=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),pse=a("a"),Gft=o("from_pretrained()"),Oft=o(" class method or the "),_se=a("a"),Vft=o("from_config()"),Xft=o(` class
method.`),zft=l(),GR=a("p"),Qft=o("This class cannot be instantiated directly using "),Bxe=a("code"),Wft=o("__init__()"),Uft=o(" (throws an error)."),Hft=l(),ia=a("div"),F(OR.$$.fragment),Jft=l(),Ixe=a("p"),Yft=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Kft=l(),Qc=a("p"),Zft=o(`Note:
Loading a model from its configuration file does `),Nxe=a("strong"),egt=o("not"),ogt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bse=a("a"),rgt=o("from_pretrained()"),tgt=o(" to load the model weights."),agt=l(),F(P7.$$.fragment),ngt=l(),et=a("div"),F(VR.$$.fragment),sgt=l(),qxe=a("p"),lgt=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),igt=l(),Vn=a("p"),dgt=o("The model class to instantiate is selected based on the "),jxe=a("code"),mgt=o("model_type"),cgt=o(` property of the config object (either
passed as an argument or loaded from `),Dxe=a("code"),fgt=o("pretrained_model_name_or_path"),ggt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gxe=a("code"),hgt=o("pretrained_model_name_or_path"),ugt=o(":"),pgt=l(),Ee=a("ul"),B7=a("li"),Oxe=a("strong"),_gt=o("albert"),bgt=o(" \u2014 "),vse=a("a"),vgt=o("FlaxAlbertForPreTraining"),Fgt=o(" (ALBERT model)"),Tgt=l(),I7=a("li"),Vxe=a("strong"),Mgt=o("bart"),Egt=o(" \u2014 "),Fse=a("a"),Cgt=o("FlaxBartForConditionalGeneration"),wgt=o(" (BART model)"),Agt=l(),N7=a("li"),Xxe=a("strong"),Lgt=o("bert"),ygt=o(" \u2014 "),Tse=a("a"),xgt=o("FlaxBertForPreTraining"),$gt=o(" (BERT model)"),kgt=l(),q7=a("li"),zxe=a("strong"),Sgt=o("big_bird"),Rgt=o(" \u2014 "),Mse=a("a"),Pgt=o("FlaxBigBirdForPreTraining"),Bgt=o(" (BigBird model)"),Igt=l(),j7=a("li"),Qxe=a("strong"),Ngt=o("electra"),qgt=o(" \u2014 "),Ese=a("a"),jgt=o("FlaxElectraForPreTraining"),Dgt=o(" (ELECTRA model)"),Ggt=l(),D7=a("li"),Wxe=a("strong"),Ogt=o("longt5"),Vgt=o(" \u2014 "),Cse=a("a"),Xgt=o("FlaxLongT5ForConditionalGeneration"),zgt=o(" (LongT5 model)"),Qgt=l(),G7=a("li"),Uxe=a("strong"),Wgt=o("mbart"),Ugt=o(" \u2014 "),wse=a("a"),Hgt=o("FlaxMBartForConditionalGeneration"),Jgt=o(" (mBART model)"),Ygt=l(),O7=a("li"),Hxe=a("strong"),Kgt=o("mt5"),Zgt=o(" \u2014 "),Ase=a("a"),eht=o("FlaxMT5ForConditionalGeneration"),oht=o(" (MT5 model)"),rht=l(),V7=a("li"),Jxe=a("strong"),tht=o("roberta"),aht=o(" \u2014 "),Lse=a("a"),nht=o("FlaxRobertaForMaskedLM"),sht=o(" (RoBERTa model)"),lht=l(),X7=a("li"),Yxe=a("strong"),iht=o("roformer"),dht=o(" \u2014 "),yse=a("a"),mht=o("FlaxRoFormerForMaskedLM"),cht=o(" (RoFormer model)"),fht=l(),z7=a("li"),Kxe=a("strong"),ght=o("t5"),hht=o(" \u2014 "),xse=a("a"),uht=o("FlaxT5ForConditionalGeneration"),pht=o(" (T5 model)"),_ht=l(),Q7=a("li"),Zxe=a("strong"),bht=o("wav2vec2"),vht=o(" \u2014 "),$se=a("a"),Fht=o("FlaxWav2Vec2ForPreTraining"),Tht=o(" (Wav2Vec2 model)"),Mht=l(),W7=a("li"),e$e=a("strong"),Eht=o("xlm-roberta"),Cht=o(" \u2014 "),kse=a("a"),wht=o("FlaxXLMRobertaForMaskedLM"),Aht=o(" (XLM-RoBERTa model)"),Lht=l(),F(U7.$$.fragment),mro=l(),Wc=a("h2"),H7=a("a"),o$e=a("span"),F(XR.$$.fragment),yht=l(),r$e=a("span"),xht=o("FlaxAutoModelForMaskedLM"),cro=l(),wr=a("div"),F(zR.$$.fragment),$ht=l(),Uc=a("p"),kht=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Sse=a("a"),Sht=o("from_pretrained()"),Rht=o(" class method or the "),Rse=a("a"),Pht=o("from_config()"),Bht=o(` class
method.`),Iht=l(),QR=a("p"),Nht=o("This class cannot be instantiated directly using "),t$e=a("code"),qht=o("__init__()"),jht=o(" (throws an error)."),Dht=l(),da=a("div"),F(WR.$$.fragment),Ght=l(),a$e=a("p"),Oht=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Vht=l(),Hc=a("p"),Xht=o(`Note:
Loading a model from its configuration file does `),n$e=a("strong"),zht=o("not"),Qht=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Pse=a("a"),Wht=o("from_pretrained()"),Uht=o(" to load the model weights."),Hht=l(),F(J7.$$.fragment),Jht=l(),ot=a("div"),F(UR.$$.fragment),Yht=l(),s$e=a("p"),Kht=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Zht=l(),Xn=a("p"),eut=o("The model class to instantiate is selected based on the "),l$e=a("code"),out=o("model_type"),rut=o(` property of the config object (either
passed as an argument or loaded from `),i$e=a("code"),tut=o("pretrained_model_name_or_path"),aut=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d$e=a("code"),nut=o("pretrained_model_name_or_path"),sut=o(":"),lut=l(),$e=a("ul"),Y7=a("li"),m$e=a("strong"),iut=o("albert"),dut=o(" \u2014 "),Bse=a("a"),mut=o("FlaxAlbertForMaskedLM"),cut=o(" (ALBERT model)"),fut=l(),K7=a("li"),c$e=a("strong"),gut=o("bart"),hut=o(" \u2014 "),Ise=a("a"),uut=o("FlaxBartForConditionalGeneration"),put=o(" (BART model)"),_ut=l(),Z7=a("li"),f$e=a("strong"),but=o("bert"),vut=o(" \u2014 "),Nse=a("a"),Fut=o("FlaxBertForMaskedLM"),Tut=o(" (BERT model)"),Mut=l(),eL=a("li"),g$e=a("strong"),Eut=o("big_bird"),Cut=o(" \u2014 "),qse=a("a"),wut=o("FlaxBigBirdForMaskedLM"),Aut=o(" (BigBird model)"),Lut=l(),oL=a("li"),h$e=a("strong"),yut=o("distilbert"),xut=o(" \u2014 "),jse=a("a"),$ut=o("FlaxDistilBertForMaskedLM"),kut=o(" (DistilBERT model)"),Sut=l(),rL=a("li"),u$e=a("strong"),Rut=o("electra"),Put=o(" \u2014 "),Dse=a("a"),But=o("FlaxElectraForMaskedLM"),Iut=o(" (ELECTRA model)"),Nut=l(),tL=a("li"),p$e=a("strong"),qut=o("mbart"),jut=o(" \u2014 "),Gse=a("a"),Dut=o("FlaxMBartForConditionalGeneration"),Gut=o(" (mBART model)"),Out=l(),aL=a("li"),_$e=a("strong"),Vut=o("roberta"),Xut=o(" \u2014 "),Ose=a("a"),zut=o("FlaxRobertaForMaskedLM"),Qut=o(" (RoBERTa model)"),Wut=l(),nL=a("li"),b$e=a("strong"),Uut=o("roformer"),Hut=o(" \u2014 "),Vse=a("a"),Jut=o("FlaxRoFormerForMaskedLM"),Yut=o(" (RoFormer model)"),Kut=l(),sL=a("li"),v$e=a("strong"),Zut=o("xlm-roberta"),ept=o(" \u2014 "),Xse=a("a"),opt=o("FlaxXLMRobertaForMaskedLM"),rpt=o(" (XLM-RoBERTa model)"),tpt=l(),F(lL.$$.fragment),fro=l(),Jc=a("h2"),iL=a("a"),F$e=a("span"),F(HR.$$.fragment),apt=l(),T$e=a("span"),npt=o("FlaxAutoModelForSeq2SeqLM"),gro=l(),Ar=a("div"),F(JR.$$.fragment),spt=l(),Yc=a("p"),lpt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),zse=a("a"),ipt=o("from_pretrained()"),dpt=o(" class method or the "),Qse=a("a"),mpt=o("from_config()"),cpt=o(` class
method.`),fpt=l(),YR=a("p"),gpt=o("This class cannot be instantiated directly using "),M$e=a("code"),hpt=o("__init__()"),upt=o(" (throws an error)."),ppt=l(),ma=a("div"),F(KR.$$.fragment),_pt=l(),E$e=a("p"),bpt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),vpt=l(),Kc=a("p"),Fpt=o(`Note:
Loading a model from its configuration file does `),C$e=a("strong"),Tpt=o("not"),Mpt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Wse=a("a"),Ept=o("from_pretrained()"),Cpt=o(" to load the model weights."),wpt=l(),F(dL.$$.fragment),Apt=l(),rt=a("div"),F(ZR.$$.fragment),Lpt=l(),w$e=a("p"),ypt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),xpt=l(),zn=a("p"),$pt=o("The model class to instantiate is selected based on the "),A$e=a("code"),kpt=o("model_type"),Spt=o(` property of the config object (either
passed as an argument or loaded from `),L$e=a("code"),Rpt=o("pretrained_model_name_or_path"),Ppt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y$e=a("code"),Bpt=o("pretrained_model_name_or_path"),Ipt=o(":"),Npt=l(),ke=a("ul"),mL=a("li"),x$e=a("strong"),qpt=o("bart"),jpt=o(" \u2014 "),Use=a("a"),Dpt=o("FlaxBartForConditionalGeneration"),Gpt=o(" (BART model)"),Opt=l(),cL=a("li"),$$e=a("strong"),Vpt=o("blenderbot"),Xpt=o(" \u2014 "),Hse=a("a"),zpt=o("FlaxBlenderbotForConditionalGeneration"),Qpt=o(" (Blenderbot model)"),Wpt=l(),fL=a("li"),k$e=a("strong"),Upt=o("blenderbot-small"),Hpt=o(" \u2014 "),Jse=a("a"),Jpt=o("FlaxBlenderbotSmallForConditionalGeneration"),Ypt=o(" (BlenderbotSmall model)"),Kpt=l(),gL=a("li"),S$e=a("strong"),Zpt=o("encoder-decoder"),e_t=o(" \u2014 "),Yse=a("a"),o_t=o("FlaxEncoderDecoderModel"),r_t=o(" (Encoder decoder model)"),t_t=l(),hL=a("li"),R$e=a("strong"),a_t=o("longt5"),n_t=o(" \u2014 "),Kse=a("a"),s_t=o("FlaxLongT5ForConditionalGeneration"),l_t=o(" (LongT5 model)"),i_t=l(),uL=a("li"),P$e=a("strong"),d_t=o("marian"),m_t=o(" \u2014 "),Zse=a("a"),c_t=o("FlaxMarianMTModel"),f_t=o(" (Marian model)"),g_t=l(),pL=a("li"),B$e=a("strong"),h_t=o("mbart"),u_t=o(" \u2014 "),ele=a("a"),p_t=o("FlaxMBartForConditionalGeneration"),__t=o(" (mBART model)"),b_t=l(),_L=a("li"),I$e=a("strong"),v_t=o("mt5"),F_t=o(" \u2014 "),ole=a("a"),T_t=o("FlaxMT5ForConditionalGeneration"),M_t=o(" (MT5 model)"),E_t=l(),bL=a("li"),N$e=a("strong"),C_t=o("pegasus"),w_t=o(" \u2014 "),rle=a("a"),A_t=o("FlaxPegasusForConditionalGeneration"),L_t=o(" (Pegasus model)"),y_t=l(),vL=a("li"),q$e=a("strong"),x_t=o("t5"),$_t=o(" \u2014 "),tle=a("a"),k_t=o("FlaxT5ForConditionalGeneration"),S_t=o(" (T5 model)"),R_t=l(),F(FL.$$.fragment),hro=l(),Zc=a("h2"),TL=a("a"),j$e=a("span"),F(eP.$$.fragment),P_t=l(),D$e=a("span"),B_t=o("FlaxAutoModelForSequenceClassification"),uro=l(),Lr=a("div"),F(oP.$$.fragment),I_t=l(),ef=a("p"),N_t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),ale=a("a"),q_t=o("from_pretrained()"),j_t=o(" class method or the "),nle=a("a"),D_t=o("from_config()"),G_t=o(` class
method.`),O_t=l(),rP=a("p"),V_t=o("This class cannot be instantiated directly using "),G$e=a("code"),X_t=o("__init__()"),z_t=o(" (throws an error)."),Q_t=l(),ca=a("div"),F(tP.$$.fragment),W_t=l(),O$e=a("p"),U_t=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),H_t=l(),of=a("p"),J_t=o(`Note:
Loading a model from its configuration file does `),V$e=a("strong"),Y_t=o("not"),K_t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sle=a("a"),Z_t=o("from_pretrained()"),e1t=o(" to load the model weights."),o1t=l(),F(ML.$$.fragment),r1t=l(),tt=a("div"),F(aP.$$.fragment),t1t=l(),X$e=a("p"),a1t=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),n1t=l(),Qn=a("p"),s1t=o("The model class to instantiate is selected based on the "),z$e=a("code"),l1t=o("model_type"),i1t=o(` property of the config object (either
passed as an argument or loaded from `),Q$e=a("code"),d1t=o("pretrained_model_name_or_path"),m1t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W$e=a("code"),c1t=o("pretrained_model_name_or_path"),f1t=o(":"),g1t=l(),Se=a("ul"),EL=a("li"),U$e=a("strong"),h1t=o("albert"),u1t=o(" \u2014 "),lle=a("a"),p1t=o("FlaxAlbertForSequenceClassification"),_1t=o(" (ALBERT model)"),b1t=l(),CL=a("li"),H$e=a("strong"),v1t=o("bart"),F1t=o(" \u2014 "),ile=a("a"),T1t=o("FlaxBartForSequenceClassification"),M1t=o(" (BART model)"),E1t=l(),wL=a("li"),J$e=a("strong"),C1t=o("bert"),w1t=o(" \u2014 "),dle=a("a"),A1t=o("FlaxBertForSequenceClassification"),L1t=o(" (BERT model)"),y1t=l(),AL=a("li"),Y$e=a("strong"),x1t=o("big_bird"),$1t=o(" \u2014 "),mle=a("a"),k1t=o("FlaxBigBirdForSequenceClassification"),S1t=o(" (BigBird model)"),R1t=l(),LL=a("li"),K$e=a("strong"),P1t=o("distilbert"),B1t=o(" \u2014 "),cle=a("a"),I1t=o("FlaxDistilBertForSequenceClassification"),N1t=o(" (DistilBERT model)"),q1t=l(),yL=a("li"),Z$e=a("strong"),j1t=o("electra"),D1t=o(" \u2014 "),fle=a("a"),G1t=o("FlaxElectraForSequenceClassification"),O1t=o(" (ELECTRA model)"),V1t=l(),xL=a("li"),eke=a("strong"),X1t=o("mbart"),z1t=o(" \u2014 "),gle=a("a"),Q1t=o("FlaxMBartForSequenceClassification"),W1t=o(" (mBART model)"),U1t=l(),$L=a("li"),oke=a("strong"),H1t=o("roberta"),J1t=o(" \u2014 "),hle=a("a"),Y1t=o("FlaxRobertaForSequenceClassification"),K1t=o(" (RoBERTa model)"),Z1t=l(),kL=a("li"),rke=a("strong"),e2t=o("roformer"),o2t=o(" \u2014 "),ule=a("a"),r2t=o("FlaxRoFormerForSequenceClassification"),t2t=o(" (RoFormer model)"),a2t=l(),SL=a("li"),tke=a("strong"),n2t=o("xlm-roberta"),s2t=o(" \u2014 "),ple=a("a"),l2t=o("FlaxXLMRobertaForSequenceClassification"),i2t=o(" (XLM-RoBERTa model)"),d2t=l(),F(RL.$$.fragment),pro=l(),rf=a("h2"),PL=a("a"),ake=a("span"),F(nP.$$.fragment),m2t=l(),nke=a("span"),c2t=o("FlaxAutoModelForQuestionAnswering"),_ro=l(),yr=a("div"),F(sP.$$.fragment),f2t=l(),tf=a("p"),g2t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),_le=a("a"),h2t=o("from_pretrained()"),u2t=o(" class method or the "),ble=a("a"),p2t=o("from_config()"),_2t=o(` class
method.`),b2t=l(),lP=a("p"),v2t=o("This class cannot be instantiated directly using "),ske=a("code"),F2t=o("__init__()"),T2t=o(" (throws an error)."),M2t=l(),fa=a("div"),F(iP.$$.fragment),E2t=l(),lke=a("p"),C2t=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),w2t=l(),af=a("p"),A2t=o(`Note:
Loading a model from its configuration file does `),ike=a("strong"),L2t=o("not"),y2t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vle=a("a"),x2t=o("from_pretrained()"),$2t=o(" to load the model weights."),k2t=l(),F(BL.$$.fragment),S2t=l(),at=a("div"),F(dP.$$.fragment),R2t=l(),dke=a("p"),P2t=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),B2t=l(),Wn=a("p"),I2t=o("The model class to instantiate is selected based on the "),mke=a("code"),N2t=o("model_type"),q2t=o(` property of the config object (either
passed as an argument or loaded from `),cke=a("code"),j2t=o("pretrained_model_name_or_path"),D2t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fke=a("code"),G2t=o("pretrained_model_name_or_path"),O2t=o(":"),V2t=l(),Re=a("ul"),IL=a("li"),gke=a("strong"),X2t=o("albert"),z2t=o(" \u2014 "),Fle=a("a"),Q2t=o("FlaxAlbertForQuestionAnswering"),W2t=o(" (ALBERT model)"),U2t=l(),NL=a("li"),hke=a("strong"),H2t=o("bart"),J2t=o(" \u2014 "),Tle=a("a"),Y2t=o("FlaxBartForQuestionAnswering"),K2t=o(" (BART model)"),Z2t=l(),qL=a("li"),uke=a("strong"),ebt=o("bert"),obt=o(" \u2014 "),Mle=a("a"),rbt=o("FlaxBertForQuestionAnswering"),tbt=o(" (BERT model)"),abt=l(),jL=a("li"),pke=a("strong"),nbt=o("big_bird"),sbt=o(" \u2014 "),Ele=a("a"),lbt=o("FlaxBigBirdForQuestionAnswering"),ibt=o(" (BigBird model)"),dbt=l(),DL=a("li"),_ke=a("strong"),mbt=o("distilbert"),cbt=o(" \u2014 "),Cle=a("a"),fbt=o("FlaxDistilBertForQuestionAnswering"),gbt=o(" (DistilBERT model)"),hbt=l(),GL=a("li"),bke=a("strong"),ubt=o("electra"),pbt=o(" \u2014 "),wle=a("a"),_bt=o("FlaxElectraForQuestionAnswering"),bbt=o(" (ELECTRA model)"),vbt=l(),OL=a("li"),vke=a("strong"),Fbt=o("mbart"),Tbt=o(" \u2014 "),Ale=a("a"),Mbt=o("FlaxMBartForQuestionAnswering"),Ebt=o(" (mBART model)"),Cbt=l(),VL=a("li"),Fke=a("strong"),wbt=o("roberta"),Abt=o(" \u2014 "),Lle=a("a"),Lbt=o("FlaxRobertaForQuestionAnswering"),ybt=o(" (RoBERTa model)"),xbt=l(),XL=a("li"),Tke=a("strong"),$bt=o("roformer"),kbt=o(" \u2014 "),yle=a("a"),Sbt=o("FlaxRoFormerForQuestionAnswering"),Rbt=o(" (RoFormer model)"),Pbt=l(),zL=a("li"),Mke=a("strong"),Bbt=o("xlm-roberta"),Ibt=o(" \u2014 "),xle=a("a"),Nbt=o("FlaxXLMRobertaForQuestionAnswering"),qbt=o(" (XLM-RoBERTa model)"),jbt=l(),F(QL.$$.fragment),bro=l(),nf=a("h2"),WL=a("a"),Eke=a("span"),F(mP.$$.fragment),Dbt=l(),Cke=a("span"),Gbt=o("FlaxAutoModelForTokenClassification"),vro=l(),xr=a("div"),F(cP.$$.fragment),Obt=l(),sf=a("p"),Vbt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),$le=a("a"),Xbt=o("from_pretrained()"),zbt=o(" class method or the "),kle=a("a"),Qbt=o("from_config()"),Wbt=o(` class
method.`),Ubt=l(),fP=a("p"),Hbt=o("This class cannot be instantiated directly using "),wke=a("code"),Jbt=o("__init__()"),Ybt=o(" (throws an error)."),Kbt=l(),ga=a("div"),F(gP.$$.fragment),Zbt=l(),Ake=a("p"),evt=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),ovt=l(),lf=a("p"),rvt=o(`Note:
Loading a model from its configuration file does `),Lke=a("strong"),tvt=o("not"),avt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Sle=a("a"),nvt=o("from_pretrained()"),svt=o(" to load the model weights."),lvt=l(),F(UL.$$.fragment),ivt=l(),nt=a("div"),F(hP.$$.fragment),dvt=l(),yke=a("p"),mvt=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),cvt=l(),Un=a("p"),fvt=o("The model class to instantiate is selected based on the "),xke=a("code"),gvt=o("model_type"),hvt=o(` property of the config object (either
passed as an argument or loaded from `),$ke=a("code"),uvt=o("pretrained_model_name_or_path"),pvt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kke=a("code"),_vt=o("pretrained_model_name_or_path"),bvt=o(":"),vvt=l(),Xe=a("ul"),HL=a("li"),Ske=a("strong"),Fvt=o("albert"),Tvt=o(" \u2014 "),Rle=a("a"),Mvt=o("FlaxAlbertForTokenClassification"),Evt=o(" (ALBERT model)"),Cvt=l(),JL=a("li"),Rke=a("strong"),wvt=o("bert"),Avt=o(" \u2014 "),Ple=a("a"),Lvt=o("FlaxBertForTokenClassification"),yvt=o(" (BERT model)"),xvt=l(),YL=a("li"),Pke=a("strong"),$vt=o("big_bird"),kvt=o(" \u2014 "),Ble=a("a"),Svt=o("FlaxBigBirdForTokenClassification"),Rvt=o(" (BigBird model)"),Pvt=l(),KL=a("li"),Bke=a("strong"),Bvt=o("distilbert"),Ivt=o(" \u2014 "),Ile=a("a"),Nvt=o("FlaxDistilBertForTokenClassification"),qvt=o(" (DistilBERT model)"),jvt=l(),ZL=a("li"),Ike=a("strong"),Dvt=o("electra"),Gvt=o(" \u2014 "),Nle=a("a"),Ovt=o("FlaxElectraForTokenClassification"),Vvt=o(" (ELECTRA model)"),Xvt=l(),ey=a("li"),Nke=a("strong"),zvt=o("roberta"),Qvt=o(" \u2014 "),qle=a("a"),Wvt=o("FlaxRobertaForTokenClassification"),Uvt=o(" (RoBERTa model)"),Hvt=l(),oy=a("li"),qke=a("strong"),Jvt=o("roformer"),Yvt=o(" \u2014 "),jle=a("a"),Kvt=o("FlaxRoFormerForTokenClassification"),Zvt=o(" (RoFormer model)"),eFt=l(),ry=a("li"),jke=a("strong"),oFt=o("xlm-roberta"),rFt=o(" \u2014 "),Dle=a("a"),tFt=o("FlaxXLMRobertaForTokenClassification"),aFt=o(" (XLM-RoBERTa model)"),nFt=l(),F(ty.$$.fragment),Fro=l(),df=a("h2"),ay=a("a"),Dke=a("span"),F(uP.$$.fragment),sFt=l(),Gke=a("span"),lFt=o("FlaxAutoModelForMultipleChoice"),Tro=l(),$r=a("div"),F(pP.$$.fragment),iFt=l(),mf=a("p"),dFt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Gle=a("a"),mFt=o("from_pretrained()"),cFt=o(" class method or the "),Ole=a("a"),fFt=o("from_config()"),gFt=o(` class
method.`),hFt=l(),_P=a("p"),uFt=o("This class cannot be instantiated directly using "),Oke=a("code"),pFt=o("__init__()"),_Ft=o(" (throws an error)."),bFt=l(),ha=a("div"),F(bP.$$.fragment),vFt=l(),Vke=a("p"),FFt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),TFt=l(),cf=a("p"),MFt=o(`Note:
Loading a model from its configuration file does `),Xke=a("strong"),EFt=o("not"),CFt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vle=a("a"),wFt=o("from_pretrained()"),AFt=o(" to load the model weights."),LFt=l(),F(ny.$$.fragment),yFt=l(),st=a("div"),F(vP.$$.fragment),xFt=l(),zke=a("p"),$Ft=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),kFt=l(),Hn=a("p"),SFt=o("The model class to instantiate is selected based on the "),Qke=a("code"),RFt=o("model_type"),PFt=o(` property of the config object (either
passed as an argument or loaded from `),Wke=a("code"),BFt=o("pretrained_model_name_or_path"),IFt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Uke=a("code"),NFt=o("pretrained_model_name_or_path"),qFt=o(":"),jFt=l(),ze=a("ul"),sy=a("li"),Hke=a("strong"),DFt=o("albert"),GFt=o(" \u2014 "),Xle=a("a"),OFt=o("FlaxAlbertForMultipleChoice"),VFt=o(" (ALBERT model)"),XFt=l(),ly=a("li"),Jke=a("strong"),zFt=o("bert"),QFt=o(" \u2014 "),zle=a("a"),WFt=o("FlaxBertForMultipleChoice"),UFt=o(" (BERT model)"),HFt=l(),iy=a("li"),Yke=a("strong"),JFt=o("big_bird"),YFt=o(" \u2014 "),Qle=a("a"),KFt=o("FlaxBigBirdForMultipleChoice"),ZFt=o(" (BigBird model)"),eTt=l(),dy=a("li"),Kke=a("strong"),oTt=o("distilbert"),rTt=o(" \u2014 "),Wle=a("a"),tTt=o("FlaxDistilBertForMultipleChoice"),aTt=o(" (DistilBERT model)"),nTt=l(),my=a("li"),Zke=a("strong"),sTt=o("electra"),lTt=o(" \u2014 "),Ule=a("a"),iTt=o("FlaxElectraForMultipleChoice"),dTt=o(" (ELECTRA model)"),mTt=l(),cy=a("li"),eSe=a("strong"),cTt=o("roberta"),fTt=o(" \u2014 "),Hle=a("a"),gTt=o("FlaxRobertaForMultipleChoice"),hTt=o(" (RoBERTa model)"),uTt=l(),fy=a("li"),oSe=a("strong"),pTt=o("roformer"),_Tt=o(" \u2014 "),Jle=a("a"),bTt=o("FlaxRoFormerForMultipleChoice"),vTt=o(" (RoFormer model)"),FTt=l(),gy=a("li"),rSe=a("strong"),TTt=o("xlm-roberta"),MTt=o(" \u2014 "),Yle=a("a"),ETt=o("FlaxXLMRobertaForMultipleChoice"),CTt=o(" (XLM-RoBERTa model)"),wTt=l(),F(hy.$$.fragment),Mro=l(),ff=a("h2"),uy=a("a"),tSe=a("span"),F(FP.$$.fragment),ATt=l(),aSe=a("span"),LTt=o("FlaxAutoModelForNextSentencePrediction"),Ero=l(),kr=a("div"),F(TP.$$.fragment),yTt=l(),gf=a("p"),xTt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Kle=a("a"),$Tt=o("from_pretrained()"),kTt=o(" class method or the "),Zle=a("a"),STt=o("from_config()"),RTt=o(` class
method.`),PTt=l(),MP=a("p"),BTt=o("This class cannot be instantiated directly using "),nSe=a("code"),ITt=o("__init__()"),NTt=o(" (throws an error)."),qTt=l(),ua=a("div"),F(EP.$$.fragment),jTt=l(),sSe=a("p"),DTt=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),GTt=l(),hf=a("p"),OTt=o(`Note:
Loading a model from its configuration file does `),lSe=a("strong"),VTt=o("not"),XTt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eie=a("a"),zTt=o("from_pretrained()"),QTt=o(" to load the model weights."),WTt=l(),F(py.$$.fragment),UTt=l(),lt=a("div"),F(CP.$$.fragment),HTt=l(),iSe=a("p"),JTt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),YTt=l(),Jn=a("p"),KTt=o("The model class to instantiate is selected based on the "),dSe=a("code"),ZTt=o("model_type"),eMt=o(` property of the config object (either
passed as an argument or loaded from `),mSe=a("code"),oMt=o("pretrained_model_name_or_path"),rMt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cSe=a("code"),tMt=o("pretrained_model_name_or_path"),aMt=o(":"),nMt=l(),fSe=a("ul"),_y=a("li"),gSe=a("strong"),sMt=o("bert"),lMt=o(" \u2014 "),oie=a("a"),iMt=o("FlaxBertForNextSentencePrediction"),dMt=o(" (BERT model)"),mMt=l(),F(by.$$.fragment),Cro=l(),uf=a("h2"),vy=a("a"),hSe=a("span"),F(wP.$$.fragment),cMt=l(),uSe=a("span"),fMt=o("FlaxAutoModelForImageClassification"),wro=l(),Sr=a("div"),F(AP.$$.fragment),gMt=l(),pf=a("p"),hMt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),rie=a("a"),uMt=o("from_pretrained()"),pMt=o(" class method or the "),tie=a("a"),_Mt=o("from_config()"),bMt=o(` class
method.`),vMt=l(),LP=a("p"),FMt=o("This class cannot be instantiated directly using "),pSe=a("code"),TMt=o("__init__()"),MMt=o(" (throws an error)."),EMt=l(),pa=a("div"),F(yP.$$.fragment),CMt=l(),_Se=a("p"),wMt=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),AMt=l(),_f=a("p"),LMt=o(`Note:
Loading a model from its configuration file does `),bSe=a("strong"),yMt=o("not"),xMt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aie=a("a"),$Mt=o("from_pretrained()"),kMt=o(" to load the model weights."),SMt=l(),F(Fy.$$.fragment),RMt=l(),it=a("div"),F(xP.$$.fragment),PMt=l(),vSe=a("p"),BMt=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),IMt=l(),Yn=a("p"),NMt=o("The model class to instantiate is selected based on the "),FSe=a("code"),qMt=o("model_type"),jMt=o(` property of the config object (either
passed as an argument or loaded from `),TSe=a("code"),DMt=o("pretrained_model_name_or_path"),GMt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MSe=a("code"),OMt=o("pretrained_model_name_or_path"),VMt=o(":"),XMt=l(),$P=a("ul"),Ty=a("li"),ESe=a("strong"),zMt=o("beit"),QMt=o(" \u2014 "),nie=a("a"),WMt=o("FlaxBeitForImageClassification"),UMt=o(" (BEiT model)"),HMt=l(),My=a("li"),CSe=a("strong"),JMt=o("vit"),YMt=o(" \u2014 "),sie=a("a"),KMt=o("FlaxViTForImageClassification"),ZMt=o(" (ViT model)"),eEt=l(),F(Ey.$$.fragment),Aro=l(),bf=a("h2"),Cy=a("a"),wSe=a("span"),F(kP.$$.fragment),oEt=l(),ASe=a("span"),rEt=o("FlaxAutoModelForVision2Seq"),Lro=l(),Rr=a("div"),F(SP.$$.fragment),tEt=l(),vf=a("p"),aEt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),lie=a("a"),nEt=o("from_pretrained()"),sEt=o(" class method or the "),iie=a("a"),lEt=o("from_config()"),iEt=o(` class
method.`),dEt=l(),RP=a("p"),mEt=o("This class cannot be instantiated directly using "),LSe=a("code"),cEt=o("__init__()"),fEt=o(" (throws an error)."),gEt=l(),_a=a("div"),F(PP.$$.fragment),hEt=l(),ySe=a("p"),uEt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),pEt=l(),Ff=a("p"),_Et=o(`Note:
Loading a model from its configuration file does `),xSe=a("strong"),bEt=o("not"),vEt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),die=a("a"),FEt=o("from_pretrained()"),TEt=o(" to load the model weights."),MEt=l(),F(wy.$$.fragment),EEt=l(),dt=a("div"),F(BP.$$.fragment),CEt=l(),$Se=a("p"),wEt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),AEt=l(),Kn=a("p"),LEt=o("The model class to instantiate is selected based on the "),kSe=a("code"),yEt=o("model_type"),xEt=o(` property of the config object (either
passed as an argument or loaded from `),SSe=a("code"),$Et=o("pretrained_model_name_or_path"),kEt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RSe=a("code"),SEt=o("pretrained_model_name_or_path"),REt=o(":"),PEt=l(),PSe=a("ul"),Ay=a("li"),BSe=a("strong"),BEt=o("vision-encoder-decoder"),IEt=o(" \u2014 "),mie=a("a"),NEt=o("FlaxVisionEncoderDecoderModel"),qEt=o(" (Vision Encoder decoder model)"),jEt=l(),F(Ly.$$.fragment),this.h()},l(c){const _=tba('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(c),u=n(c,"H1",{class:!0});var IP=s(u);f=n(IP,"A",{id:!0,class:!0,href:!0});var ISe=s(f);p=n(ISe,"SPAN",{});var NSe=s(p);T(m.$$.fragment,NSe),NSe.forEach(t),ISe.forEach(t),h=i(IP),yo=n(IP,"SPAN",{});var qSe=s(yo);td=r(qSe,"Auto Classes"),qSe.forEach(t),IP.forEach(t),Cf=i(c),pt=n(c,"P",{});var NP=s(pt);ad=r(NP,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),nd=n(NP,"CODE",{});var jSe=s(nd);ax=r(jSe,"from_pretrained()"),jSe.forEach(t),wf=r(NP,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),NP.forEach(t),Ve=i(c),He=n(c,"P",{});var Zn=s(He);sd=r(Zn,"Instantiating one of "),es=n(Zn,"A",{href:!0});var DSe=s(es);nx=r(DSe,"AutoConfig"),DSe.forEach(t),os=r(Zn,", "),rs=n(Zn,"A",{href:!0});var GSe=s(rs);sx=r(GSe,"AutoModel"),GSe.forEach(t),ld=r(Zn,`, and
`),ts=n(Zn,"A",{href:!0});var OSe=s(ts);lx=r(OSe,"AutoTokenizer"),OSe.forEach(t),id=r(Zn," will directly create a class of the relevant architecture. For instance"),Zn.forEach(t),Af=i(c),T(Qa.$$.fragment,c),Je=i(c),Ae=n(c,"P",{});var qP=s(Ae);lI=r(qP,"will create a model that is an instance of "),dd=n(qP,"A",{href:!0});var VSe=s(dd);iI=r(VSe,"BertModel"),VSe.forEach(t),dI=r(qP,"."),qP.forEach(t),xo=i(c),Wa=n(c,"P",{});var jP=s(Wa);mI=r(jP,"There is one class of "),Lf=n(jP,"CODE",{});var XSe=s(Lf);cI=r(XSe,"AutoModel"),XSe.forEach(t),Xao=r(jP," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),jP.forEach(t),ueo=i(c),md=n(c,"H2",{class:!0});var DP=s(md);yf=n(DP,"A",{id:!0,class:!0,href:!0});var zSe=s(yf);ume=n(zSe,"SPAN",{});var QSe=s(ume);T(ix.$$.fragment,QSe),QSe.forEach(t),zSe.forEach(t),zao=i(DP),pme=n(DP,"SPAN",{});var WSe=s(pme);Qao=r(WSe,"Extending the Auto Classes"),WSe.forEach(t),DP.forEach(t),peo=i(c),as=n(c,"P",{});var Tf=s(as);Wao=r(Tf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),_me=n(Tf,"CODE",{});var USe=s(_me);Uao=r(USe,"NewModel"),USe.forEach(t),Hao=r(Tf,", make sure you have a "),bme=n(Tf,"CODE",{});var HSe=s(bme);Jao=r(HSe,"NewModelConfig"),HSe.forEach(t),Yao=r(Tf,` then you can add those to the auto
classes like this:`),Tf.forEach(t),_eo=i(c),T(dx.$$.fragment,c),beo=i(c),fI=n(c,"P",{});var JSe=s(fI);Kao=r(JSe,"You will then be able to use the auto classes like you would usually do!"),JSe.forEach(t),veo=i(c),T(xf.$$.fragment,c),Feo=i(c),cd=n(c,"H2",{class:!0});var GP=s(cd);$f=n(GP,"A",{id:!0,class:!0,href:!0});var YSe=s($f);vme=n(YSe,"SPAN",{});var KSe=s(vme);T(mx.$$.fragment,KSe),KSe.forEach(t),YSe.forEach(t),Zao=i(GP),Fme=n(GP,"SPAN",{});var ZSe=s(Fme);eno=r(ZSe,"AutoConfig"),ZSe.forEach(t),GP.forEach(t),Teo=i(c),$o=n(c,"DIV",{class:!0});var ht=s($o);T(cx.$$.fragment,ht),ono=i(ht),fx=n(ht,"P",{});var OP=s(fx);rno=r(OP,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),gI=n(OP,"A",{href:!0});var eRe=s(gI);tno=r(eRe,"from_pretrained()"),eRe.forEach(t),ano=r(OP," class method."),OP.forEach(t),nno=i(ht),gx=n(ht,"P",{});var VP=s(gx);sno=r(VP,"This class cannot be instantiated directly using "),Tme=n(VP,"CODE",{});var oRe=s(Tme);lno=r(oRe,"__init__()"),oRe.forEach(t),ino=r(VP," (throws an error)."),VP.forEach(t),dno=i(ht),Pr=n(ht,"DIV",{class:!0});var ut=s(Pr);T(hx.$$.fragment,ut),mno=i(ut),Mme=n(ut,"P",{});var rRe=s(Mme);cno=r(rRe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),rRe.forEach(t),fno=i(ut),fd=n(ut,"P",{});var Mf=s(fd);gno=r(Mf,"The configuration class to instantiate is selected based on the "),Eme=n(Mf,"CODE",{});var tRe=s(Eme);hno=r(tRe,"model_type"),tRe.forEach(t),uno=r(Mf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Cme=n(Mf,"CODE",{});var aRe=s(Cme);pno=r(aRe,"pretrained_model_name_or_path"),aRe.forEach(t),_no=r(Mf,":"),Mf.forEach(t),bno=i(ut),A=n(ut,"UL",{});var L=s(A);kf=n(L,"LI",{});var yy=s(kf);wme=n(yy,"STRONG",{});var nRe=s(wme);vno=r(nRe,"albert"),nRe.forEach(t),Fno=r(yy," \u2014 "),hI=n(yy,"A",{href:!0});var sRe=s(hI);Tno=r(sRe,"AlbertConfig"),sRe.forEach(t),Mno=r(yy," (ALBERT model)"),yy.forEach(t),Eno=i(L),Sf=n(L,"LI",{});var xy=s(Sf);Ame=n(xy,"STRONG",{});var lRe=s(Ame);Cno=r(lRe,"bart"),lRe.forEach(t),wno=r(xy," \u2014 "),uI=n(xy,"A",{href:!0});var iRe=s(uI);Ano=r(iRe,"BartConfig"),iRe.forEach(t),Lno=r(xy," (BART model)"),xy.forEach(t),yno=i(L),Rf=n(L,"LI",{});var $y=s(Rf);Lme=n($y,"STRONG",{});var dRe=s(Lme);xno=r(dRe,"beit"),dRe.forEach(t),$no=r($y," \u2014 "),pI=n($y,"A",{href:!0});var mRe=s(pI);kno=r(mRe,"BeitConfig"),mRe.forEach(t),Sno=r($y," (BEiT model)"),$y.forEach(t),Rno=i(L),Pf=n(L,"LI",{});var ky=s(Pf);yme=n(ky,"STRONG",{});var cRe=s(yme);Pno=r(cRe,"bert"),cRe.forEach(t),Bno=r(ky," \u2014 "),_I=n(ky,"A",{href:!0});var fRe=s(_I);Ino=r(fRe,"BertConfig"),fRe.forEach(t),Nno=r(ky," (BERT model)"),ky.forEach(t),qno=i(L),Bf=n(L,"LI",{});var Sy=s(Bf);xme=n(Sy,"STRONG",{});var gRe=s(xme);jno=r(gRe,"bert-generation"),gRe.forEach(t),Dno=r(Sy," \u2014 "),bI=n(Sy,"A",{href:!0});var hRe=s(bI);Gno=r(hRe,"BertGenerationConfig"),hRe.forEach(t),Ono=r(Sy," (Bert Generation model)"),Sy.forEach(t),Vno=i(L),If=n(L,"LI",{});var Ry=s(If);$me=n(Ry,"STRONG",{});var uRe=s($me);Xno=r(uRe,"big_bird"),uRe.forEach(t),zno=r(Ry," \u2014 "),vI=n(Ry,"A",{href:!0});var pRe=s(vI);Qno=r(pRe,"BigBirdConfig"),pRe.forEach(t),Wno=r(Ry," (BigBird model)"),Ry.forEach(t),Uno=i(L),Nf=n(L,"LI",{});var Py=s(Nf);kme=n(Py,"STRONG",{});var _Re=s(kme);Hno=r(_Re,"bigbird_pegasus"),_Re.forEach(t),Jno=r(Py," \u2014 "),FI=n(Py,"A",{href:!0});var bRe=s(FI);Yno=r(bRe,"BigBirdPegasusConfig"),bRe.forEach(t),Kno=r(Py," (BigBird-Pegasus model)"),Py.forEach(t),Zno=i(L),qf=n(L,"LI",{});var By=s(qf);Sme=n(By,"STRONG",{});var vRe=s(Sme);eso=r(vRe,"blenderbot"),vRe.forEach(t),oso=r(By," \u2014 "),TI=n(By,"A",{href:!0});var FRe=s(TI);rso=r(FRe,"BlenderbotConfig"),FRe.forEach(t),tso=r(By," (Blenderbot model)"),By.forEach(t),aso=i(L),jf=n(L,"LI",{});var Iy=s(jf);Rme=n(Iy,"STRONG",{});var TRe=s(Rme);nso=r(TRe,"blenderbot-small"),TRe.forEach(t),sso=r(Iy," \u2014 "),MI=n(Iy,"A",{href:!0});var MRe=s(MI);lso=r(MRe,"BlenderbotSmallConfig"),MRe.forEach(t),iso=r(Iy," (BlenderbotSmall model)"),Iy.forEach(t),dso=i(L),Df=n(L,"LI",{});var Ny=s(Df);Pme=n(Ny,"STRONG",{});var ERe=s(Pme);mso=r(ERe,"bloom"),ERe.forEach(t),cso=r(Ny," \u2014 "),EI=n(Ny,"A",{href:!0});var CRe=s(EI);fso=r(CRe,"BloomConfig"),CRe.forEach(t),gso=r(Ny," (BLOOM model)"),Ny.forEach(t),hso=i(L),Gf=n(L,"LI",{});var qy=s(Gf);Bme=n(qy,"STRONG",{});var wRe=s(Bme);uso=r(wRe,"camembert"),wRe.forEach(t),pso=r(qy," \u2014 "),CI=n(qy,"A",{href:!0});var ARe=s(CI);_so=r(ARe,"CamembertConfig"),ARe.forEach(t),bso=r(qy," (CamemBERT model)"),qy.forEach(t),vso=i(L),Of=n(L,"LI",{});var jy=s(Of);Ime=n(jy,"STRONG",{});var LRe=s(Ime);Fso=r(LRe,"canine"),LRe.forEach(t),Tso=r(jy," \u2014 "),wI=n(jy,"A",{href:!0});var yRe=s(wI);Mso=r(yRe,"CanineConfig"),yRe.forEach(t),Eso=r(jy," (CANINE model)"),jy.forEach(t),Cso=i(L),Vf=n(L,"LI",{});var Dy=s(Vf);Nme=n(Dy,"STRONG",{});var xRe=s(Nme);wso=r(xRe,"clip"),xRe.forEach(t),Aso=r(Dy," \u2014 "),AI=n(Dy,"A",{href:!0});var $Re=s(AI);Lso=r($Re,"CLIPConfig"),$Re.forEach(t),yso=r(Dy," (CLIP model)"),Dy.forEach(t),xso=i(L),Xf=n(L,"LI",{});var Gy=s(Xf);qme=n(Gy,"STRONG",{});var kRe=s(qme);$so=r(kRe,"codegen"),kRe.forEach(t),kso=r(Gy," \u2014 "),LI=n(Gy,"A",{href:!0});var SRe=s(LI);Sso=r(SRe,"CodeGenConfig"),SRe.forEach(t),Rso=r(Gy," (CodeGen model)"),Gy.forEach(t),Pso=i(L),zf=n(L,"LI",{});var Oy=s(zf);jme=n(Oy,"STRONG",{});var RRe=s(jme);Bso=r(RRe,"conditional_detr"),RRe.forEach(t),Iso=r(Oy," \u2014 "),yI=n(Oy,"A",{href:!0});var PRe=s(yI);Nso=r(PRe,"ConditionalDetrConfig"),PRe.forEach(t),qso=r(Oy," (Conditional DETR model)"),Oy.forEach(t),jso=i(L),Qf=n(L,"LI",{});var Vy=s(Qf);Dme=n(Vy,"STRONG",{});var BRe=s(Dme);Dso=r(BRe,"convbert"),BRe.forEach(t),Gso=r(Vy," \u2014 "),xI=n(Vy,"A",{href:!0});var IRe=s(xI);Oso=r(IRe,"ConvBertConfig"),IRe.forEach(t),Vso=r(Vy," (ConvBERT model)"),Vy.forEach(t),Xso=i(L),Wf=n(L,"LI",{});var Xy=s(Wf);Gme=n(Xy,"STRONG",{});var NRe=s(Gme);zso=r(NRe,"convnext"),NRe.forEach(t),Qso=r(Xy," \u2014 "),$I=n(Xy,"A",{href:!0});var qRe=s($I);Wso=r(qRe,"ConvNextConfig"),qRe.forEach(t),Uso=r(Xy," (ConvNeXT model)"),Xy.forEach(t),Hso=i(L),Uf=n(L,"LI",{});var zy=s(Uf);Ome=n(zy,"STRONG",{});var jRe=s(Ome);Jso=r(jRe,"ctrl"),jRe.forEach(t),Yso=r(zy," \u2014 "),kI=n(zy,"A",{href:!0});var DRe=s(kI);Kso=r(DRe,"CTRLConfig"),DRe.forEach(t),Zso=r(zy," (CTRL model)"),zy.forEach(t),elo=i(L),Hf=n(L,"LI",{});var Qy=s(Hf);Vme=n(Qy,"STRONG",{});var GRe=s(Vme);olo=r(GRe,"cvt"),GRe.forEach(t),rlo=r(Qy," \u2014 "),SI=n(Qy,"A",{href:!0});var ORe=s(SI);tlo=r(ORe,"CvtConfig"),ORe.forEach(t),alo=r(Qy," (CvT model)"),Qy.forEach(t),nlo=i(L),Jf=n(L,"LI",{});var Wy=s(Jf);Xme=n(Wy,"STRONG",{});var VRe=s(Xme);slo=r(VRe,"data2vec-audio"),VRe.forEach(t),llo=r(Wy," \u2014 "),RI=n(Wy,"A",{href:!0});var XRe=s(RI);ilo=r(XRe,"Data2VecAudioConfig"),XRe.forEach(t),dlo=r(Wy," (Data2VecAudio model)"),Wy.forEach(t),mlo=i(L),Yf=n(L,"LI",{});var Uy=s(Yf);zme=n(Uy,"STRONG",{});var zRe=s(zme);clo=r(zRe,"data2vec-text"),zRe.forEach(t),flo=r(Uy," \u2014 "),PI=n(Uy,"A",{href:!0});var QRe=s(PI);glo=r(QRe,"Data2VecTextConfig"),QRe.forEach(t),hlo=r(Uy," (Data2VecText model)"),Uy.forEach(t),ulo=i(L),Kf=n(L,"LI",{});var Hy=s(Kf);Qme=n(Hy,"STRONG",{});var WRe=s(Qme);plo=r(WRe,"data2vec-vision"),WRe.forEach(t),_lo=r(Hy," \u2014 "),BI=n(Hy,"A",{href:!0});var URe=s(BI);blo=r(URe,"Data2VecVisionConfig"),URe.forEach(t),vlo=r(Hy," (Data2VecVision model)"),Hy.forEach(t),Flo=i(L),Zf=n(L,"LI",{});var Jy=s(Zf);Wme=n(Jy,"STRONG",{});var HRe=s(Wme);Tlo=r(HRe,"deberta"),HRe.forEach(t),Mlo=r(Jy," \u2014 "),II=n(Jy,"A",{href:!0});var JRe=s(II);Elo=r(JRe,"DebertaConfig"),JRe.forEach(t),Clo=r(Jy," (DeBERTa model)"),Jy.forEach(t),wlo=i(L),eg=n(L,"LI",{});var Yy=s(eg);Ume=n(Yy,"STRONG",{});var YRe=s(Ume);Alo=r(YRe,"deberta-v2"),YRe.forEach(t),Llo=r(Yy," \u2014 "),NI=n(Yy,"A",{href:!0});var KRe=s(NI);ylo=r(KRe,"DebertaV2Config"),KRe.forEach(t),xlo=r(Yy," (DeBERTa-v2 model)"),Yy.forEach(t),$lo=i(L),og=n(L,"LI",{});var Ky=s(og);Hme=n(Ky,"STRONG",{});var ZRe=s(Hme);klo=r(ZRe,"decision_transformer"),ZRe.forEach(t),Slo=r(Ky," \u2014 "),qI=n(Ky,"A",{href:!0});var ePe=s(qI);Rlo=r(ePe,"DecisionTransformerConfig"),ePe.forEach(t),Plo=r(Ky," (Decision Transformer model)"),Ky.forEach(t),Blo=i(L),rg=n(L,"LI",{});var Zy=s(rg);Jme=n(Zy,"STRONG",{});var oPe=s(Jme);Ilo=r(oPe,"deformable_detr"),oPe.forEach(t),Nlo=r(Zy," \u2014 "),jI=n(Zy,"A",{href:!0});var rPe=s(jI);qlo=r(rPe,"DeformableDetrConfig"),rPe.forEach(t),jlo=r(Zy," (Deformable DETR model)"),Zy.forEach(t),Dlo=i(L),tg=n(L,"LI",{});var tPe=s(tg);Yme=n(tPe,"STRONG",{});var GEt=s(Yme);Glo=r(GEt,"deit"),GEt.forEach(t),Olo=r(tPe," \u2014 "),DI=n(tPe,"A",{href:!0});var OEt=s(DI);Vlo=r(OEt,"DeiTConfig"),OEt.forEach(t),Xlo=r(tPe," (DeiT model)"),tPe.forEach(t),zlo=i(L),ag=n(L,"LI",{});var aPe=s(ag);Kme=n(aPe,"STRONG",{});var VEt=s(Kme);Qlo=r(VEt,"detr"),VEt.forEach(t),Wlo=r(aPe," \u2014 "),GI=n(aPe,"A",{href:!0});var XEt=s(GI);Ulo=r(XEt,"DetrConfig"),XEt.forEach(t),Hlo=r(aPe," (DETR model)"),aPe.forEach(t),Jlo=i(L),ng=n(L,"LI",{});var nPe=s(ng);Zme=n(nPe,"STRONG",{});var zEt=s(Zme);Ylo=r(zEt,"distilbert"),zEt.forEach(t),Klo=r(nPe," \u2014 "),OI=n(nPe,"A",{href:!0});var QEt=s(OI);Zlo=r(QEt,"DistilBertConfig"),QEt.forEach(t),eio=r(nPe," (DistilBERT model)"),nPe.forEach(t),oio=i(L),sg=n(L,"LI",{});var sPe=s(sg);ece=n(sPe,"STRONG",{});var WEt=s(ece);rio=r(WEt,"donut-swin"),WEt.forEach(t),tio=r(sPe," \u2014 "),VI=n(sPe,"A",{href:!0});var UEt=s(VI);aio=r(UEt,"DonutSwinConfig"),UEt.forEach(t),nio=r(sPe," (DonutSwin model)"),sPe.forEach(t),sio=i(L),lg=n(L,"LI",{});var lPe=s(lg);oce=n(lPe,"STRONG",{});var HEt=s(oce);lio=r(HEt,"dpr"),HEt.forEach(t),iio=r(lPe," \u2014 "),XI=n(lPe,"A",{href:!0});var JEt=s(XI);dio=r(JEt,"DPRConfig"),JEt.forEach(t),mio=r(lPe," (DPR model)"),lPe.forEach(t),cio=i(L),ig=n(L,"LI",{});var iPe=s(ig);rce=n(iPe,"STRONG",{});var YEt=s(rce);fio=r(YEt,"dpt"),YEt.forEach(t),gio=r(iPe," \u2014 "),zI=n(iPe,"A",{href:!0});var KEt=s(zI);hio=r(KEt,"DPTConfig"),KEt.forEach(t),uio=r(iPe," (DPT model)"),iPe.forEach(t),pio=i(L),dg=n(L,"LI",{});var dPe=s(dg);tce=n(dPe,"STRONG",{});var ZEt=s(tce);_io=r(ZEt,"electra"),ZEt.forEach(t),bio=r(dPe," \u2014 "),QI=n(dPe,"A",{href:!0});var e4t=s(QI);vio=r(e4t,"ElectraConfig"),e4t.forEach(t),Fio=r(dPe," (ELECTRA model)"),dPe.forEach(t),Tio=i(L),mg=n(L,"LI",{});var mPe=s(mg);ace=n(mPe,"STRONG",{});var o4t=s(ace);Mio=r(o4t,"encoder-decoder"),o4t.forEach(t),Eio=r(mPe," \u2014 "),WI=n(mPe,"A",{href:!0});var r4t=s(WI);Cio=r(r4t,"EncoderDecoderConfig"),r4t.forEach(t),wio=r(mPe," (Encoder decoder model)"),mPe.forEach(t),Aio=i(L),cg=n(L,"LI",{});var cPe=s(cg);nce=n(cPe,"STRONG",{});var t4t=s(nce);Lio=r(t4t,"ernie"),t4t.forEach(t),yio=r(cPe," \u2014 "),UI=n(cPe,"A",{href:!0});var a4t=s(UI);xio=r(a4t,"ErnieConfig"),a4t.forEach(t),$io=r(cPe," (ERNIE model)"),cPe.forEach(t),kio=i(L),fg=n(L,"LI",{});var fPe=s(fg);sce=n(fPe,"STRONG",{});var n4t=s(sce);Sio=r(n4t,"esm"),n4t.forEach(t),Rio=r(fPe," \u2014 "),HI=n(fPe,"A",{href:!0});var s4t=s(HI);Pio=r(s4t,"EsmConfig"),s4t.forEach(t),Bio=r(fPe," (ESM model)"),fPe.forEach(t),Iio=i(L),gg=n(L,"LI",{});var gPe=s(gg);lce=n(gPe,"STRONG",{});var l4t=s(lce);Nio=r(l4t,"flaubert"),l4t.forEach(t),qio=r(gPe," \u2014 "),JI=n(gPe,"A",{href:!0});var i4t=s(JI);jio=r(i4t,"FlaubertConfig"),i4t.forEach(t),Dio=r(gPe," (FlauBERT model)"),gPe.forEach(t),Gio=i(L),hg=n(L,"LI",{});var hPe=s(hg);ice=n(hPe,"STRONG",{});var d4t=s(ice);Oio=r(d4t,"flava"),d4t.forEach(t),Vio=r(hPe," \u2014 "),YI=n(hPe,"A",{href:!0});var m4t=s(YI);Xio=r(m4t,"FlavaConfig"),m4t.forEach(t),zio=r(hPe," (FLAVA model)"),hPe.forEach(t),Qio=i(L),ug=n(L,"LI",{});var uPe=s(ug);dce=n(uPe,"STRONG",{});var c4t=s(dce);Wio=r(c4t,"fnet"),c4t.forEach(t),Uio=r(uPe," \u2014 "),KI=n(uPe,"A",{href:!0});var f4t=s(KI);Hio=r(f4t,"FNetConfig"),f4t.forEach(t),Jio=r(uPe," (FNet model)"),uPe.forEach(t),Yio=i(L),pg=n(L,"LI",{});var pPe=s(pg);mce=n(pPe,"STRONG",{});var g4t=s(mce);Kio=r(g4t,"fsmt"),g4t.forEach(t),Zio=r(pPe," \u2014 "),ZI=n(pPe,"A",{href:!0});var h4t=s(ZI);edo=r(h4t,"FSMTConfig"),h4t.forEach(t),odo=r(pPe," (FairSeq Machine-Translation model)"),pPe.forEach(t),rdo=i(L),_g=n(L,"LI",{});var _Pe=s(_g);cce=n(_Pe,"STRONG",{});var u4t=s(cce);tdo=r(u4t,"funnel"),u4t.forEach(t),ado=r(_Pe," \u2014 "),eN=n(_Pe,"A",{href:!0});var p4t=s(eN);ndo=r(p4t,"FunnelConfig"),p4t.forEach(t),sdo=r(_Pe," (Funnel Transformer model)"),_Pe.forEach(t),ldo=i(L),bg=n(L,"LI",{});var bPe=s(bg);fce=n(bPe,"STRONG",{});var _4t=s(fce);ido=r(_4t,"glpn"),_4t.forEach(t),ddo=r(bPe," \u2014 "),oN=n(bPe,"A",{href:!0});var b4t=s(oN);mdo=r(b4t,"GLPNConfig"),b4t.forEach(t),cdo=r(bPe," (GLPN model)"),bPe.forEach(t),fdo=i(L),vg=n(L,"LI",{});var vPe=s(vg);gce=n(vPe,"STRONG",{});var v4t=s(gce);gdo=r(v4t,"gpt2"),v4t.forEach(t),hdo=r(vPe," \u2014 "),rN=n(vPe,"A",{href:!0});var F4t=s(rN);udo=r(F4t,"GPT2Config"),F4t.forEach(t),pdo=r(vPe," (OpenAI GPT-2 model)"),vPe.forEach(t),_do=i(L),Fg=n(L,"LI",{});var FPe=s(Fg);hce=n(FPe,"STRONG",{});var T4t=s(hce);bdo=r(T4t,"gpt_neo"),T4t.forEach(t),vdo=r(FPe," \u2014 "),tN=n(FPe,"A",{href:!0});var M4t=s(tN);Fdo=r(M4t,"GPTNeoConfig"),M4t.forEach(t),Tdo=r(FPe," (GPT Neo model)"),FPe.forEach(t),Mdo=i(L),Tg=n(L,"LI",{});var TPe=s(Tg);uce=n(TPe,"STRONG",{});var E4t=s(uce);Edo=r(E4t,"gpt_neox"),E4t.forEach(t),Cdo=r(TPe," \u2014 "),aN=n(TPe,"A",{href:!0});var C4t=s(aN);wdo=r(C4t,"GPTNeoXConfig"),C4t.forEach(t),Ado=r(TPe," (GPT NeoX model)"),TPe.forEach(t),Ldo=i(L),Mg=n(L,"LI",{});var MPe=s(Mg);pce=n(MPe,"STRONG",{});var w4t=s(pce);ydo=r(w4t,"gpt_neox_japanese"),w4t.forEach(t),xdo=r(MPe," \u2014 "),nN=n(MPe,"A",{href:!0});var A4t=s(nN);$do=r(A4t,"GPTNeoXJapaneseConfig"),A4t.forEach(t),kdo=r(MPe," (GPT NeoX Japanese model)"),MPe.forEach(t),Sdo=i(L),Eg=n(L,"LI",{});var EPe=s(Eg);_ce=n(EPe,"STRONG",{});var L4t=s(_ce);Rdo=r(L4t,"gptj"),L4t.forEach(t),Pdo=r(EPe," \u2014 "),sN=n(EPe,"A",{href:!0});var y4t=s(sN);Bdo=r(y4t,"GPTJConfig"),y4t.forEach(t),Ido=r(EPe," (GPT-J model)"),EPe.forEach(t),Ndo=i(L),Cg=n(L,"LI",{});var CPe=s(Cg);bce=n(CPe,"STRONG",{});var x4t=s(bce);qdo=r(x4t,"groupvit"),x4t.forEach(t),jdo=r(CPe," \u2014 "),lN=n(CPe,"A",{href:!0});var $4t=s(lN);Ddo=r($4t,"GroupViTConfig"),$4t.forEach(t),Gdo=r(CPe," (GroupViT model)"),CPe.forEach(t),Odo=i(L),wg=n(L,"LI",{});var wPe=s(wg);vce=n(wPe,"STRONG",{});var k4t=s(vce);Vdo=r(k4t,"hubert"),k4t.forEach(t),Xdo=r(wPe," \u2014 "),iN=n(wPe,"A",{href:!0});var S4t=s(iN);zdo=r(S4t,"HubertConfig"),S4t.forEach(t),Qdo=r(wPe," (Hubert model)"),wPe.forEach(t),Wdo=i(L),Ag=n(L,"LI",{});var APe=s(Ag);Fce=n(APe,"STRONG",{});var R4t=s(Fce);Udo=r(R4t,"ibert"),R4t.forEach(t),Hdo=r(APe," \u2014 "),dN=n(APe,"A",{href:!0});var P4t=s(dN);Jdo=r(P4t,"IBertConfig"),P4t.forEach(t),Ydo=r(APe," (I-BERT model)"),APe.forEach(t),Kdo=i(L),Lg=n(L,"LI",{});var LPe=s(Lg);Tce=n(LPe,"STRONG",{});var B4t=s(Tce);Zdo=r(B4t,"imagegpt"),B4t.forEach(t),emo=r(LPe," \u2014 "),mN=n(LPe,"A",{href:!0});var I4t=s(mN);omo=r(I4t,"ImageGPTConfig"),I4t.forEach(t),rmo=r(LPe," (ImageGPT model)"),LPe.forEach(t),tmo=i(L),yg=n(L,"LI",{});var yPe=s(yg);Mce=n(yPe,"STRONG",{});var N4t=s(Mce);amo=r(N4t,"layoutlm"),N4t.forEach(t),nmo=r(yPe," \u2014 "),cN=n(yPe,"A",{href:!0});var q4t=s(cN);smo=r(q4t,"LayoutLMConfig"),q4t.forEach(t),lmo=r(yPe," (LayoutLM model)"),yPe.forEach(t),imo=i(L),xg=n(L,"LI",{});var xPe=s(xg);Ece=n(xPe,"STRONG",{});var j4t=s(Ece);dmo=r(j4t,"layoutlmv2"),j4t.forEach(t),mmo=r(xPe," \u2014 "),fN=n(xPe,"A",{href:!0});var D4t=s(fN);cmo=r(D4t,"LayoutLMv2Config"),D4t.forEach(t),fmo=r(xPe," (LayoutLMv2 model)"),xPe.forEach(t),gmo=i(L),$g=n(L,"LI",{});var $Pe=s($g);Cce=n($Pe,"STRONG",{});var G4t=s(Cce);hmo=r(G4t,"layoutlmv3"),G4t.forEach(t),umo=r($Pe," \u2014 "),gN=n($Pe,"A",{href:!0});var O4t=s(gN);pmo=r(O4t,"LayoutLMv3Config"),O4t.forEach(t),_mo=r($Pe," (LayoutLMv3 model)"),$Pe.forEach(t),bmo=i(L),kg=n(L,"LI",{});var kPe=s(kg);wce=n(kPe,"STRONG",{});var V4t=s(wce);vmo=r(V4t,"led"),V4t.forEach(t),Fmo=r(kPe," \u2014 "),hN=n(kPe,"A",{href:!0});var X4t=s(hN);Tmo=r(X4t,"LEDConfig"),X4t.forEach(t),Mmo=r(kPe," (LED model)"),kPe.forEach(t),Emo=i(L),Sg=n(L,"LI",{});var SPe=s(Sg);Ace=n(SPe,"STRONG",{});var z4t=s(Ace);Cmo=r(z4t,"levit"),z4t.forEach(t),wmo=r(SPe," \u2014 "),uN=n(SPe,"A",{href:!0});var Q4t=s(uN);Amo=r(Q4t,"LevitConfig"),Q4t.forEach(t),Lmo=r(SPe," (LeViT model)"),SPe.forEach(t),ymo=i(L),Rg=n(L,"LI",{});var RPe=s(Rg);Lce=n(RPe,"STRONG",{});var W4t=s(Lce);xmo=r(W4t,"longformer"),W4t.forEach(t),$mo=r(RPe," \u2014 "),pN=n(RPe,"A",{href:!0});var U4t=s(pN);kmo=r(U4t,"LongformerConfig"),U4t.forEach(t),Smo=r(RPe," (Longformer model)"),RPe.forEach(t),Rmo=i(L),Pg=n(L,"LI",{});var PPe=s(Pg);yce=n(PPe,"STRONG",{});var H4t=s(yce);Pmo=r(H4t,"longt5"),H4t.forEach(t),Bmo=r(PPe," \u2014 "),_N=n(PPe,"A",{href:!0});var J4t=s(_N);Imo=r(J4t,"LongT5Config"),J4t.forEach(t),Nmo=r(PPe," (LongT5 model)"),PPe.forEach(t),qmo=i(L),Bg=n(L,"LI",{});var BPe=s(Bg);xce=n(BPe,"STRONG",{});var Y4t=s(xce);jmo=r(Y4t,"luke"),Y4t.forEach(t),Dmo=r(BPe," \u2014 "),bN=n(BPe,"A",{href:!0});var K4t=s(bN);Gmo=r(K4t,"LukeConfig"),K4t.forEach(t),Omo=r(BPe," (LUKE model)"),BPe.forEach(t),Vmo=i(L),Ig=n(L,"LI",{});var IPe=s(Ig);$ce=n(IPe,"STRONG",{});var Z4t=s($ce);Xmo=r(Z4t,"lxmert"),Z4t.forEach(t),zmo=r(IPe," \u2014 "),vN=n(IPe,"A",{href:!0});var eCt=s(vN);Qmo=r(eCt,"LxmertConfig"),eCt.forEach(t),Wmo=r(IPe," (LXMERT model)"),IPe.forEach(t),Umo=i(L),Ng=n(L,"LI",{});var NPe=s(Ng);kce=n(NPe,"STRONG",{});var oCt=s(kce);Hmo=r(oCt,"m2m_100"),oCt.forEach(t),Jmo=r(NPe," \u2014 "),FN=n(NPe,"A",{href:!0});var rCt=s(FN);Ymo=r(rCt,"M2M100Config"),rCt.forEach(t),Kmo=r(NPe," (M2M100 model)"),NPe.forEach(t),Zmo=i(L),qg=n(L,"LI",{});var qPe=s(qg);Sce=n(qPe,"STRONG",{});var tCt=s(Sce);eco=r(tCt,"marian"),tCt.forEach(t),oco=r(qPe," \u2014 "),TN=n(qPe,"A",{href:!0});var aCt=s(TN);rco=r(aCt,"MarianConfig"),aCt.forEach(t),tco=r(qPe," (Marian model)"),qPe.forEach(t),aco=i(L),jg=n(L,"LI",{});var jPe=s(jg);Rce=n(jPe,"STRONG",{});var nCt=s(Rce);nco=r(nCt,"markuplm"),nCt.forEach(t),sco=r(jPe," \u2014 "),MN=n(jPe,"A",{href:!0});var sCt=s(MN);lco=r(sCt,"MarkupLMConfig"),sCt.forEach(t),ico=r(jPe," (MarkupLM model)"),jPe.forEach(t),dco=i(L),Dg=n(L,"LI",{});var DPe=s(Dg);Pce=n(DPe,"STRONG",{});var lCt=s(Pce);mco=r(lCt,"maskformer"),lCt.forEach(t),cco=r(DPe," \u2014 "),EN=n(DPe,"A",{href:!0});var iCt=s(EN);fco=r(iCt,"MaskFormerConfig"),iCt.forEach(t),gco=r(DPe," (MaskFormer model)"),DPe.forEach(t),hco=i(L),Gg=n(L,"LI",{});var GPe=s(Gg);Bce=n(GPe,"STRONG",{});var dCt=s(Bce);uco=r(dCt,"mbart"),dCt.forEach(t),pco=r(GPe," \u2014 "),CN=n(GPe,"A",{href:!0});var mCt=s(CN);_co=r(mCt,"MBartConfig"),mCt.forEach(t),bco=r(GPe," (mBART model)"),GPe.forEach(t),vco=i(L),Og=n(L,"LI",{});var OPe=s(Og);Ice=n(OPe,"STRONG",{});var cCt=s(Ice);Fco=r(cCt,"mctct"),cCt.forEach(t),Tco=r(OPe," \u2014 "),wN=n(OPe,"A",{href:!0});var fCt=s(wN);Mco=r(fCt,"MCTCTConfig"),fCt.forEach(t),Eco=r(OPe," (M-CTC-T model)"),OPe.forEach(t),Cco=i(L),Vg=n(L,"LI",{});var VPe=s(Vg);Nce=n(VPe,"STRONG",{});var gCt=s(Nce);wco=r(gCt,"megatron-bert"),gCt.forEach(t),Aco=r(VPe," \u2014 "),AN=n(VPe,"A",{href:!0});var hCt=s(AN);Lco=r(hCt,"MegatronBertConfig"),hCt.forEach(t),yco=r(VPe," (Megatron-BERT model)"),VPe.forEach(t),xco=i(L),Xg=n(L,"LI",{});var XPe=s(Xg);qce=n(XPe,"STRONG",{});var uCt=s(qce);$co=r(uCt,"mobilebert"),uCt.forEach(t),kco=r(XPe," \u2014 "),LN=n(XPe,"A",{href:!0});var pCt=s(LN);Sco=r(pCt,"MobileBertConfig"),pCt.forEach(t),Rco=r(XPe," (MobileBERT model)"),XPe.forEach(t),Pco=i(L),zg=n(L,"LI",{});var zPe=s(zg);jce=n(zPe,"STRONG",{});var _Ct=s(jce);Bco=r(_Ct,"mobilevit"),_Ct.forEach(t),Ico=r(zPe," \u2014 "),yN=n(zPe,"A",{href:!0});var bCt=s(yN);Nco=r(bCt,"MobileViTConfig"),bCt.forEach(t),qco=r(zPe," (MobileViT model)"),zPe.forEach(t),jco=i(L),Qg=n(L,"LI",{});var QPe=s(Qg);Dce=n(QPe,"STRONG",{});var vCt=s(Dce);Dco=r(vCt,"mpnet"),vCt.forEach(t),Gco=r(QPe," \u2014 "),xN=n(QPe,"A",{href:!0});var FCt=s(xN);Oco=r(FCt,"MPNetConfig"),FCt.forEach(t),Vco=r(QPe," (MPNet model)"),QPe.forEach(t),Xco=i(L),Wg=n(L,"LI",{});var WPe=s(Wg);Gce=n(WPe,"STRONG",{});var TCt=s(Gce);zco=r(TCt,"mt5"),TCt.forEach(t),Qco=r(WPe," \u2014 "),$N=n(WPe,"A",{href:!0});var MCt=s($N);Wco=r(MCt,"MT5Config"),MCt.forEach(t),Uco=r(WPe," (MT5 model)"),WPe.forEach(t),Hco=i(L),Ug=n(L,"LI",{});var UPe=s(Ug);Oce=n(UPe,"STRONG",{});var ECt=s(Oce);Jco=r(ECt,"mvp"),ECt.forEach(t),Yco=r(UPe," \u2014 "),kN=n(UPe,"A",{href:!0});var CCt=s(kN);Kco=r(CCt,"MvpConfig"),CCt.forEach(t),Zco=r(UPe," (MVP model)"),UPe.forEach(t),efo=i(L),Hg=n(L,"LI",{});var HPe=s(Hg);Vce=n(HPe,"STRONG",{});var wCt=s(Vce);ofo=r(wCt,"nezha"),wCt.forEach(t),rfo=r(HPe," \u2014 "),SN=n(HPe,"A",{href:!0});var ACt=s(SN);tfo=r(ACt,"NezhaConfig"),ACt.forEach(t),afo=r(HPe," (Nezha model)"),HPe.forEach(t),nfo=i(L),Jg=n(L,"LI",{});var JPe=s(Jg);Xce=n(JPe,"STRONG",{});var LCt=s(Xce);sfo=r(LCt,"nystromformer"),LCt.forEach(t),lfo=r(JPe," \u2014 "),RN=n(JPe,"A",{href:!0});var yCt=s(RN);ifo=r(yCt,"NystromformerConfig"),yCt.forEach(t),dfo=r(JPe," (Nystr\xF6mformer model)"),JPe.forEach(t),mfo=i(L),Yg=n(L,"LI",{});var YPe=s(Yg);zce=n(YPe,"STRONG",{});var xCt=s(zce);cfo=r(xCt,"openai-gpt"),xCt.forEach(t),ffo=r(YPe," \u2014 "),PN=n(YPe,"A",{href:!0});var $Ct=s(PN);gfo=r($Ct,"OpenAIGPTConfig"),$Ct.forEach(t),hfo=r(YPe," (OpenAI GPT model)"),YPe.forEach(t),ufo=i(L),Kg=n(L,"LI",{});var KPe=s(Kg);Qce=n(KPe,"STRONG",{});var kCt=s(Qce);pfo=r(kCt,"opt"),kCt.forEach(t),_fo=r(KPe," \u2014 "),BN=n(KPe,"A",{href:!0});var SCt=s(BN);bfo=r(SCt,"OPTConfig"),SCt.forEach(t),vfo=r(KPe," (OPT model)"),KPe.forEach(t),Ffo=i(L),Zg=n(L,"LI",{});var ZPe=s(Zg);Wce=n(ZPe,"STRONG",{});var RCt=s(Wce);Tfo=r(RCt,"owlvit"),RCt.forEach(t),Mfo=r(ZPe," \u2014 "),IN=n(ZPe,"A",{href:!0});var PCt=s(IN);Efo=r(PCt,"OwlViTConfig"),PCt.forEach(t),Cfo=r(ZPe," (OWL-ViT model)"),ZPe.forEach(t),wfo=i(L),eh=n(L,"LI",{});var eBe=s(eh);Uce=n(eBe,"STRONG",{});var BCt=s(Uce);Afo=r(BCt,"pegasus"),BCt.forEach(t),Lfo=r(eBe," \u2014 "),NN=n(eBe,"A",{href:!0});var ICt=s(NN);yfo=r(ICt,"PegasusConfig"),ICt.forEach(t),xfo=r(eBe," (Pegasus model)"),eBe.forEach(t),$fo=i(L),oh=n(L,"LI",{});var oBe=s(oh);Hce=n(oBe,"STRONG",{});var NCt=s(Hce);kfo=r(NCt,"pegasus_x"),NCt.forEach(t),Sfo=r(oBe," \u2014 "),qN=n(oBe,"A",{href:!0});var qCt=s(qN);Rfo=r(qCt,"PegasusXConfig"),qCt.forEach(t),Pfo=r(oBe," (PEGASUS-X model)"),oBe.forEach(t),Bfo=i(L),rh=n(L,"LI",{});var rBe=s(rh);Jce=n(rBe,"STRONG",{});var jCt=s(Jce);Ifo=r(jCt,"perceiver"),jCt.forEach(t),Nfo=r(rBe," \u2014 "),jN=n(rBe,"A",{href:!0});var DCt=s(jN);qfo=r(DCt,"PerceiverConfig"),DCt.forEach(t),jfo=r(rBe," (Perceiver model)"),rBe.forEach(t),Dfo=i(L),th=n(L,"LI",{});var tBe=s(th);Yce=n(tBe,"STRONG",{});var GCt=s(Yce);Gfo=r(GCt,"plbart"),GCt.forEach(t),Ofo=r(tBe," \u2014 "),DN=n(tBe,"A",{href:!0});var OCt=s(DN);Vfo=r(OCt,"PLBartConfig"),OCt.forEach(t),Xfo=r(tBe," (PLBart model)"),tBe.forEach(t),zfo=i(L),ah=n(L,"LI",{});var aBe=s(ah);Kce=n(aBe,"STRONG",{});var VCt=s(Kce);Qfo=r(VCt,"poolformer"),VCt.forEach(t),Wfo=r(aBe," \u2014 "),GN=n(aBe,"A",{href:!0});var XCt=s(GN);Ufo=r(XCt,"PoolFormerConfig"),XCt.forEach(t),Hfo=r(aBe," (PoolFormer model)"),aBe.forEach(t),Jfo=i(L),nh=n(L,"LI",{});var nBe=s(nh);Zce=n(nBe,"STRONG",{});var zCt=s(Zce);Yfo=r(zCt,"prophetnet"),zCt.forEach(t),Kfo=r(nBe," \u2014 "),ON=n(nBe,"A",{href:!0});var QCt=s(ON);Zfo=r(QCt,"ProphetNetConfig"),QCt.forEach(t),ego=r(nBe," (ProphetNet model)"),nBe.forEach(t),ogo=i(L),sh=n(L,"LI",{});var sBe=s(sh);efe=n(sBe,"STRONG",{});var WCt=s(efe);rgo=r(WCt,"qdqbert"),WCt.forEach(t),tgo=r(sBe," \u2014 "),VN=n(sBe,"A",{href:!0});var UCt=s(VN);ago=r(UCt,"QDQBertConfig"),UCt.forEach(t),ngo=r(sBe," (QDQBert model)"),sBe.forEach(t),sgo=i(L),lh=n(L,"LI",{});var lBe=s(lh);ofe=n(lBe,"STRONG",{});var HCt=s(ofe);lgo=r(HCt,"rag"),HCt.forEach(t),igo=r(lBe," \u2014 "),XN=n(lBe,"A",{href:!0});var JCt=s(XN);dgo=r(JCt,"RagConfig"),JCt.forEach(t),mgo=r(lBe," (RAG model)"),lBe.forEach(t),cgo=i(L),ih=n(L,"LI",{});var iBe=s(ih);rfe=n(iBe,"STRONG",{});var YCt=s(rfe);fgo=r(YCt,"realm"),YCt.forEach(t),ggo=r(iBe," \u2014 "),zN=n(iBe,"A",{href:!0});var KCt=s(zN);hgo=r(KCt,"RealmConfig"),KCt.forEach(t),ugo=r(iBe," (REALM model)"),iBe.forEach(t),pgo=i(L),dh=n(L,"LI",{});var dBe=s(dh);tfe=n(dBe,"STRONG",{});var ZCt=s(tfe);_go=r(ZCt,"reformer"),ZCt.forEach(t),bgo=r(dBe," \u2014 "),QN=n(dBe,"A",{href:!0});var e3t=s(QN);vgo=r(e3t,"ReformerConfig"),e3t.forEach(t),Fgo=r(dBe," (Reformer model)"),dBe.forEach(t),Tgo=i(L),mh=n(L,"LI",{});var mBe=s(mh);afe=n(mBe,"STRONG",{});var o3t=s(afe);Mgo=r(o3t,"regnet"),o3t.forEach(t),Ego=r(mBe," \u2014 "),WN=n(mBe,"A",{href:!0});var r3t=s(WN);Cgo=r(r3t,"RegNetConfig"),r3t.forEach(t),wgo=r(mBe," (RegNet model)"),mBe.forEach(t),Ago=i(L),ch=n(L,"LI",{});var cBe=s(ch);nfe=n(cBe,"STRONG",{});var t3t=s(nfe);Lgo=r(t3t,"rembert"),t3t.forEach(t),ygo=r(cBe," \u2014 "),UN=n(cBe,"A",{href:!0});var a3t=s(UN);xgo=r(a3t,"RemBertConfig"),a3t.forEach(t),$go=r(cBe," (RemBERT model)"),cBe.forEach(t),kgo=i(L),fh=n(L,"LI",{});var fBe=s(fh);sfe=n(fBe,"STRONG",{});var n3t=s(sfe);Sgo=r(n3t,"resnet"),n3t.forEach(t),Rgo=r(fBe," \u2014 "),HN=n(fBe,"A",{href:!0});var s3t=s(HN);Pgo=r(s3t,"ResNetConfig"),s3t.forEach(t),Bgo=r(fBe," (ResNet model)"),fBe.forEach(t),Igo=i(L),gh=n(L,"LI",{});var gBe=s(gh);lfe=n(gBe,"STRONG",{});var l3t=s(lfe);Ngo=r(l3t,"retribert"),l3t.forEach(t),qgo=r(gBe," \u2014 "),JN=n(gBe,"A",{href:!0});var i3t=s(JN);jgo=r(i3t,"RetriBertConfig"),i3t.forEach(t),Dgo=r(gBe," (RetriBERT model)"),gBe.forEach(t),Ggo=i(L),hh=n(L,"LI",{});var hBe=s(hh);ife=n(hBe,"STRONG",{});var d3t=s(ife);Ogo=r(d3t,"roberta"),d3t.forEach(t),Vgo=r(hBe," \u2014 "),YN=n(hBe,"A",{href:!0});var m3t=s(YN);Xgo=r(m3t,"RobertaConfig"),m3t.forEach(t),zgo=r(hBe," (RoBERTa model)"),hBe.forEach(t),Qgo=i(L),uh=n(L,"LI",{});var uBe=s(uh);dfe=n(uBe,"STRONG",{});var c3t=s(dfe);Wgo=r(c3t,"roformer"),c3t.forEach(t),Ugo=r(uBe," \u2014 "),KN=n(uBe,"A",{href:!0});var f3t=s(KN);Hgo=r(f3t,"RoFormerConfig"),f3t.forEach(t),Jgo=r(uBe," (RoFormer model)"),uBe.forEach(t),Ygo=i(L),ph=n(L,"LI",{});var pBe=s(ph);mfe=n(pBe,"STRONG",{});var g3t=s(mfe);Kgo=r(g3t,"segformer"),g3t.forEach(t),Zgo=r(pBe," \u2014 "),ZN=n(pBe,"A",{href:!0});var h3t=s(ZN);eho=r(h3t,"SegformerConfig"),h3t.forEach(t),oho=r(pBe," (SegFormer model)"),pBe.forEach(t),rho=i(L),_h=n(L,"LI",{});var _Be=s(_h);cfe=n(_Be,"STRONG",{});var u3t=s(cfe);tho=r(u3t,"sew"),u3t.forEach(t),aho=r(_Be," \u2014 "),eq=n(_Be,"A",{href:!0});var p3t=s(eq);nho=r(p3t,"SEWConfig"),p3t.forEach(t),sho=r(_Be," (SEW model)"),_Be.forEach(t),lho=i(L),bh=n(L,"LI",{});var bBe=s(bh);ffe=n(bBe,"STRONG",{});var _3t=s(ffe);iho=r(_3t,"sew-d"),_3t.forEach(t),dho=r(bBe," \u2014 "),oq=n(bBe,"A",{href:!0});var b3t=s(oq);mho=r(b3t,"SEWDConfig"),b3t.forEach(t),cho=r(bBe," (SEW-D model)"),bBe.forEach(t),fho=i(L),vh=n(L,"LI",{});var vBe=s(vh);gfe=n(vBe,"STRONG",{});var v3t=s(gfe);gho=r(v3t,"speech-encoder-decoder"),v3t.forEach(t),hho=r(vBe," \u2014 "),rq=n(vBe,"A",{href:!0});var F3t=s(rq);uho=r(F3t,"SpeechEncoderDecoderConfig"),F3t.forEach(t),pho=r(vBe," (Speech Encoder decoder model)"),vBe.forEach(t),_ho=i(L),Fh=n(L,"LI",{});var FBe=s(Fh);hfe=n(FBe,"STRONG",{});var T3t=s(hfe);bho=r(T3t,"speech_to_text"),T3t.forEach(t),vho=r(FBe," \u2014 "),tq=n(FBe,"A",{href:!0});var M3t=s(tq);Fho=r(M3t,"Speech2TextConfig"),M3t.forEach(t),Tho=r(FBe," (Speech2Text model)"),FBe.forEach(t),Mho=i(L),Th=n(L,"LI",{});var TBe=s(Th);ufe=n(TBe,"STRONG",{});var E3t=s(ufe);Eho=r(E3t,"speech_to_text_2"),E3t.forEach(t),Cho=r(TBe," \u2014 "),aq=n(TBe,"A",{href:!0});var C3t=s(aq);who=r(C3t,"Speech2Text2Config"),C3t.forEach(t),Aho=r(TBe," (Speech2Text2 model)"),TBe.forEach(t),Lho=i(L),Mh=n(L,"LI",{});var MBe=s(Mh);pfe=n(MBe,"STRONG",{});var w3t=s(pfe);yho=r(w3t,"splinter"),w3t.forEach(t),xho=r(MBe," \u2014 "),nq=n(MBe,"A",{href:!0});var A3t=s(nq);$ho=r(A3t,"SplinterConfig"),A3t.forEach(t),kho=r(MBe," (Splinter model)"),MBe.forEach(t),Sho=i(L),Eh=n(L,"LI",{});var EBe=s(Eh);_fe=n(EBe,"STRONG",{});var L3t=s(_fe);Rho=r(L3t,"squeezebert"),L3t.forEach(t),Pho=r(EBe," \u2014 "),sq=n(EBe,"A",{href:!0});var y3t=s(sq);Bho=r(y3t,"SqueezeBertConfig"),y3t.forEach(t),Iho=r(EBe," (SqueezeBERT model)"),EBe.forEach(t),Nho=i(L),Ch=n(L,"LI",{});var CBe=s(Ch);bfe=n(CBe,"STRONG",{});var x3t=s(bfe);qho=r(x3t,"swin"),x3t.forEach(t),jho=r(CBe," \u2014 "),lq=n(CBe,"A",{href:!0});var $3t=s(lq);Dho=r($3t,"SwinConfig"),$3t.forEach(t),Gho=r(CBe," (Swin Transformer model)"),CBe.forEach(t),Oho=i(L),wh=n(L,"LI",{});var wBe=s(wh);vfe=n(wBe,"STRONG",{});var k3t=s(vfe);Vho=r(k3t,"swinv2"),k3t.forEach(t),Xho=r(wBe," \u2014 "),iq=n(wBe,"A",{href:!0});var S3t=s(iq);zho=r(S3t,"Swinv2Config"),S3t.forEach(t),Qho=r(wBe," (Swin Transformer V2 model)"),wBe.forEach(t),Who=i(L),Ah=n(L,"LI",{});var ABe=s(Ah);Ffe=n(ABe,"STRONG",{});var R3t=s(Ffe);Uho=r(R3t,"t5"),R3t.forEach(t),Hho=r(ABe," \u2014 "),dq=n(ABe,"A",{href:!0});var P3t=s(dq);Jho=r(P3t,"T5Config"),P3t.forEach(t),Yho=r(ABe," (T5 model)"),ABe.forEach(t),Kho=i(L),Lh=n(L,"LI",{});var LBe=s(Lh);Tfe=n(LBe,"STRONG",{});var B3t=s(Tfe);Zho=r(B3t,"tapas"),B3t.forEach(t),euo=r(LBe," \u2014 "),mq=n(LBe,"A",{href:!0});var I3t=s(mq);ouo=r(I3t,"TapasConfig"),I3t.forEach(t),ruo=r(LBe," (TAPAS model)"),LBe.forEach(t),tuo=i(L),yh=n(L,"LI",{});var yBe=s(yh);Mfe=n(yBe,"STRONG",{});var N3t=s(Mfe);auo=r(N3t,"time_series_transformer"),N3t.forEach(t),nuo=r(yBe," \u2014 "),cq=n(yBe,"A",{href:!0});var q3t=s(cq);suo=r(q3t,"TimeSeriesTransformerConfig"),q3t.forEach(t),luo=r(yBe," (Time Series Transformer model)"),yBe.forEach(t),iuo=i(L),xh=n(L,"LI",{});var xBe=s(xh);Efe=n(xBe,"STRONG",{});var j3t=s(Efe);duo=r(j3t,"trajectory_transformer"),j3t.forEach(t),muo=r(xBe," \u2014 "),fq=n(xBe,"A",{href:!0});var D3t=s(fq);cuo=r(D3t,"TrajectoryTransformerConfig"),D3t.forEach(t),fuo=r(xBe," (Trajectory Transformer model)"),xBe.forEach(t),guo=i(L),$h=n(L,"LI",{});var $Be=s($h);Cfe=n($Be,"STRONG",{});var G3t=s(Cfe);huo=r(G3t,"transfo-xl"),G3t.forEach(t),uuo=r($Be," \u2014 "),gq=n($Be,"A",{href:!0});var O3t=s(gq);puo=r(O3t,"TransfoXLConfig"),O3t.forEach(t),_uo=r($Be," (Transformer-XL model)"),$Be.forEach(t),buo=i(L),kh=n(L,"LI",{});var kBe=s(kh);wfe=n(kBe,"STRONG",{});var V3t=s(wfe);vuo=r(V3t,"trocr"),V3t.forEach(t),Fuo=r(kBe," \u2014 "),hq=n(kBe,"A",{href:!0});var X3t=s(hq);Tuo=r(X3t,"TrOCRConfig"),X3t.forEach(t),Muo=r(kBe," (TrOCR model)"),kBe.forEach(t),Euo=i(L),Sh=n(L,"LI",{});var SBe=s(Sh);Afe=n(SBe,"STRONG",{});var z3t=s(Afe);Cuo=r(z3t,"unispeech"),z3t.forEach(t),wuo=r(SBe," \u2014 "),uq=n(SBe,"A",{href:!0});var Q3t=s(uq);Auo=r(Q3t,"UniSpeechConfig"),Q3t.forEach(t),Luo=r(SBe," (UniSpeech model)"),SBe.forEach(t),yuo=i(L),Rh=n(L,"LI",{});var RBe=s(Rh);Lfe=n(RBe,"STRONG",{});var W3t=s(Lfe);xuo=r(W3t,"unispeech-sat"),W3t.forEach(t),$uo=r(RBe," \u2014 "),pq=n(RBe,"A",{href:!0});var U3t=s(pq);kuo=r(U3t,"UniSpeechSatConfig"),U3t.forEach(t),Suo=r(RBe," (UniSpeechSat model)"),RBe.forEach(t),Ruo=i(L),Ph=n(L,"LI",{});var PBe=s(Ph);yfe=n(PBe,"STRONG",{});var H3t=s(yfe);Puo=r(H3t,"van"),H3t.forEach(t),Buo=r(PBe," \u2014 "),_q=n(PBe,"A",{href:!0});var J3t=s(_q);Iuo=r(J3t,"VanConfig"),J3t.forEach(t),Nuo=r(PBe," (VAN model)"),PBe.forEach(t),quo=i(L),Bh=n(L,"LI",{});var BBe=s(Bh);xfe=n(BBe,"STRONG",{});var Y3t=s(xfe);juo=r(Y3t,"videomae"),Y3t.forEach(t),Duo=r(BBe," \u2014 "),bq=n(BBe,"A",{href:!0});var K3t=s(bq);Guo=r(K3t,"VideoMAEConfig"),K3t.forEach(t),Ouo=r(BBe," (VideoMAE model)"),BBe.forEach(t),Vuo=i(L),Ih=n(L,"LI",{});var IBe=s(Ih);$fe=n(IBe,"STRONG",{});var Z3t=s($fe);Xuo=r(Z3t,"vilt"),Z3t.forEach(t),zuo=r(IBe," \u2014 "),vq=n(IBe,"A",{href:!0});var e5t=s(vq);Quo=r(e5t,"ViltConfig"),e5t.forEach(t),Wuo=r(IBe," (ViLT model)"),IBe.forEach(t),Uuo=i(L),Nh=n(L,"LI",{});var NBe=s(Nh);kfe=n(NBe,"STRONG",{});var o5t=s(kfe);Huo=r(o5t,"vision-encoder-decoder"),o5t.forEach(t),Juo=r(NBe," \u2014 "),Fq=n(NBe,"A",{href:!0});var r5t=s(Fq);Yuo=r(r5t,"VisionEncoderDecoderConfig"),r5t.forEach(t),Kuo=r(NBe," (Vision Encoder decoder model)"),NBe.forEach(t),Zuo=i(L),qh=n(L,"LI",{});var qBe=s(qh);Sfe=n(qBe,"STRONG",{});var t5t=s(Sfe);epo=r(t5t,"vision-text-dual-encoder"),t5t.forEach(t),opo=r(qBe," \u2014 "),Tq=n(qBe,"A",{href:!0});var a5t=s(Tq);rpo=r(a5t,"VisionTextDualEncoderConfig"),a5t.forEach(t),tpo=r(qBe," (VisionTextDualEncoder model)"),qBe.forEach(t),apo=i(L),jh=n(L,"LI",{});var jBe=s(jh);Rfe=n(jBe,"STRONG",{});var n5t=s(Rfe);npo=r(n5t,"visual_bert"),n5t.forEach(t),spo=r(jBe," \u2014 "),Mq=n(jBe,"A",{href:!0});var s5t=s(Mq);lpo=r(s5t,"VisualBertConfig"),s5t.forEach(t),ipo=r(jBe," (VisualBERT model)"),jBe.forEach(t),dpo=i(L),Dh=n(L,"LI",{});var DBe=s(Dh);Pfe=n(DBe,"STRONG",{});var l5t=s(Pfe);mpo=r(l5t,"vit"),l5t.forEach(t),cpo=r(DBe," \u2014 "),Eq=n(DBe,"A",{href:!0});var i5t=s(Eq);fpo=r(i5t,"ViTConfig"),i5t.forEach(t),gpo=r(DBe," (ViT model)"),DBe.forEach(t),hpo=i(L),Gh=n(L,"LI",{});var GBe=s(Gh);Bfe=n(GBe,"STRONG",{});var d5t=s(Bfe);upo=r(d5t,"vit_mae"),d5t.forEach(t),ppo=r(GBe," \u2014 "),Cq=n(GBe,"A",{href:!0});var m5t=s(Cq);_po=r(m5t,"ViTMAEConfig"),m5t.forEach(t),bpo=r(GBe," (ViTMAE model)"),GBe.forEach(t),vpo=i(L),Oh=n(L,"LI",{});var OBe=s(Oh);Ife=n(OBe,"STRONG",{});var c5t=s(Ife);Fpo=r(c5t,"vit_msn"),c5t.forEach(t),Tpo=r(OBe," \u2014 "),wq=n(OBe,"A",{href:!0});var f5t=s(wq);Mpo=r(f5t,"ViTMSNConfig"),f5t.forEach(t),Epo=r(OBe," (ViTMSN model)"),OBe.forEach(t),Cpo=i(L),Vh=n(L,"LI",{});var VBe=s(Vh);Nfe=n(VBe,"STRONG",{});var g5t=s(Nfe);wpo=r(g5t,"wav2vec2"),g5t.forEach(t),Apo=r(VBe," \u2014 "),Aq=n(VBe,"A",{href:!0});var h5t=s(Aq);Lpo=r(h5t,"Wav2Vec2Config"),h5t.forEach(t),ypo=r(VBe," (Wav2Vec2 model)"),VBe.forEach(t),xpo=i(L),Xh=n(L,"LI",{});var XBe=s(Xh);qfe=n(XBe,"STRONG",{});var u5t=s(qfe);$po=r(u5t,"wav2vec2-conformer"),u5t.forEach(t),kpo=r(XBe," \u2014 "),Lq=n(XBe,"A",{href:!0});var p5t=s(Lq);Spo=r(p5t,"Wav2Vec2ConformerConfig"),p5t.forEach(t),Rpo=r(XBe," (Wav2Vec2-Conformer model)"),XBe.forEach(t),Ppo=i(L),zh=n(L,"LI",{});var zBe=s(zh);jfe=n(zBe,"STRONG",{});var _5t=s(jfe);Bpo=r(_5t,"wavlm"),_5t.forEach(t),Ipo=r(zBe," \u2014 "),yq=n(zBe,"A",{href:!0});var b5t=s(yq);Npo=r(b5t,"WavLMConfig"),b5t.forEach(t),qpo=r(zBe," (WavLM model)"),zBe.forEach(t),jpo=i(L),Qh=n(L,"LI",{});var QBe=s(Qh);Dfe=n(QBe,"STRONG",{});var v5t=s(Dfe);Dpo=r(v5t,"whisper"),v5t.forEach(t),Gpo=r(QBe," \u2014 "),xq=n(QBe,"A",{href:!0});var F5t=s(xq);Opo=r(F5t,"WhisperConfig"),F5t.forEach(t),Vpo=r(QBe," (Whisper model)"),QBe.forEach(t),Xpo=i(L),Wh=n(L,"LI",{});var WBe=s(Wh);Gfe=n(WBe,"STRONG",{});var T5t=s(Gfe);zpo=r(T5t,"xclip"),T5t.forEach(t),Qpo=r(WBe," \u2014 "),$q=n(WBe,"A",{href:!0});var M5t=s($q);Wpo=r(M5t,"XCLIPConfig"),M5t.forEach(t),Upo=r(WBe," (X-CLIP model)"),WBe.forEach(t),Hpo=i(L),Uh=n(L,"LI",{});var UBe=s(Uh);Ofe=n(UBe,"STRONG",{});var E5t=s(Ofe);Jpo=r(E5t,"xglm"),E5t.forEach(t),Ypo=r(UBe," \u2014 "),kq=n(UBe,"A",{href:!0});var C5t=s(kq);Kpo=r(C5t,"XGLMConfig"),C5t.forEach(t),Zpo=r(UBe," (XGLM model)"),UBe.forEach(t),e_o=i(L),Hh=n(L,"LI",{});var HBe=s(Hh);Vfe=n(HBe,"STRONG",{});var w5t=s(Vfe);o_o=r(w5t,"xlm"),w5t.forEach(t),r_o=r(HBe," \u2014 "),Sq=n(HBe,"A",{href:!0});var A5t=s(Sq);t_o=r(A5t,"XLMConfig"),A5t.forEach(t),a_o=r(HBe," (XLM model)"),HBe.forEach(t),n_o=i(L),Jh=n(L,"LI",{});var JBe=s(Jh);Xfe=n(JBe,"STRONG",{});var L5t=s(Xfe);s_o=r(L5t,"xlm-prophetnet"),L5t.forEach(t),l_o=r(JBe," \u2014 "),Rq=n(JBe,"A",{href:!0});var y5t=s(Rq);i_o=r(y5t,"XLMProphetNetConfig"),y5t.forEach(t),d_o=r(JBe," (XLM-ProphetNet model)"),JBe.forEach(t),m_o=i(L),Yh=n(L,"LI",{});var YBe=s(Yh);zfe=n(YBe,"STRONG",{});var x5t=s(zfe);c_o=r(x5t,"xlm-roberta"),x5t.forEach(t),f_o=r(YBe," \u2014 "),Pq=n(YBe,"A",{href:!0});var $5t=s(Pq);g_o=r($5t,"XLMRobertaConfig"),$5t.forEach(t),h_o=r(YBe," (XLM-RoBERTa model)"),YBe.forEach(t),u_o=i(L),Kh=n(L,"LI",{});var KBe=s(Kh);Qfe=n(KBe,"STRONG",{});var k5t=s(Qfe);p_o=r(k5t,"xlm-roberta-xl"),k5t.forEach(t),__o=r(KBe," \u2014 "),Bq=n(KBe,"A",{href:!0});var S5t=s(Bq);b_o=r(S5t,"XLMRobertaXLConfig"),S5t.forEach(t),v_o=r(KBe," (XLM-RoBERTa-XL model)"),KBe.forEach(t),F_o=i(L),Zh=n(L,"LI",{});var ZBe=s(Zh);Wfe=n(ZBe,"STRONG",{});var R5t=s(Wfe);T_o=r(R5t,"xlnet"),R5t.forEach(t),M_o=r(ZBe," \u2014 "),Iq=n(ZBe,"A",{href:!0});var P5t=s(Iq);E_o=r(P5t,"XLNetConfig"),P5t.forEach(t),C_o=r(ZBe," (XLNet model)"),ZBe.forEach(t),w_o=i(L),eu=n(L,"LI",{});var eIe=s(eu);Ufe=n(eIe,"STRONG",{});var B5t=s(Ufe);A_o=r(B5t,"yolos"),B5t.forEach(t),L_o=r(eIe," \u2014 "),Nq=n(eIe,"A",{href:!0});var I5t=s(Nq);y_o=r(I5t,"YolosConfig"),I5t.forEach(t),x_o=r(eIe," (YOLOS model)"),eIe.forEach(t),$_o=i(L),ou=n(L,"LI",{});var oIe=s(ou);Hfe=n(oIe,"STRONG",{});var N5t=s(Hfe);k_o=r(N5t,"yoso"),N5t.forEach(t),S_o=r(oIe," \u2014 "),qq=n(oIe,"A",{href:!0});var q5t=s(qq);R_o=r(q5t,"YosoConfig"),q5t.forEach(t),P_o=r(oIe," (YOSO model)"),oIe.forEach(t),L.forEach(t),B_o=i(ut),T(ru.$$.fragment,ut),ut.forEach(t),I_o=i(ht),tu=n(ht,"DIV",{class:!0});var xro=s(tu);T(ux.$$.fragment,xro),N_o=i(xro),Jfe=n(xro,"P",{});var j5t=s(Jfe);q_o=r(j5t,"Register a new configuration for this class."),j5t.forEach(t),xro.forEach(t),ht.forEach(t),Meo=i(c),gd=n(c,"H2",{class:!0});var $ro=s(gd);au=n($ro,"A",{id:!0,class:!0,href:!0});var D5t=s(au);Yfe=n(D5t,"SPAN",{});var G5t=s(Yfe);T(px.$$.fragment,G5t),G5t.forEach(t),D5t.forEach(t),j_o=i($ro),Kfe=n($ro,"SPAN",{});var O5t=s(Kfe);D_o=r(O5t,"AutoTokenizer"),O5t.forEach(t),$ro.forEach(t),Eeo=i(c),ko=n(c,"DIV",{class:!0});var Ml=s(ko);T(_x.$$.fragment,Ml),G_o=i(Ml),bx=n(Ml,"P",{});var kro=s(bx);O_o=r(kro,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),jq=n(kro,"A",{href:!0});var V5t=s(jq);V_o=r(V5t,"AutoTokenizer.from_pretrained()"),V5t.forEach(t),X_o=r(kro," class method."),kro.forEach(t),z_o=i(Ml),vx=n(Ml,"P",{});var Sro=s(vx);Q_o=r(Sro,"This class cannot be instantiated directly using "),Zfe=n(Sro,"CODE",{});var X5t=s(Zfe);W_o=r(X5t,"__init__()"),X5t.forEach(t),U_o=r(Sro," (throws an error)."),Sro.forEach(t),H_o=i(Ml),Br=n(Ml,"DIV",{class:!0});var El=s(Br);T(Fx.$$.fragment,El),J_o=i(El),ege=n(El,"P",{});var z5t=s(ege);Y_o=r(z5t,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),z5t.forEach(t),K_o=i(El),Ua=n(El,"P",{});var e8=s(Ua);Z_o=r(e8,"The tokenizer class to instantiate is selected based on the "),oge=n(e8,"CODE",{});var Q5t=s(oge);e1o=r(Q5t,"model_type"),Q5t.forEach(t),o1o=r(e8,` property of the config object (either
passed as an argument or loaded from `),rge=n(e8,"CODE",{});var W5t=s(rge);r1o=r(W5t,"pretrained_model_name_or_path"),W5t.forEach(t),t1o=r(e8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tge=n(e8,"CODE",{});var U5t=s(tge);a1o=r(U5t,"pretrained_model_name_or_path"),U5t.forEach(t),n1o=r(e8,":"),e8.forEach(t),s1o=i(El),k=n(El,"UL",{});var S=s(k);ns=n(S,"LI",{});var XP=s(ns);age=n(XP,"STRONG",{});var H5t=s(age);l1o=r(H5t,"albert"),H5t.forEach(t),i1o=r(XP," \u2014 "),Dq=n(XP,"A",{href:!0});var J5t=s(Dq);d1o=r(J5t,"AlbertTokenizer"),J5t.forEach(t),m1o=r(XP," or "),Gq=n(XP,"A",{href:!0});var Y5t=s(Gq);c1o=r(Y5t,"AlbertTokenizerFast"),Y5t.forEach(t),f1o=r(XP," (ALBERT model)"),XP.forEach(t),g1o=i(S),ss=n(S,"LI",{});var zP=s(ss);nge=n(zP,"STRONG",{});var K5t=s(nge);h1o=r(K5t,"bart"),K5t.forEach(t),u1o=r(zP," \u2014 "),Oq=n(zP,"A",{href:!0});var Z5t=s(Oq);p1o=r(Z5t,"BartTokenizer"),Z5t.forEach(t),_1o=r(zP," or "),Vq=n(zP,"A",{href:!0});var e0t=s(Vq);b1o=r(e0t,"BartTokenizerFast"),e0t.forEach(t),v1o=r(zP," (BART model)"),zP.forEach(t),F1o=i(S),ls=n(S,"LI",{});var QP=s(ls);sge=n(QP,"STRONG",{});var o0t=s(sge);T1o=r(o0t,"barthez"),o0t.forEach(t),M1o=r(QP," \u2014 "),Xq=n(QP,"A",{href:!0});var r0t=s(Xq);E1o=r(r0t,"BarthezTokenizer"),r0t.forEach(t),C1o=r(QP," or "),zq=n(QP,"A",{href:!0});var t0t=s(zq);w1o=r(t0t,"BarthezTokenizerFast"),t0t.forEach(t),A1o=r(QP," (BARThez model)"),QP.forEach(t),L1o=i(S),nu=n(S,"LI",{});var rIe=s(nu);lge=n(rIe,"STRONG",{});var a0t=s(lge);y1o=r(a0t,"bartpho"),a0t.forEach(t),x1o=r(rIe," \u2014 "),Qq=n(rIe,"A",{href:!0});var n0t=s(Qq);$1o=r(n0t,"BartphoTokenizer"),n0t.forEach(t),k1o=r(rIe," (BARTpho model)"),rIe.forEach(t),S1o=i(S),is=n(S,"LI",{});var WP=s(is);ige=n(WP,"STRONG",{});var s0t=s(ige);R1o=r(s0t,"bert"),s0t.forEach(t),P1o=r(WP," \u2014 "),Wq=n(WP,"A",{href:!0});var l0t=s(Wq);B1o=r(l0t,"BertTokenizer"),l0t.forEach(t),I1o=r(WP," or "),Uq=n(WP,"A",{href:!0});var i0t=s(Uq);N1o=r(i0t,"BertTokenizerFast"),i0t.forEach(t),q1o=r(WP," (BERT model)"),WP.forEach(t),j1o=i(S),su=n(S,"LI",{});var tIe=s(su);dge=n(tIe,"STRONG",{});var d0t=s(dge);D1o=r(d0t,"bert-generation"),d0t.forEach(t),G1o=r(tIe," \u2014 "),Hq=n(tIe,"A",{href:!0});var m0t=s(Hq);O1o=r(m0t,"BertGenerationTokenizer"),m0t.forEach(t),V1o=r(tIe," (Bert Generation model)"),tIe.forEach(t),X1o=i(S),lu=n(S,"LI",{});var aIe=s(lu);mge=n(aIe,"STRONG",{});var c0t=s(mge);z1o=r(c0t,"bert-japanese"),c0t.forEach(t),Q1o=r(aIe," \u2014 "),Jq=n(aIe,"A",{href:!0});var f0t=s(Jq);W1o=r(f0t,"BertJapaneseTokenizer"),f0t.forEach(t),U1o=r(aIe," (BertJapanese model)"),aIe.forEach(t),H1o=i(S),iu=n(S,"LI",{});var nIe=s(iu);cge=n(nIe,"STRONG",{});var g0t=s(cge);J1o=r(g0t,"bertweet"),g0t.forEach(t),Y1o=r(nIe," \u2014 "),Yq=n(nIe,"A",{href:!0});var h0t=s(Yq);K1o=r(h0t,"BertweetTokenizer"),h0t.forEach(t),Z1o=r(nIe," (BERTweet model)"),nIe.forEach(t),e2o=i(S),ds=n(S,"LI",{});var UP=s(ds);fge=n(UP,"STRONG",{});var u0t=s(fge);o2o=r(u0t,"big_bird"),u0t.forEach(t),r2o=r(UP," \u2014 "),Kq=n(UP,"A",{href:!0});var p0t=s(Kq);t2o=r(p0t,"BigBirdTokenizer"),p0t.forEach(t),a2o=r(UP," or "),Zq=n(UP,"A",{href:!0});var _0t=s(Zq);n2o=r(_0t,"BigBirdTokenizerFast"),_0t.forEach(t),s2o=r(UP," (BigBird model)"),UP.forEach(t),l2o=i(S),ms=n(S,"LI",{});var HP=s(ms);gge=n(HP,"STRONG",{});var b0t=s(gge);i2o=r(b0t,"bigbird_pegasus"),b0t.forEach(t),d2o=r(HP," \u2014 "),ej=n(HP,"A",{href:!0});var v0t=s(ej);m2o=r(v0t,"PegasusTokenizer"),v0t.forEach(t),c2o=r(HP," or "),oj=n(HP,"A",{href:!0});var F0t=s(oj);f2o=r(F0t,"PegasusTokenizerFast"),F0t.forEach(t),g2o=r(HP," (BigBird-Pegasus model)"),HP.forEach(t),h2o=i(S),cs=n(S,"LI",{});var JP=s(cs);hge=n(JP,"STRONG",{});var T0t=s(hge);u2o=r(T0t,"blenderbot"),T0t.forEach(t),p2o=r(JP," \u2014 "),rj=n(JP,"A",{href:!0});var M0t=s(rj);_2o=r(M0t,"BlenderbotTokenizer"),M0t.forEach(t),b2o=r(JP," or "),tj=n(JP,"A",{href:!0});var E0t=s(tj);v2o=r(E0t,"BlenderbotTokenizerFast"),E0t.forEach(t),F2o=r(JP," (Blenderbot model)"),JP.forEach(t),T2o=i(S),du=n(S,"LI",{});var sIe=s(du);uge=n(sIe,"STRONG",{});var C0t=s(uge);M2o=r(C0t,"blenderbot-small"),C0t.forEach(t),E2o=r(sIe," \u2014 "),aj=n(sIe,"A",{href:!0});var w0t=s(aj);C2o=r(w0t,"BlenderbotSmallTokenizer"),w0t.forEach(t),w2o=r(sIe," (BlenderbotSmall model)"),sIe.forEach(t),A2o=i(S),mu=n(S,"LI",{});var lIe=s(mu);pge=n(lIe,"STRONG",{});var A0t=s(pge);L2o=r(A0t,"bloom"),A0t.forEach(t),y2o=r(lIe," \u2014 "),nj=n(lIe,"A",{href:!0});var L0t=s(nj);x2o=r(L0t,"BloomTokenizerFast"),L0t.forEach(t),$2o=r(lIe," (BLOOM model)"),lIe.forEach(t),k2o=i(S),cu=n(S,"LI",{});var iIe=s(cu);_ge=n(iIe,"STRONG",{});var y0t=s(_ge);S2o=r(y0t,"byt5"),y0t.forEach(t),R2o=r(iIe," \u2014 "),sj=n(iIe,"A",{href:!0});var x0t=s(sj);P2o=r(x0t,"ByT5Tokenizer"),x0t.forEach(t),B2o=r(iIe," (ByT5 model)"),iIe.forEach(t),I2o=i(S),fs=n(S,"LI",{});var YP=s(fs);bge=n(YP,"STRONG",{});var $0t=s(bge);N2o=r($0t,"camembert"),$0t.forEach(t),q2o=r(YP," \u2014 "),lj=n(YP,"A",{href:!0});var k0t=s(lj);j2o=r(k0t,"CamembertTokenizer"),k0t.forEach(t),D2o=r(YP," or "),ij=n(YP,"A",{href:!0});var S0t=s(ij);G2o=r(S0t,"CamembertTokenizerFast"),S0t.forEach(t),O2o=r(YP," (CamemBERT model)"),YP.forEach(t),V2o=i(S),fu=n(S,"LI",{});var dIe=s(fu);vge=n(dIe,"STRONG",{});var R0t=s(vge);X2o=r(R0t,"canine"),R0t.forEach(t),z2o=r(dIe," \u2014 "),dj=n(dIe,"A",{href:!0});var P0t=s(dj);Q2o=r(P0t,"CanineTokenizer"),P0t.forEach(t),W2o=r(dIe," (CANINE model)"),dIe.forEach(t),U2o=i(S),gs=n(S,"LI",{});var KP=s(gs);Fge=n(KP,"STRONG",{});var B0t=s(Fge);H2o=r(B0t,"clip"),B0t.forEach(t),J2o=r(KP," \u2014 "),mj=n(KP,"A",{href:!0});var I0t=s(mj);Y2o=r(I0t,"CLIPTokenizer"),I0t.forEach(t),K2o=r(KP," or "),cj=n(KP,"A",{href:!0});var N0t=s(cj);Z2o=r(N0t,"CLIPTokenizerFast"),N0t.forEach(t),ebo=r(KP," (CLIP model)"),KP.forEach(t),obo=i(S),hs=n(S,"LI",{});var ZP=s(hs);Tge=n(ZP,"STRONG",{});var q0t=s(Tge);rbo=r(q0t,"codegen"),q0t.forEach(t),tbo=r(ZP," \u2014 "),fj=n(ZP,"A",{href:!0});var j0t=s(fj);abo=r(j0t,"CodeGenTokenizer"),j0t.forEach(t),nbo=r(ZP," or "),gj=n(ZP,"A",{href:!0});var D0t=s(gj);sbo=r(D0t,"CodeGenTokenizerFast"),D0t.forEach(t),lbo=r(ZP," (CodeGen model)"),ZP.forEach(t),ibo=i(S),us=n(S,"LI",{});var eB=s(us);Mge=n(eB,"STRONG",{});var G0t=s(Mge);dbo=r(G0t,"convbert"),G0t.forEach(t),mbo=r(eB," \u2014 "),hj=n(eB,"A",{href:!0});var O0t=s(hj);cbo=r(O0t,"ConvBertTokenizer"),O0t.forEach(t),fbo=r(eB," or "),uj=n(eB,"A",{href:!0});var V0t=s(uj);gbo=r(V0t,"ConvBertTokenizerFast"),V0t.forEach(t),hbo=r(eB," (ConvBERT model)"),eB.forEach(t),ubo=i(S),ps=n(S,"LI",{});var oB=s(ps);Ege=n(oB,"STRONG",{});var X0t=s(Ege);pbo=r(X0t,"cpm"),X0t.forEach(t),_bo=r(oB," \u2014 "),pj=n(oB,"A",{href:!0});var z0t=s(pj);bbo=r(z0t,"CpmTokenizer"),z0t.forEach(t),vbo=r(oB," or "),_j=n(oB,"A",{href:!0});var Q0t=s(_j);Fbo=r(Q0t,"CpmTokenizerFast"),Q0t.forEach(t),Tbo=r(oB," (CPM model)"),oB.forEach(t),Mbo=i(S),gu=n(S,"LI",{});var mIe=s(gu);Cge=n(mIe,"STRONG",{});var W0t=s(Cge);Ebo=r(W0t,"ctrl"),W0t.forEach(t),Cbo=r(mIe," \u2014 "),bj=n(mIe,"A",{href:!0});var U0t=s(bj);wbo=r(U0t,"CTRLTokenizer"),U0t.forEach(t),Abo=r(mIe," (CTRL model)"),mIe.forEach(t),Lbo=i(S),_s=n(S,"LI",{});var rB=s(_s);wge=n(rB,"STRONG",{});var H0t=s(wge);ybo=r(H0t,"data2vec-text"),H0t.forEach(t),xbo=r(rB," \u2014 "),vj=n(rB,"A",{href:!0});var J0t=s(vj);$bo=r(J0t,"RobertaTokenizer"),J0t.forEach(t),kbo=r(rB," or "),Fj=n(rB,"A",{href:!0});var Y0t=s(Fj);Sbo=r(Y0t,"RobertaTokenizerFast"),Y0t.forEach(t),Rbo=r(rB," (Data2VecText model)"),rB.forEach(t),Pbo=i(S),bs=n(S,"LI",{});var tB=s(bs);Age=n(tB,"STRONG",{});var K0t=s(Age);Bbo=r(K0t,"deberta"),K0t.forEach(t),Ibo=r(tB," \u2014 "),Tj=n(tB,"A",{href:!0});var Z0t=s(Tj);Nbo=r(Z0t,"DebertaTokenizer"),Z0t.forEach(t),qbo=r(tB," or "),Mj=n(tB,"A",{href:!0});var ewt=s(Mj);jbo=r(ewt,"DebertaTokenizerFast"),ewt.forEach(t),Dbo=r(tB," (DeBERTa model)"),tB.forEach(t),Gbo=i(S),vs=n(S,"LI",{});var aB=s(vs);Lge=n(aB,"STRONG",{});var owt=s(Lge);Obo=r(owt,"deberta-v2"),owt.forEach(t),Vbo=r(aB," \u2014 "),Ej=n(aB,"A",{href:!0});var rwt=s(Ej);Xbo=r(rwt,"DebertaV2Tokenizer"),rwt.forEach(t),zbo=r(aB," or "),Cj=n(aB,"A",{href:!0});var twt=s(Cj);Qbo=r(twt,"DebertaV2TokenizerFast"),twt.forEach(t),Wbo=r(aB," (DeBERTa-v2 model)"),aB.forEach(t),Ubo=i(S),Fs=n(S,"LI",{});var nB=s(Fs);yge=n(nB,"STRONG",{});var awt=s(yge);Hbo=r(awt,"distilbert"),awt.forEach(t),Jbo=r(nB," \u2014 "),wj=n(nB,"A",{href:!0});var nwt=s(wj);Ybo=r(nwt,"DistilBertTokenizer"),nwt.forEach(t),Kbo=r(nB," or "),Aj=n(nB,"A",{href:!0});var swt=s(Aj);Zbo=r(swt,"DistilBertTokenizerFast"),swt.forEach(t),evo=r(nB," (DistilBERT model)"),nB.forEach(t),ovo=i(S),Ts=n(S,"LI",{});var sB=s(Ts);xge=n(sB,"STRONG",{});var lwt=s(xge);rvo=r(lwt,"dpr"),lwt.forEach(t),tvo=r(sB," \u2014 "),Lj=n(sB,"A",{href:!0});var iwt=s(Lj);avo=r(iwt,"DPRQuestionEncoderTokenizer"),iwt.forEach(t),nvo=r(sB," or "),yj=n(sB,"A",{href:!0});var dwt=s(yj);svo=r(dwt,"DPRQuestionEncoderTokenizerFast"),dwt.forEach(t),lvo=r(sB," (DPR model)"),sB.forEach(t),ivo=i(S),Ms=n(S,"LI",{});var lB=s(Ms);$ge=n(lB,"STRONG",{});var mwt=s($ge);dvo=r(mwt,"electra"),mwt.forEach(t),mvo=r(lB," \u2014 "),xj=n(lB,"A",{href:!0});var cwt=s(xj);cvo=r(cwt,"ElectraTokenizer"),cwt.forEach(t),fvo=r(lB," or "),$j=n(lB,"A",{href:!0});var fwt=s($j);gvo=r(fwt,"ElectraTokenizerFast"),fwt.forEach(t),hvo=r(lB," (ELECTRA model)"),lB.forEach(t),uvo=i(S),Es=n(S,"LI",{});var iB=s(Es);kge=n(iB,"STRONG",{});var gwt=s(kge);pvo=r(gwt,"ernie"),gwt.forEach(t),_vo=r(iB," \u2014 "),kj=n(iB,"A",{href:!0});var hwt=s(kj);bvo=r(hwt,"BertTokenizer"),hwt.forEach(t),vvo=r(iB," or "),Sj=n(iB,"A",{href:!0});var uwt=s(Sj);Fvo=r(uwt,"BertTokenizerFast"),uwt.forEach(t),Tvo=r(iB," (ERNIE model)"),iB.forEach(t),Mvo=i(S),hu=n(S,"LI",{});var cIe=s(hu);Sge=n(cIe,"STRONG",{});var pwt=s(Sge);Evo=r(pwt,"flaubert"),pwt.forEach(t),Cvo=r(cIe," \u2014 "),Rj=n(cIe,"A",{href:!0});var _wt=s(Rj);wvo=r(_wt,"FlaubertTokenizer"),_wt.forEach(t),Avo=r(cIe," (FlauBERT model)"),cIe.forEach(t),Lvo=i(S),Cs=n(S,"LI",{});var dB=s(Cs);Rge=n(dB,"STRONG",{});var bwt=s(Rge);yvo=r(bwt,"fnet"),bwt.forEach(t),xvo=r(dB," \u2014 "),Pj=n(dB,"A",{href:!0});var vwt=s(Pj);$vo=r(vwt,"FNetTokenizer"),vwt.forEach(t),kvo=r(dB," or "),Bj=n(dB,"A",{href:!0});var Fwt=s(Bj);Svo=r(Fwt,"FNetTokenizerFast"),Fwt.forEach(t),Rvo=r(dB," (FNet model)"),dB.forEach(t),Pvo=i(S),uu=n(S,"LI",{});var fIe=s(uu);Pge=n(fIe,"STRONG",{});var Twt=s(Pge);Bvo=r(Twt,"fsmt"),Twt.forEach(t),Ivo=r(fIe," \u2014 "),Ij=n(fIe,"A",{href:!0});var Mwt=s(Ij);Nvo=r(Mwt,"FSMTTokenizer"),Mwt.forEach(t),qvo=r(fIe," (FairSeq Machine-Translation model)"),fIe.forEach(t),jvo=i(S),ws=n(S,"LI",{});var mB=s(ws);Bge=n(mB,"STRONG",{});var Ewt=s(Bge);Dvo=r(Ewt,"funnel"),Ewt.forEach(t),Gvo=r(mB," \u2014 "),Nj=n(mB,"A",{href:!0});var Cwt=s(Nj);Ovo=r(Cwt,"FunnelTokenizer"),Cwt.forEach(t),Vvo=r(mB," or "),qj=n(mB,"A",{href:!0});var wwt=s(qj);Xvo=r(wwt,"FunnelTokenizerFast"),wwt.forEach(t),zvo=r(mB," (Funnel Transformer model)"),mB.forEach(t),Qvo=i(S),As=n(S,"LI",{});var cB=s(As);Ige=n(cB,"STRONG",{});var Awt=s(Ige);Wvo=r(Awt,"gpt2"),Awt.forEach(t),Uvo=r(cB," \u2014 "),jj=n(cB,"A",{href:!0});var Lwt=s(jj);Hvo=r(Lwt,"GPT2Tokenizer"),Lwt.forEach(t),Jvo=r(cB," or "),Dj=n(cB,"A",{href:!0});var ywt=s(Dj);Yvo=r(ywt,"GPT2TokenizerFast"),ywt.forEach(t),Kvo=r(cB," (OpenAI GPT-2 model)"),cB.forEach(t),Zvo=i(S),Ls=n(S,"LI",{});var fB=s(Ls);Nge=n(fB,"STRONG",{});var xwt=s(Nge);eFo=r(xwt,"gpt_neo"),xwt.forEach(t),oFo=r(fB," \u2014 "),Gj=n(fB,"A",{href:!0});var $wt=s(Gj);rFo=r($wt,"GPT2Tokenizer"),$wt.forEach(t),tFo=r(fB," or "),Oj=n(fB,"A",{href:!0});var kwt=s(Oj);aFo=r(kwt,"GPT2TokenizerFast"),kwt.forEach(t),nFo=r(fB," (GPT Neo model)"),fB.forEach(t),sFo=i(S),pu=n(S,"LI",{});var gIe=s(pu);qge=n(gIe,"STRONG",{});var Swt=s(qge);lFo=r(Swt,"gpt_neox"),Swt.forEach(t),iFo=r(gIe," \u2014 "),Vj=n(gIe,"A",{href:!0});var Rwt=s(Vj);dFo=r(Rwt,"GPTNeoXTokenizerFast"),Rwt.forEach(t),mFo=r(gIe," (GPT NeoX model)"),gIe.forEach(t),cFo=i(S),_u=n(S,"LI",{});var hIe=s(_u);jge=n(hIe,"STRONG",{});var Pwt=s(jge);fFo=r(Pwt,"gpt_neox_japanese"),Pwt.forEach(t),gFo=r(hIe," \u2014 "),Xj=n(hIe,"A",{href:!0});var Bwt=s(Xj);hFo=r(Bwt,"GPTNeoXJapaneseTokenizer"),Bwt.forEach(t),uFo=r(hIe," (GPT NeoX Japanese model)"),hIe.forEach(t),pFo=i(S),ys=n(S,"LI",{});var gB=s(ys);Dge=n(gB,"STRONG",{});var Iwt=s(Dge);_Fo=r(Iwt,"gptj"),Iwt.forEach(t),bFo=r(gB," \u2014 "),zj=n(gB,"A",{href:!0});var Nwt=s(zj);vFo=r(Nwt,"GPT2Tokenizer"),Nwt.forEach(t),FFo=r(gB," or "),Qj=n(gB,"A",{href:!0});var qwt=s(Qj);TFo=r(qwt,"GPT2TokenizerFast"),qwt.forEach(t),MFo=r(gB," (GPT-J model)"),gB.forEach(t),EFo=i(S),xs=n(S,"LI",{});var hB=s(xs);Gge=n(hB,"STRONG",{});var jwt=s(Gge);CFo=r(jwt,"groupvit"),jwt.forEach(t),wFo=r(hB," \u2014 "),Wj=n(hB,"A",{href:!0});var Dwt=s(Wj);AFo=r(Dwt,"CLIPTokenizer"),Dwt.forEach(t),LFo=r(hB," or "),Uj=n(hB,"A",{href:!0});var Gwt=s(Uj);yFo=r(Gwt,"CLIPTokenizerFast"),Gwt.forEach(t),xFo=r(hB," (GroupViT model)"),hB.forEach(t),$Fo=i(S),$s=n(S,"LI",{});var uB=s($s);Oge=n(uB,"STRONG",{});var Owt=s(Oge);kFo=r(Owt,"herbert"),Owt.forEach(t),SFo=r(uB," \u2014 "),Hj=n(uB,"A",{href:!0});var Vwt=s(Hj);RFo=r(Vwt,"HerbertTokenizer"),Vwt.forEach(t),PFo=r(uB," or "),Jj=n(uB,"A",{href:!0});var Xwt=s(Jj);BFo=r(Xwt,"HerbertTokenizerFast"),Xwt.forEach(t),IFo=r(uB," (HerBERT model)"),uB.forEach(t),NFo=i(S),bu=n(S,"LI",{});var uIe=s(bu);Vge=n(uIe,"STRONG",{});var zwt=s(Vge);qFo=r(zwt,"hubert"),zwt.forEach(t),jFo=r(uIe," \u2014 "),Yj=n(uIe,"A",{href:!0});var Qwt=s(Yj);DFo=r(Qwt,"Wav2Vec2CTCTokenizer"),Qwt.forEach(t),GFo=r(uIe," (Hubert model)"),uIe.forEach(t),OFo=i(S),ks=n(S,"LI",{});var pB=s(ks);Xge=n(pB,"STRONG",{});var Wwt=s(Xge);VFo=r(Wwt,"ibert"),Wwt.forEach(t),XFo=r(pB," \u2014 "),Kj=n(pB,"A",{href:!0});var Uwt=s(Kj);zFo=r(Uwt,"RobertaTokenizer"),Uwt.forEach(t),QFo=r(pB," or "),Zj=n(pB,"A",{href:!0});var Hwt=s(Zj);WFo=r(Hwt,"RobertaTokenizerFast"),Hwt.forEach(t),UFo=r(pB," (I-BERT model)"),pB.forEach(t),HFo=i(S),Ss=n(S,"LI",{});var _B=s(Ss);zge=n(_B,"STRONG",{});var Jwt=s(zge);JFo=r(Jwt,"layoutlm"),Jwt.forEach(t),YFo=r(_B," \u2014 "),eD=n(_B,"A",{href:!0});var Ywt=s(eD);KFo=r(Ywt,"LayoutLMTokenizer"),Ywt.forEach(t),ZFo=r(_B," or "),oD=n(_B,"A",{href:!0});var Kwt=s(oD);eTo=r(Kwt,"LayoutLMTokenizerFast"),Kwt.forEach(t),oTo=r(_B," (LayoutLM model)"),_B.forEach(t),rTo=i(S),Rs=n(S,"LI",{});var bB=s(Rs);Qge=n(bB,"STRONG",{});var Zwt=s(Qge);tTo=r(Zwt,"layoutlmv2"),Zwt.forEach(t),aTo=r(bB," \u2014 "),rD=n(bB,"A",{href:!0});var eAt=s(rD);nTo=r(eAt,"LayoutLMv2Tokenizer"),eAt.forEach(t),sTo=r(bB," or "),tD=n(bB,"A",{href:!0});var oAt=s(tD);lTo=r(oAt,"LayoutLMv2TokenizerFast"),oAt.forEach(t),iTo=r(bB," (LayoutLMv2 model)"),bB.forEach(t),dTo=i(S),Ps=n(S,"LI",{});var vB=s(Ps);Wge=n(vB,"STRONG",{});var rAt=s(Wge);mTo=r(rAt,"layoutlmv3"),rAt.forEach(t),cTo=r(vB," \u2014 "),aD=n(vB,"A",{href:!0});var tAt=s(aD);fTo=r(tAt,"LayoutLMv3Tokenizer"),tAt.forEach(t),gTo=r(vB," or "),nD=n(vB,"A",{href:!0});var aAt=s(nD);hTo=r(aAt,"LayoutLMv3TokenizerFast"),aAt.forEach(t),uTo=r(vB," (LayoutLMv3 model)"),vB.forEach(t),pTo=i(S),Bs=n(S,"LI",{});var FB=s(Bs);Uge=n(FB,"STRONG",{});var nAt=s(Uge);_To=r(nAt,"layoutxlm"),nAt.forEach(t),bTo=r(FB," \u2014 "),sD=n(FB,"A",{href:!0});var sAt=s(sD);vTo=r(sAt,"LayoutXLMTokenizer"),sAt.forEach(t),FTo=r(FB," or "),lD=n(FB,"A",{href:!0});var lAt=s(lD);TTo=r(lAt,"LayoutXLMTokenizerFast"),lAt.forEach(t),MTo=r(FB," (LayoutXLM model)"),FB.forEach(t),ETo=i(S),Is=n(S,"LI",{});var TB=s(Is);Hge=n(TB,"STRONG",{});var iAt=s(Hge);CTo=r(iAt,"led"),iAt.forEach(t),wTo=r(TB," \u2014 "),iD=n(TB,"A",{href:!0});var dAt=s(iD);ATo=r(dAt,"LEDTokenizer"),dAt.forEach(t),LTo=r(TB," or "),dD=n(TB,"A",{href:!0});var mAt=s(dD);yTo=r(mAt,"LEDTokenizerFast"),mAt.forEach(t),xTo=r(TB," (LED model)"),TB.forEach(t),$To=i(S),Ns=n(S,"LI",{});var MB=s(Ns);Jge=n(MB,"STRONG",{});var cAt=s(Jge);kTo=r(cAt,"longformer"),cAt.forEach(t),STo=r(MB," \u2014 "),mD=n(MB,"A",{href:!0});var fAt=s(mD);RTo=r(fAt,"LongformerTokenizer"),fAt.forEach(t),PTo=r(MB," or "),cD=n(MB,"A",{href:!0});var gAt=s(cD);BTo=r(gAt,"LongformerTokenizerFast"),gAt.forEach(t),ITo=r(MB," (Longformer model)"),MB.forEach(t),NTo=i(S),qs=n(S,"LI",{});var EB=s(qs);Yge=n(EB,"STRONG",{});var hAt=s(Yge);qTo=r(hAt,"longt5"),hAt.forEach(t),jTo=r(EB," \u2014 "),fD=n(EB,"A",{href:!0});var uAt=s(fD);DTo=r(uAt,"T5Tokenizer"),uAt.forEach(t),GTo=r(EB," or "),gD=n(EB,"A",{href:!0});var pAt=s(gD);OTo=r(pAt,"T5TokenizerFast"),pAt.forEach(t),VTo=r(EB," (LongT5 model)"),EB.forEach(t),XTo=i(S),vu=n(S,"LI",{});var pIe=s(vu);Kge=n(pIe,"STRONG",{});var _At=s(Kge);zTo=r(_At,"luke"),_At.forEach(t),QTo=r(pIe," \u2014 "),hD=n(pIe,"A",{href:!0});var bAt=s(hD);WTo=r(bAt,"LukeTokenizer"),bAt.forEach(t),UTo=r(pIe," (LUKE model)"),pIe.forEach(t),HTo=i(S),js=n(S,"LI",{});var CB=s(js);Zge=n(CB,"STRONG",{});var vAt=s(Zge);JTo=r(vAt,"lxmert"),vAt.forEach(t),YTo=r(CB," \u2014 "),uD=n(CB,"A",{href:!0});var FAt=s(uD);KTo=r(FAt,"LxmertTokenizer"),FAt.forEach(t),ZTo=r(CB," or "),pD=n(CB,"A",{href:!0});var TAt=s(pD);eMo=r(TAt,"LxmertTokenizerFast"),TAt.forEach(t),oMo=r(CB," (LXMERT model)"),CB.forEach(t),rMo=i(S),Fu=n(S,"LI",{});var _Ie=s(Fu);ehe=n(_Ie,"STRONG",{});var MAt=s(ehe);tMo=r(MAt,"m2m_100"),MAt.forEach(t),aMo=r(_Ie," \u2014 "),_D=n(_Ie,"A",{href:!0});var EAt=s(_D);nMo=r(EAt,"M2M100Tokenizer"),EAt.forEach(t),sMo=r(_Ie," (M2M100 model)"),_Ie.forEach(t),lMo=i(S),Tu=n(S,"LI",{});var bIe=s(Tu);ohe=n(bIe,"STRONG",{});var CAt=s(ohe);iMo=r(CAt,"marian"),CAt.forEach(t),dMo=r(bIe," \u2014 "),bD=n(bIe,"A",{href:!0});var wAt=s(bD);mMo=r(wAt,"MarianTokenizer"),wAt.forEach(t),cMo=r(bIe," (Marian model)"),bIe.forEach(t),fMo=i(S),Ds=n(S,"LI",{});var wB=s(Ds);rhe=n(wB,"STRONG",{});var AAt=s(rhe);gMo=r(AAt,"mbart"),AAt.forEach(t),hMo=r(wB," \u2014 "),vD=n(wB,"A",{href:!0});var LAt=s(vD);uMo=r(LAt,"MBartTokenizer"),LAt.forEach(t),pMo=r(wB," or "),FD=n(wB,"A",{href:!0});var yAt=s(FD);_Mo=r(yAt,"MBartTokenizerFast"),yAt.forEach(t),bMo=r(wB," (mBART model)"),wB.forEach(t),vMo=i(S),Gs=n(S,"LI",{});var AB=s(Gs);the=n(AB,"STRONG",{});var xAt=s(the);FMo=r(xAt,"mbart50"),xAt.forEach(t),TMo=r(AB," \u2014 "),TD=n(AB,"A",{href:!0});var $At=s(TD);MMo=r($At,"MBart50Tokenizer"),$At.forEach(t),EMo=r(AB," or "),MD=n(AB,"A",{href:!0});var kAt=s(MD);CMo=r(kAt,"MBart50TokenizerFast"),kAt.forEach(t),wMo=r(AB," (mBART-50 model)"),AB.forEach(t),AMo=i(S),Os=n(S,"LI",{});var LB=s(Os);ahe=n(LB,"STRONG",{});var SAt=s(ahe);LMo=r(SAt,"megatron-bert"),SAt.forEach(t),yMo=r(LB," \u2014 "),ED=n(LB,"A",{href:!0});var RAt=s(ED);xMo=r(RAt,"BertTokenizer"),RAt.forEach(t),$Mo=r(LB," or "),CD=n(LB,"A",{href:!0});var PAt=s(CD);kMo=r(PAt,"BertTokenizerFast"),PAt.forEach(t),SMo=r(LB," (Megatron-BERT model)"),LB.forEach(t),RMo=i(S),Mu=n(S,"LI",{});var vIe=s(Mu);nhe=n(vIe,"STRONG",{});var BAt=s(nhe);PMo=r(BAt,"mluke"),BAt.forEach(t),BMo=r(vIe," \u2014 "),wD=n(vIe,"A",{href:!0});var IAt=s(wD);IMo=r(IAt,"MLukeTokenizer"),IAt.forEach(t),NMo=r(vIe," (mLUKE model)"),vIe.forEach(t),qMo=i(S),Vs=n(S,"LI",{});var yB=s(Vs);she=n(yB,"STRONG",{});var NAt=s(she);jMo=r(NAt,"mobilebert"),NAt.forEach(t),DMo=r(yB," \u2014 "),AD=n(yB,"A",{href:!0});var qAt=s(AD);GMo=r(qAt,"MobileBertTokenizer"),qAt.forEach(t),OMo=r(yB," or "),LD=n(yB,"A",{href:!0});var jAt=s(LD);VMo=r(jAt,"MobileBertTokenizerFast"),jAt.forEach(t),XMo=r(yB," (MobileBERT model)"),yB.forEach(t),zMo=i(S),Xs=n(S,"LI",{});var xB=s(Xs);lhe=n(xB,"STRONG",{});var DAt=s(lhe);QMo=r(DAt,"mpnet"),DAt.forEach(t),WMo=r(xB," \u2014 "),yD=n(xB,"A",{href:!0});var GAt=s(yD);UMo=r(GAt,"MPNetTokenizer"),GAt.forEach(t),HMo=r(xB," or "),xD=n(xB,"A",{href:!0});var OAt=s(xD);JMo=r(OAt,"MPNetTokenizerFast"),OAt.forEach(t),YMo=r(xB," (MPNet model)"),xB.forEach(t),KMo=i(S),zs=n(S,"LI",{});var $B=s(zs);ihe=n($B,"STRONG",{});var VAt=s(ihe);ZMo=r(VAt,"mt5"),VAt.forEach(t),eEo=r($B," \u2014 "),$D=n($B,"A",{href:!0});var XAt=s($D);oEo=r(XAt,"MT5Tokenizer"),XAt.forEach(t),rEo=r($B," or "),kD=n($B,"A",{href:!0});var zAt=s(kD);tEo=r(zAt,"MT5TokenizerFast"),zAt.forEach(t),aEo=r($B," (MT5 model)"),$B.forEach(t),nEo=i(S),Qs=n(S,"LI",{});var kB=s(Qs);dhe=n(kB,"STRONG",{});var QAt=s(dhe);sEo=r(QAt,"mvp"),QAt.forEach(t),lEo=r(kB," \u2014 "),SD=n(kB,"A",{href:!0});var WAt=s(SD);iEo=r(WAt,"MvpTokenizer"),WAt.forEach(t),dEo=r(kB," or "),RD=n(kB,"A",{href:!0});var UAt=s(RD);mEo=r(UAt,"MvpTokenizerFast"),UAt.forEach(t),cEo=r(kB," (MVP model)"),kB.forEach(t),fEo=i(S),Ws=n(S,"LI",{});var SB=s(Ws);mhe=n(SB,"STRONG",{});var HAt=s(mhe);gEo=r(HAt,"nezha"),HAt.forEach(t),hEo=r(SB," \u2014 "),PD=n(SB,"A",{href:!0});var JAt=s(PD);uEo=r(JAt,"BertTokenizer"),JAt.forEach(t),pEo=r(SB," or "),BD=n(SB,"A",{href:!0});var YAt=s(BD);_Eo=r(YAt,"BertTokenizerFast"),YAt.forEach(t),bEo=r(SB," (Nezha model)"),SB.forEach(t),vEo=i(S),Us=n(S,"LI",{});var RB=s(Us);che=n(RB,"STRONG",{});var KAt=s(che);FEo=r(KAt,"nllb"),KAt.forEach(t),TEo=r(RB," \u2014 "),ID=n(RB,"A",{href:!0});var ZAt=s(ID);MEo=r(ZAt,"NllbTokenizer"),ZAt.forEach(t),EEo=r(RB," or "),ND=n(RB,"A",{href:!0});var e6t=s(ND);CEo=r(e6t,"NllbTokenizerFast"),e6t.forEach(t),wEo=r(RB," (NLLB model)"),RB.forEach(t),AEo=i(S),Hs=n(S,"LI",{});var PB=s(Hs);fhe=n(PB,"STRONG",{});var o6t=s(fhe);LEo=r(o6t,"nystromformer"),o6t.forEach(t),yEo=r(PB," \u2014 "),qD=n(PB,"A",{href:!0});var r6t=s(qD);xEo=r(r6t,"AlbertTokenizer"),r6t.forEach(t),$Eo=r(PB," or "),jD=n(PB,"A",{href:!0});var t6t=s(jD);kEo=r(t6t,"AlbertTokenizerFast"),t6t.forEach(t),SEo=r(PB," (Nystr\xF6mformer model)"),PB.forEach(t),REo=i(S),Js=n(S,"LI",{});var BB=s(Js);ghe=n(BB,"STRONG",{});var a6t=s(ghe);PEo=r(a6t,"openai-gpt"),a6t.forEach(t),BEo=r(BB," \u2014 "),DD=n(BB,"A",{href:!0});var n6t=s(DD);IEo=r(n6t,"OpenAIGPTTokenizer"),n6t.forEach(t),NEo=r(BB," or "),GD=n(BB,"A",{href:!0});var s6t=s(GD);qEo=r(s6t,"OpenAIGPTTokenizerFast"),s6t.forEach(t),jEo=r(BB," (OpenAI GPT model)"),BB.forEach(t),DEo=i(S),Eu=n(S,"LI",{});var FIe=s(Eu);hhe=n(FIe,"STRONG",{});var l6t=s(hhe);GEo=r(l6t,"opt"),l6t.forEach(t),OEo=r(FIe," \u2014 "),OD=n(FIe,"A",{href:!0});var i6t=s(OD);VEo=r(i6t,"GPT2Tokenizer"),i6t.forEach(t),XEo=r(FIe," (OPT model)"),FIe.forEach(t),zEo=i(S),Ys=n(S,"LI",{});var IB=s(Ys);uhe=n(IB,"STRONG",{});var d6t=s(uhe);QEo=r(d6t,"owlvit"),d6t.forEach(t),WEo=r(IB," \u2014 "),VD=n(IB,"A",{href:!0});var m6t=s(VD);UEo=r(m6t,"CLIPTokenizer"),m6t.forEach(t),HEo=r(IB," or "),XD=n(IB,"A",{href:!0});var c6t=s(XD);JEo=r(c6t,"CLIPTokenizerFast"),c6t.forEach(t),YEo=r(IB," (OWL-ViT model)"),IB.forEach(t),KEo=i(S),Ks=n(S,"LI",{});var NB=s(Ks);phe=n(NB,"STRONG",{});var f6t=s(phe);ZEo=r(f6t,"pegasus"),f6t.forEach(t),e4o=r(NB," \u2014 "),zD=n(NB,"A",{href:!0});var g6t=s(zD);o4o=r(g6t,"PegasusTokenizer"),g6t.forEach(t),r4o=r(NB," or "),QD=n(NB,"A",{href:!0});var h6t=s(QD);t4o=r(h6t,"PegasusTokenizerFast"),h6t.forEach(t),a4o=r(NB," (Pegasus model)"),NB.forEach(t),n4o=i(S),Cu=n(S,"LI",{});var TIe=s(Cu);_he=n(TIe,"STRONG",{});var u6t=s(_he);s4o=r(u6t,"perceiver"),u6t.forEach(t),l4o=r(TIe," \u2014 "),WD=n(TIe,"A",{href:!0});var p6t=s(WD);i4o=r(p6t,"PerceiverTokenizer"),p6t.forEach(t),d4o=r(TIe," (Perceiver model)"),TIe.forEach(t),m4o=i(S),wu=n(S,"LI",{});var MIe=s(wu);bhe=n(MIe,"STRONG",{});var _6t=s(bhe);c4o=r(_6t,"phobert"),_6t.forEach(t),f4o=r(MIe," \u2014 "),UD=n(MIe,"A",{href:!0});var b6t=s(UD);g4o=r(b6t,"PhobertTokenizer"),b6t.forEach(t),h4o=r(MIe," (PhoBERT model)"),MIe.forEach(t),u4o=i(S),Au=n(S,"LI",{});var EIe=s(Au);vhe=n(EIe,"STRONG",{});var v6t=s(vhe);p4o=r(v6t,"plbart"),v6t.forEach(t),_4o=r(EIe," \u2014 "),HD=n(EIe,"A",{href:!0});var F6t=s(HD);b4o=r(F6t,"PLBartTokenizer"),F6t.forEach(t),v4o=r(EIe," (PLBart model)"),EIe.forEach(t),F4o=i(S),Lu=n(S,"LI",{});var CIe=s(Lu);Fhe=n(CIe,"STRONG",{});var T6t=s(Fhe);T4o=r(T6t,"prophetnet"),T6t.forEach(t),M4o=r(CIe," \u2014 "),JD=n(CIe,"A",{href:!0});var M6t=s(JD);E4o=r(M6t,"ProphetNetTokenizer"),M6t.forEach(t),C4o=r(CIe," (ProphetNet model)"),CIe.forEach(t),w4o=i(S),Zs=n(S,"LI",{});var qB=s(Zs);The=n(qB,"STRONG",{});var E6t=s(The);A4o=r(E6t,"qdqbert"),E6t.forEach(t),L4o=r(qB," \u2014 "),YD=n(qB,"A",{href:!0});var C6t=s(YD);y4o=r(C6t,"BertTokenizer"),C6t.forEach(t),x4o=r(qB," or "),KD=n(qB,"A",{href:!0});var w6t=s(KD);$4o=r(w6t,"BertTokenizerFast"),w6t.forEach(t),k4o=r(qB," (QDQBert model)"),qB.forEach(t),S4o=i(S),yu=n(S,"LI",{});var wIe=s(yu);Mhe=n(wIe,"STRONG",{});var A6t=s(Mhe);R4o=r(A6t,"rag"),A6t.forEach(t),P4o=r(wIe," \u2014 "),ZD=n(wIe,"A",{href:!0});var L6t=s(ZD);B4o=r(L6t,"RagTokenizer"),L6t.forEach(t),I4o=r(wIe," (RAG model)"),wIe.forEach(t),N4o=i(S),el=n(S,"LI",{});var jB=s(el);Ehe=n(jB,"STRONG",{});var y6t=s(Ehe);q4o=r(y6t,"realm"),y6t.forEach(t),j4o=r(jB," \u2014 "),eG=n(jB,"A",{href:!0});var x6t=s(eG);D4o=r(x6t,"RealmTokenizer"),x6t.forEach(t),G4o=r(jB," or "),oG=n(jB,"A",{href:!0});var $6t=s(oG);O4o=r($6t,"RealmTokenizerFast"),$6t.forEach(t),V4o=r(jB," (REALM model)"),jB.forEach(t),X4o=i(S),ol=n(S,"LI",{});var DB=s(ol);Che=n(DB,"STRONG",{});var k6t=s(Che);z4o=r(k6t,"reformer"),k6t.forEach(t),Q4o=r(DB," \u2014 "),rG=n(DB,"A",{href:!0});var S6t=s(rG);W4o=r(S6t,"ReformerTokenizer"),S6t.forEach(t),U4o=r(DB," or "),tG=n(DB,"A",{href:!0});var R6t=s(tG);H4o=r(R6t,"ReformerTokenizerFast"),R6t.forEach(t),J4o=r(DB," (Reformer model)"),DB.forEach(t),Y4o=i(S),rl=n(S,"LI",{});var GB=s(rl);whe=n(GB,"STRONG",{});var P6t=s(whe);K4o=r(P6t,"rembert"),P6t.forEach(t),Z4o=r(GB," \u2014 "),aG=n(GB,"A",{href:!0});var B6t=s(aG);eCo=r(B6t,"RemBertTokenizer"),B6t.forEach(t),oCo=r(GB," or "),nG=n(GB,"A",{href:!0});var I6t=s(nG);rCo=r(I6t,"RemBertTokenizerFast"),I6t.forEach(t),tCo=r(GB," (RemBERT model)"),GB.forEach(t),aCo=i(S),tl=n(S,"LI",{});var OB=s(tl);Ahe=n(OB,"STRONG",{});var N6t=s(Ahe);nCo=r(N6t,"retribert"),N6t.forEach(t),sCo=r(OB," \u2014 "),sG=n(OB,"A",{href:!0});var q6t=s(sG);lCo=r(q6t,"RetriBertTokenizer"),q6t.forEach(t),iCo=r(OB," or "),lG=n(OB,"A",{href:!0});var j6t=s(lG);dCo=r(j6t,"RetriBertTokenizerFast"),j6t.forEach(t),mCo=r(OB," (RetriBERT model)"),OB.forEach(t),cCo=i(S),al=n(S,"LI",{});var VB=s(al);Lhe=n(VB,"STRONG",{});var D6t=s(Lhe);fCo=r(D6t,"roberta"),D6t.forEach(t),gCo=r(VB," \u2014 "),iG=n(VB,"A",{href:!0});var G6t=s(iG);hCo=r(G6t,"RobertaTokenizer"),G6t.forEach(t),uCo=r(VB," or "),dG=n(VB,"A",{href:!0});var O6t=s(dG);pCo=r(O6t,"RobertaTokenizerFast"),O6t.forEach(t),_Co=r(VB," (RoBERTa model)"),VB.forEach(t),bCo=i(S),nl=n(S,"LI",{});var XB=s(nl);yhe=n(XB,"STRONG",{});var V6t=s(yhe);vCo=r(V6t,"roformer"),V6t.forEach(t),FCo=r(XB," \u2014 "),mG=n(XB,"A",{href:!0});var X6t=s(mG);TCo=r(X6t,"RoFormerTokenizer"),X6t.forEach(t),MCo=r(XB," or "),cG=n(XB,"A",{href:!0});var z6t=s(cG);ECo=r(z6t,"RoFormerTokenizerFast"),z6t.forEach(t),CCo=r(XB," (RoFormer model)"),XB.forEach(t),wCo=i(S),xu=n(S,"LI",{});var AIe=s(xu);xhe=n(AIe,"STRONG",{});var Q6t=s(xhe);ACo=r(Q6t,"speech_to_text"),Q6t.forEach(t),LCo=r(AIe," \u2014 "),fG=n(AIe,"A",{href:!0});var W6t=s(fG);yCo=r(W6t,"Speech2TextTokenizer"),W6t.forEach(t),xCo=r(AIe," (Speech2Text model)"),AIe.forEach(t),$Co=i(S),$u=n(S,"LI",{});var LIe=s($u);$he=n(LIe,"STRONG",{});var U6t=s($he);kCo=r(U6t,"speech_to_text_2"),U6t.forEach(t),SCo=r(LIe," \u2014 "),gG=n(LIe,"A",{href:!0});var H6t=s(gG);RCo=r(H6t,"Speech2Text2Tokenizer"),H6t.forEach(t),PCo=r(LIe," (Speech2Text2 model)"),LIe.forEach(t),BCo=i(S),sl=n(S,"LI",{});var zB=s(sl);khe=n(zB,"STRONG",{});var J6t=s(khe);ICo=r(J6t,"splinter"),J6t.forEach(t),NCo=r(zB," \u2014 "),hG=n(zB,"A",{href:!0});var Y6t=s(hG);qCo=r(Y6t,"SplinterTokenizer"),Y6t.forEach(t),jCo=r(zB," or "),uG=n(zB,"A",{href:!0});var K6t=s(uG);DCo=r(K6t,"SplinterTokenizerFast"),K6t.forEach(t),GCo=r(zB," (Splinter model)"),zB.forEach(t),OCo=i(S),ll=n(S,"LI",{});var QB=s(ll);She=n(QB,"STRONG",{});var Z6t=s(She);VCo=r(Z6t,"squeezebert"),Z6t.forEach(t),XCo=r(QB," \u2014 "),pG=n(QB,"A",{href:!0});var e7t=s(pG);zCo=r(e7t,"SqueezeBertTokenizer"),e7t.forEach(t),QCo=r(QB," or "),_G=n(QB,"A",{href:!0});var o7t=s(_G);WCo=r(o7t,"SqueezeBertTokenizerFast"),o7t.forEach(t),UCo=r(QB," (SqueezeBERT model)"),QB.forEach(t),HCo=i(S),il=n(S,"LI",{});var WB=s(il);Rhe=n(WB,"STRONG",{});var r7t=s(Rhe);JCo=r(r7t,"t5"),r7t.forEach(t),YCo=r(WB," \u2014 "),bG=n(WB,"A",{href:!0});var t7t=s(bG);KCo=r(t7t,"T5Tokenizer"),t7t.forEach(t),ZCo=r(WB," or "),vG=n(WB,"A",{href:!0});var a7t=s(vG);e3o=r(a7t,"T5TokenizerFast"),a7t.forEach(t),o3o=r(WB," (T5 model)"),WB.forEach(t),r3o=i(S),ku=n(S,"LI",{});var yIe=s(ku);Phe=n(yIe,"STRONG",{});var n7t=s(Phe);t3o=r(n7t,"tapas"),n7t.forEach(t),a3o=r(yIe," \u2014 "),FG=n(yIe,"A",{href:!0});var s7t=s(FG);n3o=r(s7t,"TapasTokenizer"),s7t.forEach(t),s3o=r(yIe," (TAPAS model)"),yIe.forEach(t),l3o=i(S),Su=n(S,"LI",{});var xIe=s(Su);Bhe=n(xIe,"STRONG",{});var l7t=s(Bhe);i3o=r(l7t,"tapex"),l7t.forEach(t),d3o=r(xIe," \u2014 "),TG=n(xIe,"A",{href:!0});var i7t=s(TG);m3o=r(i7t,"TapexTokenizer"),i7t.forEach(t),c3o=r(xIe," (TAPEX model)"),xIe.forEach(t),f3o=i(S),Ru=n(S,"LI",{});var $Ie=s(Ru);Ihe=n($Ie,"STRONG",{});var d7t=s(Ihe);g3o=r(d7t,"transfo-xl"),d7t.forEach(t),h3o=r($Ie," \u2014 "),MG=n($Ie,"A",{href:!0});var m7t=s(MG);u3o=r(m7t,"TransfoXLTokenizer"),m7t.forEach(t),p3o=r($Ie," (Transformer-XL model)"),$Ie.forEach(t),_3o=i(S),dl=n(S,"LI",{});var UB=s(dl);Nhe=n(UB,"STRONG",{});var c7t=s(Nhe);b3o=r(c7t,"vilt"),c7t.forEach(t),v3o=r(UB," \u2014 "),EG=n(UB,"A",{href:!0});var f7t=s(EG);F3o=r(f7t,"BertTokenizer"),f7t.forEach(t),T3o=r(UB," or "),CG=n(UB,"A",{href:!0});var g7t=s(CG);M3o=r(g7t,"BertTokenizerFast"),g7t.forEach(t),E3o=r(UB," (ViLT model)"),UB.forEach(t),C3o=i(S),ml=n(S,"LI",{});var HB=s(ml);qhe=n(HB,"STRONG",{});var h7t=s(qhe);w3o=r(h7t,"visual_bert"),h7t.forEach(t),A3o=r(HB," \u2014 "),wG=n(HB,"A",{href:!0});var u7t=s(wG);L3o=r(u7t,"BertTokenizer"),u7t.forEach(t),y3o=r(HB," or "),AG=n(HB,"A",{href:!0});var p7t=s(AG);x3o=r(p7t,"BertTokenizerFast"),p7t.forEach(t),$3o=r(HB," (VisualBERT model)"),HB.forEach(t),k3o=i(S),Pu=n(S,"LI",{});var kIe=s(Pu);jhe=n(kIe,"STRONG",{});var _7t=s(jhe);S3o=r(_7t,"wav2vec2"),_7t.forEach(t),R3o=r(kIe," \u2014 "),LG=n(kIe,"A",{href:!0});var b7t=s(LG);P3o=r(b7t,"Wav2Vec2CTCTokenizer"),b7t.forEach(t),B3o=r(kIe," (Wav2Vec2 model)"),kIe.forEach(t),I3o=i(S),Bu=n(S,"LI",{});var SIe=s(Bu);Dhe=n(SIe,"STRONG",{});var v7t=s(Dhe);N3o=r(v7t,"wav2vec2-conformer"),v7t.forEach(t),q3o=r(SIe," \u2014 "),yG=n(SIe,"A",{href:!0});var F7t=s(yG);j3o=r(F7t,"Wav2Vec2CTCTokenizer"),F7t.forEach(t),D3o=r(SIe," (Wav2Vec2-Conformer model)"),SIe.forEach(t),G3o=i(S),Iu=n(S,"LI",{});var RIe=s(Iu);Ghe=n(RIe,"STRONG",{});var T7t=s(Ghe);O3o=r(T7t,"wav2vec2_phoneme"),T7t.forEach(t),V3o=r(RIe," \u2014 "),xG=n(RIe,"A",{href:!0});var M7t=s(xG);X3o=r(M7t,"Wav2Vec2PhonemeCTCTokenizer"),M7t.forEach(t),z3o=r(RIe," (Wav2Vec2Phoneme model)"),RIe.forEach(t),Q3o=i(S),Nu=n(S,"LI",{});var PIe=s(Nu);Ohe=n(PIe,"STRONG",{});var E7t=s(Ohe);W3o=r(E7t,"whisper"),E7t.forEach(t),U3o=r(PIe," \u2014 "),$G=n(PIe,"A",{href:!0});var C7t=s($G);H3o=r(C7t,"WhisperTokenizer"),C7t.forEach(t),J3o=r(PIe," (Whisper model)"),PIe.forEach(t),Y3o=i(S),cl=n(S,"LI",{});var JB=s(cl);Vhe=n(JB,"STRONG",{});var w7t=s(Vhe);K3o=r(w7t,"xclip"),w7t.forEach(t),Z3o=r(JB," \u2014 "),kG=n(JB,"A",{href:!0});var A7t=s(kG);e5o=r(A7t,"CLIPTokenizer"),A7t.forEach(t),o5o=r(JB," or "),SG=n(JB,"A",{href:!0});var L7t=s(SG);r5o=r(L7t,"CLIPTokenizerFast"),L7t.forEach(t),t5o=r(JB," (X-CLIP model)"),JB.forEach(t),a5o=i(S),fl=n(S,"LI",{});var YB=s(fl);Xhe=n(YB,"STRONG",{});var y7t=s(Xhe);n5o=r(y7t,"xglm"),y7t.forEach(t),s5o=r(YB," \u2014 "),RG=n(YB,"A",{href:!0});var x7t=s(RG);l5o=r(x7t,"XGLMTokenizer"),x7t.forEach(t),i5o=r(YB," or "),PG=n(YB,"A",{href:!0});var $7t=s(PG);d5o=r($7t,"XGLMTokenizerFast"),$7t.forEach(t),m5o=r(YB," (XGLM model)"),YB.forEach(t),c5o=i(S),qu=n(S,"LI",{});var BIe=s(qu);zhe=n(BIe,"STRONG",{});var k7t=s(zhe);f5o=r(k7t,"xlm"),k7t.forEach(t),g5o=r(BIe," \u2014 "),BG=n(BIe,"A",{href:!0});var S7t=s(BG);h5o=r(S7t,"XLMTokenizer"),S7t.forEach(t),u5o=r(BIe," (XLM model)"),BIe.forEach(t),p5o=i(S),ju=n(S,"LI",{});var IIe=s(ju);Qhe=n(IIe,"STRONG",{});var R7t=s(Qhe);_5o=r(R7t,"xlm-prophetnet"),R7t.forEach(t),b5o=r(IIe," \u2014 "),IG=n(IIe,"A",{href:!0});var P7t=s(IG);v5o=r(P7t,"XLMProphetNetTokenizer"),P7t.forEach(t),F5o=r(IIe," (XLM-ProphetNet model)"),IIe.forEach(t),T5o=i(S),gl=n(S,"LI",{});var KB=s(gl);Whe=n(KB,"STRONG",{});var B7t=s(Whe);M5o=r(B7t,"xlm-roberta"),B7t.forEach(t),E5o=r(KB," \u2014 "),NG=n(KB,"A",{href:!0});var I7t=s(NG);C5o=r(I7t,"XLMRobertaTokenizer"),I7t.forEach(t),w5o=r(KB," or "),qG=n(KB,"A",{href:!0});var N7t=s(qG);A5o=r(N7t,"XLMRobertaTokenizerFast"),N7t.forEach(t),L5o=r(KB," (XLM-RoBERTa model)"),KB.forEach(t),y5o=i(S),hl=n(S,"LI",{});var ZB=s(hl);Uhe=n(ZB,"STRONG",{});var q7t=s(Uhe);x5o=r(q7t,"xlm-roberta-xl"),q7t.forEach(t),$5o=r(ZB," \u2014 "),jG=n(ZB,"A",{href:!0});var j7t=s(jG);k5o=r(j7t,"XLMRobertaTokenizer"),j7t.forEach(t),S5o=r(ZB," or "),DG=n(ZB,"A",{href:!0});var D7t=s(DG);R5o=r(D7t,"XLMRobertaTokenizerFast"),D7t.forEach(t),P5o=r(ZB," (XLM-RoBERTa-XL model)"),ZB.forEach(t),B5o=i(S),ul=n(S,"LI",{});var eI=s(ul);Hhe=n(eI,"STRONG",{});var G7t=s(Hhe);I5o=r(G7t,"xlnet"),G7t.forEach(t),N5o=r(eI," \u2014 "),GG=n(eI,"A",{href:!0});var O7t=s(GG);q5o=r(O7t,"XLNetTokenizer"),O7t.forEach(t),j5o=r(eI," or "),OG=n(eI,"A",{href:!0});var V7t=s(OG);D5o=r(V7t,"XLNetTokenizerFast"),V7t.forEach(t),G5o=r(eI," (XLNet model)"),eI.forEach(t),O5o=i(S),pl=n(S,"LI",{});var oI=s(pl);Jhe=n(oI,"STRONG",{});var X7t=s(Jhe);V5o=r(X7t,"yoso"),X7t.forEach(t),X5o=r(oI," \u2014 "),VG=n(oI,"A",{href:!0});var z7t=s(VG);z5o=r(z7t,"AlbertTokenizer"),z7t.forEach(t),Q5o=r(oI," or "),XG=n(oI,"A",{href:!0});var Q7t=s(XG);W5o=r(Q7t,"AlbertTokenizerFast"),Q7t.forEach(t),U5o=r(oI," (YOSO model)"),oI.forEach(t),S.forEach(t),H5o=i(El),T(Du.$$.fragment,El),El.forEach(t),J5o=i(Ml),Gu=n(Ml,"DIV",{class:!0});var Rro=s(Gu);T(Tx.$$.fragment,Rro),Y5o=i(Rro),Yhe=n(Rro,"P",{});var W7t=s(Yhe);K5o=r(W7t,"Register a new tokenizer in this mapping."),W7t.forEach(t),Rro.forEach(t),Ml.forEach(t),Ceo=i(c),hd=n(c,"H2",{class:!0});var Pro=s(hd);Ou=n(Pro,"A",{id:!0,class:!0,href:!0});var U7t=s(Ou);Khe=n(U7t,"SPAN",{});var H7t=s(Khe);T(Mx.$$.fragment,H7t),H7t.forEach(t),U7t.forEach(t),Z5o=i(Pro),Zhe=n(Pro,"SPAN",{});var J7t=s(Zhe);e0o=r(J7t,"AutoFeatureExtractor"),J7t.forEach(t),Pro.forEach(t),weo=i(c),So=n(c,"DIV",{class:!0});var Cl=s(So);T(Ex.$$.fragment,Cl),o0o=i(Cl),Cx=n(Cl,"P",{});var Bro=s(Cx);r0o=r(Bro,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),zG=n(Bro,"A",{href:!0});var Y7t=s(zG);t0o=r(Y7t,"AutoFeatureExtractor.from_pretrained()"),Y7t.forEach(t),a0o=r(Bro," class method."),Bro.forEach(t),n0o=i(Cl),wx=n(Cl,"P",{});var Iro=s(wx);s0o=r(Iro,"This class cannot be instantiated directly using "),eue=n(Iro,"CODE",{});var K7t=s(eue);l0o=r(K7t,"__init__()"),K7t.forEach(t),i0o=r(Iro," (throws an error)."),Iro.forEach(t),d0o=i(Cl),Ye=n(Cl,"DIV",{class:!0});var ba=s(Ye);T(Ax.$$.fragment,ba),m0o=i(ba),oue=n(ba,"P",{});var Z7t=s(oue);c0o=r(Z7t,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Z7t.forEach(t),f0o=i(ba),Ha=n(ba,"P",{});var o8=s(Ha);g0o=r(o8,"The feature extractor class to instantiate is selected based on the "),rue=n(o8,"CODE",{});var eLt=s(rue);h0o=r(eLt,"model_type"),eLt.forEach(t),u0o=r(o8,` property of the config object
(either passed as an argument or loaded from `),tue=n(o8,"CODE",{});var oLt=s(tue);p0o=r(oLt,"pretrained_model_name_or_path"),oLt.forEach(t),_0o=r(o8,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),aue=n(o8,"CODE",{});var rLt=s(aue);b0o=r(rLt,"pretrained_model_name_or_path"),rLt.forEach(t),v0o=r(o8,":"),o8.forEach(t),F0o=i(ba),z=n(ba,"UL",{});var W=s(z);Vu=n(W,"LI",{});var NIe=s(Vu);nue=n(NIe,"STRONG",{});var tLt=s(nue);T0o=r(tLt,"beit"),tLt.forEach(t),M0o=r(NIe," \u2014 "),QG=n(NIe,"A",{href:!0});var aLt=s(QG);E0o=r(aLt,"BeitFeatureExtractor"),aLt.forEach(t),C0o=r(NIe," (BEiT model)"),NIe.forEach(t),w0o=i(W),Xu=n(W,"LI",{});var qIe=s(Xu);sue=n(qIe,"STRONG",{});var nLt=s(sue);A0o=r(nLt,"clip"),nLt.forEach(t),L0o=r(qIe," \u2014 "),WG=n(qIe,"A",{href:!0});var sLt=s(WG);y0o=r(sLt,"CLIPFeatureExtractor"),sLt.forEach(t),x0o=r(qIe," (CLIP model)"),qIe.forEach(t),$0o=i(W),zu=n(W,"LI",{});var jIe=s(zu);lue=n(jIe,"STRONG",{});var lLt=s(lue);k0o=r(lLt,"conditional_detr"),lLt.forEach(t),S0o=r(jIe," \u2014 "),UG=n(jIe,"A",{href:!0});var iLt=s(UG);R0o=r(iLt,"ConditionalDetrFeatureExtractor"),iLt.forEach(t),P0o=r(jIe," (Conditional DETR model)"),jIe.forEach(t),B0o=i(W),Qu=n(W,"LI",{});var DIe=s(Qu);iue=n(DIe,"STRONG",{});var dLt=s(iue);I0o=r(dLt,"convnext"),dLt.forEach(t),N0o=r(DIe," \u2014 "),HG=n(DIe,"A",{href:!0});var mLt=s(HG);q0o=r(mLt,"ConvNextFeatureExtractor"),mLt.forEach(t),j0o=r(DIe," (ConvNeXT model)"),DIe.forEach(t),D0o=i(W),Wu=n(W,"LI",{});var GIe=s(Wu);due=n(GIe,"STRONG",{});var cLt=s(due);G0o=r(cLt,"cvt"),cLt.forEach(t),O0o=r(GIe," \u2014 "),JG=n(GIe,"A",{href:!0});var fLt=s(JG);V0o=r(fLt,"ConvNextFeatureExtractor"),fLt.forEach(t),X0o=r(GIe," (CvT model)"),GIe.forEach(t),z0o=i(W),Uu=n(W,"LI",{});var OIe=s(Uu);mue=n(OIe,"STRONG",{});var gLt=s(mue);Q0o=r(gLt,"data2vec-audio"),gLt.forEach(t),W0o=r(OIe," \u2014 "),YG=n(OIe,"A",{href:!0});var hLt=s(YG);U0o=r(hLt,"Wav2Vec2FeatureExtractor"),hLt.forEach(t),H0o=r(OIe," (Data2VecAudio model)"),OIe.forEach(t),J0o=i(W),Hu=n(W,"LI",{});var VIe=s(Hu);cue=n(VIe,"STRONG",{});var uLt=s(cue);Y0o=r(uLt,"data2vec-vision"),uLt.forEach(t),K0o=r(VIe," \u2014 "),KG=n(VIe,"A",{href:!0});var pLt=s(KG);Z0o=r(pLt,"BeitFeatureExtractor"),pLt.forEach(t),ewo=r(VIe," (Data2VecVision model)"),VIe.forEach(t),owo=i(W),Ju=n(W,"LI",{});var XIe=s(Ju);fue=n(XIe,"STRONG",{});var _Lt=s(fue);rwo=r(_Lt,"deformable_detr"),_Lt.forEach(t),two=r(XIe," \u2014 "),ZG=n(XIe,"A",{href:!0});var bLt=s(ZG);awo=r(bLt,"DeformableDetrFeatureExtractor"),bLt.forEach(t),nwo=r(XIe," (Deformable DETR model)"),XIe.forEach(t),swo=i(W),Yu=n(W,"LI",{});var zIe=s(Yu);gue=n(zIe,"STRONG",{});var vLt=s(gue);lwo=r(vLt,"deit"),vLt.forEach(t),iwo=r(zIe," \u2014 "),eO=n(zIe,"A",{href:!0});var FLt=s(eO);dwo=r(FLt,"DeiTFeatureExtractor"),FLt.forEach(t),mwo=r(zIe," (DeiT model)"),zIe.forEach(t),cwo=i(W),Ku=n(W,"LI",{});var QIe=s(Ku);hue=n(QIe,"STRONG",{});var TLt=s(hue);fwo=r(TLt,"detr"),TLt.forEach(t),gwo=r(QIe," \u2014 "),oO=n(QIe,"A",{href:!0});var MLt=s(oO);hwo=r(MLt,"DetrFeatureExtractor"),MLt.forEach(t),uwo=r(QIe," (DETR model)"),QIe.forEach(t),pwo=i(W),Zu=n(W,"LI",{});var WIe=s(Zu);uue=n(WIe,"STRONG",{});var ELt=s(uue);_wo=r(ELt,"donut"),ELt.forEach(t),bwo=r(WIe," \u2014 "),rO=n(WIe,"A",{href:!0});var CLt=s(rO);vwo=r(CLt,"DonutFeatureExtractor"),CLt.forEach(t),Fwo=r(WIe," (Donut model)"),WIe.forEach(t),Two=i(W),ep=n(W,"LI",{});var UIe=s(ep);pue=n(UIe,"STRONG",{});var wLt=s(pue);Mwo=r(wLt,"dpt"),wLt.forEach(t),Ewo=r(UIe," \u2014 "),tO=n(UIe,"A",{href:!0});var ALt=s(tO);Cwo=r(ALt,"DPTFeatureExtractor"),ALt.forEach(t),wwo=r(UIe," (DPT model)"),UIe.forEach(t),Awo=i(W),op=n(W,"LI",{});var HIe=s(op);_ue=n(HIe,"STRONG",{});var LLt=s(_ue);Lwo=r(LLt,"flava"),LLt.forEach(t),ywo=r(HIe," \u2014 "),aO=n(HIe,"A",{href:!0});var yLt=s(aO);xwo=r(yLt,"FlavaFeatureExtractor"),yLt.forEach(t),$wo=r(HIe," (FLAVA model)"),HIe.forEach(t),kwo=i(W),rp=n(W,"LI",{});var JIe=s(rp);bue=n(JIe,"STRONG",{});var xLt=s(bue);Swo=r(xLt,"glpn"),xLt.forEach(t),Rwo=r(JIe," \u2014 "),nO=n(JIe,"A",{href:!0});var $Lt=s(nO);Pwo=r($Lt,"GLPNFeatureExtractor"),$Lt.forEach(t),Bwo=r(JIe," (GLPN model)"),JIe.forEach(t),Iwo=i(W),tp=n(W,"LI",{});var YIe=s(tp);vue=n(YIe,"STRONG",{});var kLt=s(vue);Nwo=r(kLt,"groupvit"),kLt.forEach(t),qwo=r(YIe," \u2014 "),sO=n(YIe,"A",{href:!0});var SLt=s(sO);jwo=r(SLt,"CLIPFeatureExtractor"),SLt.forEach(t),Dwo=r(YIe," (GroupViT model)"),YIe.forEach(t),Gwo=i(W),ap=n(W,"LI",{});var KIe=s(ap);Fue=n(KIe,"STRONG",{});var RLt=s(Fue);Owo=r(RLt,"hubert"),RLt.forEach(t),Vwo=r(KIe," \u2014 "),lO=n(KIe,"A",{href:!0});var PLt=s(lO);Xwo=r(PLt,"Wav2Vec2FeatureExtractor"),PLt.forEach(t),zwo=r(KIe," (Hubert model)"),KIe.forEach(t),Qwo=i(W),np=n(W,"LI",{});var ZIe=s(np);Tue=n(ZIe,"STRONG",{});var BLt=s(Tue);Wwo=r(BLt,"imagegpt"),BLt.forEach(t),Uwo=r(ZIe," \u2014 "),iO=n(ZIe,"A",{href:!0});var ILt=s(iO);Hwo=r(ILt,"ImageGPTFeatureExtractor"),ILt.forEach(t),Jwo=r(ZIe," (ImageGPT model)"),ZIe.forEach(t),Ywo=i(W),sp=n(W,"LI",{});var eNe=s(sp);Mue=n(eNe,"STRONG",{});var NLt=s(Mue);Kwo=r(NLt,"layoutlmv2"),NLt.forEach(t),Zwo=r(eNe," \u2014 "),dO=n(eNe,"A",{href:!0});var qLt=s(dO);eAo=r(qLt,"LayoutLMv2FeatureExtractor"),qLt.forEach(t),oAo=r(eNe," (LayoutLMv2 model)"),eNe.forEach(t),rAo=i(W),lp=n(W,"LI",{});var oNe=s(lp);Eue=n(oNe,"STRONG",{});var jLt=s(Eue);tAo=r(jLt,"layoutlmv3"),jLt.forEach(t),aAo=r(oNe," \u2014 "),mO=n(oNe,"A",{href:!0});var DLt=s(mO);nAo=r(DLt,"LayoutLMv3FeatureExtractor"),DLt.forEach(t),sAo=r(oNe," (LayoutLMv3 model)"),oNe.forEach(t),lAo=i(W),ip=n(W,"LI",{});var rNe=s(ip);Cue=n(rNe,"STRONG",{});var GLt=s(Cue);iAo=r(GLt,"levit"),GLt.forEach(t),dAo=r(rNe," \u2014 "),cO=n(rNe,"A",{href:!0});var OLt=s(cO);mAo=r(OLt,"LevitFeatureExtractor"),OLt.forEach(t),cAo=r(rNe," (LeViT model)"),rNe.forEach(t),fAo=i(W),dp=n(W,"LI",{});var tNe=s(dp);wue=n(tNe,"STRONG",{});var VLt=s(wue);gAo=r(VLt,"maskformer"),VLt.forEach(t),hAo=r(tNe," \u2014 "),fO=n(tNe,"A",{href:!0});var XLt=s(fO);uAo=r(XLt,"MaskFormerFeatureExtractor"),XLt.forEach(t),pAo=r(tNe," (MaskFormer model)"),tNe.forEach(t),_Ao=i(W),mp=n(W,"LI",{});var aNe=s(mp);Aue=n(aNe,"STRONG",{});var zLt=s(Aue);bAo=r(zLt,"mctct"),zLt.forEach(t),vAo=r(aNe," \u2014 "),gO=n(aNe,"A",{href:!0});var QLt=s(gO);FAo=r(QLt,"MCTCTFeatureExtractor"),QLt.forEach(t),TAo=r(aNe," (M-CTC-T model)"),aNe.forEach(t),MAo=i(W),cp=n(W,"LI",{});var nNe=s(cp);Lue=n(nNe,"STRONG",{});var WLt=s(Lue);EAo=r(WLt,"mobilevit"),WLt.forEach(t),CAo=r(nNe," \u2014 "),hO=n(nNe,"A",{href:!0});var ULt=s(hO);wAo=r(ULt,"MobileViTFeatureExtractor"),ULt.forEach(t),AAo=r(nNe," (MobileViT model)"),nNe.forEach(t),LAo=i(W),fp=n(W,"LI",{});var sNe=s(fp);yue=n(sNe,"STRONG",{});var HLt=s(yue);yAo=r(HLt,"owlvit"),HLt.forEach(t),xAo=r(sNe," \u2014 "),uO=n(sNe,"A",{href:!0});var JLt=s(uO);$Ao=r(JLt,"OwlViTFeatureExtractor"),JLt.forEach(t),kAo=r(sNe," (OWL-ViT model)"),sNe.forEach(t),SAo=i(W),gp=n(W,"LI",{});var lNe=s(gp);xue=n(lNe,"STRONG",{});var YLt=s(xue);RAo=r(YLt,"perceiver"),YLt.forEach(t),PAo=r(lNe," \u2014 "),pO=n(lNe,"A",{href:!0});var KLt=s(pO);BAo=r(KLt,"PerceiverFeatureExtractor"),KLt.forEach(t),IAo=r(lNe," (Perceiver model)"),lNe.forEach(t),NAo=i(W),hp=n(W,"LI",{});var iNe=s(hp);$ue=n(iNe,"STRONG",{});var ZLt=s($ue);qAo=r(ZLt,"poolformer"),ZLt.forEach(t),jAo=r(iNe," \u2014 "),_O=n(iNe,"A",{href:!0});var eyt=s(_O);DAo=r(eyt,"PoolFormerFeatureExtractor"),eyt.forEach(t),GAo=r(iNe," (PoolFormer model)"),iNe.forEach(t),OAo=i(W),up=n(W,"LI",{});var dNe=s(up);kue=n(dNe,"STRONG",{});var oyt=s(kue);VAo=r(oyt,"regnet"),oyt.forEach(t),XAo=r(dNe," \u2014 "),bO=n(dNe,"A",{href:!0});var ryt=s(bO);zAo=r(ryt,"ConvNextFeatureExtractor"),ryt.forEach(t),QAo=r(dNe," (RegNet model)"),dNe.forEach(t),WAo=i(W),pp=n(W,"LI",{});var mNe=s(pp);Sue=n(mNe,"STRONG",{});var tyt=s(Sue);UAo=r(tyt,"resnet"),tyt.forEach(t),HAo=r(mNe," \u2014 "),vO=n(mNe,"A",{href:!0});var ayt=s(vO);JAo=r(ayt,"ConvNextFeatureExtractor"),ayt.forEach(t),YAo=r(mNe," (ResNet model)"),mNe.forEach(t),KAo=i(W),_p=n(W,"LI",{});var cNe=s(_p);Rue=n(cNe,"STRONG",{});var nyt=s(Rue);ZAo=r(nyt,"segformer"),nyt.forEach(t),e6o=r(cNe," \u2014 "),FO=n(cNe,"A",{href:!0});var syt=s(FO);o6o=r(syt,"SegformerFeatureExtractor"),syt.forEach(t),r6o=r(cNe," (SegFormer model)"),cNe.forEach(t),t6o=i(W),bp=n(W,"LI",{});var fNe=s(bp);Pue=n(fNe,"STRONG",{});var lyt=s(Pue);a6o=r(lyt,"speech_to_text"),lyt.forEach(t),n6o=r(fNe," \u2014 "),TO=n(fNe,"A",{href:!0});var iyt=s(TO);s6o=r(iyt,"Speech2TextFeatureExtractor"),iyt.forEach(t),l6o=r(fNe," (Speech2Text model)"),fNe.forEach(t),i6o=i(W),vp=n(W,"LI",{});var gNe=s(vp);Bue=n(gNe,"STRONG",{});var dyt=s(Bue);d6o=r(dyt,"swin"),dyt.forEach(t),m6o=r(gNe," \u2014 "),MO=n(gNe,"A",{href:!0});var myt=s(MO);c6o=r(myt,"ViTFeatureExtractor"),myt.forEach(t),f6o=r(gNe," (Swin Transformer model)"),gNe.forEach(t),g6o=i(W),Fp=n(W,"LI",{});var hNe=s(Fp);Iue=n(hNe,"STRONG",{});var cyt=s(Iue);h6o=r(cyt,"swinv2"),cyt.forEach(t),u6o=r(hNe," \u2014 "),EO=n(hNe,"A",{href:!0});var fyt=s(EO);p6o=r(fyt,"ViTFeatureExtractor"),fyt.forEach(t),_6o=r(hNe," (Swin Transformer V2 model)"),hNe.forEach(t),b6o=i(W),Tp=n(W,"LI",{});var uNe=s(Tp);Nue=n(uNe,"STRONG",{});var gyt=s(Nue);v6o=r(gyt,"van"),gyt.forEach(t),F6o=r(uNe," \u2014 "),CO=n(uNe,"A",{href:!0});var hyt=s(CO);T6o=r(hyt,"ConvNextFeatureExtractor"),hyt.forEach(t),M6o=r(uNe," (VAN model)"),uNe.forEach(t),E6o=i(W),Mp=n(W,"LI",{});var pNe=s(Mp);que=n(pNe,"STRONG",{});var uyt=s(que);C6o=r(uyt,"videomae"),uyt.forEach(t),w6o=r(pNe," \u2014 "),wO=n(pNe,"A",{href:!0});var pyt=s(wO);A6o=r(pyt,"VideoMAEFeatureExtractor"),pyt.forEach(t),L6o=r(pNe," (VideoMAE model)"),pNe.forEach(t),y6o=i(W),Ep=n(W,"LI",{});var _Ne=s(Ep);jue=n(_Ne,"STRONG",{});var _yt=s(jue);x6o=r(_yt,"vilt"),_yt.forEach(t),$6o=r(_Ne," \u2014 "),AO=n(_Ne,"A",{href:!0});var byt=s(AO);k6o=r(byt,"ViltFeatureExtractor"),byt.forEach(t),S6o=r(_Ne," (ViLT model)"),_Ne.forEach(t),R6o=i(W),Cp=n(W,"LI",{});var bNe=s(Cp);Due=n(bNe,"STRONG",{});var vyt=s(Due);P6o=r(vyt,"vit"),vyt.forEach(t),B6o=r(bNe," \u2014 "),LO=n(bNe,"A",{href:!0});var Fyt=s(LO);I6o=r(Fyt,"ViTFeatureExtractor"),Fyt.forEach(t),N6o=r(bNe," (ViT model)"),bNe.forEach(t),q6o=i(W),wp=n(W,"LI",{});var vNe=s(wp);Gue=n(vNe,"STRONG",{});var Tyt=s(Gue);j6o=r(Tyt,"vit_mae"),Tyt.forEach(t),D6o=r(vNe," \u2014 "),yO=n(vNe,"A",{href:!0});var Myt=s(yO);G6o=r(Myt,"ViTFeatureExtractor"),Myt.forEach(t),O6o=r(vNe," (ViTMAE model)"),vNe.forEach(t),V6o=i(W),Ap=n(W,"LI",{});var FNe=s(Ap);Oue=n(FNe,"STRONG",{});var Eyt=s(Oue);X6o=r(Eyt,"vit_msn"),Eyt.forEach(t),z6o=r(FNe," \u2014 "),xO=n(FNe,"A",{href:!0});var Cyt=s(xO);Q6o=r(Cyt,"ViTFeatureExtractor"),Cyt.forEach(t),W6o=r(FNe," (ViTMSN model)"),FNe.forEach(t),U6o=i(W),Lp=n(W,"LI",{});var TNe=s(Lp);Vue=n(TNe,"STRONG",{});var wyt=s(Vue);H6o=r(wyt,"wav2vec2"),wyt.forEach(t),J6o=r(TNe," \u2014 "),$O=n(TNe,"A",{href:!0});var Ayt=s($O);Y6o=r(Ayt,"Wav2Vec2FeatureExtractor"),Ayt.forEach(t),K6o=r(TNe," (Wav2Vec2 model)"),TNe.forEach(t),Z6o=i(W),yp=n(W,"LI",{});var MNe=s(yp);Xue=n(MNe,"STRONG",{});var Lyt=s(Xue);e7o=r(Lyt,"wav2vec2-conformer"),Lyt.forEach(t),o7o=r(MNe," \u2014 "),kO=n(MNe,"A",{href:!0});var yyt=s(kO);r7o=r(yyt,"Wav2Vec2FeatureExtractor"),yyt.forEach(t),t7o=r(MNe," (Wav2Vec2-Conformer model)"),MNe.forEach(t),a7o=i(W),xp=n(W,"LI",{});var ENe=s(xp);zue=n(ENe,"STRONG",{});var xyt=s(zue);n7o=r(xyt,"whisper"),xyt.forEach(t),s7o=r(ENe," \u2014 "),SO=n(ENe,"A",{href:!0});var $yt=s(SO);l7o=r($yt,"WhisperFeatureExtractor"),$yt.forEach(t),i7o=r(ENe," (Whisper model)"),ENe.forEach(t),d7o=i(W),$p=n(W,"LI",{});var CNe=s($p);Que=n(CNe,"STRONG",{});var kyt=s(Que);m7o=r(kyt,"xclip"),kyt.forEach(t),c7o=r(CNe," \u2014 "),RO=n(CNe,"A",{href:!0});var Syt=s(RO);f7o=r(Syt,"CLIPFeatureExtractor"),Syt.forEach(t),g7o=r(CNe," (X-CLIP model)"),CNe.forEach(t),h7o=i(W),kp=n(W,"LI",{});var wNe=s(kp);Wue=n(wNe,"STRONG",{});var Ryt=s(Wue);u7o=r(Ryt,"yolos"),Ryt.forEach(t),p7o=r(wNe," \u2014 "),PO=n(wNe,"A",{href:!0});var Pyt=s(PO);_7o=r(Pyt,"YolosFeatureExtractor"),Pyt.forEach(t),b7o=r(wNe," (YOLOS model)"),wNe.forEach(t),W.forEach(t),v7o=i(ba),T(Sp.$$.fragment,ba),F7o=i(ba),T(Rp.$$.fragment,ba),ba.forEach(t),T7o=i(Cl),Pp=n(Cl,"DIV",{class:!0});var Nro=s(Pp);T(Lx.$$.fragment,Nro),M7o=i(Nro),Uue=n(Nro,"P",{});var Byt=s(Uue);E7o=r(Byt,"Register a new feature extractor for this class."),Byt.forEach(t),Nro.forEach(t),Cl.forEach(t),Aeo=i(c),ud=n(c,"H2",{class:!0});var qro=s(ud);Bp=n(qro,"A",{id:!0,class:!0,href:!0});var Iyt=s(Bp);Hue=n(Iyt,"SPAN",{});var Nyt=s(Hue);T(yx.$$.fragment,Nyt),Nyt.forEach(t),Iyt.forEach(t),C7o=i(qro),Jue=n(qro,"SPAN",{});var qyt=s(Jue);w7o=r(qyt,"AutoProcessor"),qyt.forEach(t),qro.forEach(t),Leo=i(c),Ro=n(c,"DIV",{class:!0});var wl=s(Ro);T(xx.$$.fragment,wl),A7o=i(wl),$x=n(wl,"P",{});var jro=s($x);L7o=r(jro,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),BO=n(jro,"A",{href:!0});var jyt=s(BO);y7o=r(jyt,"AutoProcessor.from_pretrained()"),jyt.forEach(t),x7o=r(jro," class method."),jro.forEach(t),$7o=i(wl),kx=n(wl,"P",{});var Dro=s(kx);k7o=r(Dro,"This class cannot be instantiated directly using "),Yue=n(Dro,"CODE",{});var Dyt=s(Yue);S7o=r(Dyt,"__init__()"),Dyt.forEach(t),R7o=r(Dro," (throws an error)."),Dro.forEach(t),P7o=i(wl),Ke=n(wl,"DIV",{class:!0});var va=s(Ke);T(Sx.$$.fragment,va),B7o=i(va),Kue=n(va,"P",{});var Gyt=s(Kue);I7o=r(Gyt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),Gyt.forEach(t),N7o=i(va),pd=n(va,"P",{});var cie=s(pd);q7o=r(cie,"The processor class to instantiate is selected based on the "),Zue=n(cie,"CODE",{});var Oyt=s(Zue);j7o=r(Oyt,"model_type"),Oyt.forEach(t),D7o=r(cie,` property of the config object (either
passed as an argument or loaded from `),epe=n(cie,"CODE",{});var Vyt=s(epe);G7o=r(Vyt,"pretrained_model_name_or_path"),Vyt.forEach(t),O7o=r(cie," if possible):"),cie.forEach(t),V7o=i(va),se=n(va,"UL",{});var ie=s(se);Ip=n(ie,"LI",{});var ANe=s(Ip);ope=n(ANe,"STRONG",{});var Xyt=s(ope);X7o=r(Xyt,"clip"),Xyt.forEach(t),z7o=r(ANe," \u2014 "),IO=n(ANe,"A",{href:!0});var zyt=s(IO);Q7o=r(zyt,"CLIPProcessor"),zyt.forEach(t),W7o=r(ANe," (CLIP model)"),ANe.forEach(t),U7o=i(ie),Np=n(ie,"LI",{});var LNe=s(Np);rpe=n(LNe,"STRONG",{});var Qyt=s(rpe);H7o=r(Qyt,"donut"),Qyt.forEach(t),J7o=r(LNe," \u2014 "),NO=n(LNe,"A",{href:!0});var Wyt=s(NO);Y7o=r(Wyt,"DonutProcessor"),Wyt.forEach(t),K7o=r(LNe," (Donut model)"),LNe.forEach(t),Z7o=i(ie),qp=n(ie,"LI",{});var yNe=s(qp);tpe=n(yNe,"STRONG",{});var Uyt=s(tpe);eLo=r(Uyt,"flava"),Uyt.forEach(t),oLo=r(yNe," \u2014 "),qO=n(yNe,"A",{href:!0});var Hyt=s(qO);rLo=r(Hyt,"FlavaProcessor"),Hyt.forEach(t),tLo=r(yNe," (FLAVA model)"),yNe.forEach(t),aLo=i(ie),jp=n(ie,"LI",{});var xNe=s(jp);ape=n(xNe,"STRONG",{});var Jyt=s(ape);nLo=r(Jyt,"groupvit"),Jyt.forEach(t),sLo=r(xNe," \u2014 "),jO=n(xNe,"A",{href:!0});var Yyt=s(jO);lLo=r(Yyt,"CLIPProcessor"),Yyt.forEach(t),iLo=r(xNe," (GroupViT model)"),xNe.forEach(t),dLo=i(ie),Dp=n(ie,"LI",{});var $Ne=s(Dp);npe=n($Ne,"STRONG",{});var Kyt=s(npe);mLo=r(Kyt,"layoutlmv2"),Kyt.forEach(t),cLo=r($Ne," \u2014 "),DO=n($Ne,"A",{href:!0});var Zyt=s(DO);fLo=r(Zyt,"LayoutLMv2Processor"),Zyt.forEach(t),gLo=r($Ne," (LayoutLMv2 model)"),$Ne.forEach(t),hLo=i(ie),Gp=n(ie,"LI",{});var kNe=s(Gp);spe=n(kNe,"STRONG",{});var e8t=s(spe);uLo=r(e8t,"layoutlmv3"),e8t.forEach(t),pLo=r(kNe," \u2014 "),GO=n(kNe,"A",{href:!0});var o8t=s(GO);_Lo=r(o8t,"LayoutLMv3Processor"),o8t.forEach(t),bLo=r(kNe," (LayoutLMv3 model)"),kNe.forEach(t),vLo=i(ie),Op=n(ie,"LI",{});var SNe=s(Op);lpe=n(SNe,"STRONG",{});var r8t=s(lpe);FLo=r(r8t,"layoutxlm"),r8t.forEach(t),TLo=r(SNe," \u2014 "),OO=n(SNe,"A",{href:!0});var t8t=s(OO);MLo=r(t8t,"LayoutXLMProcessor"),t8t.forEach(t),ELo=r(SNe," (LayoutXLM model)"),SNe.forEach(t),CLo=i(ie),Vp=n(ie,"LI",{});var RNe=s(Vp);ipe=n(RNe,"STRONG",{});var a8t=s(ipe);wLo=r(a8t,"markuplm"),a8t.forEach(t),ALo=r(RNe," \u2014 "),VO=n(RNe,"A",{href:!0});var n8t=s(VO);LLo=r(n8t,"MarkupLMProcessor"),n8t.forEach(t),yLo=r(RNe," (MarkupLM model)"),RNe.forEach(t),xLo=i(ie),Xp=n(ie,"LI",{});var PNe=s(Xp);dpe=n(PNe,"STRONG",{});var s8t=s(dpe);$Lo=r(s8t,"owlvit"),s8t.forEach(t),kLo=r(PNe," \u2014 "),XO=n(PNe,"A",{href:!0});var l8t=s(XO);SLo=r(l8t,"OwlViTProcessor"),l8t.forEach(t),RLo=r(PNe," (OWL-ViT model)"),PNe.forEach(t),PLo=i(ie),zp=n(ie,"LI",{});var BNe=s(zp);mpe=n(BNe,"STRONG",{});var i8t=s(mpe);BLo=r(i8t,"sew"),i8t.forEach(t),ILo=r(BNe," \u2014 "),zO=n(BNe,"A",{href:!0});var d8t=s(zO);NLo=r(d8t,"Wav2Vec2Processor"),d8t.forEach(t),qLo=r(BNe," (SEW model)"),BNe.forEach(t),jLo=i(ie),Qp=n(ie,"LI",{});var INe=s(Qp);cpe=n(INe,"STRONG",{});var m8t=s(cpe);DLo=r(m8t,"sew-d"),m8t.forEach(t),GLo=r(INe," \u2014 "),QO=n(INe,"A",{href:!0});var c8t=s(QO);OLo=r(c8t,"Wav2Vec2Processor"),c8t.forEach(t),VLo=r(INe," (SEW-D model)"),INe.forEach(t),XLo=i(ie),Wp=n(ie,"LI",{});var NNe=s(Wp);fpe=n(NNe,"STRONG",{});var f8t=s(fpe);zLo=r(f8t,"speech_to_text"),f8t.forEach(t),QLo=r(NNe," \u2014 "),WO=n(NNe,"A",{href:!0});var g8t=s(WO);WLo=r(g8t,"Speech2TextProcessor"),g8t.forEach(t),ULo=r(NNe," (Speech2Text model)"),NNe.forEach(t),HLo=i(ie),Up=n(ie,"LI",{});var qNe=s(Up);gpe=n(qNe,"STRONG",{});var h8t=s(gpe);JLo=r(h8t,"speech_to_text_2"),h8t.forEach(t),YLo=r(qNe," \u2014 "),UO=n(qNe,"A",{href:!0});var u8t=s(UO);KLo=r(u8t,"Speech2Text2Processor"),u8t.forEach(t),ZLo=r(qNe," (Speech2Text2 model)"),qNe.forEach(t),eyo=i(ie),Hp=n(ie,"LI",{});var jNe=s(Hp);hpe=n(jNe,"STRONG",{});var p8t=s(hpe);oyo=r(p8t,"trocr"),p8t.forEach(t),ryo=r(jNe," \u2014 "),HO=n(jNe,"A",{href:!0});var _8t=s(HO);tyo=r(_8t,"TrOCRProcessor"),_8t.forEach(t),ayo=r(jNe," (TrOCR model)"),jNe.forEach(t),nyo=i(ie),Jp=n(ie,"LI",{});var DNe=s(Jp);upe=n(DNe,"STRONG",{});var b8t=s(upe);syo=r(b8t,"unispeech"),b8t.forEach(t),lyo=r(DNe," \u2014 "),JO=n(DNe,"A",{href:!0});var v8t=s(JO);iyo=r(v8t,"Wav2Vec2Processor"),v8t.forEach(t),dyo=r(DNe," (UniSpeech model)"),DNe.forEach(t),myo=i(ie),Yp=n(ie,"LI",{});var GNe=s(Yp);ppe=n(GNe,"STRONG",{});var F8t=s(ppe);cyo=r(F8t,"unispeech-sat"),F8t.forEach(t),fyo=r(GNe," \u2014 "),YO=n(GNe,"A",{href:!0});var T8t=s(YO);gyo=r(T8t,"Wav2Vec2Processor"),T8t.forEach(t),hyo=r(GNe," (UniSpeechSat model)"),GNe.forEach(t),uyo=i(ie),Kp=n(ie,"LI",{});var ONe=s(Kp);_pe=n(ONe,"STRONG",{});var M8t=s(_pe);pyo=r(M8t,"vilt"),M8t.forEach(t),_yo=r(ONe," \u2014 "),KO=n(ONe,"A",{href:!0});var E8t=s(KO);byo=r(E8t,"ViltProcessor"),E8t.forEach(t),vyo=r(ONe," (ViLT model)"),ONe.forEach(t),Fyo=i(ie),Zp=n(ie,"LI",{});var VNe=s(Zp);bpe=n(VNe,"STRONG",{});var C8t=s(bpe);Tyo=r(C8t,"vision-text-dual-encoder"),C8t.forEach(t),Myo=r(VNe," \u2014 "),ZO=n(VNe,"A",{href:!0});var w8t=s(ZO);Eyo=r(w8t,"VisionTextDualEncoderProcessor"),w8t.forEach(t),Cyo=r(VNe," (VisionTextDualEncoder model)"),VNe.forEach(t),wyo=i(ie),e_=n(ie,"LI",{});var XNe=s(e_);vpe=n(XNe,"STRONG",{});var A8t=s(vpe);Ayo=r(A8t,"wav2vec2"),A8t.forEach(t),Lyo=r(XNe," \u2014 "),eV=n(XNe,"A",{href:!0});var L8t=s(eV);yyo=r(L8t,"Wav2Vec2Processor"),L8t.forEach(t),xyo=r(XNe," (Wav2Vec2 model)"),XNe.forEach(t),$yo=i(ie),o_=n(ie,"LI",{});var zNe=s(o_);Fpe=n(zNe,"STRONG",{});var y8t=s(Fpe);kyo=r(y8t,"wav2vec2-conformer"),y8t.forEach(t),Syo=r(zNe," \u2014 "),oV=n(zNe,"A",{href:!0});var x8t=s(oV);Ryo=r(x8t,"Wav2Vec2Processor"),x8t.forEach(t),Pyo=r(zNe," (Wav2Vec2-Conformer model)"),zNe.forEach(t),Byo=i(ie),r_=n(ie,"LI",{});var QNe=s(r_);Tpe=n(QNe,"STRONG",{});var $8t=s(Tpe);Iyo=r($8t,"wavlm"),$8t.forEach(t),Nyo=r(QNe," \u2014 "),rV=n(QNe,"A",{href:!0});var k8t=s(rV);qyo=r(k8t,"Wav2Vec2Processor"),k8t.forEach(t),jyo=r(QNe," (WavLM model)"),QNe.forEach(t),Dyo=i(ie),t_=n(ie,"LI",{});var WNe=s(t_);Mpe=n(WNe,"STRONG",{});var S8t=s(Mpe);Gyo=r(S8t,"whisper"),S8t.forEach(t),Oyo=r(WNe," \u2014 "),tV=n(WNe,"A",{href:!0});var R8t=s(tV);Vyo=r(R8t,"WhisperProcessor"),R8t.forEach(t),Xyo=r(WNe," (Whisper model)"),WNe.forEach(t),zyo=i(ie),a_=n(ie,"LI",{});var UNe=s(a_);Epe=n(UNe,"STRONG",{});var P8t=s(Epe);Qyo=r(P8t,"xclip"),P8t.forEach(t),Wyo=r(UNe," \u2014 "),aV=n(UNe,"A",{href:!0});var B8t=s(aV);Uyo=r(B8t,"CLIPProcessor"),B8t.forEach(t),Hyo=r(UNe," (X-CLIP model)"),UNe.forEach(t),ie.forEach(t),Jyo=i(va),T(n_.$$.fragment,va),Yyo=i(va),T(s_.$$.fragment,va),va.forEach(t),Kyo=i(wl),l_=n(wl,"DIV",{class:!0});var Gro=s(l_);T(Rx.$$.fragment,Gro),Zyo=i(Gro),Cpe=n(Gro,"P",{});var I8t=s(Cpe);e8o=r(I8t,"Register a new processor for this class."),I8t.forEach(t),Gro.forEach(t),wl.forEach(t),yeo=i(c),_d=n(c,"H2",{class:!0});var Oro=s(_d);i_=n(Oro,"A",{id:!0,class:!0,href:!0});var N8t=s(i_);wpe=n(N8t,"SPAN",{});var q8t=s(wpe);T(Px.$$.fragment,q8t),q8t.forEach(t),N8t.forEach(t),o8o=i(Oro),Ape=n(Oro,"SPAN",{});var j8t=s(Ape);r8o=r(j8t,"AutoModel"),j8t.forEach(t),Oro.forEach(t),xeo=i(c),Po=n(c,"DIV",{class:!0});var Al=s(Po);T(Bx.$$.fragment,Al),t8o=i(Al),bd=n(Al,"P",{});var fie=s(bd);a8o=r(fie,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),nV=n(fie,"A",{href:!0});var D8t=s(nV);n8o=r(D8t,"from_pretrained()"),D8t.forEach(t),s8o=r(fie," class method or the "),sV=n(fie,"A",{href:!0});var G8t=s(sV);l8o=r(G8t,"from_config()"),G8t.forEach(t),i8o=r(fie,` class
method.`),fie.forEach(t),d8o=i(Al),Ix=n(Al,"P",{});var Vro=s(Ix);m8o=r(Vro,"This class cannot be instantiated directly using "),Lpe=n(Vro,"CODE",{});var O8t=s(Lpe);c8o=r(O8t,"__init__()"),O8t.forEach(t),f8o=r(Vro," (throws an error)."),Vro.forEach(t),g8o=i(Al),_t=n(Al,"DIV",{class:!0});var r8=s(_t);T(Nx.$$.fragment,r8),h8o=i(r8),ype=n(r8,"P",{});var V8t=s(ype);u8o=r(V8t,"Instantiates one of the base model classes of the library from a configuration."),V8t.forEach(t),p8o=i(r8),vd=n(r8,"P",{});var gie=s(vd);_8o=r(gie,`Note:
Loading a model from its configuration file does `),xpe=n(gie,"STRONG",{});var X8t=s(xpe);b8o=r(X8t,"not"),X8t.forEach(t),v8o=r(gie,` load the model weights. It only affects the
model\u2019s configuration. Use `),lV=n(gie,"A",{href:!0});var z8t=s(lV);F8o=r(z8t,"from_pretrained()"),z8t.forEach(t),T8o=r(gie," to load the model weights."),gie.forEach(t),M8o=i(r8),T(d_.$$.fragment,r8),r8.forEach(t),E8o=i(Al),Ze=n(Al,"DIV",{class:!0});var Fa=s(Ze);T(qx.$$.fragment,Fa),C8o=i(Fa),$pe=n(Fa,"P",{});var Q8t=s($pe);w8o=r(Q8t,"Instantiate one of the base model classes of the library from a pretrained model."),Q8t.forEach(t),A8o=i(Fa),Ja=n(Fa,"P",{});var t8=s(Ja);L8o=r(t8,"The model class to instantiate is selected based on the "),kpe=n(t8,"CODE",{});var W8t=s(kpe);y8o=r(W8t,"model_type"),W8t.forEach(t),x8o=r(t8,` property of the config object (either
passed as an argument or loaded from `),Spe=n(t8,"CODE",{});var U8t=s(Spe);$8o=r(U8t,"pretrained_model_name_or_path"),U8t.forEach(t),k8o=r(t8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rpe=n(t8,"CODE",{});var H8t=s(Rpe);S8o=r(H8t,"pretrained_model_name_or_path"),H8t.forEach(t),R8o=r(t8,":"),t8.forEach(t),P8o=i(Fa),y=n(Fa,"UL",{});var x=s(y);m_=n(x,"LI",{});var HNe=s(m_);Ppe=n(HNe,"STRONG",{});var J8t=s(Ppe);B8o=r(J8t,"albert"),J8t.forEach(t),I8o=r(HNe," \u2014 "),iV=n(HNe,"A",{href:!0});var Y8t=s(iV);N8o=r(Y8t,"AlbertModel"),Y8t.forEach(t),q8o=r(HNe," (ALBERT model)"),HNe.forEach(t),j8o=i(x),c_=n(x,"LI",{});var JNe=s(c_);Bpe=n(JNe,"STRONG",{});var K8t=s(Bpe);D8o=r(K8t,"bart"),K8t.forEach(t),G8o=r(JNe," \u2014 "),dV=n(JNe,"A",{href:!0});var Z8t=s(dV);O8o=r(Z8t,"BartModel"),Z8t.forEach(t),V8o=r(JNe," (BART model)"),JNe.forEach(t),X8o=i(x),f_=n(x,"LI",{});var YNe=s(f_);Ipe=n(YNe,"STRONG",{});var e9t=s(Ipe);z8o=r(e9t,"beit"),e9t.forEach(t),Q8o=r(YNe," \u2014 "),mV=n(YNe,"A",{href:!0});var o9t=s(mV);W8o=r(o9t,"BeitModel"),o9t.forEach(t),U8o=r(YNe," (BEiT model)"),YNe.forEach(t),H8o=i(x),g_=n(x,"LI",{});var KNe=s(g_);Npe=n(KNe,"STRONG",{});var r9t=s(Npe);J8o=r(r9t,"bert"),r9t.forEach(t),Y8o=r(KNe," \u2014 "),cV=n(KNe,"A",{href:!0});var t9t=s(cV);K8o=r(t9t,"BertModel"),t9t.forEach(t),Z8o=r(KNe," (BERT model)"),KNe.forEach(t),e9o=i(x),h_=n(x,"LI",{});var ZNe=s(h_);qpe=n(ZNe,"STRONG",{});var a9t=s(qpe);o9o=r(a9t,"bert-generation"),a9t.forEach(t),r9o=r(ZNe," \u2014 "),fV=n(ZNe,"A",{href:!0});var n9t=s(fV);t9o=r(n9t,"BertGenerationEncoder"),n9t.forEach(t),a9o=r(ZNe," (Bert Generation model)"),ZNe.forEach(t),n9o=i(x),u_=n(x,"LI",{});var eqe=s(u_);jpe=n(eqe,"STRONG",{});var s9t=s(jpe);s9o=r(s9t,"big_bird"),s9t.forEach(t),l9o=r(eqe," \u2014 "),gV=n(eqe,"A",{href:!0});var l9t=s(gV);i9o=r(l9t,"BigBirdModel"),l9t.forEach(t),d9o=r(eqe," (BigBird model)"),eqe.forEach(t),m9o=i(x),p_=n(x,"LI",{});var oqe=s(p_);Dpe=n(oqe,"STRONG",{});var i9t=s(Dpe);c9o=r(i9t,"bigbird_pegasus"),i9t.forEach(t),f9o=r(oqe," \u2014 "),hV=n(oqe,"A",{href:!0});var d9t=s(hV);g9o=r(d9t,"BigBirdPegasusModel"),d9t.forEach(t),h9o=r(oqe," (BigBird-Pegasus model)"),oqe.forEach(t),u9o=i(x),__=n(x,"LI",{});var rqe=s(__);Gpe=n(rqe,"STRONG",{});var m9t=s(Gpe);p9o=r(m9t,"blenderbot"),m9t.forEach(t),_9o=r(rqe," \u2014 "),uV=n(rqe,"A",{href:!0});var c9t=s(uV);b9o=r(c9t,"BlenderbotModel"),c9t.forEach(t),v9o=r(rqe," (Blenderbot model)"),rqe.forEach(t),F9o=i(x),b_=n(x,"LI",{});var tqe=s(b_);Ope=n(tqe,"STRONG",{});var f9t=s(Ope);T9o=r(f9t,"blenderbot-small"),f9t.forEach(t),M9o=r(tqe," \u2014 "),pV=n(tqe,"A",{href:!0});var g9t=s(pV);E9o=r(g9t,"BlenderbotSmallModel"),g9t.forEach(t),C9o=r(tqe," (BlenderbotSmall model)"),tqe.forEach(t),w9o=i(x),v_=n(x,"LI",{});var aqe=s(v_);Vpe=n(aqe,"STRONG",{});var h9t=s(Vpe);A9o=r(h9t,"bloom"),h9t.forEach(t),L9o=r(aqe," \u2014 "),_V=n(aqe,"A",{href:!0});var u9t=s(_V);y9o=r(u9t,"BloomModel"),u9t.forEach(t),x9o=r(aqe," (BLOOM model)"),aqe.forEach(t),$9o=i(x),F_=n(x,"LI",{});var nqe=s(F_);Xpe=n(nqe,"STRONG",{});var p9t=s(Xpe);k9o=r(p9t,"camembert"),p9t.forEach(t),S9o=r(nqe," \u2014 "),bV=n(nqe,"A",{href:!0});var _9t=s(bV);R9o=r(_9t,"CamembertModel"),_9t.forEach(t),P9o=r(nqe," (CamemBERT model)"),nqe.forEach(t),B9o=i(x),T_=n(x,"LI",{});var sqe=s(T_);zpe=n(sqe,"STRONG",{});var b9t=s(zpe);I9o=r(b9t,"canine"),b9t.forEach(t),N9o=r(sqe," \u2014 "),vV=n(sqe,"A",{href:!0});var v9t=s(vV);q9o=r(v9t,"CanineModel"),v9t.forEach(t),j9o=r(sqe," (CANINE model)"),sqe.forEach(t),D9o=i(x),M_=n(x,"LI",{});var lqe=s(M_);Qpe=n(lqe,"STRONG",{});var F9t=s(Qpe);G9o=r(F9t,"clip"),F9t.forEach(t),O9o=r(lqe," \u2014 "),FV=n(lqe,"A",{href:!0});var T9t=s(FV);V9o=r(T9t,"CLIPModel"),T9t.forEach(t),X9o=r(lqe," (CLIP model)"),lqe.forEach(t),z9o=i(x),E_=n(x,"LI",{});var iqe=s(E_);Wpe=n(iqe,"STRONG",{});var M9t=s(Wpe);Q9o=r(M9t,"codegen"),M9t.forEach(t),W9o=r(iqe," \u2014 "),TV=n(iqe,"A",{href:!0});var E9t=s(TV);U9o=r(E9t,"CodeGenModel"),E9t.forEach(t),H9o=r(iqe," (CodeGen model)"),iqe.forEach(t),J9o=i(x),C_=n(x,"LI",{});var dqe=s(C_);Upe=n(dqe,"STRONG",{});var C9t=s(Upe);Y9o=r(C9t,"conditional_detr"),C9t.forEach(t),K9o=r(dqe," \u2014 "),MV=n(dqe,"A",{href:!0});var w9t=s(MV);Z9o=r(w9t,"ConditionalDetrModel"),w9t.forEach(t),exo=r(dqe," (Conditional DETR model)"),dqe.forEach(t),oxo=i(x),w_=n(x,"LI",{});var mqe=s(w_);Hpe=n(mqe,"STRONG",{});var A9t=s(Hpe);rxo=r(A9t,"convbert"),A9t.forEach(t),txo=r(mqe," \u2014 "),EV=n(mqe,"A",{href:!0});var L9t=s(EV);axo=r(L9t,"ConvBertModel"),L9t.forEach(t),nxo=r(mqe," (ConvBERT model)"),mqe.forEach(t),sxo=i(x),A_=n(x,"LI",{});var cqe=s(A_);Jpe=n(cqe,"STRONG",{});var y9t=s(Jpe);lxo=r(y9t,"convnext"),y9t.forEach(t),ixo=r(cqe," \u2014 "),CV=n(cqe,"A",{href:!0});var x9t=s(CV);dxo=r(x9t,"ConvNextModel"),x9t.forEach(t),mxo=r(cqe," (ConvNeXT model)"),cqe.forEach(t),cxo=i(x),L_=n(x,"LI",{});var fqe=s(L_);Ype=n(fqe,"STRONG",{});var $9t=s(Ype);fxo=r($9t,"ctrl"),$9t.forEach(t),gxo=r(fqe," \u2014 "),wV=n(fqe,"A",{href:!0});var k9t=s(wV);hxo=r(k9t,"CTRLModel"),k9t.forEach(t),uxo=r(fqe," (CTRL model)"),fqe.forEach(t),pxo=i(x),y_=n(x,"LI",{});var gqe=s(y_);Kpe=n(gqe,"STRONG",{});var S9t=s(Kpe);_xo=r(S9t,"cvt"),S9t.forEach(t),bxo=r(gqe," \u2014 "),AV=n(gqe,"A",{href:!0});var R9t=s(AV);vxo=r(R9t,"CvtModel"),R9t.forEach(t),Fxo=r(gqe," (CvT model)"),gqe.forEach(t),Txo=i(x),x_=n(x,"LI",{});var hqe=s(x_);Zpe=n(hqe,"STRONG",{});var P9t=s(Zpe);Mxo=r(P9t,"data2vec-audio"),P9t.forEach(t),Exo=r(hqe," \u2014 "),LV=n(hqe,"A",{href:!0});var B9t=s(LV);Cxo=r(B9t,"Data2VecAudioModel"),B9t.forEach(t),wxo=r(hqe," (Data2VecAudio model)"),hqe.forEach(t),Axo=i(x),$_=n(x,"LI",{});var uqe=s($_);e_e=n(uqe,"STRONG",{});var I9t=s(e_e);Lxo=r(I9t,"data2vec-text"),I9t.forEach(t),yxo=r(uqe," \u2014 "),yV=n(uqe,"A",{href:!0});var N9t=s(yV);xxo=r(N9t,"Data2VecTextModel"),N9t.forEach(t),$xo=r(uqe," (Data2VecText model)"),uqe.forEach(t),kxo=i(x),k_=n(x,"LI",{});var pqe=s(k_);o_e=n(pqe,"STRONG",{});var q9t=s(o_e);Sxo=r(q9t,"data2vec-vision"),q9t.forEach(t),Rxo=r(pqe," \u2014 "),xV=n(pqe,"A",{href:!0});var j9t=s(xV);Pxo=r(j9t,"Data2VecVisionModel"),j9t.forEach(t),Bxo=r(pqe," (Data2VecVision model)"),pqe.forEach(t),Ixo=i(x),S_=n(x,"LI",{});var _qe=s(S_);r_e=n(_qe,"STRONG",{});var D9t=s(r_e);Nxo=r(D9t,"deberta"),D9t.forEach(t),qxo=r(_qe," \u2014 "),$V=n(_qe,"A",{href:!0});var G9t=s($V);jxo=r(G9t,"DebertaModel"),G9t.forEach(t),Dxo=r(_qe," (DeBERTa model)"),_qe.forEach(t),Gxo=i(x),R_=n(x,"LI",{});var bqe=s(R_);t_e=n(bqe,"STRONG",{});var O9t=s(t_e);Oxo=r(O9t,"deberta-v2"),O9t.forEach(t),Vxo=r(bqe," \u2014 "),kV=n(bqe,"A",{href:!0});var V9t=s(kV);Xxo=r(V9t,"DebertaV2Model"),V9t.forEach(t),zxo=r(bqe," (DeBERTa-v2 model)"),bqe.forEach(t),Qxo=i(x),P_=n(x,"LI",{});var vqe=s(P_);a_e=n(vqe,"STRONG",{});var X9t=s(a_e);Wxo=r(X9t,"decision_transformer"),X9t.forEach(t),Uxo=r(vqe," \u2014 "),SV=n(vqe,"A",{href:!0});var z9t=s(SV);Hxo=r(z9t,"DecisionTransformerModel"),z9t.forEach(t),Jxo=r(vqe," (Decision Transformer model)"),vqe.forEach(t),Yxo=i(x),B_=n(x,"LI",{});var Fqe=s(B_);n_e=n(Fqe,"STRONG",{});var Q9t=s(n_e);Kxo=r(Q9t,"deformable_detr"),Q9t.forEach(t),Zxo=r(Fqe," \u2014 "),RV=n(Fqe,"A",{href:!0});var W9t=s(RV);e$o=r(W9t,"DeformableDetrModel"),W9t.forEach(t),o$o=r(Fqe," (Deformable DETR model)"),Fqe.forEach(t),r$o=i(x),I_=n(x,"LI",{});var Tqe=s(I_);s_e=n(Tqe,"STRONG",{});var U9t=s(s_e);t$o=r(U9t,"deit"),U9t.forEach(t),a$o=r(Tqe," \u2014 "),PV=n(Tqe,"A",{href:!0});var H9t=s(PV);n$o=r(H9t,"DeiTModel"),H9t.forEach(t),s$o=r(Tqe," (DeiT model)"),Tqe.forEach(t),l$o=i(x),N_=n(x,"LI",{});var Mqe=s(N_);l_e=n(Mqe,"STRONG",{});var J9t=s(l_e);i$o=r(J9t,"detr"),J9t.forEach(t),d$o=r(Mqe," \u2014 "),BV=n(Mqe,"A",{href:!0});var Y9t=s(BV);m$o=r(Y9t,"DetrModel"),Y9t.forEach(t),c$o=r(Mqe," (DETR model)"),Mqe.forEach(t),f$o=i(x),q_=n(x,"LI",{});var Eqe=s(q_);i_e=n(Eqe,"STRONG",{});var K9t=s(i_e);g$o=r(K9t,"distilbert"),K9t.forEach(t),h$o=r(Eqe," \u2014 "),IV=n(Eqe,"A",{href:!0});var Z9t=s(IV);u$o=r(Z9t,"DistilBertModel"),Z9t.forEach(t),p$o=r(Eqe," (DistilBERT model)"),Eqe.forEach(t),_$o=i(x),j_=n(x,"LI",{});var Cqe=s(j_);d_e=n(Cqe,"STRONG",{});var ext=s(d_e);b$o=r(ext,"donut-swin"),ext.forEach(t),v$o=r(Cqe," \u2014 "),NV=n(Cqe,"A",{href:!0});var oxt=s(NV);F$o=r(oxt,"DonutSwinModel"),oxt.forEach(t),T$o=r(Cqe," (DonutSwin model)"),Cqe.forEach(t),M$o=i(x),D_=n(x,"LI",{});var wqe=s(D_);m_e=n(wqe,"STRONG",{});var rxt=s(m_e);E$o=r(rxt,"dpr"),rxt.forEach(t),C$o=r(wqe," \u2014 "),qV=n(wqe,"A",{href:!0});var txt=s(qV);w$o=r(txt,"DPRQuestionEncoder"),txt.forEach(t),A$o=r(wqe," (DPR model)"),wqe.forEach(t),L$o=i(x),G_=n(x,"LI",{});var Aqe=s(G_);c_e=n(Aqe,"STRONG",{});var axt=s(c_e);y$o=r(axt,"dpt"),axt.forEach(t),x$o=r(Aqe," \u2014 "),jV=n(Aqe,"A",{href:!0});var nxt=s(jV);$$o=r(nxt,"DPTModel"),nxt.forEach(t),k$o=r(Aqe," (DPT model)"),Aqe.forEach(t),S$o=i(x),O_=n(x,"LI",{});var Lqe=s(O_);f_e=n(Lqe,"STRONG",{});var sxt=s(f_e);R$o=r(sxt,"electra"),sxt.forEach(t),P$o=r(Lqe," \u2014 "),DV=n(Lqe,"A",{href:!0});var lxt=s(DV);B$o=r(lxt,"ElectraModel"),lxt.forEach(t),I$o=r(Lqe," (ELECTRA model)"),Lqe.forEach(t),N$o=i(x),V_=n(x,"LI",{});var yqe=s(V_);g_e=n(yqe,"STRONG",{});var ixt=s(g_e);q$o=r(ixt,"ernie"),ixt.forEach(t),j$o=r(yqe," \u2014 "),GV=n(yqe,"A",{href:!0});var dxt=s(GV);D$o=r(dxt,"ErnieModel"),dxt.forEach(t),G$o=r(yqe," (ERNIE model)"),yqe.forEach(t),O$o=i(x),X_=n(x,"LI",{});var xqe=s(X_);h_e=n(xqe,"STRONG",{});var mxt=s(h_e);V$o=r(mxt,"esm"),mxt.forEach(t),X$o=r(xqe," \u2014 "),OV=n(xqe,"A",{href:!0});var cxt=s(OV);z$o=r(cxt,"EsmModel"),cxt.forEach(t),Q$o=r(xqe," (ESM model)"),xqe.forEach(t),W$o=i(x),z_=n(x,"LI",{});var $qe=s(z_);u_e=n($qe,"STRONG",{});var fxt=s(u_e);U$o=r(fxt,"flaubert"),fxt.forEach(t),H$o=r($qe," \u2014 "),VV=n($qe,"A",{href:!0});var gxt=s(VV);J$o=r(gxt,"FlaubertModel"),gxt.forEach(t),Y$o=r($qe," (FlauBERT model)"),$qe.forEach(t),K$o=i(x),Q_=n(x,"LI",{});var kqe=s(Q_);p_e=n(kqe,"STRONG",{});var hxt=s(p_e);Z$o=r(hxt,"flava"),hxt.forEach(t),eko=r(kqe," \u2014 "),XV=n(kqe,"A",{href:!0});var uxt=s(XV);oko=r(uxt,"FlavaModel"),uxt.forEach(t),rko=r(kqe," (FLAVA model)"),kqe.forEach(t),tko=i(x),W_=n(x,"LI",{});var Sqe=s(W_);__e=n(Sqe,"STRONG",{});var pxt=s(__e);ako=r(pxt,"fnet"),pxt.forEach(t),nko=r(Sqe," \u2014 "),zV=n(Sqe,"A",{href:!0});var _xt=s(zV);sko=r(_xt,"FNetModel"),_xt.forEach(t),lko=r(Sqe," (FNet model)"),Sqe.forEach(t),iko=i(x),U_=n(x,"LI",{});var Rqe=s(U_);b_e=n(Rqe,"STRONG",{});var bxt=s(b_e);dko=r(bxt,"fsmt"),bxt.forEach(t),mko=r(Rqe," \u2014 "),QV=n(Rqe,"A",{href:!0});var vxt=s(QV);cko=r(vxt,"FSMTModel"),vxt.forEach(t),fko=r(Rqe," (FairSeq Machine-Translation model)"),Rqe.forEach(t),gko=i(x),_l=n(x,"LI",{});var rI=s(_l);v_e=n(rI,"STRONG",{});var Fxt=s(v_e);hko=r(Fxt,"funnel"),Fxt.forEach(t),uko=r(rI," \u2014 "),WV=n(rI,"A",{href:!0});var Txt=s(WV);pko=r(Txt,"FunnelModel"),Txt.forEach(t),_ko=r(rI," or "),UV=n(rI,"A",{href:!0});var Mxt=s(UV);bko=r(Mxt,"FunnelBaseModel"),Mxt.forEach(t),vko=r(rI," (Funnel Transformer model)"),rI.forEach(t),Fko=i(x),H_=n(x,"LI",{});var Pqe=s(H_);F_e=n(Pqe,"STRONG",{});var Ext=s(F_e);Tko=r(Ext,"glpn"),Ext.forEach(t),Mko=r(Pqe," \u2014 "),HV=n(Pqe,"A",{href:!0});var Cxt=s(HV);Eko=r(Cxt,"GLPNModel"),Cxt.forEach(t),Cko=r(Pqe," (GLPN model)"),Pqe.forEach(t),wko=i(x),J_=n(x,"LI",{});var Bqe=s(J_);T_e=n(Bqe,"STRONG",{});var wxt=s(T_e);Ako=r(wxt,"gpt2"),wxt.forEach(t),Lko=r(Bqe," \u2014 "),JV=n(Bqe,"A",{href:!0});var Axt=s(JV);yko=r(Axt,"GPT2Model"),Axt.forEach(t),xko=r(Bqe," (OpenAI GPT-2 model)"),Bqe.forEach(t),$ko=i(x),Y_=n(x,"LI",{});var Iqe=s(Y_);M_e=n(Iqe,"STRONG",{});var Lxt=s(M_e);kko=r(Lxt,"gpt_neo"),Lxt.forEach(t),Sko=r(Iqe," \u2014 "),YV=n(Iqe,"A",{href:!0});var yxt=s(YV);Rko=r(yxt,"GPTNeoModel"),yxt.forEach(t),Pko=r(Iqe," (GPT Neo model)"),Iqe.forEach(t),Bko=i(x),K_=n(x,"LI",{});var Nqe=s(K_);E_e=n(Nqe,"STRONG",{});var xxt=s(E_e);Iko=r(xxt,"gpt_neox"),xxt.forEach(t),Nko=r(Nqe," \u2014 "),KV=n(Nqe,"A",{href:!0});var $xt=s(KV);qko=r($xt,"GPTNeoXModel"),$xt.forEach(t),jko=r(Nqe," (GPT NeoX model)"),Nqe.forEach(t),Dko=i(x),Z_=n(x,"LI",{});var qqe=s(Z_);C_e=n(qqe,"STRONG",{});var kxt=s(C_e);Gko=r(kxt,"gpt_neox_japanese"),kxt.forEach(t),Oko=r(qqe," \u2014 "),ZV=n(qqe,"A",{href:!0});var Sxt=s(ZV);Vko=r(Sxt,"GPTNeoXJapaneseModel"),Sxt.forEach(t),Xko=r(qqe," (GPT NeoX Japanese model)"),qqe.forEach(t),zko=i(x),e1=n(x,"LI",{});var jqe=s(e1);w_e=n(jqe,"STRONG",{});var Rxt=s(w_e);Qko=r(Rxt,"gptj"),Rxt.forEach(t),Wko=r(jqe," \u2014 "),eX=n(jqe,"A",{href:!0});var Pxt=s(eX);Uko=r(Pxt,"GPTJModel"),Pxt.forEach(t),Hko=r(jqe," (GPT-J model)"),jqe.forEach(t),Jko=i(x),o1=n(x,"LI",{});var Dqe=s(o1);A_e=n(Dqe,"STRONG",{});var Bxt=s(A_e);Yko=r(Bxt,"groupvit"),Bxt.forEach(t),Kko=r(Dqe," \u2014 "),oX=n(Dqe,"A",{href:!0});var Ixt=s(oX);Zko=r(Ixt,"GroupViTModel"),Ixt.forEach(t),eSo=r(Dqe," (GroupViT model)"),Dqe.forEach(t),oSo=i(x),r1=n(x,"LI",{});var Gqe=s(r1);L_e=n(Gqe,"STRONG",{});var Nxt=s(L_e);rSo=r(Nxt,"hubert"),Nxt.forEach(t),tSo=r(Gqe," \u2014 "),rX=n(Gqe,"A",{href:!0});var qxt=s(rX);aSo=r(qxt,"HubertModel"),qxt.forEach(t),nSo=r(Gqe," (Hubert model)"),Gqe.forEach(t),sSo=i(x),t1=n(x,"LI",{});var Oqe=s(t1);y_e=n(Oqe,"STRONG",{});var jxt=s(y_e);lSo=r(jxt,"ibert"),jxt.forEach(t),iSo=r(Oqe," \u2014 "),tX=n(Oqe,"A",{href:!0});var Dxt=s(tX);dSo=r(Dxt,"IBertModel"),Dxt.forEach(t),mSo=r(Oqe," (I-BERT model)"),Oqe.forEach(t),cSo=i(x),a1=n(x,"LI",{});var Vqe=s(a1);x_e=n(Vqe,"STRONG",{});var Gxt=s(x_e);fSo=r(Gxt,"imagegpt"),Gxt.forEach(t),gSo=r(Vqe," \u2014 "),aX=n(Vqe,"A",{href:!0});var Oxt=s(aX);hSo=r(Oxt,"ImageGPTModel"),Oxt.forEach(t),uSo=r(Vqe," (ImageGPT model)"),Vqe.forEach(t),pSo=i(x),n1=n(x,"LI",{});var Xqe=s(n1);$_e=n(Xqe,"STRONG",{});var Vxt=s($_e);_So=r(Vxt,"layoutlm"),Vxt.forEach(t),bSo=r(Xqe," \u2014 "),nX=n(Xqe,"A",{href:!0});var Xxt=s(nX);vSo=r(Xxt,"LayoutLMModel"),Xxt.forEach(t),FSo=r(Xqe," (LayoutLM model)"),Xqe.forEach(t),TSo=i(x),s1=n(x,"LI",{});var zqe=s(s1);k_e=n(zqe,"STRONG",{});var zxt=s(k_e);MSo=r(zxt,"layoutlmv2"),zxt.forEach(t),ESo=r(zqe," \u2014 "),sX=n(zqe,"A",{href:!0});var Qxt=s(sX);CSo=r(Qxt,"LayoutLMv2Model"),Qxt.forEach(t),wSo=r(zqe," (LayoutLMv2 model)"),zqe.forEach(t),ASo=i(x),l1=n(x,"LI",{});var Qqe=s(l1);S_e=n(Qqe,"STRONG",{});var Wxt=s(S_e);LSo=r(Wxt,"layoutlmv3"),Wxt.forEach(t),ySo=r(Qqe," \u2014 "),lX=n(Qqe,"A",{href:!0});var Uxt=s(lX);xSo=r(Uxt,"LayoutLMv3Model"),Uxt.forEach(t),$So=r(Qqe," (LayoutLMv3 model)"),Qqe.forEach(t),kSo=i(x),i1=n(x,"LI",{});var Wqe=s(i1);R_e=n(Wqe,"STRONG",{});var Hxt=s(R_e);SSo=r(Hxt,"led"),Hxt.forEach(t),RSo=r(Wqe," \u2014 "),iX=n(Wqe,"A",{href:!0});var Jxt=s(iX);PSo=r(Jxt,"LEDModel"),Jxt.forEach(t),BSo=r(Wqe," (LED model)"),Wqe.forEach(t),ISo=i(x),d1=n(x,"LI",{});var Uqe=s(d1);P_e=n(Uqe,"STRONG",{});var Yxt=s(P_e);NSo=r(Yxt,"levit"),Yxt.forEach(t),qSo=r(Uqe," \u2014 "),dX=n(Uqe,"A",{href:!0});var Kxt=s(dX);jSo=r(Kxt,"LevitModel"),Kxt.forEach(t),DSo=r(Uqe," (LeViT model)"),Uqe.forEach(t),GSo=i(x),m1=n(x,"LI",{});var Hqe=s(m1);B_e=n(Hqe,"STRONG",{});var Zxt=s(B_e);OSo=r(Zxt,"longformer"),Zxt.forEach(t),VSo=r(Hqe," \u2014 "),mX=n(Hqe,"A",{href:!0});var e$t=s(mX);XSo=r(e$t,"LongformerModel"),e$t.forEach(t),zSo=r(Hqe," (Longformer model)"),Hqe.forEach(t),QSo=i(x),c1=n(x,"LI",{});var Jqe=s(c1);I_e=n(Jqe,"STRONG",{});var o$t=s(I_e);WSo=r(o$t,"longt5"),o$t.forEach(t),USo=r(Jqe," \u2014 "),cX=n(Jqe,"A",{href:!0});var r$t=s(cX);HSo=r(r$t,"LongT5Model"),r$t.forEach(t),JSo=r(Jqe," (LongT5 model)"),Jqe.forEach(t),YSo=i(x),f1=n(x,"LI",{});var Yqe=s(f1);N_e=n(Yqe,"STRONG",{});var t$t=s(N_e);KSo=r(t$t,"luke"),t$t.forEach(t),ZSo=r(Yqe," \u2014 "),fX=n(Yqe,"A",{href:!0});var a$t=s(fX);eRo=r(a$t,"LukeModel"),a$t.forEach(t),oRo=r(Yqe," (LUKE model)"),Yqe.forEach(t),rRo=i(x),g1=n(x,"LI",{});var Kqe=s(g1);q_e=n(Kqe,"STRONG",{});var n$t=s(q_e);tRo=r(n$t,"lxmert"),n$t.forEach(t),aRo=r(Kqe," \u2014 "),gX=n(Kqe,"A",{href:!0});var s$t=s(gX);nRo=r(s$t,"LxmertModel"),s$t.forEach(t),sRo=r(Kqe," (LXMERT model)"),Kqe.forEach(t),lRo=i(x),h1=n(x,"LI",{});var Zqe=s(h1);j_e=n(Zqe,"STRONG",{});var l$t=s(j_e);iRo=r(l$t,"m2m_100"),l$t.forEach(t),dRo=r(Zqe," \u2014 "),hX=n(Zqe,"A",{href:!0});var i$t=s(hX);mRo=r(i$t,"M2M100Model"),i$t.forEach(t),cRo=r(Zqe," (M2M100 model)"),Zqe.forEach(t),fRo=i(x),u1=n(x,"LI",{});var eje=s(u1);D_e=n(eje,"STRONG",{});var d$t=s(D_e);gRo=r(d$t,"marian"),d$t.forEach(t),hRo=r(eje," \u2014 "),uX=n(eje,"A",{href:!0});var m$t=s(uX);uRo=r(m$t,"MarianModel"),m$t.forEach(t),pRo=r(eje," (Marian model)"),eje.forEach(t),_Ro=i(x),p1=n(x,"LI",{});var oje=s(p1);G_e=n(oje,"STRONG",{});var c$t=s(G_e);bRo=r(c$t,"markuplm"),c$t.forEach(t),vRo=r(oje," \u2014 "),pX=n(oje,"A",{href:!0});var f$t=s(pX);FRo=r(f$t,"MarkupLMModel"),f$t.forEach(t),TRo=r(oje," (MarkupLM model)"),oje.forEach(t),MRo=i(x),_1=n(x,"LI",{});var rje=s(_1);O_e=n(rje,"STRONG",{});var g$t=s(O_e);ERo=r(g$t,"maskformer"),g$t.forEach(t),CRo=r(rje," \u2014 "),_X=n(rje,"A",{href:!0});var h$t=s(_X);wRo=r(h$t,"MaskFormerModel"),h$t.forEach(t),ARo=r(rje," (MaskFormer model)"),rje.forEach(t),LRo=i(x),b1=n(x,"LI",{});var tje=s(b1);V_e=n(tje,"STRONG",{});var u$t=s(V_e);yRo=r(u$t,"mbart"),u$t.forEach(t),xRo=r(tje," \u2014 "),bX=n(tje,"A",{href:!0});var p$t=s(bX);$Ro=r(p$t,"MBartModel"),p$t.forEach(t),kRo=r(tje," (mBART model)"),tje.forEach(t),SRo=i(x),v1=n(x,"LI",{});var aje=s(v1);X_e=n(aje,"STRONG",{});var _$t=s(X_e);RRo=r(_$t,"mctct"),_$t.forEach(t),PRo=r(aje," \u2014 "),vX=n(aje,"A",{href:!0});var b$t=s(vX);BRo=r(b$t,"MCTCTModel"),b$t.forEach(t),IRo=r(aje," (M-CTC-T model)"),aje.forEach(t),NRo=i(x),F1=n(x,"LI",{});var nje=s(F1);z_e=n(nje,"STRONG",{});var v$t=s(z_e);qRo=r(v$t,"megatron-bert"),v$t.forEach(t),jRo=r(nje," \u2014 "),FX=n(nje,"A",{href:!0});var F$t=s(FX);DRo=r(F$t,"MegatronBertModel"),F$t.forEach(t),GRo=r(nje," (Megatron-BERT model)"),nje.forEach(t),ORo=i(x),T1=n(x,"LI",{});var sje=s(T1);Q_e=n(sje,"STRONG",{});var T$t=s(Q_e);VRo=r(T$t,"mobilebert"),T$t.forEach(t),XRo=r(sje," \u2014 "),TX=n(sje,"A",{href:!0});var M$t=s(TX);zRo=r(M$t,"MobileBertModel"),M$t.forEach(t),QRo=r(sje," (MobileBERT model)"),sje.forEach(t),WRo=i(x),M1=n(x,"LI",{});var lje=s(M1);W_e=n(lje,"STRONG",{});var E$t=s(W_e);URo=r(E$t,"mobilevit"),E$t.forEach(t),HRo=r(lje," \u2014 "),MX=n(lje,"A",{href:!0});var C$t=s(MX);JRo=r(C$t,"MobileViTModel"),C$t.forEach(t),YRo=r(lje," (MobileViT model)"),lje.forEach(t),KRo=i(x),E1=n(x,"LI",{});var ije=s(E1);U_e=n(ije,"STRONG",{});var w$t=s(U_e);ZRo=r(w$t,"mpnet"),w$t.forEach(t),ePo=r(ije," \u2014 "),EX=n(ije,"A",{href:!0});var A$t=s(EX);oPo=r(A$t,"MPNetModel"),A$t.forEach(t),rPo=r(ije," (MPNet model)"),ije.forEach(t),tPo=i(x),C1=n(x,"LI",{});var dje=s(C1);H_e=n(dje,"STRONG",{});var L$t=s(H_e);aPo=r(L$t,"mt5"),L$t.forEach(t),nPo=r(dje," \u2014 "),CX=n(dje,"A",{href:!0});var y$t=s(CX);sPo=r(y$t,"MT5Model"),y$t.forEach(t),lPo=r(dje," (MT5 model)"),dje.forEach(t),iPo=i(x),w1=n(x,"LI",{});var mje=s(w1);J_e=n(mje,"STRONG",{});var x$t=s(J_e);dPo=r(x$t,"mvp"),x$t.forEach(t),mPo=r(mje," \u2014 "),wX=n(mje,"A",{href:!0});var $$t=s(wX);cPo=r($$t,"MvpModel"),$$t.forEach(t),fPo=r(mje," (MVP model)"),mje.forEach(t),gPo=i(x),A1=n(x,"LI",{});var cje=s(A1);Y_e=n(cje,"STRONG",{});var k$t=s(Y_e);hPo=r(k$t,"nezha"),k$t.forEach(t),uPo=r(cje," \u2014 "),AX=n(cje,"A",{href:!0});var S$t=s(AX);pPo=r(S$t,"NezhaModel"),S$t.forEach(t),_Po=r(cje," (Nezha model)"),cje.forEach(t),bPo=i(x),L1=n(x,"LI",{});var fje=s(L1);K_e=n(fje,"STRONG",{});var R$t=s(K_e);vPo=r(R$t,"nllb"),R$t.forEach(t),FPo=r(fje," \u2014 "),LX=n(fje,"A",{href:!0});var P$t=s(LX);TPo=r(P$t,"M2M100Model"),P$t.forEach(t),MPo=r(fje," (NLLB model)"),fje.forEach(t),EPo=i(x),y1=n(x,"LI",{});var gje=s(y1);Z_e=n(gje,"STRONG",{});var B$t=s(Z_e);CPo=r(B$t,"nystromformer"),B$t.forEach(t),wPo=r(gje," \u2014 "),yX=n(gje,"A",{href:!0});var I$t=s(yX);APo=r(I$t,"NystromformerModel"),I$t.forEach(t),LPo=r(gje," (Nystr\xF6mformer model)"),gje.forEach(t),yPo=i(x),x1=n(x,"LI",{});var hje=s(x1);e1e=n(hje,"STRONG",{});var N$t=s(e1e);xPo=r(N$t,"openai-gpt"),N$t.forEach(t),$Po=r(hje," \u2014 "),xX=n(hje,"A",{href:!0});var q$t=s(xX);kPo=r(q$t,"OpenAIGPTModel"),q$t.forEach(t),SPo=r(hje," (OpenAI GPT model)"),hje.forEach(t),RPo=i(x),$1=n(x,"LI",{});var uje=s($1);o1e=n(uje,"STRONG",{});var j$t=s(o1e);PPo=r(j$t,"opt"),j$t.forEach(t),BPo=r(uje," \u2014 "),$X=n(uje,"A",{href:!0});var D$t=s($X);IPo=r(D$t,"OPTModel"),D$t.forEach(t),NPo=r(uje," (OPT model)"),uje.forEach(t),qPo=i(x),k1=n(x,"LI",{});var pje=s(k1);r1e=n(pje,"STRONG",{});var G$t=s(r1e);jPo=r(G$t,"owlvit"),G$t.forEach(t),DPo=r(pje," \u2014 "),kX=n(pje,"A",{href:!0});var O$t=s(kX);GPo=r(O$t,"OwlViTModel"),O$t.forEach(t),OPo=r(pje," (OWL-ViT model)"),pje.forEach(t),VPo=i(x),S1=n(x,"LI",{});var _je=s(S1);t1e=n(_je,"STRONG",{});var V$t=s(t1e);XPo=r(V$t,"pegasus"),V$t.forEach(t),zPo=r(_je," \u2014 "),SX=n(_je,"A",{href:!0});var X$t=s(SX);QPo=r(X$t,"PegasusModel"),X$t.forEach(t),WPo=r(_je," (Pegasus model)"),_je.forEach(t),UPo=i(x),R1=n(x,"LI",{});var bje=s(R1);a1e=n(bje,"STRONG",{});var z$t=s(a1e);HPo=r(z$t,"pegasus_x"),z$t.forEach(t),JPo=r(bje," \u2014 "),RX=n(bje,"A",{href:!0});var Q$t=s(RX);YPo=r(Q$t,"PegasusXModel"),Q$t.forEach(t),KPo=r(bje," (PEGASUS-X model)"),bje.forEach(t),ZPo=i(x),P1=n(x,"LI",{});var vje=s(P1);n1e=n(vje,"STRONG",{});var W$t=s(n1e);eBo=r(W$t,"perceiver"),W$t.forEach(t),oBo=r(vje," \u2014 "),PX=n(vje,"A",{href:!0});var U$t=s(PX);rBo=r(U$t,"PerceiverModel"),U$t.forEach(t),tBo=r(vje," (Perceiver model)"),vje.forEach(t),aBo=i(x),B1=n(x,"LI",{});var Fje=s(B1);s1e=n(Fje,"STRONG",{});var H$t=s(s1e);nBo=r(H$t,"plbart"),H$t.forEach(t),sBo=r(Fje," \u2014 "),BX=n(Fje,"A",{href:!0});var J$t=s(BX);lBo=r(J$t,"PLBartModel"),J$t.forEach(t),iBo=r(Fje," (PLBart model)"),Fje.forEach(t),dBo=i(x),I1=n(x,"LI",{});var Tje=s(I1);l1e=n(Tje,"STRONG",{});var Y$t=s(l1e);mBo=r(Y$t,"poolformer"),Y$t.forEach(t),cBo=r(Tje," \u2014 "),IX=n(Tje,"A",{href:!0});var K$t=s(IX);fBo=r(K$t,"PoolFormerModel"),K$t.forEach(t),gBo=r(Tje," (PoolFormer model)"),Tje.forEach(t),hBo=i(x),N1=n(x,"LI",{});var Mje=s(N1);i1e=n(Mje,"STRONG",{});var Z$t=s(i1e);uBo=r(Z$t,"prophetnet"),Z$t.forEach(t),pBo=r(Mje," \u2014 "),NX=n(Mje,"A",{href:!0});var ekt=s(NX);_Bo=r(ekt,"ProphetNetModel"),ekt.forEach(t),bBo=r(Mje," (ProphetNet model)"),Mje.forEach(t),vBo=i(x),q1=n(x,"LI",{});var Eje=s(q1);d1e=n(Eje,"STRONG",{});var okt=s(d1e);FBo=r(okt,"qdqbert"),okt.forEach(t),TBo=r(Eje," \u2014 "),qX=n(Eje,"A",{href:!0});var rkt=s(qX);MBo=r(rkt,"QDQBertModel"),rkt.forEach(t),EBo=r(Eje," (QDQBert model)"),Eje.forEach(t),CBo=i(x),j1=n(x,"LI",{});var Cje=s(j1);m1e=n(Cje,"STRONG",{});var tkt=s(m1e);wBo=r(tkt,"reformer"),tkt.forEach(t),ABo=r(Cje," \u2014 "),jX=n(Cje,"A",{href:!0});var akt=s(jX);LBo=r(akt,"ReformerModel"),akt.forEach(t),yBo=r(Cje," (Reformer model)"),Cje.forEach(t),xBo=i(x),D1=n(x,"LI",{});var wje=s(D1);c1e=n(wje,"STRONG",{});var nkt=s(c1e);$Bo=r(nkt,"regnet"),nkt.forEach(t),kBo=r(wje," \u2014 "),DX=n(wje,"A",{href:!0});var skt=s(DX);SBo=r(skt,"RegNetModel"),skt.forEach(t),RBo=r(wje," (RegNet model)"),wje.forEach(t),PBo=i(x),G1=n(x,"LI",{});var Aje=s(G1);f1e=n(Aje,"STRONG",{});var lkt=s(f1e);BBo=r(lkt,"rembert"),lkt.forEach(t),IBo=r(Aje," \u2014 "),GX=n(Aje,"A",{href:!0});var ikt=s(GX);NBo=r(ikt,"RemBertModel"),ikt.forEach(t),qBo=r(Aje," (RemBERT model)"),Aje.forEach(t),jBo=i(x),O1=n(x,"LI",{});var Lje=s(O1);g1e=n(Lje,"STRONG",{});var dkt=s(g1e);DBo=r(dkt,"resnet"),dkt.forEach(t),GBo=r(Lje," \u2014 "),OX=n(Lje,"A",{href:!0});var mkt=s(OX);OBo=r(mkt,"ResNetModel"),mkt.forEach(t),VBo=r(Lje," (ResNet model)"),Lje.forEach(t),XBo=i(x),V1=n(x,"LI",{});var yje=s(V1);h1e=n(yje,"STRONG",{});var ckt=s(h1e);zBo=r(ckt,"retribert"),ckt.forEach(t),QBo=r(yje," \u2014 "),VX=n(yje,"A",{href:!0});var fkt=s(VX);WBo=r(fkt,"RetriBertModel"),fkt.forEach(t),UBo=r(yje," (RetriBERT model)"),yje.forEach(t),HBo=i(x),X1=n(x,"LI",{});var xje=s(X1);u1e=n(xje,"STRONG",{});var gkt=s(u1e);JBo=r(gkt,"roberta"),gkt.forEach(t),YBo=r(xje," \u2014 "),XX=n(xje,"A",{href:!0});var hkt=s(XX);KBo=r(hkt,"RobertaModel"),hkt.forEach(t),ZBo=r(xje," (RoBERTa model)"),xje.forEach(t),eIo=i(x),z1=n(x,"LI",{});var $je=s(z1);p1e=n($je,"STRONG",{});var ukt=s(p1e);oIo=r(ukt,"roformer"),ukt.forEach(t),rIo=r($je," \u2014 "),zX=n($je,"A",{href:!0});var pkt=s(zX);tIo=r(pkt,"RoFormerModel"),pkt.forEach(t),aIo=r($je," (RoFormer model)"),$je.forEach(t),nIo=i(x),Q1=n(x,"LI",{});var kje=s(Q1);_1e=n(kje,"STRONG",{});var _kt=s(_1e);sIo=r(_kt,"segformer"),_kt.forEach(t),lIo=r(kje," \u2014 "),QX=n(kje,"A",{href:!0});var bkt=s(QX);iIo=r(bkt,"SegformerModel"),bkt.forEach(t),dIo=r(kje," (SegFormer model)"),kje.forEach(t),mIo=i(x),W1=n(x,"LI",{});var Sje=s(W1);b1e=n(Sje,"STRONG",{});var vkt=s(b1e);cIo=r(vkt,"sew"),vkt.forEach(t),fIo=r(Sje," \u2014 "),WX=n(Sje,"A",{href:!0});var Fkt=s(WX);gIo=r(Fkt,"SEWModel"),Fkt.forEach(t),hIo=r(Sje," (SEW model)"),Sje.forEach(t),uIo=i(x),U1=n(x,"LI",{});var Rje=s(U1);v1e=n(Rje,"STRONG",{});var Tkt=s(v1e);pIo=r(Tkt,"sew-d"),Tkt.forEach(t),_Io=r(Rje," \u2014 "),UX=n(Rje,"A",{href:!0});var Mkt=s(UX);bIo=r(Mkt,"SEWDModel"),Mkt.forEach(t),vIo=r(Rje," (SEW-D model)"),Rje.forEach(t),FIo=i(x),H1=n(x,"LI",{});var Pje=s(H1);F1e=n(Pje,"STRONG",{});var Ekt=s(F1e);TIo=r(Ekt,"speech_to_text"),Ekt.forEach(t),MIo=r(Pje," \u2014 "),HX=n(Pje,"A",{href:!0});var Ckt=s(HX);EIo=r(Ckt,"Speech2TextModel"),Ckt.forEach(t),CIo=r(Pje," (Speech2Text model)"),Pje.forEach(t),wIo=i(x),J1=n(x,"LI",{});var Bje=s(J1);T1e=n(Bje,"STRONG",{});var wkt=s(T1e);AIo=r(wkt,"splinter"),wkt.forEach(t),LIo=r(Bje," \u2014 "),JX=n(Bje,"A",{href:!0});var Akt=s(JX);yIo=r(Akt,"SplinterModel"),Akt.forEach(t),xIo=r(Bje," (Splinter model)"),Bje.forEach(t),$Io=i(x),Y1=n(x,"LI",{});var Ije=s(Y1);M1e=n(Ije,"STRONG",{});var Lkt=s(M1e);kIo=r(Lkt,"squeezebert"),Lkt.forEach(t),SIo=r(Ije," \u2014 "),YX=n(Ije,"A",{href:!0});var ykt=s(YX);RIo=r(ykt,"SqueezeBertModel"),ykt.forEach(t),PIo=r(Ije," (SqueezeBERT model)"),Ije.forEach(t),BIo=i(x),K1=n(x,"LI",{});var Nje=s(K1);E1e=n(Nje,"STRONG",{});var xkt=s(E1e);IIo=r(xkt,"swin"),xkt.forEach(t),NIo=r(Nje," \u2014 "),KX=n(Nje,"A",{href:!0});var $kt=s(KX);qIo=r($kt,"SwinModel"),$kt.forEach(t),jIo=r(Nje," (Swin Transformer model)"),Nje.forEach(t),DIo=i(x),Z1=n(x,"LI",{});var qje=s(Z1);C1e=n(qje,"STRONG",{});var kkt=s(C1e);GIo=r(kkt,"swinv2"),kkt.forEach(t),OIo=r(qje," \u2014 "),ZX=n(qje,"A",{href:!0});var Skt=s(ZX);VIo=r(Skt,"Swinv2Model"),Skt.forEach(t),XIo=r(qje," (Swin Transformer V2 model)"),qje.forEach(t),zIo=i(x),e2=n(x,"LI",{});var jje=s(e2);w1e=n(jje,"STRONG",{});var Rkt=s(w1e);QIo=r(Rkt,"t5"),Rkt.forEach(t),WIo=r(jje," \u2014 "),ez=n(jje,"A",{href:!0});var Pkt=s(ez);UIo=r(Pkt,"T5Model"),Pkt.forEach(t),HIo=r(jje," (T5 model)"),jje.forEach(t),JIo=i(x),o2=n(x,"LI",{});var Dje=s(o2);A1e=n(Dje,"STRONG",{});var Bkt=s(A1e);YIo=r(Bkt,"tapas"),Bkt.forEach(t),KIo=r(Dje," \u2014 "),oz=n(Dje,"A",{href:!0});var Ikt=s(oz);ZIo=r(Ikt,"TapasModel"),Ikt.forEach(t),eNo=r(Dje," (TAPAS model)"),Dje.forEach(t),oNo=i(x),r2=n(x,"LI",{});var Gje=s(r2);L1e=n(Gje,"STRONG",{});var Nkt=s(L1e);rNo=r(Nkt,"time_series_transformer"),Nkt.forEach(t),tNo=r(Gje," \u2014 "),rz=n(Gje,"A",{href:!0});var qkt=s(rz);aNo=r(qkt,"TimeSeriesTransformerModel"),qkt.forEach(t),nNo=r(Gje," (Time Series Transformer model)"),Gje.forEach(t),sNo=i(x),t2=n(x,"LI",{});var Oje=s(t2);y1e=n(Oje,"STRONG",{});var jkt=s(y1e);lNo=r(jkt,"trajectory_transformer"),jkt.forEach(t),iNo=r(Oje," \u2014 "),tz=n(Oje,"A",{href:!0});var Dkt=s(tz);dNo=r(Dkt,"TrajectoryTransformerModel"),Dkt.forEach(t),mNo=r(Oje," (Trajectory Transformer model)"),Oje.forEach(t),cNo=i(x),a2=n(x,"LI",{});var Vje=s(a2);x1e=n(Vje,"STRONG",{});var Gkt=s(x1e);fNo=r(Gkt,"transfo-xl"),Gkt.forEach(t),gNo=r(Vje," \u2014 "),az=n(Vje,"A",{href:!0});var Okt=s(az);hNo=r(Okt,"TransfoXLModel"),Okt.forEach(t),uNo=r(Vje," (Transformer-XL model)"),Vje.forEach(t),pNo=i(x),n2=n(x,"LI",{});var Xje=s(n2);$1e=n(Xje,"STRONG",{});var Vkt=s($1e);_No=r(Vkt,"unispeech"),Vkt.forEach(t),bNo=r(Xje," \u2014 "),nz=n(Xje,"A",{href:!0});var Xkt=s(nz);vNo=r(Xkt,"UniSpeechModel"),Xkt.forEach(t),FNo=r(Xje," (UniSpeech model)"),Xje.forEach(t),TNo=i(x),s2=n(x,"LI",{});var zje=s(s2);k1e=n(zje,"STRONG",{});var zkt=s(k1e);MNo=r(zkt,"unispeech-sat"),zkt.forEach(t),ENo=r(zje," \u2014 "),sz=n(zje,"A",{href:!0});var Qkt=s(sz);CNo=r(Qkt,"UniSpeechSatModel"),Qkt.forEach(t),wNo=r(zje," (UniSpeechSat model)"),zje.forEach(t),ANo=i(x),l2=n(x,"LI",{});var Qje=s(l2);S1e=n(Qje,"STRONG",{});var Wkt=s(S1e);LNo=r(Wkt,"van"),Wkt.forEach(t),yNo=r(Qje," \u2014 "),lz=n(Qje,"A",{href:!0});var Ukt=s(lz);xNo=r(Ukt,"VanModel"),Ukt.forEach(t),$No=r(Qje," (VAN model)"),Qje.forEach(t),kNo=i(x),i2=n(x,"LI",{});var Wje=s(i2);R1e=n(Wje,"STRONG",{});var Hkt=s(R1e);SNo=r(Hkt,"videomae"),Hkt.forEach(t),RNo=r(Wje," \u2014 "),iz=n(Wje,"A",{href:!0});var Jkt=s(iz);PNo=r(Jkt,"VideoMAEModel"),Jkt.forEach(t),BNo=r(Wje," (VideoMAE model)"),Wje.forEach(t),INo=i(x),d2=n(x,"LI",{});var Uje=s(d2);P1e=n(Uje,"STRONG",{});var Ykt=s(P1e);NNo=r(Ykt,"vilt"),Ykt.forEach(t),qNo=r(Uje," \u2014 "),dz=n(Uje,"A",{href:!0});var Kkt=s(dz);jNo=r(Kkt,"ViltModel"),Kkt.forEach(t),DNo=r(Uje," (ViLT model)"),Uje.forEach(t),GNo=i(x),m2=n(x,"LI",{});var Hje=s(m2);B1e=n(Hje,"STRONG",{});var Zkt=s(B1e);ONo=r(Zkt,"vision-text-dual-encoder"),Zkt.forEach(t),VNo=r(Hje," \u2014 "),mz=n(Hje,"A",{href:!0});var eSt=s(mz);XNo=r(eSt,"VisionTextDualEncoderModel"),eSt.forEach(t),zNo=r(Hje," (VisionTextDualEncoder model)"),Hje.forEach(t),QNo=i(x),c2=n(x,"LI",{});var Jje=s(c2);I1e=n(Jje,"STRONG",{});var oSt=s(I1e);WNo=r(oSt,"visual_bert"),oSt.forEach(t),UNo=r(Jje," \u2014 "),cz=n(Jje,"A",{href:!0});var rSt=s(cz);HNo=r(rSt,"VisualBertModel"),rSt.forEach(t),JNo=r(Jje," (VisualBERT model)"),Jje.forEach(t),YNo=i(x),f2=n(x,"LI",{});var Yje=s(f2);N1e=n(Yje,"STRONG",{});var tSt=s(N1e);KNo=r(tSt,"vit"),tSt.forEach(t),ZNo=r(Yje," \u2014 "),fz=n(Yje,"A",{href:!0});var aSt=s(fz);eqo=r(aSt,"ViTModel"),aSt.forEach(t),oqo=r(Yje," (ViT model)"),Yje.forEach(t),rqo=i(x),g2=n(x,"LI",{});var Kje=s(g2);q1e=n(Kje,"STRONG",{});var nSt=s(q1e);tqo=r(nSt,"vit_mae"),nSt.forEach(t),aqo=r(Kje," \u2014 "),gz=n(Kje,"A",{href:!0});var sSt=s(gz);nqo=r(sSt,"ViTMAEModel"),sSt.forEach(t),sqo=r(Kje," (ViTMAE model)"),Kje.forEach(t),lqo=i(x),h2=n(x,"LI",{});var Zje=s(h2);j1e=n(Zje,"STRONG",{});var lSt=s(j1e);iqo=r(lSt,"vit_msn"),lSt.forEach(t),dqo=r(Zje," \u2014 "),hz=n(Zje,"A",{href:!0});var iSt=s(hz);mqo=r(iSt,"ViTMSNModel"),iSt.forEach(t),cqo=r(Zje," (ViTMSN model)"),Zje.forEach(t),fqo=i(x),u2=n(x,"LI",{});var eDe=s(u2);D1e=n(eDe,"STRONG",{});var dSt=s(D1e);gqo=r(dSt,"wav2vec2"),dSt.forEach(t),hqo=r(eDe," \u2014 "),uz=n(eDe,"A",{href:!0});var mSt=s(uz);uqo=r(mSt,"Wav2Vec2Model"),mSt.forEach(t),pqo=r(eDe," (Wav2Vec2 model)"),eDe.forEach(t),_qo=i(x),p2=n(x,"LI",{});var oDe=s(p2);G1e=n(oDe,"STRONG",{});var cSt=s(G1e);bqo=r(cSt,"wav2vec2-conformer"),cSt.forEach(t),vqo=r(oDe," \u2014 "),pz=n(oDe,"A",{href:!0});var fSt=s(pz);Fqo=r(fSt,"Wav2Vec2ConformerModel"),fSt.forEach(t),Tqo=r(oDe," (Wav2Vec2-Conformer model)"),oDe.forEach(t),Mqo=i(x),_2=n(x,"LI",{});var rDe=s(_2);O1e=n(rDe,"STRONG",{});var gSt=s(O1e);Eqo=r(gSt,"wavlm"),gSt.forEach(t),Cqo=r(rDe," \u2014 "),_z=n(rDe,"A",{href:!0});var hSt=s(_z);wqo=r(hSt,"WavLMModel"),hSt.forEach(t),Aqo=r(rDe," (WavLM model)"),rDe.forEach(t),Lqo=i(x),b2=n(x,"LI",{});var tDe=s(b2);V1e=n(tDe,"STRONG",{});var uSt=s(V1e);yqo=r(uSt,"whisper"),uSt.forEach(t),xqo=r(tDe," \u2014 "),bz=n(tDe,"A",{href:!0});var pSt=s(bz);$qo=r(pSt,"WhisperModel"),pSt.forEach(t),kqo=r(tDe," (Whisper model)"),tDe.forEach(t),Sqo=i(x),v2=n(x,"LI",{});var aDe=s(v2);X1e=n(aDe,"STRONG",{});var _St=s(X1e);Rqo=r(_St,"xclip"),_St.forEach(t),Pqo=r(aDe," \u2014 "),vz=n(aDe,"A",{href:!0});var bSt=s(vz);Bqo=r(bSt,"XCLIPModel"),bSt.forEach(t),Iqo=r(aDe," (X-CLIP model)"),aDe.forEach(t),Nqo=i(x),F2=n(x,"LI",{});var nDe=s(F2);z1e=n(nDe,"STRONG",{});var vSt=s(z1e);qqo=r(vSt,"xglm"),vSt.forEach(t),jqo=r(nDe," \u2014 "),Fz=n(nDe,"A",{href:!0});var FSt=s(Fz);Dqo=r(FSt,"XGLMModel"),FSt.forEach(t),Gqo=r(nDe," (XGLM model)"),nDe.forEach(t),Oqo=i(x),T2=n(x,"LI",{});var sDe=s(T2);Q1e=n(sDe,"STRONG",{});var TSt=s(Q1e);Vqo=r(TSt,"xlm"),TSt.forEach(t),Xqo=r(sDe," \u2014 "),Tz=n(sDe,"A",{href:!0});var MSt=s(Tz);zqo=r(MSt,"XLMModel"),MSt.forEach(t),Qqo=r(sDe," (XLM model)"),sDe.forEach(t),Wqo=i(x),M2=n(x,"LI",{});var lDe=s(M2);W1e=n(lDe,"STRONG",{});var ESt=s(W1e);Uqo=r(ESt,"xlm-prophetnet"),ESt.forEach(t),Hqo=r(lDe," \u2014 "),Mz=n(lDe,"A",{href:!0});var CSt=s(Mz);Jqo=r(CSt,"XLMProphetNetModel"),CSt.forEach(t),Yqo=r(lDe," (XLM-ProphetNet model)"),lDe.forEach(t),Kqo=i(x),E2=n(x,"LI",{});var iDe=s(E2);U1e=n(iDe,"STRONG",{});var wSt=s(U1e);Zqo=r(wSt,"xlm-roberta"),wSt.forEach(t),ejo=r(iDe," \u2014 "),Ez=n(iDe,"A",{href:!0});var ASt=s(Ez);ojo=r(ASt,"XLMRobertaModel"),ASt.forEach(t),rjo=r(iDe," (XLM-RoBERTa model)"),iDe.forEach(t),tjo=i(x),C2=n(x,"LI",{});var dDe=s(C2);H1e=n(dDe,"STRONG",{});var LSt=s(H1e);ajo=r(LSt,"xlm-roberta-xl"),LSt.forEach(t),njo=r(dDe," \u2014 "),Cz=n(dDe,"A",{href:!0});var ySt=s(Cz);sjo=r(ySt,"XLMRobertaXLModel"),ySt.forEach(t),ljo=r(dDe," (XLM-RoBERTa-XL model)"),dDe.forEach(t),ijo=i(x),w2=n(x,"LI",{});var mDe=s(w2);J1e=n(mDe,"STRONG",{});var xSt=s(J1e);djo=r(xSt,"xlnet"),xSt.forEach(t),mjo=r(mDe," \u2014 "),wz=n(mDe,"A",{href:!0});var $St=s(wz);cjo=r($St,"XLNetModel"),$St.forEach(t),fjo=r(mDe," (XLNet model)"),mDe.forEach(t),gjo=i(x),A2=n(x,"LI",{});var cDe=s(A2);Y1e=n(cDe,"STRONG",{});var kSt=s(Y1e);hjo=r(kSt,"yolos"),kSt.forEach(t),ujo=r(cDe," \u2014 "),Az=n(cDe,"A",{href:!0});var SSt=s(Az);pjo=r(SSt,"YolosModel"),SSt.forEach(t),_jo=r(cDe," (YOLOS model)"),cDe.forEach(t),bjo=i(x),L2=n(x,"LI",{});var fDe=s(L2);K1e=n(fDe,"STRONG",{});var RSt=s(K1e);vjo=r(RSt,"yoso"),RSt.forEach(t),Fjo=r(fDe," \u2014 "),Lz=n(fDe,"A",{href:!0});var PSt=s(Lz);Tjo=r(PSt,"YosoModel"),PSt.forEach(t),Mjo=r(fDe," (YOSO model)"),fDe.forEach(t),x.forEach(t),Ejo=i(Fa),y2=n(Fa,"P",{});var gDe=s(y2);Cjo=r(gDe,"The model is set in evaluation mode by default using "),Z1e=n(gDe,"CODE",{});var BSt=s(Z1e);wjo=r(BSt,"model.eval()"),BSt.forEach(t),Ajo=r(gDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),e2e=n(gDe,"CODE",{});var ISt=s(e2e);Ljo=r(ISt,"model.train()"),ISt.forEach(t),gDe.forEach(t),yjo=i(Fa),T(x2.$$.fragment,Fa),Fa.forEach(t),Al.forEach(t),$eo=i(c),Fd=n(c,"H2",{class:!0});var Xro=s(Fd);$2=n(Xro,"A",{id:!0,class:!0,href:!0});var NSt=s($2);o2e=n(NSt,"SPAN",{});var qSt=s(o2e);T(jx.$$.fragment,qSt),qSt.forEach(t),NSt.forEach(t),xjo=i(Xro),r2e=n(Xro,"SPAN",{});var jSt=s(r2e);$jo=r(jSt,"AutoModelForPreTraining"),jSt.forEach(t),Xro.forEach(t),keo=i(c),Bo=n(c,"DIV",{class:!0});var Ll=s(Bo);T(Dx.$$.fragment,Ll),kjo=i(Ll),Td=n(Ll,"P",{});var hie=s(Td);Sjo=r(hie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),yz=n(hie,"A",{href:!0});var DSt=s(yz);Rjo=r(DSt,"from_pretrained()"),DSt.forEach(t),Pjo=r(hie," class method or the "),xz=n(hie,"A",{href:!0});var GSt=s(xz);Bjo=r(GSt,"from_config()"),GSt.forEach(t),Ijo=r(hie,` class
method.`),hie.forEach(t),Njo=i(Ll),Gx=n(Ll,"P",{});var zro=s(Gx);qjo=r(zro,"This class cannot be instantiated directly using "),t2e=n(zro,"CODE",{});var OSt=s(t2e);jjo=r(OSt,"__init__()"),OSt.forEach(t),Djo=r(zro," (throws an error)."),zro.forEach(t),Gjo=i(Ll),bt=n(Ll,"DIV",{class:!0});var a8=s(bt);T(Ox.$$.fragment,a8),Ojo=i(a8),a2e=n(a8,"P",{});var VSt=s(a2e);Vjo=r(VSt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),VSt.forEach(t),Xjo=i(a8),Md=n(a8,"P",{});var uie=s(Md);zjo=r(uie,`Note:
Loading a model from its configuration file does `),n2e=n(uie,"STRONG",{});var XSt=s(n2e);Qjo=r(XSt,"not"),XSt.forEach(t),Wjo=r(uie,` load the model weights. It only affects the
model\u2019s configuration. Use `),$z=n(uie,"A",{href:!0});var zSt=s($z);Ujo=r(zSt,"from_pretrained()"),zSt.forEach(t),Hjo=r(uie," to load the model weights."),uie.forEach(t),Jjo=i(a8),T(k2.$$.fragment,a8),a8.forEach(t),Yjo=i(Ll),eo=n(Ll,"DIV",{class:!0});var Ta=s(eo);T(Vx.$$.fragment,Ta),Kjo=i(Ta),s2e=n(Ta,"P",{});var QSt=s(s2e);Zjo=r(QSt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),QSt.forEach(t),eDo=i(Ta),Ya=n(Ta,"P",{});var n8=s(Ya);oDo=r(n8,"The model class to instantiate is selected based on the "),l2e=n(n8,"CODE",{});var WSt=s(l2e);rDo=r(WSt,"model_type"),WSt.forEach(t),tDo=r(n8,` property of the config object (either
passed as an argument or loaded from `),i2e=n(n8,"CODE",{});var USt=s(i2e);aDo=r(USt,"pretrained_model_name_or_path"),USt.forEach(t),nDo=r(n8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d2e=n(n8,"CODE",{});var HSt=s(d2e);sDo=r(HSt,"pretrained_model_name_or_path"),HSt.forEach(t),lDo=r(n8,":"),n8.forEach(t),iDo=i(Ta),G=n(Ta,"UL",{});var O=s(G);S2=n(O,"LI",{});var hDe=s(S2);m2e=n(hDe,"STRONG",{});var JSt=s(m2e);dDo=r(JSt,"albert"),JSt.forEach(t),mDo=r(hDe," \u2014 "),kz=n(hDe,"A",{href:!0});var YSt=s(kz);cDo=r(YSt,"AlbertForPreTraining"),YSt.forEach(t),fDo=r(hDe," (ALBERT model)"),hDe.forEach(t),gDo=i(O),R2=n(O,"LI",{});var uDe=s(R2);c2e=n(uDe,"STRONG",{});var KSt=s(c2e);hDo=r(KSt,"bart"),KSt.forEach(t),uDo=r(uDe," \u2014 "),Sz=n(uDe,"A",{href:!0});var ZSt=s(Sz);pDo=r(ZSt,"BartForConditionalGeneration"),ZSt.forEach(t),_Do=r(uDe," (BART model)"),uDe.forEach(t),bDo=i(O),P2=n(O,"LI",{});var pDe=s(P2);f2e=n(pDe,"STRONG",{});var eRt=s(f2e);vDo=r(eRt,"bert"),eRt.forEach(t),FDo=r(pDe," \u2014 "),Rz=n(pDe,"A",{href:!0});var oRt=s(Rz);TDo=r(oRt,"BertForPreTraining"),oRt.forEach(t),MDo=r(pDe," (BERT model)"),pDe.forEach(t),EDo=i(O),B2=n(O,"LI",{});var _De=s(B2);g2e=n(_De,"STRONG",{});var rRt=s(g2e);CDo=r(rRt,"big_bird"),rRt.forEach(t),wDo=r(_De," \u2014 "),Pz=n(_De,"A",{href:!0});var tRt=s(Pz);ADo=r(tRt,"BigBirdForPreTraining"),tRt.forEach(t),LDo=r(_De," (BigBird model)"),_De.forEach(t),yDo=i(O),I2=n(O,"LI",{});var bDe=s(I2);h2e=n(bDe,"STRONG",{});var aRt=s(h2e);xDo=r(aRt,"bloom"),aRt.forEach(t),$Do=r(bDe," \u2014 "),Bz=n(bDe,"A",{href:!0});var nRt=s(Bz);kDo=r(nRt,"BloomForCausalLM"),nRt.forEach(t),SDo=r(bDe," (BLOOM model)"),bDe.forEach(t),RDo=i(O),N2=n(O,"LI",{});var vDe=s(N2);u2e=n(vDe,"STRONG",{});var sRt=s(u2e);PDo=r(sRt,"camembert"),sRt.forEach(t),BDo=r(vDe," \u2014 "),Iz=n(vDe,"A",{href:!0});var lRt=s(Iz);IDo=r(lRt,"CamembertForMaskedLM"),lRt.forEach(t),NDo=r(vDe," (CamemBERT model)"),vDe.forEach(t),qDo=i(O),q2=n(O,"LI",{});var FDe=s(q2);p2e=n(FDe,"STRONG",{});var iRt=s(p2e);jDo=r(iRt,"ctrl"),iRt.forEach(t),DDo=r(FDe," \u2014 "),Nz=n(FDe,"A",{href:!0});var dRt=s(Nz);GDo=r(dRt,"CTRLLMHeadModel"),dRt.forEach(t),ODo=r(FDe," (CTRL model)"),FDe.forEach(t),VDo=i(O),j2=n(O,"LI",{});var TDe=s(j2);_2e=n(TDe,"STRONG",{});var mRt=s(_2e);XDo=r(mRt,"data2vec-text"),mRt.forEach(t),zDo=r(TDe," \u2014 "),qz=n(TDe,"A",{href:!0});var cRt=s(qz);QDo=r(cRt,"Data2VecTextForMaskedLM"),cRt.forEach(t),WDo=r(TDe," (Data2VecText model)"),TDe.forEach(t),UDo=i(O),D2=n(O,"LI",{});var MDe=s(D2);b2e=n(MDe,"STRONG",{});var fRt=s(b2e);HDo=r(fRt,"deberta"),fRt.forEach(t),JDo=r(MDe," \u2014 "),jz=n(MDe,"A",{href:!0});var gRt=s(jz);YDo=r(gRt,"DebertaForMaskedLM"),gRt.forEach(t),KDo=r(MDe," (DeBERTa model)"),MDe.forEach(t),ZDo=i(O),G2=n(O,"LI",{});var EDe=s(G2);v2e=n(EDe,"STRONG",{});var hRt=s(v2e);eGo=r(hRt,"deberta-v2"),hRt.forEach(t),oGo=r(EDe," \u2014 "),Dz=n(EDe,"A",{href:!0});var uRt=s(Dz);rGo=r(uRt,"DebertaV2ForMaskedLM"),uRt.forEach(t),tGo=r(EDe," (DeBERTa-v2 model)"),EDe.forEach(t),aGo=i(O),O2=n(O,"LI",{});var CDe=s(O2);F2e=n(CDe,"STRONG",{});var pRt=s(F2e);nGo=r(pRt,"distilbert"),pRt.forEach(t),sGo=r(CDe," \u2014 "),Gz=n(CDe,"A",{href:!0});var _Rt=s(Gz);lGo=r(_Rt,"DistilBertForMaskedLM"),_Rt.forEach(t),iGo=r(CDe," (DistilBERT model)"),CDe.forEach(t),dGo=i(O),V2=n(O,"LI",{});var wDe=s(V2);T2e=n(wDe,"STRONG",{});var bRt=s(T2e);mGo=r(bRt,"electra"),bRt.forEach(t),cGo=r(wDe," \u2014 "),Oz=n(wDe,"A",{href:!0});var vRt=s(Oz);fGo=r(vRt,"ElectraForPreTraining"),vRt.forEach(t),gGo=r(wDe," (ELECTRA model)"),wDe.forEach(t),hGo=i(O),X2=n(O,"LI",{});var ADe=s(X2);M2e=n(ADe,"STRONG",{});var FRt=s(M2e);uGo=r(FRt,"ernie"),FRt.forEach(t),pGo=r(ADe," \u2014 "),Vz=n(ADe,"A",{href:!0});var TRt=s(Vz);_Go=r(TRt,"ErnieForPreTraining"),TRt.forEach(t),bGo=r(ADe," (ERNIE model)"),ADe.forEach(t),vGo=i(O),z2=n(O,"LI",{});var LDe=s(z2);E2e=n(LDe,"STRONG",{});var MRt=s(E2e);FGo=r(MRt,"flaubert"),MRt.forEach(t),TGo=r(LDe," \u2014 "),Xz=n(LDe,"A",{href:!0});var ERt=s(Xz);MGo=r(ERt,"FlaubertWithLMHeadModel"),ERt.forEach(t),EGo=r(LDe," (FlauBERT model)"),LDe.forEach(t),CGo=i(O),Q2=n(O,"LI",{});var yDe=s(Q2);C2e=n(yDe,"STRONG",{});var CRt=s(C2e);wGo=r(CRt,"flava"),CRt.forEach(t),AGo=r(yDe," \u2014 "),zz=n(yDe,"A",{href:!0});var wRt=s(zz);LGo=r(wRt,"FlavaForPreTraining"),wRt.forEach(t),yGo=r(yDe," (FLAVA model)"),yDe.forEach(t),xGo=i(O),W2=n(O,"LI",{});var xDe=s(W2);w2e=n(xDe,"STRONG",{});var ARt=s(w2e);$Go=r(ARt,"fnet"),ARt.forEach(t),kGo=r(xDe," \u2014 "),Qz=n(xDe,"A",{href:!0});var LRt=s(Qz);SGo=r(LRt,"FNetForPreTraining"),LRt.forEach(t),RGo=r(xDe," (FNet model)"),xDe.forEach(t),PGo=i(O),U2=n(O,"LI",{});var $De=s(U2);A2e=n($De,"STRONG",{});var yRt=s(A2e);BGo=r(yRt,"fsmt"),yRt.forEach(t),IGo=r($De," \u2014 "),Wz=n($De,"A",{href:!0});var xRt=s(Wz);NGo=r(xRt,"FSMTForConditionalGeneration"),xRt.forEach(t),qGo=r($De," (FairSeq Machine-Translation model)"),$De.forEach(t),jGo=i(O),H2=n(O,"LI",{});var kDe=s(H2);L2e=n(kDe,"STRONG",{});var $Rt=s(L2e);DGo=r($Rt,"funnel"),$Rt.forEach(t),GGo=r(kDe," \u2014 "),Uz=n(kDe,"A",{href:!0});var kRt=s(Uz);OGo=r(kRt,"FunnelForPreTraining"),kRt.forEach(t),VGo=r(kDe," (Funnel Transformer model)"),kDe.forEach(t),XGo=i(O),J2=n(O,"LI",{});var SDe=s(J2);y2e=n(SDe,"STRONG",{});var SRt=s(y2e);zGo=r(SRt,"gpt2"),SRt.forEach(t),QGo=r(SDe," \u2014 "),Hz=n(SDe,"A",{href:!0});var RRt=s(Hz);WGo=r(RRt,"GPT2LMHeadModel"),RRt.forEach(t),UGo=r(SDe," (OpenAI GPT-2 model)"),SDe.forEach(t),HGo=i(O),Y2=n(O,"LI",{});var RDe=s(Y2);x2e=n(RDe,"STRONG",{});var PRt=s(x2e);JGo=r(PRt,"ibert"),PRt.forEach(t),YGo=r(RDe," \u2014 "),Jz=n(RDe,"A",{href:!0});var BRt=s(Jz);KGo=r(BRt,"IBertForMaskedLM"),BRt.forEach(t),ZGo=r(RDe," (I-BERT model)"),RDe.forEach(t),eOo=i(O),K2=n(O,"LI",{});var PDe=s(K2);$2e=n(PDe,"STRONG",{});var IRt=s($2e);oOo=r(IRt,"layoutlm"),IRt.forEach(t),rOo=r(PDe," \u2014 "),Yz=n(PDe,"A",{href:!0});var NRt=s(Yz);tOo=r(NRt,"LayoutLMForMaskedLM"),NRt.forEach(t),aOo=r(PDe," (LayoutLM model)"),PDe.forEach(t),nOo=i(O),Z2=n(O,"LI",{});var BDe=s(Z2);k2e=n(BDe,"STRONG",{});var qRt=s(k2e);sOo=r(qRt,"longformer"),qRt.forEach(t),lOo=r(BDe," \u2014 "),Kz=n(BDe,"A",{href:!0});var jRt=s(Kz);iOo=r(jRt,"LongformerForMaskedLM"),jRt.forEach(t),dOo=r(BDe," (Longformer model)"),BDe.forEach(t),mOo=i(O),eb=n(O,"LI",{});var IDe=s(eb);S2e=n(IDe,"STRONG",{});var DRt=s(S2e);cOo=r(DRt,"luke"),DRt.forEach(t),fOo=r(IDe," \u2014 "),Zz=n(IDe,"A",{href:!0});var GRt=s(Zz);gOo=r(GRt,"LukeForMaskedLM"),GRt.forEach(t),hOo=r(IDe," (LUKE model)"),IDe.forEach(t),uOo=i(O),ob=n(O,"LI",{});var NDe=s(ob);R2e=n(NDe,"STRONG",{});var ORt=s(R2e);pOo=r(ORt,"lxmert"),ORt.forEach(t),_Oo=r(NDe," \u2014 "),eQ=n(NDe,"A",{href:!0});var VRt=s(eQ);bOo=r(VRt,"LxmertForPreTraining"),VRt.forEach(t),vOo=r(NDe," (LXMERT model)"),NDe.forEach(t),FOo=i(O),rb=n(O,"LI",{});var qDe=s(rb);P2e=n(qDe,"STRONG",{});var XRt=s(P2e);TOo=r(XRt,"megatron-bert"),XRt.forEach(t),MOo=r(qDe," \u2014 "),oQ=n(qDe,"A",{href:!0});var zRt=s(oQ);EOo=r(zRt,"MegatronBertForPreTraining"),zRt.forEach(t),COo=r(qDe," (Megatron-BERT model)"),qDe.forEach(t),wOo=i(O),tb=n(O,"LI",{});var jDe=s(tb);B2e=n(jDe,"STRONG",{});var QRt=s(B2e);AOo=r(QRt,"mobilebert"),QRt.forEach(t),LOo=r(jDe," \u2014 "),rQ=n(jDe,"A",{href:!0});var WRt=s(rQ);yOo=r(WRt,"MobileBertForPreTraining"),WRt.forEach(t),xOo=r(jDe," (MobileBERT model)"),jDe.forEach(t),$Oo=i(O),ab=n(O,"LI",{});var DDe=s(ab);I2e=n(DDe,"STRONG",{});var URt=s(I2e);kOo=r(URt,"mpnet"),URt.forEach(t),SOo=r(DDe," \u2014 "),tQ=n(DDe,"A",{href:!0});var HRt=s(tQ);ROo=r(HRt,"MPNetForMaskedLM"),HRt.forEach(t),POo=r(DDe," (MPNet model)"),DDe.forEach(t),BOo=i(O),nb=n(O,"LI",{});var GDe=s(nb);N2e=n(GDe,"STRONG",{});var JRt=s(N2e);IOo=r(JRt,"mvp"),JRt.forEach(t),NOo=r(GDe," \u2014 "),aQ=n(GDe,"A",{href:!0});var YRt=s(aQ);qOo=r(YRt,"MvpForConditionalGeneration"),YRt.forEach(t),jOo=r(GDe," (MVP model)"),GDe.forEach(t),DOo=i(O),sb=n(O,"LI",{});var ODe=s(sb);q2e=n(ODe,"STRONG",{});var KRt=s(q2e);GOo=r(KRt,"nezha"),KRt.forEach(t),OOo=r(ODe," \u2014 "),nQ=n(ODe,"A",{href:!0});var ZRt=s(nQ);VOo=r(ZRt,"NezhaForPreTraining"),ZRt.forEach(t),XOo=r(ODe," (Nezha model)"),ODe.forEach(t),zOo=i(O),lb=n(O,"LI",{});var VDe=s(lb);j2e=n(VDe,"STRONG",{});var ePt=s(j2e);QOo=r(ePt,"openai-gpt"),ePt.forEach(t),WOo=r(VDe," \u2014 "),sQ=n(VDe,"A",{href:!0});var oPt=s(sQ);UOo=r(oPt,"OpenAIGPTLMHeadModel"),oPt.forEach(t),HOo=r(VDe," (OpenAI GPT model)"),VDe.forEach(t),JOo=i(O),ib=n(O,"LI",{});var XDe=s(ib);D2e=n(XDe,"STRONG",{});var rPt=s(D2e);YOo=r(rPt,"retribert"),rPt.forEach(t),KOo=r(XDe," \u2014 "),lQ=n(XDe,"A",{href:!0});var tPt=s(lQ);ZOo=r(tPt,"RetriBertModel"),tPt.forEach(t),eVo=r(XDe," (RetriBERT model)"),XDe.forEach(t),oVo=i(O),db=n(O,"LI",{});var zDe=s(db);G2e=n(zDe,"STRONG",{});var aPt=s(G2e);rVo=r(aPt,"roberta"),aPt.forEach(t),tVo=r(zDe," \u2014 "),iQ=n(zDe,"A",{href:!0});var nPt=s(iQ);aVo=r(nPt,"RobertaForMaskedLM"),nPt.forEach(t),nVo=r(zDe," (RoBERTa model)"),zDe.forEach(t),sVo=i(O),mb=n(O,"LI",{});var QDe=s(mb);O2e=n(QDe,"STRONG",{});var sPt=s(O2e);lVo=r(sPt,"splinter"),sPt.forEach(t),iVo=r(QDe," \u2014 "),dQ=n(QDe,"A",{href:!0});var lPt=s(dQ);dVo=r(lPt,"SplinterForPreTraining"),lPt.forEach(t),mVo=r(QDe," (Splinter model)"),QDe.forEach(t),cVo=i(O),cb=n(O,"LI",{});var WDe=s(cb);V2e=n(WDe,"STRONG",{});var iPt=s(V2e);fVo=r(iPt,"squeezebert"),iPt.forEach(t),gVo=r(WDe," \u2014 "),mQ=n(WDe,"A",{href:!0});var dPt=s(mQ);hVo=r(dPt,"SqueezeBertForMaskedLM"),dPt.forEach(t),uVo=r(WDe," (SqueezeBERT model)"),WDe.forEach(t),pVo=i(O),fb=n(O,"LI",{});var UDe=s(fb);X2e=n(UDe,"STRONG",{});var mPt=s(X2e);_Vo=r(mPt,"t5"),mPt.forEach(t),bVo=r(UDe," \u2014 "),cQ=n(UDe,"A",{href:!0});var cPt=s(cQ);vVo=r(cPt,"T5ForConditionalGeneration"),cPt.forEach(t),FVo=r(UDe," (T5 model)"),UDe.forEach(t),TVo=i(O),gb=n(O,"LI",{});var HDe=s(gb);z2e=n(HDe,"STRONG",{});var fPt=s(z2e);MVo=r(fPt,"tapas"),fPt.forEach(t),EVo=r(HDe," \u2014 "),fQ=n(HDe,"A",{href:!0});var gPt=s(fQ);CVo=r(gPt,"TapasForMaskedLM"),gPt.forEach(t),wVo=r(HDe," (TAPAS model)"),HDe.forEach(t),AVo=i(O),hb=n(O,"LI",{});var JDe=s(hb);Q2e=n(JDe,"STRONG",{});var hPt=s(Q2e);LVo=r(hPt,"transfo-xl"),hPt.forEach(t),yVo=r(JDe," \u2014 "),gQ=n(JDe,"A",{href:!0});var uPt=s(gQ);xVo=r(uPt,"TransfoXLLMHeadModel"),uPt.forEach(t),$Vo=r(JDe," (Transformer-XL model)"),JDe.forEach(t),kVo=i(O),ub=n(O,"LI",{});var YDe=s(ub);W2e=n(YDe,"STRONG",{});var pPt=s(W2e);SVo=r(pPt,"unispeech"),pPt.forEach(t),RVo=r(YDe," \u2014 "),hQ=n(YDe,"A",{href:!0});var _Pt=s(hQ);PVo=r(_Pt,"UniSpeechForPreTraining"),_Pt.forEach(t),BVo=r(YDe," (UniSpeech model)"),YDe.forEach(t),IVo=i(O),pb=n(O,"LI",{});var KDe=s(pb);U2e=n(KDe,"STRONG",{});var bPt=s(U2e);NVo=r(bPt,"unispeech-sat"),bPt.forEach(t),qVo=r(KDe," \u2014 "),uQ=n(KDe,"A",{href:!0});var vPt=s(uQ);jVo=r(vPt,"UniSpeechSatForPreTraining"),vPt.forEach(t),DVo=r(KDe," (UniSpeechSat model)"),KDe.forEach(t),GVo=i(O),_b=n(O,"LI",{});var ZDe=s(_b);H2e=n(ZDe,"STRONG",{});var FPt=s(H2e);OVo=r(FPt,"videomae"),FPt.forEach(t),VVo=r(ZDe," \u2014 "),pQ=n(ZDe,"A",{href:!0});var TPt=s(pQ);XVo=r(TPt,"VideoMAEForPreTraining"),TPt.forEach(t),zVo=r(ZDe," (VideoMAE model)"),ZDe.forEach(t),QVo=i(O),bb=n(O,"LI",{});var eGe=s(bb);J2e=n(eGe,"STRONG",{});var MPt=s(J2e);WVo=r(MPt,"visual_bert"),MPt.forEach(t),UVo=r(eGe," \u2014 "),_Q=n(eGe,"A",{href:!0});var EPt=s(_Q);HVo=r(EPt,"VisualBertForPreTraining"),EPt.forEach(t),JVo=r(eGe," (VisualBERT model)"),eGe.forEach(t),YVo=i(O),vb=n(O,"LI",{});var oGe=s(vb);Y2e=n(oGe,"STRONG",{});var CPt=s(Y2e);KVo=r(CPt,"vit_mae"),CPt.forEach(t),ZVo=r(oGe," \u2014 "),bQ=n(oGe,"A",{href:!0});var wPt=s(bQ);eXo=r(wPt,"ViTMAEForPreTraining"),wPt.forEach(t),oXo=r(oGe," (ViTMAE model)"),oGe.forEach(t),rXo=i(O),Fb=n(O,"LI",{});var rGe=s(Fb);K2e=n(rGe,"STRONG",{});var APt=s(K2e);tXo=r(APt,"wav2vec2"),APt.forEach(t),aXo=r(rGe," \u2014 "),vQ=n(rGe,"A",{href:!0});var LPt=s(vQ);nXo=r(LPt,"Wav2Vec2ForPreTraining"),LPt.forEach(t),sXo=r(rGe," (Wav2Vec2 model)"),rGe.forEach(t),lXo=i(O),Tb=n(O,"LI",{});var tGe=s(Tb);Z2e=n(tGe,"STRONG",{});var yPt=s(Z2e);iXo=r(yPt,"wav2vec2-conformer"),yPt.forEach(t),dXo=r(tGe," \u2014 "),FQ=n(tGe,"A",{href:!0});var xPt=s(FQ);mXo=r(xPt,"Wav2Vec2ConformerForPreTraining"),xPt.forEach(t),cXo=r(tGe," (Wav2Vec2-Conformer model)"),tGe.forEach(t),fXo=i(O),Mb=n(O,"LI",{});var aGe=s(Mb);ebe=n(aGe,"STRONG",{});var $Pt=s(ebe);gXo=r($Pt,"xlm"),$Pt.forEach(t),hXo=r(aGe," \u2014 "),TQ=n(aGe,"A",{href:!0});var kPt=s(TQ);uXo=r(kPt,"XLMWithLMHeadModel"),kPt.forEach(t),pXo=r(aGe," (XLM model)"),aGe.forEach(t),_Xo=i(O),Eb=n(O,"LI",{});var nGe=s(Eb);obe=n(nGe,"STRONG",{});var SPt=s(obe);bXo=r(SPt,"xlm-roberta"),SPt.forEach(t),vXo=r(nGe," \u2014 "),MQ=n(nGe,"A",{href:!0});var RPt=s(MQ);FXo=r(RPt,"XLMRobertaForMaskedLM"),RPt.forEach(t),TXo=r(nGe," (XLM-RoBERTa model)"),nGe.forEach(t),MXo=i(O),Cb=n(O,"LI",{});var sGe=s(Cb);rbe=n(sGe,"STRONG",{});var PPt=s(rbe);EXo=r(PPt,"xlm-roberta-xl"),PPt.forEach(t),CXo=r(sGe," \u2014 "),EQ=n(sGe,"A",{href:!0});var BPt=s(EQ);wXo=r(BPt,"XLMRobertaXLForMaskedLM"),BPt.forEach(t),AXo=r(sGe," (XLM-RoBERTa-XL model)"),sGe.forEach(t),LXo=i(O),wb=n(O,"LI",{});var lGe=s(wb);tbe=n(lGe,"STRONG",{});var IPt=s(tbe);yXo=r(IPt,"xlnet"),IPt.forEach(t),xXo=r(lGe," \u2014 "),CQ=n(lGe,"A",{href:!0});var NPt=s(CQ);$Xo=r(NPt,"XLNetLMHeadModel"),NPt.forEach(t),kXo=r(lGe," (XLNet model)"),lGe.forEach(t),O.forEach(t),SXo=i(Ta),Ab=n(Ta,"P",{});var iGe=s(Ab);RXo=r(iGe,"The model is set in evaluation mode by default using "),abe=n(iGe,"CODE",{});var qPt=s(abe);PXo=r(qPt,"model.eval()"),qPt.forEach(t),BXo=r(iGe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nbe=n(iGe,"CODE",{});var jPt=s(nbe);IXo=r(jPt,"model.train()"),jPt.forEach(t),iGe.forEach(t),NXo=i(Ta),T(Lb.$$.fragment,Ta),Ta.forEach(t),Ll.forEach(t),Seo=i(c),Ed=n(c,"H2",{class:!0});var Qro=s(Ed);yb=n(Qro,"A",{id:!0,class:!0,href:!0});var DPt=s(yb);sbe=n(DPt,"SPAN",{});var GPt=s(sbe);T(Xx.$$.fragment,GPt),GPt.forEach(t),DPt.forEach(t),qXo=i(Qro),lbe=n(Qro,"SPAN",{});var OPt=s(lbe);jXo=r(OPt,"AutoModelForCausalLM"),OPt.forEach(t),Qro.forEach(t),Reo=i(c),Io=n(c,"DIV",{class:!0});var yl=s(Io);T(zx.$$.fragment,yl),DXo=i(yl),Cd=n(yl,"P",{});var pie=s(Cd);GXo=r(pie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wQ=n(pie,"A",{href:!0});var VPt=s(wQ);OXo=r(VPt,"from_pretrained()"),VPt.forEach(t),VXo=r(pie," class method or the "),AQ=n(pie,"A",{href:!0});var XPt=s(AQ);XXo=r(XPt,"from_config()"),XPt.forEach(t),zXo=r(pie,` class
method.`),pie.forEach(t),QXo=i(yl),Qx=n(yl,"P",{});var Wro=s(Qx);WXo=r(Wro,"This class cannot be instantiated directly using "),ibe=n(Wro,"CODE",{});var zPt=s(ibe);UXo=r(zPt,"__init__()"),zPt.forEach(t),HXo=r(Wro," (throws an error)."),Wro.forEach(t),JXo=i(yl),vt=n(yl,"DIV",{class:!0});var s8=s(vt);T(Wx.$$.fragment,s8),YXo=i(s8),dbe=n(s8,"P",{});var QPt=s(dbe);KXo=r(QPt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),QPt.forEach(t),ZXo=i(s8),wd=n(s8,"P",{});var _ie=s(wd);ezo=r(_ie,`Note:
Loading a model from its configuration file does `),mbe=n(_ie,"STRONG",{});var WPt=s(mbe);ozo=r(WPt,"not"),WPt.forEach(t),rzo=r(_ie,` load the model weights. It only affects the
model\u2019s configuration. Use `),LQ=n(_ie,"A",{href:!0});var UPt=s(LQ);tzo=r(UPt,"from_pretrained()"),UPt.forEach(t),azo=r(_ie," to load the model weights."),_ie.forEach(t),nzo=i(s8),T(xb.$$.fragment,s8),s8.forEach(t),szo=i(yl),oo=n(yl,"DIV",{class:!0});var Ma=s(oo);T(Ux.$$.fragment,Ma),lzo=i(Ma),cbe=n(Ma,"P",{});var HPt=s(cbe);izo=r(HPt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),HPt.forEach(t),dzo=i(Ma),Ka=n(Ma,"P",{});var l8=s(Ka);mzo=r(l8,"The model class to instantiate is selected based on the "),fbe=n(l8,"CODE",{});var JPt=s(fbe);czo=r(JPt,"model_type"),JPt.forEach(t),fzo=r(l8,` property of the config object (either
passed as an argument or loaded from `),gbe=n(l8,"CODE",{});var YPt=s(gbe);gzo=r(YPt,"pretrained_model_name_or_path"),YPt.forEach(t),hzo=r(l8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hbe=n(l8,"CODE",{});var KPt=s(hbe);uzo=r(KPt,"pretrained_model_name_or_path"),KPt.forEach(t),pzo=r(l8,":"),l8.forEach(t),_zo=i(Ma),Q=n(Ma,"UL",{});var U=s(Q);$b=n(U,"LI",{});var dGe=s($b);ube=n(dGe,"STRONG",{});var ZPt=s(ube);bzo=r(ZPt,"bart"),ZPt.forEach(t),vzo=r(dGe," \u2014 "),yQ=n(dGe,"A",{href:!0});var eBt=s(yQ);Fzo=r(eBt,"BartForCausalLM"),eBt.forEach(t),Tzo=r(dGe," (BART model)"),dGe.forEach(t),Mzo=i(U),kb=n(U,"LI",{});var mGe=s(kb);pbe=n(mGe,"STRONG",{});var oBt=s(pbe);Ezo=r(oBt,"bert"),oBt.forEach(t),Czo=r(mGe," \u2014 "),xQ=n(mGe,"A",{href:!0});var rBt=s(xQ);wzo=r(rBt,"BertLMHeadModel"),rBt.forEach(t),Azo=r(mGe," (BERT model)"),mGe.forEach(t),Lzo=i(U),Sb=n(U,"LI",{});var cGe=s(Sb);_be=n(cGe,"STRONG",{});var tBt=s(_be);yzo=r(tBt,"bert-generation"),tBt.forEach(t),xzo=r(cGe," \u2014 "),$Q=n(cGe,"A",{href:!0});var aBt=s($Q);$zo=r(aBt,"BertGenerationDecoder"),aBt.forEach(t),kzo=r(cGe," (Bert Generation model)"),cGe.forEach(t),Szo=i(U),Rb=n(U,"LI",{});var fGe=s(Rb);bbe=n(fGe,"STRONG",{});var nBt=s(bbe);Rzo=r(nBt,"big_bird"),nBt.forEach(t),Pzo=r(fGe," \u2014 "),kQ=n(fGe,"A",{href:!0});var sBt=s(kQ);Bzo=r(sBt,"BigBirdForCausalLM"),sBt.forEach(t),Izo=r(fGe," (BigBird model)"),fGe.forEach(t),Nzo=i(U),Pb=n(U,"LI",{});var gGe=s(Pb);vbe=n(gGe,"STRONG",{});var lBt=s(vbe);qzo=r(lBt,"bigbird_pegasus"),lBt.forEach(t),jzo=r(gGe," \u2014 "),SQ=n(gGe,"A",{href:!0});var iBt=s(SQ);Dzo=r(iBt,"BigBirdPegasusForCausalLM"),iBt.forEach(t),Gzo=r(gGe," (BigBird-Pegasus model)"),gGe.forEach(t),Ozo=i(U),Bb=n(U,"LI",{});var hGe=s(Bb);Fbe=n(hGe,"STRONG",{});var dBt=s(Fbe);Vzo=r(dBt,"blenderbot"),dBt.forEach(t),Xzo=r(hGe," \u2014 "),RQ=n(hGe,"A",{href:!0});var mBt=s(RQ);zzo=r(mBt,"BlenderbotForCausalLM"),mBt.forEach(t),Qzo=r(hGe," (Blenderbot model)"),hGe.forEach(t),Wzo=i(U),Ib=n(U,"LI",{});var uGe=s(Ib);Tbe=n(uGe,"STRONG",{});var cBt=s(Tbe);Uzo=r(cBt,"blenderbot-small"),cBt.forEach(t),Hzo=r(uGe," \u2014 "),PQ=n(uGe,"A",{href:!0});var fBt=s(PQ);Jzo=r(fBt,"BlenderbotSmallForCausalLM"),fBt.forEach(t),Yzo=r(uGe," (BlenderbotSmall model)"),uGe.forEach(t),Kzo=i(U),Nb=n(U,"LI",{});var pGe=s(Nb);Mbe=n(pGe,"STRONG",{});var gBt=s(Mbe);Zzo=r(gBt,"bloom"),gBt.forEach(t),eQo=r(pGe," \u2014 "),BQ=n(pGe,"A",{href:!0});var hBt=s(BQ);oQo=r(hBt,"BloomForCausalLM"),hBt.forEach(t),rQo=r(pGe," (BLOOM model)"),pGe.forEach(t),tQo=i(U),qb=n(U,"LI",{});var _Ge=s(qb);Ebe=n(_Ge,"STRONG",{});var uBt=s(Ebe);aQo=r(uBt,"camembert"),uBt.forEach(t),nQo=r(_Ge," \u2014 "),IQ=n(_Ge,"A",{href:!0});var pBt=s(IQ);sQo=r(pBt,"CamembertForCausalLM"),pBt.forEach(t),lQo=r(_Ge," (CamemBERT model)"),_Ge.forEach(t),iQo=i(U),jb=n(U,"LI",{});var bGe=s(jb);Cbe=n(bGe,"STRONG",{});var _Bt=s(Cbe);dQo=r(_Bt,"codegen"),_Bt.forEach(t),mQo=r(bGe," \u2014 "),NQ=n(bGe,"A",{href:!0});var bBt=s(NQ);cQo=r(bBt,"CodeGenForCausalLM"),bBt.forEach(t),fQo=r(bGe," (CodeGen model)"),bGe.forEach(t),gQo=i(U),Db=n(U,"LI",{});var vGe=s(Db);wbe=n(vGe,"STRONG",{});var vBt=s(wbe);hQo=r(vBt,"ctrl"),vBt.forEach(t),uQo=r(vGe," \u2014 "),qQ=n(vGe,"A",{href:!0});var FBt=s(qQ);pQo=r(FBt,"CTRLLMHeadModel"),FBt.forEach(t),_Qo=r(vGe," (CTRL model)"),vGe.forEach(t),bQo=i(U),Gb=n(U,"LI",{});var FGe=s(Gb);Abe=n(FGe,"STRONG",{});var TBt=s(Abe);vQo=r(TBt,"data2vec-text"),TBt.forEach(t),FQo=r(FGe," \u2014 "),jQ=n(FGe,"A",{href:!0});var MBt=s(jQ);TQo=r(MBt,"Data2VecTextForCausalLM"),MBt.forEach(t),MQo=r(FGe," (Data2VecText model)"),FGe.forEach(t),EQo=i(U),Ob=n(U,"LI",{});var TGe=s(Ob);Lbe=n(TGe,"STRONG",{});var EBt=s(Lbe);CQo=r(EBt,"electra"),EBt.forEach(t),wQo=r(TGe," \u2014 "),DQ=n(TGe,"A",{href:!0});var CBt=s(DQ);AQo=r(CBt,"ElectraForCausalLM"),CBt.forEach(t),LQo=r(TGe," (ELECTRA model)"),TGe.forEach(t),yQo=i(U),Vb=n(U,"LI",{});var MGe=s(Vb);ybe=n(MGe,"STRONG",{});var wBt=s(ybe);xQo=r(wBt,"ernie"),wBt.forEach(t),$Qo=r(MGe," \u2014 "),GQ=n(MGe,"A",{href:!0});var ABt=s(GQ);kQo=r(ABt,"ErnieForCausalLM"),ABt.forEach(t),SQo=r(MGe," (ERNIE model)"),MGe.forEach(t),RQo=i(U),Xb=n(U,"LI",{});var EGe=s(Xb);xbe=n(EGe,"STRONG",{});var LBt=s(xbe);PQo=r(LBt,"gpt2"),LBt.forEach(t),BQo=r(EGe," \u2014 "),OQ=n(EGe,"A",{href:!0});var yBt=s(OQ);IQo=r(yBt,"GPT2LMHeadModel"),yBt.forEach(t),NQo=r(EGe," (OpenAI GPT-2 model)"),EGe.forEach(t),qQo=i(U),zb=n(U,"LI",{});var CGe=s(zb);$be=n(CGe,"STRONG",{});var xBt=s($be);jQo=r(xBt,"gpt_neo"),xBt.forEach(t),DQo=r(CGe," \u2014 "),VQ=n(CGe,"A",{href:!0});var $Bt=s(VQ);GQo=r($Bt,"GPTNeoForCausalLM"),$Bt.forEach(t),OQo=r(CGe," (GPT Neo model)"),CGe.forEach(t),VQo=i(U),Qb=n(U,"LI",{});var wGe=s(Qb);kbe=n(wGe,"STRONG",{});var kBt=s(kbe);XQo=r(kBt,"gpt_neox"),kBt.forEach(t),zQo=r(wGe," \u2014 "),XQ=n(wGe,"A",{href:!0});var SBt=s(XQ);QQo=r(SBt,"GPTNeoXForCausalLM"),SBt.forEach(t),WQo=r(wGe," (GPT NeoX model)"),wGe.forEach(t),UQo=i(U),Wb=n(U,"LI",{});var AGe=s(Wb);Sbe=n(AGe,"STRONG",{});var RBt=s(Sbe);HQo=r(RBt,"gpt_neox_japanese"),RBt.forEach(t),JQo=r(AGe," \u2014 "),zQ=n(AGe,"A",{href:!0});var PBt=s(zQ);YQo=r(PBt,"GPTNeoXJapaneseForCausalLM"),PBt.forEach(t),KQo=r(AGe," (GPT NeoX Japanese model)"),AGe.forEach(t),ZQo=i(U),Ub=n(U,"LI",{});var LGe=s(Ub);Rbe=n(LGe,"STRONG",{});var BBt=s(Rbe);eWo=r(BBt,"gptj"),BBt.forEach(t),oWo=r(LGe," \u2014 "),QQ=n(LGe,"A",{href:!0});var IBt=s(QQ);rWo=r(IBt,"GPTJForCausalLM"),IBt.forEach(t),tWo=r(LGe," (GPT-J model)"),LGe.forEach(t),aWo=i(U),Hb=n(U,"LI",{});var yGe=s(Hb);Pbe=n(yGe,"STRONG",{});var NBt=s(Pbe);nWo=r(NBt,"marian"),NBt.forEach(t),sWo=r(yGe," \u2014 "),WQ=n(yGe,"A",{href:!0});var qBt=s(WQ);lWo=r(qBt,"MarianForCausalLM"),qBt.forEach(t),iWo=r(yGe," (Marian model)"),yGe.forEach(t),dWo=i(U),Jb=n(U,"LI",{});var xGe=s(Jb);Bbe=n(xGe,"STRONG",{});var jBt=s(Bbe);mWo=r(jBt,"mbart"),jBt.forEach(t),cWo=r(xGe," \u2014 "),UQ=n(xGe,"A",{href:!0});var DBt=s(UQ);fWo=r(DBt,"MBartForCausalLM"),DBt.forEach(t),gWo=r(xGe," (mBART model)"),xGe.forEach(t),hWo=i(U),Yb=n(U,"LI",{});var $Ge=s(Yb);Ibe=n($Ge,"STRONG",{});var GBt=s(Ibe);uWo=r(GBt,"megatron-bert"),GBt.forEach(t),pWo=r($Ge," \u2014 "),HQ=n($Ge,"A",{href:!0});var OBt=s(HQ);_Wo=r(OBt,"MegatronBertForCausalLM"),OBt.forEach(t),bWo=r($Ge," (Megatron-BERT model)"),$Ge.forEach(t),vWo=i(U),Kb=n(U,"LI",{});var kGe=s(Kb);Nbe=n(kGe,"STRONG",{});var VBt=s(Nbe);FWo=r(VBt,"mvp"),VBt.forEach(t),TWo=r(kGe," \u2014 "),JQ=n(kGe,"A",{href:!0});var XBt=s(JQ);MWo=r(XBt,"MvpForCausalLM"),XBt.forEach(t),EWo=r(kGe," (MVP model)"),kGe.forEach(t),CWo=i(U),Zb=n(U,"LI",{});var SGe=s(Zb);qbe=n(SGe,"STRONG",{});var zBt=s(qbe);wWo=r(zBt,"openai-gpt"),zBt.forEach(t),AWo=r(SGe," \u2014 "),YQ=n(SGe,"A",{href:!0});var QBt=s(YQ);LWo=r(QBt,"OpenAIGPTLMHeadModel"),QBt.forEach(t),yWo=r(SGe," (OpenAI GPT model)"),SGe.forEach(t),xWo=i(U),ev=n(U,"LI",{});var RGe=s(ev);jbe=n(RGe,"STRONG",{});var WBt=s(jbe);$Wo=r(WBt,"opt"),WBt.forEach(t),kWo=r(RGe," \u2014 "),KQ=n(RGe,"A",{href:!0});var UBt=s(KQ);SWo=r(UBt,"OPTForCausalLM"),UBt.forEach(t),RWo=r(RGe," (OPT model)"),RGe.forEach(t),PWo=i(U),ov=n(U,"LI",{});var PGe=s(ov);Dbe=n(PGe,"STRONG",{});var HBt=s(Dbe);BWo=r(HBt,"pegasus"),HBt.forEach(t),IWo=r(PGe," \u2014 "),ZQ=n(PGe,"A",{href:!0});var JBt=s(ZQ);NWo=r(JBt,"PegasusForCausalLM"),JBt.forEach(t),qWo=r(PGe," (Pegasus model)"),PGe.forEach(t),jWo=i(U),rv=n(U,"LI",{});var BGe=s(rv);Gbe=n(BGe,"STRONG",{});var YBt=s(Gbe);DWo=r(YBt,"plbart"),YBt.forEach(t),GWo=r(BGe," \u2014 "),eW=n(BGe,"A",{href:!0});var KBt=s(eW);OWo=r(KBt,"PLBartForCausalLM"),KBt.forEach(t),VWo=r(BGe," (PLBart model)"),BGe.forEach(t),XWo=i(U),tv=n(U,"LI",{});var IGe=s(tv);Obe=n(IGe,"STRONG",{});var ZBt=s(Obe);zWo=r(ZBt,"prophetnet"),ZBt.forEach(t),QWo=r(IGe," \u2014 "),oW=n(IGe,"A",{href:!0});var eIt=s(oW);WWo=r(eIt,"ProphetNetForCausalLM"),eIt.forEach(t),UWo=r(IGe," (ProphetNet model)"),IGe.forEach(t),HWo=i(U),av=n(U,"LI",{});var NGe=s(av);Vbe=n(NGe,"STRONG",{});var oIt=s(Vbe);JWo=r(oIt,"qdqbert"),oIt.forEach(t),YWo=r(NGe," \u2014 "),rW=n(NGe,"A",{href:!0});var rIt=s(rW);KWo=r(rIt,"QDQBertLMHeadModel"),rIt.forEach(t),ZWo=r(NGe," (QDQBert model)"),NGe.forEach(t),eUo=i(U),nv=n(U,"LI",{});var qGe=s(nv);Xbe=n(qGe,"STRONG",{});var tIt=s(Xbe);oUo=r(tIt,"reformer"),tIt.forEach(t),rUo=r(qGe," \u2014 "),tW=n(qGe,"A",{href:!0});var aIt=s(tW);tUo=r(aIt,"ReformerModelWithLMHead"),aIt.forEach(t),aUo=r(qGe," (Reformer model)"),qGe.forEach(t),nUo=i(U),sv=n(U,"LI",{});var jGe=s(sv);zbe=n(jGe,"STRONG",{});var nIt=s(zbe);sUo=r(nIt,"rembert"),nIt.forEach(t),lUo=r(jGe," \u2014 "),aW=n(jGe,"A",{href:!0});var sIt=s(aW);iUo=r(sIt,"RemBertForCausalLM"),sIt.forEach(t),dUo=r(jGe," (RemBERT model)"),jGe.forEach(t),mUo=i(U),lv=n(U,"LI",{});var DGe=s(lv);Qbe=n(DGe,"STRONG",{});var lIt=s(Qbe);cUo=r(lIt,"roberta"),lIt.forEach(t),fUo=r(DGe," \u2014 "),nW=n(DGe,"A",{href:!0});var iIt=s(nW);gUo=r(iIt,"RobertaForCausalLM"),iIt.forEach(t),hUo=r(DGe," (RoBERTa model)"),DGe.forEach(t),uUo=i(U),iv=n(U,"LI",{});var GGe=s(iv);Wbe=n(GGe,"STRONG",{});var dIt=s(Wbe);pUo=r(dIt,"roformer"),dIt.forEach(t),_Uo=r(GGe," \u2014 "),sW=n(GGe,"A",{href:!0});var mIt=s(sW);bUo=r(mIt,"RoFormerForCausalLM"),mIt.forEach(t),vUo=r(GGe," (RoFormer model)"),GGe.forEach(t),FUo=i(U),dv=n(U,"LI",{});var OGe=s(dv);Ube=n(OGe,"STRONG",{});var cIt=s(Ube);TUo=r(cIt,"speech_to_text_2"),cIt.forEach(t),MUo=r(OGe," \u2014 "),lW=n(OGe,"A",{href:!0});var fIt=s(lW);EUo=r(fIt,"Speech2Text2ForCausalLM"),fIt.forEach(t),CUo=r(OGe," (Speech2Text2 model)"),OGe.forEach(t),wUo=i(U),mv=n(U,"LI",{});var VGe=s(mv);Hbe=n(VGe,"STRONG",{});var gIt=s(Hbe);AUo=r(gIt,"transfo-xl"),gIt.forEach(t),LUo=r(VGe," \u2014 "),iW=n(VGe,"A",{href:!0});var hIt=s(iW);yUo=r(hIt,"TransfoXLLMHeadModel"),hIt.forEach(t),xUo=r(VGe," (Transformer-XL model)"),VGe.forEach(t),$Uo=i(U),cv=n(U,"LI",{});var XGe=s(cv);Jbe=n(XGe,"STRONG",{});var uIt=s(Jbe);kUo=r(uIt,"trocr"),uIt.forEach(t),SUo=r(XGe," \u2014 "),dW=n(XGe,"A",{href:!0});var pIt=s(dW);RUo=r(pIt,"TrOCRForCausalLM"),pIt.forEach(t),PUo=r(XGe," (TrOCR model)"),XGe.forEach(t),BUo=i(U),fv=n(U,"LI",{});var zGe=s(fv);Ybe=n(zGe,"STRONG",{});var _It=s(Ybe);IUo=r(_It,"xglm"),_It.forEach(t),NUo=r(zGe," \u2014 "),mW=n(zGe,"A",{href:!0});var bIt=s(mW);qUo=r(bIt,"XGLMForCausalLM"),bIt.forEach(t),jUo=r(zGe," (XGLM model)"),zGe.forEach(t),DUo=i(U),gv=n(U,"LI",{});var QGe=s(gv);Kbe=n(QGe,"STRONG",{});var vIt=s(Kbe);GUo=r(vIt,"xlm"),vIt.forEach(t),OUo=r(QGe," \u2014 "),cW=n(QGe,"A",{href:!0});var FIt=s(cW);VUo=r(FIt,"XLMWithLMHeadModel"),FIt.forEach(t),XUo=r(QGe," (XLM model)"),QGe.forEach(t),zUo=i(U),hv=n(U,"LI",{});var WGe=s(hv);Zbe=n(WGe,"STRONG",{});var TIt=s(Zbe);QUo=r(TIt,"xlm-prophetnet"),TIt.forEach(t),WUo=r(WGe," \u2014 "),fW=n(WGe,"A",{href:!0});var MIt=s(fW);UUo=r(MIt,"XLMProphetNetForCausalLM"),MIt.forEach(t),HUo=r(WGe," (XLM-ProphetNet model)"),WGe.forEach(t),JUo=i(U),uv=n(U,"LI",{});var UGe=s(uv);eve=n(UGe,"STRONG",{});var EIt=s(eve);YUo=r(EIt,"xlm-roberta"),EIt.forEach(t),KUo=r(UGe," \u2014 "),gW=n(UGe,"A",{href:!0});var CIt=s(gW);ZUo=r(CIt,"XLMRobertaForCausalLM"),CIt.forEach(t),eHo=r(UGe," (XLM-RoBERTa model)"),UGe.forEach(t),oHo=i(U),pv=n(U,"LI",{});var HGe=s(pv);ove=n(HGe,"STRONG",{});var wIt=s(ove);rHo=r(wIt,"xlm-roberta-xl"),wIt.forEach(t),tHo=r(HGe," \u2014 "),hW=n(HGe,"A",{href:!0});var AIt=s(hW);aHo=r(AIt,"XLMRobertaXLForCausalLM"),AIt.forEach(t),nHo=r(HGe," (XLM-RoBERTa-XL model)"),HGe.forEach(t),sHo=i(U),_v=n(U,"LI",{});var JGe=s(_v);rve=n(JGe,"STRONG",{});var LIt=s(rve);lHo=r(LIt,"xlnet"),LIt.forEach(t),iHo=r(JGe," \u2014 "),uW=n(JGe,"A",{href:!0});var yIt=s(uW);dHo=r(yIt,"XLNetLMHeadModel"),yIt.forEach(t),mHo=r(JGe," (XLNet model)"),JGe.forEach(t),U.forEach(t),cHo=i(Ma),bv=n(Ma,"P",{});var YGe=s(bv);fHo=r(YGe,"The model is set in evaluation mode by default using "),tve=n(YGe,"CODE",{});var xIt=s(tve);gHo=r(xIt,"model.eval()"),xIt.forEach(t),hHo=r(YGe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ave=n(YGe,"CODE",{});var $It=s(ave);uHo=r($It,"model.train()"),$It.forEach(t),YGe.forEach(t),pHo=i(Ma),T(vv.$$.fragment,Ma),Ma.forEach(t),yl.forEach(t),Peo=i(c),Ad=n(c,"H2",{class:!0});var Uro=s(Ad);Fv=n(Uro,"A",{id:!0,class:!0,href:!0});var kIt=s(Fv);nve=n(kIt,"SPAN",{});var SIt=s(nve);T(Hx.$$.fragment,SIt),SIt.forEach(t),kIt.forEach(t),_Ho=i(Uro),sve=n(Uro,"SPAN",{});var RIt=s(sve);bHo=r(RIt,"AutoModelForMaskedLM"),RIt.forEach(t),Uro.forEach(t),Beo=i(c),No=n(c,"DIV",{class:!0});var xl=s(No);T(Jx.$$.fragment,xl),vHo=i(xl),Ld=n(xl,"P",{});var bie=s(Ld);FHo=r(bie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),pW=n(bie,"A",{href:!0});var PIt=s(pW);THo=r(PIt,"from_pretrained()"),PIt.forEach(t),MHo=r(bie," class method or the "),_W=n(bie,"A",{href:!0});var BIt=s(_W);EHo=r(BIt,"from_config()"),BIt.forEach(t),CHo=r(bie,` class
method.`),bie.forEach(t),wHo=i(xl),Yx=n(xl,"P",{});var Hro=s(Yx);AHo=r(Hro,"This class cannot be instantiated directly using "),lve=n(Hro,"CODE",{});var IIt=s(lve);LHo=r(IIt,"__init__()"),IIt.forEach(t),yHo=r(Hro," (throws an error)."),Hro.forEach(t),xHo=i(xl),Ft=n(xl,"DIV",{class:!0});var i8=s(Ft);T(Kx.$$.fragment,i8),$Ho=i(i8),ive=n(i8,"P",{});var NIt=s(ive);kHo=r(NIt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),NIt.forEach(t),SHo=i(i8),yd=n(i8,"P",{});var vie=s(yd);RHo=r(vie,`Note:
Loading a model from its configuration file does `),dve=n(vie,"STRONG",{});var qIt=s(dve);PHo=r(qIt,"not"),qIt.forEach(t),BHo=r(vie,` load the model weights. It only affects the
model\u2019s configuration. Use `),bW=n(vie,"A",{href:!0});var jIt=s(bW);IHo=r(jIt,"from_pretrained()"),jIt.forEach(t),NHo=r(vie," to load the model weights."),vie.forEach(t),qHo=i(i8),T(Tv.$$.fragment,i8),i8.forEach(t),jHo=i(xl),ro=n(xl,"DIV",{class:!0});var Ea=s(ro);T(Zx.$$.fragment,Ea),DHo=i(Ea),mve=n(Ea,"P",{});var DIt=s(mve);GHo=r(DIt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),DIt.forEach(t),OHo=i(Ea),Za=n(Ea,"P",{});var d8=s(Za);VHo=r(d8,"The model class to instantiate is selected based on the "),cve=n(d8,"CODE",{});var GIt=s(cve);XHo=r(GIt,"model_type"),GIt.forEach(t),zHo=r(d8,` property of the config object (either
passed as an argument or loaded from `),fve=n(d8,"CODE",{});var OIt=s(fve);QHo=r(OIt,"pretrained_model_name_or_path"),OIt.forEach(t),WHo=r(d8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gve=n(d8,"CODE",{});var VIt=s(gve);UHo=r(VIt,"pretrained_model_name_or_path"),VIt.forEach(t),HHo=r(d8,":"),d8.forEach(t),JHo=i(Ea),J=n(Ea,"UL",{});var K=s(J);Mv=n(K,"LI",{});var KGe=s(Mv);hve=n(KGe,"STRONG",{});var XIt=s(hve);YHo=r(XIt,"albert"),XIt.forEach(t),KHo=r(KGe," \u2014 "),vW=n(KGe,"A",{href:!0});var zIt=s(vW);ZHo=r(zIt,"AlbertForMaskedLM"),zIt.forEach(t),eJo=r(KGe," (ALBERT model)"),KGe.forEach(t),oJo=i(K),Ev=n(K,"LI",{});var ZGe=s(Ev);uve=n(ZGe,"STRONG",{});var QIt=s(uve);rJo=r(QIt,"bart"),QIt.forEach(t),tJo=r(ZGe," \u2014 "),FW=n(ZGe,"A",{href:!0});var WIt=s(FW);aJo=r(WIt,"BartForConditionalGeneration"),WIt.forEach(t),nJo=r(ZGe," (BART model)"),ZGe.forEach(t),sJo=i(K),Cv=n(K,"LI",{});var eOe=s(Cv);pve=n(eOe,"STRONG",{});var UIt=s(pve);lJo=r(UIt,"bert"),UIt.forEach(t),iJo=r(eOe," \u2014 "),TW=n(eOe,"A",{href:!0});var HIt=s(TW);dJo=r(HIt,"BertForMaskedLM"),HIt.forEach(t),mJo=r(eOe," (BERT model)"),eOe.forEach(t),cJo=i(K),wv=n(K,"LI",{});var oOe=s(wv);_ve=n(oOe,"STRONG",{});var JIt=s(_ve);fJo=r(JIt,"big_bird"),JIt.forEach(t),gJo=r(oOe," \u2014 "),MW=n(oOe,"A",{href:!0});var YIt=s(MW);hJo=r(YIt,"BigBirdForMaskedLM"),YIt.forEach(t),uJo=r(oOe," (BigBird model)"),oOe.forEach(t),pJo=i(K),Av=n(K,"LI",{});var rOe=s(Av);bve=n(rOe,"STRONG",{});var KIt=s(bve);_Jo=r(KIt,"camembert"),KIt.forEach(t),bJo=r(rOe," \u2014 "),EW=n(rOe,"A",{href:!0});var ZIt=s(EW);vJo=r(ZIt,"CamembertForMaskedLM"),ZIt.forEach(t),FJo=r(rOe," (CamemBERT model)"),rOe.forEach(t),TJo=i(K),Lv=n(K,"LI",{});var tOe=s(Lv);vve=n(tOe,"STRONG",{});var eNt=s(vve);MJo=r(eNt,"convbert"),eNt.forEach(t),EJo=r(tOe," \u2014 "),CW=n(tOe,"A",{href:!0});var oNt=s(CW);CJo=r(oNt,"ConvBertForMaskedLM"),oNt.forEach(t),wJo=r(tOe," (ConvBERT model)"),tOe.forEach(t),AJo=i(K),yv=n(K,"LI",{});var aOe=s(yv);Fve=n(aOe,"STRONG",{});var rNt=s(Fve);LJo=r(rNt,"data2vec-text"),rNt.forEach(t),yJo=r(aOe," \u2014 "),wW=n(aOe,"A",{href:!0});var tNt=s(wW);xJo=r(tNt,"Data2VecTextForMaskedLM"),tNt.forEach(t),$Jo=r(aOe," (Data2VecText model)"),aOe.forEach(t),kJo=i(K),xv=n(K,"LI",{});var nOe=s(xv);Tve=n(nOe,"STRONG",{});var aNt=s(Tve);SJo=r(aNt,"deberta"),aNt.forEach(t),RJo=r(nOe," \u2014 "),AW=n(nOe,"A",{href:!0});var nNt=s(AW);PJo=r(nNt,"DebertaForMaskedLM"),nNt.forEach(t),BJo=r(nOe," (DeBERTa model)"),nOe.forEach(t),IJo=i(K),$v=n(K,"LI",{});var sOe=s($v);Mve=n(sOe,"STRONG",{});var sNt=s(Mve);NJo=r(sNt,"deberta-v2"),sNt.forEach(t),qJo=r(sOe," \u2014 "),LW=n(sOe,"A",{href:!0});var lNt=s(LW);jJo=r(lNt,"DebertaV2ForMaskedLM"),lNt.forEach(t),DJo=r(sOe," (DeBERTa-v2 model)"),sOe.forEach(t),GJo=i(K),kv=n(K,"LI",{});var lOe=s(kv);Eve=n(lOe,"STRONG",{});var iNt=s(Eve);OJo=r(iNt,"distilbert"),iNt.forEach(t),VJo=r(lOe," \u2014 "),yW=n(lOe,"A",{href:!0});var dNt=s(yW);XJo=r(dNt,"DistilBertForMaskedLM"),dNt.forEach(t),zJo=r(lOe," (DistilBERT model)"),lOe.forEach(t),QJo=i(K),Sv=n(K,"LI",{});var iOe=s(Sv);Cve=n(iOe,"STRONG",{});var mNt=s(Cve);WJo=r(mNt,"electra"),mNt.forEach(t),UJo=r(iOe," \u2014 "),xW=n(iOe,"A",{href:!0});var cNt=s(xW);HJo=r(cNt,"ElectraForMaskedLM"),cNt.forEach(t),JJo=r(iOe," (ELECTRA model)"),iOe.forEach(t),YJo=i(K),Rv=n(K,"LI",{});var dOe=s(Rv);wve=n(dOe,"STRONG",{});var fNt=s(wve);KJo=r(fNt,"ernie"),fNt.forEach(t),ZJo=r(dOe," \u2014 "),$W=n(dOe,"A",{href:!0});var gNt=s($W);eYo=r(gNt,"ErnieForMaskedLM"),gNt.forEach(t),oYo=r(dOe," (ERNIE model)"),dOe.forEach(t),rYo=i(K),Pv=n(K,"LI",{});var mOe=s(Pv);Ave=n(mOe,"STRONG",{});var hNt=s(Ave);tYo=r(hNt,"flaubert"),hNt.forEach(t),aYo=r(mOe," \u2014 "),kW=n(mOe,"A",{href:!0});var uNt=s(kW);nYo=r(uNt,"FlaubertWithLMHeadModel"),uNt.forEach(t),sYo=r(mOe," (FlauBERT model)"),mOe.forEach(t),lYo=i(K),Bv=n(K,"LI",{});var cOe=s(Bv);Lve=n(cOe,"STRONG",{});var pNt=s(Lve);iYo=r(pNt,"fnet"),pNt.forEach(t),dYo=r(cOe," \u2014 "),SW=n(cOe,"A",{href:!0});var _Nt=s(SW);mYo=r(_Nt,"FNetForMaskedLM"),_Nt.forEach(t),cYo=r(cOe," (FNet model)"),cOe.forEach(t),fYo=i(K),Iv=n(K,"LI",{});var fOe=s(Iv);yve=n(fOe,"STRONG",{});var bNt=s(yve);gYo=r(bNt,"funnel"),bNt.forEach(t),hYo=r(fOe," \u2014 "),RW=n(fOe,"A",{href:!0});var vNt=s(RW);uYo=r(vNt,"FunnelForMaskedLM"),vNt.forEach(t),pYo=r(fOe," (Funnel Transformer model)"),fOe.forEach(t),_Yo=i(K),Nv=n(K,"LI",{});var gOe=s(Nv);xve=n(gOe,"STRONG",{});var FNt=s(xve);bYo=r(FNt,"ibert"),FNt.forEach(t),vYo=r(gOe," \u2014 "),PW=n(gOe,"A",{href:!0});var TNt=s(PW);FYo=r(TNt,"IBertForMaskedLM"),TNt.forEach(t),TYo=r(gOe," (I-BERT model)"),gOe.forEach(t),MYo=i(K),qv=n(K,"LI",{});var hOe=s(qv);$ve=n(hOe,"STRONG",{});var MNt=s($ve);EYo=r(MNt,"layoutlm"),MNt.forEach(t),CYo=r(hOe," \u2014 "),BW=n(hOe,"A",{href:!0});var ENt=s(BW);wYo=r(ENt,"LayoutLMForMaskedLM"),ENt.forEach(t),AYo=r(hOe," (LayoutLM model)"),hOe.forEach(t),LYo=i(K),jv=n(K,"LI",{});var uOe=s(jv);kve=n(uOe,"STRONG",{});var CNt=s(kve);yYo=r(CNt,"longformer"),CNt.forEach(t),xYo=r(uOe," \u2014 "),IW=n(uOe,"A",{href:!0});var wNt=s(IW);$Yo=r(wNt,"LongformerForMaskedLM"),wNt.forEach(t),kYo=r(uOe," (Longformer model)"),uOe.forEach(t),SYo=i(K),Dv=n(K,"LI",{});var pOe=s(Dv);Sve=n(pOe,"STRONG",{});var ANt=s(Sve);RYo=r(ANt,"luke"),ANt.forEach(t),PYo=r(pOe," \u2014 "),NW=n(pOe,"A",{href:!0});var LNt=s(NW);BYo=r(LNt,"LukeForMaskedLM"),LNt.forEach(t),IYo=r(pOe," (LUKE model)"),pOe.forEach(t),NYo=i(K),Gv=n(K,"LI",{});var _Oe=s(Gv);Rve=n(_Oe,"STRONG",{});var yNt=s(Rve);qYo=r(yNt,"mbart"),yNt.forEach(t),jYo=r(_Oe," \u2014 "),qW=n(_Oe,"A",{href:!0});var xNt=s(qW);DYo=r(xNt,"MBartForConditionalGeneration"),xNt.forEach(t),GYo=r(_Oe," (mBART model)"),_Oe.forEach(t),OYo=i(K),Ov=n(K,"LI",{});var bOe=s(Ov);Pve=n(bOe,"STRONG",{});var $Nt=s(Pve);VYo=r($Nt,"megatron-bert"),$Nt.forEach(t),XYo=r(bOe," \u2014 "),jW=n(bOe,"A",{href:!0});var kNt=s(jW);zYo=r(kNt,"MegatronBertForMaskedLM"),kNt.forEach(t),QYo=r(bOe," (Megatron-BERT model)"),bOe.forEach(t),WYo=i(K),Vv=n(K,"LI",{});var vOe=s(Vv);Bve=n(vOe,"STRONG",{});var SNt=s(Bve);UYo=r(SNt,"mobilebert"),SNt.forEach(t),HYo=r(vOe," \u2014 "),DW=n(vOe,"A",{href:!0});var RNt=s(DW);JYo=r(RNt,"MobileBertForMaskedLM"),RNt.forEach(t),YYo=r(vOe," (MobileBERT model)"),vOe.forEach(t),KYo=i(K),Xv=n(K,"LI",{});var FOe=s(Xv);Ive=n(FOe,"STRONG",{});var PNt=s(Ive);ZYo=r(PNt,"mpnet"),PNt.forEach(t),eKo=r(FOe," \u2014 "),GW=n(FOe,"A",{href:!0});var BNt=s(GW);oKo=r(BNt,"MPNetForMaskedLM"),BNt.forEach(t),rKo=r(FOe," (MPNet model)"),FOe.forEach(t),tKo=i(K),zv=n(K,"LI",{});var TOe=s(zv);Nve=n(TOe,"STRONG",{});var INt=s(Nve);aKo=r(INt,"mvp"),INt.forEach(t),nKo=r(TOe," \u2014 "),OW=n(TOe,"A",{href:!0});var NNt=s(OW);sKo=r(NNt,"MvpForConditionalGeneration"),NNt.forEach(t),lKo=r(TOe," (MVP model)"),TOe.forEach(t),iKo=i(K),Qv=n(K,"LI",{});var MOe=s(Qv);qve=n(MOe,"STRONG",{});var qNt=s(qve);dKo=r(qNt,"nezha"),qNt.forEach(t),mKo=r(MOe," \u2014 "),VW=n(MOe,"A",{href:!0});var jNt=s(VW);cKo=r(jNt,"NezhaForMaskedLM"),jNt.forEach(t),fKo=r(MOe," (Nezha model)"),MOe.forEach(t),gKo=i(K),Wv=n(K,"LI",{});var EOe=s(Wv);jve=n(EOe,"STRONG",{});var DNt=s(jve);hKo=r(DNt,"nystromformer"),DNt.forEach(t),uKo=r(EOe," \u2014 "),XW=n(EOe,"A",{href:!0});var GNt=s(XW);pKo=r(GNt,"NystromformerForMaskedLM"),GNt.forEach(t),_Ko=r(EOe," (Nystr\xF6mformer model)"),EOe.forEach(t),bKo=i(K),Uv=n(K,"LI",{});var COe=s(Uv);Dve=n(COe,"STRONG",{});var ONt=s(Dve);vKo=r(ONt,"perceiver"),ONt.forEach(t),FKo=r(COe," \u2014 "),zW=n(COe,"A",{href:!0});var VNt=s(zW);TKo=r(VNt,"PerceiverForMaskedLM"),VNt.forEach(t),MKo=r(COe," (Perceiver model)"),COe.forEach(t),EKo=i(K),Hv=n(K,"LI",{});var wOe=s(Hv);Gve=n(wOe,"STRONG",{});var XNt=s(Gve);CKo=r(XNt,"qdqbert"),XNt.forEach(t),wKo=r(wOe," \u2014 "),QW=n(wOe,"A",{href:!0});var zNt=s(QW);AKo=r(zNt,"QDQBertForMaskedLM"),zNt.forEach(t),LKo=r(wOe," (QDQBert model)"),wOe.forEach(t),yKo=i(K),Jv=n(K,"LI",{});var AOe=s(Jv);Ove=n(AOe,"STRONG",{});var QNt=s(Ove);xKo=r(QNt,"reformer"),QNt.forEach(t),$Ko=r(AOe," \u2014 "),WW=n(AOe,"A",{href:!0});var WNt=s(WW);kKo=r(WNt,"ReformerForMaskedLM"),WNt.forEach(t),SKo=r(AOe," (Reformer model)"),AOe.forEach(t),RKo=i(K),Yv=n(K,"LI",{});var LOe=s(Yv);Vve=n(LOe,"STRONG",{});var UNt=s(Vve);PKo=r(UNt,"rembert"),UNt.forEach(t),BKo=r(LOe," \u2014 "),UW=n(LOe,"A",{href:!0});var HNt=s(UW);IKo=r(HNt,"RemBertForMaskedLM"),HNt.forEach(t),NKo=r(LOe," (RemBERT model)"),LOe.forEach(t),qKo=i(K),Kv=n(K,"LI",{});var yOe=s(Kv);Xve=n(yOe,"STRONG",{});var JNt=s(Xve);jKo=r(JNt,"roberta"),JNt.forEach(t),DKo=r(yOe," \u2014 "),HW=n(yOe,"A",{href:!0});var YNt=s(HW);GKo=r(YNt,"RobertaForMaskedLM"),YNt.forEach(t),OKo=r(yOe," (RoBERTa model)"),yOe.forEach(t),VKo=i(K),Zv=n(K,"LI",{});var xOe=s(Zv);zve=n(xOe,"STRONG",{});var KNt=s(zve);XKo=r(KNt,"roformer"),KNt.forEach(t),zKo=r(xOe," \u2014 "),JW=n(xOe,"A",{href:!0});var ZNt=s(JW);QKo=r(ZNt,"RoFormerForMaskedLM"),ZNt.forEach(t),WKo=r(xOe," (RoFormer model)"),xOe.forEach(t),UKo=i(K),eF=n(K,"LI",{});var $Oe=s(eF);Qve=n($Oe,"STRONG",{});var eqt=s(Qve);HKo=r(eqt,"squeezebert"),eqt.forEach(t),JKo=r($Oe," \u2014 "),YW=n($Oe,"A",{href:!0});var oqt=s(YW);YKo=r(oqt,"SqueezeBertForMaskedLM"),oqt.forEach(t),KKo=r($Oe," (SqueezeBERT model)"),$Oe.forEach(t),ZKo=i(K),oF=n(K,"LI",{});var kOe=s(oF);Wve=n(kOe,"STRONG",{});var rqt=s(Wve);eZo=r(rqt,"tapas"),rqt.forEach(t),oZo=r(kOe," \u2014 "),KW=n(kOe,"A",{href:!0});var tqt=s(KW);rZo=r(tqt,"TapasForMaskedLM"),tqt.forEach(t),tZo=r(kOe," (TAPAS model)"),kOe.forEach(t),aZo=i(K),rF=n(K,"LI",{});var SOe=s(rF);Uve=n(SOe,"STRONG",{});var aqt=s(Uve);nZo=r(aqt,"wav2vec2"),aqt.forEach(t),sZo=r(SOe," \u2014 "),Hve=n(SOe,"CODE",{});var nqt=s(Hve);lZo=r(nqt,"Wav2Vec2ForMaskedLM"),nqt.forEach(t),iZo=r(SOe," (Wav2Vec2 model)"),SOe.forEach(t),dZo=i(K),tF=n(K,"LI",{});var ROe=s(tF);Jve=n(ROe,"STRONG",{});var sqt=s(Jve);mZo=r(sqt,"xlm"),sqt.forEach(t),cZo=r(ROe," \u2014 "),ZW=n(ROe,"A",{href:!0});var lqt=s(ZW);fZo=r(lqt,"XLMWithLMHeadModel"),lqt.forEach(t),gZo=r(ROe," (XLM model)"),ROe.forEach(t),hZo=i(K),aF=n(K,"LI",{});var POe=s(aF);Yve=n(POe,"STRONG",{});var iqt=s(Yve);uZo=r(iqt,"xlm-roberta"),iqt.forEach(t),pZo=r(POe," \u2014 "),eU=n(POe,"A",{href:!0});var dqt=s(eU);_Zo=r(dqt,"XLMRobertaForMaskedLM"),dqt.forEach(t),bZo=r(POe," (XLM-RoBERTa model)"),POe.forEach(t),vZo=i(K),nF=n(K,"LI",{});var BOe=s(nF);Kve=n(BOe,"STRONG",{});var mqt=s(Kve);FZo=r(mqt,"xlm-roberta-xl"),mqt.forEach(t),TZo=r(BOe," \u2014 "),oU=n(BOe,"A",{href:!0});var cqt=s(oU);MZo=r(cqt,"XLMRobertaXLForMaskedLM"),cqt.forEach(t),EZo=r(BOe," (XLM-RoBERTa-XL model)"),BOe.forEach(t),CZo=i(K),sF=n(K,"LI",{});var IOe=s(sF);Zve=n(IOe,"STRONG",{});var fqt=s(Zve);wZo=r(fqt,"yoso"),fqt.forEach(t),AZo=r(IOe," \u2014 "),rU=n(IOe,"A",{href:!0});var gqt=s(rU);LZo=r(gqt,"YosoForMaskedLM"),gqt.forEach(t),yZo=r(IOe," (YOSO model)"),IOe.forEach(t),K.forEach(t),xZo=i(Ea),lF=n(Ea,"P",{});var NOe=s(lF);$Zo=r(NOe,"The model is set in evaluation mode by default using "),eFe=n(NOe,"CODE",{});var hqt=s(eFe);kZo=r(hqt,"model.eval()"),hqt.forEach(t),SZo=r(NOe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),oFe=n(NOe,"CODE",{});var uqt=s(oFe);RZo=r(uqt,"model.train()"),uqt.forEach(t),NOe.forEach(t),PZo=i(Ea),T(iF.$$.fragment,Ea),Ea.forEach(t),xl.forEach(t),Ieo=i(c),xd=n(c,"H2",{class:!0});var Jro=s(xd);dF=n(Jro,"A",{id:!0,class:!0,href:!0});var pqt=s(dF);rFe=n(pqt,"SPAN",{});var _qt=s(rFe);T(e$.$$.fragment,_qt),_qt.forEach(t),pqt.forEach(t),BZo=i(Jro),tFe=n(Jro,"SPAN",{});var bqt=s(tFe);IZo=r(bqt,"AutoModelForSeq2SeqLM"),bqt.forEach(t),Jro.forEach(t),Neo=i(c),qo=n(c,"DIV",{class:!0});var $l=s(qo);T(o$.$$.fragment,$l),NZo=i($l),$d=n($l,"P",{});var Fie=s($d);qZo=r(Fie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),tU=n(Fie,"A",{href:!0});var vqt=s(tU);jZo=r(vqt,"from_pretrained()"),vqt.forEach(t),DZo=r(Fie," class method or the "),aU=n(Fie,"A",{href:!0});var Fqt=s(aU);GZo=r(Fqt,"from_config()"),Fqt.forEach(t),OZo=r(Fie,` class
method.`),Fie.forEach(t),VZo=i($l),r$=n($l,"P",{});var Yro=s(r$);XZo=r(Yro,"This class cannot be instantiated directly using "),aFe=n(Yro,"CODE",{});var Tqt=s(aFe);zZo=r(Tqt,"__init__()"),Tqt.forEach(t),QZo=r(Yro," (throws an error)."),Yro.forEach(t),WZo=i($l),Tt=n($l,"DIV",{class:!0});var m8=s(Tt);T(t$.$$.fragment,m8),UZo=i(m8),nFe=n(m8,"P",{});var Mqt=s(nFe);HZo=r(Mqt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Mqt.forEach(t),JZo=i(m8),kd=n(m8,"P",{});var Tie=s(kd);YZo=r(Tie,`Note:
Loading a model from its configuration file does `),sFe=n(Tie,"STRONG",{});var Eqt=s(sFe);KZo=r(Eqt,"not"),Eqt.forEach(t),ZZo=r(Tie,` load the model weights. It only affects the
model\u2019s configuration. Use `),nU=n(Tie,"A",{href:!0});var Cqt=s(nU);eer=r(Cqt,"from_pretrained()"),Cqt.forEach(t),oer=r(Tie," to load the model weights."),Tie.forEach(t),rer=i(m8),T(mF.$$.fragment,m8),m8.forEach(t),ter=i($l),to=n($l,"DIV",{class:!0});var Ca=s(to);T(a$.$$.fragment,Ca),aer=i(Ca),lFe=n(Ca,"P",{});var wqt=s(lFe);ner=r(wqt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),wqt.forEach(t),ser=i(Ca),en=n(Ca,"P",{});var c8=s(en);ler=r(c8,"The model class to instantiate is selected based on the "),iFe=n(c8,"CODE",{});var Aqt=s(iFe);ier=r(Aqt,"model_type"),Aqt.forEach(t),der=r(c8,` property of the config object (either
passed as an argument or loaded from `),dFe=n(c8,"CODE",{});var Lqt=s(dFe);mer=r(Lqt,"pretrained_model_name_or_path"),Lqt.forEach(t),cer=r(c8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mFe=n(c8,"CODE",{});var yqt=s(mFe);fer=r(yqt,"pretrained_model_name_or_path"),yqt.forEach(t),ger=r(c8,":"),c8.forEach(t),her=i(Ca),fe=n(Ca,"UL",{});var pe=s(fe);cF=n(pe,"LI",{});var qOe=s(cF);cFe=n(qOe,"STRONG",{});var xqt=s(cFe);uer=r(xqt,"bart"),xqt.forEach(t),per=r(qOe," \u2014 "),sU=n(qOe,"A",{href:!0});var $qt=s(sU);_er=r($qt,"BartForConditionalGeneration"),$qt.forEach(t),ber=r(qOe," (BART model)"),qOe.forEach(t),ver=i(pe),fF=n(pe,"LI",{});var jOe=s(fF);fFe=n(jOe,"STRONG",{});var kqt=s(fFe);Fer=r(kqt,"bigbird_pegasus"),kqt.forEach(t),Ter=r(jOe," \u2014 "),lU=n(jOe,"A",{href:!0});var Sqt=s(lU);Mer=r(Sqt,"BigBirdPegasusForConditionalGeneration"),Sqt.forEach(t),Eer=r(jOe," (BigBird-Pegasus model)"),jOe.forEach(t),Cer=i(pe),gF=n(pe,"LI",{});var DOe=s(gF);gFe=n(DOe,"STRONG",{});var Rqt=s(gFe);wer=r(Rqt,"blenderbot"),Rqt.forEach(t),Aer=r(DOe," \u2014 "),iU=n(DOe,"A",{href:!0});var Pqt=s(iU);Ler=r(Pqt,"BlenderbotForConditionalGeneration"),Pqt.forEach(t),yer=r(DOe," (Blenderbot model)"),DOe.forEach(t),xer=i(pe),hF=n(pe,"LI",{});var GOe=s(hF);hFe=n(GOe,"STRONG",{});var Bqt=s(hFe);$er=r(Bqt,"blenderbot-small"),Bqt.forEach(t),ker=r(GOe," \u2014 "),dU=n(GOe,"A",{href:!0});var Iqt=s(dU);Ser=r(Iqt,"BlenderbotSmallForConditionalGeneration"),Iqt.forEach(t),Rer=r(GOe," (BlenderbotSmall model)"),GOe.forEach(t),Per=i(pe),uF=n(pe,"LI",{});var OOe=s(uF);uFe=n(OOe,"STRONG",{});var Nqt=s(uFe);Ber=r(Nqt,"encoder-decoder"),Nqt.forEach(t),Ier=r(OOe," \u2014 "),mU=n(OOe,"A",{href:!0});var qqt=s(mU);Ner=r(qqt,"EncoderDecoderModel"),qqt.forEach(t),qer=r(OOe," (Encoder decoder model)"),OOe.forEach(t),jer=i(pe),pF=n(pe,"LI",{});var VOe=s(pF);pFe=n(VOe,"STRONG",{});var jqt=s(pFe);Der=r(jqt,"fsmt"),jqt.forEach(t),Ger=r(VOe," \u2014 "),cU=n(VOe,"A",{href:!0});var Dqt=s(cU);Oer=r(Dqt,"FSMTForConditionalGeneration"),Dqt.forEach(t),Ver=r(VOe," (FairSeq Machine-Translation model)"),VOe.forEach(t),Xer=i(pe),_F=n(pe,"LI",{});var XOe=s(_F);_Fe=n(XOe,"STRONG",{});var Gqt=s(_Fe);zer=r(Gqt,"led"),Gqt.forEach(t),Qer=r(XOe," \u2014 "),fU=n(XOe,"A",{href:!0});var Oqt=s(fU);Wer=r(Oqt,"LEDForConditionalGeneration"),Oqt.forEach(t),Uer=r(XOe," (LED model)"),XOe.forEach(t),Her=i(pe),bF=n(pe,"LI",{});var zOe=s(bF);bFe=n(zOe,"STRONG",{});var Vqt=s(bFe);Jer=r(Vqt,"longt5"),Vqt.forEach(t),Yer=r(zOe," \u2014 "),gU=n(zOe,"A",{href:!0});var Xqt=s(gU);Ker=r(Xqt,"LongT5ForConditionalGeneration"),Xqt.forEach(t),Zer=r(zOe," (LongT5 model)"),zOe.forEach(t),eor=i(pe),vF=n(pe,"LI",{});var QOe=s(vF);vFe=n(QOe,"STRONG",{});var zqt=s(vFe);oor=r(zqt,"m2m_100"),zqt.forEach(t),ror=r(QOe," \u2014 "),hU=n(QOe,"A",{href:!0});var Qqt=s(hU);tor=r(Qqt,"M2M100ForConditionalGeneration"),Qqt.forEach(t),aor=r(QOe," (M2M100 model)"),QOe.forEach(t),nor=i(pe),FF=n(pe,"LI",{});var WOe=s(FF);FFe=n(WOe,"STRONG",{});var Wqt=s(FFe);sor=r(Wqt,"marian"),Wqt.forEach(t),lor=r(WOe," \u2014 "),uU=n(WOe,"A",{href:!0});var Uqt=s(uU);ior=r(Uqt,"MarianMTModel"),Uqt.forEach(t),dor=r(WOe," (Marian model)"),WOe.forEach(t),mor=i(pe),TF=n(pe,"LI",{});var UOe=s(TF);TFe=n(UOe,"STRONG",{});var Hqt=s(TFe);cor=r(Hqt,"mbart"),Hqt.forEach(t),gor=r(UOe," \u2014 "),pU=n(UOe,"A",{href:!0});var Jqt=s(pU);hor=r(Jqt,"MBartForConditionalGeneration"),Jqt.forEach(t),uor=r(UOe," (mBART model)"),UOe.forEach(t),por=i(pe),MF=n(pe,"LI",{});var HOe=s(MF);MFe=n(HOe,"STRONG",{});var Yqt=s(MFe);_or=r(Yqt,"mt5"),Yqt.forEach(t),bor=r(HOe," \u2014 "),_U=n(HOe,"A",{href:!0});var Kqt=s(_U);vor=r(Kqt,"MT5ForConditionalGeneration"),Kqt.forEach(t),For=r(HOe," (MT5 model)"),HOe.forEach(t),Tor=i(pe),EF=n(pe,"LI",{});var JOe=s(EF);EFe=n(JOe,"STRONG",{});var Zqt=s(EFe);Mor=r(Zqt,"mvp"),Zqt.forEach(t),Eor=r(JOe," \u2014 "),bU=n(JOe,"A",{href:!0});var ejt=s(bU);Cor=r(ejt,"MvpForConditionalGeneration"),ejt.forEach(t),wor=r(JOe," (MVP model)"),JOe.forEach(t),Aor=i(pe),CF=n(pe,"LI",{});var YOe=s(CF);CFe=n(YOe,"STRONG",{});var ojt=s(CFe);Lor=r(ojt,"nllb"),ojt.forEach(t),yor=r(YOe," \u2014 "),vU=n(YOe,"A",{href:!0});var rjt=s(vU);xor=r(rjt,"M2M100ForConditionalGeneration"),rjt.forEach(t),$or=r(YOe," (NLLB model)"),YOe.forEach(t),kor=i(pe),wF=n(pe,"LI",{});var KOe=s(wF);wFe=n(KOe,"STRONG",{});var tjt=s(wFe);Sor=r(tjt,"pegasus"),tjt.forEach(t),Ror=r(KOe," \u2014 "),FU=n(KOe,"A",{href:!0});var ajt=s(FU);Por=r(ajt,"PegasusForConditionalGeneration"),ajt.forEach(t),Bor=r(KOe," (Pegasus model)"),KOe.forEach(t),Ior=i(pe),AF=n(pe,"LI",{});var ZOe=s(AF);AFe=n(ZOe,"STRONG",{});var njt=s(AFe);Nor=r(njt,"pegasus_x"),njt.forEach(t),qor=r(ZOe," \u2014 "),TU=n(ZOe,"A",{href:!0});var sjt=s(TU);jor=r(sjt,"PegasusXForConditionalGeneration"),sjt.forEach(t),Dor=r(ZOe," (PEGASUS-X model)"),ZOe.forEach(t),Gor=i(pe),LF=n(pe,"LI",{});var eVe=s(LF);LFe=n(eVe,"STRONG",{});var ljt=s(LFe);Oor=r(ljt,"plbart"),ljt.forEach(t),Vor=r(eVe," \u2014 "),MU=n(eVe,"A",{href:!0});var ijt=s(MU);Xor=r(ijt,"PLBartForConditionalGeneration"),ijt.forEach(t),zor=r(eVe," (PLBart model)"),eVe.forEach(t),Qor=i(pe),yF=n(pe,"LI",{});var oVe=s(yF);yFe=n(oVe,"STRONG",{});var djt=s(yFe);Wor=r(djt,"prophetnet"),djt.forEach(t),Uor=r(oVe," \u2014 "),EU=n(oVe,"A",{href:!0});var mjt=s(EU);Hor=r(mjt,"ProphetNetForConditionalGeneration"),mjt.forEach(t),Jor=r(oVe," (ProphetNet model)"),oVe.forEach(t),Yor=i(pe),xF=n(pe,"LI",{});var rVe=s(xF);xFe=n(rVe,"STRONG",{});var cjt=s(xFe);Kor=r(cjt,"t5"),cjt.forEach(t),Zor=r(rVe," \u2014 "),CU=n(rVe,"A",{href:!0});var fjt=s(CU);err=r(fjt,"T5ForConditionalGeneration"),fjt.forEach(t),orr=r(rVe," (T5 model)"),rVe.forEach(t),rrr=i(pe),$F=n(pe,"LI",{});var tVe=s($F);$Fe=n(tVe,"STRONG",{});var gjt=s($Fe);trr=r(gjt,"xlm-prophetnet"),gjt.forEach(t),arr=r(tVe," \u2014 "),wU=n(tVe,"A",{href:!0});var hjt=s(wU);nrr=r(hjt,"XLMProphetNetForConditionalGeneration"),hjt.forEach(t),srr=r(tVe," (XLM-ProphetNet model)"),tVe.forEach(t),pe.forEach(t),lrr=i(Ca),kF=n(Ca,"P",{});var aVe=s(kF);irr=r(aVe,"The model is set in evaluation mode by default using "),kFe=n(aVe,"CODE",{});var ujt=s(kFe);drr=r(ujt,"model.eval()"),ujt.forEach(t),mrr=r(aVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),SFe=n(aVe,"CODE",{});var pjt=s(SFe);crr=r(pjt,"model.train()"),pjt.forEach(t),aVe.forEach(t),frr=i(Ca),T(SF.$$.fragment,Ca),Ca.forEach(t),$l.forEach(t),qeo=i(c),Sd=n(c,"H2",{class:!0});var Kro=s(Sd);RF=n(Kro,"A",{id:!0,class:!0,href:!0});var _jt=s(RF);RFe=n(_jt,"SPAN",{});var bjt=s(RFe);T(n$.$$.fragment,bjt),bjt.forEach(t),_jt.forEach(t),grr=i(Kro),PFe=n(Kro,"SPAN",{});var vjt=s(PFe);hrr=r(vjt,"AutoModelForSequenceClassification"),vjt.forEach(t),Kro.forEach(t),jeo=i(c),jo=n(c,"DIV",{class:!0});var kl=s(jo);T(s$.$$.fragment,kl),urr=i(kl),Rd=n(kl,"P",{});var Mie=s(Rd);prr=r(Mie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),AU=n(Mie,"A",{href:!0});var Fjt=s(AU);_rr=r(Fjt,"from_pretrained()"),Fjt.forEach(t),brr=r(Mie," class method or the "),LU=n(Mie,"A",{href:!0});var Tjt=s(LU);vrr=r(Tjt,"from_config()"),Tjt.forEach(t),Frr=r(Mie,` class
method.`),Mie.forEach(t),Trr=i(kl),l$=n(kl,"P",{});var Zro=s(l$);Mrr=r(Zro,"This class cannot be instantiated directly using "),BFe=n(Zro,"CODE",{});var Mjt=s(BFe);Err=r(Mjt,"__init__()"),Mjt.forEach(t),Crr=r(Zro," (throws an error)."),Zro.forEach(t),wrr=i(kl),Mt=n(kl,"DIV",{class:!0});var f8=s(Mt);T(i$.$$.fragment,f8),Arr=i(f8),IFe=n(f8,"P",{});var Ejt=s(IFe);Lrr=r(Ejt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Ejt.forEach(t),yrr=i(f8),Pd=n(f8,"P",{});var Eie=s(Pd);xrr=r(Eie,`Note:
Loading a model from its configuration file does `),NFe=n(Eie,"STRONG",{});var Cjt=s(NFe);$rr=r(Cjt,"not"),Cjt.forEach(t),krr=r(Eie,` load the model weights. It only affects the
model\u2019s configuration. Use `),yU=n(Eie,"A",{href:!0});var wjt=s(yU);Srr=r(wjt,"from_pretrained()"),wjt.forEach(t),Rrr=r(Eie," to load the model weights."),Eie.forEach(t),Prr=i(f8),T(PF.$$.fragment,f8),f8.forEach(t),Brr=i(kl),ao=n(kl,"DIV",{class:!0});var wa=s(ao);T(d$.$$.fragment,wa),Irr=i(wa),qFe=n(wa,"P",{});var Ajt=s(qFe);Nrr=r(Ajt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Ajt.forEach(t),qrr=i(wa),on=n(wa,"P",{});var g8=s(on);jrr=r(g8,"The model class to instantiate is selected based on the "),jFe=n(g8,"CODE",{});var Ljt=s(jFe);Drr=r(Ljt,"model_type"),Ljt.forEach(t),Grr=r(g8,` property of the config object (either
passed as an argument or loaded from `),DFe=n(g8,"CODE",{});var yjt=s(DFe);Orr=r(yjt,"pretrained_model_name_or_path"),yjt.forEach(t),Vrr=r(g8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),GFe=n(g8,"CODE",{});var xjt=s(GFe);Xrr=r(xjt,"pretrained_model_name_or_path"),xjt.forEach(t),zrr=r(g8,":"),g8.forEach(t),Qrr=i(wa),B=n(wa,"UL",{});var j=s(B);BF=n(j,"LI",{});var nVe=s(BF);OFe=n(nVe,"STRONG",{});var $jt=s(OFe);Wrr=r($jt,"albert"),$jt.forEach(t),Urr=r(nVe," \u2014 "),xU=n(nVe,"A",{href:!0});var kjt=s(xU);Hrr=r(kjt,"AlbertForSequenceClassification"),kjt.forEach(t),Jrr=r(nVe," (ALBERT model)"),nVe.forEach(t),Yrr=i(j),IF=n(j,"LI",{});var sVe=s(IF);VFe=n(sVe,"STRONG",{});var Sjt=s(VFe);Krr=r(Sjt,"bart"),Sjt.forEach(t),Zrr=r(sVe," \u2014 "),$U=n(sVe,"A",{href:!0});var Rjt=s($U);etr=r(Rjt,"BartForSequenceClassification"),Rjt.forEach(t),otr=r(sVe," (BART model)"),sVe.forEach(t),rtr=i(j),NF=n(j,"LI",{});var lVe=s(NF);XFe=n(lVe,"STRONG",{});var Pjt=s(XFe);ttr=r(Pjt,"bert"),Pjt.forEach(t),atr=r(lVe," \u2014 "),kU=n(lVe,"A",{href:!0});var Bjt=s(kU);ntr=r(Bjt,"BertForSequenceClassification"),Bjt.forEach(t),str=r(lVe," (BERT model)"),lVe.forEach(t),ltr=i(j),qF=n(j,"LI",{});var iVe=s(qF);zFe=n(iVe,"STRONG",{});var Ijt=s(zFe);itr=r(Ijt,"big_bird"),Ijt.forEach(t),dtr=r(iVe," \u2014 "),SU=n(iVe,"A",{href:!0});var Njt=s(SU);mtr=r(Njt,"BigBirdForSequenceClassification"),Njt.forEach(t),ctr=r(iVe," (BigBird model)"),iVe.forEach(t),ftr=i(j),jF=n(j,"LI",{});var dVe=s(jF);QFe=n(dVe,"STRONG",{});var qjt=s(QFe);gtr=r(qjt,"bigbird_pegasus"),qjt.forEach(t),htr=r(dVe," \u2014 "),RU=n(dVe,"A",{href:!0});var jjt=s(RU);utr=r(jjt,"BigBirdPegasusForSequenceClassification"),jjt.forEach(t),ptr=r(dVe," (BigBird-Pegasus model)"),dVe.forEach(t),_tr=i(j),DF=n(j,"LI",{});var mVe=s(DF);WFe=n(mVe,"STRONG",{});var Djt=s(WFe);btr=r(Djt,"bloom"),Djt.forEach(t),vtr=r(mVe," \u2014 "),PU=n(mVe,"A",{href:!0});var Gjt=s(PU);Ftr=r(Gjt,"BloomForSequenceClassification"),Gjt.forEach(t),Ttr=r(mVe," (BLOOM model)"),mVe.forEach(t),Mtr=i(j),GF=n(j,"LI",{});var cVe=s(GF);UFe=n(cVe,"STRONG",{});var Ojt=s(UFe);Etr=r(Ojt,"camembert"),Ojt.forEach(t),Ctr=r(cVe," \u2014 "),BU=n(cVe,"A",{href:!0});var Vjt=s(BU);wtr=r(Vjt,"CamembertForSequenceClassification"),Vjt.forEach(t),Atr=r(cVe," (CamemBERT model)"),cVe.forEach(t),Ltr=i(j),OF=n(j,"LI",{});var fVe=s(OF);HFe=n(fVe,"STRONG",{});var Xjt=s(HFe);ytr=r(Xjt,"canine"),Xjt.forEach(t),xtr=r(fVe," \u2014 "),IU=n(fVe,"A",{href:!0});var zjt=s(IU);$tr=r(zjt,"CanineForSequenceClassification"),zjt.forEach(t),ktr=r(fVe," (CANINE model)"),fVe.forEach(t),Str=i(j),VF=n(j,"LI",{});var gVe=s(VF);JFe=n(gVe,"STRONG",{});var Qjt=s(JFe);Rtr=r(Qjt,"convbert"),Qjt.forEach(t),Ptr=r(gVe," \u2014 "),NU=n(gVe,"A",{href:!0});var Wjt=s(NU);Btr=r(Wjt,"ConvBertForSequenceClassification"),Wjt.forEach(t),Itr=r(gVe," (ConvBERT model)"),gVe.forEach(t),Ntr=i(j),XF=n(j,"LI",{});var hVe=s(XF);YFe=n(hVe,"STRONG",{});var Ujt=s(YFe);qtr=r(Ujt,"ctrl"),Ujt.forEach(t),jtr=r(hVe," \u2014 "),qU=n(hVe,"A",{href:!0});var Hjt=s(qU);Dtr=r(Hjt,"CTRLForSequenceClassification"),Hjt.forEach(t),Gtr=r(hVe," (CTRL model)"),hVe.forEach(t),Otr=i(j),zF=n(j,"LI",{});var uVe=s(zF);KFe=n(uVe,"STRONG",{});var Jjt=s(KFe);Vtr=r(Jjt,"data2vec-text"),Jjt.forEach(t),Xtr=r(uVe," \u2014 "),jU=n(uVe,"A",{href:!0});var Yjt=s(jU);ztr=r(Yjt,"Data2VecTextForSequenceClassification"),Yjt.forEach(t),Qtr=r(uVe," (Data2VecText model)"),uVe.forEach(t),Wtr=i(j),QF=n(j,"LI",{});var pVe=s(QF);ZFe=n(pVe,"STRONG",{});var Kjt=s(ZFe);Utr=r(Kjt,"deberta"),Kjt.forEach(t),Htr=r(pVe," \u2014 "),DU=n(pVe,"A",{href:!0});var Zjt=s(DU);Jtr=r(Zjt,"DebertaForSequenceClassification"),Zjt.forEach(t),Ytr=r(pVe," (DeBERTa model)"),pVe.forEach(t),Ktr=i(j),WF=n(j,"LI",{});var _Ve=s(WF);eTe=n(_Ve,"STRONG",{});var eDt=s(eTe);Ztr=r(eDt,"deberta-v2"),eDt.forEach(t),ear=r(_Ve," \u2014 "),GU=n(_Ve,"A",{href:!0});var oDt=s(GU);oar=r(oDt,"DebertaV2ForSequenceClassification"),oDt.forEach(t),rar=r(_Ve," (DeBERTa-v2 model)"),_Ve.forEach(t),tar=i(j),UF=n(j,"LI",{});var bVe=s(UF);oTe=n(bVe,"STRONG",{});var rDt=s(oTe);aar=r(rDt,"distilbert"),rDt.forEach(t),nar=r(bVe," \u2014 "),OU=n(bVe,"A",{href:!0});var tDt=s(OU);sar=r(tDt,"DistilBertForSequenceClassification"),tDt.forEach(t),lar=r(bVe," (DistilBERT model)"),bVe.forEach(t),iar=i(j),HF=n(j,"LI",{});var vVe=s(HF);rTe=n(vVe,"STRONG",{});var aDt=s(rTe);dar=r(aDt,"electra"),aDt.forEach(t),mar=r(vVe," \u2014 "),VU=n(vVe,"A",{href:!0});var nDt=s(VU);car=r(nDt,"ElectraForSequenceClassification"),nDt.forEach(t),far=r(vVe," (ELECTRA model)"),vVe.forEach(t),gar=i(j),JF=n(j,"LI",{});var FVe=s(JF);tTe=n(FVe,"STRONG",{});var sDt=s(tTe);har=r(sDt,"ernie"),sDt.forEach(t),uar=r(FVe," \u2014 "),XU=n(FVe,"A",{href:!0});var lDt=s(XU);par=r(lDt,"ErnieForSequenceClassification"),lDt.forEach(t),_ar=r(FVe," (ERNIE model)"),FVe.forEach(t),bar=i(j),YF=n(j,"LI",{});var TVe=s(YF);aTe=n(TVe,"STRONG",{});var iDt=s(aTe);Far=r(iDt,"esm"),iDt.forEach(t),Tar=r(TVe," \u2014 "),zU=n(TVe,"A",{href:!0});var dDt=s(zU);Mar=r(dDt,"EsmForSequenceClassification"),dDt.forEach(t),Ear=r(TVe," (ESM model)"),TVe.forEach(t),Car=i(j),KF=n(j,"LI",{});var MVe=s(KF);nTe=n(MVe,"STRONG",{});var mDt=s(nTe);war=r(mDt,"flaubert"),mDt.forEach(t),Aar=r(MVe," \u2014 "),QU=n(MVe,"A",{href:!0});var cDt=s(QU);Lar=r(cDt,"FlaubertForSequenceClassification"),cDt.forEach(t),yar=r(MVe," (FlauBERT model)"),MVe.forEach(t),xar=i(j),ZF=n(j,"LI",{});var EVe=s(ZF);sTe=n(EVe,"STRONG",{});var fDt=s(sTe);$ar=r(fDt,"fnet"),fDt.forEach(t),kar=r(EVe," \u2014 "),WU=n(EVe,"A",{href:!0});var gDt=s(WU);Sar=r(gDt,"FNetForSequenceClassification"),gDt.forEach(t),Rar=r(EVe," (FNet model)"),EVe.forEach(t),Par=i(j),eT=n(j,"LI",{});var CVe=s(eT);lTe=n(CVe,"STRONG",{});var hDt=s(lTe);Bar=r(hDt,"funnel"),hDt.forEach(t),Iar=r(CVe," \u2014 "),UU=n(CVe,"A",{href:!0});var uDt=s(UU);Nar=r(uDt,"FunnelForSequenceClassification"),uDt.forEach(t),qar=r(CVe," (Funnel Transformer model)"),CVe.forEach(t),jar=i(j),oT=n(j,"LI",{});var wVe=s(oT);iTe=n(wVe,"STRONG",{});var pDt=s(iTe);Dar=r(pDt,"gpt2"),pDt.forEach(t),Gar=r(wVe," \u2014 "),HU=n(wVe,"A",{href:!0});var _Dt=s(HU);Oar=r(_Dt,"GPT2ForSequenceClassification"),_Dt.forEach(t),Var=r(wVe," (OpenAI GPT-2 model)"),wVe.forEach(t),Xar=i(j),rT=n(j,"LI",{});var AVe=s(rT);dTe=n(AVe,"STRONG",{});var bDt=s(dTe);zar=r(bDt,"gpt_neo"),bDt.forEach(t),Qar=r(AVe," \u2014 "),JU=n(AVe,"A",{href:!0});var vDt=s(JU);War=r(vDt,"GPTNeoForSequenceClassification"),vDt.forEach(t),Uar=r(AVe," (GPT Neo model)"),AVe.forEach(t),Har=i(j),tT=n(j,"LI",{});var LVe=s(tT);mTe=n(LVe,"STRONG",{});var FDt=s(mTe);Jar=r(FDt,"gptj"),FDt.forEach(t),Yar=r(LVe," \u2014 "),YU=n(LVe,"A",{href:!0});var TDt=s(YU);Kar=r(TDt,"GPTJForSequenceClassification"),TDt.forEach(t),Zar=r(LVe," (GPT-J model)"),LVe.forEach(t),enr=i(j),aT=n(j,"LI",{});var yVe=s(aT);cTe=n(yVe,"STRONG",{});var MDt=s(cTe);onr=r(MDt,"ibert"),MDt.forEach(t),rnr=r(yVe," \u2014 "),KU=n(yVe,"A",{href:!0});var EDt=s(KU);tnr=r(EDt,"IBertForSequenceClassification"),EDt.forEach(t),anr=r(yVe," (I-BERT model)"),yVe.forEach(t),nnr=i(j),nT=n(j,"LI",{});var xVe=s(nT);fTe=n(xVe,"STRONG",{});var CDt=s(fTe);snr=r(CDt,"layoutlm"),CDt.forEach(t),lnr=r(xVe," \u2014 "),ZU=n(xVe,"A",{href:!0});var wDt=s(ZU);inr=r(wDt,"LayoutLMForSequenceClassification"),wDt.forEach(t),dnr=r(xVe," (LayoutLM model)"),xVe.forEach(t),mnr=i(j),sT=n(j,"LI",{});var $Ve=s(sT);gTe=n($Ve,"STRONG",{});var ADt=s(gTe);cnr=r(ADt,"layoutlmv2"),ADt.forEach(t),fnr=r($Ve," \u2014 "),eH=n($Ve,"A",{href:!0});var LDt=s(eH);gnr=r(LDt,"LayoutLMv2ForSequenceClassification"),LDt.forEach(t),hnr=r($Ve," (LayoutLMv2 model)"),$Ve.forEach(t),unr=i(j),lT=n(j,"LI",{});var kVe=s(lT);hTe=n(kVe,"STRONG",{});var yDt=s(hTe);pnr=r(yDt,"layoutlmv3"),yDt.forEach(t),_nr=r(kVe," \u2014 "),oH=n(kVe,"A",{href:!0});var xDt=s(oH);bnr=r(xDt,"LayoutLMv3ForSequenceClassification"),xDt.forEach(t),vnr=r(kVe," (LayoutLMv3 model)"),kVe.forEach(t),Fnr=i(j),iT=n(j,"LI",{});var SVe=s(iT);uTe=n(SVe,"STRONG",{});var $Dt=s(uTe);Tnr=r($Dt,"led"),$Dt.forEach(t),Mnr=r(SVe," \u2014 "),rH=n(SVe,"A",{href:!0});var kDt=s(rH);Enr=r(kDt,"LEDForSequenceClassification"),kDt.forEach(t),Cnr=r(SVe," (LED model)"),SVe.forEach(t),wnr=i(j),dT=n(j,"LI",{});var RVe=s(dT);pTe=n(RVe,"STRONG",{});var SDt=s(pTe);Anr=r(SDt,"longformer"),SDt.forEach(t),Lnr=r(RVe," \u2014 "),tH=n(RVe,"A",{href:!0});var RDt=s(tH);ynr=r(RDt,"LongformerForSequenceClassification"),RDt.forEach(t),xnr=r(RVe," (Longformer model)"),RVe.forEach(t),$nr=i(j),mT=n(j,"LI",{});var PVe=s(mT);_Te=n(PVe,"STRONG",{});var PDt=s(_Te);knr=r(PDt,"luke"),PDt.forEach(t),Snr=r(PVe," \u2014 "),aH=n(PVe,"A",{href:!0});var BDt=s(aH);Rnr=r(BDt,"LukeForSequenceClassification"),BDt.forEach(t),Pnr=r(PVe," (LUKE model)"),PVe.forEach(t),Bnr=i(j),cT=n(j,"LI",{});var BVe=s(cT);bTe=n(BVe,"STRONG",{});var IDt=s(bTe);Inr=r(IDt,"markuplm"),IDt.forEach(t),Nnr=r(BVe," \u2014 "),nH=n(BVe,"A",{href:!0});var NDt=s(nH);qnr=r(NDt,"MarkupLMForSequenceClassification"),NDt.forEach(t),jnr=r(BVe," (MarkupLM model)"),BVe.forEach(t),Dnr=i(j),fT=n(j,"LI",{});var IVe=s(fT);vTe=n(IVe,"STRONG",{});var qDt=s(vTe);Gnr=r(qDt,"mbart"),qDt.forEach(t),Onr=r(IVe," \u2014 "),sH=n(IVe,"A",{href:!0});var jDt=s(sH);Vnr=r(jDt,"MBartForSequenceClassification"),jDt.forEach(t),Xnr=r(IVe," (mBART model)"),IVe.forEach(t),znr=i(j),gT=n(j,"LI",{});var NVe=s(gT);FTe=n(NVe,"STRONG",{});var DDt=s(FTe);Qnr=r(DDt,"megatron-bert"),DDt.forEach(t),Wnr=r(NVe," \u2014 "),lH=n(NVe,"A",{href:!0});var GDt=s(lH);Unr=r(GDt,"MegatronBertForSequenceClassification"),GDt.forEach(t),Hnr=r(NVe," (Megatron-BERT model)"),NVe.forEach(t),Jnr=i(j),hT=n(j,"LI",{});var qVe=s(hT);TTe=n(qVe,"STRONG",{});var ODt=s(TTe);Ynr=r(ODt,"mobilebert"),ODt.forEach(t),Knr=r(qVe," \u2014 "),iH=n(qVe,"A",{href:!0});var VDt=s(iH);Znr=r(VDt,"MobileBertForSequenceClassification"),VDt.forEach(t),esr=r(qVe," (MobileBERT model)"),qVe.forEach(t),osr=i(j),uT=n(j,"LI",{});var jVe=s(uT);MTe=n(jVe,"STRONG",{});var XDt=s(MTe);rsr=r(XDt,"mpnet"),XDt.forEach(t),tsr=r(jVe," \u2014 "),dH=n(jVe,"A",{href:!0});var zDt=s(dH);asr=r(zDt,"MPNetForSequenceClassification"),zDt.forEach(t),nsr=r(jVe," (MPNet model)"),jVe.forEach(t),ssr=i(j),pT=n(j,"LI",{});var DVe=s(pT);ETe=n(DVe,"STRONG",{});var QDt=s(ETe);lsr=r(QDt,"mvp"),QDt.forEach(t),isr=r(DVe," \u2014 "),mH=n(DVe,"A",{href:!0});var WDt=s(mH);dsr=r(WDt,"MvpForSequenceClassification"),WDt.forEach(t),msr=r(DVe," (MVP model)"),DVe.forEach(t),csr=i(j),_T=n(j,"LI",{});var GVe=s(_T);CTe=n(GVe,"STRONG",{});var UDt=s(CTe);fsr=r(UDt,"nezha"),UDt.forEach(t),gsr=r(GVe," \u2014 "),cH=n(GVe,"A",{href:!0});var HDt=s(cH);hsr=r(HDt,"NezhaForSequenceClassification"),HDt.forEach(t),usr=r(GVe," (Nezha model)"),GVe.forEach(t),psr=i(j),bT=n(j,"LI",{});var OVe=s(bT);wTe=n(OVe,"STRONG",{});var JDt=s(wTe);_sr=r(JDt,"nystromformer"),JDt.forEach(t),bsr=r(OVe," \u2014 "),fH=n(OVe,"A",{href:!0});var YDt=s(fH);vsr=r(YDt,"NystromformerForSequenceClassification"),YDt.forEach(t),Fsr=r(OVe," (Nystr\xF6mformer model)"),OVe.forEach(t),Tsr=i(j),vT=n(j,"LI",{});var VVe=s(vT);ATe=n(VVe,"STRONG",{});var KDt=s(ATe);Msr=r(KDt,"openai-gpt"),KDt.forEach(t),Esr=r(VVe," \u2014 "),gH=n(VVe,"A",{href:!0});var ZDt=s(gH);Csr=r(ZDt,"OpenAIGPTForSequenceClassification"),ZDt.forEach(t),wsr=r(VVe," (OpenAI GPT model)"),VVe.forEach(t),Asr=i(j),FT=n(j,"LI",{});var XVe=s(FT);LTe=n(XVe,"STRONG",{});var eGt=s(LTe);Lsr=r(eGt,"opt"),eGt.forEach(t),ysr=r(XVe," \u2014 "),hH=n(XVe,"A",{href:!0});var oGt=s(hH);xsr=r(oGt,"OPTForSequenceClassification"),oGt.forEach(t),$sr=r(XVe," (OPT model)"),XVe.forEach(t),ksr=i(j),TT=n(j,"LI",{});var zVe=s(TT);yTe=n(zVe,"STRONG",{});var rGt=s(yTe);Ssr=r(rGt,"perceiver"),rGt.forEach(t),Rsr=r(zVe," \u2014 "),uH=n(zVe,"A",{href:!0});var tGt=s(uH);Psr=r(tGt,"PerceiverForSequenceClassification"),tGt.forEach(t),Bsr=r(zVe," (Perceiver model)"),zVe.forEach(t),Isr=i(j),MT=n(j,"LI",{});var QVe=s(MT);xTe=n(QVe,"STRONG",{});var aGt=s(xTe);Nsr=r(aGt,"plbart"),aGt.forEach(t),qsr=r(QVe," \u2014 "),pH=n(QVe,"A",{href:!0});var nGt=s(pH);jsr=r(nGt,"PLBartForSequenceClassification"),nGt.forEach(t),Dsr=r(QVe," (PLBart model)"),QVe.forEach(t),Gsr=i(j),ET=n(j,"LI",{});var WVe=s(ET);$Te=n(WVe,"STRONG",{});var sGt=s($Te);Osr=r(sGt,"qdqbert"),sGt.forEach(t),Vsr=r(WVe," \u2014 "),_H=n(WVe,"A",{href:!0});var lGt=s(_H);Xsr=r(lGt,"QDQBertForSequenceClassification"),lGt.forEach(t),zsr=r(WVe," (QDQBert model)"),WVe.forEach(t),Qsr=i(j),CT=n(j,"LI",{});var UVe=s(CT);kTe=n(UVe,"STRONG",{});var iGt=s(kTe);Wsr=r(iGt,"reformer"),iGt.forEach(t),Usr=r(UVe," \u2014 "),bH=n(UVe,"A",{href:!0});var dGt=s(bH);Hsr=r(dGt,"ReformerForSequenceClassification"),dGt.forEach(t),Jsr=r(UVe," (Reformer model)"),UVe.forEach(t),Ysr=i(j),wT=n(j,"LI",{});var HVe=s(wT);STe=n(HVe,"STRONG",{});var mGt=s(STe);Ksr=r(mGt,"rembert"),mGt.forEach(t),Zsr=r(HVe," \u2014 "),vH=n(HVe,"A",{href:!0});var cGt=s(vH);elr=r(cGt,"RemBertForSequenceClassification"),cGt.forEach(t),olr=r(HVe," (RemBERT model)"),HVe.forEach(t),rlr=i(j),AT=n(j,"LI",{});var JVe=s(AT);RTe=n(JVe,"STRONG",{});var fGt=s(RTe);tlr=r(fGt,"roberta"),fGt.forEach(t),alr=r(JVe," \u2014 "),FH=n(JVe,"A",{href:!0});var gGt=s(FH);nlr=r(gGt,"RobertaForSequenceClassification"),gGt.forEach(t),slr=r(JVe," (RoBERTa model)"),JVe.forEach(t),llr=i(j),LT=n(j,"LI",{});var YVe=s(LT);PTe=n(YVe,"STRONG",{});var hGt=s(PTe);ilr=r(hGt,"roformer"),hGt.forEach(t),dlr=r(YVe," \u2014 "),TH=n(YVe,"A",{href:!0});var uGt=s(TH);mlr=r(uGt,"RoFormerForSequenceClassification"),uGt.forEach(t),clr=r(YVe," (RoFormer model)"),YVe.forEach(t),flr=i(j),yT=n(j,"LI",{});var KVe=s(yT);BTe=n(KVe,"STRONG",{});var pGt=s(BTe);glr=r(pGt,"squeezebert"),pGt.forEach(t),hlr=r(KVe," \u2014 "),MH=n(KVe,"A",{href:!0});var _Gt=s(MH);ulr=r(_Gt,"SqueezeBertForSequenceClassification"),_Gt.forEach(t),plr=r(KVe," (SqueezeBERT model)"),KVe.forEach(t),_lr=i(j),xT=n(j,"LI",{});var ZVe=s(xT);ITe=n(ZVe,"STRONG",{});var bGt=s(ITe);blr=r(bGt,"tapas"),bGt.forEach(t),vlr=r(ZVe," \u2014 "),EH=n(ZVe,"A",{href:!0});var vGt=s(EH);Flr=r(vGt,"TapasForSequenceClassification"),vGt.forEach(t),Tlr=r(ZVe," (TAPAS model)"),ZVe.forEach(t),Mlr=i(j),$T=n(j,"LI",{});var eXe=s($T);NTe=n(eXe,"STRONG",{});var FGt=s(NTe);Elr=r(FGt,"transfo-xl"),FGt.forEach(t),Clr=r(eXe," \u2014 "),CH=n(eXe,"A",{href:!0});var TGt=s(CH);wlr=r(TGt,"TransfoXLForSequenceClassification"),TGt.forEach(t),Alr=r(eXe," (Transformer-XL model)"),eXe.forEach(t),Llr=i(j),kT=n(j,"LI",{});var oXe=s(kT);qTe=n(oXe,"STRONG",{});var MGt=s(qTe);ylr=r(MGt,"xlm"),MGt.forEach(t),xlr=r(oXe," \u2014 "),wH=n(oXe,"A",{href:!0});var EGt=s(wH);$lr=r(EGt,"XLMForSequenceClassification"),EGt.forEach(t),klr=r(oXe," (XLM model)"),oXe.forEach(t),Slr=i(j),ST=n(j,"LI",{});var rXe=s(ST);jTe=n(rXe,"STRONG",{});var CGt=s(jTe);Rlr=r(CGt,"xlm-roberta"),CGt.forEach(t),Plr=r(rXe," \u2014 "),AH=n(rXe,"A",{href:!0});var wGt=s(AH);Blr=r(wGt,"XLMRobertaForSequenceClassification"),wGt.forEach(t),Ilr=r(rXe," (XLM-RoBERTa model)"),rXe.forEach(t),Nlr=i(j),RT=n(j,"LI",{});var tXe=s(RT);DTe=n(tXe,"STRONG",{});var AGt=s(DTe);qlr=r(AGt,"xlm-roberta-xl"),AGt.forEach(t),jlr=r(tXe," \u2014 "),LH=n(tXe,"A",{href:!0});var LGt=s(LH);Dlr=r(LGt,"XLMRobertaXLForSequenceClassification"),LGt.forEach(t),Glr=r(tXe," (XLM-RoBERTa-XL model)"),tXe.forEach(t),Olr=i(j),PT=n(j,"LI",{});var aXe=s(PT);GTe=n(aXe,"STRONG",{});var yGt=s(GTe);Vlr=r(yGt,"xlnet"),yGt.forEach(t),Xlr=r(aXe," \u2014 "),yH=n(aXe,"A",{href:!0});var xGt=s(yH);zlr=r(xGt,"XLNetForSequenceClassification"),xGt.forEach(t),Qlr=r(aXe," (XLNet model)"),aXe.forEach(t),Wlr=i(j),BT=n(j,"LI",{});var nXe=s(BT);OTe=n(nXe,"STRONG",{});var $Gt=s(OTe);Ulr=r($Gt,"yoso"),$Gt.forEach(t),Hlr=r(nXe," \u2014 "),xH=n(nXe,"A",{href:!0});var kGt=s(xH);Jlr=r(kGt,"YosoForSequenceClassification"),kGt.forEach(t),Ylr=r(nXe," (YOSO model)"),nXe.forEach(t),j.forEach(t),Klr=i(wa),IT=n(wa,"P",{});var sXe=s(IT);Zlr=r(sXe,"The model is set in evaluation mode by default using "),VTe=n(sXe,"CODE",{});var SGt=s(VTe);eir=r(SGt,"model.eval()"),SGt.forEach(t),oir=r(sXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),XTe=n(sXe,"CODE",{});var RGt=s(XTe);rir=r(RGt,"model.train()"),RGt.forEach(t),sXe.forEach(t),tir=i(wa),T(NT.$$.fragment,wa),wa.forEach(t),kl.forEach(t),Deo=i(c),Bd=n(c,"H2",{class:!0});var eto=s(Bd);qT=n(eto,"A",{id:!0,class:!0,href:!0});var PGt=s(qT);zTe=n(PGt,"SPAN",{});var BGt=s(zTe);T(m$.$$.fragment,BGt),BGt.forEach(t),PGt.forEach(t),air=i(eto),QTe=n(eto,"SPAN",{});var IGt=s(QTe);nir=r(IGt,"AutoModelForMultipleChoice"),IGt.forEach(t),eto.forEach(t),Geo=i(c),Do=n(c,"DIV",{class:!0});var Sl=s(Do);T(c$.$$.fragment,Sl),sir=i(Sl),Id=n(Sl,"P",{});var Cie=s(Id);lir=r(Cie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),$H=n(Cie,"A",{href:!0});var NGt=s($H);iir=r(NGt,"from_pretrained()"),NGt.forEach(t),dir=r(Cie," class method or the "),kH=n(Cie,"A",{href:!0});var qGt=s(kH);mir=r(qGt,"from_config()"),qGt.forEach(t),cir=r(Cie,` class
method.`),Cie.forEach(t),fir=i(Sl),f$=n(Sl,"P",{});var oto=s(f$);gir=r(oto,"This class cannot be instantiated directly using "),WTe=n(oto,"CODE",{});var jGt=s(WTe);hir=r(jGt,"__init__()"),jGt.forEach(t),uir=r(oto," (throws an error)."),oto.forEach(t),pir=i(Sl),Et=n(Sl,"DIV",{class:!0});var h8=s(Et);T(g$.$$.fragment,h8),_ir=i(h8),UTe=n(h8,"P",{});var DGt=s(UTe);bir=r(DGt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),DGt.forEach(t),vir=i(h8),Nd=n(h8,"P",{});var wie=s(Nd);Fir=r(wie,`Note:
Loading a model from its configuration file does `),HTe=n(wie,"STRONG",{});var GGt=s(HTe);Tir=r(GGt,"not"),GGt.forEach(t),Mir=r(wie,` load the model weights. It only affects the
model\u2019s configuration. Use `),SH=n(wie,"A",{href:!0});var OGt=s(SH);Eir=r(OGt,"from_pretrained()"),OGt.forEach(t),Cir=r(wie," to load the model weights."),wie.forEach(t),wir=i(h8),T(jT.$$.fragment,h8),h8.forEach(t),Air=i(Sl),no=n(Sl,"DIV",{class:!0});var Aa=s(no);T(h$.$$.fragment,Aa),Lir=i(Aa),JTe=n(Aa,"P",{});var VGt=s(JTe);yir=r(VGt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),VGt.forEach(t),xir=i(Aa),rn=n(Aa,"P",{});var u8=s(rn);$ir=r(u8,"The model class to instantiate is selected based on the "),YTe=n(u8,"CODE",{});var XGt=s(YTe);kir=r(XGt,"model_type"),XGt.forEach(t),Sir=r(u8,` property of the config object (either
passed as an argument or loaded from `),KTe=n(u8,"CODE",{});var zGt=s(KTe);Rir=r(zGt,"pretrained_model_name_or_path"),zGt.forEach(t),Pir=r(u8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZTe=n(u8,"CODE",{});var QGt=s(ZTe);Bir=r(QGt,"pretrained_model_name_or_path"),QGt.forEach(t),Iir=r(u8,":"),u8.forEach(t),Nir=i(Aa),Z=n(Aa,"UL",{});var ee=s(Z);DT=n(ee,"LI",{});var lXe=s(DT);eMe=n(lXe,"STRONG",{});var WGt=s(eMe);qir=r(WGt,"albert"),WGt.forEach(t),jir=r(lXe," \u2014 "),RH=n(lXe,"A",{href:!0});var UGt=s(RH);Dir=r(UGt,"AlbertForMultipleChoice"),UGt.forEach(t),Gir=r(lXe," (ALBERT model)"),lXe.forEach(t),Oir=i(ee),GT=n(ee,"LI",{});var iXe=s(GT);oMe=n(iXe,"STRONG",{});var HGt=s(oMe);Vir=r(HGt,"bert"),HGt.forEach(t),Xir=r(iXe," \u2014 "),PH=n(iXe,"A",{href:!0});var JGt=s(PH);zir=r(JGt,"BertForMultipleChoice"),JGt.forEach(t),Qir=r(iXe," (BERT model)"),iXe.forEach(t),Wir=i(ee),OT=n(ee,"LI",{});var dXe=s(OT);rMe=n(dXe,"STRONG",{});var YGt=s(rMe);Uir=r(YGt,"big_bird"),YGt.forEach(t),Hir=r(dXe," \u2014 "),BH=n(dXe,"A",{href:!0});var KGt=s(BH);Jir=r(KGt,"BigBirdForMultipleChoice"),KGt.forEach(t),Yir=r(dXe," (BigBird model)"),dXe.forEach(t),Kir=i(ee),VT=n(ee,"LI",{});var mXe=s(VT);tMe=n(mXe,"STRONG",{});var ZGt=s(tMe);Zir=r(ZGt,"camembert"),ZGt.forEach(t),edr=r(mXe," \u2014 "),IH=n(mXe,"A",{href:!0});var eOt=s(IH);odr=r(eOt,"CamembertForMultipleChoice"),eOt.forEach(t),rdr=r(mXe," (CamemBERT model)"),mXe.forEach(t),tdr=i(ee),XT=n(ee,"LI",{});var cXe=s(XT);aMe=n(cXe,"STRONG",{});var oOt=s(aMe);adr=r(oOt,"canine"),oOt.forEach(t),ndr=r(cXe," \u2014 "),NH=n(cXe,"A",{href:!0});var rOt=s(NH);sdr=r(rOt,"CanineForMultipleChoice"),rOt.forEach(t),ldr=r(cXe," (CANINE model)"),cXe.forEach(t),idr=i(ee),zT=n(ee,"LI",{});var fXe=s(zT);nMe=n(fXe,"STRONG",{});var tOt=s(nMe);ddr=r(tOt,"convbert"),tOt.forEach(t),mdr=r(fXe," \u2014 "),qH=n(fXe,"A",{href:!0});var aOt=s(qH);cdr=r(aOt,"ConvBertForMultipleChoice"),aOt.forEach(t),fdr=r(fXe," (ConvBERT model)"),fXe.forEach(t),gdr=i(ee),QT=n(ee,"LI",{});var gXe=s(QT);sMe=n(gXe,"STRONG",{});var nOt=s(sMe);hdr=r(nOt,"data2vec-text"),nOt.forEach(t),udr=r(gXe," \u2014 "),jH=n(gXe,"A",{href:!0});var sOt=s(jH);pdr=r(sOt,"Data2VecTextForMultipleChoice"),sOt.forEach(t),_dr=r(gXe," (Data2VecText model)"),gXe.forEach(t),bdr=i(ee),WT=n(ee,"LI",{});var hXe=s(WT);lMe=n(hXe,"STRONG",{});var lOt=s(lMe);vdr=r(lOt,"deberta-v2"),lOt.forEach(t),Fdr=r(hXe," \u2014 "),DH=n(hXe,"A",{href:!0});var iOt=s(DH);Tdr=r(iOt,"DebertaV2ForMultipleChoice"),iOt.forEach(t),Mdr=r(hXe," (DeBERTa-v2 model)"),hXe.forEach(t),Edr=i(ee),UT=n(ee,"LI",{});var uXe=s(UT);iMe=n(uXe,"STRONG",{});var dOt=s(iMe);Cdr=r(dOt,"distilbert"),dOt.forEach(t),wdr=r(uXe," \u2014 "),GH=n(uXe,"A",{href:!0});var mOt=s(GH);Adr=r(mOt,"DistilBertForMultipleChoice"),mOt.forEach(t),Ldr=r(uXe," (DistilBERT model)"),uXe.forEach(t),ydr=i(ee),HT=n(ee,"LI",{});var pXe=s(HT);dMe=n(pXe,"STRONG",{});var cOt=s(dMe);xdr=r(cOt,"electra"),cOt.forEach(t),$dr=r(pXe," \u2014 "),OH=n(pXe,"A",{href:!0});var fOt=s(OH);kdr=r(fOt,"ElectraForMultipleChoice"),fOt.forEach(t),Sdr=r(pXe," (ELECTRA model)"),pXe.forEach(t),Rdr=i(ee),JT=n(ee,"LI",{});var _Xe=s(JT);mMe=n(_Xe,"STRONG",{});var gOt=s(mMe);Pdr=r(gOt,"ernie"),gOt.forEach(t),Bdr=r(_Xe," \u2014 "),VH=n(_Xe,"A",{href:!0});var hOt=s(VH);Idr=r(hOt,"ErnieForMultipleChoice"),hOt.forEach(t),Ndr=r(_Xe," (ERNIE model)"),_Xe.forEach(t),qdr=i(ee),YT=n(ee,"LI",{});var bXe=s(YT);cMe=n(bXe,"STRONG",{});var uOt=s(cMe);jdr=r(uOt,"flaubert"),uOt.forEach(t),Ddr=r(bXe," \u2014 "),XH=n(bXe,"A",{href:!0});var pOt=s(XH);Gdr=r(pOt,"FlaubertForMultipleChoice"),pOt.forEach(t),Odr=r(bXe," (FlauBERT model)"),bXe.forEach(t),Vdr=i(ee),KT=n(ee,"LI",{});var vXe=s(KT);fMe=n(vXe,"STRONG",{});var _Ot=s(fMe);Xdr=r(_Ot,"fnet"),_Ot.forEach(t),zdr=r(vXe," \u2014 "),zH=n(vXe,"A",{href:!0});var bOt=s(zH);Qdr=r(bOt,"FNetForMultipleChoice"),bOt.forEach(t),Wdr=r(vXe," (FNet model)"),vXe.forEach(t),Udr=i(ee),ZT=n(ee,"LI",{});var FXe=s(ZT);gMe=n(FXe,"STRONG",{});var vOt=s(gMe);Hdr=r(vOt,"funnel"),vOt.forEach(t),Jdr=r(FXe," \u2014 "),QH=n(FXe,"A",{href:!0});var FOt=s(QH);Ydr=r(FOt,"FunnelForMultipleChoice"),FOt.forEach(t),Kdr=r(FXe," (Funnel Transformer model)"),FXe.forEach(t),Zdr=i(ee),eM=n(ee,"LI",{});var TXe=s(eM);hMe=n(TXe,"STRONG",{});var TOt=s(hMe);emr=r(TOt,"ibert"),TOt.forEach(t),omr=r(TXe," \u2014 "),WH=n(TXe,"A",{href:!0});var MOt=s(WH);rmr=r(MOt,"IBertForMultipleChoice"),MOt.forEach(t),tmr=r(TXe," (I-BERT model)"),TXe.forEach(t),amr=i(ee),oM=n(ee,"LI",{});var MXe=s(oM);uMe=n(MXe,"STRONG",{});var EOt=s(uMe);nmr=r(EOt,"longformer"),EOt.forEach(t),smr=r(MXe," \u2014 "),UH=n(MXe,"A",{href:!0});var COt=s(UH);lmr=r(COt,"LongformerForMultipleChoice"),COt.forEach(t),imr=r(MXe," (Longformer model)"),MXe.forEach(t),dmr=i(ee),rM=n(ee,"LI",{});var EXe=s(rM);pMe=n(EXe,"STRONG",{});var wOt=s(pMe);mmr=r(wOt,"luke"),wOt.forEach(t),cmr=r(EXe," \u2014 "),HH=n(EXe,"A",{href:!0});var AOt=s(HH);fmr=r(AOt,"LukeForMultipleChoice"),AOt.forEach(t),gmr=r(EXe," (LUKE model)"),EXe.forEach(t),hmr=i(ee),tM=n(ee,"LI",{});var CXe=s(tM);_Me=n(CXe,"STRONG",{});var LOt=s(_Me);umr=r(LOt,"megatron-bert"),LOt.forEach(t),pmr=r(CXe," \u2014 "),JH=n(CXe,"A",{href:!0});var yOt=s(JH);_mr=r(yOt,"MegatronBertForMultipleChoice"),yOt.forEach(t),bmr=r(CXe," (Megatron-BERT model)"),CXe.forEach(t),vmr=i(ee),aM=n(ee,"LI",{});var wXe=s(aM);bMe=n(wXe,"STRONG",{});var xOt=s(bMe);Fmr=r(xOt,"mobilebert"),xOt.forEach(t),Tmr=r(wXe," \u2014 "),YH=n(wXe,"A",{href:!0});var $Ot=s(YH);Mmr=r($Ot,"MobileBertForMultipleChoice"),$Ot.forEach(t),Emr=r(wXe," (MobileBERT model)"),wXe.forEach(t),Cmr=i(ee),nM=n(ee,"LI",{});var AXe=s(nM);vMe=n(AXe,"STRONG",{});var kOt=s(vMe);wmr=r(kOt,"mpnet"),kOt.forEach(t),Amr=r(AXe," \u2014 "),KH=n(AXe,"A",{href:!0});var SOt=s(KH);Lmr=r(SOt,"MPNetForMultipleChoice"),SOt.forEach(t),ymr=r(AXe," (MPNet model)"),AXe.forEach(t),xmr=i(ee),sM=n(ee,"LI",{});var LXe=s(sM);FMe=n(LXe,"STRONG",{});var ROt=s(FMe);$mr=r(ROt,"nezha"),ROt.forEach(t),kmr=r(LXe," \u2014 "),ZH=n(LXe,"A",{href:!0});var POt=s(ZH);Smr=r(POt,"NezhaForMultipleChoice"),POt.forEach(t),Rmr=r(LXe," (Nezha model)"),LXe.forEach(t),Pmr=i(ee),lM=n(ee,"LI",{});var yXe=s(lM);TMe=n(yXe,"STRONG",{});var BOt=s(TMe);Bmr=r(BOt,"nystromformer"),BOt.forEach(t),Imr=r(yXe," \u2014 "),eJ=n(yXe,"A",{href:!0});var IOt=s(eJ);Nmr=r(IOt,"NystromformerForMultipleChoice"),IOt.forEach(t),qmr=r(yXe," (Nystr\xF6mformer model)"),yXe.forEach(t),jmr=i(ee),iM=n(ee,"LI",{});var xXe=s(iM);MMe=n(xXe,"STRONG",{});var NOt=s(MMe);Dmr=r(NOt,"qdqbert"),NOt.forEach(t),Gmr=r(xXe," \u2014 "),oJ=n(xXe,"A",{href:!0});var qOt=s(oJ);Omr=r(qOt,"QDQBertForMultipleChoice"),qOt.forEach(t),Vmr=r(xXe," (QDQBert model)"),xXe.forEach(t),Xmr=i(ee),dM=n(ee,"LI",{});var $Xe=s(dM);EMe=n($Xe,"STRONG",{});var jOt=s(EMe);zmr=r(jOt,"rembert"),jOt.forEach(t),Qmr=r($Xe," \u2014 "),rJ=n($Xe,"A",{href:!0});var DOt=s(rJ);Wmr=r(DOt,"RemBertForMultipleChoice"),DOt.forEach(t),Umr=r($Xe," (RemBERT model)"),$Xe.forEach(t),Hmr=i(ee),mM=n(ee,"LI",{});var kXe=s(mM);CMe=n(kXe,"STRONG",{});var GOt=s(CMe);Jmr=r(GOt,"roberta"),GOt.forEach(t),Ymr=r(kXe," \u2014 "),tJ=n(kXe,"A",{href:!0});var OOt=s(tJ);Kmr=r(OOt,"RobertaForMultipleChoice"),OOt.forEach(t),Zmr=r(kXe," (RoBERTa model)"),kXe.forEach(t),ecr=i(ee),cM=n(ee,"LI",{});var SXe=s(cM);wMe=n(SXe,"STRONG",{});var VOt=s(wMe);ocr=r(VOt,"roformer"),VOt.forEach(t),rcr=r(SXe," \u2014 "),aJ=n(SXe,"A",{href:!0});var XOt=s(aJ);tcr=r(XOt,"RoFormerForMultipleChoice"),XOt.forEach(t),acr=r(SXe," (RoFormer model)"),SXe.forEach(t),ncr=i(ee),fM=n(ee,"LI",{});var RXe=s(fM);AMe=n(RXe,"STRONG",{});var zOt=s(AMe);scr=r(zOt,"squeezebert"),zOt.forEach(t),lcr=r(RXe," \u2014 "),nJ=n(RXe,"A",{href:!0});var QOt=s(nJ);icr=r(QOt,"SqueezeBertForMultipleChoice"),QOt.forEach(t),dcr=r(RXe," (SqueezeBERT model)"),RXe.forEach(t),mcr=i(ee),gM=n(ee,"LI",{});var PXe=s(gM);LMe=n(PXe,"STRONG",{});var WOt=s(LMe);ccr=r(WOt,"xlm"),WOt.forEach(t),fcr=r(PXe," \u2014 "),sJ=n(PXe,"A",{href:!0});var UOt=s(sJ);gcr=r(UOt,"XLMForMultipleChoice"),UOt.forEach(t),hcr=r(PXe," (XLM model)"),PXe.forEach(t),ucr=i(ee),hM=n(ee,"LI",{});var BXe=s(hM);yMe=n(BXe,"STRONG",{});var HOt=s(yMe);pcr=r(HOt,"xlm-roberta"),HOt.forEach(t),_cr=r(BXe," \u2014 "),lJ=n(BXe,"A",{href:!0});var JOt=s(lJ);bcr=r(JOt,"XLMRobertaForMultipleChoice"),JOt.forEach(t),vcr=r(BXe," (XLM-RoBERTa model)"),BXe.forEach(t),Fcr=i(ee),uM=n(ee,"LI",{});var IXe=s(uM);xMe=n(IXe,"STRONG",{});var YOt=s(xMe);Tcr=r(YOt,"xlm-roberta-xl"),YOt.forEach(t),Mcr=r(IXe," \u2014 "),iJ=n(IXe,"A",{href:!0});var KOt=s(iJ);Ecr=r(KOt,"XLMRobertaXLForMultipleChoice"),KOt.forEach(t),Ccr=r(IXe," (XLM-RoBERTa-XL model)"),IXe.forEach(t),wcr=i(ee),pM=n(ee,"LI",{});var NXe=s(pM);$Me=n(NXe,"STRONG",{});var ZOt=s($Me);Acr=r(ZOt,"xlnet"),ZOt.forEach(t),Lcr=r(NXe," \u2014 "),dJ=n(NXe,"A",{href:!0});var eVt=s(dJ);ycr=r(eVt,"XLNetForMultipleChoice"),eVt.forEach(t),xcr=r(NXe," (XLNet model)"),NXe.forEach(t),$cr=i(ee),_M=n(ee,"LI",{});var qXe=s(_M);kMe=n(qXe,"STRONG",{});var oVt=s(kMe);kcr=r(oVt,"yoso"),oVt.forEach(t),Scr=r(qXe," \u2014 "),mJ=n(qXe,"A",{href:!0});var rVt=s(mJ);Rcr=r(rVt,"YosoForMultipleChoice"),rVt.forEach(t),Pcr=r(qXe," (YOSO model)"),qXe.forEach(t),ee.forEach(t),Bcr=i(Aa),bM=n(Aa,"P",{});var jXe=s(bM);Icr=r(jXe,"The model is set in evaluation mode by default using "),SMe=n(jXe,"CODE",{});var tVt=s(SMe);Ncr=r(tVt,"model.eval()"),tVt.forEach(t),qcr=r(jXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),RMe=n(jXe,"CODE",{});var aVt=s(RMe);jcr=r(aVt,"model.train()"),aVt.forEach(t),jXe.forEach(t),Dcr=i(Aa),T(vM.$$.fragment,Aa),Aa.forEach(t),Sl.forEach(t),Oeo=i(c),qd=n(c,"H2",{class:!0});var rto=s(qd);FM=n(rto,"A",{id:!0,class:!0,href:!0});var nVt=s(FM);PMe=n(nVt,"SPAN",{});var sVt=s(PMe);T(u$.$$.fragment,sVt),sVt.forEach(t),nVt.forEach(t),Gcr=i(rto),BMe=n(rto,"SPAN",{});var lVt=s(BMe);Ocr=r(lVt,"AutoModelForNextSentencePrediction"),lVt.forEach(t),rto.forEach(t),Veo=i(c),Go=n(c,"DIV",{class:!0});var Rl=s(Go);T(p$.$$.fragment,Rl),Vcr=i(Rl),jd=n(Rl,"P",{});var Aie=s(jd);Xcr=r(Aie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),cJ=n(Aie,"A",{href:!0});var iVt=s(cJ);zcr=r(iVt,"from_pretrained()"),iVt.forEach(t),Qcr=r(Aie," class method or the "),fJ=n(Aie,"A",{href:!0});var dVt=s(fJ);Wcr=r(dVt,"from_config()"),dVt.forEach(t),Ucr=r(Aie,` class
method.`),Aie.forEach(t),Hcr=i(Rl),_$=n(Rl,"P",{});var tto=s(_$);Jcr=r(tto,"This class cannot be instantiated directly using "),IMe=n(tto,"CODE",{});var mVt=s(IMe);Ycr=r(mVt,"__init__()"),mVt.forEach(t),Kcr=r(tto," (throws an error)."),tto.forEach(t),Zcr=i(Rl),Ct=n(Rl,"DIV",{class:!0});var p8=s(Ct);T(b$.$$.fragment,p8),efr=i(p8),NMe=n(p8,"P",{});var cVt=s(NMe);ofr=r(cVt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),cVt.forEach(t),rfr=i(p8),Dd=n(p8,"P",{});var Lie=s(Dd);tfr=r(Lie,`Note:
Loading a model from its configuration file does `),qMe=n(Lie,"STRONG",{});var fVt=s(qMe);afr=r(fVt,"not"),fVt.forEach(t),nfr=r(Lie,` load the model weights. It only affects the
model\u2019s configuration. Use `),gJ=n(Lie,"A",{href:!0});var gVt=s(gJ);sfr=r(gVt,"from_pretrained()"),gVt.forEach(t),lfr=r(Lie," to load the model weights."),Lie.forEach(t),ifr=i(p8),T(TM.$$.fragment,p8),p8.forEach(t),dfr=i(Rl),so=n(Rl,"DIV",{class:!0});var La=s(so);T(v$.$$.fragment,La),mfr=i(La),jMe=n(La,"P",{});var hVt=s(jMe);cfr=r(hVt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),hVt.forEach(t),ffr=i(La),tn=n(La,"P",{});var _8=s(tn);gfr=r(_8,"The model class to instantiate is selected based on the "),DMe=n(_8,"CODE",{});var uVt=s(DMe);hfr=r(uVt,"model_type"),uVt.forEach(t),ufr=r(_8,` property of the config object (either
passed as an argument or loaded from `),GMe=n(_8,"CODE",{});var pVt=s(GMe);pfr=r(pVt,"pretrained_model_name_or_path"),pVt.forEach(t),_fr=r(_8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),OMe=n(_8,"CODE",{});var _Vt=s(OMe);bfr=r(_Vt,"pretrained_model_name_or_path"),_Vt.forEach(t),vfr=r(_8,":"),_8.forEach(t),Ffr=i(La),Ue=n(La,"UL",{});var mt=s(Ue);MM=n(mt,"LI",{});var DXe=s(MM);VMe=n(DXe,"STRONG",{});var bVt=s(VMe);Tfr=r(bVt,"bert"),bVt.forEach(t),Mfr=r(DXe," \u2014 "),hJ=n(DXe,"A",{href:!0});var vVt=s(hJ);Efr=r(vVt,"BertForNextSentencePrediction"),vVt.forEach(t),Cfr=r(DXe," (BERT model)"),DXe.forEach(t),wfr=i(mt),EM=n(mt,"LI",{});var GXe=s(EM);XMe=n(GXe,"STRONG",{});var FVt=s(XMe);Afr=r(FVt,"ernie"),FVt.forEach(t),Lfr=r(GXe," \u2014 "),uJ=n(GXe,"A",{href:!0});var TVt=s(uJ);yfr=r(TVt,"ErnieForNextSentencePrediction"),TVt.forEach(t),xfr=r(GXe," (ERNIE model)"),GXe.forEach(t),$fr=i(mt),CM=n(mt,"LI",{});var OXe=s(CM);zMe=n(OXe,"STRONG",{});var MVt=s(zMe);kfr=r(MVt,"fnet"),MVt.forEach(t),Sfr=r(OXe," \u2014 "),pJ=n(OXe,"A",{href:!0});var EVt=s(pJ);Rfr=r(EVt,"FNetForNextSentencePrediction"),EVt.forEach(t),Pfr=r(OXe," (FNet model)"),OXe.forEach(t),Bfr=i(mt),wM=n(mt,"LI",{});var VXe=s(wM);QMe=n(VXe,"STRONG",{});var CVt=s(QMe);Ifr=r(CVt,"megatron-bert"),CVt.forEach(t),Nfr=r(VXe," \u2014 "),_J=n(VXe,"A",{href:!0});var wVt=s(_J);qfr=r(wVt,"MegatronBertForNextSentencePrediction"),wVt.forEach(t),jfr=r(VXe," (Megatron-BERT model)"),VXe.forEach(t),Dfr=i(mt),AM=n(mt,"LI",{});var XXe=s(AM);WMe=n(XXe,"STRONG",{});var AVt=s(WMe);Gfr=r(AVt,"mobilebert"),AVt.forEach(t),Ofr=r(XXe," \u2014 "),bJ=n(XXe,"A",{href:!0});var LVt=s(bJ);Vfr=r(LVt,"MobileBertForNextSentencePrediction"),LVt.forEach(t),Xfr=r(XXe," (MobileBERT model)"),XXe.forEach(t),zfr=i(mt),LM=n(mt,"LI",{});var zXe=s(LM);UMe=n(zXe,"STRONG",{});var yVt=s(UMe);Qfr=r(yVt,"nezha"),yVt.forEach(t),Wfr=r(zXe," \u2014 "),vJ=n(zXe,"A",{href:!0});var xVt=s(vJ);Ufr=r(xVt,"NezhaForNextSentencePrediction"),xVt.forEach(t),Hfr=r(zXe," (Nezha model)"),zXe.forEach(t),Jfr=i(mt),yM=n(mt,"LI",{});var QXe=s(yM);HMe=n(QXe,"STRONG",{});var $Vt=s(HMe);Yfr=r($Vt,"qdqbert"),$Vt.forEach(t),Kfr=r(QXe," \u2014 "),FJ=n(QXe,"A",{href:!0});var kVt=s(FJ);Zfr=r(kVt,"QDQBertForNextSentencePrediction"),kVt.forEach(t),egr=r(QXe," (QDQBert model)"),QXe.forEach(t),mt.forEach(t),ogr=i(La),xM=n(La,"P",{});var WXe=s(xM);rgr=r(WXe,"The model is set in evaluation mode by default using "),JMe=n(WXe,"CODE",{});var SVt=s(JMe);tgr=r(SVt,"model.eval()"),SVt.forEach(t),agr=r(WXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),YMe=n(WXe,"CODE",{});var RVt=s(YMe);ngr=r(RVt,"model.train()"),RVt.forEach(t),WXe.forEach(t),sgr=i(La),T($M.$$.fragment,La),La.forEach(t),Rl.forEach(t),Xeo=i(c),Gd=n(c,"H2",{class:!0});var ato=s(Gd);kM=n(ato,"A",{id:!0,class:!0,href:!0});var PVt=s(kM);KMe=n(PVt,"SPAN",{});var BVt=s(KMe);T(F$.$$.fragment,BVt),BVt.forEach(t),PVt.forEach(t),lgr=i(ato),ZMe=n(ato,"SPAN",{});var IVt=s(ZMe);igr=r(IVt,"AutoModelForTokenClassification"),IVt.forEach(t),ato.forEach(t),zeo=i(c),Oo=n(c,"DIV",{class:!0});var Pl=s(Oo);T(T$.$$.fragment,Pl),dgr=i(Pl),Od=n(Pl,"P",{});var yie=s(Od);mgr=r(yie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),TJ=n(yie,"A",{href:!0});var NVt=s(TJ);cgr=r(NVt,"from_pretrained()"),NVt.forEach(t),fgr=r(yie," class method or the "),MJ=n(yie,"A",{href:!0});var qVt=s(MJ);ggr=r(qVt,"from_config()"),qVt.forEach(t),hgr=r(yie,` class
method.`),yie.forEach(t),ugr=i(Pl),M$=n(Pl,"P",{});var nto=s(M$);pgr=r(nto,"This class cannot be instantiated directly using "),eEe=n(nto,"CODE",{});var jVt=s(eEe);_gr=r(jVt,"__init__()"),jVt.forEach(t),bgr=r(nto," (throws an error)."),nto.forEach(t),vgr=i(Pl),wt=n(Pl,"DIV",{class:!0});var b8=s(wt);T(E$.$$.fragment,b8),Fgr=i(b8),oEe=n(b8,"P",{});var DVt=s(oEe);Tgr=r(DVt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),DVt.forEach(t),Mgr=i(b8),Vd=n(b8,"P",{});var xie=s(Vd);Egr=r(xie,`Note:
Loading a model from its configuration file does `),rEe=n(xie,"STRONG",{});var GVt=s(rEe);Cgr=r(GVt,"not"),GVt.forEach(t),wgr=r(xie,` load the model weights. It only affects the
model\u2019s configuration. Use `),EJ=n(xie,"A",{href:!0});var OVt=s(EJ);Agr=r(OVt,"from_pretrained()"),OVt.forEach(t),Lgr=r(xie," to load the model weights."),xie.forEach(t),ygr=i(b8),T(SM.$$.fragment,b8),b8.forEach(t),xgr=i(Pl),lo=n(Pl,"DIV",{class:!0});var ya=s(lo);T(C$.$$.fragment,ya),$gr=i(ya),tEe=n(ya,"P",{});var VVt=s(tEe);kgr=r(VVt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),VVt.forEach(t),Sgr=i(ya),an=n(ya,"P",{});var v8=s(an);Rgr=r(v8,"The model class to instantiate is selected based on the "),aEe=n(v8,"CODE",{});var XVt=s(aEe);Pgr=r(XVt,"model_type"),XVt.forEach(t),Bgr=r(v8,` property of the config object (either
passed as an argument or loaded from `),nEe=n(v8,"CODE",{});var zVt=s(nEe);Igr=r(zVt,"pretrained_model_name_or_path"),zVt.forEach(t),Ngr=r(v8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sEe=n(v8,"CODE",{});var QVt=s(sEe);qgr=r(QVt,"pretrained_model_name_or_path"),QVt.forEach(t),jgr=r(v8,":"),v8.forEach(t),Dgr=i(ya),H=n(ya,"UL",{});var Y=s(H);RM=n(Y,"LI",{});var UXe=s(RM);lEe=n(UXe,"STRONG",{});var WVt=s(lEe);Ggr=r(WVt,"albert"),WVt.forEach(t),Ogr=r(UXe," \u2014 "),CJ=n(UXe,"A",{href:!0});var UVt=s(CJ);Vgr=r(UVt,"AlbertForTokenClassification"),UVt.forEach(t),Xgr=r(UXe," (ALBERT model)"),UXe.forEach(t),zgr=i(Y),PM=n(Y,"LI",{});var HXe=s(PM);iEe=n(HXe,"STRONG",{});var HVt=s(iEe);Qgr=r(HVt,"bert"),HVt.forEach(t),Wgr=r(HXe," \u2014 "),wJ=n(HXe,"A",{href:!0});var JVt=s(wJ);Ugr=r(JVt,"BertForTokenClassification"),JVt.forEach(t),Hgr=r(HXe," (BERT model)"),HXe.forEach(t),Jgr=i(Y),BM=n(Y,"LI",{});var JXe=s(BM);dEe=n(JXe,"STRONG",{});var YVt=s(dEe);Ygr=r(YVt,"big_bird"),YVt.forEach(t),Kgr=r(JXe," \u2014 "),AJ=n(JXe,"A",{href:!0});var KVt=s(AJ);Zgr=r(KVt,"BigBirdForTokenClassification"),KVt.forEach(t),ehr=r(JXe," (BigBird model)"),JXe.forEach(t),ohr=i(Y),IM=n(Y,"LI",{});var YXe=s(IM);mEe=n(YXe,"STRONG",{});var ZVt=s(mEe);rhr=r(ZVt,"bloom"),ZVt.forEach(t),thr=r(YXe," \u2014 "),LJ=n(YXe,"A",{href:!0});var eXt=s(LJ);ahr=r(eXt,"BloomForTokenClassification"),eXt.forEach(t),nhr=r(YXe," (BLOOM model)"),YXe.forEach(t),shr=i(Y),NM=n(Y,"LI",{});var KXe=s(NM);cEe=n(KXe,"STRONG",{});var oXt=s(cEe);lhr=r(oXt,"camembert"),oXt.forEach(t),ihr=r(KXe," \u2014 "),yJ=n(KXe,"A",{href:!0});var rXt=s(yJ);dhr=r(rXt,"CamembertForTokenClassification"),rXt.forEach(t),mhr=r(KXe," (CamemBERT model)"),KXe.forEach(t),chr=i(Y),qM=n(Y,"LI",{});var ZXe=s(qM);fEe=n(ZXe,"STRONG",{});var tXt=s(fEe);fhr=r(tXt,"canine"),tXt.forEach(t),ghr=r(ZXe," \u2014 "),xJ=n(ZXe,"A",{href:!0});var aXt=s(xJ);hhr=r(aXt,"CanineForTokenClassification"),aXt.forEach(t),uhr=r(ZXe," (CANINE model)"),ZXe.forEach(t),phr=i(Y),jM=n(Y,"LI",{});var eze=s(jM);gEe=n(eze,"STRONG",{});var nXt=s(gEe);_hr=r(nXt,"convbert"),nXt.forEach(t),bhr=r(eze," \u2014 "),$J=n(eze,"A",{href:!0});var sXt=s($J);vhr=r(sXt,"ConvBertForTokenClassification"),sXt.forEach(t),Fhr=r(eze," (ConvBERT model)"),eze.forEach(t),Thr=i(Y),DM=n(Y,"LI",{});var oze=s(DM);hEe=n(oze,"STRONG",{});var lXt=s(hEe);Mhr=r(lXt,"data2vec-text"),lXt.forEach(t),Ehr=r(oze," \u2014 "),kJ=n(oze,"A",{href:!0});var iXt=s(kJ);Chr=r(iXt,"Data2VecTextForTokenClassification"),iXt.forEach(t),whr=r(oze," (Data2VecText model)"),oze.forEach(t),Ahr=i(Y),GM=n(Y,"LI",{});var rze=s(GM);uEe=n(rze,"STRONG",{});var dXt=s(uEe);Lhr=r(dXt,"deberta"),dXt.forEach(t),yhr=r(rze," \u2014 "),SJ=n(rze,"A",{href:!0});var mXt=s(SJ);xhr=r(mXt,"DebertaForTokenClassification"),mXt.forEach(t),$hr=r(rze," (DeBERTa model)"),rze.forEach(t),khr=i(Y),OM=n(Y,"LI",{});var tze=s(OM);pEe=n(tze,"STRONG",{});var cXt=s(pEe);Shr=r(cXt,"deberta-v2"),cXt.forEach(t),Rhr=r(tze," \u2014 "),RJ=n(tze,"A",{href:!0});var fXt=s(RJ);Phr=r(fXt,"DebertaV2ForTokenClassification"),fXt.forEach(t),Bhr=r(tze," (DeBERTa-v2 model)"),tze.forEach(t),Ihr=i(Y),VM=n(Y,"LI",{});var aze=s(VM);_Ee=n(aze,"STRONG",{});var gXt=s(_Ee);Nhr=r(gXt,"distilbert"),gXt.forEach(t),qhr=r(aze," \u2014 "),PJ=n(aze,"A",{href:!0});var hXt=s(PJ);jhr=r(hXt,"DistilBertForTokenClassification"),hXt.forEach(t),Dhr=r(aze," (DistilBERT model)"),aze.forEach(t),Ghr=i(Y),XM=n(Y,"LI",{});var nze=s(XM);bEe=n(nze,"STRONG",{});var uXt=s(bEe);Ohr=r(uXt,"electra"),uXt.forEach(t),Vhr=r(nze," \u2014 "),BJ=n(nze,"A",{href:!0});var pXt=s(BJ);Xhr=r(pXt,"ElectraForTokenClassification"),pXt.forEach(t),zhr=r(nze," (ELECTRA model)"),nze.forEach(t),Qhr=i(Y),zM=n(Y,"LI",{});var sze=s(zM);vEe=n(sze,"STRONG",{});var _Xt=s(vEe);Whr=r(_Xt,"ernie"),_Xt.forEach(t),Uhr=r(sze," \u2014 "),IJ=n(sze,"A",{href:!0});var bXt=s(IJ);Hhr=r(bXt,"ErnieForTokenClassification"),bXt.forEach(t),Jhr=r(sze," (ERNIE model)"),sze.forEach(t),Yhr=i(Y),QM=n(Y,"LI",{});var lze=s(QM);FEe=n(lze,"STRONG",{});var vXt=s(FEe);Khr=r(vXt,"esm"),vXt.forEach(t),Zhr=r(lze," \u2014 "),NJ=n(lze,"A",{href:!0});var FXt=s(NJ);eur=r(FXt,"EsmForTokenClassification"),FXt.forEach(t),our=r(lze," (ESM model)"),lze.forEach(t),rur=i(Y),WM=n(Y,"LI",{});var ize=s(WM);TEe=n(ize,"STRONG",{});var TXt=s(TEe);tur=r(TXt,"flaubert"),TXt.forEach(t),aur=r(ize," \u2014 "),qJ=n(ize,"A",{href:!0});var MXt=s(qJ);nur=r(MXt,"FlaubertForTokenClassification"),MXt.forEach(t),sur=r(ize," (FlauBERT model)"),ize.forEach(t),lur=i(Y),UM=n(Y,"LI",{});var dze=s(UM);MEe=n(dze,"STRONG",{});var EXt=s(MEe);iur=r(EXt,"fnet"),EXt.forEach(t),dur=r(dze," \u2014 "),jJ=n(dze,"A",{href:!0});var CXt=s(jJ);mur=r(CXt,"FNetForTokenClassification"),CXt.forEach(t),cur=r(dze," (FNet model)"),dze.forEach(t),fur=i(Y),HM=n(Y,"LI",{});var mze=s(HM);EEe=n(mze,"STRONG",{});var wXt=s(EEe);gur=r(wXt,"funnel"),wXt.forEach(t),hur=r(mze," \u2014 "),DJ=n(mze,"A",{href:!0});var AXt=s(DJ);uur=r(AXt,"FunnelForTokenClassification"),AXt.forEach(t),pur=r(mze," (Funnel Transformer model)"),mze.forEach(t),_ur=i(Y),JM=n(Y,"LI",{});var cze=s(JM);CEe=n(cze,"STRONG",{});var LXt=s(CEe);bur=r(LXt,"gpt2"),LXt.forEach(t),vur=r(cze," \u2014 "),GJ=n(cze,"A",{href:!0});var yXt=s(GJ);Fur=r(yXt,"GPT2ForTokenClassification"),yXt.forEach(t),Tur=r(cze," (OpenAI GPT-2 model)"),cze.forEach(t),Mur=i(Y),YM=n(Y,"LI",{});var fze=s(YM);wEe=n(fze,"STRONG",{});var xXt=s(wEe);Eur=r(xXt,"ibert"),xXt.forEach(t),Cur=r(fze," \u2014 "),OJ=n(fze,"A",{href:!0});var $Xt=s(OJ);wur=r($Xt,"IBertForTokenClassification"),$Xt.forEach(t),Aur=r(fze," (I-BERT model)"),fze.forEach(t),Lur=i(Y),KM=n(Y,"LI",{});var gze=s(KM);AEe=n(gze,"STRONG",{});var kXt=s(AEe);yur=r(kXt,"layoutlm"),kXt.forEach(t),xur=r(gze," \u2014 "),VJ=n(gze,"A",{href:!0});var SXt=s(VJ);$ur=r(SXt,"LayoutLMForTokenClassification"),SXt.forEach(t),kur=r(gze," (LayoutLM model)"),gze.forEach(t),Sur=i(Y),ZM=n(Y,"LI",{});var hze=s(ZM);LEe=n(hze,"STRONG",{});var RXt=s(LEe);Rur=r(RXt,"layoutlmv2"),RXt.forEach(t),Pur=r(hze," \u2014 "),XJ=n(hze,"A",{href:!0});var PXt=s(XJ);Bur=r(PXt,"LayoutLMv2ForTokenClassification"),PXt.forEach(t),Iur=r(hze," (LayoutLMv2 model)"),hze.forEach(t),Nur=i(Y),eE=n(Y,"LI",{});var uze=s(eE);yEe=n(uze,"STRONG",{});var BXt=s(yEe);qur=r(BXt,"layoutlmv3"),BXt.forEach(t),jur=r(uze," \u2014 "),zJ=n(uze,"A",{href:!0});var IXt=s(zJ);Dur=r(IXt,"LayoutLMv3ForTokenClassification"),IXt.forEach(t),Gur=r(uze," (LayoutLMv3 model)"),uze.forEach(t),Our=i(Y),oE=n(Y,"LI",{});var pze=s(oE);xEe=n(pze,"STRONG",{});var NXt=s(xEe);Vur=r(NXt,"longformer"),NXt.forEach(t),Xur=r(pze," \u2014 "),QJ=n(pze,"A",{href:!0});var qXt=s(QJ);zur=r(qXt,"LongformerForTokenClassification"),qXt.forEach(t),Qur=r(pze," (Longformer model)"),pze.forEach(t),Wur=i(Y),rE=n(Y,"LI",{});var _ze=s(rE);$Ee=n(_ze,"STRONG",{});var jXt=s($Ee);Uur=r(jXt,"luke"),jXt.forEach(t),Hur=r(_ze," \u2014 "),WJ=n(_ze,"A",{href:!0});var DXt=s(WJ);Jur=r(DXt,"LukeForTokenClassification"),DXt.forEach(t),Yur=r(_ze," (LUKE model)"),_ze.forEach(t),Kur=i(Y),tE=n(Y,"LI",{});var bze=s(tE);kEe=n(bze,"STRONG",{});var GXt=s(kEe);Zur=r(GXt,"markuplm"),GXt.forEach(t),epr=r(bze," \u2014 "),UJ=n(bze,"A",{href:!0});var OXt=s(UJ);opr=r(OXt,"MarkupLMForTokenClassification"),OXt.forEach(t),rpr=r(bze," (MarkupLM model)"),bze.forEach(t),tpr=i(Y),aE=n(Y,"LI",{});var vze=s(aE);SEe=n(vze,"STRONG",{});var VXt=s(SEe);apr=r(VXt,"megatron-bert"),VXt.forEach(t),npr=r(vze," \u2014 "),HJ=n(vze,"A",{href:!0});var XXt=s(HJ);spr=r(XXt,"MegatronBertForTokenClassification"),XXt.forEach(t),lpr=r(vze," (Megatron-BERT model)"),vze.forEach(t),ipr=i(Y),nE=n(Y,"LI",{});var Fze=s(nE);REe=n(Fze,"STRONG",{});var zXt=s(REe);dpr=r(zXt,"mobilebert"),zXt.forEach(t),mpr=r(Fze," \u2014 "),JJ=n(Fze,"A",{href:!0});var QXt=s(JJ);cpr=r(QXt,"MobileBertForTokenClassification"),QXt.forEach(t),fpr=r(Fze," (MobileBERT model)"),Fze.forEach(t),gpr=i(Y),sE=n(Y,"LI",{});var Tze=s(sE);PEe=n(Tze,"STRONG",{});var WXt=s(PEe);hpr=r(WXt,"mpnet"),WXt.forEach(t),upr=r(Tze," \u2014 "),YJ=n(Tze,"A",{href:!0});var UXt=s(YJ);ppr=r(UXt,"MPNetForTokenClassification"),UXt.forEach(t),_pr=r(Tze," (MPNet model)"),Tze.forEach(t),bpr=i(Y),lE=n(Y,"LI",{});var Mze=s(lE);BEe=n(Mze,"STRONG",{});var HXt=s(BEe);vpr=r(HXt,"nezha"),HXt.forEach(t),Fpr=r(Mze," \u2014 "),KJ=n(Mze,"A",{href:!0});var JXt=s(KJ);Tpr=r(JXt,"NezhaForTokenClassification"),JXt.forEach(t),Mpr=r(Mze," (Nezha model)"),Mze.forEach(t),Epr=i(Y),iE=n(Y,"LI",{});var Eze=s(iE);IEe=n(Eze,"STRONG",{});var YXt=s(IEe);Cpr=r(YXt,"nystromformer"),YXt.forEach(t),wpr=r(Eze," \u2014 "),ZJ=n(Eze,"A",{href:!0});var KXt=s(ZJ);Apr=r(KXt,"NystromformerForTokenClassification"),KXt.forEach(t),Lpr=r(Eze," (Nystr\xF6mformer model)"),Eze.forEach(t),ypr=i(Y),dE=n(Y,"LI",{});var Cze=s(dE);NEe=n(Cze,"STRONG",{});var ZXt=s(NEe);xpr=r(ZXt,"qdqbert"),ZXt.forEach(t),$pr=r(Cze," \u2014 "),eY=n(Cze,"A",{href:!0});var ezt=s(eY);kpr=r(ezt,"QDQBertForTokenClassification"),ezt.forEach(t),Spr=r(Cze," (QDQBert model)"),Cze.forEach(t),Rpr=i(Y),mE=n(Y,"LI",{});var wze=s(mE);qEe=n(wze,"STRONG",{});var ozt=s(qEe);Ppr=r(ozt,"rembert"),ozt.forEach(t),Bpr=r(wze," \u2014 "),oY=n(wze,"A",{href:!0});var rzt=s(oY);Ipr=r(rzt,"RemBertForTokenClassification"),rzt.forEach(t),Npr=r(wze," (RemBERT model)"),wze.forEach(t),qpr=i(Y),cE=n(Y,"LI",{});var Aze=s(cE);jEe=n(Aze,"STRONG",{});var tzt=s(jEe);jpr=r(tzt,"roberta"),tzt.forEach(t),Dpr=r(Aze," \u2014 "),rY=n(Aze,"A",{href:!0});var azt=s(rY);Gpr=r(azt,"RobertaForTokenClassification"),azt.forEach(t),Opr=r(Aze," (RoBERTa model)"),Aze.forEach(t),Vpr=i(Y),fE=n(Y,"LI",{});var Lze=s(fE);DEe=n(Lze,"STRONG",{});var nzt=s(DEe);Xpr=r(nzt,"roformer"),nzt.forEach(t),zpr=r(Lze," \u2014 "),tY=n(Lze,"A",{href:!0});var szt=s(tY);Qpr=r(szt,"RoFormerForTokenClassification"),szt.forEach(t),Wpr=r(Lze," (RoFormer model)"),Lze.forEach(t),Upr=i(Y),gE=n(Y,"LI",{});var yze=s(gE);GEe=n(yze,"STRONG",{});var lzt=s(GEe);Hpr=r(lzt,"squeezebert"),lzt.forEach(t),Jpr=r(yze," \u2014 "),aY=n(yze,"A",{href:!0});var izt=s(aY);Ypr=r(izt,"SqueezeBertForTokenClassification"),izt.forEach(t),Kpr=r(yze," (SqueezeBERT model)"),yze.forEach(t),Zpr=i(Y),hE=n(Y,"LI",{});var xze=s(hE);OEe=n(xze,"STRONG",{});var dzt=s(OEe);e_r=r(dzt,"xlm"),dzt.forEach(t),o_r=r(xze," \u2014 "),nY=n(xze,"A",{href:!0});var mzt=s(nY);r_r=r(mzt,"XLMForTokenClassification"),mzt.forEach(t),t_r=r(xze," (XLM model)"),xze.forEach(t),a_r=i(Y),uE=n(Y,"LI",{});var $ze=s(uE);VEe=n($ze,"STRONG",{});var czt=s(VEe);n_r=r(czt,"xlm-roberta"),czt.forEach(t),s_r=r($ze," \u2014 "),sY=n($ze,"A",{href:!0});var fzt=s(sY);l_r=r(fzt,"XLMRobertaForTokenClassification"),fzt.forEach(t),i_r=r($ze," (XLM-RoBERTa model)"),$ze.forEach(t),d_r=i(Y),pE=n(Y,"LI",{});var kze=s(pE);XEe=n(kze,"STRONG",{});var gzt=s(XEe);m_r=r(gzt,"xlm-roberta-xl"),gzt.forEach(t),c_r=r(kze," \u2014 "),lY=n(kze,"A",{href:!0});var hzt=s(lY);f_r=r(hzt,"XLMRobertaXLForTokenClassification"),hzt.forEach(t),g_r=r(kze," (XLM-RoBERTa-XL model)"),kze.forEach(t),h_r=i(Y),_E=n(Y,"LI",{});var Sze=s(_E);zEe=n(Sze,"STRONG",{});var uzt=s(zEe);u_r=r(uzt,"xlnet"),uzt.forEach(t),p_r=r(Sze," \u2014 "),iY=n(Sze,"A",{href:!0});var pzt=s(iY);__r=r(pzt,"XLNetForTokenClassification"),pzt.forEach(t),b_r=r(Sze," (XLNet model)"),Sze.forEach(t),v_r=i(Y),bE=n(Y,"LI",{});var Rze=s(bE);QEe=n(Rze,"STRONG",{});var _zt=s(QEe);F_r=r(_zt,"yoso"),_zt.forEach(t),T_r=r(Rze," \u2014 "),dY=n(Rze,"A",{href:!0});var bzt=s(dY);M_r=r(bzt,"YosoForTokenClassification"),bzt.forEach(t),E_r=r(Rze," (YOSO model)"),Rze.forEach(t),Y.forEach(t),C_r=i(ya),vE=n(ya,"P",{});var Pze=s(vE);w_r=r(Pze,"The model is set in evaluation mode by default using "),WEe=n(Pze,"CODE",{});var vzt=s(WEe);A_r=r(vzt,"model.eval()"),vzt.forEach(t),L_r=r(Pze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),UEe=n(Pze,"CODE",{});var Fzt=s(UEe);y_r=r(Fzt,"model.train()"),Fzt.forEach(t),Pze.forEach(t),x_r=i(ya),T(FE.$$.fragment,ya),ya.forEach(t),Pl.forEach(t),Qeo=i(c),Xd=n(c,"H2",{class:!0});var sto=s(Xd);TE=n(sto,"A",{id:!0,class:!0,href:!0});var Tzt=s(TE);HEe=n(Tzt,"SPAN",{});var Mzt=s(HEe);T(w$.$$.fragment,Mzt),Mzt.forEach(t),Tzt.forEach(t),$_r=i(sto),JEe=n(sto,"SPAN",{});var Ezt=s(JEe);k_r=r(Ezt,"AutoModelForQuestionAnswering"),Ezt.forEach(t),sto.forEach(t),Weo=i(c),Vo=n(c,"DIV",{class:!0});var Bl=s(Vo);T(A$.$$.fragment,Bl),S_r=i(Bl),zd=n(Bl,"P",{});var $ie=s(zd);R_r=r($ie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),mY=n($ie,"A",{href:!0});var Czt=s(mY);P_r=r(Czt,"from_pretrained()"),Czt.forEach(t),B_r=r($ie," class method or the "),cY=n($ie,"A",{href:!0});var wzt=s(cY);I_r=r(wzt,"from_config()"),wzt.forEach(t),N_r=r($ie,` class
method.`),$ie.forEach(t),q_r=i(Bl),L$=n(Bl,"P",{});var lto=s(L$);j_r=r(lto,"This class cannot be instantiated directly using "),YEe=n(lto,"CODE",{});var Azt=s(YEe);D_r=r(Azt,"__init__()"),Azt.forEach(t),G_r=r(lto," (throws an error)."),lto.forEach(t),O_r=i(Bl),At=n(Bl,"DIV",{class:!0});var F8=s(At);T(y$.$$.fragment,F8),V_r=i(F8),KEe=n(F8,"P",{});var Lzt=s(KEe);X_r=r(Lzt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Lzt.forEach(t),z_r=i(F8),Qd=n(F8,"P",{});var kie=s(Qd);Q_r=r(kie,`Note:
Loading a model from its configuration file does `),ZEe=n(kie,"STRONG",{});var yzt=s(ZEe);W_r=r(yzt,"not"),yzt.forEach(t),U_r=r(kie,` load the model weights. It only affects the
model\u2019s configuration. Use `),fY=n(kie,"A",{href:!0});var xzt=s(fY);H_r=r(xzt,"from_pretrained()"),xzt.forEach(t),J_r=r(kie," to load the model weights."),kie.forEach(t),Y_r=i(F8),T(ME.$$.fragment,F8),F8.forEach(t),K_r=i(Bl),io=n(Bl,"DIV",{class:!0});var xa=s(io);T(x$.$$.fragment,xa),Z_r=i(xa),e4e=n(xa,"P",{});var $zt=s(e4e);e1r=r($zt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),$zt.forEach(t),o1r=i(xa),nn=n(xa,"P",{});var T8=s(nn);r1r=r(T8,"The model class to instantiate is selected based on the "),o4e=n(T8,"CODE",{});var kzt=s(o4e);t1r=r(kzt,"model_type"),kzt.forEach(t),a1r=r(T8,` property of the config object (either
passed as an argument or loaded from `),r4e=n(T8,"CODE",{});var Szt=s(r4e);n1r=r(Szt,"pretrained_model_name_or_path"),Szt.forEach(t),s1r=r(T8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t4e=n(T8,"CODE",{});var Rzt=s(t4e);l1r=r(Rzt,"pretrained_model_name_or_path"),Rzt.forEach(t),i1r=r(T8,":"),T8.forEach(t),d1r=i(xa),V=n(xa,"UL",{});var X=s(V);EE=n(X,"LI",{});var Bze=s(EE);a4e=n(Bze,"STRONG",{});var Pzt=s(a4e);m1r=r(Pzt,"albert"),Pzt.forEach(t),c1r=r(Bze," \u2014 "),gY=n(Bze,"A",{href:!0});var Bzt=s(gY);f1r=r(Bzt,"AlbertForQuestionAnswering"),Bzt.forEach(t),g1r=r(Bze," (ALBERT model)"),Bze.forEach(t),h1r=i(X),CE=n(X,"LI",{});var Ize=s(CE);n4e=n(Ize,"STRONG",{});var Izt=s(n4e);u1r=r(Izt,"bart"),Izt.forEach(t),p1r=r(Ize," \u2014 "),hY=n(Ize,"A",{href:!0});var Nzt=s(hY);_1r=r(Nzt,"BartForQuestionAnswering"),Nzt.forEach(t),b1r=r(Ize," (BART model)"),Ize.forEach(t),v1r=i(X),wE=n(X,"LI",{});var Nze=s(wE);s4e=n(Nze,"STRONG",{});var qzt=s(s4e);F1r=r(qzt,"bert"),qzt.forEach(t),T1r=r(Nze," \u2014 "),uY=n(Nze,"A",{href:!0});var jzt=s(uY);M1r=r(jzt,"BertForQuestionAnswering"),jzt.forEach(t),E1r=r(Nze," (BERT model)"),Nze.forEach(t),C1r=i(X),AE=n(X,"LI",{});var qze=s(AE);l4e=n(qze,"STRONG",{});var Dzt=s(l4e);w1r=r(Dzt,"big_bird"),Dzt.forEach(t),A1r=r(qze," \u2014 "),pY=n(qze,"A",{href:!0});var Gzt=s(pY);L1r=r(Gzt,"BigBirdForQuestionAnswering"),Gzt.forEach(t),y1r=r(qze," (BigBird model)"),qze.forEach(t),x1r=i(X),LE=n(X,"LI",{});var jze=s(LE);i4e=n(jze,"STRONG",{});var Ozt=s(i4e);$1r=r(Ozt,"bigbird_pegasus"),Ozt.forEach(t),k1r=r(jze," \u2014 "),_Y=n(jze,"A",{href:!0});var Vzt=s(_Y);S1r=r(Vzt,"BigBirdPegasusForQuestionAnswering"),Vzt.forEach(t),R1r=r(jze," (BigBird-Pegasus model)"),jze.forEach(t),P1r=i(X),yE=n(X,"LI",{});var Dze=s(yE);d4e=n(Dze,"STRONG",{});var Xzt=s(d4e);B1r=r(Xzt,"bloom"),Xzt.forEach(t),I1r=r(Dze," \u2014 "),bY=n(Dze,"A",{href:!0});var zzt=s(bY);N1r=r(zzt,"BloomForQuestionAnswering"),zzt.forEach(t),q1r=r(Dze," (BLOOM model)"),Dze.forEach(t),j1r=i(X),xE=n(X,"LI",{});var Gze=s(xE);m4e=n(Gze,"STRONG",{});var Qzt=s(m4e);D1r=r(Qzt,"camembert"),Qzt.forEach(t),G1r=r(Gze," \u2014 "),vY=n(Gze,"A",{href:!0});var Wzt=s(vY);O1r=r(Wzt,"CamembertForQuestionAnswering"),Wzt.forEach(t),V1r=r(Gze," (CamemBERT model)"),Gze.forEach(t),X1r=i(X),$E=n(X,"LI",{});var Oze=s($E);c4e=n(Oze,"STRONG",{});var Uzt=s(c4e);z1r=r(Uzt,"canine"),Uzt.forEach(t),Q1r=r(Oze," \u2014 "),FY=n(Oze,"A",{href:!0});var Hzt=s(FY);W1r=r(Hzt,"CanineForQuestionAnswering"),Hzt.forEach(t),U1r=r(Oze," (CANINE model)"),Oze.forEach(t),H1r=i(X),kE=n(X,"LI",{});var Vze=s(kE);f4e=n(Vze,"STRONG",{});var Jzt=s(f4e);J1r=r(Jzt,"convbert"),Jzt.forEach(t),Y1r=r(Vze," \u2014 "),TY=n(Vze,"A",{href:!0});var Yzt=s(TY);K1r=r(Yzt,"ConvBertForQuestionAnswering"),Yzt.forEach(t),Z1r=r(Vze," (ConvBERT model)"),Vze.forEach(t),e2r=i(X),SE=n(X,"LI",{});var Xze=s(SE);g4e=n(Xze,"STRONG",{});var Kzt=s(g4e);o2r=r(Kzt,"data2vec-text"),Kzt.forEach(t),r2r=r(Xze," \u2014 "),MY=n(Xze,"A",{href:!0});var Zzt=s(MY);t2r=r(Zzt,"Data2VecTextForQuestionAnswering"),Zzt.forEach(t),a2r=r(Xze," (Data2VecText model)"),Xze.forEach(t),n2r=i(X),RE=n(X,"LI",{});var zze=s(RE);h4e=n(zze,"STRONG",{});var eQt=s(h4e);s2r=r(eQt,"deberta"),eQt.forEach(t),l2r=r(zze," \u2014 "),EY=n(zze,"A",{href:!0});var oQt=s(EY);i2r=r(oQt,"DebertaForQuestionAnswering"),oQt.forEach(t),d2r=r(zze," (DeBERTa model)"),zze.forEach(t),m2r=i(X),PE=n(X,"LI",{});var Qze=s(PE);u4e=n(Qze,"STRONG",{});var rQt=s(u4e);c2r=r(rQt,"deberta-v2"),rQt.forEach(t),f2r=r(Qze," \u2014 "),CY=n(Qze,"A",{href:!0});var tQt=s(CY);g2r=r(tQt,"DebertaV2ForQuestionAnswering"),tQt.forEach(t),h2r=r(Qze," (DeBERTa-v2 model)"),Qze.forEach(t),u2r=i(X),BE=n(X,"LI",{});var Wze=s(BE);p4e=n(Wze,"STRONG",{});var aQt=s(p4e);p2r=r(aQt,"distilbert"),aQt.forEach(t),_2r=r(Wze," \u2014 "),wY=n(Wze,"A",{href:!0});var nQt=s(wY);b2r=r(nQt,"DistilBertForQuestionAnswering"),nQt.forEach(t),v2r=r(Wze," (DistilBERT model)"),Wze.forEach(t),F2r=i(X),IE=n(X,"LI",{});var Uze=s(IE);_4e=n(Uze,"STRONG",{});var sQt=s(_4e);T2r=r(sQt,"electra"),sQt.forEach(t),M2r=r(Uze," \u2014 "),AY=n(Uze,"A",{href:!0});var lQt=s(AY);E2r=r(lQt,"ElectraForQuestionAnswering"),lQt.forEach(t),C2r=r(Uze," (ELECTRA model)"),Uze.forEach(t),w2r=i(X),NE=n(X,"LI",{});var Hze=s(NE);b4e=n(Hze,"STRONG",{});var iQt=s(b4e);A2r=r(iQt,"ernie"),iQt.forEach(t),L2r=r(Hze," \u2014 "),LY=n(Hze,"A",{href:!0});var dQt=s(LY);y2r=r(dQt,"ErnieForQuestionAnswering"),dQt.forEach(t),x2r=r(Hze," (ERNIE model)"),Hze.forEach(t),$2r=i(X),qE=n(X,"LI",{});var Jze=s(qE);v4e=n(Jze,"STRONG",{});var mQt=s(v4e);k2r=r(mQt,"flaubert"),mQt.forEach(t),S2r=r(Jze," \u2014 "),yY=n(Jze,"A",{href:!0});var cQt=s(yY);R2r=r(cQt,"FlaubertForQuestionAnsweringSimple"),cQt.forEach(t),P2r=r(Jze," (FlauBERT model)"),Jze.forEach(t),B2r=i(X),jE=n(X,"LI",{});var Yze=s(jE);F4e=n(Yze,"STRONG",{});var fQt=s(F4e);I2r=r(fQt,"fnet"),fQt.forEach(t),N2r=r(Yze," \u2014 "),xY=n(Yze,"A",{href:!0});var gQt=s(xY);q2r=r(gQt,"FNetForQuestionAnswering"),gQt.forEach(t),j2r=r(Yze," (FNet model)"),Yze.forEach(t),D2r=i(X),DE=n(X,"LI",{});var Kze=s(DE);T4e=n(Kze,"STRONG",{});var hQt=s(T4e);G2r=r(hQt,"funnel"),hQt.forEach(t),O2r=r(Kze," \u2014 "),$Y=n(Kze,"A",{href:!0});var uQt=s($Y);V2r=r(uQt,"FunnelForQuestionAnswering"),uQt.forEach(t),X2r=r(Kze," (Funnel Transformer model)"),Kze.forEach(t),z2r=i(X),GE=n(X,"LI",{});var Zze=s(GE);M4e=n(Zze,"STRONG",{});var pQt=s(M4e);Q2r=r(pQt,"gptj"),pQt.forEach(t),W2r=r(Zze," \u2014 "),kY=n(Zze,"A",{href:!0});var _Qt=s(kY);U2r=r(_Qt,"GPTJForQuestionAnswering"),_Qt.forEach(t),H2r=r(Zze," (GPT-J model)"),Zze.forEach(t),J2r=i(X),OE=n(X,"LI",{});var eQe=s(OE);E4e=n(eQe,"STRONG",{});var bQt=s(E4e);Y2r=r(bQt,"ibert"),bQt.forEach(t),K2r=r(eQe," \u2014 "),SY=n(eQe,"A",{href:!0});var vQt=s(SY);Z2r=r(vQt,"IBertForQuestionAnswering"),vQt.forEach(t),ebr=r(eQe," (I-BERT model)"),eQe.forEach(t),obr=i(X),VE=n(X,"LI",{});var oQe=s(VE);C4e=n(oQe,"STRONG",{});var FQt=s(C4e);rbr=r(FQt,"layoutlmv2"),FQt.forEach(t),tbr=r(oQe," \u2014 "),RY=n(oQe,"A",{href:!0});var TQt=s(RY);abr=r(TQt,"LayoutLMv2ForQuestionAnswering"),TQt.forEach(t),nbr=r(oQe," (LayoutLMv2 model)"),oQe.forEach(t),sbr=i(X),XE=n(X,"LI",{});var rQe=s(XE);w4e=n(rQe,"STRONG",{});var MQt=s(w4e);lbr=r(MQt,"layoutlmv3"),MQt.forEach(t),ibr=r(rQe," \u2014 "),PY=n(rQe,"A",{href:!0});var EQt=s(PY);dbr=r(EQt,"LayoutLMv3ForQuestionAnswering"),EQt.forEach(t),mbr=r(rQe," (LayoutLMv3 model)"),rQe.forEach(t),cbr=i(X),zE=n(X,"LI",{});var tQe=s(zE);A4e=n(tQe,"STRONG",{});var CQt=s(A4e);fbr=r(CQt,"led"),CQt.forEach(t),gbr=r(tQe," \u2014 "),BY=n(tQe,"A",{href:!0});var wQt=s(BY);hbr=r(wQt,"LEDForQuestionAnswering"),wQt.forEach(t),ubr=r(tQe," (LED model)"),tQe.forEach(t),pbr=i(X),QE=n(X,"LI",{});var aQe=s(QE);L4e=n(aQe,"STRONG",{});var AQt=s(L4e);_br=r(AQt,"longformer"),AQt.forEach(t),bbr=r(aQe," \u2014 "),IY=n(aQe,"A",{href:!0});var LQt=s(IY);vbr=r(LQt,"LongformerForQuestionAnswering"),LQt.forEach(t),Fbr=r(aQe," (Longformer model)"),aQe.forEach(t),Tbr=i(X),WE=n(X,"LI",{});var nQe=s(WE);y4e=n(nQe,"STRONG",{});var yQt=s(y4e);Mbr=r(yQt,"luke"),yQt.forEach(t),Ebr=r(nQe," \u2014 "),NY=n(nQe,"A",{href:!0});var xQt=s(NY);Cbr=r(xQt,"LukeForQuestionAnswering"),xQt.forEach(t),wbr=r(nQe," (LUKE model)"),nQe.forEach(t),Abr=i(X),UE=n(X,"LI",{});var sQe=s(UE);x4e=n(sQe,"STRONG",{});var $Qt=s(x4e);Lbr=r($Qt,"lxmert"),$Qt.forEach(t),ybr=r(sQe," \u2014 "),qY=n(sQe,"A",{href:!0});var kQt=s(qY);xbr=r(kQt,"LxmertForQuestionAnswering"),kQt.forEach(t),$br=r(sQe," (LXMERT model)"),sQe.forEach(t),kbr=i(X),HE=n(X,"LI",{});var lQe=s(HE);$4e=n(lQe,"STRONG",{});var SQt=s($4e);Sbr=r(SQt,"markuplm"),SQt.forEach(t),Rbr=r(lQe," \u2014 "),jY=n(lQe,"A",{href:!0});var RQt=s(jY);Pbr=r(RQt,"MarkupLMForQuestionAnswering"),RQt.forEach(t),Bbr=r(lQe," (MarkupLM model)"),lQe.forEach(t),Ibr=i(X),JE=n(X,"LI",{});var iQe=s(JE);k4e=n(iQe,"STRONG",{});var PQt=s(k4e);Nbr=r(PQt,"mbart"),PQt.forEach(t),qbr=r(iQe," \u2014 "),DY=n(iQe,"A",{href:!0});var BQt=s(DY);jbr=r(BQt,"MBartForQuestionAnswering"),BQt.forEach(t),Dbr=r(iQe," (mBART model)"),iQe.forEach(t),Gbr=i(X),YE=n(X,"LI",{});var dQe=s(YE);S4e=n(dQe,"STRONG",{});var IQt=s(S4e);Obr=r(IQt,"megatron-bert"),IQt.forEach(t),Vbr=r(dQe," \u2014 "),GY=n(dQe,"A",{href:!0});var NQt=s(GY);Xbr=r(NQt,"MegatronBertForQuestionAnswering"),NQt.forEach(t),zbr=r(dQe," (Megatron-BERT model)"),dQe.forEach(t),Qbr=i(X),KE=n(X,"LI",{});var mQe=s(KE);R4e=n(mQe,"STRONG",{});var qQt=s(R4e);Wbr=r(qQt,"mobilebert"),qQt.forEach(t),Ubr=r(mQe," \u2014 "),OY=n(mQe,"A",{href:!0});var jQt=s(OY);Hbr=r(jQt,"MobileBertForQuestionAnswering"),jQt.forEach(t),Jbr=r(mQe," (MobileBERT model)"),mQe.forEach(t),Ybr=i(X),ZE=n(X,"LI",{});var cQe=s(ZE);P4e=n(cQe,"STRONG",{});var DQt=s(P4e);Kbr=r(DQt,"mpnet"),DQt.forEach(t),Zbr=r(cQe," \u2014 "),VY=n(cQe,"A",{href:!0});var GQt=s(VY);evr=r(GQt,"MPNetForQuestionAnswering"),GQt.forEach(t),ovr=r(cQe," (MPNet model)"),cQe.forEach(t),rvr=i(X),e4=n(X,"LI",{});var fQe=s(e4);B4e=n(fQe,"STRONG",{});var OQt=s(B4e);tvr=r(OQt,"mvp"),OQt.forEach(t),avr=r(fQe," \u2014 "),XY=n(fQe,"A",{href:!0});var VQt=s(XY);nvr=r(VQt,"MvpForQuestionAnswering"),VQt.forEach(t),svr=r(fQe," (MVP model)"),fQe.forEach(t),lvr=i(X),o4=n(X,"LI",{});var gQe=s(o4);I4e=n(gQe,"STRONG",{});var XQt=s(I4e);ivr=r(XQt,"nezha"),XQt.forEach(t),dvr=r(gQe," \u2014 "),zY=n(gQe,"A",{href:!0});var zQt=s(zY);mvr=r(zQt,"NezhaForQuestionAnswering"),zQt.forEach(t),cvr=r(gQe," (Nezha model)"),gQe.forEach(t),fvr=i(X),r4=n(X,"LI",{});var hQe=s(r4);N4e=n(hQe,"STRONG",{});var QQt=s(N4e);gvr=r(QQt,"nystromformer"),QQt.forEach(t),hvr=r(hQe," \u2014 "),QY=n(hQe,"A",{href:!0});var WQt=s(QY);uvr=r(WQt,"NystromformerForQuestionAnswering"),WQt.forEach(t),pvr=r(hQe," (Nystr\xF6mformer model)"),hQe.forEach(t),_vr=i(X),t4=n(X,"LI",{});var uQe=s(t4);q4e=n(uQe,"STRONG",{});var UQt=s(q4e);bvr=r(UQt,"qdqbert"),UQt.forEach(t),vvr=r(uQe," \u2014 "),WY=n(uQe,"A",{href:!0});var HQt=s(WY);Fvr=r(HQt,"QDQBertForQuestionAnswering"),HQt.forEach(t),Tvr=r(uQe," (QDQBert model)"),uQe.forEach(t),Mvr=i(X),a4=n(X,"LI",{});var pQe=s(a4);j4e=n(pQe,"STRONG",{});var JQt=s(j4e);Evr=r(JQt,"reformer"),JQt.forEach(t),Cvr=r(pQe," \u2014 "),UY=n(pQe,"A",{href:!0});var YQt=s(UY);wvr=r(YQt,"ReformerForQuestionAnswering"),YQt.forEach(t),Avr=r(pQe," (Reformer model)"),pQe.forEach(t),Lvr=i(X),n4=n(X,"LI",{});var _Qe=s(n4);D4e=n(_Qe,"STRONG",{});var KQt=s(D4e);yvr=r(KQt,"rembert"),KQt.forEach(t),xvr=r(_Qe," \u2014 "),HY=n(_Qe,"A",{href:!0});var ZQt=s(HY);$vr=r(ZQt,"RemBertForQuestionAnswering"),ZQt.forEach(t),kvr=r(_Qe," (RemBERT model)"),_Qe.forEach(t),Svr=i(X),s4=n(X,"LI",{});var bQe=s(s4);G4e=n(bQe,"STRONG",{});var eWt=s(G4e);Rvr=r(eWt,"roberta"),eWt.forEach(t),Pvr=r(bQe," \u2014 "),JY=n(bQe,"A",{href:!0});var oWt=s(JY);Bvr=r(oWt,"RobertaForQuestionAnswering"),oWt.forEach(t),Ivr=r(bQe," (RoBERTa model)"),bQe.forEach(t),Nvr=i(X),l4=n(X,"LI",{});var vQe=s(l4);O4e=n(vQe,"STRONG",{});var rWt=s(O4e);qvr=r(rWt,"roformer"),rWt.forEach(t),jvr=r(vQe," \u2014 "),YY=n(vQe,"A",{href:!0});var tWt=s(YY);Dvr=r(tWt,"RoFormerForQuestionAnswering"),tWt.forEach(t),Gvr=r(vQe," (RoFormer model)"),vQe.forEach(t),Ovr=i(X),i4=n(X,"LI",{});var FQe=s(i4);V4e=n(FQe,"STRONG",{});var aWt=s(V4e);Vvr=r(aWt,"splinter"),aWt.forEach(t),Xvr=r(FQe," \u2014 "),KY=n(FQe,"A",{href:!0});var nWt=s(KY);zvr=r(nWt,"SplinterForQuestionAnswering"),nWt.forEach(t),Qvr=r(FQe," (Splinter model)"),FQe.forEach(t),Wvr=i(X),d4=n(X,"LI",{});var TQe=s(d4);X4e=n(TQe,"STRONG",{});var sWt=s(X4e);Uvr=r(sWt,"squeezebert"),sWt.forEach(t),Hvr=r(TQe," \u2014 "),ZY=n(TQe,"A",{href:!0});var lWt=s(ZY);Jvr=r(lWt,"SqueezeBertForQuestionAnswering"),lWt.forEach(t),Yvr=r(TQe," (SqueezeBERT model)"),TQe.forEach(t),Kvr=i(X),m4=n(X,"LI",{});var MQe=s(m4);z4e=n(MQe,"STRONG",{});var iWt=s(z4e);Zvr=r(iWt,"xlm"),iWt.forEach(t),eFr=r(MQe," \u2014 "),eK=n(MQe,"A",{href:!0});var dWt=s(eK);oFr=r(dWt,"XLMForQuestionAnsweringSimple"),dWt.forEach(t),rFr=r(MQe," (XLM model)"),MQe.forEach(t),tFr=i(X),c4=n(X,"LI",{});var EQe=s(c4);Q4e=n(EQe,"STRONG",{});var mWt=s(Q4e);aFr=r(mWt,"xlm-roberta"),mWt.forEach(t),nFr=r(EQe," \u2014 "),oK=n(EQe,"A",{href:!0});var cWt=s(oK);sFr=r(cWt,"XLMRobertaForQuestionAnswering"),cWt.forEach(t),lFr=r(EQe," (XLM-RoBERTa model)"),EQe.forEach(t),iFr=i(X),f4=n(X,"LI",{});var CQe=s(f4);W4e=n(CQe,"STRONG",{});var fWt=s(W4e);dFr=r(fWt,"xlm-roberta-xl"),fWt.forEach(t),mFr=r(CQe," \u2014 "),rK=n(CQe,"A",{href:!0});var gWt=s(rK);cFr=r(gWt,"XLMRobertaXLForQuestionAnswering"),gWt.forEach(t),fFr=r(CQe," (XLM-RoBERTa-XL model)"),CQe.forEach(t),gFr=i(X),g4=n(X,"LI",{});var wQe=s(g4);U4e=n(wQe,"STRONG",{});var hWt=s(U4e);hFr=r(hWt,"xlnet"),hWt.forEach(t),uFr=r(wQe," \u2014 "),tK=n(wQe,"A",{href:!0});var uWt=s(tK);pFr=r(uWt,"XLNetForQuestionAnsweringSimple"),uWt.forEach(t),_Fr=r(wQe," (XLNet model)"),wQe.forEach(t),bFr=i(X),h4=n(X,"LI",{});var AQe=s(h4);H4e=n(AQe,"STRONG",{});var pWt=s(H4e);vFr=r(pWt,"yoso"),pWt.forEach(t),FFr=r(AQe," \u2014 "),aK=n(AQe,"A",{href:!0});var _Wt=s(aK);TFr=r(_Wt,"YosoForQuestionAnswering"),_Wt.forEach(t),MFr=r(AQe," (YOSO model)"),AQe.forEach(t),X.forEach(t),EFr=i(xa),u4=n(xa,"P",{});var LQe=s(u4);CFr=r(LQe,"The model is set in evaluation mode by default using "),J4e=n(LQe,"CODE",{});var bWt=s(J4e);wFr=r(bWt,"model.eval()"),bWt.forEach(t),AFr=r(LQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Y4e=n(LQe,"CODE",{});var vWt=s(Y4e);LFr=r(vWt,"model.train()"),vWt.forEach(t),LQe.forEach(t),yFr=i(xa),T(p4.$$.fragment,xa),xa.forEach(t),Bl.forEach(t),Ueo=i(c),Wd=n(c,"H2",{class:!0});var ito=s(Wd);_4=n(ito,"A",{id:!0,class:!0,href:!0});var FWt=s(_4);K4e=n(FWt,"SPAN",{});var TWt=s(K4e);T($$.$$.fragment,TWt),TWt.forEach(t),FWt.forEach(t),xFr=i(ito),Z4e=n(ito,"SPAN",{});var MWt=s(Z4e);$Fr=r(MWt,"AutoModelForTableQuestionAnswering"),MWt.forEach(t),ito.forEach(t),Heo=i(c),Xo=n(c,"DIV",{class:!0});var Il=s(Xo);T(k$.$$.fragment,Il),kFr=i(Il),Ud=n(Il,"P",{});var Sie=s(Ud);SFr=r(Sie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),nK=n(Sie,"A",{href:!0});var EWt=s(nK);RFr=r(EWt,"from_pretrained()"),EWt.forEach(t),PFr=r(Sie," class method or the "),sK=n(Sie,"A",{href:!0});var CWt=s(sK);BFr=r(CWt,"from_config()"),CWt.forEach(t),IFr=r(Sie,` class
method.`),Sie.forEach(t),NFr=i(Il),S$=n(Il,"P",{});var dto=s(S$);qFr=r(dto,"This class cannot be instantiated directly using "),eCe=n(dto,"CODE",{});var wWt=s(eCe);jFr=r(wWt,"__init__()"),wWt.forEach(t),DFr=r(dto," (throws an error)."),dto.forEach(t),GFr=i(Il),Lt=n(Il,"DIV",{class:!0});var M8=s(Lt);T(R$.$$.fragment,M8),OFr=i(M8),oCe=n(M8,"P",{});var AWt=s(oCe);VFr=r(AWt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),AWt.forEach(t),XFr=i(M8),Hd=n(M8,"P",{});var Rie=s(Hd);zFr=r(Rie,`Note:
Loading a model from its configuration file does `),rCe=n(Rie,"STRONG",{});var LWt=s(rCe);QFr=r(LWt,"not"),LWt.forEach(t),WFr=r(Rie,` load the model weights. It only affects the
model\u2019s configuration. Use `),lK=n(Rie,"A",{href:!0});var yWt=s(lK);UFr=r(yWt,"from_pretrained()"),yWt.forEach(t),HFr=r(Rie," to load the model weights."),Rie.forEach(t),JFr=i(M8),T(b4.$$.fragment,M8),M8.forEach(t),YFr=i(Il),mo=n(Il,"DIV",{class:!0});var $a=s(mo);T(P$.$$.fragment,$a),KFr=i($a),tCe=n($a,"P",{});var xWt=s(tCe);ZFr=r(xWt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),xWt.forEach(t),eTr=i($a),sn=n($a,"P",{});var E8=s(sn);oTr=r(E8,"The model class to instantiate is selected based on the "),aCe=n(E8,"CODE",{});var $Wt=s(aCe);rTr=r($Wt,"model_type"),$Wt.forEach(t),tTr=r(E8,` property of the config object (either
passed as an argument or loaded from `),nCe=n(E8,"CODE",{});var kWt=s(nCe);aTr=r(kWt,"pretrained_model_name_or_path"),kWt.forEach(t),nTr=r(E8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sCe=n(E8,"CODE",{});var SWt=s(sCe);sTr=r(SWt,"pretrained_model_name_or_path"),SWt.forEach(t),lTr=r(E8,":"),E8.forEach(t),iTr=i($a),lCe=n($a,"UL",{});var RWt=s(lCe);v4=n(RWt,"LI",{});var yQe=s(v4);iCe=n(yQe,"STRONG",{});var PWt=s(iCe);dTr=r(PWt,"tapas"),PWt.forEach(t),mTr=r(yQe," \u2014 "),iK=n(yQe,"A",{href:!0});var BWt=s(iK);cTr=r(BWt,"TapasForQuestionAnswering"),BWt.forEach(t),fTr=r(yQe," (TAPAS model)"),yQe.forEach(t),RWt.forEach(t),gTr=i($a),F4=n($a,"P",{});var xQe=s(F4);hTr=r(xQe,"The model is set in evaluation mode by default using "),dCe=n(xQe,"CODE",{});var IWt=s(dCe);uTr=r(IWt,"model.eval()"),IWt.forEach(t),pTr=r(xQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mCe=n(xQe,"CODE",{});var NWt=s(mCe);_Tr=r(NWt,"model.train()"),NWt.forEach(t),xQe.forEach(t),bTr=i($a),T(T4.$$.fragment,$a),$a.forEach(t),Il.forEach(t),Jeo=i(c),Jd=n(c,"H2",{class:!0});var mto=s(Jd);M4=n(mto,"A",{id:!0,class:!0,href:!0});var qWt=s(M4);cCe=n(qWt,"SPAN",{});var jWt=s(cCe);T(B$.$$.fragment,jWt),jWt.forEach(t),qWt.forEach(t),vTr=i(mto),fCe=n(mto,"SPAN",{});var DWt=s(fCe);FTr=r(DWt,"AutoModelForDocumentQuestionAnswering"),DWt.forEach(t),mto.forEach(t),Yeo=i(c),zo=n(c,"DIV",{class:!0});var Nl=s(zo);T(I$.$$.fragment,Nl),TTr=i(Nl),Yd=n(Nl,"P",{});var Pie=s(Yd);MTr=r(Pie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),dK=n(Pie,"A",{href:!0});var GWt=s(dK);ETr=r(GWt,"from_pretrained()"),GWt.forEach(t),CTr=r(Pie," class method or the "),mK=n(Pie,"A",{href:!0});var OWt=s(mK);wTr=r(OWt,"from_config()"),OWt.forEach(t),ATr=r(Pie,` class
method.`),Pie.forEach(t),LTr=i(Nl),N$=n(Nl,"P",{});var cto=s(N$);yTr=r(cto,"This class cannot be instantiated directly using "),gCe=n(cto,"CODE",{});var VWt=s(gCe);xTr=r(VWt,"__init__()"),VWt.forEach(t),$Tr=r(cto," (throws an error)."),cto.forEach(t),kTr=i(Nl),yt=n(Nl,"DIV",{class:!0});var C8=s(yt);T(q$.$$.fragment,C8),STr=i(C8),hCe=n(C8,"P",{});var XWt=s(hCe);RTr=r(XWt,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),XWt.forEach(t),PTr=i(C8),Kd=n(C8,"P",{});var Bie=s(Kd);BTr=r(Bie,`Note:
Loading a model from its configuration file does `),uCe=n(Bie,"STRONG",{});var zWt=s(uCe);ITr=r(zWt,"not"),zWt.forEach(t),NTr=r(Bie,` load the model weights. It only affects the
model\u2019s configuration. Use `),cK=n(Bie,"A",{href:!0});var QWt=s(cK);qTr=r(QWt,"from_pretrained()"),QWt.forEach(t),jTr=r(Bie," to load the model weights."),Bie.forEach(t),DTr=i(C8),T(E4.$$.fragment,C8),C8.forEach(t),GTr=i(Nl),co=n(Nl,"DIV",{class:!0});var ka=s(co);T(j$.$$.fragment,ka),OTr=i(ka),pCe=n(ka,"P",{});var WWt=s(pCe);VTr=r(WWt,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),WWt.forEach(t),XTr=i(ka),ln=n(ka,"P",{});var w8=s(ln);zTr=r(w8,"The model class to instantiate is selected based on the "),_Ce=n(w8,"CODE",{});var UWt=s(_Ce);QTr=r(UWt,"model_type"),UWt.forEach(t),WTr=r(w8,` property of the config object (either
passed as an argument or loaded from `),bCe=n(w8,"CODE",{});var HWt=s(bCe);UTr=r(HWt,"pretrained_model_name_or_path"),HWt.forEach(t),HTr=r(w8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vCe=n(w8,"CODE",{});var JWt=s(vCe);JTr=r(JWt,"pretrained_model_name_or_path"),JWt.forEach(t),YTr=r(w8,":"),w8.forEach(t),KTr=i(ka),Zd=n(ka,"UL",{});var Iie=s(Zd);C4=n(Iie,"LI",{});var $Qe=s(C4);FCe=n($Qe,"STRONG",{});var YWt=s(FCe);ZTr=r(YWt,"layoutlm"),YWt.forEach(t),eMr=r($Qe," \u2014 "),fK=n($Qe,"A",{href:!0});var KWt=s(fK);oMr=r(KWt,"LayoutLMForQuestionAnswering"),KWt.forEach(t),rMr=r($Qe," (LayoutLM model)"),$Qe.forEach(t),tMr=i(Iie),w4=n(Iie,"LI",{});var kQe=s(w4);TCe=n(kQe,"STRONG",{});var ZWt=s(TCe);aMr=r(ZWt,"layoutlmv2"),ZWt.forEach(t),nMr=r(kQe," \u2014 "),gK=n(kQe,"A",{href:!0});var eUt=s(gK);sMr=r(eUt,"LayoutLMv2ForQuestionAnswering"),eUt.forEach(t),lMr=r(kQe," (LayoutLMv2 model)"),kQe.forEach(t),iMr=i(Iie),A4=n(Iie,"LI",{});var SQe=s(A4);MCe=n(SQe,"STRONG",{});var oUt=s(MCe);dMr=r(oUt,"layoutlmv3"),oUt.forEach(t),mMr=r(SQe," \u2014 "),hK=n(SQe,"A",{href:!0});var rUt=s(hK);cMr=r(rUt,"LayoutLMv3ForQuestionAnswering"),rUt.forEach(t),fMr=r(SQe," (LayoutLMv3 model)"),SQe.forEach(t),Iie.forEach(t),gMr=i(ka),L4=n(ka,"P",{});var RQe=s(L4);hMr=r(RQe,"The model is set in evaluation mode by default using "),ECe=n(RQe,"CODE",{});var tUt=s(ECe);uMr=r(tUt,"model.eval()"),tUt.forEach(t),pMr=r(RQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CCe=n(RQe,"CODE",{});var aUt=s(CCe);_Mr=r(aUt,"model.train()"),aUt.forEach(t),RQe.forEach(t),bMr=i(ka),T(y4.$$.fragment,ka),ka.forEach(t),Nl.forEach(t),Keo=i(c),em=n(c,"H2",{class:!0});var fto=s(em);x4=n(fto,"A",{id:!0,class:!0,href:!0});var nUt=s(x4);wCe=n(nUt,"SPAN",{});var sUt=s(wCe);T(D$.$$.fragment,sUt),sUt.forEach(t),nUt.forEach(t),vMr=i(fto),ACe=n(fto,"SPAN",{});var lUt=s(ACe);FMr=r(lUt,"AutoModelForImageClassification"),lUt.forEach(t),fto.forEach(t),Zeo=i(c),Qo=n(c,"DIV",{class:!0});var ql=s(Qo);T(G$.$$.fragment,ql),TMr=i(ql),om=n(ql,"P",{});var Nie=s(om);MMr=r(Nie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),uK=n(Nie,"A",{href:!0});var iUt=s(uK);EMr=r(iUt,"from_pretrained()"),iUt.forEach(t),CMr=r(Nie," class method or the "),pK=n(Nie,"A",{href:!0});var dUt=s(pK);wMr=r(dUt,"from_config()"),dUt.forEach(t),AMr=r(Nie,` class
method.`),Nie.forEach(t),LMr=i(ql),O$=n(ql,"P",{});var gto=s(O$);yMr=r(gto,"This class cannot be instantiated directly using "),LCe=n(gto,"CODE",{});var mUt=s(LCe);xMr=r(mUt,"__init__()"),mUt.forEach(t),$Mr=r(gto," (throws an error)."),gto.forEach(t),kMr=i(ql),xt=n(ql,"DIV",{class:!0});var A8=s(xt);T(V$.$$.fragment,A8),SMr=i(A8),yCe=n(A8,"P",{});var cUt=s(yCe);RMr=r(cUt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),cUt.forEach(t),PMr=i(A8),rm=n(A8,"P",{});var qie=s(rm);BMr=r(qie,`Note:
Loading a model from its configuration file does `),xCe=n(qie,"STRONG",{});var fUt=s(xCe);IMr=r(fUt,"not"),fUt.forEach(t),NMr=r(qie,` load the model weights. It only affects the
model\u2019s configuration. Use `),_K=n(qie,"A",{href:!0});var gUt=s(_K);qMr=r(gUt,"from_pretrained()"),gUt.forEach(t),jMr=r(qie," to load the model weights."),qie.forEach(t),DMr=i(A8),T($4.$$.fragment,A8),A8.forEach(t),GMr=i(ql),fo=n(ql,"DIV",{class:!0});var Sa=s(fo);T(X$.$$.fragment,Sa),OMr=i(Sa),$Ce=n(Sa,"P",{});var hUt=s($Ce);VMr=r(hUt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),hUt.forEach(t),XMr=i(Sa),dn=n(Sa,"P",{});var L8=s(dn);zMr=r(L8,"The model class to instantiate is selected based on the "),kCe=n(L8,"CODE",{});var uUt=s(kCe);QMr=r(uUt,"model_type"),uUt.forEach(t),WMr=r(L8,` property of the config object (either
passed as an argument or loaded from `),SCe=n(L8,"CODE",{});var pUt=s(SCe);UMr=r(pUt,"pretrained_model_name_or_path"),pUt.forEach(t),HMr=r(L8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RCe=n(L8,"CODE",{});var _Ut=s(RCe);JMr=r(_Ut,"pretrained_model_name_or_path"),_Ut.forEach(t),YMr=r(L8,":"),L8.forEach(t),KMr=i(Sa),be=n(Sa,"UL",{});var Fe=s(be);k4=n(Fe,"LI",{});var PQe=s(k4);PCe=n(PQe,"STRONG",{});var bUt=s(PCe);ZMr=r(bUt,"beit"),bUt.forEach(t),eEr=r(PQe," \u2014 "),bK=n(PQe,"A",{href:!0});var vUt=s(bK);oEr=r(vUt,"BeitForImageClassification"),vUt.forEach(t),rEr=r(PQe," (BEiT model)"),PQe.forEach(t),tEr=i(Fe),S4=n(Fe,"LI",{});var BQe=s(S4);BCe=n(BQe,"STRONG",{});var FUt=s(BCe);aEr=r(FUt,"convnext"),FUt.forEach(t),nEr=r(BQe," \u2014 "),vK=n(BQe,"A",{href:!0});var TUt=s(vK);sEr=r(TUt,"ConvNextForImageClassification"),TUt.forEach(t),lEr=r(BQe," (ConvNeXT model)"),BQe.forEach(t),iEr=i(Fe),R4=n(Fe,"LI",{});var IQe=s(R4);ICe=n(IQe,"STRONG",{});var MUt=s(ICe);dEr=r(MUt,"cvt"),MUt.forEach(t),mEr=r(IQe," \u2014 "),FK=n(IQe,"A",{href:!0});var EUt=s(FK);cEr=r(EUt,"CvtForImageClassification"),EUt.forEach(t),fEr=r(IQe," (CvT model)"),IQe.forEach(t),gEr=i(Fe),P4=n(Fe,"LI",{});var NQe=s(P4);NCe=n(NQe,"STRONG",{});var CUt=s(NCe);hEr=r(CUt,"data2vec-vision"),CUt.forEach(t),uEr=r(NQe," \u2014 "),TK=n(NQe,"A",{href:!0});var wUt=s(TK);pEr=r(wUt,"Data2VecVisionForImageClassification"),wUt.forEach(t),_Er=r(NQe," (Data2VecVision model)"),NQe.forEach(t),bEr=i(Fe),bl=n(Fe,"LI",{});var tI=s(bl);qCe=n(tI,"STRONG",{});var AUt=s(qCe);vEr=r(AUt,"deit"),AUt.forEach(t),FEr=r(tI," \u2014 "),MK=n(tI,"A",{href:!0});var LUt=s(MK);TEr=r(LUt,"DeiTForImageClassification"),LUt.forEach(t),MEr=r(tI," or "),EK=n(tI,"A",{href:!0});var yUt=s(EK);EEr=r(yUt,"DeiTForImageClassificationWithTeacher"),yUt.forEach(t),CEr=r(tI," (DeiT model)"),tI.forEach(t),wEr=i(Fe),B4=n(Fe,"LI",{});var qQe=s(B4);jCe=n(qQe,"STRONG",{});var xUt=s(jCe);AEr=r(xUt,"imagegpt"),xUt.forEach(t),LEr=r(qQe," \u2014 "),CK=n(qQe,"A",{href:!0});var $Ut=s(CK);yEr=r($Ut,"ImageGPTForImageClassification"),$Ut.forEach(t),xEr=r(qQe," (ImageGPT model)"),qQe.forEach(t),$Er=i(Fe),vl=n(Fe,"LI",{});var aI=s(vl);DCe=n(aI,"STRONG",{});var kUt=s(DCe);kEr=r(kUt,"levit"),kUt.forEach(t),SEr=r(aI," \u2014 "),wK=n(aI,"A",{href:!0});var SUt=s(wK);REr=r(SUt,"LevitForImageClassification"),SUt.forEach(t),PEr=r(aI," or "),AK=n(aI,"A",{href:!0});var RUt=s(AK);BEr=r(RUt,"LevitForImageClassificationWithTeacher"),RUt.forEach(t),IEr=r(aI," (LeViT model)"),aI.forEach(t),NEr=i(Fe),I4=n(Fe,"LI",{});var jQe=s(I4);GCe=n(jQe,"STRONG",{});var PUt=s(GCe);qEr=r(PUt,"mobilevit"),PUt.forEach(t),jEr=r(jQe," \u2014 "),LK=n(jQe,"A",{href:!0});var BUt=s(LK);DEr=r(BUt,"MobileViTForImageClassification"),BUt.forEach(t),GEr=r(jQe," (MobileViT model)"),jQe.forEach(t),OEr=i(Fe),$t=n(Fe,"LI",{});var Ef=s($t);OCe=n(Ef,"STRONG",{});var IUt=s(OCe);VEr=r(IUt,"perceiver"),IUt.forEach(t),XEr=r(Ef," \u2014 "),yK=n(Ef,"A",{href:!0});var NUt=s(yK);zEr=r(NUt,"PerceiverForImageClassificationLearned"),NUt.forEach(t),QEr=r(Ef," or "),xK=n(Ef,"A",{href:!0});var qUt=s(xK);WEr=r(qUt,"PerceiverForImageClassificationFourier"),qUt.forEach(t),UEr=r(Ef," or "),$K=n(Ef,"A",{href:!0});var jUt=s($K);HEr=r(jUt,"PerceiverForImageClassificationConvProcessing"),jUt.forEach(t),JEr=r(Ef," (Perceiver model)"),Ef.forEach(t),YEr=i(Fe),N4=n(Fe,"LI",{});var DQe=s(N4);VCe=n(DQe,"STRONG",{});var DUt=s(VCe);KEr=r(DUt,"poolformer"),DUt.forEach(t),ZEr=r(DQe," \u2014 "),kK=n(DQe,"A",{href:!0});var GUt=s(kK);e4r=r(GUt,"PoolFormerForImageClassification"),GUt.forEach(t),o4r=r(DQe," (PoolFormer model)"),DQe.forEach(t),r4r=i(Fe),q4=n(Fe,"LI",{});var GQe=s(q4);XCe=n(GQe,"STRONG",{});var OUt=s(XCe);t4r=r(OUt,"regnet"),OUt.forEach(t),a4r=r(GQe," \u2014 "),SK=n(GQe,"A",{href:!0});var VUt=s(SK);n4r=r(VUt,"RegNetForImageClassification"),VUt.forEach(t),s4r=r(GQe," (RegNet model)"),GQe.forEach(t),l4r=i(Fe),j4=n(Fe,"LI",{});var OQe=s(j4);zCe=n(OQe,"STRONG",{});var XUt=s(zCe);i4r=r(XUt,"resnet"),XUt.forEach(t),d4r=r(OQe," \u2014 "),RK=n(OQe,"A",{href:!0});var zUt=s(RK);m4r=r(zUt,"ResNetForImageClassification"),zUt.forEach(t),c4r=r(OQe," (ResNet model)"),OQe.forEach(t),f4r=i(Fe),D4=n(Fe,"LI",{});var VQe=s(D4);QCe=n(VQe,"STRONG",{});var QUt=s(QCe);g4r=r(QUt,"segformer"),QUt.forEach(t),h4r=r(VQe," \u2014 "),PK=n(VQe,"A",{href:!0});var WUt=s(PK);u4r=r(WUt,"SegformerForImageClassification"),WUt.forEach(t),p4r=r(VQe," (SegFormer model)"),VQe.forEach(t),_4r=i(Fe),G4=n(Fe,"LI",{});var XQe=s(G4);WCe=n(XQe,"STRONG",{});var UUt=s(WCe);b4r=r(UUt,"swin"),UUt.forEach(t),v4r=r(XQe," \u2014 "),BK=n(XQe,"A",{href:!0});var HUt=s(BK);F4r=r(HUt,"SwinForImageClassification"),HUt.forEach(t),T4r=r(XQe," (Swin Transformer model)"),XQe.forEach(t),M4r=i(Fe),O4=n(Fe,"LI",{});var zQe=s(O4);UCe=n(zQe,"STRONG",{});var JUt=s(UCe);E4r=r(JUt,"swinv2"),JUt.forEach(t),C4r=r(zQe," \u2014 "),IK=n(zQe,"A",{href:!0});var YUt=s(IK);w4r=r(YUt,"Swinv2ForImageClassification"),YUt.forEach(t),A4r=r(zQe," (Swin Transformer V2 model)"),zQe.forEach(t),L4r=i(Fe),V4=n(Fe,"LI",{});var QQe=s(V4);HCe=n(QQe,"STRONG",{});var KUt=s(HCe);y4r=r(KUt,"van"),KUt.forEach(t),x4r=r(QQe," \u2014 "),NK=n(QQe,"A",{href:!0});var ZUt=s(NK);$4r=r(ZUt,"VanForImageClassification"),ZUt.forEach(t),k4r=r(QQe," (VAN model)"),QQe.forEach(t),S4r=i(Fe),X4=n(Fe,"LI",{});var WQe=s(X4);JCe=n(WQe,"STRONG",{});var eHt=s(JCe);R4r=r(eHt,"vit"),eHt.forEach(t),P4r=r(WQe," \u2014 "),qK=n(WQe,"A",{href:!0});var oHt=s(qK);B4r=r(oHt,"ViTForImageClassification"),oHt.forEach(t),I4r=r(WQe," (ViT model)"),WQe.forEach(t),N4r=i(Fe),z4=n(Fe,"LI",{});var UQe=s(z4);YCe=n(UQe,"STRONG",{});var rHt=s(YCe);q4r=r(rHt,"vit_msn"),rHt.forEach(t),j4r=r(UQe," \u2014 "),jK=n(UQe,"A",{href:!0});var tHt=s(jK);D4r=r(tHt,"ViTMSNForImageClassification"),tHt.forEach(t),G4r=r(UQe," (ViTMSN model)"),UQe.forEach(t),Fe.forEach(t),O4r=i(Sa),Q4=n(Sa,"P",{});var HQe=s(Q4);V4r=r(HQe,"The model is set in evaluation mode by default using "),KCe=n(HQe,"CODE",{});var aHt=s(KCe);X4r=r(aHt,"model.eval()"),aHt.forEach(t),z4r=r(HQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ZCe=n(HQe,"CODE",{});var nHt=s(ZCe);Q4r=r(nHt,"model.train()"),nHt.forEach(t),HQe.forEach(t),W4r=i(Sa),T(W4.$$.fragment,Sa),Sa.forEach(t),ql.forEach(t),eoo=i(c),tm=n(c,"H2",{class:!0});var hto=s(tm);U4=n(hto,"A",{id:!0,class:!0,href:!0});var sHt=s(U4);e3e=n(sHt,"SPAN",{});var lHt=s(e3e);T(z$.$$.fragment,lHt),lHt.forEach(t),sHt.forEach(t),U4r=i(hto),o3e=n(hto,"SPAN",{});var iHt=s(o3e);H4r=r(iHt,"AutoModelForVideoClassification"),iHt.forEach(t),hto.forEach(t),ooo=i(c),Wo=n(c,"DIV",{class:!0});var jl=s(Wo);T(Q$.$$.fragment,jl),J4r=i(jl),am=n(jl,"P",{});var jie=s(am);Y4r=r(jie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),DK=n(jie,"A",{href:!0});var dHt=s(DK);K4r=r(dHt,"from_pretrained()"),dHt.forEach(t),Z4r=r(jie," class method or the "),GK=n(jie,"A",{href:!0});var mHt=s(GK);eCr=r(mHt,"from_config()"),mHt.forEach(t),oCr=r(jie,` class
method.`),jie.forEach(t),rCr=i(jl),W$=n(jl,"P",{});var uto=s(W$);tCr=r(uto,"This class cannot be instantiated directly using "),r3e=n(uto,"CODE",{});var cHt=s(r3e);aCr=r(cHt,"__init__()"),cHt.forEach(t),nCr=r(uto," (throws an error)."),uto.forEach(t),sCr=i(jl),kt=n(jl,"DIV",{class:!0});var y8=s(kt);T(U$.$$.fragment,y8),lCr=i(y8),t3e=n(y8,"P",{});var fHt=s(t3e);iCr=r(fHt,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),fHt.forEach(t),dCr=i(y8),nm=n(y8,"P",{});var Die=s(nm);mCr=r(Die,`Note:
Loading a model from its configuration file does `),a3e=n(Die,"STRONG",{});var gHt=s(a3e);cCr=r(gHt,"not"),gHt.forEach(t),fCr=r(Die,` load the model weights. It only affects the
model\u2019s configuration. Use `),OK=n(Die,"A",{href:!0});var hHt=s(OK);gCr=r(hHt,"from_pretrained()"),hHt.forEach(t),hCr=r(Die," to load the model weights."),Die.forEach(t),uCr=i(y8),T(H4.$$.fragment,y8),y8.forEach(t),pCr=i(jl),go=n(jl,"DIV",{class:!0});var Ra=s(go);T(H$.$$.fragment,Ra),_Cr=i(Ra),n3e=n(Ra,"P",{});var uHt=s(n3e);bCr=r(uHt,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),uHt.forEach(t),vCr=i(Ra),mn=n(Ra,"P",{});var x8=s(mn);FCr=r(x8,"The model class to instantiate is selected based on the "),s3e=n(x8,"CODE",{});var pHt=s(s3e);TCr=r(pHt,"model_type"),pHt.forEach(t),MCr=r(x8,` property of the config object (either
passed as an argument or loaded from `),l3e=n(x8,"CODE",{});var _Ht=s(l3e);ECr=r(_Ht,"pretrained_model_name_or_path"),_Ht.forEach(t),CCr=r(x8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i3e=n(x8,"CODE",{});var bHt=s(i3e);wCr=r(bHt,"pretrained_model_name_or_path"),bHt.forEach(t),ACr=r(x8,":"),x8.forEach(t),LCr=i(Ra),d3e=n(Ra,"UL",{});var vHt=s(d3e);J4=n(vHt,"LI",{});var JQe=s(J4);m3e=n(JQe,"STRONG",{});var FHt=s(m3e);yCr=r(FHt,"videomae"),FHt.forEach(t),xCr=r(JQe," \u2014 "),VK=n(JQe,"A",{href:!0});var THt=s(VK);$Cr=r(THt,"VideoMAEForVideoClassification"),THt.forEach(t),kCr=r(JQe," (VideoMAE model)"),JQe.forEach(t),vHt.forEach(t),SCr=i(Ra),Y4=n(Ra,"P",{});var YQe=s(Y4);RCr=r(YQe,"The model is set in evaluation mode by default using "),c3e=n(YQe,"CODE",{});var MHt=s(c3e);PCr=r(MHt,"model.eval()"),MHt.forEach(t),BCr=r(YQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f3e=n(YQe,"CODE",{});var EHt=s(f3e);ICr=r(EHt,"model.train()"),EHt.forEach(t),YQe.forEach(t),NCr=i(Ra),T(K4.$$.fragment,Ra),Ra.forEach(t),jl.forEach(t),roo=i(c),sm=n(c,"H2",{class:!0});var pto=s(sm);Z4=n(pto,"A",{id:!0,class:!0,href:!0});var CHt=s(Z4);g3e=n(CHt,"SPAN",{});var wHt=s(g3e);T(J$.$$.fragment,wHt),wHt.forEach(t),CHt.forEach(t),qCr=i(pto),h3e=n(pto,"SPAN",{});var AHt=s(h3e);jCr=r(AHt,"AutoModelForVision2Seq"),AHt.forEach(t),pto.forEach(t),too=i(c),Uo=n(c,"DIV",{class:!0});var Dl=s(Uo);T(Y$.$$.fragment,Dl),DCr=i(Dl),lm=n(Dl,"P",{});var Gie=s(lm);GCr=r(Gie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),XK=n(Gie,"A",{href:!0});var LHt=s(XK);OCr=r(LHt,"from_pretrained()"),LHt.forEach(t),VCr=r(Gie," class method or the "),zK=n(Gie,"A",{href:!0});var yHt=s(zK);XCr=r(yHt,"from_config()"),yHt.forEach(t),zCr=r(Gie,` class
method.`),Gie.forEach(t),QCr=i(Dl),K$=n(Dl,"P",{});var _to=s(K$);WCr=r(_to,"This class cannot be instantiated directly using "),u3e=n(_to,"CODE",{});var xHt=s(u3e);UCr=r(xHt,"__init__()"),xHt.forEach(t),HCr=r(_to," (throws an error)."),_to.forEach(t),JCr=i(Dl),St=n(Dl,"DIV",{class:!0});var $8=s(St);T(Z$.$$.fragment,$8),YCr=i($8),p3e=n($8,"P",{});var $Ht=s(p3e);KCr=r($Ht,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),$Ht.forEach(t),ZCr=i($8),im=n($8,"P",{});var Oie=s(im);e3r=r(Oie,`Note:
Loading a model from its configuration file does `),_3e=n(Oie,"STRONG",{});var kHt=s(_3e);o3r=r(kHt,"not"),kHt.forEach(t),r3r=r(Oie,` load the model weights. It only affects the
model\u2019s configuration. Use `),QK=n(Oie,"A",{href:!0});var SHt=s(QK);t3r=r(SHt,"from_pretrained()"),SHt.forEach(t),a3r=r(Oie," to load the model weights."),Oie.forEach(t),n3r=i($8),T(eC.$$.fragment,$8),$8.forEach(t),s3r=i(Dl),ho=n(Dl,"DIV",{class:!0});var Pa=s(ho);T(ek.$$.fragment,Pa),l3r=i(Pa),b3e=n(Pa,"P",{});var RHt=s(b3e);i3r=r(RHt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),RHt.forEach(t),d3r=i(Pa),cn=n(Pa,"P",{});var k8=s(cn);m3r=r(k8,"The model class to instantiate is selected based on the "),v3e=n(k8,"CODE",{});var PHt=s(v3e);c3r=r(PHt,"model_type"),PHt.forEach(t),f3r=r(k8,` property of the config object (either
passed as an argument or loaded from `),F3e=n(k8,"CODE",{});var BHt=s(F3e);g3r=r(BHt,"pretrained_model_name_or_path"),BHt.forEach(t),h3r=r(k8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T3e=n(k8,"CODE",{});var IHt=s(T3e);u3r=r(IHt,"pretrained_model_name_or_path"),IHt.forEach(t),p3r=r(k8,":"),k8.forEach(t),_3r=i(Pa),M3e=n(Pa,"UL",{});var NHt=s(M3e);oC=n(NHt,"LI",{});var KQe=s(oC);E3e=n(KQe,"STRONG",{});var qHt=s(E3e);b3r=r(qHt,"vision-encoder-decoder"),qHt.forEach(t),v3r=r(KQe," \u2014 "),WK=n(KQe,"A",{href:!0});var jHt=s(WK);F3r=r(jHt,"VisionEncoderDecoderModel"),jHt.forEach(t),T3r=r(KQe," (Vision Encoder decoder model)"),KQe.forEach(t),NHt.forEach(t),M3r=i(Pa),rC=n(Pa,"P",{});var ZQe=s(rC);E3r=r(ZQe,"The model is set in evaluation mode by default using "),C3e=n(ZQe,"CODE",{});var DHt=s(C3e);C3r=r(DHt,"model.eval()"),DHt.forEach(t),w3r=r(ZQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w3e=n(ZQe,"CODE",{});var GHt=s(w3e);A3r=r(GHt,"model.train()"),GHt.forEach(t),ZQe.forEach(t),L3r=i(Pa),T(tC.$$.fragment,Pa),Pa.forEach(t),Dl.forEach(t),aoo=i(c),dm=n(c,"H2",{class:!0});var bto=s(dm);aC=n(bto,"A",{id:!0,class:!0,href:!0});var OHt=s(aC);A3e=n(OHt,"SPAN",{});var VHt=s(A3e);T(ok.$$.fragment,VHt),VHt.forEach(t),OHt.forEach(t),y3r=i(bto),L3e=n(bto,"SPAN",{});var XHt=s(L3e);x3r=r(XHt,"AutoModelForVisualQuestionAnswering"),XHt.forEach(t),bto.forEach(t),noo=i(c),Ho=n(c,"DIV",{class:!0});var Gl=s(Ho);T(rk.$$.fragment,Gl),$3r=i(Gl),mm=n(Gl,"P",{});var Vie=s(mm);k3r=r(Vie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),UK=n(Vie,"A",{href:!0});var zHt=s(UK);S3r=r(zHt,"from_pretrained()"),zHt.forEach(t),R3r=r(Vie," class method or the "),HK=n(Vie,"A",{href:!0});var QHt=s(HK);P3r=r(QHt,"from_config()"),QHt.forEach(t),B3r=r(Vie,` class
method.`),Vie.forEach(t),I3r=i(Gl),tk=n(Gl,"P",{});var vto=s(tk);N3r=r(vto,"This class cannot be instantiated directly using "),y3e=n(vto,"CODE",{});var WHt=s(y3e);q3r=r(WHt,"__init__()"),WHt.forEach(t),j3r=r(vto," (throws an error)."),vto.forEach(t),D3r=i(Gl),Rt=n(Gl,"DIV",{class:!0});var S8=s(Rt);T(ak.$$.fragment,S8),G3r=i(S8),x3e=n(S8,"P",{});var UHt=s(x3e);O3r=r(UHt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),UHt.forEach(t),V3r=i(S8),cm=n(S8,"P",{});var Xie=s(cm);X3r=r(Xie,`Note:
Loading a model from its configuration file does `),$3e=n(Xie,"STRONG",{});var HHt=s($3e);z3r=r(HHt,"not"),HHt.forEach(t),Q3r=r(Xie,` load the model weights. It only affects the
model\u2019s configuration. Use `),JK=n(Xie,"A",{href:!0});var JHt=s(JK);W3r=r(JHt,"from_pretrained()"),JHt.forEach(t),U3r=r(Xie," to load the model weights."),Xie.forEach(t),H3r=i(S8),T(nC.$$.fragment,S8),S8.forEach(t),J3r=i(Gl),uo=n(Gl,"DIV",{class:!0});var Ba=s(uo);T(nk.$$.fragment,Ba),Y3r=i(Ba),k3e=n(Ba,"P",{});var YHt=s(k3e);K3r=r(YHt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),YHt.forEach(t),Z3r=i(Ba),fn=n(Ba,"P",{});var R8=s(fn);e5r=r(R8,"The model class to instantiate is selected based on the "),S3e=n(R8,"CODE",{});var KHt=s(S3e);o5r=r(KHt,"model_type"),KHt.forEach(t),r5r=r(R8,` property of the config object (either
passed as an argument or loaded from `),R3e=n(R8,"CODE",{});var ZHt=s(R3e);t5r=r(ZHt,"pretrained_model_name_or_path"),ZHt.forEach(t),a5r=r(R8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P3e=n(R8,"CODE",{});var eJt=s(P3e);n5r=r(eJt,"pretrained_model_name_or_path"),eJt.forEach(t),s5r=r(R8,":"),R8.forEach(t),l5r=i(Ba),B3e=n(Ba,"UL",{});var oJt=s(B3e);sC=n(oJt,"LI",{});var eWe=s(sC);I3e=n(eWe,"STRONG",{});var rJt=s(I3e);i5r=r(rJt,"vilt"),rJt.forEach(t),d5r=r(eWe," \u2014 "),YK=n(eWe,"A",{href:!0});var tJt=s(YK);m5r=r(tJt,"ViltForQuestionAnswering"),tJt.forEach(t),c5r=r(eWe," (ViLT model)"),eWe.forEach(t),oJt.forEach(t),f5r=i(Ba),lC=n(Ba,"P",{});var oWe=s(lC);g5r=r(oWe,"The model is set in evaluation mode by default using "),N3e=n(oWe,"CODE",{});var aJt=s(N3e);h5r=r(aJt,"model.eval()"),aJt.forEach(t),u5r=r(oWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q3e=n(oWe,"CODE",{});var nJt=s(q3e);p5r=r(nJt,"model.train()"),nJt.forEach(t),oWe.forEach(t),_5r=i(Ba),T(iC.$$.fragment,Ba),Ba.forEach(t),Gl.forEach(t),soo=i(c),fm=n(c,"H2",{class:!0});var Fto=s(fm);dC=n(Fto,"A",{id:!0,class:!0,href:!0});var sJt=s(dC);j3e=n(sJt,"SPAN",{});var lJt=s(j3e);T(sk.$$.fragment,lJt),lJt.forEach(t),sJt.forEach(t),b5r=i(Fto),D3e=n(Fto,"SPAN",{});var iJt=s(D3e);v5r=r(iJt,"AutoModelForAudioClassification"),iJt.forEach(t),Fto.forEach(t),loo=i(c),Jo=n(c,"DIV",{class:!0});var Ol=s(Jo);T(lk.$$.fragment,Ol),F5r=i(Ol),gm=n(Ol,"P",{});var zie=s(gm);T5r=r(zie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),KK=n(zie,"A",{href:!0});var dJt=s(KK);M5r=r(dJt,"from_pretrained()"),dJt.forEach(t),E5r=r(zie," class method or the "),ZK=n(zie,"A",{href:!0});var mJt=s(ZK);C5r=r(mJt,"from_config()"),mJt.forEach(t),w5r=r(zie,` class
method.`),zie.forEach(t),A5r=i(Ol),ik=n(Ol,"P",{});var Tto=s(ik);L5r=r(Tto,"This class cannot be instantiated directly using "),G3e=n(Tto,"CODE",{});var cJt=s(G3e);y5r=r(cJt,"__init__()"),cJt.forEach(t),x5r=r(Tto," (throws an error)."),Tto.forEach(t),$5r=i(Ol),Pt=n(Ol,"DIV",{class:!0});var P8=s(Pt);T(dk.$$.fragment,P8),k5r=i(P8),O3e=n(P8,"P",{});var fJt=s(O3e);S5r=r(fJt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),fJt.forEach(t),R5r=i(P8),hm=n(P8,"P",{});var Qie=s(hm);P5r=r(Qie,`Note:
Loading a model from its configuration file does `),V3e=n(Qie,"STRONG",{});var gJt=s(V3e);B5r=r(gJt,"not"),gJt.forEach(t),I5r=r(Qie,` load the model weights. It only affects the
model\u2019s configuration. Use `),eZ=n(Qie,"A",{href:!0});var hJt=s(eZ);N5r=r(hJt,"from_pretrained()"),hJt.forEach(t),q5r=r(Qie," to load the model weights."),Qie.forEach(t),j5r=i(P8),T(mC.$$.fragment,P8),P8.forEach(t),D5r=i(Ol),po=n(Ol,"DIV",{class:!0});var Ia=s(po);T(mk.$$.fragment,Ia),G5r=i(Ia),X3e=n(Ia,"P",{});var uJt=s(X3e);O5r=r(uJt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),uJt.forEach(t),V5r=i(Ia),gn=n(Ia,"P",{});var B8=s(gn);X5r=r(B8,"The model class to instantiate is selected based on the "),z3e=n(B8,"CODE",{});var pJt=s(z3e);z5r=r(pJt,"model_type"),pJt.forEach(t),Q5r=r(B8,` property of the config object (either
passed as an argument or loaded from `),Q3e=n(B8,"CODE",{});var _Jt=s(Q3e);W5r=r(_Jt,"pretrained_model_name_or_path"),_Jt.forEach(t),U5r=r(B8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W3e=n(B8,"CODE",{});var bJt=s(W3e);H5r=r(bJt,"pretrained_model_name_or_path"),bJt.forEach(t),J5r=r(B8,":"),B8.forEach(t),Y5r=i(Ia),Pe=n(Ia,"UL",{});var Qe=s(Pe);cC=n(Qe,"LI",{});var rWe=s(cC);U3e=n(rWe,"STRONG",{});var vJt=s(U3e);K5r=r(vJt,"data2vec-audio"),vJt.forEach(t),Z5r=r(rWe," \u2014 "),oZ=n(rWe,"A",{href:!0});var FJt=s(oZ);e0r=r(FJt,"Data2VecAudioForSequenceClassification"),FJt.forEach(t),o0r=r(rWe," (Data2VecAudio model)"),rWe.forEach(t),r0r=i(Qe),fC=n(Qe,"LI",{});var tWe=s(fC);H3e=n(tWe,"STRONG",{});var TJt=s(H3e);t0r=r(TJt,"hubert"),TJt.forEach(t),a0r=r(tWe," \u2014 "),rZ=n(tWe,"A",{href:!0});var MJt=s(rZ);n0r=r(MJt,"HubertForSequenceClassification"),MJt.forEach(t),s0r=r(tWe," (Hubert model)"),tWe.forEach(t),l0r=i(Qe),gC=n(Qe,"LI",{});var aWe=s(gC);J3e=n(aWe,"STRONG",{});var EJt=s(J3e);i0r=r(EJt,"sew"),EJt.forEach(t),d0r=r(aWe," \u2014 "),tZ=n(aWe,"A",{href:!0});var CJt=s(tZ);m0r=r(CJt,"SEWForSequenceClassification"),CJt.forEach(t),c0r=r(aWe," (SEW model)"),aWe.forEach(t),f0r=i(Qe),hC=n(Qe,"LI",{});var nWe=s(hC);Y3e=n(nWe,"STRONG",{});var wJt=s(Y3e);g0r=r(wJt,"sew-d"),wJt.forEach(t),h0r=r(nWe," \u2014 "),aZ=n(nWe,"A",{href:!0});var AJt=s(aZ);u0r=r(AJt,"SEWDForSequenceClassification"),AJt.forEach(t),p0r=r(nWe," (SEW-D model)"),nWe.forEach(t),_0r=i(Qe),uC=n(Qe,"LI",{});var sWe=s(uC);K3e=n(sWe,"STRONG",{});var LJt=s(K3e);b0r=r(LJt,"unispeech"),LJt.forEach(t),v0r=r(sWe," \u2014 "),nZ=n(sWe,"A",{href:!0});var yJt=s(nZ);F0r=r(yJt,"UniSpeechForSequenceClassification"),yJt.forEach(t),T0r=r(sWe," (UniSpeech model)"),sWe.forEach(t),M0r=i(Qe),pC=n(Qe,"LI",{});var lWe=s(pC);Z3e=n(lWe,"STRONG",{});var xJt=s(Z3e);E0r=r(xJt,"unispeech-sat"),xJt.forEach(t),C0r=r(lWe," \u2014 "),sZ=n(lWe,"A",{href:!0});var $Jt=s(sZ);w0r=r($Jt,"UniSpeechSatForSequenceClassification"),$Jt.forEach(t),A0r=r(lWe," (UniSpeechSat model)"),lWe.forEach(t),L0r=i(Qe),_C=n(Qe,"LI",{});var iWe=s(_C);e5e=n(iWe,"STRONG",{});var kJt=s(e5e);y0r=r(kJt,"wav2vec2"),kJt.forEach(t),x0r=r(iWe," \u2014 "),lZ=n(iWe,"A",{href:!0});var SJt=s(lZ);$0r=r(SJt,"Wav2Vec2ForSequenceClassification"),SJt.forEach(t),k0r=r(iWe," (Wav2Vec2 model)"),iWe.forEach(t),S0r=i(Qe),bC=n(Qe,"LI",{});var dWe=s(bC);o5e=n(dWe,"STRONG",{});var RJt=s(o5e);R0r=r(RJt,"wav2vec2-conformer"),RJt.forEach(t),P0r=r(dWe," \u2014 "),iZ=n(dWe,"A",{href:!0});var PJt=s(iZ);B0r=r(PJt,"Wav2Vec2ConformerForSequenceClassification"),PJt.forEach(t),I0r=r(dWe," (Wav2Vec2-Conformer model)"),dWe.forEach(t),N0r=i(Qe),vC=n(Qe,"LI",{});var mWe=s(vC);r5e=n(mWe,"STRONG",{});var BJt=s(r5e);q0r=r(BJt,"wavlm"),BJt.forEach(t),j0r=r(mWe," \u2014 "),dZ=n(mWe,"A",{href:!0});var IJt=s(dZ);D0r=r(IJt,"WavLMForSequenceClassification"),IJt.forEach(t),G0r=r(mWe," (WavLM model)"),mWe.forEach(t),Qe.forEach(t),O0r=i(Ia),FC=n(Ia,"P",{});var cWe=s(FC);V0r=r(cWe,"The model is set in evaluation mode by default using "),t5e=n(cWe,"CODE",{});var NJt=s(t5e);X0r=r(NJt,"model.eval()"),NJt.forEach(t),z0r=r(cWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a5e=n(cWe,"CODE",{});var qJt=s(a5e);Q0r=r(qJt,"model.train()"),qJt.forEach(t),cWe.forEach(t),W0r=i(Ia),T(TC.$$.fragment,Ia),Ia.forEach(t),Ol.forEach(t),ioo=i(c),um=n(c,"H2",{class:!0});var Mto=s(um);MC=n(Mto,"A",{id:!0,class:!0,href:!0});var jJt=s(MC);n5e=n(jJt,"SPAN",{});var DJt=s(n5e);T(ck.$$.fragment,DJt),DJt.forEach(t),jJt.forEach(t),U0r=i(Mto),s5e=n(Mto,"SPAN",{});var GJt=s(s5e);H0r=r(GJt,"AutoModelForAudioFrameClassification"),GJt.forEach(t),Mto.forEach(t),doo=i(c),Yo=n(c,"DIV",{class:!0});var Vl=s(Yo);T(fk.$$.fragment,Vl),J0r=i(Vl),pm=n(Vl,"P",{});var Wie=s(pm);Y0r=r(Wie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),mZ=n(Wie,"A",{href:!0});var OJt=s(mZ);K0r=r(OJt,"from_pretrained()"),OJt.forEach(t),Z0r=r(Wie," class method or the "),cZ=n(Wie,"A",{href:!0});var VJt=s(cZ);ewr=r(VJt,"from_config()"),VJt.forEach(t),owr=r(Wie,` class
method.`),Wie.forEach(t),rwr=i(Vl),gk=n(Vl,"P",{});var Eto=s(gk);twr=r(Eto,"This class cannot be instantiated directly using "),l5e=n(Eto,"CODE",{});var XJt=s(l5e);awr=r(XJt,"__init__()"),XJt.forEach(t),nwr=r(Eto," (throws an error)."),Eto.forEach(t),swr=i(Vl),Bt=n(Vl,"DIV",{class:!0});var I8=s(Bt);T(hk.$$.fragment,I8),lwr=i(I8),i5e=n(I8,"P",{});var zJt=s(i5e);iwr=r(zJt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),zJt.forEach(t),dwr=i(I8),_m=n(I8,"P",{});var Uie=s(_m);mwr=r(Uie,`Note:
Loading a model from its configuration file does `),d5e=n(Uie,"STRONG",{});var QJt=s(d5e);cwr=r(QJt,"not"),QJt.forEach(t),fwr=r(Uie,` load the model weights. It only affects the
model\u2019s configuration. Use `),fZ=n(Uie,"A",{href:!0});var WJt=s(fZ);gwr=r(WJt,"from_pretrained()"),WJt.forEach(t),hwr=r(Uie," to load the model weights."),Uie.forEach(t),uwr=i(I8),T(EC.$$.fragment,I8),I8.forEach(t),pwr=i(Vl),_o=n(Vl,"DIV",{class:!0});var Na=s(_o);T(uk.$$.fragment,Na),_wr=i(Na),m5e=n(Na,"P",{});var UJt=s(m5e);bwr=r(UJt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),UJt.forEach(t),vwr=i(Na),hn=n(Na,"P",{});var N8=s(hn);Fwr=r(N8,"The model class to instantiate is selected based on the "),c5e=n(N8,"CODE",{});var HJt=s(c5e);Twr=r(HJt,"model_type"),HJt.forEach(t),Mwr=r(N8,` property of the config object (either
passed as an argument or loaded from `),f5e=n(N8,"CODE",{});var JJt=s(f5e);Ewr=r(JJt,"pretrained_model_name_or_path"),JJt.forEach(t),Cwr=r(N8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g5e=n(N8,"CODE",{});var YJt=s(g5e);wwr=r(YJt,"pretrained_model_name_or_path"),YJt.forEach(t),Awr=r(N8,":"),N8.forEach(t),Lwr=i(Na),ct=n(Na,"UL",{});var Xl=s(ct);CC=n(Xl,"LI",{});var fWe=s(CC);h5e=n(fWe,"STRONG",{});var KJt=s(h5e);ywr=r(KJt,"data2vec-audio"),KJt.forEach(t),xwr=r(fWe," \u2014 "),gZ=n(fWe,"A",{href:!0});var ZJt=s(gZ);$wr=r(ZJt,"Data2VecAudioForAudioFrameClassification"),ZJt.forEach(t),kwr=r(fWe," (Data2VecAudio model)"),fWe.forEach(t),Swr=i(Xl),wC=n(Xl,"LI",{});var gWe=s(wC);u5e=n(gWe,"STRONG",{});var eYt=s(u5e);Rwr=r(eYt,"unispeech-sat"),eYt.forEach(t),Pwr=r(gWe," \u2014 "),hZ=n(gWe,"A",{href:!0});var oYt=s(hZ);Bwr=r(oYt,"UniSpeechSatForAudioFrameClassification"),oYt.forEach(t),Iwr=r(gWe," (UniSpeechSat model)"),gWe.forEach(t),Nwr=i(Xl),AC=n(Xl,"LI",{});var hWe=s(AC);p5e=n(hWe,"STRONG",{});var rYt=s(p5e);qwr=r(rYt,"wav2vec2"),rYt.forEach(t),jwr=r(hWe," \u2014 "),uZ=n(hWe,"A",{href:!0});var tYt=s(uZ);Dwr=r(tYt,"Wav2Vec2ForAudioFrameClassification"),tYt.forEach(t),Gwr=r(hWe," (Wav2Vec2 model)"),hWe.forEach(t),Owr=i(Xl),LC=n(Xl,"LI",{});var uWe=s(LC);_5e=n(uWe,"STRONG",{});var aYt=s(_5e);Vwr=r(aYt,"wav2vec2-conformer"),aYt.forEach(t),Xwr=r(uWe," \u2014 "),pZ=n(uWe,"A",{href:!0});var nYt=s(pZ);zwr=r(nYt,"Wav2Vec2ConformerForAudioFrameClassification"),nYt.forEach(t),Qwr=r(uWe," (Wav2Vec2-Conformer model)"),uWe.forEach(t),Wwr=i(Xl),yC=n(Xl,"LI",{});var pWe=s(yC);b5e=n(pWe,"STRONG",{});var sYt=s(b5e);Uwr=r(sYt,"wavlm"),sYt.forEach(t),Hwr=r(pWe," \u2014 "),_Z=n(pWe,"A",{href:!0});var lYt=s(_Z);Jwr=r(lYt,"WavLMForAudioFrameClassification"),lYt.forEach(t),Ywr=r(pWe," (WavLM model)"),pWe.forEach(t),Xl.forEach(t),Kwr=i(Na),xC=n(Na,"P",{});var _We=s(xC);Zwr=r(_We,"The model is set in evaluation mode by default using "),v5e=n(_We,"CODE",{});var iYt=s(v5e);eAr=r(iYt,"model.eval()"),iYt.forEach(t),oAr=r(_We,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F5e=n(_We,"CODE",{});var dYt=s(F5e);rAr=r(dYt,"model.train()"),dYt.forEach(t),_We.forEach(t),tAr=i(Na),T($C.$$.fragment,Na),Na.forEach(t),Vl.forEach(t),moo=i(c),bm=n(c,"H2",{class:!0});var Cto=s(bm);kC=n(Cto,"A",{id:!0,class:!0,href:!0});var mYt=s(kC);T5e=n(mYt,"SPAN",{});var cYt=s(T5e);T(pk.$$.fragment,cYt),cYt.forEach(t),mYt.forEach(t),aAr=i(Cto),M5e=n(Cto,"SPAN",{});var fYt=s(M5e);nAr=r(fYt,"AutoModelForCTC"),fYt.forEach(t),Cto.forEach(t),coo=i(c),Ko=n(c,"DIV",{class:!0});var zl=s(Ko);T(_k.$$.fragment,zl),sAr=i(zl),vm=n(zl,"P",{});var Hie=s(vm);lAr=r(Hie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),bZ=n(Hie,"A",{href:!0});var gYt=s(bZ);iAr=r(gYt,"from_pretrained()"),gYt.forEach(t),dAr=r(Hie," class method or the "),vZ=n(Hie,"A",{href:!0});var hYt=s(vZ);mAr=r(hYt,"from_config()"),hYt.forEach(t),cAr=r(Hie,` class
method.`),Hie.forEach(t),fAr=i(zl),bk=n(zl,"P",{});var wto=s(bk);gAr=r(wto,"This class cannot be instantiated directly using "),E5e=n(wto,"CODE",{});var uYt=s(E5e);hAr=r(uYt,"__init__()"),uYt.forEach(t),uAr=r(wto," (throws an error)."),wto.forEach(t),pAr=i(zl),It=n(zl,"DIV",{class:!0});var q8=s(It);T(vk.$$.fragment,q8),_Ar=i(q8),C5e=n(q8,"P",{});var pYt=s(C5e);bAr=r(pYt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),pYt.forEach(t),vAr=i(q8),Fm=n(q8,"P",{});var Jie=s(Fm);FAr=r(Jie,`Note:
Loading a model from its configuration file does `),w5e=n(Jie,"STRONG",{});var _Yt=s(w5e);TAr=r(_Yt,"not"),_Yt.forEach(t),MAr=r(Jie,` load the model weights. It only affects the
model\u2019s configuration. Use `),FZ=n(Jie,"A",{href:!0});var bYt=s(FZ);EAr=r(bYt,"from_pretrained()"),bYt.forEach(t),CAr=r(Jie," to load the model weights."),Jie.forEach(t),wAr=i(q8),T(SC.$$.fragment,q8),q8.forEach(t),AAr=i(zl),bo=n(zl,"DIV",{class:!0});var qa=s(bo);T(Fk.$$.fragment,qa),LAr=i(qa),A5e=n(qa,"P",{});var vYt=s(A5e);yAr=r(vYt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),vYt.forEach(t),xAr=i(qa),un=n(qa,"P",{});var j8=s(un);$Ar=r(j8,"The model class to instantiate is selected based on the "),L5e=n(j8,"CODE",{});var FYt=s(L5e);kAr=r(FYt,"model_type"),FYt.forEach(t),SAr=r(j8,` property of the config object (either
passed as an argument or loaded from `),y5e=n(j8,"CODE",{});var TYt=s(y5e);RAr=r(TYt,"pretrained_model_name_or_path"),TYt.forEach(t),PAr=r(j8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x5e=n(j8,"CODE",{});var MYt=s(x5e);BAr=r(MYt,"pretrained_model_name_or_path"),MYt.forEach(t),IAr=r(j8,":"),j8.forEach(t),NAr=i(qa),Le=n(qa,"UL",{});var Ie=s(Le);RC=n(Ie,"LI",{});var bWe=s(RC);$5e=n(bWe,"STRONG",{});var EYt=s($5e);qAr=r(EYt,"data2vec-audio"),EYt.forEach(t),jAr=r(bWe," \u2014 "),TZ=n(bWe,"A",{href:!0});var CYt=s(TZ);DAr=r(CYt,"Data2VecAudioForCTC"),CYt.forEach(t),GAr=r(bWe," (Data2VecAudio model)"),bWe.forEach(t),OAr=i(Ie),PC=n(Ie,"LI",{});var vWe=s(PC);k5e=n(vWe,"STRONG",{});var wYt=s(k5e);VAr=r(wYt,"hubert"),wYt.forEach(t),XAr=r(vWe," \u2014 "),MZ=n(vWe,"A",{href:!0});var AYt=s(MZ);zAr=r(AYt,"HubertForCTC"),AYt.forEach(t),QAr=r(vWe," (Hubert model)"),vWe.forEach(t),WAr=i(Ie),BC=n(Ie,"LI",{});var FWe=s(BC);S5e=n(FWe,"STRONG",{});var LYt=s(S5e);UAr=r(LYt,"mctct"),LYt.forEach(t),HAr=r(FWe," \u2014 "),EZ=n(FWe,"A",{href:!0});var yYt=s(EZ);JAr=r(yYt,"MCTCTForCTC"),yYt.forEach(t),YAr=r(FWe," (M-CTC-T model)"),FWe.forEach(t),KAr=i(Ie),IC=n(Ie,"LI",{});var TWe=s(IC);R5e=n(TWe,"STRONG",{});var xYt=s(R5e);ZAr=r(xYt,"sew"),xYt.forEach(t),e6r=r(TWe," \u2014 "),CZ=n(TWe,"A",{href:!0});var $Yt=s(CZ);o6r=r($Yt,"SEWForCTC"),$Yt.forEach(t),r6r=r(TWe," (SEW model)"),TWe.forEach(t),t6r=i(Ie),NC=n(Ie,"LI",{});var MWe=s(NC);P5e=n(MWe,"STRONG",{});var kYt=s(P5e);a6r=r(kYt,"sew-d"),kYt.forEach(t),n6r=r(MWe," \u2014 "),wZ=n(MWe,"A",{href:!0});var SYt=s(wZ);s6r=r(SYt,"SEWDForCTC"),SYt.forEach(t),l6r=r(MWe," (SEW-D model)"),MWe.forEach(t),i6r=i(Ie),qC=n(Ie,"LI",{});var EWe=s(qC);B5e=n(EWe,"STRONG",{});var RYt=s(B5e);d6r=r(RYt,"unispeech"),RYt.forEach(t),m6r=r(EWe," \u2014 "),AZ=n(EWe,"A",{href:!0});var PYt=s(AZ);c6r=r(PYt,"UniSpeechForCTC"),PYt.forEach(t),f6r=r(EWe," (UniSpeech model)"),EWe.forEach(t),g6r=i(Ie),jC=n(Ie,"LI",{});var CWe=s(jC);I5e=n(CWe,"STRONG",{});var BYt=s(I5e);h6r=r(BYt,"unispeech-sat"),BYt.forEach(t),u6r=r(CWe," \u2014 "),LZ=n(CWe,"A",{href:!0});var IYt=s(LZ);p6r=r(IYt,"UniSpeechSatForCTC"),IYt.forEach(t),_6r=r(CWe," (UniSpeechSat model)"),CWe.forEach(t),b6r=i(Ie),DC=n(Ie,"LI",{});var wWe=s(DC);N5e=n(wWe,"STRONG",{});var NYt=s(N5e);v6r=r(NYt,"wav2vec2"),NYt.forEach(t),F6r=r(wWe," \u2014 "),yZ=n(wWe,"A",{href:!0});var qYt=s(yZ);T6r=r(qYt,"Wav2Vec2ForCTC"),qYt.forEach(t),M6r=r(wWe," (Wav2Vec2 model)"),wWe.forEach(t),E6r=i(Ie),GC=n(Ie,"LI",{});var AWe=s(GC);q5e=n(AWe,"STRONG",{});var jYt=s(q5e);C6r=r(jYt,"wav2vec2-conformer"),jYt.forEach(t),w6r=r(AWe," \u2014 "),xZ=n(AWe,"A",{href:!0});var DYt=s(xZ);A6r=r(DYt,"Wav2Vec2ConformerForCTC"),DYt.forEach(t),L6r=r(AWe," (Wav2Vec2-Conformer model)"),AWe.forEach(t),y6r=i(Ie),OC=n(Ie,"LI",{});var LWe=s(OC);j5e=n(LWe,"STRONG",{});var GYt=s(j5e);x6r=r(GYt,"wavlm"),GYt.forEach(t),$6r=r(LWe," \u2014 "),$Z=n(LWe,"A",{href:!0});var OYt=s($Z);k6r=r(OYt,"WavLMForCTC"),OYt.forEach(t),S6r=r(LWe," (WavLM model)"),LWe.forEach(t),Ie.forEach(t),R6r=i(qa),VC=n(qa,"P",{});var yWe=s(VC);P6r=r(yWe,"The model is set in evaluation mode by default using "),D5e=n(yWe,"CODE",{});var VYt=s(D5e);B6r=r(VYt,"model.eval()"),VYt.forEach(t),I6r=r(yWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),G5e=n(yWe,"CODE",{});var XYt=s(G5e);N6r=r(XYt,"model.train()"),XYt.forEach(t),yWe.forEach(t),q6r=i(qa),T(XC.$$.fragment,qa),qa.forEach(t),zl.forEach(t),foo=i(c),Tm=n(c,"H2",{class:!0});var Ato=s(Tm);zC=n(Ato,"A",{id:!0,class:!0,href:!0});var zYt=s(zC);O5e=n(zYt,"SPAN",{});var QYt=s(O5e);T(Tk.$$.fragment,QYt),QYt.forEach(t),zYt.forEach(t),j6r=i(Ato),V5e=n(Ato,"SPAN",{});var WYt=s(V5e);D6r=r(WYt,"AutoModelForSpeechSeq2Seq"),WYt.forEach(t),Ato.forEach(t),goo=i(c),Zo=n(c,"DIV",{class:!0});var Ql=s(Zo);T(Mk.$$.fragment,Ql),G6r=i(Ql),Mm=n(Ql,"P",{});var Yie=s(Mm);O6r=r(Yie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),kZ=n(Yie,"A",{href:!0});var UYt=s(kZ);V6r=r(UYt,"from_pretrained()"),UYt.forEach(t),X6r=r(Yie," class method or the "),SZ=n(Yie,"A",{href:!0});var HYt=s(SZ);z6r=r(HYt,"from_config()"),HYt.forEach(t),Q6r=r(Yie,` class
method.`),Yie.forEach(t),W6r=i(Ql),Ek=n(Ql,"P",{});var Lto=s(Ek);U6r=r(Lto,"This class cannot be instantiated directly using "),X5e=n(Lto,"CODE",{});var JYt=s(X5e);H6r=r(JYt,"__init__()"),JYt.forEach(t),J6r=r(Lto," (throws an error)."),Lto.forEach(t),Y6r=i(Ql),Nt=n(Ql,"DIV",{class:!0});var D8=s(Nt);T(Ck.$$.fragment,D8),K6r=i(D8),z5e=n(D8,"P",{});var YYt=s(z5e);Z6r=r(YYt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),YYt.forEach(t),e7r=i(D8),Em=n(D8,"P",{});var Kie=s(Em);o7r=r(Kie,`Note:
Loading a model from its configuration file does `),Q5e=n(Kie,"STRONG",{});var KYt=s(Q5e);r7r=r(KYt,"not"),KYt.forEach(t),t7r=r(Kie,` load the model weights. It only affects the
model\u2019s configuration. Use `),RZ=n(Kie,"A",{href:!0});var ZYt=s(RZ);a7r=r(ZYt,"from_pretrained()"),ZYt.forEach(t),n7r=r(Kie," to load the model weights."),Kie.forEach(t),s7r=i(D8),T(QC.$$.fragment,D8),D8.forEach(t),l7r=i(Ql),vo=n(Ql,"DIV",{class:!0});var ja=s(vo);T(wk.$$.fragment,ja),i7r=i(ja),W5e=n(ja,"P",{});var eKt=s(W5e);d7r=r(eKt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),eKt.forEach(t),m7r=i(ja),pn=n(ja,"P",{});var G8=s(pn);c7r=r(G8,"The model class to instantiate is selected based on the "),U5e=n(G8,"CODE",{});var oKt=s(U5e);f7r=r(oKt,"model_type"),oKt.forEach(t),g7r=r(G8,` property of the config object (either
passed as an argument or loaded from `),H5e=n(G8,"CODE",{});var rKt=s(H5e);h7r=r(rKt,"pretrained_model_name_or_path"),rKt.forEach(t),u7r=r(G8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J5e=n(G8,"CODE",{});var tKt=s(J5e);p7r=r(tKt,"pretrained_model_name_or_path"),tKt.forEach(t),_7r=r(G8,":"),G8.forEach(t),b7r=i(ja),Cm=n(ja,"UL",{});var Zie=s(Cm);WC=n(Zie,"LI",{});var xWe=s(WC);Y5e=n(xWe,"STRONG",{});var aKt=s(Y5e);v7r=r(aKt,"speech-encoder-decoder"),aKt.forEach(t),F7r=r(xWe," \u2014 "),PZ=n(xWe,"A",{href:!0});var nKt=s(PZ);T7r=r(nKt,"SpeechEncoderDecoderModel"),nKt.forEach(t),M7r=r(xWe," (Speech Encoder decoder model)"),xWe.forEach(t),E7r=i(Zie),UC=n(Zie,"LI",{});var $We=s(UC);K5e=n($We,"STRONG",{});var sKt=s(K5e);C7r=r(sKt,"speech_to_text"),sKt.forEach(t),w7r=r($We," \u2014 "),BZ=n($We,"A",{href:!0});var lKt=s(BZ);A7r=r(lKt,"Speech2TextForConditionalGeneration"),lKt.forEach(t),L7r=r($We," (Speech2Text model)"),$We.forEach(t),y7r=i(Zie),HC=n(Zie,"LI",{});var kWe=s(HC);Z5e=n(kWe,"STRONG",{});var iKt=s(Z5e);x7r=r(iKt,"whisper"),iKt.forEach(t),$7r=r(kWe," \u2014 "),IZ=n(kWe,"A",{href:!0});var dKt=s(IZ);k7r=r(dKt,"WhisperForConditionalGeneration"),dKt.forEach(t),S7r=r(kWe," (Whisper model)"),kWe.forEach(t),Zie.forEach(t),R7r=i(ja),JC=n(ja,"P",{});var SWe=s(JC);P7r=r(SWe,"The model is set in evaluation mode by default using "),e0e=n(SWe,"CODE",{});var mKt=s(e0e);B7r=r(mKt,"model.eval()"),mKt.forEach(t),I7r=r(SWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o0e=n(SWe,"CODE",{});var cKt=s(o0e);N7r=r(cKt,"model.train()"),cKt.forEach(t),SWe.forEach(t),q7r=i(ja),T(YC.$$.fragment,ja),ja.forEach(t),Ql.forEach(t),hoo=i(c),wm=n(c,"H2",{class:!0});var yto=s(wm);KC=n(yto,"A",{id:!0,class:!0,href:!0});var fKt=s(KC);r0e=n(fKt,"SPAN",{});var gKt=s(r0e);T(Ak.$$.fragment,gKt),gKt.forEach(t),fKt.forEach(t),j7r=i(yto),t0e=n(yto,"SPAN",{});var hKt=s(t0e);D7r=r(hKt,"AutoModelForAudioXVector"),hKt.forEach(t),yto.forEach(t),uoo=i(c),er=n(c,"DIV",{class:!0});var Wl=s(er);T(Lk.$$.fragment,Wl),G7r=i(Wl),Am=n(Wl,"P",{});var ede=s(Am);O7r=r(ede,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),NZ=n(ede,"A",{href:!0});var uKt=s(NZ);V7r=r(uKt,"from_pretrained()"),uKt.forEach(t),X7r=r(ede," class method or the "),qZ=n(ede,"A",{href:!0});var pKt=s(qZ);z7r=r(pKt,"from_config()"),pKt.forEach(t),Q7r=r(ede,` class
method.`),ede.forEach(t),W7r=i(Wl),yk=n(Wl,"P",{});var xto=s(yk);U7r=r(xto,"This class cannot be instantiated directly using "),a0e=n(xto,"CODE",{});var _Kt=s(a0e);H7r=r(_Kt,"__init__()"),_Kt.forEach(t),J7r=r(xto," (throws an error)."),xto.forEach(t),Y7r=i(Wl),qt=n(Wl,"DIV",{class:!0});var O8=s(qt);T(xk.$$.fragment,O8),K7r=i(O8),n0e=n(O8,"P",{});var bKt=s(n0e);Z7r=r(bKt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),bKt.forEach(t),eLr=i(O8),Lm=n(O8,"P",{});var ode=s(Lm);oLr=r(ode,`Note:
Loading a model from its configuration file does `),s0e=n(ode,"STRONG",{});var vKt=s(s0e);rLr=r(vKt,"not"),vKt.forEach(t),tLr=r(ode,` load the model weights. It only affects the
model\u2019s configuration. Use `),jZ=n(ode,"A",{href:!0});var FKt=s(jZ);aLr=r(FKt,"from_pretrained()"),FKt.forEach(t),nLr=r(ode," to load the model weights."),ode.forEach(t),sLr=i(O8),T(ZC.$$.fragment,O8),O8.forEach(t),lLr=i(Wl),Fo=n(Wl,"DIV",{class:!0});var Da=s(Fo);T($k.$$.fragment,Da),iLr=i(Da),l0e=n(Da,"P",{});var TKt=s(l0e);dLr=r(TKt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),TKt.forEach(t),mLr=i(Da),_n=n(Da,"P",{});var V8=s(_n);cLr=r(V8,"The model class to instantiate is selected based on the "),i0e=n(V8,"CODE",{});var MKt=s(i0e);fLr=r(MKt,"model_type"),MKt.forEach(t),gLr=r(V8,` property of the config object (either
passed as an argument or loaded from `),d0e=n(V8,"CODE",{});var EKt=s(d0e);hLr=r(EKt,"pretrained_model_name_or_path"),EKt.forEach(t),uLr=r(V8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m0e=n(V8,"CODE",{});var CKt=s(m0e);pLr=r(CKt,"pretrained_model_name_or_path"),CKt.forEach(t),_Lr=r(V8,":"),V8.forEach(t),bLr=i(Da),ft=n(Da,"UL",{});var Ul=s(ft);e3=n(Ul,"LI",{});var RWe=s(e3);c0e=n(RWe,"STRONG",{});var wKt=s(c0e);vLr=r(wKt,"data2vec-audio"),wKt.forEach(t),FLr=r(RWe," \u2014 "),DZ=n(RWe,"A",{href:!0});var AKt=s(DZ);TLr=r(AKt,"Data2VecAudioForXVector"),AKt.forEach(t),MLr=r(RWe," (Data2VecAudio model)"),RWe.forEach(t),ELr=i(Ul),o3=n(Ul,"LI",{});var PWe=s(o3);f0e=n(PWe,"STRONG",{});var LKt=s(f0e);CLr=r(LKt,"unispeech-sat"),LKt.forEach(t),wLr=r(PWe," \u2014 "),GZ=n(PWe,"A",{href:!0});var yKt=s(GZ);ALr=r(yKt,"UniSpeechSatForXVector"),yKt.forEach(t),LLr=r(PWe," (UniSpeechSat model)"),PWe.forEach(t),yLr=i(Ul),r3=n(Ul,"LI",{});var BWe=s(r3);g0e=n(BWe,"STRONG",{});var xKt=s(g0e);xLr=r(xKt,"wav2vec2"),xKt.forEach(t),$Lr=r(BWe," \u2014 "),OZ=n(BWe,"A",{href:!0});var $Kt=s(OZ);kLr=r($Kt,"Wav2Vec2ForXVector"),$Kt.forEach(t),SLr=r(BWe," (Wav2Vec2 model)"),BWe.forEach(t),RLr=i(Ul),t3=n(Ul,"LI",{});var IWe=s(t3);h0e=n(IWe,"STRONG",{});var kKt=s(h0e);PLr=r(kKt,"wav2vec2-conformer"),kKt.forEach(t),BLr=r(IWe," \u2014 "),VZ=n(IWe,"A",{href:!0});var SKt=s(VZ);ILr=r(SKt,"Wav2Vec2ConformerForXVector"),SKt.forEach(t),NLr=r(IWe," (Wav2Vec2-Conformer model)"),IWe.forEach(t),qLr=i(Ul),a3=n(Ul,"LI",{});var NWe=s(a3);u0e=n(NWe,"STRONG",{});var RKt=s(u0e);jLr=r(RKt,"wavlm"),RKt.forEach(t),DLr=r(NWe," \u2014 "),XZ=n(NWe,"A",{href:!0});var PKt=s(XZ);GLr=r(PKt,"WavLMForXVector"),PKt.forEach(t),OLr=r(NWe," (WavLM model)"),NWe.forEach(t),Ul.forEach(t),VLr=i(Da),n3=n(Da,"P",{});var qWe=s(n3);XLr=r(qWe,"The model is set in evaluation mode by default using "),p0e=n(qWe,"CODE",{});var BKt=s(p0e);zLr=r(BKt,"model.eval()"),BKt.forEach(t),QLr=r(qWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_0e=n(qWe,"CODE",{});var IKt=s(_0e);WLr=r(IKt,"model.train()"),IKt.forEach(t),qWe.forEach(t),ULr=i(Da),T(s3.$$.fragment,Da),Da.forEach(t),Wl.forEach(t),poo=i(c),ym=n(c,"H2",{class:!0});var $to=s(ym);l3=n($to,"A",{id:!0,class:!0,href:!0});var NKt=s(l3);b0e=n(NKt,"SPAN",{});var qKt=s(b0e);T(kk.$$.fragment,qKt),qKt.forEach(t),NKt.forEach(t),HLr=i($to),v0e=n($to,"SPAN",{});var jKt=s(v0e);JLr=r(jKt,"AutoModelForMaskedImageModeling"),jKt.forEach(t),$to.forEach(t),_oo=i(c),or=n(c,"DIV",{class:!0});var Hl=s(or);T(Sk.$$.fragment,Hl),YLr=i(Hl),xm=n(Hl,"P",{});var rde=s(xm);KLr=r(rde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),zZ=n(rde,"A",{href:!0});var DKt=s(zZ);ZLr=r(DKt,"from_pretrained()"),DKt.forEach(t),eyr=r(rde," class method or the "),QZ=n(rde,"A",{href:!0});var GKt=s(QZ);oyr=r(GKt,"from_config()"),GKt.forEach(t),ryr=r(rde,` class
method.`),rde.forEach(t),tyr=i(Hl),Rk=n(Hl,"P",{});var kto=s(Rk);ayr=r(kto,"This class cannot be instantiated directly using "),F0e=n(kto,"CODE",{});var OKt=s(F0e);nyr=r(OKt,"__init__()"),OKt.forEach(t),syr=r(kto," (throws an error)."),kto.forEach(t),lyr=i(Hl),jt=n(Hl,"DIV",{class:!0});var X8=s(jt);T(Pk.$$.fragment,X8),iyr=i(X8),T0e=n(X8,"P",{});var VKt=s(T0e);dyr=r(VKt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),VKt.forEach(t),myr=i(X8),$m=n(X8,"P",{});var tde=s($m);cyr=r(tde,`Note:
Loading a model from its configuration file does `),M0e=n(tde,"STRONG",{});var XKt=s(M0e);fyr=r(XKt,"not"),XKt.forEach(t),gyr=r(tde,` load the model weights. It only affects the
model\u2019s configuration. Use `),WZ=n(tde,"A",{href:!0});var zKt=s(WZ);hyr=r(zKt,"from_pretrained()"),zKt.forEach(t),uyr=r(tde," to load the model weights."),tde.forEach(t),pyr=i(X8),T(i3.$$.fragment,X8),X8.forEach(t),_yr=i(Hl),To=n(Hl,"DIV",{class:!0});var Ga=s(To);T(Bk.$$.fragment,Ga),byr=i(Ga),E0e=n(Ga,"P",{});var QKt=s(E0e);vyr=r(QKt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),QKt.forEach(t),Fyr=i(Ga),bn=n(Ga,"P",{});var z8=s(bn);Tyr=r(z8,"The model class to instantiate is selected based on the "),C0e=n(z8,"CODE",{});var WKt=s(C0e);Myr=r(WKt,"model_type"),WKt.forEach(t),Eyr=r(z8,` property of the config object (either
passed as an argument or loaded from `),w0e=n(z8,"CODE",{});var UKt=s(w0e);Cyr=r(UKt,"pretrained_model_name_or_path"),UKt.forEach(t),wyr=r(z8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A0e=n(z8,"CODE",{});var HKt=s(A0e);Ayr=r(HKt,"pretrained_model_name_or_path"),HKt.forEach(t),Lyr=r(z8,":"),z8.forEach(t),yyr=i(Ga),vn=n(Ga,"UL",{});var Q8=s(vn);d3=n(Q8,"LI",{});var jWe=s(d3);L0e=n(jWe,"STRONG",{});var JKt=s(L0e);xyr=r(JKt,"deit"),JKt.forEach(t),$yr=r(jWe," \u2014 "),UZ=n(jWe,"A",{href:!0});var YKt=s(UZ);kyr=r(YKt,"DeiTForMaskedImageModeling"),YKt.forEach(t),Syr=r(jWe," (DeiT model)"),jWe.forEach(t),Ryr=i(Q8),m3=n(Q8,"LI",{});var DWe=s(m3);y0e=n(DWe,"STRONG",{});var KKt=s(y0e);Pyr=r(KKt,"swin"),KKt.forEach(t),Byr=r(DWe," \u2014 "),HZ=n(DWe,"A",{href:!0});var ZKt=s(HZ);Iyr=r(ZKt,"SwinForMaskedImageModeling"),ZKt.forEach(t),Nyr=r(DWe," (Swin Transformer model)"),DWe.forEach(t),qyr=i(Q8),c3=n(Q8,"LI",{});var GWe=s(c3);x0e=n(GWe,"STRONG",{});var eZt=s(x0e);jyr=r(eZt,"swinv2"),eZt.forEach(t),Dyr=r(GWe," \u2014 "),JZ=n(GWe,"A",{href:!0});var oZt=s(JZ);Gyr=r(oZt,"Swinv2ForMaskedImageModeling"),oZt.forEach(t),Oyr=r(GWe," (Swin Transformer V2 model)"),GWe.forEach(t),Vyr=i(Q8),f3=n(Q8,"LI",{});var OWe=s(f3);$0e=n(OWe,"STRONG",{});var rZt=s($0e);Xyr=r(rZt,"vit"),rZt.forEach(t),zyr=r(OWe," \u2014 "),YZ=n(OWe,"A",{href:!0});var tZt=s(YZ);Qyr=r(tZt,"ViTForMaskedImageModeling"),tZt.forEach(t),Wyr=r(OWe," (ViT model)"),OWe.forEach(t),Q8.forEach(t),Uyr=i(Ga),g3=n(Ga,"P",{});var VWe=s(g3);Hyr=r(VWe,"The model is set in evaluation mode by default using "),k0e=n(VWe,"CODE",{});var aZt=s(k0e);Jyr=r(aZt,"model.eval()"),aZt.forEach(t),Yyr=r(VWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S0e=n(VWe,"CODE",{});var nZt=s(S0e);Kyr=r(nZt,"model.train()"),nZt.forEach(t),VWe.forEach(t),Zyr=i(Ga),T(h3.$$.fragment,Ga),Ga.forEach(t),Hl.forEach(t),boo=i(c),km=n(c,"H2",{class:!0});var Sto=s(km);u3=n(Sto,"A",{id:!0,class:!0,href:!0});var sZt=s(u3);R0e=n(sZt,"SPAN",{});var lZt=s(R0e);T(Ik.$$.fragment,lZt),lZt.forEach(t),sZt.forEach(t),e8r=i(Sto),P0e=n(Sto,"SPAN",{});var iZt=s(P0e);o8r=r(iZt,"AutoModelForObjectDetection"),iZt.forEach(t),Sto.forEach(t),voo=i(c),rr=n(c,"DIV",{class:!0});var Jl=s(rr);T(Nk.$$.fragment,Jl),r8r=i(Jl),Sm=n(Jl,"P",{});var ade=s(Sm);t8r=r(ade,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),KZ=n(ade,"A",{href:!0});var dZt=s(KZ);a8r=r(dZt,"from_pretrained()"),dZt.forEach(t),n8r=r(ade," class method or the "),ZZ=n(ade,"A",{href:!0});var mZt=s(ZZ);s8r=r(mZt,"from_config()"),mZt.forEach(t),l8r=r(ade,` class
method.`),ade.forEach(t),i8r=i(Jl),qk=n(Jl,"P",{});var Rto=s(qk);d8r=r(Rto,"This class cannot be instantiated directly using "),B0e=n(Rto,"CODE",{});var cZt=s(B0e);m8r=r(cZt,"__init__()"),cZt.forEach(t),c8r=r(Rto," (throws an error)."),Rto.forEach(t),f8r=i(Jl),Dt=n(Jl,"DIV",{class:!0});var W8=s(Dt);T(jk.$$.fragment,W8),g8r=i(W8),I0e=n(W8,"P",{});var fZt=s(I0e);h8r=r(fZt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),fZt.forEach(t),u8r=i(W8),Rm=n(W8,"P",{});var nde=s(Rm);p8r=r(nde,`Note:
Loading a model from its configuration file does `),N0e=n(nde,"STRONG",{});var gZt=s(N0e);_8r=r(gZt,"not"),gZt.forEach(t),b8r=r(nde,` load the model weights. It only affects the
model\u2019s configuration. Use `),eee=n(nde,"A",{href:!0});var hZt=s(eee);v8r=r(hZt,"from_pretrained()"),hZt.forEach(t),F8r=r(nde," to load the model weights."),nde.forEach(t),T8r=i(W8),T(p3.$$.fragment,W8),W8.forEach(t),M8r=i(Jl),Mo=n(Jl,"DIV",{class:!0});var Oa=s(Mo);T(Dk.$$.fragment,Oa),E8r=i(Oa),q0e=n(Oa,"P",{});var uZt=s(q0e);C8r=r(uZt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),uZt.forEach(t),w8r=i(Oa),Fn=n(Oa,"P",{});var U8=s(Fn);A8r=r(U8,"The model class to instantiate is selected based on the "),j0e=n(U8,"CODE",{});var pZt=s(j0e);L8r=r(pZt,"model_type"),pZt.forEach(t),y8r=r(U8,` property of the config object (either
passed as an argument or loaded from `),D0e=n(U8,"CODE",{});var _Zt=s(D0e);x8r=r(_Zt,"pretrained_model_name_or_path"),_Zt.forEach(t),$8r=r(U8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G0e=n(U8,"CODE",{});var bZt=s(G0e);k8r=r(bZt,"pretrained_model_name_or_path"),bZt.forEach(t),S8r=r(U8,":"),U8.forEach(t),R8r=i(Oa),Tn=n(Oa,"UL",{});var H8=s(Tn);_3=n(H8,"LI",{});var XWe=s(_3);O0e=n(XWe,"STRONG",{});var vZt=s(O0e);P8r=r(vZt,"conditional_detr"),vZt.forEach(t),B8r=r(XWe," \u2014 "),oee=n(XWe,"A",{href:!0});var FZt=s(oee);I8r=r(FZt,"ConditionalDetrForObjectDetection"),FZt.forEach(t),N8r=r(XWe," (Conditional DETR model)"),XWe.forEach(t),q8r=i(H8),b3=n(H8,"LI",{});var zWe=s(b3);V0e=n(zWe,"STRONG",{});var TZt=s(V0e);j8r=r(TZt,"deformable_detr"),TZt.forEach(t),D8r=r(zWe," \u2014 "),ree=n(zWe,"A",{href:!0});var MZt=s(ree);G8r=r(MZt,"DeformableDetrForObjectDetection"),MZt.forEach(t),O8r=r(zWe," (Deformable DETR model)"),zWe.forEach(t),V8r=i(H8),v3=n(H8,"LI",{});var QWe=s(v3);X0e=n(QWe,"STRONG",{});var EZt=s(X0e);X8r=r(EZt,"detr"),EZt.forEach(t),z8r=r(QWe," \u2014 "),tee=n(QWe,"A",{href:!0});var CZt=s(tee);Q8r=r(CZt,"DetrForObjectDetection"),CZt.forEach(t),W8r=r(QWe," (DETR model)"),QWe.forEach(t),U8r=i(H8),F3=n(H8,"LI",{});var WWe=s(F3);z0e=n(WWe,"STRONG",{});var wZt=s(z0e);H8r=r(wZt,"yolos"),wZt.forEach(t),J8r=r(WWe," \u2014 "),aee=n(WWe,"A",{href:!0});var AZt=s(aee);Y8r=r(AZt,"YolosForObjectDetection"),AZt.forEach(t),K8r=r(WWe," (YOLOS model)"),WWe.forEach(t),H8.forEach(t),Z8r=i(Oa),T3=n(Oa,"P",{});var UWe=s(T3);e9r=r(UWe,"The model is set in evaluation mode by default using "),Q0e=n(UWe,"CODE",{});var LZt=s(Q0e);o9r=r(LZt,"model.eval()"),LZt.forEach(t),r9r=r(UWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W0e=n(UWe,"CODE",{});var yZt=s(W0e);t9r=r(yZt,"model.train()"),yZt.forEach(t),UWe.forEach(t),a9r=i(Oa),T(M3.$$.fragment,Oa),Oa.forEach(t),Jl.forEach(t),Foo=i(c),Pm=n(c,"H2",{class:!0});var Pto=s(Pm);E3=n(Pto,"A",{id:!0,class:!0,href:!0});var xZt=s(E3);U0e=n(xZt,"SPAN",{});var $Zt=s(U0e);T(Gk.$$.fragment,$Zt),$Zt.forEach(t),xZt.forEach(t),n9r=i(Pto),H0e=n(Pto,"SPAN",{});var kZt=s(H0e);s9r=r(kZt,"AutoModelForImageSegmentation"),kZt.forEach(t),Pto.forEach(t),Too=i(c),tr=n(c,"DIV",{class:!0});var Yl=s(tr);T(Ok.$$.fragment,Yl),l9r=i(Yl),Bm=n(Yl,"P",{});var sde=s(Bm);i9r=r(sde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),nee=n(sde,"A",{href:!0});var SZt=s(nee);d9r=r(SZt,"from_pretrained()"),SZt.forEach(t),m9r=r(sde," class method or the "),see=n(sde,"A",{href:!0});var RZt=s(see);c9r=r(RZt,"from_config()"),RZt.forEach(t),f9r=r(sde,` class
method.`),sde.forEach(t),g9r=i(Yl),Vk=n(Yl,"P",{});var Bto=s(Vk);h9r=r(Bto,"This class cannot be instantiated directly using "),J0e=n(Bto,"CODE",{});var PZt=s(J0e);u9r=r(PZt,"__init__()"),PZt.forEach(t),p9r=r(Bto," (throws an error)."),Bto.forEach(t),_9r=i(Yl),Gt=n(Yl,"DIV",{class:!0});var J8=s(Gt);T(Xk.$$.fragment,J8),b9r=i(J8),Y0e=n(J8,"P",{});var BZt=s(Y0e);v9r=r(BZt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),BZt.forEach(t),F9r=i(J8),Im=n(J8,"P",{});var lde=s(Im);T9r=r(lde,`Note:
Loading a model from its configuration file does `),K0e=n(lde,"STRONG",{});var IZt=s(K0e);M9r=r(IZt,"not"),IZt.forEach(t),E9r=r(lde,` load the model weights. It only affects the
model\u2019s configuration. Use `),lee=n(lde,"A",{href:!0});var NZt=s(lee);C9r=r(NZt,"from_pretrained()"),NZt.forEach(t),w9r=r(lde," to load the model weights."),lde.forEach(t),A9r=i(J8),T(C3.$$.fragment,J8),J8.forEach(t),L9r=i(Yl),Eo=n(Yl,"DIV",{class:!0});var Va=s(Eo);T(zk.$$.fragment,Va),y9r=i(Va),Z0e=n(Va,"P",{});var qZt=s(Z0e);x9r=r(qZt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),qZt.forEach(t),$9r=i(Va),Mn=n(Va,"P",{});var Y8=s(Mn);k9r=r(Y8,"The model class to instantiate is selected based on the "),ewe=n(Y8,"CODE",{});var jZt=s(ewe);S9r=r(jZt,"model_type"),jZt.forEach(t),R9r=r(Y8,` property of the config object (either
passed as an argument or loaded from `),owe=n(Y8,"CODE",{});var DZt=s(owe);P9r=r(DZt,"pretrained_model_name_or_path"),DZt.forEach(t),B9r=r(Y8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rwe=n(Y8,"CODE",{});var GZt=s(rwe);I9r=r(GZt,"pretrained_model_name_or_path"),GZt.forEach(t),N9r=r(Y8,":"),Y8.forEach(t),q9r=i(Va),twe=n(Va,"UL",{});var OZt=s(twe);w3=n(OZt,"LI",{});var HWe=s(w3);awe=n(HWe,"STRONG",{});var VZt=s(awe);j9r=r(VZt,"detr"),VZt.forEach(t),D9r=r(HWe," \u2014 "),iee=n(HWe,"A",{href:!0});var XZt=s(iee);G9r=r(XZt,"DetrForSegmentation"),XZt.forEach(t),O9r=r(HWe," (DETR model)"),HWe.forEach(t),OZt.forEach(t),V9r=i(Va),A3=n(Va,"P",{});var JWe=s(A3);X9r=r(JWe,"The model is set in evaluation mode by default using "),nwe=n(JWe,"CODE",{});var zZt=s(nwe);z9r=r(zZt,"model.eval()"),zZt.forEach(t),Q9r=r(JWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),swe=n(JWe,"CODE",{});var QZt=s(swe);W9r=r(QZt,"model.train()"),QZt.forEach(t),JWe.forEach(t),U9r=i(Va),T(L3.$$.fragment,Va),Va.forEach(t),Yl.forEach(t),Moo=i(c),Nm=n(c,"H2",{class:!0});var Ito=s(Nm);y3=n(Ito,"A",{id:!0,class:!0,href:!0});var WZt=s(y3);lwe=n(WZt,"SPAN",{});var UZt=s(lwe);T(Qk.$$.fragment,UZt),UZt.forEach(t),WZt.forEach(t),H9r=i(Ito),iwe=n(Ito,"SPAN",{});var HZt=s(iwe);J9r=r(HZt,"AutoModelForSemanticSegmentation"),HZt.forEach(t),Ito.forEach(t),Eoo=i(c),ar=n(c,"DIV",{class:!0});var Kl=s(ar);T(Wk.$$.fragment,Kl),Y9r=i(Kl),qm=n(Kl,"P",{});var ide=s(qm);K9r=r(ide,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),dee=n(ide,"A",{href:!0});var JZt=s(dee);Z9r=r(JZt,"from_pretrained()"),JZt.forEach(t),exr=r(ide," class method or the "),mee=n(ide,"A",{href:!0});var YZt=s(mee);oxr=r(YZt,"from_config()"),YZt.forEach(t),rxr=r(ide,` class
method.`),ide.forEach(t),txr=i(Kl),Uk=n(Kl,"P",{});var Nto=s(Uk);axr=r(Nto,"This class cannot be instantiated directly using "),dwe=n(Nto,"CODE",{});var KZt=s(dwe);nxr=r(KZt,"__init__()"),KZt.forEach(t),sxr=r(Nto," (throws an error)."),Nto.forEach(t),lxr=i(Kl),Ot=n(Kl,"DIV",{class:!0});var K8=s(Ot);T(Hk.$$.fragment,K8),ixr=i(K8),mwe=n(K8,"P",{});var ZZt=s(mwe);dxr=r(ZZt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),ZZt.forEach(t),mxr=i(K8),jm=n(K8,"P",{});var dde=s(jm);cxr=r(dde,`Note:
Loading a model from its configuration file does `),cwe=n(dde,"STRONG",{});var eea=s(cwe);fxr=r(eea,"not"),eea.forEach(t),gxr=r(dde,` load the model weights. It only affects the
model\u2019s configuration. Use `),cee=n(dde,"A",{href:!0});var oea=s(cee);hxr=r(oea,"from_pretrained()"),oea.forEach(t),uxr=r(dde," to load the model weights."),dde.forEach(t),pxr=i(K8),T(x3.$$.fragment,K8),K8.forEach(t),_xr=i(Kl),Co=n(Kl,"DIV",{class:!0});var Xa=s(Co);T(Jk.$$.fragment,Xa),bxr=i(Xa),fwe=n(Xa,"P",{});var rea=s(fwe);vxr=r(rea,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),rea.forEach(t),Fxr=i(Xa),En=n(Xa,"P",{});var Z8=s(En);Txr=r(Z8,"The model class to instantiate is selected based on the "),gwe=n(Z8,"CODE",{});var tea=s(gwe);Mxr=r(tea,"model_type"),tea.forEach(t),Exr=r(Z8,` property of the config object (either
passed as an argument or loaded from `),hwe=n(Z8,"CODE",{});var aea=s(hwe);Cxr=r(aea,"pretrained_model_name_or_path"),aea.forEach(t),wxr=r(Z8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uwe=n(Z8,"CODE",{});var nea=s(uwe);Axr=r(nea,"pretrained_model_name_or_path"),nea.forEach(t),Lxr=r(Z8,":"),Z8.forEach(t),yxr=i(Xa),gt=n(Xa,"UL",{});var Zl=s(gt);$3=n(Zl,"LI",{});var YWe=s($3);pwe=n(YWe,"STRONG",{});var sea=s(pwe);xxr=r(sea,"beit"),sea.forEach(t),$xr=r(YWe," \u2014 "),fee=n(YWe,"A",{href:!0});var lea=s(fee);kxr=r(lea,"BeitForSemanticSegmentation"),lea.forEach(t),Sxr=r(YWe," (BEiT model)"),YWe.forEach(t),Rxr=i(Zl),k3=n(Zl,"LI",{});var KWe=s(k3);_we=n(KWe,"STRONG",{});var iea=s(_we);Pxr=r(iea,"data2vec-vision"),iea.forEach(t),Bxr=r(KWe," \u2014 "),gee=n(KWe,"A",{href:!0});var dea=s(gee);Ixr=r(dea,"Data2VecVisionForSemanticSegmentation"),dea.forEach(t),Nxr=r(KWe," (Data2VecVision model)"),KWe.forEach(t),qxr=i(Zl),S3=n(Zl,"LI",{});var ZWe=s(S3);bwe=n(ZWe,"STRONG",{});var mea=s(bwe);jxr=r(mea,"dpt"),mea.forEach(t),Dxr=r(ZWe," \u2014 "),hee=n(ZWe,"A",{href:!0});var cea=s(hee);Gxr=r(cea,"DPTForSemanticSegmentation"),cea.forEach(t),Oxr=r(ZWe," (DPT model)"),ZWe.forEach(t),Vxr=i(Zl),R3=n(Zl,"LI",{});var eUe=s(R3);vwe=n(eUe,"STRONG",{});var fea=s(vwe);Xxr=r(fea,"mobilevit"),fea.forEach(t),zxr=r(eUe," \u2014 "),uee=n(eUe,"A",{href:!0});var gea=s(uee);Qxr=r(gea,"MobileViTForSemanticSegmentation"),gea.forEach(t),Wxr=r(eUe," (MobileViT model)"),eUe.forEach(t),Uxr=i(Zl),P3=n(Zl,"LI",{});var oUe=s(P3);Fwe=n(oUe,"STRONG",{});var hea=s(Fwe);Hxr=r(hea,"segformer"),hea.forEach(t),Jxr=r(oUe," \u2014 "),pee=n(oUe,"A",{href:!0});var uea=s(pee);Yxr=r(uea,"SegformerForSemanticSegmentation"),uea.forEach(t),Kxr=r(oUe," (SegFormer model)"),oUe.forEach(t),Zl.forEach(t),Zxr=i(Xa),B3=n(Xa,"P",{});var rUe=s(B3);e$r=r(rUe,"The model is set in evaluation mode by default using "),Twe=n(rUe,"CODE",{});var pea=s(Twe);o$r=r(pea,"model.eval()"),pea.forEach(t),r$r=r(rUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mwe=n(rUe,"CODE",{});var _ea=s(Mwe);t$r=r(_ea,"model.train()"),_ea.forEach(t),rUe.forEach(t),a$r=i(Xa),T(I3.$$.fragment,Xa),Xa.forEach(t),Kl.forEach(t),Coo=i(c),Dm=n(c,"H2",{class:!0});var qto=s(Dm);N3=n(qto,"A",{id:!0,class:!0,href:!0});var bea=s(N3);Ewe=n(bea,"SPAN",{});var vea=s(Ewe);T(Yk.$$.fragment,vea),vea.forEach(t),bea.forEach(t),n$r=i(qto),Cwe=n(qto,"SPAN",{});var Fea=s(Cwe);s$r=r(Fea,"AutoModelForInstanceSegmentation"),Fea.forEach(t),qto.forEach(t),woo=i(c),nr=n(c,"DIV",{class:!0});var ei=s(nr);T(Kk.$$.fragment,ei),l$r=i(ei),Gm=n(ei,"P",{});var mde=s(Gm);i$r=r(mde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),_ee=n(mde,"A",{href:!0});var Tea=s(_ee);d$r=r(Tea,"from_pretrained()"),Tea.forEach(t),m$r=r(mde," class method or the "),bee=n(mde,"A",{href:!0});var Mea=s(bee);c$r=r(Mea,"from_config()"),Mea.forEach(t),f$r=r(mde,` class
method.`),mde.forEach(t),g$r=i(ei),Zk=n(ei,"P",{});var jto=s(Zk);h$r=r(jto,"This class cannot be instantiated directly using "),wwe=n(jto,"CODE",{});var Eea=s(wwe);u$r=r(Eea,"__init__()"),Eea.forEach(t),p$r=r(jto," (throws an error)."),jto.forEach(t),_$r=i(ei),Vt=n(ei,"DIV",{class:!0});var e9=s(Vt);T(eS.$$.fragment,e9),b$r=i(e9),Awe=n(e9,"P",{});var Cea=s(Awe);v$r=r(Cea,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Cea.forEach(t),F$r=i(e9),Om=n(e9,"P",{});var cde=s(Om);T$r=r(cde,`Note:
Loading a model from its configuration file does `),Lwe=n(cde,"STRONG",{});var wea=s(Lwe);M$r=r(wea,"not"),wea.forEach(t),E$r=r(cde,` load the model weights. It only affects the
model\u2019s configuration. Use `),vee=n(cde,"A",{href:!0});var Aea=s(vee);C$r=r(Aea,"from_pretrained()"),Aea.forEach(t),w$r=r(cde," to load the model weights."),cde.forEach(t),A$r=i(e9),T(q3.$$.fragment,e9),e9.forEach(t),L$r=i(ei),wo=n(ei,"DIV",{class:!0});var za=s(wo);T(oS.$$.fragment,za),y$r=i(za),ywe=n(za,"P",{});var Lea=s(ywe);x$r=r(Lea,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Lea.forEach(t),$$r=i(za),Cn=n(za,"P",{});var o9=s(Cn);k$r=r(o9,"The model class to instantiate is selected based on the "),xwe=n(o9,"CODE",{});var yea=s(xwe);S$r=r(yea,"model_type"),yea.forEach(t),R$r=r(o9,` property of the config object (either
passed as an argument or loaded from `),$we=n(o9,"CODE",{});var xea=s($we);P$r=r(xea,"pretrained_model_name_or_path"),xea.forEach(t),B$r=r(o9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kwe=n(o9,"CODE",{});var $ea=s(kwe);I$r=r($ea,"pretrained_model_name_or_path"),$ea.forEach(t),N$r=r(o9,":"),o9.forEach(t),q$r=i(za),Swe=n(za,"UL",{});var kea=s(Swe);j3=n(kea,"LI",{});var tUe=s(j3);Rwe=n(tUe,"STRONG",{});var Sea=s(Rwe);j$r=r(Sea,"maskformer"),Sea.forEach(t),D$r=r(tUe," \u2014 "),Fee=n(tUe,"A",{href:!0});var Rea=s(Fee);G$r=r(Rea,"MaskFormerForInstanceSegmentation"),Rea.forEach(t),O$r=r(tUe," (MaskFormer model)"),tUe.forEach(t),kea.forEach(t),V$r=i(za),D3=n(za,"P",{});var aUe=s(D3);X$r=r(aUe,"The model is set in evaluation mode by default using "),Pwe=n(aUe,"CODE",{});var Pea=s(Pwe);z$r=r(Pea,"model.eval()"),Pea.forEach(t),Q$r=r(aUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Bwe=n(aUe,"CODE",{});var Bea=s(Bwe);W$r=r(Bea,"model.train()"),Bea.forEach(t),aUe.forEach(t),U$r=i(za),T(G3.$$.fragment,za),za.forEach(t),ei.forEach(t),Aoo=i(c),Vm=n(c,"H2",{class:!0});var Dto=s(Vm);O3=n(Dto,"A",{id:!0,class:!0,href:!0});var Iea=s(O3);Iwe=n(Iea,"SPAN",{});var Nea=s(Iwe);T(rS.$$.fragment,Nea),Nea.forEach(t),Iea.forEach(t),H$r=i(Dto),Nwe=n(Dto,"SPAN",{});var qea=s(Nwe);J$r=r(qea,"TFAutoModel"),qea.forEach(t),Dto.forEach(t),Loo=i(c),sr=n(c,"DIV",{class:!0});var oi=s(sr);T(tS.$$.fragment,oi),Y$r=i(oi),Xm=n(oi,"P",{});var fde=s(Xm);K$r=r(fde,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Tee=n(fde,"A",{href:!0});var jea=s(Tee);Z$r=r(jea,"from_pretrained()"),jea.forEach(t),ekr=r(fde," class method or the "),Mee=n(fde,"A",{href:!0});var Dea=s(Mee);okr=r(Dea,"from_config()"),Dea.forEach(t),rkr=r(fde,` class
method.`),fde.forEach(t),tkr=i(oi),aS=n(oi,"P",{});var Gto=s(aS);akr=r(Gto,"This class cannot be instantiated directly using "),qwe=n(Gto,"CODE",{});var Gea=s(qwe);nkr=r(Gea,"__init__()"),Gea.forEach(t),skr=r(Gto," (throws an error)."),Gto.forEach(t),lkr=i(oi),Xt=n(oi,"DIV",{class:!0});var r9=s(Xt);T(nS.$$.fragment,r9),ikr=i(r9),jwe=n(r9,"P",{});var Oea=s(jwe);dkr=r(Oea,"Instantiates one of the base model classes of the library from a configuration."),Oea.forEach(t),mkr=i(r9),zm=n(r9,"P",{});var gde=s(zm);ckr=r(gde,`Note:
Loading a model from its configuration file does `),Dwe=n(gde,"STRONG",{});var Vea=s(Dwe);fkr=r(Vea,"not"),Vea.forEach(t),gkr=r(gde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Eee=n(gde,"A",{href:!0});var Xea=s(Eee);hkr=r(Xea,"from_pretrained()"),Xea.forEach(t),ukr=r(gde," to load the model weights."),gde.forEach(t),pkr=i(r9),T(V3.$$.fragment,r9),r9.forEach(t),_kr=i(oi),Ir=n(oi,"DIV",{class:!0});var ri=s(Ir);T(sS.$$.fragment,ri),bkr=i(ri),Gwe=n(ri,"P",{});var zea=s(Gwe);vkr=r(zea,"Instantiate one of the base model classes of the library from a pretrained model."),zea.forEach(t),Fkr=i(ri),wn=n(ri,"P",{});var t9=s(wn);Tkr=r(t9,"The model class to instantiate is selected based on the "),Owe=n(t9,"CODE",{});var Qea=s(Owe);Mkr=r(Qea,"model_type"),Qea.forEach(t),Ekr=r(t9,` property of the config object (either
passed as an argument or loaded from `),Vwe=n(t9,"CODE",{});var Wea=s(Vwe);Ckr=r(Wea,"pretrained_model_name_or_path"),Wea.forEach(t),wkr=r(t9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xwe=n(t9,"CODE",{});var Uea=s(Xwe);Akr=r(Uea,"pretrained_model_name_or_path"),Uea.forEach(t),Lkr=r(t9,":"),t9.forEach(t),ykr=i(ri),I=n(ri,"UL",{});var D=s(I);X3=n(D,"LI",{});var nUe=s(X3);zwe=n(nUe,"STRONG",{});var Hea=s(zwe);xkr=r(Hea,"albert"),Hea.forEach(t),$kr=r(nUe," \u2014 "),Cee=n(nUe,"A",{href:!0});var Jea=s(Cee);kkr=r(Jea,"TFAlbertModel"),Jea.forEach(t),Skr=r(nUe," (ALBERT model)"),nUe.forEach(t),Rkr=i(D),z3=n(D,"LI",{});var sUe=s(z3);Qwe=n(sUe,"STRONG",{});var Yea=s(Qwe);Pkr=r(Yea,"bart"),Yea.forEach(t),Bkr=r(sUe," \u2014 "),wee=n(sUe,"A",{href:!0});var Kea=s(wee);Ikr=r(Kea,"TFBartModel"),Kea.forEach(t),Nkr=r(sUe," (BART model)"),sUe.forEach(t),qkr=i(D),Q3=n(D,"LI",{});var lUe=s(Q3);Wwe=n(lUe,"STRONG",{});var Zea=s(Wwe);jkr=r(Zea,"bert"),Zea.forEach(t),Dkr=r(lUe," \u2014 "),Aee=n(lUe,"A",{href:!0});var eoa=s(Aee);Gkr=r(eoa,"TFBertModel"),eoa.forEach(t),Okr=r(lUe," (BERT model)"),lUe.forEach(t),Vkr=i(D),W3=n(D,"LI",{});var iUe=s(W3);Uwe=n(iUe,"STRONG",{});var ooa=s(Uwe);Xkr=r(ooa,"blenderbot"),ooa.forEach(t),zkr=r(iUe," \u2014 "),Lee=n(iUe,"A",{href:!0});var roa=s(Lee);Qkr=r(roa,"TFBlenderbotModel"),roa.forEach(t),Wkr=r(iUe," (Blenderbot model)"),iUe.forEach(t),Ukr=i(D),U3=n(D,"LI",{});var dUe=s(U3);Hwe=n(dUe,"STRONG",{});var toa=s(Hwe);Hkr=r(toa,"blenderbot-small"),toa.forEach(t),Jkr=r(dUe," \u2014 "),yee=n(dUe,"A",{href:!0});var aoa=s(yee);Ykr=r(aoa,"TFBlenderbotSmallModel"),aoa.forEach(t),Kkr=r(dUe," (BlenderbotSmall model)"),dUe.forEach(t),Zkr=i(D),H3=n(D,"LI",{});var mUe=s(H3);Jwe=n(mUe,"STRONG",{});var noa=s(Jwe);eSr=r(noa,"camembert"),noa.forEach(t),oSr=r(mUe," \u2014 "),xee=n(mUe,"A",{href:!0});var soa=s(xee);rSr=r(soa,"TFCamembertModel"),soa.forEach(t),tSr=r(mUe," (CamemBERT model)"),mUe.forEach(t),aSr=i(D),J3=n(D,"LI",{});var cUe=s(J3);Ywe=n(cUe,"STRONG",{});var loa=s(Ywe);nSr=r(loa,"clip"),loa.forEach(t),sSr=r(cUe," \u2014 "),$ee=n(cUe,"A",{href:!0});var ioa=s($ee);lSr=r(ioa,"TFCLIPModel"),ioa.forEach(t),iSr=r(cUe," (CLIP model)"),cUe.forEach(t),dSr=i(D),Y3=n(D,"LI",{});var fUe=s(Y3);Kwe=n(fUe,"STRONG",{});var doa=s(Kwe);mSr=r(doa,"convbert"),doa.forEach(t),cSr=r(fUe," \u2014 "),kee=n(fUe,"A",{href:!0});var moa=s(kee);fSr=r(moa,"TFConvBertModel"),moa.forEach(t),gSr=r(fUe," (ConvBERT model)"),fUe.forEach(t),hSr=i(D),K3=n(D,"LI",{});var gUe=s(K3);Zwe=n(gUe,"STRONG",{});var coa=s(Zwe);uSr=r(coa,"convnext"),coa.forEach(t),pSr=r(gUe," \u2014 "),See=n(gUe,"A",{href:!0});var foa=s(See);_Sr=r(foa,"TFConvNextModel"),foa.forEach(t),bSr=r(gUe," (ConvNeXT model)"),gUe.forEach(t),vSr=i(D),Z3=n(D,"LI",{});var hUe=s(Z3);eAe=n(hUe,"STRONG",{});var goa=s(eAe);FSr=r(goa,"ctrl"),goa.forEach(t),TSr=r(hUe," \u2014 "),Ree=n(hUe,"A",{href:!0});var hoa=s(Ree);MSr=r(hoa,"TFCTRLModel"),hoa.forEach(t),ESr=r(hUe," (CTRL model)"),hUe.forEach(t),CSr=i(D),e5=n(D,"LI",{});var uUe=s(e5);oAe=n(uUe,"STRONG",{});var uoa=s(oAe);wSr=r(uoa,"data2vec-vision"),uoa.forEach(t),ASr=r(uUe," \u2014 "),Pee=n(uUe,"A",{href:!0});var poa=s(Pee);LSr=r(poa,"TFData2VecVisionModel"),poa.forEach(t),ySr=r(uUe," (Data2VecVision model)"),uUe.forEach(t),xSr=i(D),o5=n(D,"LI",{});var pUe=s(o5);rAe=n(pUe,"STRONG",{});var _oa=s(rAe);$Sr=r(_oa,"deberta"),_oa.forEach(t),kSr=r(pUe," \u2014 "),Bee=n(pUe,"A",{href:!0});var boa=s(Bee);SSr=r(boa,"TFDebertaModel"),boa.forEach(t),RSr=r(pUe," (DeBERTa model)"),pUe.forEach(t),PSr=i(D),r5=n(D,"LI",{});var _Ue=s(r5);tAe=n(_Ue,"STRONG",{});var voa=s(tAe);BSr=r(voa,"deberta-v2"),voa.forEach(t),ISr=r(_Ue," \u2014 "),Iee=n(_Ue,"A",{href:!0});var Foa=s(Iee);NSr=r(Foa,"TFDebertaV2Model"),Foa.forEach(t),qSr=r(_Ue," (DeBERTa-v2 model)"),_Ue.forEach(t),jSr=i(D),t5=n(D,"LI",{});var bUe=s(t5);aAe=n(bUe,"STRONG",{});var Toa=s(aAe);DSr=r(Toa,"deit"),Toa.forEach(t),GSr=r(bUe," \u2014 "),Nee=n(bUe,"A",{href:!0});var Moa=s(Nee);OSr=r(Moa,"TFDeiTModel"),Moa.forEach(t),VSr=r(bUe," (DeiT model)"),bUe.forEach(t),XSr=i(D),a5=n(D,"LI",{});var vUe=s(a5);nAe=n(vUe,"STRONG",{});var Eoa=s(nAe);zSr=r(Eoa,"distilbert"),Eoa.forEach(t),QSr=r(vUe," \u2014 "),qee=n(vUe,"A",{href:!0});var Coa=s(qee);WSr=r(Coa,"TFDistilBertModel"),Coa.forEach(t),USr=r(vUe," (DistilBERT model)"),vUe.forEach(t),HSr=i(D),n5=n(D,"LI",{});var FUe=s(n5);sAe=n(FUe,"STRONG",{});var woa=s(sAe);JSr=r(woa,"dpr"),woa.forEach(t),YSr=r(FUe," \u2014 "),jee=n(FUe,"A",{href:!0});var Aoa=s(jee);KSr=r(Aoa,"TFDPRQuestionEncoder"),Aoa.forEach(t),ZSr=r(FUe," (DPR model)"),FUe.forEach(t),eRr=i(D),s5=n(D,"LI",{});var TUe=s(s5);lAe=n(TUe,"STRONG",{});var Loa=s(lAe);oRr=r(Loa,"electra"),Loa.forEach(t),rRr=r(TUe," \u2014 "),Dee=n(TUe,"A",{href:!0});var yoa=s(Dee);tRr=r(yoa,"TFElectraModel"),yoa.forEach(t),aRr=r(TUe," (ELECTRA model)"),TUe.forEach(t),nRr=i(D),l5=n(D,"LI",{});var MUe=s(l5);iAe=n(MUe,"STRONG",{});var xoa=s(iAe);sRr=r(xoa,"flaubert"),xoa.forEach(t),lRr=r(MUe," \u2014 "),Gee=n(MUe,"A",{href:!0});var $oa=s(Gee);iRr=r($oa,"TFFlaubertModel"),$oa.forEach(t),dRr=r(MUe," (FlauBERT model)"),MUe.forEach(t),mRr=i(D),Fl=n(D,"LI",{});var nI=s(Fl);dAe=n(nI,"STRONG",{});var koa=s(dAe);cRr=r(koa,"funnel"),koa.forEach(t),fRr=r(nI," \u2014 "),Oee=n(nI,"A",{href:!0});var Soa=s(Oee);gRr=r(Soa,"TFFunnelModel"),Soa.forEach(t),hRr=r(nI," or "),Vee=n(nI,"A",{href:!0});var Roa=s(Vee);uRr=r(Roa,"TFFunnelBaseModel"),Roa.forEach(t),pRr=r(nI," (Funnel Transformer model)"),nI.forEach(t),_Rr=i(D),i5=n(D,"LI",{});var EUe=s(i5);mAe=n(EUe,"STRONG",{});var Poa=s(mAe);bRr=r(Poa,"gpt2"),Poa.forEach(t),vRr=r(EUe," \u2014 "),Xee=n(EUe,"A",{href:!0});var Boa=s(Xee);FRr=r(Boa,"TFGPT2Model"),Boa.forEach(t),TRr=r(EUe," (OpenAI GPT-2 model)"),EUe.forEach(t),MRr=i(D),d5=n(D,"LI",{});var CUe=s(d5);cAe=n(CUe,"STRONG",{});var Ioa=s(cAe);ERr=r(Ioa,"gptj"),Ioa.forEach(t),CRr=r(CUe," \u2014 "),zee=n(CUe,"A",{href:!0});var Noa=s(zee);wRr=r(Noa,"TFGPTJModel"),Noa.forEach(t),ARr=r(CUe," (GPT-J model)"),CUe.forEach(t),LRr=i(D),m5=n(D,"LI",{});var wUe=s(m5);fAe=n(wUe,"STRONG",{});var qoa=s(fAe);yRr=r(qoa,"groupvit"),qoa.forEach(t),xRr=r(wUe," \u2014 "),Qee=n(wUe,"A",{href:!0});var joa=s(Qee);$Rr=r(joa,"TFGroupViTModel"),joa.forEach(t),kRr=r(wUe," (GroupViT model)"),wUe.forEach(t),SRr=i(D),c5=n(D,"LI",{});var AUe=s(c5);gAe=n(AUe,"STRONG",{});var Doa=s(gAe);RRr=r(Doa,"hubert"),Doa.forEach(t),PRr=r(AUe," \u2014 "),Wee=n(AUe,"A",{href:!0});var Goa=s(Wee);BRr=r(Goa,"TFHubertModel"),Goa.forEach(t),IRr=r(AUe," (Hubert model)"),AUe.forEach(t),NRr=i(D),f5=n(D,"LI",{});var LUe=s(f5);hAe=n(LUe,"STRONG",{});var Ooa=s(hAe);qRr=r(Ooa,"layoutlm"),Ooa.forEach(t),jRr=r(LUe," \u2014 "),Uee=n(LUe,"A",{href:!0});var Voa=s(Uee);DRr=r(Voa,"TFLayoutLMModel"),Voa.forEach(t),GRr=r(LUe," (LayoutLM model)"),LUe.forEach(t),ORr=i(D),g5=n(D,"LI",{});var yUe=s(g5);uAe=n(yUe,"STRONG",{});var Xoa=s(uAe);VRr=r(Xoa,"layoutlmv3"),Xoa.forEach(t),XRr=r(yUe," \u2014 "),Hee=n(yUe,"A",{href:!0});var zoa=s(Hee);zRr=r(zoa,"TFLayoutLMv3Model"),zoa.forEach(t),QRr=r(yUe," (LayoutLMv3 model)"),yUe.forEach(t),WRr=i(D),h5=n(D,"LI",{});var xUe=s(h5);pAe=n(xUe,"STRONG",{});var Qoa=s(pAe);URr=r(Qoa,"led"),Qoa.forEach(t),HRr=r(xUe," \u2014 "),Jee=n(xUe,"A",{href:!0});var Woa=s(Jee);JRr=r(Woa,"TFLEDModel"),Woa.forEach(t),YRr=r(xUe," (LED model)"),xUe.forEach(t),KRr=i(D),u5=n(D,"LI",{});var $Ue=s(u5);_Ae=n($Ue,"STRONG",{});var Uoa=s(_Ae);ZRr=r(Uoa,"longformer"),Uoa.forEach(t),ePr=r($Ue," \u2014 "),Yee=n($Ue,"A",{href:!0});var Hoa=s(Yee);oPr=r(Hoa,"TFLongformerModel"),Hoa.forEach(t),rPr=r($Ue," (Longformer model)"),$Ue.forEach(t),tPr=i(D),p5=n(D,"LI",{});var kUe=s(p5);bAe=n(kUe,"STRONG",{});var Joa=s(bAe);aPr=r(Joa,"lxmert"),Joa.forEach(t),nPr=r(kUe," \u2014 "),Kee=n(kUe,"A",{href:!0});var Yoa=s(Kee);sPr=r(Yoa,"TFLxmertModel"),Yoa.forEach(t),lPr=r(kUe," (LXMERT model)"),kUe.forEach(t),iPr=i(D),_5=n(D,"LI",{});var SUe=s(_5);vAe=n(SUe,"STRONG",{});var Koa=s(vAe);dPr=r(Koa,"marian"),Koa.forEach(t),mPr=r(SUe," \u2014 "),Zee=n(SUe,"A",{href:!0});var Zoa=s(Zee);cPr=r(Zoa,"TFMarianModel"),Zoa.forEach(t),fPr=r(SUe," (Marian model)"),SUe.forEach(t),gPr=i(D),b5=n(D,"LI",{});var RUe=s(b5);FAe=n(RUe,"STRONG",{});var era=s(FAe);hPr=r(era,"mbart"),era.forEach(t),uPr=r(RUe," \u2014 "),eoe=n(RUe,"A",{href:!0});var ora=s(eoe);pPr=r(ora,"TFMBartModel"),ora.forEach(t),_Pr=r(RUe," (mBART model)"),RUe.forEach(t),bPr=i(D),v5=n(D,"LI",{});var PUe=s(v5);TAe=n(PUe,"STRONG",{});var rra=s(TAe);vPr=r(rra,"mobilebert"),rra.forEach(t),FPr=r(PUe," \u2014 "),ooe=n(PUe,"A",{href:!0});var tra=s(ooe);TPr=r(tra,"TFMobileBertModel"),tra.forEach(t),MPr=r(PUe," (MobileBERT model)"),PUe.forEach(t),EPr=i(D),F5=n(D,"LI",{});var BUe=s(F5);MAe=n(BUe,"STRONG",{});var ara=s(MAe);CPr=r(ara,"mobilevit"),ara.forEach(t),wPr=r(BUe," \u2014 "),roe=n(BUe,"A",{href:!0});var nra=s(roe);APr=r(nra,"TFMobileViTModel"),nra.forEach(t),LPr=r(BUe," (MobileViT model)"),BUe.forEach(t),yPr=i(D),T5=n(D,"LI",{});var IUe=s(T5);EAe=n(IUe,"STRONG",{});var sra=s(EAe);xPr=r(sra,"mpnet"),sra.forEach(t),$Pr=r(IUe," \u2014 "),toe=n(IUe,"A",{href:!0});var lra=s(toe);kPr=r(lra,"TFMPNetModel"),lra.forEach(t),SPr=r(IUe," (MPNet model)"),IUe.forEach(t),RPr=i(D),M5=n(D,"LI",{});var NUe=s(M5);CAe=n(NUe,"STRONG",{});var ira=s(CAe);PPr=r(ira,"mt5"),ira.forEach(t),BPr=r(NUe," \u2014 "),aoe=n(NUe,"A",{href:!0});var dra=s(aoe);IPr=r(dra,"TFMT5Model"),dra.forEach(t),NPr=r(NUe," (MT5 model)"),NUe.forEach(t),qPr=i(D),E5=n(D,"LI",{});var qUe=s(E5);wAe=n(qUe,"STRONG",{});var mra=s(wAe);jPr=r(mra,"openai-gpt"),mra.forEach(t),DPr=r(qUe," \u2014 "),noe=n(qUe,"A",{href:!0});var cra=s(noe);GPr=r(cra,"TFOpenAIGPTModel"),cra.forEach(t),OPr=r(qUe," (OpenAI GPT model)"),qUe.forEach(t),VPr=i(D),C5=n(D,"LI",{});var jUe=s(C5);AAe=n(jUe,"STRONG",{});var fra=s(AAe);XPr=r(fra,"opt"),fra.forEach(t),zPr=r(jUe," \u2014 "),soe=n(jUe,"A",{href:!0});var gra=s(soe);QPr=r(gra,"TFOPTModel"),gra.forEach(t),WPr=r(jUe," (OPT model)"),jUe.forEach(t),UPr=i(D),w5=n(D,"LI",{});var DUe=s(w5);LAe=n(DUe,"STRONG",{});var hra=s(LAe);HPr=r(hra,"pegasus"),hra.forEach(t),JPr=r(DUe," \u2014 "),loe=n(DUe,"A",{href:!0});var ura=s(loe);YPr=r(ura,"TFPegasusModel"),ura.forEach(t),KPr=r(DUe," (Pegasus model)"),DUe.forEach(t),ZPr=i(D),A5=n(D,"LI",{});var GUe=s(A5);yAe=n(GUe,"STRONG",{});var pra=s(yAe);eBr=r(pra,"regnet"),pra.forEach(t),oBr=r(GUe," \u2014 "),ioe=n(GUe,"A",{href:!0});var _ra=s(ioe);rBr=r(_ra,"TFRegNetModel"),_ra.forEach(t),tBr=r(GUe," (RegNet model)"),GUe.forEach(t),aBr=i(D),L5=n(D,"LI",{});var OUe=s(L5);xAe=n(OUe,"STRONG",{});var bra=s(xAe);nBr=r(bra,"rembert"),bra.forEach(t),sBr=r(OUe," \u2014 "),doe=n(OUe,"A",{href:!0});var vra=s(doe);lBr=r(vra,"TFRemBertModel"),vra.forEach(t),iBr=r(OUe," (RemBERT model)"),OUe.forEach(t),dBr=i(D),y5=n(D,"LI",{});var VUe=s(y5);$Ae=n(VUe,"STRONG",{});var Fra=s($Ae);mBr=r(Fra,"resnet"),Fra.forEach(t),cBr=r(VUe," \u2014 "),moe=n(VUe,"A",{href:!0});var Tra=s(moe);fBr=r(Tra,"TFResNetModel"),Tra.forEach(t),gBr=r(VUe," (ResNet model)"),VUe.forEach(t),hBr=i(D),x5=n(D,"LI",{});var XUe=s(x5);kAe=n(XUe,"STRONG",{});var Mra=s(kAe);uBr=r(Mra,"roberta"),Mra.forEach(t),pBr=r(XUe," \u2014 "),coe=n(XUe,"A",{href:!0});var Era=s(coe);_Br=r(Era,"TFRobertaModel"),Era.forEach(t),bBr=r(XUe," (RoBERTa model)"),XUe.forEach(t),vBr=i(D),$5=n(D,"LI",{});var zUe=s($5);SAe=n(zUe,"STRONG",{});var Cra=s(SAe);FBr=r(Cra,"roformer"),Cra.forEach(t),TBr=r(zUe," \u2014 "),foe=n(zUe,"A",{href:!0});var wra=s(foe);MBr=r(wra,"TFRoFormerModel"),wra.forEach(t),EBr=r(zUe," (RoFormer model)"),zUe.forEach(t),CBr=i(D),k5=n(D,"LI",{});var QUe=s(k5);RAe=n(QUe,"STRONG",{});var Ara=s(RAe);wBr=r(Ara,"segformer"),Ara.forEach(t),ABr=r(QUe," \u2014 "),goe=n(QUe,"A",{href:!0});var Lra=s(goe);LBr=r(Lra,"TFSegformerModel"),Lra.forEach(t),yBr=r(QUe," (SegFormer model)"),QUe.forEach(t),xBr=i(D),S5=n(D,"LI",{});var WUe=s(S5);PAe=n(WUe,"STRONG",{});var yra=s(PAe);$Br=r(yra,"speech_to_text"),yra.forEach(t),kBr=r(WUe," \u2014 "),hoe=n(WUe,"A",{href:!0});var xra=s(hoe);SBr=r(xra,"TFSpeech2TextModel"),xra.forEach(t),RBr=r(WUe," (Speech2Text model)"),WUe.forEach(t),PBr=i(D),R5=n(D,"LI",{});var UUe=s(R5);BAe=n(UUe,"STRONG",{});var $ra=s(BAe);BBr=r($ra,"swin"),$ra.forEach(t),IBr=r(UUe," \u2014 "),uoe=n(UUe,"A",{href:!0});var kra=s(uoe);NBr=r(kra,"TFSwinModel"),kra.forEach(t),qBr=r(UUe," (Swin Transformer model)"),UUe.forEach(t),jBr=i(D),P5=n(D,"LI",{});var HUe=s(P5);IAe=n(HUe,"STRONG",{});var Sra=s(IAe);DBr=r(Sra,"t5"),Sra.forEach(t),GBr=r(HUe," \u2014 "),poe=n(HUe,"A",{href:!0});var Rra=s(poe);OBr=r(Rra,"TFT5Model"),Rra.forEach(t),VBr=r(HUe," (T5 model)"),HUe.forEach(t),XBr=i(D),B5=n(D,"LI",{});var JUe=s(B5);NAe=n(JUe,"STRONG",{});var Pra=s(NAe);zBr=r(Pra,"tapas"),Pra.forEach(t),QBr=r(JUe," \u2014 "),_oe=n(JUe,"A",{href:!0});var Bra=s(_oe);WBr=r(Bra,"TFTapasModel"),Bra.forEach(t),UBr=r(JUe," (TAPAS model)"),JUe.forEach(t),HBr=i(D),I5=n(D,"LI",{});var YUe=s(I5);qAe=n(YUe,"STRONG",{});var Ira=s(qAe);JBr=r(Ira,"transfo-xl"),Ira.forEach(t),YBr=r(YUe," \u2014 "),boe=n(YUe,"A",{href:!0});var Nra=s(boe);KBr=r(Nra,"TFTransfoXLModel"),Nra.forEach(t),ZBr=r(YUe," (Transformer-XL model)"),YUe.forEach(t),eIr=i(D),N5=n(D,"LI",{});var KUe=s(N5);jAe=n(KUe,"STRONG",{});var qra=s(jAe);oIr=r(qra,"vit"),qra.forEach(t),rIr=r(KUe," \u2014 "),voe=n(KUe,"A",{href:!0});var jra=s(voe);tIr=r(jra,"TFViTModel"),jra.forEach(t),aIr=r(KUe," (ViT model)"),KUe.forEach(t),nIr=i(D),q5=n(D,"LI",{});var ZUe=s(q5);DAe=n(ZUe,"STRONG",{});var Dra=s(DAe);sIr=r(Dra,"vit_mae"),Dra.forEach(t),lIr=r(ZUe," \u2014 "),Foe=n(ZUe,"A",{href:!0});var Gra=s(Foe);iIr=r(Gra,"TFViTMAEModel"),Gra.forEach(t),dIr=r(ZUe," (ViTMAE model)"),ZUe.forEach(t),mIr=i(D),j5=n(D,"LI",{});var eHe=s(j5);GAe=n(eHe,"STRONG",{});var Ora=s(GAe);cIr=r(Ora,"wav2vec2"),Ora.forEach(t),fIr=r(eHe," \u2014 "),Toe=n(eHe,"A",{href:!0});var Vra=s(Toe);gIr=r(Vra,"TFWav2Vec2Model"),Vra.forEach(t),hIr=r(eHe," (Wav2Vec2 model)"),eHe.forEach(t),uIr=i(D),D5=n(D,"LI",{});var oHe=s(D5);OAe=n(oHe,"STRONG",{});var Xra=s(OAe);pIr=r(Xra,"xglm"),Xra.forEach(t),_Ir=r(oHe," \u2014 "),Moe=n(oHe,"A",{href:!0});var zra=s(Moe);bIr=r(zra,"TFXGLMModel"),zra.forEach(t),vIr=r(oHe," (XGLM model)"),oHe.forEach(t),FIr=i(D),G5=n(D,"LI",{});var rHe=s(G5);VAe=n(rHe,"STRONG",{});var Qra=s(VAe);TIr=r(Qra,"xlm"),Qra.forEach(t),MIr=r(rHe," \u2014 "),Eoe=n(rHe,"A",{href:!0});var Wra=s(Eoe);EIr=r(Wra,"TFXLMModel"),Wra.forEach(t),CIr=r(rHe," (XLM model)"),rHe.forEach(t),wIr=i(D),O5=n(D,"LI",{});var tHe=s(O5);XAe=n(tHe,"STRONG",{});var Ura=s(XAe);AIr=r(Ura,"xlm-roberta"),Ura.forEach(t),LIr=r(tHe," \u2014 "),Coe=n(tHe,"A",{href:!0});var Hra=s(Coe);yIr=r(Hra,"TFXLMRobertaModel"),Hra.forEach(t),xIr=r(tHe," (XLM-RoBERTa model)"),tHe.forEach(t),$Ir=i(D),V5=n(D,"LI",{});var aHe=s(V5);zAe=n(aHe,"STRONG",{});var Jra=s(zAe);kIr=r(Jra,"xlnet"),Jra.forEach(t),SIr=r(aHe," \u2014 "),woe=n(aHe,"A",{href:!0});var Yra=s(woe);RIr=r(Yra,"TFXLNetModel"),Yra.forEach(t),PIr=r(aHe," (XLNet model)"),aHe.forEach(t),D.forEach(t),BIr=i(ri),T(X5.$$.fragment,ri),ri.forEach(t),oi.forEach(t),yoo=i(c),Qm=n(c,"H2",{class:!0});var Oto=s(Qm);z5=n(Oto,"A",{id:!0,class:!0,href:!0});var Kra=s(z5);QAe=n(Kra,"SPAN",{});var Zra=s(QAe);T(lS.$$.fragment,Zra),Zra.forEach(t),Kra.forEach(t),IIr=i(Oto),WAe=n(Oto,"SPAN",{});var eta=s(WAe);NIr=r(eta,"TFAutoModelForPreTraining"),eta.forEach(t),Oto.forEach(t),xoo=i(c),lr=n(c,"DIV",{class:!0});var ti=s(lr);T(iS.$$.fragment,ti),qIr=i(ti),Wm=n(ti,"P",{});var hde=s(Wm);jIr=r(hde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Aoe=n(hde,"A",{href:!0});var ota=s(Aoe);DIr=r(ota,"from_pretrained()"),ota.forEach(t),GIr=r(hde," class method or the "),Loe=n(hde,"A",{href:!0});var rta=s(Loe);OIr=r(rta,"from_config()"),rta.forEach(t),VIr=r(hde,` class
method.`),hde.forEach(t),XIr=i(ti),dS=n(ti,"P",{});var Vto=s(dS);zIr=r(Vto,"This class cannot be instantiated directly using "),UAe=n(Vto,"CODE",{});var tta=s(UAe);QIr=r(tta,"__init__()"),tta.forEach(t),WIr=r(Vto," (throws an error)."),Vto.forEach(t),UIr=i(ti),zt=n(ti,"DIV",{class:!0});var a9=s(zt);T(mS.$$.fragment,a9),HIr=i(a9),HAe=n(a9,"P",{});var ata=s(HAe);JIr=r(ata,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),ata.forEach(t),YIr=i(a9),Um=n(a9,"P",{});var ude=s(Um);KIr=r(ude,`Note:
Loading a model from its configuration file does `),JAe=n(ude,"STRONG",{});var nta=s(JAe);ZIr=r(nta,"not"),nta.forEach(t),eNr=r(ude,` load the model weights. It only affects the
model\u2019s configuration. Use `),yoe=n(ude,"A",{href:!0});var sta=s(yoe);oNr=r(sta,"from_pretrained()"),sta.forEach(t),rNr=r(ude," to load the model weights."),ude.forEach(t),tNr=i(a9),T(Q5.$$.fragment,a9),a9.forEach(t),aNr=i(ti),Nr=n(ti,"DIV",{class:!0});var ai=s(Nr);T(cS.$$.fragment,ai),nNr=i(ai),YAe=n(ai,"P",{});var lta=s(YAe);sNr=r(lta,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),lta.forEach(t),lNr=i(ai),An=n(ai,"P",{});var n9=s(An);iNr=r(n9,"The model class to instantiate is selected based on the "),KAe=n(n9,"CODE",{});var ita=s(KAe);dNr=r(ita,"model_type"),ita.forEach(t),mNr=r(n9,` property of the config object (either
passed as an argument or loaded from `),ZAe=n(n9,"CODE",{});var dta=s(ZAe);cNr=r(dta,"pretrained_model_name_or_path"),dta.forEach(t),fNr=r(n9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e6e=n(n9,"CODE",{});var mta=s(e6e);gNr=r(mta,"pretrained_model_name_or_path"),mta.forEach(t),hNr=r(n9,":"),n9.forEach(t),uNr=i(ai),le=n(ai,"UL",{});var de=s(le);W5=n(de,"LI",{});var nHe=s(W5);o6e=n(nHe,"STRONG",{});var cta=s(o6e);pNr=r(cta,"albert"),cta.forEach(t),_Nr=r(nHe," \u2014 "),xoe=n(nHe,"A",{href:!0});var fta=s(xoe);bNr=r(fta,"TFAlbertForPreTraining"),fta.forEach(t),vNr=r(nHe," (ALBERT model)"),nHe.forEach(t),FNr=i(de),U5=n(de,"LI",{});var sHe=s(U5);r6e=n(sHe,"STRONG",{});var gta=s(r6e);TNr=r(gta,"bart"),gta.forEach(t),MNr=r(sHe," \u2014 "),$oe=n(sHe,"A",{href:!0});var hta=s($oe);ENr=r(hta,"TFBartForConditionalGeneration"),hta.forEach(t),CNr=r(sHe," (BART model)"),sHe.forEach(t),wNr=i(de),H5=n(de,"LI",{});var lHe=s(H5);t6e=n(lHe,"STRONG",{});var uta=s(t6e);ANr=r(uta,"bert"),uta.forEach(t),LNr=r(lHe," \u2014 "),koe=n(lHe,"A",{href:!0});var pta=s(koe);yNr=r(pta,"TFBertForPreTraining"),pta.forEach(t),xNr=r(lHe," (BERT model)"),lHe.forEach(t),$Nr=i(de),J5=n(de,"LI",{});var iHe=s(J5);a6e=n(iHe,"STRONG",{});var _ta=s(a6e);kNr=r(_ta,"camembert"),_ta.forEach(t),SNr=r(iHe," \u2014 "),Soe=n(iHe,"A",{href:!0});var bta=s(Soe);RNr=r(bta,"TFCamembertForMaskedLM"),bta.forEach(t),PNr=r(iHe," (CamemBERT model)"),iHe.forEach(t),BNr=i(de),Y5=n(de,"LI",{});var dHe=s(Y5);n6e=n(dHe,"STRONG",{});var vta=s(n6e);INr=r(vta,"ctrl"),vta.forEach(t),NNr=r(dHe," \u2014 "),Roe=n(dHe,"A",{href:!0});var Fta=s(Roe);qNr=r(Fta,"TFCTRLLMHeadModel"),Fta.forEach(t),jNr=r(dHe," (CTRL model)"),dHe.forEach(t),DNr=i(de),K5=n(de,"LI",{});var mHe=s(K5);s6e=n(mHe,"STRONG",{});var Tta=s(s6e);GNr=r(Tta,"distilbert"),Tta.forEach(t),ONr=r(mHe," \u2014 "),Poe=n(mHe,"A",{href:!0});var Mta=s(Poe);VNr=r(Mta,"TFDistilBertForMaskedLM"),Mta.forEach(t),XNr=r(mHe," (DistilBERT model)"),mHe.forEach(t),zNr=i(de),Z5=n(de,"LI",{});var cHe=s(Z5);l6e=n(cHe,"STRONG",{});var Eta=s(l6e);QNr=r(Eta,"electra"),Eta.forEach(t),WNr=r(cHe," \u2014 "),Boe=n(cHe,"A",{href:!0});var Cta=s(Boe);UNr=r(Cta,"TFElectraForPreTraining"),Cta.forEach(t),HNr=r(cHe," (ELECTRA model)"),cHe.forEach(t),JNr=i(de),e0=n(de,"LI",{});var fHe=s(e0);i6e=n(fHe,"STRONG",{});var wta=s(i6e);YNr=r(wta,"flaubert"),wta.forEach(t),KNr=r(fHe," \u2014 "),Ioe=n(fHe,"A",{href:!0});var Ata=s(Ioe);ZNr=r(Ata,"TFFlaubertWithLMHeadModel"),Ata.forEach(t),eqr=r(fHe," (FlauBERT model)"),fHe.forEach(t),oqr=i(de),o0=n(de,"LI",{});var gHe=s(o0);d6e=n(gHe,"STRONG",{});var Lta=s(d6e);rqr=r(Lta,"funnel"),Lta.forEach(t),tqr=r(gHe," \u2014 "),Noe=n(gHe,"A",{href:!0});var yta=s(Noe);aqr=r(yta,"TFFunnelForPreTraining"),yta.forEach(t),nqr=r(gHe," (Funnel Transformer model)"),gHe.forEach(t),sqr=i(de),r0=n(de,"LI",{});var hHe=s(r0);m6e=n(hHe,"STRONG",{});var xta=s(m6e);lqr=r(xta,"gpt2"),xta.forEach(t),iqr=r(hHe," \u2014 "),qoe=n(hHe,"A",{href:!0});var $ta=s(qoe);dqr=r($ta,"TFGPT2LMHeadModel"),$ta.forEach(t),mqr=r(hHe," (OpenAI GPT-2 model)"),hHe.forEach(t),cqr=i(de),t0=n(de,"LI",{});var uHe=s(t0);c6e=n(uHe,"STRONG",{});var kta=s(c6e);fqr=r(kta,"layoutlm"),kta.forEach(t),gqr=r(uHe," \u2014 "),joe=n(uHe,"A",{href:!0});var Sta=s(joe);hqr=r(Sta,"TFLayoutLMForMaskedLM"),Sta.forEach(t),uqr=r(uHe," (LayoutLM model)"),uHe.forEach(t),pqr=i(de),a0=n(de,"LI",{});var pHe=s(a0);f6e=n(pHe,"STRONG",{});var Rta=s(f6e);_qr=r(Rta,"lxmert"),Rta.forEach(t),bqr=r(pHe," \u2014 "),Doe=n(pHe,"A",{href:!0});var Pta=s(Doe);vqr=r(Pta,"TFLxmertForPreTraining"),Pta.forEach(t),Fqr=r(pHe," (LXMERT model)"),pHe.forEach(t),Tqr=i(de),n0=n(de,"LI",{});var _He=s(n0);g6e=n(_He,"STRONG",{});var Bta=s(g6e);Mqr=r(Bta,"mobilebert"),Bta.forEach(t),Eqr=r(_He," \u2014 "),Goe=n(_He,"A",{href:!0});var Ita=s(Goe);Cqr=r(Ita,"TFMobileBertForPreTraining"),Ita.forEach(t),wqr=r(_He," (MobileBERT model)"),_He.forEach(t),Aqr=i(de),s0=n(de,"LI",{});var bHe=s(s0);h6e=n(bHe,"STRONG",{});var Nta=s(h6e);Lqr=r(Nta,"mpnet"),Nta.forEach(t),yqr=r(bHe," \u2014 "),Ooe=n(bHe,"A",{href:!0});var qta=s(Ooe);xqr=r(qta,"TFMPNetForMaskedLM"),qta.forEach(t),$qr=r(bHe," (MPNet model)"),bHe.forEach(t),kqr=i(de),l0=n(de,"LI",{});var vHe=s(l0);u6e=n(vHe,"STRONG",{});var jta=s(u6e);Sqr=r(jta,"openai-gpt"),jta.forEach(t),Rqr=r(vHe," \u2014 "),Voe=n(vHe,"A",{href:!0});var Dta=s(Voe);Pqr=r(Dta,"TFOpenAIGPTLMHeadModel"),Dta.forEach(t),Bqr=r(vHe," (OpenAI GPT model)"),vHe.forEach(t),Iqr=i(de),i0=n(de,"LI",{});var FHe=s(i0);p6e=n(FHe,"STRONG",{});var Gta=s(p6e);Nqr=r(Gta,"roberta"),Gta.forEach(t),qqr=r(FHe," \u2014 "),Xoe=n(FHe,"A",{href:!0});var Ota=s(Xoe);jqr=r(Ota,"TFRobertaForMaskedLM"),Ota.forEach(t),Dqr=r(FHe," (RoBERTa model)"),FHe.forEach(t),Gqr=i(de),d0=n(de,"LI",{});var THe=s(d0);_6e=n(THe,"STRONG",{});var Vta=s(_6e);Oqr=r(Vta,"t5"),Vta.forEach(t),Vqr=r(THe," \u2014 "),zoe=n(THe,"A",{href:!0});var Xta=s(zoe);Xqr=r(Xta,"TFT5ForConditionalGeneration"),Xta.forEach(t),zqr=r(THe," (T5 model)"),THe.forEach(t),Qqr=i(de),m0=n(de,"LI",{});var MHe=s(m0);b6e=n(MHe,"STRONG",{});var zta=s(b6e);Wqr=r(zta,"tapas"),zta.forEach(t),Uqr=r(MHe," \u2014 "),Qoe=n(MHe,"A",{href:!0});var Qta=s(Qoe);Hqr=r(Qta,"TFTapasForMaskedLM"),Qta.forEach(t),Jqr=r(MHe," (TAPAS model)"),MHe.forEach(t),Yqr=i(de),c0=n(de,"LI",{});var EHe=s(c0);v6e=n(EHe,"STRONG",{});var Wta=s(v6e);Kqr=r(Wta,"transfo-xl"),Wta.forEach(t),Zqr=r(EHe," \u2014 "),Woe=n(EHe,"A",{href:!0});var Uta=s(Woe);ejr=r(Uta,"TFTransfoXLLMHeadModel"),Uta.forEach(t),ojr=r(EHe," (Transformer-XL model)"),EHe.forEach(t),rjr=i(de),f0=n(de,"LI",{});var CHe=s(f0);F6e=n(CHe,"STRONG",{});var Hta=s(F6e);tjr=r(Hta,"vit_mae"),Hta.forEach(t),ajr=r(CHe," \u2014 "),Uoe=n(CHe,"A",{href:!0});var Jta=s(Uoe);njr=r(Jta,"TFViTMAEForPreTraining"),Jta.forEach(t),sjr=r(CHe," (ViTMAE model)"),CHe.forEach(t),ljr=i(de),g0=n(de,"LI",{});var wHe=s(g0);T6e=n(wHe,"STRONG",{});var Yta=s(T6e);ijr=r(Yta,"xlm"),Yta.forEach(t),djr=r(wHe," \u2014 "),Hoe=n(wHe,"A",{href:!0});var Kta=s(Hoe);mjr=r(Kta,"TFXLMWithLMHeadModel"),Kta.forEach(t),cjr=r(wHe," (XLM model)"),wHe.forEach(t),fjr=i(de),h0=n(de,"LI",{});var AHe=s(h0);M6e=n(AHe,"STRONG",{});var Zta=s(M6e);gjr=r(Zta,"xlm-roberta"),Zta.forEach(t),hjr=r(AHe," \u2014 "),Joe=n(AHe,"A",{href:!0});var eaa=s(Joe);ujr=r(eaa,"TFXLMRobertaForMaskedLM"),eaa.forEach(t),pjr=r(AHe," (XLM-RoBERTa model)"),AHe.forEach(t),_jr=i(de),u0=n(de,"LI",{});var LHe=s(u0);E6e=n(LHe,"STRONG",{});var oaa=s(E6e);bjr=r(oaa,"xlnet"),oaa.forEach(t),vjr=r(LHe," \u2014 "),Yoe=n(LHe,"A",{href:!0});var raa=s(Yoe);Fjr=r(raa,"TFXLNetLMHeadModel"),raa.forEach(t),Tjr=r(LHe," (XLNet model)"),LHe.forEach(t),de.forEach(t),Mjr=i(ai),T(p0.$$.fragment,ai),ai.forEach(t),ti.forEach(t),$oo=i(c),Hm=n(c,"H2",{class:!0});var Xto=s(Hm);_0=n(Xto,"A",{id:!0,class:!0,href:!0});var taa=s(_0);C6e=n(taa,"SPAN",{});var aaa=s(C6e);T(fS.$$.fragment,aaa),aaa.forEach(t),taa.forEach(t),Ejr=i(Xto),w6e=n(Xto,"SPAN",{});var naa=s(w6e);Cjr=r(naa,"TFAutoModelForCausalLM"),naa.forEach(t),Xto.forEach(t),koo=i(c),ir=n(c,"DIV",{class:!0});var ni=s(ir);T(gS.$$.fragment,ni),wjr=i(ni),Jm=n(ni,"P",{});var pde=s(Jm);Ajr=r(pde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Koe=n(pde,"A",{href:!0});var saa=s(Koe);Ljr=r(saa,"from_pretrained()"),saa.forEach(t),yjr=r(pde," class method or the "),Zoe=n(pde,"A",{href:!0});var laa=s(Zoe);xjr=r(laa,"from_config()"),laa.forEach(t),$jr=r(pde,` class
method.`),pde.forEach(t),kjr=i(ni),hS=n(ni,"P",{});var zto=s(hS);Sjr=r(zto,"This class cannot be instantiated directly using "),A6e=n(zto,"CODE",{});var iaa=s(A6e);Rjr=r(iaa,"__init__()"),iaa.forEach(t),Pjr=r(zto," (throws an error)."),zto.forEach(t),Bjr=i(ni),Qt=n(ni,"DIV",{class:!0});var s9=s(Qt);T(uS.$$.fragment,s9),Ijr=i(s9),L6e=n(s9,"P",{});var daa=s(L6e);Njr=r(daa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),daa.forEach(t),qjr=i(s9),Ym=n(s9,"P",{});var _de=s(Ym);jjr=r(_de,`Note:
Loading a model from its configuration file does `),y6e=n(_de,"STRONG",{});var maa=s(y6e);Djr=r(maa,"not"),maa.forEach(t),Gjr=r(_de,` load the model weights. It only affects the
model\u2019s configuration. Use `),ere=n(_de,"A",{href:!0});var caa=s(ere);Ojr=r(caa,"from_pretrained()"),caa.forEach(t),Vjr=r(_de," to load the model weights."),_de.forEach(t),Xjr=i(s9),T(b0.$$.fragment,s9),s9.forEach(t),zjr=i(ni),qr=n(ni,"DIV",{class:!0});var si=s(qr);T(pS.$$.fragment,si),Qjr=i(si),x6e=n(si,"P",{});var faa=s(x6e);Wjr=r(faa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),faa.forEach(t),Ujr=i(si),Ln=n(si,"P",{});var l9=s(Ln);Hjr=r(l9,"The model class to instantiate is selected based on the "),$6e=n(l9,"CODE",{});var gaa=s($6e);Jjr=r(gaa,"model_type"),gaa.forEach(t),Yjr=r(l9,` property of the config object (either
passed as an argument or loaded from `),k6e=n(l9,"CODE",{});var haa=s(k6e);Kjr=r(haa,"pretrained_model_name_or_path"),haa.forEach(t),Zjr=r(l9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S6e=n(l9,"CODE",{});var uaa=s(S6e);eDr=r(uaa,"pretrained_model_name_or_path"),uaa.forEach(t),oDr=r(l9,":"),l9.forEach(t),rDr=i(si),Me=n(si,"UL",{});var Ce=s(Me);v0=n(Ce,"LI",{});var yHe=s(v0);R6e=n(yHe,"STRONG",{});var paa=s(R6e);tDr=r(paa,"bert"),paa.forEach(t),aDr=r(yHe," \u2014 "),ore=n(yHe,"A",{href:!0});var _aa=s(ore);nDr=r(_aa,"TFBertLMHeadModel"),_aa.forEach(t),sDr=r(yHe," (BERT model)"),yHe.forEach(t),lDr=i(Ce),F0=n(Ce,"LI",{});var xHe=s(F0);P6e=n(xHe,"STRONG",{});var baa=s(P6e);iDr=r(baa,"camembert"),baa.forEach(t),dDr=r(xHe," \u2014 "),rre=n(xHe,"A",{href:!0});var vaa=s(rre);mDr=r(vaa,"TFCamembertForCausalLM"),vaa.forEach(t),cDr=r(xHe," (CamemBERT model)"),xHe.forEach(t),fDr=i(Ce),T0=n(Ce,"LI",{});var $He=s(T0);B6e=n($He,"STRONG",{});var Faa=s(B6e);gDr=r(Faa,"ctrl"),Faa.forEach(t),hDr=r($He," \u2014 "),tre=n($He,"A",{href:!0});var Taa=s(tre);uDr=r(Taa,"TFCTRLLMHeadModel"),Taa.forEach(t),pDr=r($He," (CTRL model)"),$He.forEach(t),_Dr=i(Ce),M0=n(Ce,"LI",{});var kHe=s(M0);I6e=n(kHe,"STRONG",{});var Maa=s(I6e);bDr=r(Maa,"gpt2"),Maa.forEach(t),vDr=r(kHe," \u2014 "),are=n(kHe,"A",{href:!0});var Eaa=s(are);FDr=r(Eaa,"TFGPT2LMHeadModel"),Eaa.forEach(t),TDr=r(kHe," (OpenAI GPT-2 model)"),kHe.forEach(t),MDr=i(Ce),E0=n(Ce,"LI",{});var SHe=s(E0);N6e=n(SHe,"STRONG",{});var Caa=s(N6e);EDr=r(Caa,"gptj"),Caa.forEach(t),CDr=r(SHe," \u2014 "),nre=n(SHe,"A",{href:!0});var waa=s(nre);wDr=r(waa,"TFGPTJForCausalLM"),waa.forEach(t),ADr=r(SHe," (GPT-J model)"),SHe.forEach(t),LDr=i(Ce),C0=n(Ce,"LI",{});var RHe=s(C0);q6e=n(RHe,"STRONG",{});var Aaa=s(q6e);yDr=r(Aaa,"openai-gpt"),Aaa.forEach(t),xDr=r(RHe," \u2014 "),sre=n(RHe,"A",{href:!0});var Laa=s(sre);$Dr=r(Laa,"TFOpenAIGPTLMHeadModel"),Laa.forEach(t),kDr=r(RHe," (OpenAI GPT model)"),RHe.forEach(t),SDr=i(Ce),w0=n(Ce,"LI",{});var PHe=s(w0);j6e=n(PHe,"STRONG",{});var yaa=s(j6e);RDr=r(yaa,"opt"),yaa.forEach(t),PDr=r(PHe," \u2014 "),lre=n(PHe,"A",{href:!0});var xaa=s(lre);BDr=r(xaa,"TFOPTForCausalLM"),xaa.forEach(t),IDr=r(PHe," (OPT model)"),PHe.forEach(t),NDr=i(Ce),A0=n(Ce,"LI",{});var BHe=s(A0);D6e=n(BHe,"STRONG",{});var $aa=s(D6e);qDr=r($aa,"rembert"),$aa.forEach(t),jDr=r(BHe," \u2014 "),ire=n(BHe,"A",{href:!0});var kaa=s(ire);DDr=r(kaa,"TFRemBertForCausalLM"),kaa.forEach(t),GDr=r(BHe," (RemBERT model)"),BHe.forEach(t),ODr=i(Ce),L0=n(Ce,"LI",{});var IHe=s(L0);G6e=n(IHe,"STRONG",{});var Saa=s(G6e);VDr=r(Saa,"roberta"),Saa.forEach(t),XDr=r(IHe," \u2014 "),dre=n(IHe,"A",{href:!0});var Raa=s(dre);zDr=r(Raa,"TFRobertaForCausalLM"),Raa.forEach(t),QDr=r(IHe," (RoBERTa model)"),IHe.forEach(t),WDr=i(Ce),y0=n(Ce,"LI",{});var NHe=s(y0);O6e=n(NHe,"STRONG",{});var Paa=s(O6e);UDr=r(Paa,"roformer"),Paa.forEach(t),HDr=r(NHe," \u2014 "),mre=n(NHe,"A",{href:!0});var Baa=s(mre);JDr=r(Baa,"TFRoFormerForCausalLM"),Baa.forEach(t),YDr=r(NHe," (RoFormer model)"),NHe.forEach(t),KDr=i(Ce),x0=n(Ce,"LI",{});var qHe=s(x0);V6e=n(qHe,"STRONG",{});var Iaa=s(V6e);ZDr=r(Iaa,"transfo-xl"),Iaa.forEach(t),eGr=r(qHe," \u2014 "),cre=n(qHe,"A",{href:!0});var Naa=s(cre);oGr=r(Naa,"TFTransfoXLLMHeadModel"),Naa.forEach(t),rGr=r(qHe," (Transformer-XL model)"),qHe.forEach(t),tGr=i(Ce),$0=n(Ce,"LI",{});var jHe=s($0);X6e=n(jHe,"STRONG",{});var qaa=s(X6e);aGr=r(qaa,"xglm"),qaa.forEach(t),nGr=r(jHe," \u2014 "),fre=n(jHe,"A",{href:!0});var jaa=s(fre);sGr=r(jaa,"TFXGLMForCausalLM"),jaa.forEach(t),lGr=r(jHe," (XGLM model)"),jHe.forEach(t),iGr=i(Ce),k0=n(Ce,"LI",{});var DHe=s(k0);z6e=n(DHe,"STRONG",{});var Daa=s(z6e);dGr=r(Daa,"xlm"),Daa.forEach(t),mGr=r(DHe," \u2014 "),gre=n(DHe,"A",{href:!0});var Gaa=s(gre);cGr=r(Gaa,"TFXLMWithLMHeadModel"),Gaa.forEach(t),fGr=r(DHe," (XLM model)"),DHe.forEach(t),gGr=i(Ce),S0=n(Ce,"LI",{});var GHe=s(S0);Q6e=n(GHe,"STRONG",{});var Oaa=s(Q6e);hGr=r(Oaa,"xlnet"),Oaa.forEach(t),uGr=r(GHe," \u2014 "),hre=n(GHe,"A",{href:!0});var Vaa=s(hre);pGr=r(Vaa,"TFXLNetLMHeadModel"),Vaa.forEach(t),_Gr=r(GHe," (XLNet model)"),GHe.forEach(t),Ce.forEach(t),bGr=i(si),T(R0.$$.fragment,si),si.forEach(t),ni.forEach(t),Soo=i(c),Km=n(c,"H2",{class:!0});var Qto=s(Km);P0=n(Qto,"A",{id:!0,class:!0,href:!0});var Xaa=s(P0);W6e=n(Xaa,"SPAN",{});var zaa=s(W6e);T(_S.$$.fragment,zaa),zaa.forEach(t),Xaa.forEach(t),vGr=i(Qto),U6e=n(Qto,"SPAN",{});var Qaa=s(U6e);FGr=r(Qaa,"TFAutoModelForImageClassification"),Qaa.forEach(t),Qto.forEach(t),Roo=i(c),dr=n(c,"DIV",{class:!0});var li=s(dr);T(bS.$$.fragment,li),TGr=i(li),Zm=n(li,"P",{});var bde=s(Zm);MGr=r(bde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),ure=n(bde,"A",{href:!0});var Waa=s(ure);EGr=r(Waa,"from_pretrained()"),Waa.forEach(t),CGr=r(bde," class method or the "),pre=n(bde,"A",{href:!0});var Uaa=s(pre);wGr=r(Uaa,"from_config()"),Uaa.forEach(t),AGr=r(bde,` class
method.`),bde.forEach(t),LGr=i(li),vS=n(li,"P",{});var Wto=s(vS);yGr=r(Wto,"This class cannot be instantiated directly using "),H6e=n(Wto,"CODE",{});var Haa=s(H6e);xGr=r(Haa,"__init__()"),Haa.forEach(t),$Gr=r(Wto," (throws an error)."),Wto.forEach(t),kGr=i(li),Wt=n(li,"DIV",{class:!0});var i9=s(Wt);T(FS.$$.fragment,i9),SGr=i(i9),J6e=n(i9,"P",{});var Jaa=s(J6e);RGr=r(Jaa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Jaa.forEach(t),PGr=i(i9),ec=n(i9,"P",{});var vde=s(ec);BGr=r(vde,`Note:
Loading a model from its configuration file does `),Y6e=n(vde,"STRONG",{});var Yaa=s(Y6e);IGr=r(Yaa,"not"),Yaa.forEach(t),NGr=r(vde,` load the model weights. It only affects the
model\u2019s configuration. Use `),_re=n(vde,"A",{href:!0});var Kaa=s(_re);qGr=r(Kaa,"from_pretrained()"),Kaa.forEach(t),jGr=r(vde," to load the model weights."),vde.forEach(t),DGr=i(i9),T(B0.$$.fragment,i9),i9.forEach(t),GGr=i(li),jr=n(li,"DIV",{class:!0});var ii=s(jr);T(TS.$$.fragment,ii),OGr=i(ii),K6e=n(ii,"P",{});var Zaa=s(K6e);VGr=r(Zaa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Zaa.forEach(t),XGr=i(ii),yn=n(ii,"P",{});var d9=s(yn);zGr=r(d9,"The model class to instantiate is selected based on the "),Z6e=n(d9,"CODE",{});var ena=s(Z6e);QGr=r(ena,"model_type"),ena.forEach(t),WGr=r(d9,` property of the config object (either
passed as an argument or loaded from `),e7e=n(d9,"CODE",{});var ona=s(e7e);UGr=r(ona,"pretrained_model_name_or_path"),ona.forEach(t),HGr=r(d9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o7e=n(d9,"CODE",{});var rna=s(o7e);JGr=r(rna,"pretrained_model_name_or_path"),rna.forEach(t),YGr=r(d9,":"),d9.forEach(t),KGr=i(ii),Be=n(ii,"UL",{});var We=s(Be);I0=n(We,"LI",{});var OHe=s(I0);r7e=n(OHe,"STRONG",{});var tna=s(r7e);ZGr=r(tna,"convnext"),tna.forEach(t),eOr=r(OHe," \u2014 "),bre=n(OHe,"A",{href:!0});var ana=s(bre);oOr=r(ana,"TFConvNextForImageClassification"),ana.forEach(t),rOr=r(OHe," (ConvNeXT model)"),OHe.forEach(t),tOr=i(We),N0=n(We,"LI",{});var VHe=s(N0);t7e=n(VHe,"STRONG",{});var nna=s(t7e);aOr=r(nna,"data2vec-vision"),nna.forEach(t),nOr=r(VHe," \u2014 "),vre=n(VHe,"A",{href:!0});var sna=s(vre);sOr=r(sna,"TFData2VecVisionForImageClassification"),sna.forEach(t),lOr=r(VHe," (Data2VecVision model)"),VHe.forEach(t),iOr=i(We),Tl=n(We,"LI",{});var sI=s(Tl);a7e=n(sI,"STRONG",{});var lna=s(a7e);dOr=r(lna,"deit"),lna.forEach(t),mOr=r(sI," \u2014 "),Fre=n(sI,"A",{href:!0});var ina=s(Fre);cOr=r(ina,"TFDeiTForImageClassification"),ina.forEach(t),fOr=r(sI," or "),Tre=n(sI,"A",{href:!0});var dna=s(Tre);gOr=r(dna,"TFDeiTForImageClassificationWithTeacher"),dna.forEach(t),hOr=r(sI," (DeiT model)"),sI.forEach(t),uOr=i(We),q0=n(We,"LI",{});var XHe=s(q0);n7e=n(XHe,"STRONG",{});var mna=s(n7e);pOr=r(mna,"mobilevit"),mna.forEach(t),_Or=r(XHe," \u2014 "),Mre=n(XHe,"A",{href:!0});var cna=s(Mre);bOr=r(cna,"TFMobileViTForImageClassification"),cna.forEach(t),vOr=r(XHe," (MobileViT model)"),XHe.forEach(t),FOr=i(We),j0=n(We,"LI",{});var zHe=s(j0);s7e=n(zHe,"STRONG",{});var fna=s(s7e);TOr=r(fna,"regnet"),fna.forEach(t),MOr=r(zHe," \u2014 "),Ere=n(zHe,"A",{href:!0});var gna=s(Ere);EOr=r(gna,"TFRegNetForImageClassification"),gna.forEach(t),COr=r(zHe," (RegNet model)"),zHe.forEach(t),wOr=i(We),D0=n(We,"LI",{});var QHe=s(D0);l7e=n(QHe,"STRONG",{});var hna=s(l7e);AOr=r(hna,"resnet"),hna.forEach(t),LOr=r(QHe," \u2014 "),Cre=n(QHe,"A",{href:!0});var una=s(Cre);yOr=r(una,"TFResNetForImageClassification"),una.forEach(t),xOr=r(QHe," (ResNet model)"),QHe.forEach(t),$Or=i(We),G0=n(We,"LI",{});var WHe=s(G0);i7e=n(WHe,"STRONG",{});var pna=s(i7e);kOr=r(pna,"segformer"),pna.forEach(t),SOr=r(WHe," \u2014 "),wre=n(WHe,"A",{href:!0});var _na=s(wre);ROr=r(_na,"TFSegformerForImageClassification"),_na.forEach(t),POr=r(WHe," (SegFormer model)"),WHe.forEach(t),BOr=i(We),O0=n(We,"LI",{});var UHe=s(O0);d7e=n(UHe,"STRONG",{});var bna=s(d7e);IOr=r(bna,"swin"),bna.forEach(t),NOr=r(UHe," \u2014 "),Are=n(UHe,"A",{href:!0});var vna=s(Are);qOr=r(vna,"TFSwinForImageClassification"),vna.forEach(t),jOr=r(UHe," (Swin Transformer model)"),UHe.forEach(t),DOr=i(We),V0=n(We,"LI",{});var HHe=s(V0);m7e=n(HHe,"STRONG",{});var Fna=s(m7e);GOr=r(Fna,"vit"),Fna.forEach(t),OOr=r(HHe," \u2014 "),Lre=n(HHe,"A",{href:!0});var Tna=s(Lre);VOr=r(Tna,"TFViTForImageClassification"),Tna.forEach(t),XOr=r(HHe," (ViT model)"),HHe.forEach(t),We.forEach(t),zOr=i(ii),T(X0.$$.fragment,ii),ii.forEach(t),li.forEach(t),Poo=i(c),oc=n(c,"H2",{class:!0});var Uto=s(oc);z0=n(Uto,"A",{id:!0,class:!0,href:!0});var Mna=s(z0);c7e=n(Mna,"SPAN",{});var Ena=s(c7e);T(MS.$$.fragment,Ena),Ena.forEach(t),Mna.forEach(t),QOr=i(Uto),f7e=n(Uto,"SPAN",{});var Cna=s(f7e);WOr=r(Cna,"TFAutoModelForSemanticSegmentation"),Cna.forEach(t),Uto.forEach(t),Boo=i(c),mr=n(c,"DIV",{class:!0});var di=s(mr);T(ES.$$.fragment,di),UOr=i(di),rc=n(di,"P",{});var Fde=s(rc);HOr=r(Fde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),yre=n(Fde,"A",{href:!0});var wna=s(yre);JOr=r(wna,"from_pretrained()"),wna.forEach(t),YOr=r(Fde," class method or the "),xre=n(Fde,"A",{href:!0});var Ana=s(xre);KOr=r(Ana,"from_config()"),Ana.forEach(t),ZOr=r(Fde,` class
method.`),Fde.forEach(t),eVr=i(di),CS=n(di,"P",{});var Hto=s(CS);oVr=r(Hto,"This class cannot be instantiated directly using "),g7e=n(Hto,"CODE",{});var Lna=s(g7e);rVr=r(Lna,"__init__()"),Lna.forEach(t),tVr=r(Hto," (throws an error)."),Hto.forEach(t),aVr=i(di),Ut=n(di,"DIV",{class:!0});var m9=s(Ut);T(wS.$$.fragment,m9),nVr=i(m9),h7e=n(m9,"P",{});var yna=s(h7e);sVr=r(yna,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),yna.forEach(t),lVr=i(m9),tc=n(m9,"P",{});var Tde=s(tc);iVr=r(Tde,`Note:
Loading a model from its configuration file does `),u7e=n(Tde,"STRONG",{});var xna=s(u7e);dVr=r(xna,"not"),xna.forEach(t),mVr=r(Tde,` load the model weights. It only affects the
model\u2019s configuration. Use `),$re=n(Tde,"A",{href:!0});var $na=s($re);cVr=r($na,"from_pretrained()"),$na.forEach(t),fVr=r(Tde," to load the model weights."),Tde.forEach(t),gVr=i(m9),T(Q0.$$.fragment,m9),m9.forEach(t),hVr=i(di),Dr=n(di,"DIV",{class:!0});var mi=s(Dr);T(AS.$$.fragment,mi),uVr=i(mi),p7e=n(mi,"P",{});var kna=s(p7e);pVr=r(kna,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),kna.forEach(t),_Vr=i(mi),xn=n(mi,"P",{});var c9=s(xn);bVr=r(c9,"The model class to instantiate is selected based on the "),_7e=n(c9,"CODE",{});var Sna=s(_7e);vVr=r(Sna,"model_type"),Sna.forEach(t),FVr=r(c9,` property of the config object (either
passed as an argument or loaded from `),b7e=n(c9,"CODE",{});var Rna=s(b7e);TVr=r(Rna,"pretrained_model_name_or_path"),Rna.forEach(t),MVr=r(c9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v7e=n(c9,"CODE",{});var Pna=s(v7e);EVr=r(Pna,"pretrained_model_name_or_path"),Pna.forEach(t),CVr=r(c9,":"),c9.forEach(t),wVr=i(mi),ac=n(mi,"UL",{});var Mde=s(ac);W0=n(Mde,"LI",{});var JHe=s(W0);F7e=n(JHe,"STRONG",{});var Bna=s(F7e);AVr=r(Bna,"data2vec-vision"),Bna.forEach(t),LVr=r(JHe," \u2014 "),kre=n(JHe,"A",{href:!0});var Ina=s(kre);yVr=r(Ina,"TFData2VecVisionForSemanticSegmentation"),Ina.forEach(t),xVr=r(JHe," (Data2VecVision model)"),JHe.forEach(t),$Vr=i(Mde),U0=n(Mde,"LI",{});var YHe=s(U0);T7e=n(YHe,"STRONG",{});var Nna=s(T7e);kVr=r(Nna,"mobilevit"),Nna.forEach(t),SVr=r(YHe," \u2014 "),Sre=n(YHe,"A",{href:!0});var qna=s(Sre);RVr=r(qna,"TFMobileViTForSemanticSegmentation"),qna.forEach(t),PVr=r(YHe," (MobileViT model)"),YHe.forEach(t),BVr=i(Mde),H0=n(Mde,"LI",{});var KHe=s(H0);M7e=n(KHe,"STRONG",{});var jna=s(M7e);IVr=r(jna,"segformer"),jna.forEach(t),NVr=r(KHe," \u2014 "),Rre=n(KHe,"A",{href:!0});var Dna=s(Rre);qVr=r(Dna,"TFSegformerForSemanticSegmentation"),Dna.forEach(t),jVr=r(KHe," (SegFormer model)"),KHe.forEach(t),Mde.forEach(t),DVr=i(mi),T(J0.$$.fragment,mi),mi.forEach(t),di.forEach(t),Ioo=i(c),nc=n(c,"H2",{class:!0});var Jto=s(nc);Y0=n(Jto,"A",{id:!0,class:!0,href:!0});var Gna=s(Y0);E7e=n(Gna,"SPAN",{});var Ona=s(E7e);T(LS.$$.fragment,Ona),Ona.forEach(t),Gna.forEach(t),GVr=i(Jto),C7e=n(Jto,"SPAN",{});var Vna=s(C7e);OVr=r(Vna,"TFAutoModelForMaskedLM"),Vna.forEach(t),Jto.forEach(t),Noo=i(c),cr=n(c,"DIV",{class:!0});var ci=s(cr);T(yS.$$.fragment,ci),VVr=i(ci),sc=n(ci,"P",{});var Ede=s(sc);XVr=r(Ede,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Pre=n(Ede,"A",{href:!0});var Xna=s(Pre);zVr=r(Xna,"from_pretrained()"),Xna.forEach(t),QVr=r(Ede," class method or the "),Bre=n(Ede,"A",{href:!0});var zna=s(Bre);WVr=r(zna,"from_config()"),zna.forEach(t),UVr=r(Ede,` class
method.`),Ede.forEach(t),HVr=i(ci),xS=n(ci,"P",{});var Yto=s(xS);JVr=r(Yto,"This class cannot be instantiated directly using "),w7e=n(Yto,"CODE",{});var Qna=s(w7e);YVr=r(Qna,"__init__()"),Qna.forEach(t),KVr=r(Yto," (throws an error)."),Yto.forEach(t),ZVr=i(ci),Ht=n(ci,"DIV",{class:!0});var f9=s(Ht);T($S.$$.fragment,f9),eXr=i(f9),A7e=n(f9,"P",{});var Wna=s(A7e);oXr=r(Wna,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Wna.forEach(t),rXr=i(f9),lc=n(f9,"P",{});var Cde=s(lc);tXr=r(Cde,`Note:
Loading a model from its configuration file does `),L7e=n(Cde,"STRONG",{});var Una=s(L7e);aXr=r(Una,"not"),Una.forEach(t),nXr=r(Cde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ire=n(Cde,"A",{href:!0});var Hna=s(Ire);sXr=r(Hna,"from_pretrained()"),Hna.forEach(t),lXr=r(Cde," to load the model weights."),Cde.forEach(t),iXr=i(f9),T(K0.$$.fragment,f9),f9.forEach(t),dXr=i(ci),Gr=n(ci,"DIV",{class:!0});var fi=s(Gr);T(kS.$$.fragment,fi),mXr=i(fi),y7e=n(fi,"P",{});var Jna=s(y7e);cXr=r(Jna,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Jna.forEach(t),fXr=i(fi),$n=n(fi,"P",{});var g9=s($n);gXr=r(g9,"The model class to instantiate is selected based on the "),x7e=n(g9,"CODE",{});var Yna=s(x7e);hXr=r(Yna,"model_type"),Yna.forEach(t),uXr=r(g9,` property of the config object (either
passed as an argument or loaded from `),$7e=n(g9,"CODE",{});var Kna=s($7e);pXr=r(Kna,"pretrained_model_name_or_path"),Kna.forEach(t),_Xr=r(g9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k7e=n(g9,"CODE",{});var Zna=s(k7e);bXr=r(Zna,"pretrained_model_name_or_path"),Zna.forEach(t),vXr=r(g9,":"),g9.forEach(t),FXr=i(fi),ge=n(fi,"UL",{});var _e=s(ge);Z0=n(_e,"LI",{});var ZHe=s(Z0);S7e=n(ZHe,"STRONG",{});var esa=s(S7e);TXr=r(esa,"albert"),esa.forEach(t),MXr=r(ZHe," \u2014 "),Nre=n(ZHe,"A",{href:!0});var osa=s(Nre);EXr=r(osa,"TFAlbertForMaskedLM"),osa.forEach(t),CXr=r(ZHe," (ALBERT model)"),ZHe.forEach(t),wXr=i(_e),ew=n(_e,"LI",{});var eJe=s(ew);R7e=n(eJe,"STRONG",{});var rsa=s(R7e);AXr=r(rsa,"bert"),rsa.forEach(t),LXr=r(eJe," \u2014 "),qre=n(eJe,"A",{href:!0});var tsa=s(qre);yXr=r(tsa,"TFBertForMaskedLM"),tsa.forEach(t),xXr=r(eJe," (BERT model)"),eJe.forEach(t),$Xr=i(_e),ow=n(_e,"LI",{});var oJe=s(ow);P7e=n(oJe,"STRONG",{});var asa=s(P7e);kXr=r(asa,"camembert"),asa.forEach(t),SXr=r(oJe," \u2014 "),jre=n(oJe,"A",{href:!0});var nsa=s(jre);RXr=r(nsa,"TFCamembertForMaskedLM"),nsa.forEach(t),PXr=r(oJe," (CamemBERT model)"),oJe.forEach(t),BXr=i(_e),rw=n(_e,"LI",{});var rJe=s(rw);B7e=n(rJe,"STRONG",{});var ssa=s(B7e);IXr=r(ssa,"convbert"),ssa.forEach(t),NXr=r(rJe," \u2014 "),Dre=n(rJe,"A",{href:!0});var lsa=s(Dre);qXr=r(lsa,"TFConvBertForMaskedLM"),lsa.forEach(t),jXr=r(rJe," (ConvBERT model)"),rJe.forEach(t),DXr=i(_e),tw=n(_e,"LI",{});var tJe=s(tw);I7e=n(tJe,"STRONG",{});var isa=s(I7e);GXr=r(isa,"deberta"),isa.forEach(t),OXr=r(tJe," \u2014 "),Gre=n(tJe,"A",{href:!0});var dsa=s(Gre);VXr=r(dsa,"TFDebertaForMaskedLM"),dsa.forEach(t),XXr=r(tJe," (DeBERTa model)"),tJe.forEach(t),zXr=i(_e),aw=n(_e,"LI",{});var aJe=s(aw);N7e=n(aJe,"STRONG",{});var msa=s(N7e);QXr=r(msa,"deberta-v2"),msa.forEach(t),WXr=r(aJe," \u2014 "),Ore=n(aJe,"A",{href:!0});var csa=s(Ore);UXr=r(csa,"TFDebertaV2ForMaskedLM"),csa.forEach(t),HXr=r(aJe," (DeBERTa-v2 model)"),aJe.forEach(t),JXr=i(_e),nw=n(_e,"LI",{});var nJe=s(nw);q7e=n(nJe,"STRONG",{});var fsa=s(q7e);YXr=r(fsa,"distilbert"),fsa.forEach(t),KXr=r(nJe," \u2014 "),Vre=n(nJe,"A",{href:!0});var gsa=s(Vre);ZXr=r(gsa,"TFDistilBertForMaskedLM"),gsa.forEach(t),ezr=r(nJe," (DistilBERT model)"),nJe.forEach(t),ozr=i(_e),sw=n(_e,"LI",{});var sJe=s(sw);j7e=n(sJe,"STRONG",{});var hsa=s(j7e);rzr=r(hsa,"electra"),hsa.forEach(t),tzr=r(sJe," \u2014 "),Xre=n(sJe,"A",{href:!0});var usa=s(Xre);azr=r(usa,"TFElectraForMaskedLM"),usa.forEach(t),nzr=r(sJe," (ELECTRA model)"),sJe.forEach(t),szr=i(_e),lw=n(_e,"LI",{});var lJe=s(lw);D7e=n(lJe,"STRONG",{});var psa=s(D7e);lzr=r(psa,"flaubert"),psa.forEach(t),izr=r(lJe," \u2014 "),zre=n(lJe,"A",{href:!0});var _sa=s(zre);dzr=r(_sa,"TFFlaubertWithLMHeadModel"),_sa.forEach(t),mzr=r(lJe," (FlauBERT model)"),lJe.forEach(t),czr=i(_e),iw=n(_e,"LI",{});var iJe=s(iw);G7e=n(iJe,"STRONG",{});var bsa=s(G7e);fzr=r(bsa,"funnel"),bsa.forEach(t),gzr=r(iJe," \u2014 "),Qre=n(iJe,"A",{href:!0});var vsa=s(Qre);hzr=r(vsa,"TFFunnelForMaskedLM"),vsa.forEach(t),uzr=r(iJe," (Funnel Transformer model)"),iJe.forEach(t),pzr=i(_e),dw=n(_e,"LI",{});var dJe=s(dw);O7e=n(dJe,"STRONG",{});var Fsa=s(O7e);_zr=r(Fsa,"layoutlm"),Fsa.forEach(t),bzr=r(dJe," \u2014 "),Wre=n(dJe,"A",{href:!0});var Tsa=s(Wre);vzr=r(Tsa,"TFLayoutLMForMaskedLM"),Tsa.forEach(t),Fzr=r(dJe," (LayoutLM model)"),dJe.forEach(t),Tzr=i(_e),mw=n(_e,"LI",{});var mJe=s(mw);V7e=n(mJe,"STRONG",{});var Msa=s(V7e);Mzr=r(Msa,"longformer"),Msa.forEach(t),Ezr=r(mJe," \u2014 "),Ure=n(mJe,"A",{href:!0});var Esa=s(Ure);Czr=r(Esa,"TFLongformerForMaskedLM"),Esa.forEach(t),wzr=r(mJe," (Longformer model)"),mJe.forEach(t),Azr=i(_e),cw=n(_e,"LI",{});var cJe=s(cw);X7e=n(cJe,"STRONG",{});var Csa=s(X7e);Lzr=r(Csa,"mobilebert"),Csa.forEach(t),yzr=r(cJe," \u2014 "),Hre=n(cJe,"A",{href:!0});var wsa=s(Hre);xzr=r(wsa,"TFMobileBertForMaskedLM"),wsa.forEach(t),$zr=r(cJe," (MobileBERT model)"),cJe.forEach(t),kzr=i(_e),fw=n(_e,"LI",{});var fJe=s(fw);z7e=n(fJe,"STRONG",{});var Asa=s(z7e);Szr=r(Asa,"mpnet"),Asa.forEach(t),Rzr=r(fJe," \u2014 "),Jre=n(fJe,"A",{href:!0});var Lsa=s(Jre);Pzr=r(Lsa,"TFMPNetForMaskedLM"),Lsa.forEach(t),Bzr=r(fJe," (MPNet model)"),fJe.forEach(t),Izr=i(_e),gw=n(_e,"LI",{});var gJe=s(gw);Q7e=n(gJe,"STRONG",{});var ysa=s(Q7e);Nzr=r(ysa,"rembert"),ysa.forEach(t),qzr=r(gJe," \u2014 "),Yre=n(gJe,"A",{href:!0});var xsa=s(Yre);jzr=r(xsa,"TFRemBertForMaskedLM"),xsa.forEach(t),Dzr=r(gJe," (RemBERT model)"),gJe.forEach(t),Gzr=i(_e),hw=n(_e,"LI",{});var hJe=s(hw);W7e=n(hJe,"STRONG",{});var $sa=s(W7e);Ozr=r($sa,"roberta"),$sa.forEach(t),Vzr=r(hJe," \u2014 "),Kre=n(hJe,"A",{href:!0});var ksa=s(Kre);Xzr=r(ksa,"TFRobertaForMaskedLM"),ksa.forEach(t),zzr=r(hJe," (RoBERTa model)"),hJe.forEach(t),Qzr=i(_e),uw=n(_e,"LI",{});var uJe=s(uw);U7e=n(uJe,"STRONG",{});var Ssa=s(U7e);Wzr=r(Ssa,"roformer"),Ssa.forEach(t),Uzr=r(uJe," \u2014 "),Zre=n(uJe,"A",{href:!0});var Rsa=s(Zre);Hzr=r(Rsa,"TFRoFormerForMaskedLM"),Rsa.forEach(t),Jzr=r(uJe," (RoFormer model)"),uJe.forEach(t),Yzr=i(_e),pw=n(_e,"LI",{});var pJe=s(pw);H7e=n(pJe,"STRONG",{});var Psa=s(H7e);Kzr=r(Psa,"tapas"),Psa.forEach(t),Zzr=r(pJe," \u2014 "),ete=n(pJe,"A",{href:!0});var Bsa=s(ete);eQr=r(Bsa,"TFTapasForMaskedLM"),Bsa.forEach(t),oQr=r(pJe," (TAPAS model)"),pJe.forEach(t),rQr=i(_e),_w=n(_e,"LI",{});var _Je=s(_w);J7e=n(_Je,"STRONG",{});var Isa=s(J7e);tQr=r(Isa,"xlm"),Isa.forEach(t),aQr=r(_Je," \u2014 "),ote=n(_Je,"A",{href:!0});var Nsa=s(ote);nQr=r(Nsa,"TFXLMWithLMHeadModel"),Nsa.forEach(t),sQr=r(_Je," (XLM model)"),_Je.forEach(t),lQr=i(_e),bw=n(_e,"LI",{});var bJe=s(bw);Y7e=n(bJe,"STRONG",{});var qsa=s(Y7e);iQr=r(qsa,"xlm-roberta"),qsa.forEach(t),dQr=r(bJe," \u2014 "),rte=n(bJe,"A",{href:!0});var jsa=s(rte);mQr=r(jsa,"TFXLMRobertaForMaskedLM"),jsa.forEach(t),cQr=r(bJe," (XLM-RoBERTa model)"),bJe.forEach(t),_e.forEach(t),fQr=i(fi),T(vw.$$.fragment,fi),fi.forEach(t),ci.forEach(t),qoo=i(c),ic=n(c,"H2",{class:!0});var Kto=s(ic);Fw=n(Kto,"A",{id:!0,class:!0,href:!0});var Dsa=s(Fw);K7e=n(Dsa,"SPAN",{});var Gsa=s(K7e);T(SS.$$.fragment,Gsa),Gsa.forEach(t),Dsa.forEach(t),gQr=i(Kto),Z7e=n(Kto,"SPAN",{});var Osa=s(Z7e);hQr=r(Osa,"TFAutoModelForSeq2SeqLM"),Osa.forEach(t),Kto.forEach(t),joo=i(c),fr=n(c,"DIV",{class:!0});var gi=s(fr);T(RS.$$.fragment,gi),uQr=i(gi),dc=n(gi,"P",{});var wde=s(dc);pQr=r(wde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),tte=n(wde,"A",{href:!0});var Vsa=s(tte);_Qr=r(Vsa,"from_pretrained()"),Vsa.forEach(t),bQr=r(wde," class method or the "),ate=n(wde,"A",{href:!0});var Xsa=s(ate);vQr=r(Xsa,"from_config()"),Xsa.forEach(t),FQr=r(wde,` class
method.`),wde.forEach(t),TQr=i(gi),PS=n(gi,"P",{});var Zto=s(PS);MQr=r(Zto,"This class cannot be instantiated directly using "),eLe=n(Zto,"CODE",{});var zsa=s(eLe);EQr=r(zsa,"__init__()"),zsa.forEach(t),CQr=r(Zto," (throws an error)."),Zto.forEach(t),wQr=i(gi),Jt=n(gi,"DIV",{class:!0});var h9=s(Jt);T(BS.$$.fragment,h9),AQr=i(h9),oLe=n(h9,"P",{});var Qsa=s(oLe);LQr=r(Qsa,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Qsa.forEach(t),yQr=i(h9),mc=n(h9,"P",{});var Ade=s(mc);xQr=r(Ade,`Note:
Loading a model from its configuration file does `),rLe=n(Ade,"STRONG",{});var Wsa=s(rLe);$Qr=r(Wsa,"not"),Wsa.forEach(t),kQr=r(Ade,` load the model weights. It only affects the
model\u2019s configuration. Use `),nte=n(Ade,"A",{href:!0});var Usa=s(nte);SQr=r(Usa,"from_pretrained()"),Usa.forEach(t),RQr=r(Ade," to load the model weights."),Ade.forEach(t),PQr=i(h9),T(Tw.$$.fragment,h9),h9.forEach(t),BQr=i(gi),Or=n(gi,"DIV",{class:!0});var hi=s(Or);T(IS.$$.fragment,hi),IQr=i(hi),tLe=n(hi,"P",{});var Hsa=s(tLe);NQr=r(Hsa,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Hsa.forEach(t),qQr=i(hi),kn=n(hi,"P",{});var u9=s(kn);jQr=r(u9,"The model class to instantiate is selected based on the "),aLe=n(u9,"CODE",{});var Jsa=s(aLe);DQr=r(Jsa,"model_type"),Jsa.forEach(t),GQr=r(u9,` property of the config object (either
passed as an argument or loaded from `),nLe=n(u9,"CODE",{});var Ysa=s(nLe);OQr=r(Ysa,"pretrained_model_name_or_path"),Ysa.forEach(t),VQr=r(u9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sLe=n(u9,"CODE",{});var Ksa=s(sLe);XQr=r(Ksa,"pretrained_model_name_or_path"),Ksa.forEach(t),zQr=r(u9,":"),u9.forEach(t),QQr=i(hi),ye=n(hi,"UL",{});var Ne=s(ye);Mw=n(Ne,"LI",{});var vJe=s(Mw);lLe=n(vJe,"STRONG",{});var Zsa=s(lLe);WQr=r(Zsa,"bart"),Zsa.forEach(t),UQr=r(vJe," \u2014 "),ste=n(vJe,"A",{href:!0});var ela=s(ste);HQr=r(ela,"TFBartForConditionalGeneration"),ela.forEach(t),JQr=r(vJe," (BART model)"),vJe.forEach(t),YQr=i(Ne),Ew=n(Ne,"LI",{});var FJe=s(Ew);iLe=n(FJe,"STRONG",{});var ola=s(iLe);KQr=r(ola,"blenderbot"),ola.forEach(t),ZQr=r(FJe," \u2014 "),lte=n(FJe,"A",{href:!0});var rla=s(lte);eWr=r(rla,"TFBlenderbotForConditionalGeneration"),rla.forEach(t),oWr=r(FJe," (Blenderbot model)"),FJe.forEach(t),rWr=i(Ne),Cw=n(Ne,"LI",{});var TJe=s(Cw);dLe=n(TJe,"STRONG",{});var tla=s(dLe);tWr=r(tla,"blenderbot-small"),tla.forEach(t),aWr=r(TJe," \u2014 "),ite=n(TJe,"A",{href:!0});var ala=s(ite);nWr=r(ala,"TFBlenderbotSmallForConditionalGeneration"),ala.forEach(t),sWr=r(TJe," (BlenderbotSmall model)"),TJe.forEach(t),lWr=i(Ne),ww=n(Ne,"LI",{});var MJe=s(ww);mLe=n(MJe,"STRONG",{});var nla=s(mLe);iWr=r(nla,"encoder-decoder"),nla.forEach(t),dWr=r(MJe," \u2014 "),dte=n(MJe,"A",{href:!0});var sla=s(dte);mWr=r(sla,"TFEncoderDecoderModel"),sla.forEach(t),cWr=r(MJe," (Encoder decoder model)"),MJe.forEach(t),fWr=i(Ne),Aw=n(Ne,"LI",{});var EJe=s(Aw);cLe=n(EJe,"STRONG",{});var lla=s(cLe);gWr=r(lla,"led"),lla.forEach(t),hWr=r(EJe," \u2014 "),mte=n(EJe,"A",{href:!0});var ila=s(mte);uWr=r(ila,"TFLEDForConditionalGeneration"),ila.forEach(t),pWr=r(EJe," (LED model)"),EJe.forEach(t),_Wr=i(Ne),Lw=n(Ne,"LI",{});var CJe=s(Lw);fLe=n(CJe,"STRONG",{});var dla=s(fLe);bWr=r(dla,"marian"),dla.forEach(t),vWr=r(CJe," \u2014 "),cte=n(CJe,"A",{href:!0});var mla=s(cte);FWr=r(mla,"TFMarianMTModel"),mla.forEach(t),TWr=r(CJe," (Marian model)"),CJe.forEach(t),MWr=i(Ne),yw=n(Ne,"LI",{});var wJe=s(yw);gLe=n(wJe,"STRONG",{});var cla=s(gLe);EWr=r(cla,"mbart"),cla.forEach(t),CWr=r(wJe," \u2014 "),fte=n(wJe,"A",{href:!0});var fla=s(fte);wWr=r(fla,"TFMBartForConditionalGeneration"),fla.forEach(t),AWr=r(wJe," (mBART model)"),wJe.forEach(t),LWr=i(Ne),xw=n(Ne,"LI",{});var AJe=s(xw);hLe=n(AJe,"STRONG",{});var gla=s(hLe);yWr=r(gla,"mt5"),gla.forEach(t),xWr=r(AJe," \u2014 "),gte=n(AJe,"A",{href:!0});var hla=s(gte);$Wr=r(hla,"TFMT5ForConditionalGeneration"),hla.forEach(t),kWr=r(AJe," (MT5 model)"),AJe.forEach(t),SWr=i(Ne),$w=n(Ne,"LI",{});var LJe=s($w);uLe=n(LJe,"STRONG",{});var ula=s(uLe);RWr=r(ula,"pegasus"),ula.forEach(t),PWr=r(LJe," \u2014 "),hte=n(LJe,"A",{href:!0});var pla=s(hte);BWr=r(pla,"TFPegasusForConditionalGeneration"),pla.forEach(t),IWr=r(LJe," (Pegasus model)"),LJe.forEach(t),NWr=i(Ne),kw=n(Ne,"LI",{});var yJe=s(kw);pLe=n(yJe,"STRONG",{});var _la=s(pLe);qWr=r(_la,"t5"),_la.forEach(t),jWr=r(yJe," \u2014 "),ute=n(yJe,"A",{href:!0});var bla=s(ute);DWr=r(bla,"TFT5ForConditionalGeneration"),bla.forEach(t),GWr=r(yJe," (T5 model)"),yJe.forEach(t),Ne.forEach(t),OWr=i(hi),T(Sw.$$.fragment,hi),hi.forEach(t),gi.forEach(t),Doo=i(c),cc=n(c,"H2",{class:!0});var eao=s(cc);Rw=n(eao,"A",{id:!0,class:!0,href:!0});var vla=s(Rw);_Le=n(vla,"SPAN",{});var Fla=s(_Le);T(NS.$$.fragment,Fla),Fla.forEach(t),vla.forEach(t),VWr=i(eao),bLe=n(eao,"SPAN",{});var Tla=s(bLe);XWr=r(Tla,"TFAutoModelForSequenceClassification"),Tla.forEach(t),eao.forEach(t),Goo=i(c),gr=n(c,"DIV",{class:!0});var ui=s(gr);T(qS.$$.fragment,ui),zWr=i(ui),fc=n(ui,"P",{});var Lde=s(fc);QWr=r(Lde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),pte=n(Lde,"A",{href:!0});var Mla=s(pte);WWr=r(Mla,"from_pretrained()"),Mla.forEach(t),UWr=r(Lde," class method or the "),_te=n(Lde,"A",{href:!0});var Ela=s(_te);HWr=r(Ela,"from_config()"),Ela.forEach(t),JWr=r(Lde,` class
method.`),Lde.forEach(t),YWr=i(ui),jS=n(ui,"P",{});var oao=s(jS);KWr=r(oao,"This class cannot be instantiated directly using "),vLe=n(oao,"CODE",{});var Cla=s(vLe);ZWr=r(Cla,"__init__()"),Cla.forEach(t),eUr=r(oao," (throws an error)."),oao.forEach(t),oUr=i(ui),Yt=n(ui,"DIV",{class:!0});var p9=s(Yt);T(DS.$$.fragment,p9),rUr=i(p9),FLe=n(p9,"P",{});var wla=s(FLe);tUr=r(wla,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),wla.forEach(t),aUr=i(p9),gc=n(p9,"P",{});var yde=s(gc);nUr=r(yde,`Note:
Loading a model from its configuration file does `),TLe=n(yde,"STRONG",{});var Ala=s(TLe);sUr=r(Ala,"not"),Ala.forEach(t),lUr=r(yde,` load the model weights. It only affects the
model\u2019s configuration. Use `),bte=n(yde,"A",{href:!0});var Lla=s(bte);iUr=r(Lla,"from_pretrained()"),Lla.forEach(t),dUr=r(yde," to load the model weights."),yde.forEach(t),mUr=i(p9),T(Pw.$$.fragment,p9),p9.forEach(t),cUr=i(ui),Vr=n(ui,"DIV",{class:!0});var pi=s(Vr);T(GS.$$.fragment,pi),fUr=i(pi),MLe=n(pi,"P",{});var yla=s(MLe);gUr=r(yla,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),yla.forEach(t),hUr=i(pi),Sn=n(pi,"P",{});var _9=s(Sn);uUr=r(_9,"The model class to instantiate is selected based on the "),ELe=n(_9,"CODE",{});var xla=s(ELe);pUr=r(xla,"model_type"),xla.forEach(t),_Ur=r(_9,` property of the config object (either
passed as an argument or loaded from `),CLe=n(_9,"CODE",{});var $la=s(CLe);bUr=r($la,"pretrained_model_name_or_path"),$la.forEach(t),vUr=r(_9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wLe=n(_9,"CODE",{});var kla=s(wLe);FUr=r(kla,"pretrained_model_name_or_path"),kla.forEach(t),TUr=r(_9,":"),_9.forEach(t),MUr=i(pi),re=n(pi,"UL",{});var ae=s(re);Bw=n(ae,"LI",{});var xJe=s(Bw);ALe=n(xJe,"STRONG",{});var Sla=s(ALe);EUr=r(Sla,"albert"),Sla.forEach(t),CUr=r(xJe," \u2014 "),vte=n(xJe,"A",{href:!0});var Rla=s(vte);wUr=r(Rla,"TFAlbertForSequenceClassification"),Rla.forEach(t),AUr=r(xJe," (ALBERT model)"),xJe.forEach(t),LUr=i(ae),Iw=n(ae,"LI",{});var $Je=s(Iw);LLe=n($Je,"STRONG",{});var Pla=s(LLe);yUr=r(Pla,"bert"),Pla.forEach(t),xUr=r($Je," \u2014 "),Fte=n($Je,"A",{href:!0});var Bla=s(Fte);$Ur=r(Bla,"TFBertForSequenceClassification"),Bla.forEach(t),kUr=r($Je," (BERT model)"),$Je.forEach(t),SUr=i(ae),Nw=n(ae,"LI",{});var kJe=s(Nw);yLe=n(kJe,"STRONG",{});var Ila=s(yLe);RUr=r(Ila,"camembert"),Ila.forEach(t),PUr=r(kJe," \u2014 "),Tte=n(kJe,"A",{href:!0});var Nla=s(Tte);BUr=r(Nla,"TFCamembertForSequenceClassification"),Nla.forEach(t),IUr=r(kJe," (CamemBERT model)"),kJe.forEach(t),NUr=i(ae),qw=n(ae,"LI",{});var SJe=s(qw);xLe=n(SJe,"STRONG",{});var qla=s(xLe);qUr=r(qla,"convbert"),qla.forEach(t),jUr=r(SJe," \u2014 "),Mte=n(SJe,"A",{href:!0});var jla=s(Mte);DUr=r(jla,"TFConvBertForSequenceClassification"),jla.forEach(t),GUr=r(SJe," (ConvBERT model)"),SJe.forEach(t),OUr=i(ae),jw=n(ae,"LI",{});var RJe=s(jw);$Le=n(RJe,"STRONG",{});var Dla=s($Le);VUr=r(Dla,"ctrl"),Dla.forEach(t),XUr=r(RJe," \u2014 "),Ete=n(RJe,"A",{href:!0});var Gla=s(Ete);zUr=r(Gla,"TFCTRLForSequenceClassification"),Gla.forEach(t),QUr=r(RJe," (CTRL model)"),RJe.forEach(t),WUr=i(ae),Dw=n(ae,"LI",{});var PJe=s(Dw);kLe=n(PJe,"STRONG",{});var Ola=s(kLe);UUr=r(Ola,"deberta"),Ola.forEach(t),HUr=r(PJe," \u2014 "),Cte=n(PJe,"A",{href:!0});var Vla=s(Cte);JUr=r(Vla,"TFDebertaForSequenceClassification"),Vla.forEach(t),YUr=r(PJe," (DeBERTa model)"),PJe.forEach(t),KUr=i(ae),Gw=n(ae,"LI",{});var BJe=s(Gw);SLe=n(BJe,"STRONG",{});var Xla=s(SLe);ZUr=r(Xla,"deberta-v2"),Xla.forEach(t),eHr=r(BJe," \u2014 "),wte=n(BJe,"A",{href:!0});var zla=s(wte);oHr=r(zla,"TFDebertaV2ForSequenceClassification"),zla.forEach(t),rHr=r(BJe," (DeBERTa-v2 model)"),BJe.forEach(t),tHr=i(ae),Ow=n(ae,"LI",{});var IJe=s(Ow);RLe=n(IJe,"STRONG",{});var Qla=s(RLe);aHr=r(Qla,"distilbert"),Qla.forEach(t),nHr=r(IJe," \u2014 "),Ate=n(IJe,"A",{href:!0});var Wla=s(Ate);sHr=r(Wla,"TFDistilBertForSequenceClassification"),Wla.forEach(t),lHr=r(IJe," (DistilBERT model)"),IJe.forEach(t),iHr=i(ae),Vw=n(ae,"LI",{});var NJe=s(Vw);PLe=n(NJe,"STRONG",{});var Ula=s(PLe);dHr=r(Ula,"electra"),Ula.forEach(t),mHr=r(NJe," \u2014 "),Lte=n(NJe,"A",{href:!0});var Hla=s(Lte);cHr=r(Hla,"TFElectraForSequenceClassification"),Hla.forEach(t),fHr=r(NJe," (ELECTRA model)"),NJe.forEach(t),gHr=i(ae),Xw=n(ae,"LI",{});var qJe=s(Xw);BLe=n(qJe,"STRONG",{});var Jla=s(BLe);hHr=r(Jla,"flaubert"),Jla.forEach(t),uHr=r(qJe," \u2014 "),yte=n(qJe,"A",{href:!0});var Yla=s(yte);pHr=r(Yla,"TFFlaubertForSequenceClassification"),Yla.forEach(t),_Hr=r(qJe," (FlauBERT model)"),qJe.forEach(t),bHr=i(ae),zw=n(ae,"LI",{});var jJe=s(zw);ILe=n(jJe,"STRONG",{});var Kla=s(ILe);vHr=r(Kla,"funnel"),Kla.forEach(t),FHr=r(jJe," \u2014 "),xte=n(jJe,"A",{href:!0});var Zla=s(xte);THr=r(Zla,"TFFunnelForSequenceClassification"),Zla.forEach(t),MHr=r(jJe," (Funnel Transformer model)"),jJe.forEach(t),EHr=i(ae),Qw=n(ae,"LI",{});var DJe=s(Qw);NLe=n(DJe,"STRONG",{});var eia=s(NLe);CHr=r(eia,"gpt2"),eia.forEach(t),wHr=r(DJe," \u2014 "),$te=n(DJe,"A",{href:!0});var oia=s($te);AHr=r(oia,"TFGPT2ForSequenceClassification"),oia.forEach(t),LHr=r(DJe," (OpenAI GPT-2 model)"),DJe.forEach(t),yHr=i(ae),Ww=n(ae,"LI",{});var GJe=s(Ww);qLe=n(GJe,"STRONG",{});var ria=s(qLe);xHr=r(ria,"gptj"),ria.forEach(t),$Hr=r(GJe," \u2014 "),kte=n(GJe,"A",{href:!0});var tia=s(kte);kHr=r(tia,"TFGPTJForSequenceClassification"),tia.forEach(t),SHr=r(GJe," (GPT-J model)"),GJe.forEach(t),RHr=i(ae),Uw=n(ae,"LI",{});var OJe=s(Uw);jLe=n(OJe,"STRONG",{});var aia=s(jLe);PHr=r(aia,"layoutlm"),aia.forEach(t),BHr=r(OJe," \u2014 "),Ste=n(OJe,"A",{href:!0});var nia=s(Ste);IHr=r(nia,"TFLayoutLMForSequenceClassification"),nia.forEach(t),NHr=r(OJe," (LayoutLM model)"),OJe.forEach(t),qHr=i(ae),Hw=n(ae,"LI",{});var VJe=s(Hw);DLe=n(VJe,"STRONG",{});var sia=s(DLe);jHr=r(sia,"layoutlmv3"),sia.forEach(t),DHr=r(VJe," \u2014 "),Rte=n(VJe,"A",{href:!0});var lia=s(Rte);GHr=r(lia,"TFLayoutLMv3ForSequenceClassification"),lia.forEach(t),OHr=r(VJe," (LayoutLMv3 model)"),VJe.forEach(t),VHr=i(ae),Jw=n(ae,"LI",{});var XJe=s(Jw);GLe=n(XJe,"STRONG",{});var iia=s(GLe);XHr=r(iia,"longformer"),iia.forEach(t),zHr=r(XJe," \u2014 "),Pte=n(XJe,"A",{href:!0});var dia=s(Pte);QHr=r(dia,"TFLongformerForSequenceClassification"),dia.forEach(t),WHr=r(XJe," (Longformer model)"),XJe.forEach(t),UHr=i(ae),Yw=n(ae,"LI",{});var zJe=s(Yw);OLe=n(zJe,"STRONG",{});var mia=s(OLe);HHr=r(mia,"mobilebert"),mia.forEach(t),JHr=r(zJe," \u2014 "),Bte=n(zJe,"A",{href:!0});var cia=s(Bte);YHr=r(cia,"TFMobileBertForSequenceClassification"),cia.forEach(t),KHr=r(zJe," (MobileBERT model)"),zJe.forEach(t),ZHr=i(ae),Kw=n(ae,"LI",{});var QJe=s(Kw);VLe=n(QJe,"STRONG",{});var fia=s(VLe);eJr=r(fia,"mpnet"),fia.forEach(t),oJr=r(QJe," \u2014 "),Ite=n(QJe,"A",{href:!0});var gia=s(Ite);rJr=r(gia,"TFMPNetForSequenceClassification"),gia.forEach(t),tJr=r(QJe," (MPNet model)"),QJe.forEach(t),aJr=i(ae),Zw=n(ae,"LI",{});var WJe=s(Zw);XLe=n(WJe,"STRONG",{});var hia=s(XLe);nJr=r(hia,"openai-gpt"),hia.forEach(t),sJr=r(WJe," \u2014 "),Nte=n(WJe,"A",{href:!0});var uia=s(Nte);lJr=r(uia,"TFOpenAIGPTForSequenceClassification"),uia.forEach(t),iJr=r(WJe," (OpenAI GPT model)"),WJe.forEach(t),dJr=i(ae),eA=n(ae,"LI",{});var UJe=s(eA);zLe=n(UJe,"STRONG",{});var pia=s(zLe);mJr=r(pia,"rembert"),pia.forEach(t),cJr=r(UJe," \u2014 "),qte=n(UJe,"A",{href:!0});var _ia=s(qte);fJr=r(_ia,"TFRemBertForSequenceClassification"),_ia.forEach(t),gJr=r(UJe," (RemBERT model)"),UJe.forEach(t),hJr=i(ae),oA=n(ae,"LI",{});var HJe=s(oA);QLe=n(HJe,"STRONG",{});var bia=s(QLe);uJr=r(bia,"roberta"),bia.forEach(t),pJr=r(HJe," \u2014 "),jte=n(HJe,"A",{href:!0});var via=s(jte);_Jr=r(via,"TFRobertaForSequenceClassification"),via.forEach(t),bJr=r(HJe," (RoBERTa model)"),HJe.forEach(t),vJr=i(ae),rA=n(ae,"LI",{});var JJe=s(rA);WLe=n(JJe,"STRONG",{});var Fia=s(WLe);FJr=r(Fia,"roformer"),Fia.forEach(t),TJr=r(JJe," \u2014 "),Dte=n(JJe,"A",{href:!0});var Tia=s(Dte);MJr=r(Tia,"TFRoFormerForSequenceClassification"),Tia.forEach(t),EJr=r(JJe," (RoFormer model)"),JJe.forEach(t),CJr=i(ae),tA=n(ae,"LI",{});var YJe=s(tA);ULe=n(YJe,"STRONG",{});var Mia=s(ULe);wJr=r(Mia,"tapas"),Mia.forEach(t),AJr=r(YJe," \u2014 "),Gte=n(YJe,"A",{href:!0});var Eia=s(Gte);LJr=r(Eia,"TFTapasForSequenceClassification"),Eia.forEach(t),yJr=r(YJe," (TAPAS model)"),YJe.forEach(t),xJr=i(ae),aA=n(ae,"LI",{});var KJe=s(aA);HLe=n(KJe,"STRONG",{});var Cia=s(HLe);$Jr=r(Cia,"transfo-xl"),Cia.forEach(t),kJr=r(KJe," \u2014 "),Ote=n(KJe,"A",{href:!0});var wia=s(Ote);SJr=r(wia,"TFTransfoXLForSequenceClassification"),wia.forEach(t),RJr=r(KJe," (Transformer-XL model)"),KJe.forEach(t),PJr=i(ae),nA=n(ae,"LI",{});var ZJe=s(nA);JLe=n(ZJe,"STRONG",{});var Aia=s(JLe);BJr=r(Aia,"xlm"),Aia.forEach(t),IJr=r(ZJe," \u2014 "),Vte=n(ZJe,"A",{href:!0});var Lia=s(Vte);NJr=r(Lia,"TFXLMForSequenceClassification"),Lia.forEach(t),qJr=r(ZJe," (XLM model)"),ZJe.forEach(t),jJr=i(ae),sA=n(ae,"LI",{});var eYe=s(sA);YLe=n(eYe,"STRONG",{});var yia=s(YLe);DJr=r(yia,"xlm-roberta"),yia.forEach(t),GJr=r(eYe," \u2014 "),Xte=n(eYe,"A",{href:!0});var xia=s(Xte);OJr=r(xia,"TFXLMRobertaForSequenceClassification"),xia.forEach(t),VJr=r(eYe," (XLM-RoBERTa model)"),eYe.forEach(t),XJr=i(ae),lA=n(ae,"LI",{});var oYe=s(lA);KLe=n(oYe,"STRONG",{});var $ia=s(KLe);zJr=r($ia,"xlnet"),$ia.forEach(t),QJr=r(oYe," \u2014 "),zte=n(oYe,"A",{href:!0});var kia=s(zte);WJr=r(kia,"TFXLNetForSequenceClassification"),kia.forEach(t),UJr=r(oYe," (XLNet model)"),oYe.forEach(t),ae.forEach(t),HJr=i(pi),T(iA.$$.fragment,pi),pi.forEach(t),ui.forEach(t),Ooo=i(c),hc=n(c,"H2",{class:!0});var rao=s(hc);dA=n(rao,"A",{id:!0,class:!0,href:!0});var Sia=s(dA);ZLe=n(Sia,"SPAN",{});var Ria=s(ZLe);T(OS.$$.fragment,Ria),Ria.forEach(t),Sia.forEach(t),JJr=i(rao),eye=n(rao,"SPAN",{});var Pia=s(eye);YJr=r(Pia,"TFAutoModelForMultipleChoice"),Pia.forEach(t),rao.forEach(t),Voo=i(c),hr=n(c,"DIV",{class:!0});var _i=s(hr);T(VS.$$.fragment,_i),KJr=i(_i),uc=n(_i,"P",{});var xde=s(uc);ZJr=r(xde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Qte=n(xde,"A",{href:!0});var Bia=s(Qte);eYr=r(Bia,"from_pretrained()"),Bia.forEach(t),oYr=r(xde," class method or the "),Wte=n(xde,"A",{href:!0});var Iia=s(Wte);rYr=r(Iia,"from_config()"),Iia.forEach(t),tYr=r(xde,` class
method.`),xde.forEach(t),aYr=i(_i),XS=n(_i,"P",{});var tao=s(XS);nYr=r(tao,"This class cannot be instantiated directly using "),oye=n(tao,"CODE",{});var Nia=s(oye);sYr=r(Nia,"__init__()"),Nia.forEach(t),lYr=r(tao," (throws an error)."),tao.forEach(t),iYr=i(_i),Kt=n(_i,"DIV",{class:!0});var b9=s(Kt);T(zS.$$.fragment,b9),dYr=i(b9),rye=n(b9,"P",{});var qia=s(rye);mYr=r(qia,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),qia.forEach(t),cYr=i(b9),pc=n(b9,"P",{});var $de=s(pc);fYr=r($de,`Note:
Loading a model from its configuration file does `),tye=n($de,"STRONG",{});var jia=s(tye);gYr=r(jia,"not"),jia.forEach(t),hYr=r($de,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ute=n($de,"A",{href:!0});var Dia=s(Ute);uYr=r(Dia,"from_pretrained()"),Dia.forEach(t),pYr=r($de," to load the model weights."),$de.forEach(t),_Yr=i(b9),T(mA.$$.fragment,b9),b9.forEach(t),bYr=i(_i),Xr=n(_i,"DIV",{class:!0});var bi=s(Xr);T(QS.$$.fragment,bi),vYr=i(bi),aye=n(bi,"P",{});var Gia=s(aye);FYr=r(Gia,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Gia.forEach(t),TYr=i(bi),Rn=n(bi,"P",{});var v9=s(Rn);MYr=r(v9,"The model class to instantiate is selected based on the "),nye=n(v9,"CODE",{});var Oia=s(nye);EYr=r(Oia,"model_type"),Oia.forEach(t),CYr=r(v9,` property of the config object (either
passed as an argument or loaded from `),sye=n(v9,"CODE",{});var Via=s(sye);wYr=r(Via,"pretrained_model_name_or_path"),Via.forEach(t),AYr=r(v9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lye=n(v9,"CODE",{});var Xia=s(lye);LYr=r(Xia,"pretrained_model_name_or_path"),Xia.forEach(t),yYr=r(v9,":"),v9.forEach(t),xYr=i(bi),ve=n(bi,"UL",{});var Te=s(ve);cA=n(Te,"LI",{});var rYe=s(cA);iye=n(rYe,"STRONG",{});var zia=s(iye);$Yr=r(zia,"albert"),zia.forEach(t),kYr=r(rYe," \u2014 "),Hte=n(rYe,"A",{href:!0});var Qia=s(Hte);SYr=r(Qia,"TFAlbertForMultipleChoice"),Qia.forEach(t),RYr=r(rYe," (ALBERT model)"),rYe.forEach(t),PYr=i(Te),fA=n(Te,"LI",{});var tYe=s(fA);dye=n(tYe,"STRONG",{});var Wia=s(dye);BYr=r(Wia,"bert"),Wia.forEach(t),IYr=r(tYe," \u2014 "),Jte=n(tYe,"A",{href:!0});var Uia=s(Jte);NYr=r(Uia,"TFBertForMultipleChoice"),Uia.forEach(t),qYr=r(tYe," (BERT model)"),tYe.forEach(t),jYr=i(Te),gA=n(Te,"LI",{});var aYe=s(gA);mye=n(aYe,"STRONG",{});var Hia=s(mye);DYr=r(Hia,"camembert"),Hia.forEach(t),GYr=r(aYe," \u2014 "),Yte=n(aYe,"A",{href:!0});var Jia=s(Yte);OYr=r(Jia,"TFCamembertForMultipleChoice"),Jia.forEach(t),VYr=r(aYe," (CamemBERT model)"),aYe.forEach(t),XYr=i(Te),hA=n(Te,"LI",{});var nYe=s(hA);cye=n(nYe,"STRONG",{});var Yia=s(cye);zYr=r(Yia,"convbert"),Yia.forEach(t),QYr=r(nYe," \u2014 "),Kte=n(nYe,"A",{href:!0});var Kia=s(Kte);WYr=r(Kia,"TFConvBertForMultipleChoice"),Kia.forEach(t),UYr=r(nYe," (ConvBERT model)"),nYe.forEach(t),HYr=i(Te),uA=n(Te,"LI",{});var sYe=s(uA);fye=n(sYe,"STRONG",{});var Zia=s(fye);JYr=r(Zia,"distilbert"),Zia.forEach(t),YYr=r(sYe," \u2014 "),Zte=n(sYe,"A",{href:!0});var eda=s(Zte);KYr=r(eda,"TFDistilBertForMultipleChoice"),eda.forEach(t),ZYr=r(sYe," (DistilBERT model)"),sYe.forEach(t),eKr=i(Te),pA=n(Te,"LI",{});var lYe=s(pA);gye=n(lYe,"STRONG",{});var oda=s(gye);oKr=r(oda,"electra"),oda.forEach(t),rKr=r(lYe," \u2014 "),eae=n(lYe,"A",{href:!0});var rda=s(eae);tKr=r(rda,"TFElectraForMultipleChoice"),rda.forEach(t),aKr=r(lYe," (ELECTRA model)"),lYe.forEach(t),nKr=i(Te),_A=n(Te,"LI",{});var iYe=s(_A);hye=n(iYe,"STRONG",{});var tda=s(hye);sKr=r(tda,"flaubert"),tda.forEach(t),lKr=r(iYe," \u2014 "),oae=n(iYe,"A",{href:!0});var ada=s(oae);iKr=r(ada,"TFFlaubertForMultipleChoice"),ada.forEach(t),dKr=r(iYe," (FlauBERT model)"),iYe.forEach(t),mKr=i(Te),bA=n(Te,"LI",{});var dYe=s(bA);uye=n(dYe,"STRONG",{});var nda=s(uye);cKr=r(nda,"funnel"),nda.forEach(t),fKr=r(dYe," \u2014 "),rae=n(dYe,"A",{href:!0});var sda=s(rae);gKr=r(sda,"TFFunnelForMultipleChoice"),sda.forEach(t),hKr=r(dYe," (Funnel Transformer model)"),dYe.forEach(t),uKr=i(Te),vA=n(Te,"LI",{});var mYe=s(vA);pye=n(mYe,"STRONG",{});var lda=s(pye);pKr=r(lda,"longformer"),lda.forEach(t),_Kr=r(mYe," \u2014 "),tae=n(mYe,"A",{href:!0});var ida=s(tae);bKr=r(ida,"TFLongformerForMultipleChoice"),ida.forEach(t),vKr=r(mYe," (Longformer model)"),mYe.forEach(t),FKr=i(Te),FA=n(Te,"LI",{});var cYe=s(FA);_ye=n(cYe,"STRONG",{});var dda=s(_ye);TKr=r(dda,"mobilebert"),dda.forEach(t),MKr=r(cYe," \u2014 "),aae=n(cYe,"A",{href:!0});var mda=s(aae);EKr=r(mda,"TFMobileBertForMultipleChoice"),mda.forEach(t),CKr=r(cYe," (MobileBERT model)"),cYe.forEach(t),wKr=i(Te),TA=n(Te,"LI",{});var fYe=s(TA);bye=n(fYe,"STRONG",{});var cda=s(bye);AKr=r(cda,"mpnet"),cda.forEach(t),LKr=r(fYe," \u2014 "),nae=n(fYe,"A",{href:!0});var fda=s(nae);yKr=r(fda,"TFMPNetForMultipleChoice"),fda.forEach(t),xKr=r(fYe," (MPNet model)"),fYe.forEach(t),$Kr=i(Te),MA=n(Te,"LI",{});var gYe=s(MA);vye=n(gYe,"STRONG",{});var gda=s(vye);kKr=r(gda,"rembert"),gda.forEach(t),SKr=r(gYe," \u2014 "),sae=n(gYe,"A",{href:!0});var hda=s(sae);RKr=r(hda,"TFRemBertForMultipleChoice"),hda.forEach(t),PKr=r(gYe," (RemBERT model)"),gYe.forEach(t),BKr=i(Te),EA=n(Te,"LI",{});var hYe=s(EA);Fye=n(hYe,"STRONG",{});var uda=s(Fye);IKr=r(uda,"roberta"),uda.forEach(t),NKr=r(hYe," \u2014 "),lae=n(hYe,"A",{href:!0});var pda=s(lae);qKr=r(pda,"TFRobertaForMultipleChoice"),pda.forEach(t),jKr=r(hYe," (RoBERTa model)"),hYe.forEach(t),DKr=i(Te),CA=n(Te,"LI",{});var uYe=s(CA);Tye=n(uYe,"STRONG",{});var _da=s(Tye);GKr=r(_da,"roformer"),_da.forEach(t),OKr=r(uYe," \u2014 "),iae=n(uYe,"A",{href:!0});var bda=s(iae);VKr=r(bda,"TFRoFormerForMultipleChoice"),bda.forEach(t),XKr=r(uYe," (RoFormer model)"),uYe.forEach(t),zKr=i(Te),wA=n(Te,"LI",{});var pYe=s(wA);Mye=n(pYe,"STRONG",{});var vda=s(Mye);QKr=r(vda,"xlm"),vda.forEach(t),WKr=r(pYe," \u2014 "),dae=n(pYe,"A",{href:!0});var Fda=s(dae);UKr=r(Fda,"TFXLMForMultipleChoice"),Fda.forEach(t),HKr=r(pYe," (XLM model)"),pYe.forEach(t),JKr=i(Te),AA=n(Te,"LI",{});var _Ye=s(AA);Eye=n(_Ye,"STRONG",{});var Tda=s(Eye);YKr=r(Tda,"xlm-roberta"),Tda.forEach(t),KKr=r(_Ye," \u2014 "),mae=n(_Ye,"A",{href:!0});var Mda=s(mae);ZKr=r(Mda,"TFXLMRobertaForMultipleChoice"),Mda.forEach(t),eZr=r(_Ye," (XLM-RoBERTa model)"),_Ye.forEach(t),oZr=i(Te),LA=n(Te,"LI",{});var bYe=s(LA);Cye=n(bYe,"STRONG",{});var Eda=s(Cye);rZr=r(Eda,"xlnet"),Eda.forEach(t),tZr=r(bYe," \u2014 "),cae=n(bYe,"A",{href:!0});var Cda=s(cae);aZr=r(Cda,"TFXLNetForMultipleChoice"),Cda.forEach(t),nZr=r(bYe," (XLNet model)"),bYe.forEach(t),Te.forEach(t),sZr=i(bi),T(yA.$$.fragment,bi),bi.forEach(t),_i.forEach(t),Xoo=i(c),_c=n(c,"H2",{class:!0});var aao=s(_c);xA=n(aao,"A",{id:!0,class:!0,href:!0});var wda=s(xA);wye=n(wda,"SPAN",{});var Ada=s(wye);T(WS.$$.fragment,Ada),Ada.forEach(t),wda.forEach(t),lZr=i(aao),Aye=n(aao,"SPAN",{});var Lda=s(Aye);iZr=r(Lda,"TFAutoModelForNextSentencePrediction"),Lda.forEach(t),aao.forEach(t),zoo=i(c),ur=n(c,"DIV",{class:!0});var vi=s(ur);T(US.$$.fragment,vi),dZr=i(vi),bc=n(vi,"P",{});var kde=s(bc);mZr=r(kde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),fae=n(kde,"A",{href:!0});var yda=s(fae);cZr=r(yda,"from_pretrained()"),yda.forEach(t),fZr=r(kde," class method or the "),gae=n(kde,"A",{href:!0});var xda=s(gae);gZr=r(xda,"from_config()"),xda.forEach(t),hZr=r(kde,` class
method.`),kde.forEach(t),uZr=i(vi),HS=n(vi,"P",{});var nao=s(HS);pZr=r(nao,"This class cannot be instantiated directly using "),Lye=n(nao,"CODE",{});var $da=s(Lye);_Zr=r($da,"__init__()"),$da.forEach(t),bZr=r(nao," (throws an error)."),nao.forEach(t),vZr=i(vi),Zt=n(vi,"DIV",{class:!0});var F9=s(Zt);T(JS.$$.fragment,F9),FZr=i(F9),yye=n(F9,"P",{});var kda=s(yye);TZr=r(kda,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),kda.forEach(t),MZr=i(F9),vc=n(F9,"P",{});var Sde=s(vc);EZr=r(Sde,`Note:
Loading a model from its configuration file does `),xye=n(Sde,"STRONG",{});var Sda=s(xye);CZr=r(Sda,"not"),Sda.forEach(t),wZr=r(Sde,` load the model weights. It only affects the
model\u2019s configuration. Use `),hae=n(Sde,"A",{href:!0});var Rda=s(hae);AZr=r(Rda,"from_pretrained()"),Rda.forEach(t),LZr=r(Sde," to load the model weights."),Sde.forEach(t),yZr=i(F9),T($A.$$.fragment,F9),F9.forEach(t),xZr=i(vi),zr=n(vi,"DIV",{class:!0});var Fi=s(zr);T(YS.$$.fragment,Fi),$Zr=i(Fi),$ye=n(Fi,"P",{});var Pda=s($ye);kZr=r(Pda,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Pda.forEach(t),SZr=i(Fi),Pn=n(Fi,"P",{});var T9=s(Pn);RZr=r(T9,"The model class to instantiate is selected based on the "),kye=n(T9,"CODE",{});var Bda=s(kye);PZr=r(Bda,"model_type"),Bda.forEach(t),BZr=r(T9,` property of the config object (either
passed as an argument or loaded from `),Sye=n(T9,"CODE",{});var Ida=s(Sye);IZr=r(Ida,"pretrained_model_name_or_path"),Ida.forEach(t),NZr=r(T9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rye=n(T9,"CODE",{});var Nda=s(Rye);qZr=r(Nda,"pretrained_model_name_or_path"),Nda.forEach(t),jZr=r(T9,":"),T9.forEach(t),DZr=i(Fi),KS=n(Fi,"UL",{});var sao=s(KS);kA=n(sao,"LI",{});var vYe=s(kA);Pye=n(vYe,"STRONG",{});var qda=s(Pye);GZr=r(qda,"bert"),qda.forEach(t),OZr=r(vYe," \u2014 "),uae=n(vYe,"A",{href:!0});var jda=s(uae);VZr=r(jda,"TFBertForNextSentencePrediction"),jda.forEach(t),XZr=r(vYe," (BERT model)"),vYe.forEach(t),zZr=i(sao),SA=n(sao,"LI",{});var FYe=s(SA);Bye=n(FYe,"STRONG",{});var Dda=s(Bye);QZr=r(Dda,"mobilebert"),Dda.forEach(t),WZr=r(FYe," \u2014 "),pae=n(FYe,"A",{href:!0});var Gda=s(pae);UZr=r(Gda,"TFMobileBertForNextSentencePrediction"),Gda.forEach(t),HZr=r(FYe," (MobileBERT model)"),FYe.forEach(t),sao.forEach(t),JZr=i(Fi),T(RA.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),Qoo=i(c),Fc=n(c,"H2",{class:!0});var lao=s(Fc);PA=n(lao,"A",{id:!0,class:!0,href:!0});var Oda=s(PA);Iye=n(Oda,"SPAN",{});var Vda=s(Iye);T(ZS.$$.fragment,Vda),Vda.forEach(t),Oda.forEach(t),YZr=i(lao),Nye=n(lao,"SPAN",{});var Xda=s(Nye);KZr=r(Xda,"TFAutoModelForTableQuestionAnswering"),Xda.forEach(t),lao.forEach(t),Woo=i(c),pr=n(c,"DIV",{class:!0});var Ti=s(pr);T(eR.$$.fragment,Ti),ZZr=i(Ti),Tc=n(Ti,"P",{});var Rde=s(Tc);eet=r(Rde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),_ae=n(Rde,"A",{href:!0});var zda=s(_ae);oet=r(zda,"from_pretrained()"),zda.forEach(t),ret=r(Rde," class method or the "),bae=n(Rde,"A",{href:!0});var Qda=s(bae);tet=r(Qda,"from_config()"),Qda.forEach(t),aet=r(Rde,` class
method.`),Rde.forEach(t),net=i(Ti),oR=n(Ti,"P",{});var iao=s(oR);set=r(iao,"This class cannot be instantiated directly using "),qye=n(iao,"CODE",{});var Wda=s(qye);iet=r(Wda,"__init__()"),Wda.forEach(t),det=r(iao," (throws an error)."),iao.forEach(t),met=i(Ti),ea=n(Ti,"DIV",{class:!0});var M9=s(ea);T(rR.$$.fragment,M9),cet=i(M9),jye=n(M9,"P",{});var Uda=s(jye);fet=r(Uda,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Uda.forEach(t),get=i(M9),Mc=n(M9,"P",{});var Pde=s(Mc);het=r(Pde,`Note:
Loading a model from its configuration file does `),Dye=n(Pde,"STRONG",{});var Hda=s(Dye);uet=r(Hda,"not"),Hda.forEach(t),pet=r(Pde,` load the model weights. It only affects the
model\u2019s configuration. Use `),vae=n(Pde,"A",{href:!0});var Jda=s(vae);_et=r(Jda,"from_pretrained()"),Jda.forEach(t),bet=r(Pde," to load the model weights."),Pde.forEach(t),vet=i(M9),T(BA.$$.fragment,M9),M9.forEach(t),Fet=i(Ti),Qr=n(Ti,"DIV",{class:!0});var Mi=s(Qr);T(tR.$$.fragment,Mi),Tet=i(Mi),Gye=n(Mi,"P",{});var Yda=s(Gye);Met=r(Yda,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Yda.forEach(t),Eet=i(Mi),Bn=n(Mi,"P",{});var E9=s(Bn);Cet=r(E9,"The model class to instantiate is selected based on the "),Oye=n(E9,"CODE",{});var Kda=s(Oye);wet=r(Kda,"model_type"),Kda.forEach(t),Aet=r(E9,` property of the config object (either
passed as an argument or loaded from `),Vye=n(E9,"CODE",{});var Zda=s(Vye);Let=r(Zda,"pretrained_model_name_or_path"),Zda.forEach(t),yet=r(E9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xye=n(E9,"CODE",{});var ema=s(Xye);xet=r(ema,"pretrained_model_name_or_path"),ema.forEach(t),$et=r(E9,":"),E9.forEach(t),ket=i(Mi),zye=n(Mi,"UL",{});var oma=s(zye);IA=n(oma,"LI",{});var TYe=s(IA);Qye=n(TYe,"STRONG",{});var rma=s(Qye);Set=r(rma,"tapas"),rma.forEach(t),Ret=r(TYe," \u2014 "),Fae=n(TYe,"A",{href:!0});var tma=s(Fae);Pet=r(tma,"TFTapasForQuestionAnswering"),tma.forEach(t),Bet=r(TYe," (TAPAS model)"),TYe.forEach(t),oma.forEach(t),Iet=i(Mi),T(NA.$$.fragment,Mi),Mi.forEach(t),Ti.forEach(t),Uoo=i(c),Ec=n(c,"H2",{class:!0});var dao=s(Ec);qA=n(dao,"A",{id:!0,class:!0,href:!0});var ama=s(qA);Wye=n(ama,"SPAN",{});var nma=s(Wye);T(aR.$$.fragment,nma),nma.forEach(t),ama.forEach(t),Net=i(dao),Uye=n(dao,"SPAN",{});var sma=s(Uye);qet=r(sma,"TFAutoModelForDocumentQuestionAnswering"),sma.forEach(t),dao.forEach(t),Hoo=i(c),_r=n(c,"DIV",{class:!0});var Ei=s(_r);T(nR.$$.fragment,Ei),jet=i(Ei),Cc=n(Ei,"P",{});var Bde=s(Cc);Det=r(Bde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Tae=n(Bde,"A",{href:!0});var lma=s(Tae);Get=r(lma,"from_pretrained()"),lma.forEach(t),Oet=r(Bde," class method or the "),Mae=n(Bde,"A",{href:!0});var ima=s(Mae);Vet=r(ima,"from_config()"),ima.forEach(t),Xet=r(Bde,` class
method.`),Bde.forEach(t),zet=i(Ei),sR=n(Ei,"P",{});var mao=s(sR);Qet=r(mao,"This class cannot be instantiated directly using "),Hye=n(mao,"CODE",{});var dma=s(Hye);Wet=r(dma,"__init__()"),dma.forEach(t),Uet=r(mao," (throws an error)."),mao.forEach(t),Het=i(Ei),oa=n(Ei,"DIV",{class:!0});var C9=s(oa);T(lR.$$.fragment,C9),Jet=i(C9),Jye=n(C9,"P",{});var mma=s(Jye);Yet=r(mma,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),mma.forEach(t),Ket=i(C9),wc=n(C9,"P",{});var Ide=s(wc);Zet=r(Ide,`Note:
Loading a model from its configuration file does `),Yye=n(Ide,"STRONG",{});var cma=s(Yye);eot=r(cma,"not"),cma.forEach(t),oot=r(Ide,` load the model weights. It only affects the
model\u2019s configuration. Use `),Eae=n(Ide,"A",{href:!0});var fma=s(Eae);rot=r(fma,"from_pretrained()"),fma.forEach(t),tot=r(Ide," to load the model weights."),Ide.forEach(t),aot=i(C9),T(jA.$$.fragment,C9),C9.forEach(t),not=i(Ei),Wr=n(Ei,"DIV",{class:!0});var Ci=s(Wr);T(iR.$$.fragment,Ci),sot=i(Ci),Kye=n(Ci,"P",{});var gma=s(Kye);lot=r(gma,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),gma.forEach(t),iot=i(Ci),In=n(Ci,"P",{});var w9=s(In);dot=r(w9,"The model class to instantiate is selected based on the "),Zye=n(w9,"CODE",{});var hma=s(Zye);mot=r(hma,"model_type"),hma.forEach(t),cot=r(w9,` property of the config object (either
passed as an argument or loaded from `),e8e=n(w9,"CODE",{});var uma=s(e8e);fot=r(uma,"pretrained_model_name_or_path"),uma.forEach(t),got=r(w9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o8e=n(w9,"CODE",{});var pma=s(o8e);hot=r(pma,"pretrained_model_name_or_path"),pma.forEach(t),uot=r(w9,":"),w9.forEach(t),pot=i(Ci),r8e=n(Ci,"UL",{});var _ma=s(r8e);DA=n(_ma,"LI",{});var MYe=s(DA);t8e=n(MYe,"STRONG",{});var bma=s(t8e);_ot=r(bma,"layoutlm"),bma.forEach(t),bot=r(MYe," \u2014 "),Cae=n(MYe,"A",{href:!0});var vma=s(Cae);vot=r(vma,"TFLayoutLMForQuestionAnswering"),vma.forEach(t),Fot=r(MYe," (LayoutLM model)"),MYe.forEach(t),_ma.forEach(t),Tot=i(Ci),T(GA.$$.fragment,Ci),Ci.forEach(t),Ei.forEach(t),Joo=i(c),Ac=n(c,"H2",{class:!0});var cao=s(Ac);OA=n(cao,"A",{id:!0,class:!0,href:!0});var Fma=s(OA);a8e=n(Fma,"SPAN",{});var Tma=s(a8e);T(dR.$$.fragment,Tma),Tma.forEach(t),Fma.forEach(t),Mot=i(cao),n8e=n(cao,"SPAN",{});var Mma=s(n8e);Eot=r(Mma,"TFAutoModelForTokenClassification"),Mma.forEach(t),cao.forEach(t),Yoo=i(c),br=n(c,"DIV",{class:!0});var wi=s(br);T(mR.$$.fragment,wi),Cot=i(wi),Lc=n(wi,"P",{});var Nde=s(Lc);wot=r(Nde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),wae=n(Nde,"A",{href:!0});var Ema=s(wae);Aot=r(Ema,"from_pretrained()"),Ema.forEach(t),Lot=r(Nde," class method or the "),Aae=n(Nde,"A",{href:!0});var Cma=s(Aae);yot=r(Cma,"from_config()"),Cma.forEach(t),xot=r(Nde,` class
method.`),Nde.forEach(t),$ot=i(wi),cR=n(wi,"P",{});var fao=s(cR);kot=r(fao,"This class cannot be instantiated directly using "),s8e=n(fao,"CODE",{});var wma=s(s8e);Sot=r(wma,"__init__()"),wma.forEach(t),Rot=r(fao," (throws an error)."),fao.forEach(t),Pot=i(wi),ra=n(wi,"DIV",{class:!0});var A9=s(ra);T(fR.$$.fragment,A9),Bot=i(A9),l8e=n(A9,"P",{});var Ama=s(l8e);Iot=r(Ama,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Ama.forEach(t),Not=i(A9),yc=n(A9,"P",{});var qde=s(yc);qot=r(qde,`Note:
Loading a model from its configuration file does `),i8e=n(qde,"STRONG",{});var Lma=s(i8e);jot=r(Lma,"not"),Lma.forEach(t),Dot=r(qde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lae=n(qde,"A",{href:!0});var yma=s(Lae);Got=r(yma,"from_pretrained()"),yma.forEach(t),Oot=r(qde," to load the model weights."),qde.forEach(t),Vot=i(A9),T(VA.$$.fragment,A9),A9.forEach(t),Xot=i(wi),Ur=n(wi,"DIV",{class:!0});var Ai=s(Ur);T(gR.$$.fragment,Ai),zot=i(Ai),d8e=n(Ai,"P",{});var xma=s(d8e);Qot=r(xma,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),xma.forEach(t),Wot=i(Ai),Nn=n(Ai,"P",{});var L9=s(Nn);Uot=r(L9,"The model class to instantiate is selected based on the "),m8e=n(L9,"CODE",{});var $ma=s(m8e);Hot=r($ma,"model_type"),$ma.forEach(t),Jot=r(L9,` property of the config object (either
passed as an argument or loaded from `),c8e=n(L9,"CODE",{});var kma=s(c8e);Yot=r(kma,"pretrained_model_name_or_path"),kma.forEach(t),Kot=r(L9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f8e=n(L9,"CODE",{});var Sma=s(f8e);Zot=r(Sma,"pretrained_model_name_or_path"),Sma.forEach(t),ert=r(L9,":"),L9.forEach(t),ort=i(Ai),me=n(Ai,"UL",{});var he=s(me);XA=n(he,"LI",{});var EYe=s(XA);g8e=n(EYe,"STRONG",{});var Rma=s(g8e);rrt=r(Rma,"albert"),Rma.forEach(t),trt=r(EYe," \u2014 "),yae=n(EYe,"A",{href:!0});var Pma=s(yae);art=r(Pma,"TFAlbertForTokenClassification"),Pma.forEach(t),nrt=r(EYe," (ALBERT model)"),EYe.forEach(t),srt=i(he),zA=n(he,"LI",{});var CYe=s(zA);h8e=n(CYe,"STRONG",{});var Bma=s(h8e);lrt=r(Bma,"bert"),Bma.forEach(t),irt=r(CYe," \u2014 "),xae=n(CYe,"A",{href:!0});var Ima=s(xae);drt=r(Ima,"TFBertForTokenClassification"),Ima.forEach(t),mrt=r(CYe," (BERT model)"),CYe.forEach(t),crt=i(he),QA=n(he,"LI",{});var wYe=s(QA);u8e=n(wYe,"STRONG",{});var Nma=s(u8e);frt=r(Nma,"camembert"),Nma.forEach(t),grt=r(wYe," \u2014 "),$ae=n(wYe,"A",{href:!0});var qma=s($ae);hrt=r(qma,"TFCamembertForTokenClassification"),qma.forEach(t),urt=r(wYe," (CamemBERT model)"),wYe.forEach(t),prt=i(he),WA=n(he,"LI",{});var AYe=s(WA);p8e=n(AYe,"STRONG",{});var jma=s(p8e);_rt=r(jma,"convbert"),jma.forEach(t),brt=r(AYe," \u2014 "),kae=n(AYe,"A",{href:!0});var Dma=s(kae);vrt=r(Dma,"TFConvBertForTokenClassification"),Dma.forEach(t),Frt=r(AYe," (ConvBERT model)"),AYe.forEach(t),Trt=i(he),UA=n(he,"LI",{});var LYe=s(UA);_8e=n(LYe,"STRONG",{});var Gma=s(_8e);Mrt=r(Gma,"deberta"),Gma.forEach(t),Ert=r(LYe," \u2014 "),Sae=n(LYe,"A",{href:!0});var Oma=s(Sae);Crt=r(Oma,"TFDebertaForTokenClassification"),Oma.forEach(t),wrt=r(LYe," (DeBERTa model)"),LYe.forEach(t),Art=i(he),HA=n(he,"LI",{});var yYe=s(HA);b8e=n(yYe,"STRONG",{});var Vma=s(b8e);Lrt=r(Vma,"deberta-v2"),Vma.forEach(t),yrt=r(yYe," \u2014 "),Rae=n(yYe,"A",{href:!0});var Xma=s(Rae);xrt=r(Xma,"TFDebertaV2ForTokenClassification"),Xma.forEach(t),$rt=r(yYe," (DeBERTa-v2 model)"),yYe.forEach(t),krt=i(he),JA=n(he,"LI",{});var xYe=s(JA);v8e=n(xYe,"STRONG",{});var zma=s(v8e);Srt=r(zma,"distilbert"),zma.forEach(t),Rrt=r(xYe," \u2014 "),Pae=n(xYe,"A",{href:!0});var Qma=s(Pae);Prt=r(Qma,"TFDistilBertForTokenClassification"),Qma.forEach(t),Brt=r(xYe," (DistilBERT model)"),xYe.forEach(t),Irt=i(he),YA=n(he,"LI",{});var $Ye=s(YA);F8e=n($Ye,"STRONG",{});var Wma=s(F8e);Nrt=r(Wma,"electra"),Wma.forEach(t),qrt=r($Ye," \u2014 "),Bae=n($Ye,"A",{href:!0});var Uma=s(Bae);jrt=r(Uma,"TFElectraForTokenClassification"),Uma.forEach(t),Drt=r($Ye," (ELECTRA model)"),$Ye.forEach(t),Grt=i(he),KA=n(he,"LI",{});var kYe=s(KA);T8e=n(kYe,"STRONG",{});var Hma=s(T8e);Ort=r(Hma,"flaubert"),Hma.forEach(t),Vrt=r(kYe," \u2014 "),Iae=n(kYe,"A",{href:!0});var Jma=s(Iae);Xrt=r(Jma,"TFFlaubertForTokenClassification"),Jma.forEach(t),zrt=r(kYe," (FlauBERT model)"),kYe.forEach(t),Qrt=i(he),ZA=n(he,"LI",{});var SYe=s(ZA);M8e=n(SYe,"STRONG",{});var Yma=s(M8e);Wrt=r(Yma,"funnel"),Yma.forEach(t),Urt=r(SYe," \u2014 "),Nae=n(SYe,"A",{href:!0});var Kma=s(Nae);Hrt=r(Kma,"TFFunnelForTokenClassification"),Kma.forEach(t),Jrt=r(SYe," (Funnel Transformer model)"),SYe.forEach(t),Yrt=i(he),e6=n(he,"LI",{});var RYe=s(e6);E8e=n(RYe,"STRONG",{});var Zma=s(E8e);Krt=r(Zma,"layoutlm"),Zma.forEach(t),Zrt=r(RYe," \u2014 "),qae=n(RYe,"A",{href:!0});var eca=s(qae);ett=r(eca,"TFLayoutLMForTokenClassification"),eca.forEach(t),ott=r(RYe," (LayoutLM model)"),RYe.forEach(t),rtt=i(he),o6=n(he,"LI",{});var PYe=s(o6);C8e=n(PYe,"STRONG",{});var oca=s(C8e);ttt=r(oca,"layoutlmv3"),oca.forEach(t),att=r(PYe," \u2014 "),jae=n(PYe,"A",{href:!0});var rca=s(jae);ntt=r(rca,"TFLayoutLMv3ForTokenClassification"),rca.forEach(t),stt=r(PYe," (LayoutLMv3 model)"),PYe.forEach(t),ltt=i(he),r6=n(he,"LI",{});var BYe=s(r6);w8e=n(BYe,"STRONG",{});var tca=s(w8e);itt=r(tca,"longformer"),tca.forEach(t),dtt=r(BYe," \u2014 "),Dae=n(BYe,"A",{href:!0});var aca=s(Dae);mtt=r(aca,"TFLongformerForTokenClassification"),aca.forEach(t),ctt=r(BYe," (Longformer model)"),BYe.forEach(t),ftt=i(he),t6=n(he,"LI",{});var IYe=s(t6);A8e=n(IYe,"STRONG",{});var nca=s(A8e);gtt=r(nca,"mobilebert"),nca.forEach(t),htt=r(IYe," \u2014 "),Gae=n(IYe,"A",{href:!0});var sca=s(Gae);utt=r(sca,"TFMobileBertForTokenClassification"),sca.forEach(t),ptt=r(IYe," (MobileBERT model)"),IYe.forEach(t),_tt=i(he),a6=n(he,"LI",{});var NYe=s(a6);L8e=n(NYe,"STRONG",{});var lca=s(L8e);btt=r(lca,"mpnet"),lca.forEach(t),vtt=r(NYe," \u2014 "),Oae=n(NYe,"A",{href:!0});var ica=s(Oae);Ftt=r(ica,"TFMPNetForTokenClassification"),ica.forEach(t),Ttt=r(NYe," (MPNet model)"),NYe.forEach(t),Mtt=i(he),n6=n(he,"LI",{});var qYe=s(n6);y8e=n(qYe,"STRONG",{});var dca=s(y8e);Ett=r(dca,"rembert"),dca.forEach(t),Ctt=r(qYe," \u2014 "),Vae=n(qYe,"A",{href:!0});var mca=s(Vae);wtt=r(mca,"TFRemBertForTokenClassification"),mca.forEach(t),Att=r(qYe," (RemBERT model)"),qYe.forEach(t),Ltt=i(he),s6=n(he,"LI",{});var jYe=s(s6);x8e=n(jYe,"STRONG",{});var cca=s(x8e);ytt=r(cca,"roberta"),cca.forEach(t),xtt=r(jYe," \u2014 "),Xae=n(jYe,"A",{href:!0});var fca=s(Xae);$tt=r(fca,"TFRobertaForTokenClassification"),fca.forEach(t),ktt=r(jYe," (RoBERTa model)"),jYe.forEach(t),Stt=i(he),l6=n(he,"LI",{});var DYe=s(l6);$8e=n(DYe,"STRONG",{});var gca=s($8e);Rtt=r(gca,"roformer"),gca.forEach(t),Ptt=r(DYe," \u2014 "),zae=n(DYe,"A",{href:!0});var hca=s(zae);Btt=r(hca,"TFRoFormerForTokenClassification"),hca.forEach(t),Itt=r(DYe," (RoFormer model)"),DYe.forEach(t),Ntt=i(he),i6=n(he,"LI",{});var GYe=s(i6);k8e=n(GYe,"STRONG",{});var uca=s(k8e);qtt=r(uca,"xlm"),uca.forEach(t),jtt=r(GYe," \u2014 "),Qae=n(GYe,"A",{href:!0});var pca=s(Qae);Dtt=r(pca,"TFXLMForTokenClassification"),pca.forEach(t),Gtt=r(GYe," (XLM model)"),GYe.forEach(t),Ott=i(he),d6=n(he,"LI",{});var OYe=s(d6);S8e=n(OYe,"STRONG",{});var _ca=s(S8e);Vtt=r(_ca,"xlm-roberta"),_ca.forEach(t),Xtt=r(OYe," \u2014 "),Wae=n(OYe,"A",{href:!0});var bca=s(Wae);ztt=r(bca,"TFXLMRobertaForTokenClassification"),bca.forEach(t),Qtt=r(OYe," (XLM-RoBERTa model)"),OYe.forEach(t),Wtt=i(he),m6=n(he,"LI",{});var VYe=s(m6);R8e=n(VYe,"STRONG",{});var vca=s(R8e);Utt=r(vca,"xlnet"),vca.forEach(t),Htt=r(VYe," \u2014 "),Uae=n(VYe,"A",{href:!0});var Fca=s(Uae);Jtt=r(Fca,"TFXLNetForTokenClassification"),Fca.forEach(t),Ytt=r(VYe," (XLNet model)"),VYe.forEach(t),he.forEach(t),Ktt=i(Ai),T(c6.$$.fragment,Ai),Ai.forEach(t),wi.forEach(t),Koo=i(c),xc=n(c,"H2",{class:!0});var gao=s(xc);f6=n(gao,"A",{id:!0,class:!0,href:!0});var Tca=s(f6);P8e=n(Tca,"SPAN",{});var Mca=s(P8e);T(hR.$$.fragment,Mca),Mca.forEach(t),Tca.forEach(t),Ztt=i(gao),B8e=n(gao,"SPAN",{});var Eca=s(B8e);eat=r(Eca,"TFAutoModelForQuestionAnswering"),Eca.forEach(t),gao.forEach(t),Zoo=i(c),vr=n(c,"DIV",{class:!0});var Li=s(vr);T(uR.$$.fragment,Li),oat=i(Li),$c=n(Li,"P",{});var jde=s($c);rat=r(jde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Hae=n(jde,"A",{href:!0});var Cca=s(Hae);tat=r(Cca,"from_pretrained()"),Cca.forEach(t),aat=r(jde," class method or the "),Jae=n(jde,"A",{href:!0});var wca=s(Jae);nat=r(wca,"from_config()"),wca.forEach(t),sat=r(jde,` class
method.`),jde.forEach(t),lat=i(Li),pR=n(Li,"P",{});var hao=s(pR);iat=r(hao,"This class cannot be instantiated directly using "),I8e=n(hao,"CODE",{});var Aca=s(I8e);dat=r(Aca,"__init__()"),Aca.forEach(t),mat=r(hao," (throws an error)."),hao.forEach(t),cat=i(Li),ta=n(Li,"DIV",{class:!0});var y9=s(ta);T(_R.$$.fragment,y9),fat=i(y9),N8e=n(y9,"P",{});var Lca=s(N8e);gat=r(Lca,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Lca.forEach(t),hat=i(y9),kc=n(y9,"P",{});var Dde=s(kc);uat=r(Dde,`Note:
Loading a model from its configuration file does `),q8e=n(Dde,"STRONG",{});var yca=s(q8e);pat=r(yca,"not"),yca.forEach(t),_at=r(Dde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yae=n(Dde,"A",{href:!0});var xca=s(Yae);bat=r(xca,"from_pretrained()"),xca.forEach(t),vat=r(Dde," to load the model weights."),Dde.forEach(t),Fat=i(y9),T(g6.$$.fragment,y9),y9.forEach(t),Tat=i(Li),Hr=n(Li,"DIV",{class:!0});var yi=s(Hr);T(bR.$$.fragment,yi),Mat=i(yi),j8e=n(yi,"P",{});var $ca=s(j8e);Eat=r($ca,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),$ca.forEach(t),Cat=i(yi),qn=n(yi,"P",{});var x9=s(qn);wat=r(x9,"The model class to instantiate is selected based on the "),D8e=n(x9,"CODE",{});var kca=s(D8e);Aat=r(kca,"model_type"),kca.forEach(t),Lat=r(x9,` property of the config object (either
passed as an argument or loaded from `),G8e=n(x9,"CODE",{});var Sca=s(G8e);yat=r(Sca,"pretrained_model_name_or_path"),Sca.forEach(t),xat=r(x9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O8e=n(x9,"CODE",{});var Rca=s(O8e);$at=r(Rca,"pretrained_model_name_or_path"),Rca.forEach(t),kat=r(x9,":"),x9.forEach(t),Sat=i(yi),ce=n(yi,"UL",{});var ue=s(ce);h6=n(ue,"LI",{});var XYe=s(h6);V8e=n(XYe,"STRONG",{});var Pca=s(V8e);Rat=r(Pca,"albert"),Pca.forEach(t),Pat=r(XYe," \u2014 "),Kae=n(XYe,"A",{href:!0});var Bca=s(Kae);Bat=r(Bca,"TFAlbertForQuestionAnswering"),Bca.forEach(t),Iat=r(XYe," (ALBERT model)"),XYe.forEach(t),Nat=i(ue),u6=n(ue,"LI",{});var zYe=s(u6);X8e=n(zYe,"STRONG",{});var Ica=s(X8e);qat=r(Ica,"bert"),Ica.forEach(t),jat=r(zYe," \u2014 "),Zae=n(zYe,"A",{href:!0});var Nca=s(Zae);Dat=r(Nca,"TFBertForQuestionAnswering"),Nca.forEach(t),Gat=r(zYe," (BERT model)"),zYe.forEach(t),Oat=i(ue),p6=n(ue,"LI",{});var QYe=s(p6);z8e=n(QYe,"STRONG",{});var qca=s(z8e);Vat=r(qca,"camembert"),qca.forEach(t),Xat=r(QYe," \u2014 "),ene=n(QYe,"A",{href:!0});var jca=s(ene);zat=r(jca,"TFCamembertForQuestionAnswering"),jca.forEach(t),Qat=r(QYe," (CamemBERT model)"),QYe.forEach(t),Wat=i(ue),_6=n(ue,"LI",{});var WYe=s(_6);Q8e=n(WYe,"STRONG",{});var Dca=s(Q8e);Uat=r(Dca,"convbert"),Dca.forEach(t),Hat=r(WYe," \u2014 "),one=n(WYe,"A",{href:!0});var Gca=s(one);Jat=r(Gca,"TFConvBertForQuestionAnswering"),Gca.forEach(t),Yat=r(WYe," (ConvBERT model)"),WYe.forEach(t),Kat=i(ue),b6=n(ue,"LI",{});var UYe=s(b6);W8e=n(UYe,"STRONG",{});var Oca=s(W8e);Zat=r(Oca,"deberta"),Oca.forEach(t),ent=r(UYe," \u2014 "),rne=n(UYe,"A",{href:!0});var Vca=s(rne);ont=r(Vca,"TFDebertaForQuestionAnswering"),Vca.forEach(t),rnt=r(UYe," (DeBERTa model)"),UYe.forEach(t),tnt=i(ue),v6=n(ue,"LI",{});var HYe=s(v6);U8e=n(HYe,"STRONG",{});var Xca=s(U8e);ant=r(Xca,"deberta-v2"),Xca.forEach(t),nnt=r(HYe," \u2014 "),tne=n(HYe,"A",{href:!0});var zca=s(tne);snt=r(zca,"TFDebertaV2ForQuestionAnswering"),zca.forEach(t),lnt=r(HYe," (DeBERTa-v2 model)"),HYe.forEach(t),int=i(ue),F6=n(ue,"LI",{});var JYe=s(F6);H8e=n(JYe,"STRONG",{});var Qca=s(H8e);dnt=r(Qca,"distilbert"),Qca.forEach(t),mnt=r(JYe," \u2014 "),ane=n(JYe,"A",{href:!0});var Wca=s(ane);cnt=r(Wca,"TFDistilBertForQuestionAnswering"),Wca.forEach(t),fnt=r(JYe," (DistilBERT model)"),JYe.forEach(t),gnt=i(ue),T6=n(ue,"LI",{});var YYe=s(T6);J8e=n(YYe,"STRONG",{});var Uca=s(J8e);hnt=r(Uca,"electra"),Uca.forEach(t),unt=r(YYe," \u2014 "),nne=n(YYe,"A",{href:!0});var Hca=s(nne);pnt=r(Hca,"TFElectraForQuestionAnswering"),Hca.forEach(t),_nt=r(YYe," (ELECTRA model)"),YYe.forEach(t),bnt=i(ue),M6=n(ue,"LI",{});var KYe=s(M6);Y8e=n(KYe,"STRONG",{});var Jca=s(Y8e);vnt=r(Jca,"flaubert"),Jca.forEach(t),Fnt=r(KYe," \u2014 "),sne=n(KYe,"A",{href:!0});var Yca=s(sne);Tnt=r(Yca,"TFFlaubertForQuestionAnsweringSimple"),Yca.forEach(t),Mnt=r(KYe," (FlauBERT model)"),KYe.forEach(t),Ent=i(ue),E6=n(ue,"LI",{});var ZYe=s(E6);K8e=n(ZYe,"STRONG",{});var Kca=s(K8e);Cnt=r(Kca,"funnel"),Kca.forEach(t),wnt=r(ZYe," \u2014 "),lne=n(ZYe,"A",{href:!0});var Zca=s(lne);Ant=r(Zca,"TFFunnelForQuestionAnswering"),Zca.forEach(t),Lnt=r(ZYe," (Funnel Transformer model)"),ZYe.forEach(t),ynt=i(ue),C6=n(ue,"LI",{});var eKe=s(C6);Z8e=n(eKe,"STRONG",{});var efa=s(Z8e);xnt=r(efa,"gptj"),efa.forEach(t),$nt=r(eKe," \u2014 "),ine=n(eKe,"A",{href:!0});var ofa=s(ine);knt=r(ofa,"TFGPTJForQuestionAnswering"),ofa.forEach(t),Snt=r(eKe," (GPT-J model)"),eKe.forEach(t),Rnt=i(ue),w6=n(ue,"LI",{});var oKe=s(w6);e9e=n(oKe,"STRONG",{});var rfa=s(e9e);Pnt=r(rfa,"layoutlmv3"),rfa.forEach(t),Bnt=r(oKe," \u2014 "),dne=n(oKe,"A",{href:!0});var tfa=s(dne);Int=r(tfa,"TFLayoutLMv3ForQuestionAnswering"),tfa.forEach(t),Nnt=r(oKe," (LayoutLMv3 model)"),oKe.forEach(t),qnt=i(ue),A6=n(ue,"LI",{});var rKe=s(A6);o9e=n(rKe,"STRONG",{});var afa=s(o9e);jnt=r(afa,"longformer"),afa.forEach(t),Dnt=r(rKe," \u2014 "),mne=n(rKe,"A",{href:!0});var nfa=s(mne);Gnt=r(nfa,"TFLongformerForQuestionAnswering"),nfa.forEach(t),Ont=r(rKe," (Longformer model)"),rKe.forEach(t),Vnt=i(ue),L6=n(ue,"LI",{});var tKe=s(L6);r9e=n(tKe,"STRONG",{});var sfa=s(r9e);Xnt=r(sfa,"mobilebert"),sfa.forEach(t),znt=r(tKe," \u2014 "),cne=n(tKe,"A",{href:!0});var lfa=s(cne);Qnt=r(lfa,"TFMobileBertForQuestionAnswering"),lfa.forEach(t),Wnt=r(tKe," (MobileBERT model)"),tKe.forEach(t),Unt=i(ue),y6=n(ue,"LI",{});var aKe=s(y6);t9e=n(aKe,"STRONG",{});var ifa=s(t9e);Hnt=r(ifa,"mpnet"),ifa.forEach(t),Jnt=r(aKe," \u2014 "),fne=n(aKe,"A",{href:!0});var dfa=s(fne);Ynt=r(dfa,"TFMPNetForQuestionAnswering"),dfa.forEach(t),Knt=r(aKe," (MPNet model)"),aKe.forEach(t),Znt=i(ue),x6=n(ue,"LI",{});var nKe=s(x6);a9e=n(nKe,"STRONG",{});var mfa=s(a9e);est=r(mfa,"rembert"),mfa.forEach(t),ost=r(nKe," \u2014 "),gne=n(nKe,"A",{href:!0});var cfa=s(gne);rst=r(cfa,"TFRemBertForQuestionAnswering"),cfa.forEach(t),tst=r(nKe," (RemBERT model)"),nKe.forEach(t),ast=i(ue),$6=n(ue,"LI",{});var sKe=s($6);n9e=n(sKe,"STRONG",{});var ffa=s(n9e);nst=r(ffa,"roberta"),ffa.forEach(t),sst=r(sKe," \u2014 "),hne=n(sKe,"A",{href:!0});var gfa=s(hne);lst=r(gfa,"TFRobertaForQuestionAnswering"),gfa.forEach(t),ist=r(sKe," (RoBERTa model)"),sKe.forEach(t),dst=i(ue),k6=n(ue,"LI",{});var lKe=s(k6);s9e=n(lKe,"STRONG",{});var hfa=s(s9e);mst=r(hfa,"roformer"),hfa.forEach(t),cst=r(lKe," \u2014 "),une=n(lKe,"A",{href:!0});var ufa=s(une);fst=r(ufa,"TFRoFormerForQuestionAnswering"),ufa.forEach(t),gst=r(lKe," (RoFormer model)"),lKe.forEach(t),hst=i(ue),S6=n(ue,"LI",{});var iKe=s(S6);l9e=n(iKe,"STRONG",{});var pfa=s(l9e);ust=r(pfa,"xlm"),pfa.forEach(t),pst=r(iKe," \u2014 "),pne=n(iKe,"A",{href:!0});var _fa=s(pne);_st=r(_fa,"TFXLMForQuestionAnsweringSimple"),_fa.forEach(t),bst=r(iKe," (XLM model)"),iKe.forEach(t),vst=i(ue),R6=n(ue,"LI",{});var dKe=s(R6);i9e=n(dKe,"STRONG",{});var bfa=s(i9e);Fst=r(bfa,"xlm-roberta"),bfa.forEach(t),Tst=r(dKe," \u2014 "),_ne=n(dKe,"A",{href:!0});var vfa=s(_ne);Mst=r(vfa,"TFXLMRobertaForQuestionAnswering"),vfa.forEach(t),Est=r(dKe," (XLM-RoBERTa model)"),dKe.forEach(t),Cst=i(ue),P6=n(ue,"LI",{});var mKe=s(P6);d9e=n(mKe,"STRONG",{});var Ffa=s(d9e);wst=r(Ffa,"xlnet"),Ffa.forEach(t),Ast=r(mKe," \u2014 "),bne=n(mKe,"A",{href:!0});var Tfa=s(bne);Lst=r(Tfa,"TFXLNetForQuestionAnsweringSimple"),Tfa.forEach(t),yst=r(mKe," (XLNet model)"),mKe.forEach(t),ue.forEach(t),xst=i(yi),T(B6.$$.fragment,yi),yi.forEach(t),Li.forEach(t),ero=i(c),Sc=n(c,"H2",{class:!0});var uao=s(Sc);I6=n(uao,"A",{id:!0,class:!0,href:!0});var Mfa=s(I6);m9e=n(Mfa,"SPAN",{});var Efa=s(m9e);T(vR.$$.fragment,Efa),Efa.forEach(t),Mfa.forEach(t),$st=i(uao),c9e=n(uao,"SPAN",{});var Cfa=s(c9e);kst=r(Cfa,"TFAutoModelForVision2Seq"),Cfa.forEach(t),uao.forEach(t),oro=i(c),Fr=n(c,"DIV",{class:!0});var xi=s(Fr);T(FR.$$.fragment,xi),Sst=i(xi),Rc=n(xi,"P",{});var Gde=s(Rc);Rst=r(Gde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),vne=n(Gde,"A",{href:!0});var wfa=s(vne);Pst=r(wfa,"from_pretrained()"),wfa.forEach(t),Bst=r(Gde," class method or the "),Fne=n(Gde,"A",{href:!0});var Afa=s(Fne);Ist=r(Afa,"from_config()"),Afa.forEach(t),Nst=r(Gde,` class
method.`),Gde.forEach(t),qst=i(xi),TR=n(xi,"P",{});var pao=s(TR);jst=r(pao,"This class cannot be instantiated directly using "),f9e=n(pao,"CODE",{});var Lfa=s(f9e);Dst=r(Lfa,"__init__()"),Lfa.forEach(t),Gst=r(pao," (throws an error)."),pao.forEach(t),Ost=i(xi),aa=n(xi,"DIV",{class:!0});var $9=s(aa);T(MR.$$.fragment,$9),Vst=i($9),g9e=n($9,"P",{});var yfa=s(g9e);Xst=r(yfa,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),yfa.forEach(t),zst=i($9),Pc=n($9,"P",{});var Ode=s(Pc);Qst=r(Ode,`Note:
Loading a model from its configuration file does `),h9e=n(Ode,"STRONG",{});var xfa=s(h9e);Wst=r(xfa,"not"),xfa.forEach(t),Ust=r(Ode,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tne=n(Ode,"A",{href:!0});var $fa=s(Tne);Hst=r($fa,"from_pretrained()"),$fa.forEach(t),Jst=r(Ode," to load the model weights."),Ode.forEach(t),Yst=i($9),T(N6.$$.fragment,$9),$9.forEach(t),Kst=i(xi),Jr=n(xi,"DIV",{class:!0});var $i=s(Jr);T(ER.$$.fragment,$i),Zst=i($i),u9e=n($i,"P",{});var kfa=s(u9e);elt=r(kfa,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),kfa.forEach(t),olt=i($i),jn=n($i,"P",{});var k9=s(jn);rlt=r(k9,"The model class to instantiate is selected based on the "),p9e=n(k9,"CODE",{});var Sfa=s(p9e);tlt=r(Sfa,"model_type"),Sfa.forEach(t),alt=r(k9,` property of the config object (either
passed as an argument or loaded from `),_9e=n(k9,"CODE",{});var Rfa=s(_9e);nlt=r(Rfa,"pretrained_model_name_or_path"),Rfa.forEach(t),slt=r(k9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b9e=n(k9,"CODE",{});var Pfa=s(b9e);llt=r(Pfa,"pretrained_model_name_or_path"),Pfa.forEach(t),ilt=r(k9,":"),k9.forEach(t),dlt=i($i),v9e=n($i,"UL",{});var Bfa=s(v9e);q6=n(Bfa,"LI",{});var cKe=s(q6);F9e=n(cKe,"STRONG",{});var Ifa=s(F9e);mlt=r(Ifa,"vision-encoder-decoder"),Ifa.forEach(t),clt=r(cKe," \u2014 "),Mne=n(cKe,"A",{href:!0});var Nfa=s(Mne);flt=r(Nfa,"TFVisionEncoderDecoderModel"),Nfa.forEach(t),glt=r(cKe," (Vision Encoder decoder model)"),cKe.forEach(t),Bfa.forEach(t),hlt=i($i),T(j6.$$.fragment,$i),$i.forEach(t),xi.forEach(t),rro=i(c),Bc=n(c,"H2",{class:!0});var _ao=s(Bc);D6=n(_ao,"A",{id:!0,class:!0,href:!0});var qfa=s(D6);T9e=n(qfa,"SPAN",{});var jfa=s(T9e);T(CR.$$.fragment,jfa),jfa.forEach(t),qfa.forEach(t),ult=i(_ao),M9e=n(_ao,"SPAN",{});var Dfa=s(M9e);plt=r(Dfa,"TFAutoModelForSpeechSeq2Seq"),Dfa.forEach(t),_ao.forEach(t),tro=i(c),Tr=n(c,"DIV",{class:!0});var ki=s(Tr);T(wR.$$.fragment,ki),_lt=i(ki),Ic=n(ki,"P",{});var Vde=s(Ic);blt=r(Vde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Ene=n(Vde,"A",{href:!0});var Gfa=s(Ene);vlt=r(Gfa,"from_pretrained()"),Gfa.forEach(t),Flt=r(Vde," class method or the "),Cne=n(Vde,"A",{href:!0});var Ofa=s(Cne);Tlt=r(Ofa,"from_config()"),Ofa.forEach(t),Mlt=r(Vde,` class
method.`),Vde.forEach(t),Elt=i(ki),AR=n(ki,"P",{});var bao=s(AR);Clt=r(bao,"This class cannot be instantiated directly using "),E9e=n(bao,"CODE",{});var Vfa=s(E9e);wlt=r(Vfa,"__init__()"),Vfa.forEach(t),Alt=r(bao," (throws an error)."),bao.forEach(t),Llt=i(ki),na=n(ki,"DIV",{class:!0});var S9=s(na);T(LR.$$.fragment,S9),ylt=i(S9),C9e=n(S9,"P",{});var Xfa=s(C9e);xlt=r(Xfa,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Xfa.forEach(t),$lt=i(S9),Nc=n(S9,"P",{});var Xde=s(Nc);klt=r(Xde,`Note:
Loading a model from its configuration file does `),w9e=n(Xde,"STRONG",{});var zfa=s(w9e);Slt=r(zfa,"not"),zfa.forEach(t),Rlt=r(Xde,` load the model weights. It only affects the
model\u2019s configuration. Use `),wne=n(Xde,"A",{href:!0});var Qfa=s(wne);Plt=r(Qfa,"from_pretrained()"),Qfa.forEach(t),Blt=r(Xde," to load the model weights."),Xde.forEach(t),Ilt=i(S9),T(G6.$$.fragment,S9),S9.forEach(t),Nlt=i(ki),Yr=n(ki,"DIV",{class:!0});var Si=s(Yr);T(yR.$$.fragment,Si),qlt=i(Si),A9e=n(Si,"P",{});var Wfa=s(A9e);jlt=r(Wfa,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Wfa.forEach(t),Dlt=i(Si),Dn=n(Si,"P",{});var R9=s(Dn);Glt=r(R9,"The model class to instantiate is selected based on the "),L9e=n(R9,"CODE",{});var Ufa=s(L9e);Olt=r(Ufa,"model_type"),Ufa.forEach(t),Vlt=r(R9,` property of the config object (either
passed as an argument or loaded from `),y9e=n(R9,"CODE",{});var Hfa=s(y9e);Xlt=r(Hfa,"pretrained_model_name_or_path"),Hfa.forEach(t),zlt=r(R9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x9e=n(R9,"CODE",{});var Jfa=s(x9e);Qlt=r(Jfa,"pretrained_model_name_or_path"),Jfa.forEach(t),Wlt=r(R9,":"),R9.forEach(t),Ult=i(Si),$9e=n(Si,"UL",{});var Yfa=s($9e);O6=n(Yfa,"LI",{});var fKe=s(O6);k9e=n(fKe,"STRONG",{});var Kfa=s(k9e);Hlt=r(Kfa,"speech_to_text"),Kfa.forEach(t),Jlt=r(fKe," \u2014 "),Ane=n(fKe,"A",{href:!0});var Zfa=s(Ane);Ylt=r(Zfa,"TFSpeech2TextForConditionalGeneration"),Zfa.forEach(t),Klt=r(fKe," (Speech2Text model)"),fKe.forEach(t),Yfa.forEach(t),Zlt=i(Si),T(V6.$$.fragment,Si),Si.forEach(t),ki.forEach(t),aro=i(c),qc=n(c,"H2",{class:!0});var vao=s(qc);X6=n(vao,"A",{id:!0,class:!0,href:!0});var ega=s(X6);S9e=n(ega,"SPAN",{});var oga=s(S9e);T(xR.$$.fragment,oga),oga.forEach(t),ega.forEach(t),eit=i(vao),R9e=n(vao,"SPAN",{});var rga=s(R9e);oit=r(rga,"FlaxAutoModel"),rga.forEach(t),vao.forEach(t),nro=i(c),Mr=n(c,"DIV",{class:!0});var Ri=s(Mr);T($R.$$.fragment,Ri),rit=i(Ri),jc=n(Ri,"P",{});var zde=s(jc);tit=r(zde,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Lne=n(zde,"A",{href:!0});var tga=s(Lne);ait=r(tga,"from_pretrained()"),tga.forEach(t),nit=r(zde," class method or the "),yne=n(zde,"A",{href:!0});var aga=s(yne);sit=r(aga,"from_config()"),aga.forEach(t),lit=r(zde,` class
method.`),zde.forEach(t),iit=i(Ri),kR=n(Ri,"P",{});var Fao=s(kR);dit=r(Fao,"This class cannot be instantiated directly using "),P9e=n(Fao,"CODE",{});var nga=s(P9e);mit=r(nga,"__init__()"),nga.forEach(t),cit=r(Fao," (throws an error)."),Fao.forEach(t),fit=i(Ri),sa=n(Ri,"DIV",{class:!0});var P9=s(sa);T(SR.$$.fragment,P9),git=i(P9),B9e=n(P9,"P",{});var sga=s(B9e);hit=r(sga,"Instantiates one of the base model classes of the library from a configuration."),sga.forEach(t),uit=i(P9),Dc=n(P9,"P",{});var Qde=s(Dc);pit=r(Qde,`Note:
Loading a model from its configuration file does `),I9e=n(Qde,"STRONG",{});var lga=s(I9e);_it=r(lga,"not"),lga.forEach(t),bit=r(Qde,` load the model weights. It only affects the
model\u2019s configuration. Use `),xne=n(Qde,"A",{href:!0});var iga=s(xne);vit=r(iga,"from_pretrained()"),iga.forEach(t),Fit=r(Qde," to load the model weights."),Qde.forEach(t),Tit=i(P9),T(z6.$$.fragment,P9),P9.forEach(t),Mit=i(Ri),Kr=n(Ri,"DIV",{class:!0});var Pi=s(Kr);T(RR.$$.fragment,Pi),Eit=i(Pi),N9e=n(Pi,"P",{});var dga=s(N9e);Cit=r(dga,"Instantiate one of the base model classes of the library from a pretrained model."),dga.forEach(t),wit=i(Pi),Gn=n(Pi,"P",{});var B9=s(Gn);Ait=r(B9,"The model class to instantiate is selected based on the "),q9e=n(B9,"CODE",{});var mga=s(q9e);Lit=r(mga,"model_type"),mga.forEach(t),yit=r(B9,` property of the config object (either
passed as an argument or loaded from `),j9e=n(B9,"CODE",{});var cga=s(j9e);xit=r(cga,"pretrained_model_name_or_path"),cga.forEach(t),$it=r(B9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D9e=n(B9,"CODE",{});var fga=s(D9e);kit=r(fga,"pretrained_model_name_or_path"),fga.forEach(t),Sit=r(B9,":"),B9.forEach(t),Rit=i(Pi),te=n(Pi,"UL",{});var ne=s(te);Q6=n(ne,"LI",{});var gKe=s(Q6);G9e=n(gKe,"STRONG",{});var gga=s(G9e);Pit=r(gga,"albert"),gga.forEach(t),Bit=r(gKe," \u2014 "),$ne=n(gKe,"A",{href:!0});var hga=s($ne);Iit=r(hga,"FlaxAlbertModel"),hga.forEach(t),Nit=r(gKe," (ALBERT model)"),gKe.forEach(t),qit=i(ne),W6=n(ne,"LI",{});var hKe=s(W6);O9e=n(hKe,"STRONG",{});var uga=s(O9e);jit=r(uga,"bart"),uga.forEach(t),Dit=r(hKe," \u2014 "),kne=n(hKe,"A",{href:!0});var pga=s(kne);Git=r(pga,"FlaxBartModel"),pga.forEach(t),Oit=r(hKe," (BART model)"),hKe.forEach(t),Vit=i(ne),U6=n(ne,"LI",{});var uKe=s(U6);V9e=n(uKe,"STRONG",{});var _ga=s(V9e);Xit=r(_ga,"beit"),_ga.forEach(t),zit=r(uKe," \u2014 "),Sne=n(uKe,"A",{href:!0});var bga=s(Sne);Qit=r(bga,"FlaxBeitModel"),bga.forEach(t),Wit=r(uKe," (BEiT model)"),uKe.forEach(t),Uit=i(ne),H6=n(ne,"LI",{});var pKe=s(H6);X9e=n(pKe,"STRONG",{});var vga=s(X9e);Hit=r(vga,"bert"),vga.forEach(t),Jit=r(pKe," \u2014 "),Rne=n(pKe,"A",{href:!0});var Fga=s(Rne);Yit=r(Fga,"FlaxBertModel"),Fga.forEach(t),Kit=r(pKe," (BERT model)"),pKe.forEach(t),Zit=i(ne),J6=n(ne,"LI",{});var _Ke=s(J6);z9e=n(_Ke,"STRONG",{});var Tga=s(z9e);edt=r(Tga,"big_bird"),Tga.forEach(t),odt=r(_Ke," \u2014 "),Pne=n(_Ke,"A",{href:!0});var Mga=s(Pne);rdt=r(Mga,"FlaxBigBirdModel"),Mga.forEach(t),tdt=r(_Ke," (BigBird model)"),_Ke.forEach(t),adt=i(ne),Y6=n(ne,"LI",{});var bKe=s(Y6);Q9e=n(bKe,"STRONG",{});var Ega=s(Q9e);ndt=r(Ega,"blenderbot"),Ega.forEach(t),sdt=r(bKe," \u2014 "),Bne=n(bKe,"A",{href:!0});var Cga=s(Bne);ldt=r(Cga,"FlaxBlenderbotModel"),Cga.forEach(t),idt=r(bKe," (Blenderbot model)"),bKe.forEach(t),ddt=i(ne),K6=n(ne,"LI",{});var vKe=s(K6);W9e=n(vKe,"STRONG",{});var wga=s(W9e);mdt=r(wga,"blenderbot-small"),wga.forEach(t),cdt=r(vKe," \u2014 "),Ine=n(vKe,"A",{href:!0});var Aga=s(Ine);fdt=r(Aga,"FlaxBlenderbotSmallModel"),Aga.forEach(t),gdt=r(vKe," (BlenderbotSmall model)"),vKe.forEach(t),hdt=i(ne),Z6=n(ne,"LI",{});var FKe=s(Z6);U9e=n(FKe,"STRONG",{});var Lga=s(U9e);udt=r(Lga,"clip"),Lga.forEach(t),pdt=r(FKe," \u2014 "),Nne=n(FKe,"A",{href:!0});var yga=s(Nne);_dt=r(yga,"FlaxCLIPModel"),yga.forEach(t),bdt=r(FKe," (CLIP model)"),FKe.forEach(t),vdt=i(ne),e7=n(ne,"LI",{});var TKe=s(e7);H9e=n(TKe,"STRONG",{});var xga=s(H9e);Fdt=r(xga,"distilbert"),xga.forEach(t),Tdt=r(TKe," \u2014 "),qne=n(TKe,"A",{href:!0});var $ga=s(qne);Mdt=r($ga,"FlaxDistilBertModel"),$ga.forEach(t),Edt=r(TKe," (DistilBERT model)"),TKe.forEach(t),Cdt=i(ne),o7=n(ne,"LI",{});var MKe=s(o7);J9e=n(MKe,"STRONG",{});var kga=s(J9e);wdt=r(kga,"electra"),kga.forEach(t),Adt=r(MKe," \u2014 "),jne=n(MKe,"A",{href:!0});var Sga=s(jne);Ldt=r(Sga,"FlaxElectraModel"),Sga.forEach(t),ydt=r(MKe," (ELECTRA model)"),MKe.forEach(t),xdt=i(ne),r7=n(ne,"LI",{});var EKe=s(r7);Y9e=n(EKe,"STRONG",{});var Rga=s(Y9e);$dt=r(Rga,"gpt2"),Rga.forEach(t),kdt=r(EKe," \u2014 "),Dne=n(EKe,"A",{href:!0});var Pga=s(Dne);Sdt=r(Pga,"FlaxGPT2Model"),Pga.forEach(t),Rdt=r(EKe," (OpenAI GPT-2 model)"),EKe.forEach(t),Pdt=i(ne),t7=n(ne,"LI",{});var CKe=s(t7);K9e=n(CKe,"STRONG",{});var Bga=s(K9e);Bdt=r(Bga,"gpt_neo"),Bga.forEach(t),Idt=r(CKe," \u2014 "),Gne=n(CKe,"A",{href:!0});var Iga=s(Gne);Ndt=r(Iga,"FlaxGPTNeoModel"),Iga.forEach(t),qdt=r(CKe," (GPT Neo model)"),CKe.forEach(t),jdt=i(ne),a7=n(ne,"LI",{});var wKe=s(a7);Z9e=n(wKe,"STRONG",{});var Nga=s(Z9e);Ddt=r(Nga,"gptj"),Nga.forEach(t),Gdt=r(wKe," \u2014 "),One=n(wKe,"A",{href:!0});var qga=s(One);Odt=r(qga,"FlaxGPTJModel"),qga.forEach(t),Vdt=r(wKe," (GPT-J model)"),wKe.forEach(t),Xdt=i(ne),n7=n(ne,"LI",{});var AKe=s(n7);exe=n(AKe,"STRONG",{});var jga=s(exe);zdt=r(jga,"longt5"),jga.forEach(t),Qdt=r(AKe," \u2014 "),Vne=n(AKe,"A",{href:!0});var Dga=s(Vne);Wdt=r(Dga,"FlaxLongT5Model"),Dga.forEach(t),Udt=r(AKe," (LongT5 model)"),AKe.forEach(t),Hdt=i(ne),s7=n(ne,"LI",{});var LKe=s(s7);oxe=n(LKe,"STRONG",{});var Gga=s(oxe);Jdt=r(Gga,"marian"),Gga.forEach(t),Ydt=r(LKe," \u2014 "),Xne=n(LKe,"A",{href:!0});var Oga=s(Xne);Kdt=r(Oga,"FlaxMarianModel"),Oga.forEach(t),Zdt=r(LKe," (Marian model)"),LKe.forEach(t),emt=i(ne),l7=n(ne,"LI",{});var yKe=s(l7);rxe=n(yKe,"STRONG",{});var Vga=s(rxe);omt=r(Vga,"mbart"),Vga.forEach(t),rmt=r(yKe," \u2014 "),zne=n(yKe,"A",{href:!0});var Xga=s(zne);tmt=r(Xga,"FlaxMBartModel"),Xga.forEach(t),amt=r(yKe," (mBART model)"),yKe.forEach(t),nmt=i(ne),i7=n(ne,"LI",{});var xKe=s(i7);txe=n(xKe,"STRONG",{});var zga=s(txe);smt=r(zga,"mt5"),zga.forEach(t),lmt=r(xKe," \u2014 "),Qne=n(xKe,"A",{href:!0});var Qga=s(Qne);imt=r(Qga,"FlaxMT5Model"),Qga.forEach(t),dmt=r(xKe," (MT5 model)"),xKe.forEach(t),mmt=i(ne),d7=n(ne,"LI",{});var $Ke=s(d7);axe=n($Ke,"STRONG",{});var Wga=s(axe);cmt=r(Wga,"opt"),Wga.forEach(t),fmt=r($Ke," \u2014 "),Wne=n($Ke,"A",{href:!0});var Uga=s(Wne);gmt=r(Uga,"FlaxOPTModel"),Uga.forEach(t),hmt=r($Ke," (OPT model)"),$Ke.forEach(t),umt=i(ne),m7=n(ne,"LI",{});var kKe=s(m7);nxe=n(kKe,"STRONG",{});var Hga=s(nxe);pmt=r(Hga,"pegasus"),Hga.forEach(t),_mt=r(kKe," \u2014 "),Une=n(kKe,"A",{href:!0});var Jga=s(Une);bmt=r(Jga,"FlaxPegasusModel"),Jga.forEach(t),vmt=r(kKe," (Pegasus model)"),kKe.forEach(t),Fmt=i(ne),c7=n(ne,"LI",{});var SKe=s(c7);sxe=n(SKe,"STRONG",{});var Yga=s(sxe);Tmt=r(Yga,"roberta"),Yga.forEach(t),Mmt=r(SKe," \u2014 "),Hne=n(SKe,"A",{href:!0});var Kga=s(Hne);Emt=r(Kga,"FlaxRobertaModel"),Kga.forEach(t),Cmt=r(SKe," (RoBERTa model)"),SKe.forEach(t),wmt=i(ne),f7=n(ne,"LI",{});var RKe=s(f7);lxe=n(RKe,"STRONG",{});var Zga=s(lxe);Amt=r(Zga,"roformer"),Zga.forEach(t),Lmt=r(RKe," \u2014 "),Jne=n(RKe,"A",{href:!0});var eha=s(Jne);ymt=r(eha,"FlaxRoFormerModel"),eha.forEach(t),xmt=r(RKe," (RoFormer model)"),RKe.forEach(t),$mt=i(ne),g7=n(ne,"LI",{});var PKe=s(g7);ixe=n(PKe,"STRONG",{});var oha=s(ixe);kmt=r(oha,"t5"),oha.forEach(t),Smt=r(PKe," \u2014 "),Yne=n(PKe,"A",{href:!0});var rha=s(Yne);Rmt=r(rha,"FlaxT5Model"),rha.forEach(t),Pmt=r(PKe," (T5 model)"),PKe.forEach(t),Bmt=i(ne),h7=n(ne,"LI",{});var BKe=s(h7);dxe=n(BKe,"STRONG",{});var tha=s(dxe);Imt=r(tha,"vision-text-dual-encoder"),tha.forEach(t),Nmt=r(BKe," \u2014 "),Kne=n(BKe,"A",{href:!0});var aha=s(Kne);qmt=r(aha,"FlaxVisionTextDualEncoderModel"),aha.forEach(t),jmt=r(BKe," (VisionTextDualEncoder model)"),BKe.forEach(t),Dmt=i(ne),u7=n(ne,"LI",{});var IKe=s(u7);mxe=n(IKe,"STRONG",{});var nha=s(mxe);Gmt=r(nha,"vit"),nha.forEach(t),Omt=r(IKe," \u2014 "),Zne=n(IKe,"A",{href:!0});var sha=s(Zne);Vmt=r(sha,"FlaxViTModel"),sha.forEach(t),Xmt=r(IKe," (ViT model)"),IKe.forEach(t),zmt=i(ne),p7=n(ne,"LI",{});var NKe=s(p7);cxe=n(NKe,"STRONG",{});var lha=s(cxe);Qmt=r(lha,"wav2vec2"),lha.forEach(t),Wmt=r(NKe," \u2014 "),ese=n(NKe,"A",{href:!0});var iha=s(ese);Umt=r(iha,"FlaxWav2Vec2Model"),iha.forEach(t),Hmt=r(NKe," (Wav2Vec2 model)"),NKe.forEach(t),Jmt=i(ne),_7=n(ne,"LI",{});var qKe=s(_7);fxe=n(qKe,"STRONG",{});var dha=s(fxe);Ymt=r(dha,"xglm"),dha.forEach(t),Kmt=r(qKe," \u2014 "),ose=n(qKe,"A",{href:!0});var mha=s(ose);Zmt=r(mha,"FlaxXGLMModel"),mha.forEach(t),ect=r(qKe," (XGLM model)"),qKe.forEach(t),oct=i(ne),b7=n(ne,"LI",{});var jKe=s(b7);gxe=n(jKe,"STRONG",{});var cha=s(gxe);rct=r(cha,"xlm-roberta"),cha.forEach(t),tct=r(jKe," \u2014 "),rse=n(jKe,"A",{href:!0});var fha=s(rse);act=r(fha,"FlaxXLMRobertaModel"),fha.forEach(t),nct=r(jKe," (XLM-RoBERTa model)"),jKe.forEach(t),ne.forEach(t),sct=i(Pi),T(v7.$$.fragment,Pi),Pi.forEach(t),Ri.forEach(t),sro=i(c),Gc=n(c,"H2",{class:!0});var Tao=s(Gc);F7=n(Tao,"A",{id:!0,class:!0,href:!0});var gha=s(F7);hxe=n(gha,"SPAN",{});var hha=s(hxe);T(PR.$$.fragment,hha),hha.forEach(t),gha.forEach(t),lct=i(Tao),uxe=n(Tao,"SPAN",{});var uha=s(uxe);ict=r(uha,"FlaxAutoModelForCausalLM"),uha.forEach(t),Tao.forEach(t),lro=i(c),Er=n(c,"DIV",{class:!0});var Bi=s(Er);T(BR.$$.fragment,Bi),dct=i(Bi),Oc=n(Bi,"P",{});var Wde=s(Oc);mct=r(Wde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),tse=n(Wde,"A",{href:!0});var pha=s(tse);cct=r(pha,"from_pretrained()"),pha.forEach(t),fct=r(Wde," class method or the "),ase=n(Wde,"A",{href:!0});var _ha=s(ase);gct=r(_ha,"from_config()"),_ha.forEach(t),hct=r(Wde,` class
method.`),Wde.forEach(t),uct=i(Bi),IR=n(Bi,"P",{});var Mao=s(IR);pct=r(Mao,"This class cannot be instantiated directly using "),pxe=n(Mao,"CODE",{});var bha=s(pxe);_ct=r(bha,"__init__()"),bha.forEach(t),bct=r(Mao," (throws an error)."),Mao.forEach(t),vct=i(Bi),la=n(Bi,"DIV",{class:!0});var I9=s(la);T(NR.$$.fragment,I9),Fct=i(I9),_xe=n(I9,"P",{});var vha=s(_xe);Tct=r(vha,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),vha.forEach(t),Mct=i(I9),Vc=n(I9,"P",{});var Ude=s(Vc);Ect=r(Ude,`Note:
Loading a model from its configuration file does `),bxe=n(Ude,"STRONG",{});var Fha=s(bxe);Cct=r(Fha,"not"),Fha.forEach(t),wct=r(Ude,` load the model weights. It only affects the
model\u2019s configuration. Use `),nse=n(Ude,"A",{href:!0});var Tha=s(nse);Act=r(Tha,"from_pretrained()"),Tha.forEach(t),Lct=r(Ude," to load the model weights."),Ude.forEach(t),yct=i(I9),T(T7.$$.fragment,I9),I9.forEach(t),xct=i(Bi),Zr=n(Bi,"DIV",{class:!0});var Ii=s(Zr);T(qR.$$.fragment,Ii),$ct=i(Ii),vxe=n(Ii,"P",{});var Mha=s(vxe);kct=r(Mha,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Mha.forEach(t),Sct=i(Ii),On=n(Ii,"P",{});var N9=s(On);Rct=r(N9,"The model class to instantiate is selected based on the "),Fxe=n(N9,"CODE",{});var Eha=s(Fxe);Pct=r(Eha,"model_type"),Eha.forEach(t),Bct=r(N9,` property of the config object (either
passed as an argument or loaded from `),Txe=n(N9,"CODE",{});var Cha=s(Txe);Ict=r(Cha,"pretrained_model_name_or_path"),Cha.forEach(t),Nct=r(N9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mxe=n(N9,"CODE",{});var wha=s(Mxe);qct=r(wha,"pretrained_model_name_or_path"),wha.forEach(t),jct=r(N9,":"),N9.forEach(t),Dct=i(Ii),xe=n(Ii,"UL",{});var qe=s(xe);M7=n(qe,"LI",{});var DKe=s(M7);Exe=n(DKe,"STRONG",{});var Aha=s(Exe);Gct=r(Aha,"bart"),Aha.forEach(t),Oct=r(DKe," \u2014 "),sse=n(DKe,"A",{href:!0});var Lha=s(sse);Vct=r(Lha,"FlaxBartForCausalLM"),Lha.forEach(t),Xct=r(DKe," (BART model)"),DKe.forEach(t),zct=i(qe),E7=n(qe,"LI",{});var GKe=s(E7);Cxe=n(GKe,"STRONG",{});var yha=s(Cxe);Qct=r(yha,"bert"),yha.forEach(t),Wct=r(GKe," \u2014 "),lse=n(GKe,"A",{href:!0});var xha=s(lse);Uct=r(xha,"FlaxBertForCausalLM"),xha.forEach(t),Hct=r(GKe," (BERT model)"),GKe.forEach(t),Jct=i(qe),C7=n(qe,"LI",{});var OKe=s(C7);wxe=n(OKe,"STRONG",{});var $ha=s(wxe);Yct=r($ha,"big_bird"),$ha.forEach(t),Kct=r(OKe," \u2014 "),ise=n(OKe,"A",{href:!0});var kha=s(ise);Zct=r(kha,"FlaxBigBirdForCausalLM"),kha.forEach(t),eft=r(OKe," (BigBird model)"),OKe.forEach(t),oft=i(qe),w7=n(qe,"LI",{});var VKe=s(w7);Axe=n(VKe,"STRONG",{});var Sha=s(Axe);rft=r(Sha,"electra"),Sha.forEach(t),tft=r(VKe," \u2014 "),dse=n(VKe,"A",{href:!0});var Rha=s(dse);aft=r(Rha,"FlaxElectraForCausalLM"),Rha.forEach(t),nft=r(VKe," (ELECTRA model)"),VKe.forEach(t),sft=i(qe),A7=n(qe,"LI",{});var XKe=s(A7);Lxe=n(XKe,"STRONG",{});var Pha=s(Lxe);lft=r(Pha,"gpt2"),Pha.forEach(t),ift=r(XKe," \u2014 "),mse=n(XKe,"A",{href:!0});var Bha=s(mse);dft=r(Bha,"FlaxGPT2LMHeadModel"),Bha.forEach(t),mft=r(XKe," (OpenAI GPT-2 model)"),XKe.forEach(t),cft=i(qe),L7=n(qe,"LI",{});var zKe=s(L7);yxe=n(zKe,"STRONG",{});var Iha=s(yxe);fft=r(Iha,"gpt_neo"),Iha.forEach(t),gft=r(zKe," \u2014 "),cse=n(zKe,"A",{href:!0});var Nha=s(cse);hft=r(Nha,"FlaxGPTNeoForCausalLM"),Nha.forEach(t),uft=r(zKe," (GPT Neo model)"),zKe.forEach(t),pft=i(qe),y7=n(qe,"LI",{});var QKe=s(y7);xxe=n(QKe,"STRONG",{});var qha=s(xxe);_ft=r(qha,"gptj"),qha.forEach(t),bft=r(QKe," \u2014 "),fse=n(QKe,"A",{href:!0});var jha=s(fse);vft=r(jha,"FlaxGPTJForCausalLM"),jha.forEach(t),Fft=r(QKe," (GPT-J model)"),QKe.forEach(t),Tft=i(qe),x7=n(qe,"LI",{});var WKe=s(x7);$xe=n(WKe,"STRONG",{});var Dha=s($xe);Mft=r(Dha,"opt"),Dha.forEach(t),Eft=r(WKe," \u2014 "),gse=n(WKe,"A",{href:!0});var Gha=s(gse);Cft=r(Gha,"FlaxOPTForCausalLM"),Gha.forEach(t),wft=r(WKe," (OPT model)"),WKe.forEach(t),Aft=i(qe),$7=n(qe,"LI",{});var UKe=s($7);kxe=n(UKe,"STRONG",{});var Oha=s(kxe);Lft=r(Oha,"roberta"),Oha.forEach(t),yft=r(UKe," \u2014 "),hse=n(UKe,"A",{href:!0});var Vha=s(hse);xft=r(Vha,"FlaxRobertaForCausalLM"),Vha.forEach(t),$ft=r(UKe," (RoBERTa model)"),UKe.forEach(t),kft=i(qe),k7=n(qe,"LI",{});var HKe=s(k7);Sxe=n(HKe,"STRONG",{});var Xha=s(Sxe);Sft=r(Xha,"xglm"),Xha.forEach(t),Rft=r(HKe," \u2014 "),use=n(HKe,"A",{href:!0});var zha=s(use);Pft=r(zha,"FlaxXGLMForCausalLM"),zha.forEach(t),Bft=r(HKe," (XGLM model)"),HKe.forEach(t),qe.forEach(t),Ift=i(Ii),T(S7.$$.fragment,Ii),Ii.forEach(t),Bi.forEach(t),iro=i(c),Xc=n(c,"H2",{class:!0});var Eao=s(Xc);R7=n(Eao,"A",{id:!0,class:!0,href:!0});var Qha=s(R7);Rxe=n(Qha,"SPAN",{});var Wha=s(Rxe);T(jR.$$.fragment,Wha),Wha.forEach(t),Qha.forEach(t),Nft=i(Eao),Pxe=n(Eao,"SPAN",{});var Uha=s(Pxe);qft=r(Uha,"FlaxAutoModelForPreTraining"),Uha.forEach(t),Eao.forEach(t),dro=i(c),Cr=n(c,"DIV",{class:!0});var Ni=s(Cr);T(DR.$$.fragment,Ni),jft=i(Ni),zc=n(Ni,"P",{});var Hde=s(zc);Dft=r(Hde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),pse=n(Hde,"A",{href:!0});var Hha=s(pse);Gft=r(Hha,"from_pretrained()"),Hha.forEach(t),Oft=r(Hde," class method or the "),_se=n(Hde,"A",{href:!0});var Jha=s(_se);Vft=r(Jha,"from_config()"),Jha.forEach(t),Xft=r(Hde,` class
method.`),Hde.forEach(t),zft=i(Ni),GR=n(Ni,"P",{});var Cao=s(GR);Qft=r(Cao,"This class cannot be instantiated directly using "),Bxe=n(Cao,"CODE",{});var Yha=s(Bxe);Wft=r(Yha,"__init__()"),Yha.forEach(t),Uft=r(Cao," (throws an error)."),Cao.forEach(t),Hft=i(Ni),ia=n(Ni,"DIV",{class:!0});var q9=s(ia);T(OR.$$.fragment,q9),Jft=i(q9),Ixe=n(q9,"P",{});var Kha=s(Ixe);Yft=r(Kha,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Kha.forEach(t),Kft=i(q9),Qc=n(q9,"P",{});var Jde=s(Qc);Zft=r(Jde,`Note:
Loading a model from its configuration file does `),Nxe=n(Jde,"STRONG",{});var Zha=s(Nxe);egt=r(Zha,"not"),Zha.forEach(t),ogt=r(Jde,` load the model weights. It only affects the
model\u2019s configuration. Use `),bse=n(Jde,"A",{href:!0});var eua=s(bse);rgt=r(eua,"from_pretrained()"),eua.forEach(t),tgt=r(Jde," to load the model weights."),Jde.forEach(t),agt=i(q9),T(P7.$$.fragment,q9),q9.forEach(t),ngt=i(Ni),et=n(Ni,"DIV",{class:!0});var qi=s(et);T(VR.$$.fragment,qi),sgt=i(qi),qxe=n(qi,"P",{});var oua=s(qxe);lgt=r(oua,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),oua.forEach(t),igt=i(qi),Vn=n(qi,"P",{});var j9=s(Vn);dgt=r(j9,"The model class to instantiate is selected based on the "),jxe=n(j9,"CODE",{});var rua=s(jxe);mgt=r(rua,"model_type"),rua.forEach(t),cgt=r(j9,` property of the config object (either
passed as an argument or loaded from `),Dxe=n(j9,"CODE",{});var tua=s(Dxe);fgt=r(tua,"pretrained_model_name_or_path"),tua.forEach(t),ggt=r(j9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gxe=n(j9,"CODE",{});var aua=s(Gxe);hgt=r(aua,"pretrained_model_name_or_path"),aua.forEach(t),ugt=r(j9,":"),j9.forEach(t),pgt=i(qi),Ee=n(qi,"UL",{});var we=s(Ee);B7=n(we,"LI",{});var JKe=s(B7);Oxe=n(JKe,"STRONG",{});var nua=s(Oxe);_gt=r(nua,"albert"),nua.forEach(t),bgt=r(JKe," \u2014 "),vse=n(JKe,"A",{href:!0});var sua=s(vse);vgt=r(sua,"FlaxAlbertForPreTraining"),sua.forEach(t),Fgt=r(JKe," (ALBERT model)"),JKe.forEach(t),Tgt=i(we),I7=n(we,"LI",{});var YKe=s(I7);Vxe=n(YKe,"STRONG",{});var lua=s(Vxe);Mgt=r(lua,"bart"),lua.forEach(t),Egt=r(YKe," \u2014 "),Fse=n(YKe,"A",{href:!0});var iua=s(Fse);Cgt=r(iua,"FlaxBartForConditionalGeneration"),iua.forEach(t),wgt=r(YKe," (BART model)"),YKe.forEach(t),Agt=i(we),N7=n(we,"LI",{});var KKe=s(N7);Xxe=n(KKe,"STRONG",{});var dua=s(Xxe);Lgt=r(dua,"bert"),dua.forEach(t),ygt=r(KKe," \u2014 "),Tse=n(KKe,"A",{href:!0});var mua=s(Tse);xgt=r(mua,"FlaxBertForPreTraining"),mua.forEach(t),$gt=r(KKe," (BERT model)"),KKe.forEach(t),kgt=i(we),q7=n(we,"LI",{});var ZKe=s(q7);zxe=n(ZKe,"STRONG",{});var cua=s(zxe);Sgt=r(cua,"big_bird"),cua.forEach(t),Rgt=r(ZKe," \u2014 "),Mse=n(ZKe,"A",{href:!0});var fua=s(Mse);Pgt=r(fua,"FlaxBigBirdForPreTraining"),fua.forEach(t),Bgt=r(ZKe," (BigBird model)"),ZKe.forEach(t),Igt=i(we),j7=n(we,"LI",{});var eZe=s(j7);Qxe=n(eZe,"STRONG",{});var gua=s(Qxe);Ngt=r(gua,"electra"),gua.forEach(t),qgt=r(eZe," \u2014 "),Ese=n(eZe,"A",{href:!0});var hua=s(Ese);jgt=r(hua,"FlaxElectraForPreTraining"),hua.forEach(t),Dgt=r(eZe," (ELECTRA model)"),eZe.forEach(t),Ggt=i(we),D7=n(we,"LI",{});var oZe=s(D7);Wxe=n(oZe,"STRONG",{});var uua=s(Wxe);Ogt=r(uua,"longt5"),uua.forEach(t),Vgt=r(oZe," \u2014 "),Cse=n(oZe,"A",{href:!0});var pua=s(Cse);Xgt=r(pua,"FlaxLongT5ForConditionalGeneration"),pua.forEach(t),zgt=r(oZe," (LongT5 model)"),oZe.forEach(t),Qgt=i(we),G7=n(we,"LI",{});var rZe=s(G7);Uxe=n(rZe,"STRONG",{});var _ua=s(Uxe);Wgt=r(_ua,"mbart"),_ua.forEach(t),Ugt=r(rZe," \u2014 "),wse=n(rZe,"A",{href:!0});var bua=s(wse);Hgt=r(bua,"FlaxMBartForConditionalGeneration"),bua.forEach(t),Jgt=r(rZe," (mBART model)"),rZe.forEach(t),Ygt=i(we),O7=n(we,"LI",{});var tZe=s(O7);Hxe=n(tZe,"STRONG",{});var vua=s(Hxe);Kgt=r(vua,"mt5"),vua.forEach(t),Zgt=r(tZe," \u2014 "),Ase=n(tZe,"A",{href:!0});var Fua=s(Ase);eht=r(Fua,"FlaxMT5ForConditionalGeneration"),Fua.forEach(t),oht=r(tZe," (MT5 model)"),tZe.forEach(t),rht=i(we),V7=n(we,"LI",{});var aZe=s(V7);Jxe=n(aZe,"STRONG",{});var Tua=s(Jxe);tht=r(Tua,"roberta"),Tua.forEach(t),aht=r(aZe," \u2014 "),Lse=n(aZe,"A",{href:!0});var Mua=s(Lse);nht=r(Mua,"FlaxRobertaForMaskedLM"),Mua.forEach(t),sht=r(aZe," (RoBERTa model)"),aZe.forEach(t),lht=i(we),X7=n(we,"LI",{});var nZe=s(X7);Yxe=n(nZe,"STRONG",{});var Eua=s(Yxe);iht=r(Eua,"roformer"),Eua.forEach(t),dht=r(nZe," \u2014 "),yse=n(nZe,"A",{href:!0});var Cua=s(yse);mht=r(Cua,"FlaxRoFormerForMaskedLM"),Cua.forEach(t),cht=r(nZe," (RoFormer model)"),nZe.forEach(t),fht=i(we),z7=n(we,"LI",{});var sZe=s(z7);Kxe=n(sZe,"STRONG",{});var wua=s(Kxe);ght=r(wua,"t5"),wua.forEach(t),hht=r(sZe," \u2014 "),xse=n(sZe,"A",{href:!0});var Aua=s(xse);uht=r(Aua,"FlaxT5ForConditionalGeneration"),Aua.forEach(t),pht=r(sZe," (T5 model)"),sZe.forEach(t),_ht=i(we),Q7=n(we,"LI",{});var lZe=s(Q7);Zxe=n(lZe,"STRONG",{});var Lua=s(Zxe);bht=r(Lua,"wav2vec2"),Lua.forEach(t),vht=r(lZe," \u2014 "),$se=n(lZe,"A",{href:!0});var yua=s($se);Fht=r(yua,"FlaxWav2Vec2ForPreTraining"),yua.forEach(t),Tht=r(lZe," (Wav2Vec2 model)"),lZe.forEach(t),Mht=i(we),W7=n(we,"LI",{});var iZe=s(W7);e$e=n(iZe,"STRONG",{});var xua=s(e$e);Eht=r(xua,"xlm-roberta"),xua.forEach(t),Cht=r(iZe," \u2014 "),kse=n(iZe,"A",{href:!0});var $ua=s(kse);wht=r($ua,"FlaxXLMRobertaForMaskedLM"),$ua.forEach(t),Aht=r(iZe," (XLM-RoBERTa model)"),iZe.forEach(t),we.forEach(t),Lht=i(qi),T(U7.$$.fragment,qi),qi.forEach(t),Ni.forEach(t),mro=i(c),Wc=n(c,"H2",{class:!0});var wao=s(Wc);H7=n(wao,"A",{id:!0,class:!0,href:!0});var kua=s(H7);o$e=n(kua,"SPAN",{});var Sua=s(o$e);T(XR.$$.fragment,Sua),Sua.forEach(t),kua.forEach(t),yht=i(wao),r$e=n(wao,"SPAN",{});var Rua=s(r$e);xht=r(Rua,"FlaxAutoModelForMaskedLM"),Rua.forEach(t),wao.forEach(t),cro=i(c),wr=n(c,"DIV",{class:!0});var ji=s(wr);T(zR.$$.fragment,ji),$ht=i(ji),Uc=n(ji,"P",{});var Yde=s(Uc);kht=r(Yde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Sse=n(Yde,"A",{href:!0});var Pua=s(Sse);Sht=r(Pua,"from_pretrained()"),Pua.forEach(t),Rht=r(Yde," class method or the "),Rse=n(Yde,"A",{href:!0});var Bua=s(Rse);Pht=r(Bua,"from_config()"),Bua.forEach(t),Bht=r(Yde,` class
method.`),Yde.forEach(t),Iht=i(ji),QR=n(ji,"P",{});var Aao=s(QR);Nht=r(Aao,"This class cannot be instantiated directly using "),t$e=n(Aao,"CODE",{});var Iua=s(t$e);qht=r(Iua,"__init__()"),Iua.forEach(t),jht=r(Aao," (throws an error)."),Aao.forEach(t),Dht=i(ji),da=n(ji,"DIV",{class:!0});var D9=s(da);T(WR.$$.fragment,D9),Ght=i(D9),a$e=n(D9,"P",{});var Nua=s(a$e);Oht=r(Nua,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Nua.forEach(t),Vht=i(D9),Hc=n(D9,"P",{});var Kde=s(Hc);Xht=r(Kde,`Note:
Loading a model from its configuration file does `),n$e=n(Kde,"STRONG",{});var qua=s(n$e);zht=r(qua,"not"),qua.forEach(t),Qht=r(Kde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Pse=n(Kde,"A",{href:!0});var jua=s(Pse);Wht=r(jua,"from_pretrained()"),jua.forEach(t),Uht=r(Kde," to load the model weights."),Kde.forEach(t),Hht=i(D9),T(J7.$$.fragment,D9),D9.forEach(t),Jht=i(ji),ot=n(ji,"DIV",{class:!0});var Di=s(ot);T(UR.$$.fragment,Di),Yht=i(Di),s$e=n(Di,"P",{});var Dua=s(s$e);Kht=r(Dua,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Dua.forEach(t),Zht=i(Di),Xn=n(Di,"P",{});var G9=s(Xn);eut=r(G9,"The model class to instantiate is selected based on the "),l$e=n(G9,"CODE",{});var Gua=s(l$e);out=r(Gua,"model_type"),Gua.forEach(t),rut=r(G9,` property of the config object (either
passed as an argument or loaded from `),i$e=n(G9,"CODE",{});var Oua=s(i$e);tut=r(Oua,"pretrained_model_name_or_path"),Oua.forEach(t),aut=r(G9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d$e=n(G9,"CODE",{});var Vua=s(d$e);nut=r(Vua,"pretrained_model_name_or_path"),Vua.forEach(t),sut=r(G9,":"),G9.forEach(t),lut=i(Di),$e=n(Di,"UL",{});var je=s($e);Y7=n(je,"LI",{});var dZe=s(Y7);m$e=n(dZe,"STRONG",{});var Xua=s(m$e);iut=r(Xua,"albert"),Xua.forEach(t),dut=r(dZe," \u2014 "),Bse=n(dZe,"A",{href:!0});var zua=s(Bse);mut=r(zua,"FlaxAlbertForMaskedLM"),zua.forEach(t),cut=r(dZe," (ALBERT model)"),dZe.forEach(t),fut=i(je),K7=n(je,"LI",{});var mZe=s(K7);c$e=n(mZe,"STRONG",{});var Qua=s(c$e);gut=r(Qua,"bart"),Qua.forEach(t),hut=r(mZe," \u2014 "),Ise=n(mZe,"A",{href:!0});var Wua=s(Ise);uut=r(Wua,"FlaxBartForConditionalGeneration"),Wua.forEach(t),put=r(mZe," (BART model)"),mZe.forEach(t),_ut=i(je),Z7=n(je,"LI",{});var cZe=s(Z7);f$e=n(cZe,"STRONG",{});var Uua=s(f$e);but=r(Uua,"bert"),Uua.forEach(t),vut=r(cZe," \u2014 "),Nse=n(cZe,"A",{href:!0});var Hua=s(Nse);Fut=r(Hua,"FlaxBertForMaskedLM"),Hua.forEach(t),Tut=r(cZe," (BERT model)"),cZe.forEach(t),Mut=i(je),eL=n(je,"LI",{});var fZe=s(eL);g$e=n(fZe,"STRONG",{});var Jua=s(g$e);Eut=r(Jua,"big_bird"),Jua.forEach(t),Cut=r(fZe," \u2014 "),qse=n(fZe,"A",{href:!0});var Yua=s(qse);wut=r(Yua,"FlaxBigBirdForMaskedLM"),Yua.forEach(t),Aut=r(fZe," (BigBird model)"),fZe.forEach(t),Lut=i(je),oL=n(je,"LI",{});var gZe=s(oL);h$e=n(gZe,"STRONG",{});var Kua=s(h$e);yut=r(Kua,"distilbert"),Kua.forEach(t),xut=r(gZe," \u2014 "),jse=n(gZe,"A",{href:!0});var Zua=s(jse);$ut=r(Zua,"FlaxDistilBertForMaskedLM"),Zua.forEach(t),kut=r(gZe," (DistilBERT model)"),gZe.forEach(t),Sut=i(je),rL=n(je,"LI",{});var hZe=s(rL);u$e=n(hZe,"STRONG",{});var epa=s(u$e);Rut=r(epa,"electra"),epa.forEach(t),Put=r(hZe," \u2014 "),Dse=n(hZe,"A",{href:!0});var opa=s(Dse);But=r(opa,"FlaxElectraForMaskedLM"),opa.forEach(t),Iut=r(hZe," (ELECTRA model)"),hZe.forEach(t),Nut=i(je),tL=n(je,"LI",{});var uZe=s(tL);p$e=n(uZe,"STRONG",{});var rpa=s(p$e);qut=r(rpa,"mbart"),rpa.forEach(t),jut=r(uZe," \u2014 "),Gse=n(uZe,"A",{href:!0});var tpa=s(Gse);Dut=r(tpa,"FlaxMBartForConditionalGeneration"),tpa.forEach(t),Gut=r(uZe," (mBART model)"),uZe.forEach(t),Out=i(je),aL=n(je,"LI",{});var pZe=s(aL);_$e=n(pZe,"STRONG",{});var apa=s(_$e);Vut=r(apa,"roberta"),apa.forEach(t),Xut=r(pZe," \u2014 "),Ose=n(pZe,"A",{href:!0});var npa=s(Ose);zut=r(npa,"FlaxRobertaForMaskedLM"),npa.forEach(t),Qut=r(pZe," (RoBERTa model)"),pZe.forEach(t),Wut=i(je),nL=n(je,"LI",{});var _Ze=s(nL);b$e=n(_Ze,"STRONG",{});var spa=s(b$e);Uut=r(spa,"roformer"),spa.forEach(t),Hut=r(_Ze," \u2014 "),Vse=n(_Ze,"A",{href:!0});var lpa=s(Vse);Jut=r(lpa,"FlaxRoFormerForMaskedLM"),lpa.forEach(t),Yut=r(_Ze," (RoFormer model)"),_Ze.forEach(t),Kut=i(je),sL=n(je,"LI",{});var bZe=s(sL);v$e=n(bZe,"STRONG",{});var ipa=s(v$e);Zut=r(ipa,"xlm-roberta"),ipa.forEach(t),ept=r(bZe," \u2014 "),Xse=n(bZe,"A",{href:!0});var dpa=s(Xse);opt=r(dpa,"FlaxXLMRobertaForMaskedLM"),dpa.forEach(t),rpt=r(bZe," (XLM-RoBERTa model)"),bZe.forEach(t),je.forEach(t),tpt=i(Di),T(lL.$$.fragment,Di),Di.forEach(t),ji.forEach(t),fro=i(c),Jc=n(c,"H2",{class:!0});var Lao=s(Jc);iL=n(Lao,"A",{id:!0,class:!0,href:!0});var mpa=s(iL);F$e=n(mpa,"SPAN",{});var cpa=s(F$e);T(HR.$$.fragment,cpa),cpa.forEach(t),mpa.forEach(t),apt=i(Lao),T$e=n(Lao,"SPAN",{});var fpa=s(T$e);npt=r(fpa,"FlaxAutoModelForSeq2SeqLM"),fpa.forEach(t),Lao.forEach(t),gro=i(c),Ar=n(c,"DIV",{class:!0});var Gi=s(Ar);T(JR.$$.fragment,Gi),spt=i(Gi),Yc=n(Gi,"P",{});var Zde=s(Yc);lpt=r(Zde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),zse=n(Zde,"A",{href:!0});var gpa=s(zse);ipt=r(gpa,"from_pretrained()"),gpa.forEach(t),dpt=r(Zde," class method or the "),Qse=n(Zde,"A",{href:!0});var hpa=s(Qse);mpt=r(hpa,"from_config()"),hpa.forEach(t),cpt=r(Zde,` class
method.`),Zde.forEach(t),fpt=i(Gi),YR=n(Gi,"P",{});var yao=s(YR);gpt=r(yao,"This class cannot be instantiated directly using "),M$e=n(yao,"CODE",{});var upa=s(M$e);hpt=r(upa,"__init__()"),upa.forEach(t),upt=r(yao," (throws an error)."),yao.forEach(t),ppt=i(Gi),ma=n(Gi,"DIV",{class:!0});var O9=s(ma);T(KR.$$.fragment,O9),_pt=i(O9),E$e=n(O9,"P",{});var ppa=s(E$e);bpt=r(ppa,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),ppa.forEach(t),vpt=i(O9),Kc=n(O9,"P",{});var eme=s(Kc);Fpt=r(eme,`Note:
Loading a model from its configuration file does `),C$e=n(eme,"STRONG",{});var _pa=s(C$e);Tpt=r(_pa,"not"),_pa.forEach(t),Mpt=r(eme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Wse=n(eme,"A",{href:!0});var bpa=s(Wse);Ept=r(bpa,"from_pretrained()"),bpa.forEach(t),Cpt=r(eme," to load the model weights."),eme.forEach(t),wpt=i(O9),T(dL.$$.fragment,O9),O9.forEach(t),Apt=i(Gi),rt=n(Gi,"DIV",{class:!0});var Oi=s(rt);T(ZR.$$.fragment,Oi),Lpt=i(Oi),w$e=n(Oi,"P",{});var vpa=s(w$e);ypt=r(vpa,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),vpa.forEach(t),xpt=i(Oi),zn=n(Oi,"P",{});var V9=s(zn);$pt=r(V9,"The model class to instantiate is selected based on the "),A$e=n(V9,"CODE",{});var Fpa=s(A$e);kpt=r(Fpa,"model_type"),Fpa.forEach(t),Spt=r(V9,` property of the config object (either
passed as an argument or loaded from `),L$e=n(V9,"CODE",{});var Tpa=s(L$e);Rpt=r(Tpa,"pretrained_model_name_or_path"),Tpa.forEach(t),Ppt=r(V9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y$e=n(V9,"CODE",{});var Mpa=s(y$e);Bpt=r(Mpa,"pretrained_model_name_or_path"),Mpa.forEach(t),Ipt=r(V9,":"),V9.forEach(t),Npt=i(Oi),ke=n(Oi,"UL",{});var De=s(ke);mL=n(De,"LI",{});var vZe=s(mL);x$e=n(vZe,"STRONG",{});var Epa=s(x$e);qpt=r(Epa,"bart"),Epa.forEach(t),jpt=r(vZe," \u2014 "),Use=n(vZe,"A",{href:!0});var Cpa=s(Use);Dpt=r(Cpa,"FlaxBartForConditionalGeneration"),Cpa.forEach(t),Gpt=r(vZe," (BART model)"),vZe.forEach(t),Opt=i(De),cL=n(De,"LI",{});var FZe=s(cL);$$e=n(FZe,"STRONG",{});var wpa=s($$e);Vpt=r(wpa,"blenderbot"),wpa.forEach(t),Xpt=r(FZe," \u2014 "),Hse=n(FZe,"A",{href:!0});var Apa=s(Hse);zpt=r(Apa,"FlaxBlenderbotForConditionalGeneration"),Apa.forEach(t),Qpt=r(FZe," (Blenderbot model)"),FZe.forEach(t),Wpt=i(De),fL=n(De,"LI",{});var TZe=s(fL);k$e=n(TZe,"STRONG",{});var Lpa=s(k$e);Upt=r(Lpa,"blenderbot-small"),Lpa.forEach(t),Hpt=r(TZe," \u2014 "),Jse=n(TZe,"A",{href:!0});var ypa=s(Jse);Jpt=r(ypa,"FlaxBlenderbotSmallForConditionalGeneration"),ypa.forEach(t),Ypt=r(TZe," (BlenderbotSmall model)"),TZe.forEach(t),Kpt=i(De),gL=n(De,"LI",{});var MZe=s(gL);S$e=n(MZe,"STRONG",{});var xpa=s(S$e);Zpt=r(xpa,"encoder-decoder"),xpa.forEach(t),e_t=r(MZe," \u2014 "),Yse=n(MZe,"A",{href:!0});var $pa=s(Yse);o_t=r($pa,"FlaxEncoderDecoderModel"),$pa.forEach(t),r_t=r(MZe," (Encoder decoder model)"),MZe.forEach(t),t_t=i(De),hL=n(De,"LI",{});var EZe=s(hL);R$e=n(EZe,"STRONG",{});var kpa=s(R$e);a_t=r(kpa,"longt5"),kpa.forEach(t),n_t=r(EZe," \u2014 "),Kse=n(EZe,"A",{href:!0});var Spa=s(Kse);s_t=r(Spa,"FlaxLongT5ForConditionalGeneration"),Spa.forEach(t),l_t=r(EZe," (LongT5 model)"),EZe.forEach(t),i_t=i(De),uL=n(De,"LI",{});var CZe=s(uL);P$e=n(CZe,"STRONG",{});var Rpa=s(P$e);d_t=r(Rpa,"marian"),Rpa.forEach(t),m_t=r(CZe," \u2014 "),Zse=n(CZe,"A",{href:!0});var Ppa=s(Zse);c_t=r(Ppa,"FlaxMarianMTModel"),Ppa.forEach(t),f_t=r(CZe," (Marian model)"),CZe.forEach(t),g_t=i(De),pL=n(De,"LI",{});var wZe=s(pL);B$e=n(wZe,"STRONG",{});var Bpa=s(B$e);h_t=r(Bpa,"mbart"),Bpa.forEach(t),u_t=r(wZe," \u2014 "),ele=n(wZe,"A",{href:!0});var Ipa=s(ele);p_t=r(Ipa,"FlaxMBartForConditionalGeneration"),Ipa.forEach(t),__t=r(wZe," (mBART model)"),wZe.forEach(t),b_t=i(De),_L=n(De,"LI",{});var AZe=s(_L);I$e=n(AZe,"STRONG",{});var Npa=s(I$e);v_t=r(Npa,"mt5"),Npa.forEach(t),F_t=r(AZe," \u2014 "),ole=n(AZe,"A",{href:!0});var qpa=s(ole);T_t=r(qpa,"FlaxMT5ForConditionalGeneration"),qpa.forEach(t),M_t=r(AZe," (MT5 model)"),AZe.forEach(t),E_t=i(De),bL=n(De,"LI",{});var LZe=s(bL);N$e=n(LZe,"STRONG",{});var jpa=s(N$e);C_t=r(jpa,"pegasus"),jpa.forEach(t),w_t=r(LZe," \u2014 "),rle=n(LZe,"A",{href:!0});var Dpa=s(rle);A_t=r(Dpa,"FlaxPegasusForConditionalGeneration"),Dpa.forEach(t),L_t=r(LZe," (Pegasus model)"),LZe.forEach(t),y_t=i(De),vL=n(De,"LI",{});var yZe=s(vL);q$e=n(yZe,"STRONG",{});var Gpa=s(q$e);x_t=r(Gpa,"t5"),Gpa.forEach(t),$_t=r(yZe," \u2014 "),tle=n(yZe,"A",{href:!0});var Opa=s(tle);k_t=r(Opa,"FlaxT5ForConditionalGeneration"),Opa.forEach(t),S_t=r(yZe," (T5 model)"),yZe.forEach(t),De.forEach(t),R_t=i(Oi),T(FL.$$.fragment,Oi),Oi.forEach(t),Gi.forEach(t),hro=i(c),Zc=n(c,"H2",{class:!0});var xao=s(Zc);TL=n(xao,"A",{id:!0,class:!0,href:!0});var Vpa=s(TL);j$e=n(Vpa,"SPAN",{});var Xpa=s(j$e);T(eP.$$.fragment,Xpa),Xpa.forEach(t),Vpa.forEach(t),P_t=i(xao),D$e=n(xao,"SPAN",{});var zpa=s(D$e);B_t=r(zpa,"FlaxAutoModelForSequenceClassification"),zpa.forEach(t),xao.forEach(t),uro=i(c),Lr=n(c,"DIV",{class:!0});var Vi=s(Lr);T(oP.$$.fragment,Vi),I_t=i(Vi),ef=n(Vi,"P",{});var ome=s(ef);N_t=r(ome,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),ale=n(ome,"A",{href:!0});var Qpa=s(ale);q_t=r(Qpa,"from_pretrained()"),Qpa.forEach(t),j_t=r(ome," class method or the "),nle=n(ome,"A",{href:!0});var Wpa=s(nle);D_t=r(Wpa,"from_config()"),Wpa.forEach(t),G_t=r(ome,` class
method.`),ome.forEach(t),O_t=i(Vi),rP=n(Vi,"P",{});var $ao=s(rP);V_t=r($ao,"This class cannot be instantiated directly using "),G$e=n($ao,"CODE",{});var Upa=s(G$e);X_t=r(Upa,"__init__()"),Upa.forEach(t),z_t=r($ao," (throws an error)."),$ao.forEach(t),Q_t=i(Vi),ca=n(Vi,"DIV",{class:!0});var X9=s(ca);T(tP.$$.fragment,X9),W_t=i(X9),O$e=n(X9,"P",{});var Hpa=s(O$e);U_t=r(Hpa,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Hpa.forEach(t),H_t=i(X9),of=n(X9,"P",{});var rme=s(of);J_t=r(rme,`Note:
Loading a model from its configuration file does `),V$e=n(rme,"STRONG",{});var Jpa=s(V$e);Y_t=r(Jpa,"not"),Jpa.forEach(t),K_t=r(rme,` load the model weights. It only affects the
model\u2019s configuration. Use `),sle=n(rme,"A",{href:!0});var Ypa=s(sle);Z_t=r(Ypa,"from_pretrained()"),Ypa.forEach(t),e1t=r(rme," to load the model weights."),rme.forEach(t),o1t=i(X9),T(ML.$$.fragment,X9),X9.forEach(t),r1t=i(Vi),tt=n(Vi,"DIV",{class:!0});var Xi=s(tt);T(aP.$$.fragment,Xi),t1t=i(Xi),X$e=n(Xi,"P",{});var Kpa=s(X$e);a1t=r(Kpa,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Kpa.forEach(t),n1t=i(Xi),Qn=n(Xi,"P",{});var z9=s(Qn);s1t=r(z9,"The model class to instantiate is selected based on the "),z$e=n(z9,"CODE",{});var Zpa=s(z$e);l1t=r(Zpa,"model_type"),Zpa.forEach(t),i1t=r(z9,` property of the config object (either
passed as an argument or loaded from `),Q$e=n(z9,"CODE",{});var e_a=s(Q$e);d1t=r(e_a,"pretrained_model_name_or_path"),e_a.forEach(t),m1t=r(z9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W$e=n(z9,"CODE",{});var o_a=s(W$e);c1t=r(o_a,"pretrained_model_name_or_path"),o_a.forEach(t),f1t=r(z9,":"),z9.forEach(t),g1t=i(Xi),Se=n(Xi,"UL",{});var Ge=s(Se);EL=n(Ge,"LI",{});var xZe=s(EL);U$e=n(xZe,"STRONG",{});var r_a=s(U$e);h1t=r(r_a,"albert"),r_a.forEach(t),u1t=r(xZe," \u2014 "),lle=n(xZe,"A",{href:!0});var t_a=s(lle);p1t=r(t_a,"FlaxAlbertForSequenceClassification"),t_a.forEach(t),_1t=r(xZe," (ALBERT model)"),xZe.forEach(t),b1t=i(Ge),CL=n(Ge,"LI",{});var $Ze=s(CL);H$e=n($Ze,"STRONG",{});var a_a=s(H$e);v1t=r(a_a,"bart"),a_a.forEach(t),F1t=r($Ze," \u2014 "),ile=n($Ze,"A",{href:!0});var n_a=s(ile);T1t=r(n_a,"FlaxBartForSequenceClassification"),n_a.forEach(t),M1t=r($Ze," (BART model)"),$Ze.forEach(t),E1t=i(Ge),wL=n(Ge,"LI",{});var kZe=s(wL);J$e=n(kZe,"STRONG",{});var s_a=s(J$e);C1t=r(s_a,"bert"),s_a.forEach(t),w1t=r(kZe," \u2014 "),dle=n(kZe,"A",{href:!0});var l_a=s(dle);A1t=r(l_a,"FlaxBertForSequenceClassification"),l_a.forEach(t),L1t=r(kZe," (BERT model)"),kZe.forEach(t),y1t=i(Ge),AL=n(Ge,"LI",{});var SZe=s(AL);Y$e=n(SZe,"STRONG",{});var i_a=s(Y$e);x1t=r(i_a,"big_bird"),i_a.forEach(t),$1t=r(SZe," \u2014 "),mle=n(SZe,"A",{href:!0});var d_a=s(mle);k1t=r(d_a,"FlaxBigBirdForSequenceClassification"),d_a.forEach(t),S1t=r(SZe," (BigBird model)"),SZe.forEach(t),R1t=i(Ge),LL=n(Ge,"LI",{});var RZe=s(LL);K$e=n(RZe,"STRONG",{});var m_a=s(K$e);P1t=r(m_a,"distilbert"),m_a.forEach(t),B1t=r(RZe," \u2014 "),cle=n(RZe,"A",{href:!0});var c_a=s(cle);I1t=r(c_a,"FlaxDistilBertForSequenceClassification"),c_a.forEach(t),N1t=r(RZe," (DistilBERT model)"),RZe.forEach(t),q1t=i(Ge),yL=n(Ge,"LI",{});var PZe=s(yL);Z$e=n(PZe,"STRONG",{});var f_a=s(Z$e);j1t=r(f_a,"electra"),f_a.forEach(t),D1t=r(PZe," \u2014 "),fle=n(PZe,"A",{href:!0});var g_a=s(fle);G1t=r(g_a,"FlaxElectraForSequenceClassification"),g_a.forEach(t),O1t=r(PZe," (ELECTRA model)"),PZe.forEach(t),V1t=i(Ge),xL=n(Ge,"LI",{});var BZe=s(xL);eke=n(BZe,"STRONG",{});var h_a=s(eke);X1t=r(h_a,"mbart"),h_a.forEach(t),z1t=r(BZe," \u2014 "),gle=n(BZe,"A",{href:!0});var u_a=s(gle);Q1t=r(u_a,"FlaxMBartForSequenceClassification"),u_a.forEach(t),W1t=r(BZe," (mBART model)"),BZe.forEach(t),U1t=i(Ge),$L=n(Ge,"LI",{});var IZe=s($L);oke=n(IZe,"STRONG",{});var p_a=s(oke);H1t=r(p_a,"roberta"),p_a.forEach(t),J1t=r(IZe," \u2014 "),hle=n(IZe,"A",{href:!0});var __a=s(hle);Y1t=r(__a,"FlaxRobertaForSequenceClassification"),__a.forEach(t),K1t=r(IZe," (RoBERTa model)"),IZe.forEach(t),Z1t=i(Ge),kL=n(Ge,"LI",{});var NZe=s(kL);rke=n(NZe,"STRONG",{});var b_a=s(rke);e2t=r(b_a,"roformer"),b_a.forEach(t),o2t=r(NZe," \u2014 "),ule=n(NZe,"A",{href:!0});var v_a=s(ule);r2t=r(v_a,"FlaxRoFormerForSequenceClassification"),v_a.forEach(t),t2t=r(NZe," (RoFormer model)"),NZe.forEach(t),a2t=i(Ge),SL=n(Ge,"LI",{});var qZe=s(SL);tke=n(qZe,"STRONG",{});var F_a=s(tke);n2t=r(F_a,"xlm-roberta"),F_a.forEach(t),s2t=r(qZe," \u2014 "),ple=n(qZe,"A",{href:!0});var T_a=s(ple);l2t=r(T_a,"FlaxXLMRobertaForSequenceClassification"),T_a.forEach(t),i2t=r(qZe," (XLM-RoBERTa model)"),qZe.forEach(t),Ge.forEach(t),d2t=i(Xi),T(RL.$$.fragment,Xi),Xi.forEach(t),Vi.forEach(t),pro=i(c),rf=n(c,"H2",{class:!0});var kao=s(rf);PL=n(kao,"A",{id:!0,class:!0,href:!0});var M_a=s(PL);ake=n(M_a,"SPAN",{});var E_a=s(ake);T(nP.$$.fragment,E_a),E_a.forEach(t),M_a.forEach(t),m2t=i(kao),nke=n(kao,"SPAN",{});var C_a=s(nke);c2t=r(C_a,"FlaxAutoModelForQuestionAnswering"),C_a.forEach(t),kao.forEach(t),_ro=i(c),yr=n(c,"DIV",{class:!0});var zi=s(yr);T(sP.$$.fragment,zi),f2t=i(zi),tf=n(zi,"P",{});var tme=s(tf);g2t=r(tme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),_le=n(tme,"A",{href:!0});var w_a=s(_le);h2t=r(w_a,"from_pretrained()"),w_a.forEach(t),u2t=r(tme," class method or the "),ble=n(tme,"A",{href:!0});var A_a=s(ble);p2t=r(A_a,"from_config()"),A_a.forEach(t),_2t=r(tme,` class
method.`),tme.forEach(t),b2t=i(zi),lP=n(zi,"P",{});var Sao=s(lP);v2t=r(Sao,"This class cannot be instantiated directly using "),ske=n(Sao,"CODE",{});var L_a=s(ske);F2t=r(L_a,"__init__()"),L_a.forEach(t),T2t=r(Sao," (throws an error)."),Sao.forEach(t),M2t=i(zi),fa=n(zi,"DIV",{class:!0});var Q9=s(fa);T(iP.$$.fragment,Q9),E2t=i(Q9),lke=n(Q9,"P",{});var y_a=s(lke);C2t=r(y_a,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),y_a.forEach(t),w2t=i(Q9),af=n(Q9,"P",{});var ame=s(af);A2t=r(ame,`Note:
Loading a model from its configuration file does `),ike=n(ame,"STRONG",{});var x_a=s(ike);L2t=r(x_a,"not"),x_a.forEach(t),y2t=r(ame,` load the model weights. It only affects the
model\u2019s configuration. Use `),vle=n(ame,"A",{href:!0});var $_a=s(vle);x2t=r($_a,"from_pretrained()"),$_a.forEach(t),$2t=r(ame," to load the model weights."),ame.forEach(t),k2t=i(Q9),T(BL.$$.fragment,Q9),Q9.forEach(t),S2t=i(zi),at=n(zi,"DIV",{class:!0});var Qi=s(at);T(dP.$$.fragment,Qi),R2t=i(Qi),dke=n(Qi,"P",{});var k_a=s(dke);P2t=r(k_a,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),k_a.forEach(t),B2t=i(Qi),Wn=n(Qi,"P",{});var W9=s(Wn);I2t=r(W9,"The model class to instantiate is selected based on the "),mke=n(W9,"CODE",{});var S_a=s(mke);N2t=r(S_a,"model_type"),S_a.forEach(t),q2t=r(W9,` property of the config object (either
passed as an argument or loaded from `),cke=n(W9,"CODE",{});var R_a=s(cke);j2t=r(R_a,"pretrained_model_name_or_path"),R_a.forEach(t),D2t=r(W9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fke=n(W9,"CODE",{});var P_a=s(fke);G2t=r(P_a,"pretrained_model_name_or_path"),P_a.forEach(t),O2t=r(W9,":"),W9.forEach(t),V2t=i(Qi),Re=n(Qi,"UL",{});var Oe=s(Re);IL=n(Oe,"LI",{});var jZe=s(IL);gke=n(jZe,"STRONG",{});var B_a=s(gke);X2t=r(B_a,"albert"),B_a.forEach(t),z2t=r(jZe," \u2014 "),Fle=n(jZe,"A",{href:!0});var I_a=s(Fle);Q2t=r(I_a,"FlaxAlbertForQuestionAnswering"),I_a.forEach(t),W2t=r(jZe," (ALBERT model)"),jZe.forEach(t),U2t=i(Oe),NL=n(Oe,"LI",{});var DZe=s(NL);hke=n(DZe,"STRONG",{});var N_a=s(hke);H2t=r(N_a,"bart"),N_a.forEach(t),J2t=r(DZe," \u2014 "),Tle=n(DZe,"A",{href:!0});var q_a=s(Tle);Y2t=r(q_a,"FlaxBartForQuestionAnswering"),q_a.forEach(t),K2t=r(DZe," (BART model)"),DZe.forEach(t),Z2t=i(Oe),qL=n(Oe,"LI",{});var GZe=s(qL);uke=n(GZe,"STRONG",{});var j_a=s(uke);ebt=r(j_a,"bert"),j_a.forEach(t),obt=r(GZe," \u2014 "),Mle=n(GZe,"A",{href:!0});var D_a=s(Mle);rbt=r(D_a,"FlaxBertForQuestionAnswering"),D_a.forEach(t),tbt=r(GZe," (BERT model)"),GZe.forEach(t),abt=i(Oe),jL=n(Oe,"LI",{});var OZe=s(jL);pke=n(OZe,"STRONG",{});var G_a=s(pke);nbt=r(G_a,"big_bird"),G_a.forEach(t),sbt=r(OZe," \u2014 "),Ele=n(OZe,"A",{href:!0});var O_a=s(Ele);lbt=r(O_a,"FlaxBigBirdForQuestionAnswering"),O_a.forEach(t),ibt=r(OZe," (BigBird model)"),OZe.forEach(t),dbt=i(Oe),DL=n(Oe,"LI",{});var VZe=s(DL);_ke=n(VZe,"STRONG",{});var V_a=s(_ke);mbt=r(V_a,"distilbert"),V_a.forEach(t),cbt=r(VZe," \u2014 "),Cle=n(VZe,"A",{href:!0});var X_a=s(Cle);fbt=r(X_a,"FlaxDistilBertForQuestionAnswering"),X_a.forEach(t),gbt=r(VZe," (DistilBERT model)"),VZe.forEach(t),hbt=i(Oe),GL=n(Oe,"LI",{});var XZe=s(GL);bke=n(XZe,"STRONG",{});var z_a=s(bke);ubt=r(z_a,"electra"),z_a.forEach(t),pbt=r(XZe," \u2014 "),wle=n(XZe,"A",{href:!0});var Q_a=s(wle);_bt=r(Q_a,"FlaxElectraForQuestionAnswering"),Q_a.forEach(t),bbt=r(XZe," (ELECTRA model)"),XZe.forEach(t),vbt=i(Oe),OL=n(Oe,"LI",{});var zZe=s(OL);vke=n(zZe,"STRONG",{});var W_a=s(vke);Fbt=r(W_a,"mbart"),W_a.forEach(t),Tbt=r(zZe," \u2014 "),Ale=n(zZe,"A",{href:!0});var U_a=s(Ale);Mbt=r(U_a,"FlaxMBartForQuestionAnswering"),U_a.forEach(t),Ebt=r(zZe," (mBART model)"),zZe.forEach(t),Cbt=i(Oe),VL=n(Oe,"LI",{});var QZe=s(VL);Fke=n(QZe,"STRONG",{});var H_a=s(Fke);wbt=r(H_a,"roberta"),H_a.forEach(t),Abt=r(QZe," \u2014 "),Lle=n(QZe,"A",{href:!0});var J_a=s(Lle);Lbt=r(J_a,"FlaxRobertaForQuestionAnswering"),J_a.forEach(t),ybt=r(QZe," (RoBERTa model)"),QZe.forEach(t),xbt=i(Oe),XL=n(Oe,"LI",{});var WZe=s(XL);Tke=n(WZe,"STRONG",{});var Y_a=s(Tke);$bt=r(Y_a,"roformer"),Y_a.forEach(t),kbt=r(WZe," \u2014 "),yle=n(WZe,"A",{href:!0});var K_a=s(yle);Sbt=r(K_a,"FlaxRoFormerForQuestionAnswering"),K_a.forEach(t),Rbt=r(WZe," (RoFormer model)"),WZe.forEach(t),Pbt=i(Oe),zL=n(Oe,"LI",{});var UZe=s(zL);Mke=n(UZe,"STRONG",{});var Z_a=s(Mke);Bbt=r(Z_a,"xlm-roberta"),Z_a.forEach(t),Ibt=r(UZe," \u2014 "),xle=n(UZe,"A",{href:!0});var e1a=s(xle);Nbt=r(e1a,"FlaxXLMRobertaForQuestionAnswering"),e1a.forEach(t),qbt=r(UZe," (XLM-RoBERTa model)"),UZe.forEach(t),Oe.forEach(t),jbt=i(Qi),T(QL.$$.fragment,Qi),Qi.forEach(t),zi.forEach(t),bro=i(c),nf=n(c,"H2",{class:!0});var Rao=s(nf);WL=n(Rao,"A",{id:!0,class:!0,href:!0});var o1a=s(WL);Eke=n(o1a,"SPAN",{});var r1a=s(Eke);T(mP.$$.fragment,r1a),r1a.forEach(t),o1a.forEach(t),Dbt=i(Rao),Cke=n(Rao,"SPAN",{});var t1a=s(Cke);Gbt=r(t1a,"FlaxAutoModelForTokenClassification"),t1a.forEach(t),Rao.forEach(t),vro=i(c),xr=n(c,"DIV",{class:!0});var Wi=s(xr);T(cP.$$.fragment,Wi),Obt=i(Wi),sf=n(Wi,"P",{});var nme=s(sf);Vbt=r(nme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),$le=n(nme,"A",{href:!0});var a1a=s($le);Xbt=r(a1a,"from_pretrained()"),a1a.forEach(t),zbt=r(nme," class method or the "),kle=n(nme,"A",{href:!0});var n1a=s(kle);Qbt=r(n1a,"from_config()"),n1a.forEach(t),Wbt=r(nme,` class
method.`),nme.forEach(t),Ubt=i(Wi),fP=n(Wi,"P",{});var Pao=s(fP);Hbt=r(Pao,"This class cannot be instantiated directly using "),wke=n(Pao,"CODE",{});var s1a=s(wke);Jbt=r(s1a,"__init__()"),s1a.forEach(t),Ybt=r(Pao," (throws an error)."),Pao.forEach(t),Kbt=i(Wi),ga=n(Wi,"DIV",{class:!0});var U9=s(ga);T(gP.$$.fragment,U9),Zbt=i(U9),Ake=n(U9,"P",{});var l1a=s(Ake);evt=r(l1a,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),l1a.forEach(t),ovt=i(U9),lf=n(U9,"P",{});var sme=s(lf);rvt=r(sme,`Note:
Loading a model from its configuration file does `),Lke=n(sme,"STRONG",{});var i1a=s(Lke);tvt=r(i1a,"not"),i1a.forEach(t),avt=r(sme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Sle=n(sme,"A",{href:!0});var d1a=s(Sle);nvt=r(d1a,"from_pretrained()"),d1a.forEach(t),svt=r(sme," to load the model weights."),sme.forEach(t),lvt=i(U9),T(UL.$$.fragment,U9),U9.forEach(t),ivt=i(Wi),nt=n(Wi,"DIV",{class:!0});var Ui=s(nt);T(hP.$$.fragment,Ui),dvt=i(Ui),yke=n(Ui,"P",{});var m1a=s(yke);mvt=r(m1a,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),m1a.forEach(t),cvt=i(Ui),Un=n(Ui,"P",{});var H9=s(Un);fvt=r(H9,"The model class to instantiate is selected based on the "),xke=n(H9,"CODE",{});var c1a=s(xke);gvt=r(c1a,"model_type"),c1a.forEach(t),hvt=r(H9,` property of the config object (either
passed as an argument or loaded from `),$ke=n(H9,"CODE",{});var f1a=s($ke);uvt=r(f1a,"pretrained_model_name_or_path"),f1a.forEach(t),pvt=r(H9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kke=n(H9,"CODE",{});var g1a=s(kke);_vt=r(g1a,"pretrained_model_name_or_path"),g1a.forEach(t),bvt=r(H9,":"),H9.forEach(t),vvt=i(Ui),Xe=n(Ui,"UL",{});var Ao=s(Xe);HL=n(Ao,"LI",{});var HZe=s(HL);Ske=n(HZe,"STRONG",{});var h1a=s(Ske);Fvt=r(h1a,"albert"),h1a.forEach(t),Tvt=r(HZe," \u2014 "),Rle=n(HZe,"A",{href:!0});var u1a=s(Rle);Mvt=r(u1a,"FlaxAlbertForTokenClassification"),u1a.forEach(t),Evt=r(HZe," (ALBERT model)"),HZe.forEach(t),Cvt=i(Ao),JL=n(Ao,"LI",{});var JZe=s(JL);Rke=n(JZe,"STRONG",{});var p1a=s(Rke);wvt=r(p1a,"bert"),p1a.forEach(t),Avt=r(JZe," \u2014 "),Ple=n(JZe,"A",{href:!0});var _1a=s(Ple);Lvt=r(_1a,"FlaxBertForTokenClassification"),_1a.forEach(t),yvt=r(JZe," (BERT model)"),JZe.forEach(t),xvt=i(Ao),YL=n(Ao,"LI",{});var YZe=s(YL);Pke=n(YZe,"STRONG",{});var b1a=s(Pke);$vt=r(b1a,"big_bird"),b1a.forEach(t),kvt=r(YZe," \u2014 "),Ble=n(YZe,"A",{href:!0});var v1a=s(Ble);Svt=r(v1a,"FlaxBigBirdForTokenClassification"),v1a.forEach(t),Rvt=r(YZe," (BigBird model)"),YZe.forEach(t),Pvt=i(Ao),KL=n(Ao,"LI",{});var KZe=s(KL);Bke=n(KZe,"STRONG",{});var F1a=s(Bke);Bvt=r(F1a,"distilbert"),F1a.forEach(t),Ivt=r(KZe," \u2014 "),Ile=n(KZe,"A",{href:!0});var T1a=s(Ile);Nvt=r(T1a,"FlaxDistilBertForTokenClassification"),T1a.forEach(t),qvt=r(KZe," (DistilBERT model)"),KZe.forEach(t),jvt=i(Ao),ZL=n(Ao,"LI",{});var ZZe=s(ZL);Ike=n(ZZe,"STRONG",{});var M1a=s(Ike);Dvt=r(M1a,"electra"),M1a.forEach(t),Gvt=r(ZZe," \u2014 "),Nle=n(ZZe,"A",{href:!0});var E1a=s(Nle);Ovt=r(E1a,"FlaxElectraForTokenClassification"),E1a.forEach(t),Vvt=r(ZZe," (ELECTRA model)"),ZZe.forEach(t),Xvt=i(Ao),ey=n(Ao,"LI",{});var eeo=s(ey);Nke=n(eeo,"STRONG",{});var C1a=s(Nke);zvt=r(C1a,"roberta"),C1a.forEach(t),Qvt=r(eeo," \u2014 "),qle=n(eeo,"A",{href:!0});var w1a=s(qle);Wvt=r(w1a,"FlaxRobertaForTokenClassification"),w1a.forEach(t),Uvt=r(eeo," (RoBERTa model)"),eeo.forEach(t),Hvt=i(Ao),oy=n(Ao,"LI",{});var oeo=s(oy);qke=n(oeo,"STRONG",{});var A1a=s(qke);Jvt=r(A1a,"roformer"),A1a.forEach(t),Yvt=r(oeo," \u2014 "),jle=n(oeo,"A",{href:!0});var L1a=s(jle);Kvt=r(L1a,"FlaxRoFormerForTokenClassification"),L1a.forEach(t),Zvt=r(oeo," (RoFormer model)"),oeo.forEach(t),eFt=i(Ao),ry=n(Ao,"LI",{});var reo=s(ry);jke=n(reo,"STRONG",{});var y1a=s(jke);oFt=r(y1a,"xlm-roberta"),y1a.forEach(t),rFt=r(reo," \u2014 "),Dle=n(reo,"A",{href:!0});var x1a=s(Dle);tFt=r(x1a,"FlaxXLMRobertaForTokenClassification"),x1a.forEach(t),aFt=r(reo," (XLM-RoBERTa model)"),reo.forEach(t),Ao.forEach(t),nFt=i(Ui),T(ty.$$.fragment,Ui),Ui.forEach(t),Wi.forEach(t),Fro=i(c),df=n(c,"H2",{class:!0});var Bao=s(df);ay=n(Bao,"A",{id:!0,class:!0,href:!0});var $1a=s(ay);Dke=n($1a,"SPAN",{});var k1a=s(Dke);T(uP.$$.fragment,k1a),k1a.forEach(t),$1a.forEach(t),sFt=i(Bao),Gke=n(Bao,"SPAN",{});var S1a=s(Gke);lFt=r(S1a,"FlaxAutoModelForMultipleChoice"),S1a.forEach(t),Bao.forEach(t),Tro=i(c),$r=n(c,"DIV",{class:!0});var Hi=s($r);T(pP.$$.fragment,Hi),iFt=i(Hi),mf=n(Hi,"P",{});var lme=s(mf);dFt=r(lme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Gle=n(lme,"A",{href:!0});var R1a=s(Gle);mFt=r(R1a,"from_pretrained()"),R1a.forEach(t),cFt=r(lme," class method or the "),Ole=n(lme,"A",{href:!0});var P1a=s(Ole);fFt=r(P1a,"from_config()"),P1a.forEach(t),gFt=r(lme,` class
method.`),lme.forEach(t),hFt=i(Hi),_P=n(Hi,"P",{});var Iao=s(_P);uFt=r(Iao,"This class cannot be instantiated directly using "),Oke=n(Iao,"CODE",{});var B1a=s(Oke);pFt=r(B1a,"__init__()"),B1a.forEach(t),_Ft=r(Iao," (throws an error)."),Iao.forEach(t),bFt=i(Hi),ha=n(Hi,"DIV",{class:!0});var J9=s(ha);T(bP.$$.fragment,J9),vFt=i(J9),Vke=n(J9,"P",{});var I1a=s(Vke);FFt=r(I1a,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),I1a.forEach(t),TFt=i(J9),cf=n(J9,"P",{});var ime=s(cf);MFt=r(ime,`Note:
Loading a model from its configuration file does `),Xke=n(ime,"STRONG",{});var N1a=s(Xke);EFt=r(N1a,"not"),N1a.forEach(t),CFt=r(ime,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vle=n(ime,"A",{href:!0});var q1a=s(Vle);wFt=r(q1a,"from_pretrained()"),q1a.forEach(t),AFt=r(ime," to load the model weights."),ime.forEach(t),LFt=i(J9),T(ny.$$.fragment,J9),J9.forEach(t),yFt=i(Hi),st=n(Hi,"DIV",{class:!0});var Ji=s(st);T(vP.$$.fragment,Ji),xFt=i(Ji),zke=n(Ji,"P",{});var j1a=s(zke);$Ft=r(j1a,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),j1a.forEach(t),kFt=i(Ji),Hn=n(Ji,"P",{});var Y9=s(Hn);SFt=r(Y9,"The model class to instantiate is selected based on the "),Qke=n(Y9,"CODE",{});var D1a=s(Qke);RFt=r(D1a,"model_type"),D1a.forEach(t),PFt=r(Y9,` property of the config object (either
passed as an argument or loaded from `),Wke=n(Y9,"CODE",{});var G1a=s(Wke);BFt=r(G1a,"pretrained_model_name_or_path"),G1a.forEach(t),IFt=r(Y9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Uke=n(Y9,"CODE",{});var O1a=s(Uke);NFt=r(O1a,"pretrained_model_name_or_path"),O1a.forEach(t),qFt=r(Y9,":"),Y9.forEach(t),jFt=i(Ji),ze=n(Ji,"UL",{});var Lo=s(ze);sy=n(Lo,"LI",{});var teo=s(sy);Hke=n(teo,"STRONG",{});var V1a=s(Hke);DFt=r(V1a,"albert"),V1a.forEach(t),GFt=r(teo," \u2014 "),Xle=n(teo,"A",{href:!0});var X1a=s(Xle);OFt=r(X1a,"FlaxAlbertForMultipleChoice"),X1a.forEach(t),VFt=r(teo," (ALBERT model)"),teo.forEach(t),XFt=i(Lo),ly=n(Lo,"LI",{});var aeo=s(ly);Jke=n(aeo,"STRONG",{});var z1a=s(Jke);zFt=r(z1a,"bert"),z1a.forEach(t),QFt=r(aeo," \u2014 "),zle=n(aeo,"A",{href:!0});var Q1a=s(zle);WFt=r(Q1a,"FlaxBertForMultipleChoice"),Q1a.forEach(t),UFt=r(aeo," (BERT model)"),aeo.forEach(t),HFt=i(Lo),iy=n(Lo,"LI",{});var neo=s(iy);Yke=n(neo,"STRONG",{});var W1a=s(Yke);JFt=r(W1a,"big_bird"),W1a.forEach(t),YFt=r(neo," \u2014 "),Qle=n(neo,"A",{href:!0});var U1a=s(Qle);KFt=r(U1a,"FlaxBigBirdForMultipleChoice"),U1a.forEach(t),ZFt=r(neo," (BigBird model)"),neo.forEach(t),eTt=i(Lo),dy=n(Lo,"LI",{});var seo=s(dy);Kke=n(seo,"STRONG",{});var H1a=s(Kke);oTt=r(H1a,"distilbert"),H1a.forEach(t),rTt=r(seo," \u2014 "),Wle=n(seo,"A",{href:!0});var J1a=s(Wle);tTt=r(J1a,"FlaxDistilBertForMultipleChoice"),J1a.forEach(t),aTt=r(seo," (DistilBERT model)"),seo.forEach(t),nTt=i(Lo),my=n(Lo,"LI",{});var leo=s(my);Zke=n(leo,"STRONG",{});var Y1a=s(Zke);sTt=r(Y1a,"electra"),Y1a.forEach(t),lTt=r(leo," \u2014 "),Ule=n(leo,"A",{href:!0});var K1a=s(Ule);iTt=r(K1a,"FlaxElectraForMultipleChoice"),K1a.forEach(t),dTt=r(leo," (ELECTRA model)"),leo.forEach(t),mTt=i(Lo),cy=n(Lo,"LI",{});var ieo=s(cy);eSe=n(ieo,"STRONG",{});var Z1a=s(eSe);cTt=r(Z1a,"roberta"),Z1a.forEach(t),fTt=r(ieo," \u2014 "),Hle=n(ieo,"A",{href:!0});var e2a=s(Hle);gTt=r(e2a,"FlaxRobertaForMultipleChoice"),e2a.forEach(t),hTt=r(ieo," (RoBERTa model)"),ieo.forEach(t),uTt=i(Lo),fy=n(Lo,"LI",{});var deo=s(fy);oSe=n(deo,"STRONG",{});var o2a=s(oSe);pTt=r(o2a,"roformer"),o2a.forEach(t),_Tt=r(deo," \u2014 "),Jle=n(deo,"A",{href:!0});var r2a=s(Jle);bTt=r(r2a,"FlaxRoFormerForMultipleChoice"),r2a.forEach(t),vTt=r(deo," (RoFormer model)"),deo.forEach(t),FTt=i(Lo),gy=n(Lo,"LI",{});var meo=s(gy);rSe=n(meo,"STRONG",{});var t2a=s(rSe);TTt=r(t2a,"xlm-roberta"),t2a.forEach(t),MTt=r(meo," \u2014 "),Yle=n(meo,"A",{href:!0});var a2a=s(Yle);ETt=r(a2a,"FlaxXLMRobertaForMultipleChoice"),a2a.forEach(t),CTt=r(meo," (XLM-RoBERTa model)"),meo.forEach(t),Lo.forEach(t),wTt=i(Ji),T(hy.$$.fragment,Ji),Ji.forEach(t),Hi.forEach(t),Mro=i(c),ff=n(c,"H2",{class:!0});var Nao=s(ff);uy=n(Nao,"A",{id:!0,class:!0,href:!0});var n2a=s(uy);tSe=n(n2a,"SPAN",{});var s2a=s(tSe);T(FP.$$.fragment,s2a),s2a.forEach(t),n2a.forEach(t),ATt=i(Nao),aSe=n(Nao,"SPAN",{});var l2a=s(aSe);LTt=r(l2a,"FlaxAutoModelForNextSentencePrediction"),l2a.forEach(t),Nao.forEach(t),Ero=i(c),kr=n(c,"DIV",{class:!0});var Yi=s(kr);T(TP.$$.fragment,Yi),yTt=i(Yi),gf=n(Yi,"P",{});var dme=s(gf);xTt=r(dme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Kle=n(dme,"A",{href:!0});var i2a=s(Kle);$Tt=r(i2a,"from_pretrained()"),i2a.forEach(t),kTt=r(dme," class method or the "),Zle=n(dme,"A",{href:!0});var d2a=s(Zle);STt=r(d2a,"from_config()"),d2a.forEach(t),RTt=r(dme,` class
method.`),dme.forEach(t),PTt=i(Yi),MP=n(Yi,"P",{});var qao=s(MP);BTt=r(qao,"This class cannot be instantiated directly using "),nSe=n(qao,"CODE",{});var m2a=s(nSe);ITt=r(m2a,"__init__()"),m2a.forEach(t),NTt=r(qao," (throws an error)."),qao.forEach(t),qTt=i(Yi),ua=n(Yi,"DIV",{class:!0});var K9=s(ua);T(EP.$$.fragment,K9),jTt=i(K9),sSe=n(K9,"P",{});var c2a=s(sSe);DTt=r(c2a,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),c2a.forEach(t),GTt=i(K9),hf=n(K9,"P",{});var mme=s(hf);OTt=r(mme,`Note:
Loading a model from its configuration file does `),lSe=n(mme,"STRONG",{});var f2a=s(lSe);VTt=r(f2a,"not"),f2a.forEach(t),XTt=r(mme,` load the model weights. It only affects the
model\u2019s configuration. Use `),eie=n(mme,"A",{href:!0});var g2a=s(eie);zTt=r(g2a,"from_pretrained()"),g2a.forEach(t),QTt=r(mme," to load the model weights."),mme.forEach(t),WTt=i(K9),T(py.$$.fragment,K9),K9.forEach(t),UTt=i(Yi),lt=n(Yi,"DIV",{class:!0});var Ki=s(lt);T(CP.$$.fragment,Ki),HTt=i(Ki),iSe=n(Ki,"P",{});var h2a=s(iSe);JTt=r(h2a,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),h2a.forEach(t),YTt=i(Ki),Jn=n(Ki,"P",{});var Z9=s(Jn);KTt=r(Z9,"The model class to instantiate is selected based on the "),dSe=n(Z9,"CODE",{});var u2a=s(dSe);ZTt=r(u2a,"model_type"),u2a.forEach(t),eMt=r(Z9,` property of the config object (either
passed as an argument or loaded from `),mSe=n(Z9,"CODE",{});var p2a=s(mSe);oMt=r(p2a,"pretrained_model_name_or_path"),p2a.forEach(t),rMt=r(Z9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cSe=n(Z9,"CODE",{});var _2a=s(cSe);tMt=r(_2a,"pretrained_model_name_or_path"),_2a.forEach(t),aMt=r(Z9,":"),Z9.forEach(t),nMt=i(Ki),fSe=n(Ki,"UL",{});var b2a=s(fSe);_y=n(b2a,"LI",{});var ceo=s(_y);gSe=n(ceo,"STRONG",{});var v2a=s(gSe);sMt=r(v2a,"bert"),v2a.forEach(t),lMt=r(ceo," \u2014 "),oie=n(ceo,"A",{href:!0});var F2a=s(oie);iMt=r(F2a,"FlaxBertForNextSentencePrediction"),F2a.forEach(t),dMt=r(ceo," (BERT model)"),ceo.forEach(t),b2a.forEach(t),mMt=i(Ki),T(by.$$.fragment,Ki),Ki.forEach(t),Yi.forEach(t),Cro=i(c),uf=n(c,"H2",{class:!0});var jao=s(uf);vy=n(jao,"A",{id:!0,class:!0,href:!0});var T2a=s(vy);hSe=n(T2a,"SPAN",{});var M2a=s(hSe);T(wP.$$.fragment,M2a),M2a.forEach(t),T2a.forEach(t),cMt=i(jao),uSe=n(jao,"SPAN",{});var E2a=s(uSe);fMt=r(E2a,"FlaxAutoModelForImageClassification"),E2a.forEach(t),jao.forEach(t),wro=i(c),Sr=n(c,"DIV",{class:!0});var Zi=s(Sr);T(AP.$$.fragment,Zi),gMt=i(Zi),pf=n(Zi,"P",{});var cme=s(pf);hMt=r(cme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),rie=n(cme,"A",{href:!0});var C2a=s(rie);uMt=r(C2a,"from_pretrained()"),C2a.forEach(t),pMt=r(cme," class method or the "),tie=n(cme,"A",{href:!0});var w2a=s(tie);_Mt=r(w2a,"from_config()"),w2a.forEach(t),bMt=r(cme,` class
method.`),cme.forEach(t),vMt=i(Zi),LP=n(Zi,"P",{});var Dao=s(LP);FMt=r(Dao,"This class cannot be instantiated directly using "),pSe=n(Dao,"CODE",{});var A2a=s(pSe);TMt=r(A2a,"__init__()"),A2a.forEach(t),MMt=r(Dao," (throws an error)."),Dao.forEach(t),EMt=i(Zi),pa=n(Zi,"DIV",{class:!0});var ex=s(pa);T(yP.$$.fragment,ex),CMt=i(ex),_Se=n(ex,"P",{});var L2a=s(_Se);wMt=r(L2a,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),L2a.forEach(t),AMt=i(ex),_f=n(ex,"P",{});var fme=s(_f);LMt=r(fme,`Note:
Loading a model from its configuration file does `),bSe=n(fme,"STRONG",{});var y2a=s(bSe);yMt=r(y2a,"not"),y2a.forEach(t),xMt=r(fme,` load the model weights. It only affects the
model\u2019s configuration. Use `),aie=n(fme,"A",{href:!0});var x2a=s(aie);$Mt=r(x2a,"from_pretrained()"),x2a.forEach(t),kMt=r(fme," to load the model weights."),fme.forEach(t),SMt=i(ex),T(Fy.$$.fragment,ex),ex.forEach(t),RMt=i(Zi),it=n(Zi,"DIV",{class:!0});var ed=s(it);T(xP.$$.fragment,ed),PMt=i(ed),vSe=n(ed,"P",{});var $2a=s(vSe);BMt=r($2a,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),$2a.forEach(t),IMt=i(ed),Yn=n(ed,"P",{});var ox=s(Yn);NMt=r(ox,"The model class to instantiate is selected based on the "),FSe=n(ox,"CODE",{});var k2a=s(FSe);qMt=r(k2a,"model_type"),k2a.forEach(t),jMt=r(ox,` property of the config object (either
passed as an argument or loaded from `),TSe=n(ox,"CODE",{});var S2a=s(TSe);DMt=r(S2a,"pretrained_model_name_or_path"),S2a.forEach(t),GMt=r(ox,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MSe=n(ox,"CODE",{});var R2a=s(MSe);OMt=r(R2a,"pretrained_model_name_or_path"),R2a.forEach(t),VMt=r(ox,":"),ox.forEach(t),XMt=i(ed),$P=n(ed,"UL",{});var Gao=s($P);Ty=n(Gao,"LI",{});var feo=s(Ty);ESe=n(feo,"STRONG",{});var P2a=s(ESe);zMt=r(P2a,"beit"),P2a.forEach(t),QMt=r(feo," \u2014 "),nie=n(feo,"A",{href:!0});var B2a=s(nie);WMt=r(B2a,"FlaxBeitForImageClassification"),B2a.forEach(t),UMt=r(feo," (BEiT model)"),feo.forEach(t),HMt=i(Gao),My=n(Gao,"LI",{});var geo=s(My);CSe=n(geo,"STRONG",{});var I2a=s(CSe);JMt=r(I2a,"vit"),I2a.forEach(t),YMt=r(geo," \u2014 "),sie=n(geo,"A",{href:!0});var N2a=s(sie);KMt=r(N2a,"FlaxViTForImageClassification"),N2a.forEach(t),ZMt=r(geo," (ViT model)"),geo.forEach(t),Gao.forEach(t),eEt=i(ed),T(Ey.$$.fragment,ed),ed.forEach(t),Zi.forEach(t),Aro=i(c),bf=n(c,"H2",{class:!0});var Oao=s(bf);Cy=n(Oao,"A",{id:!0,class:!0,href:!0});var q2a=s(Cy);wSe=n(q2a,"SPAN",{});var j2a=s(wSe);T(kP.$$.fragment,j2a),j2a.forEach(t),q2a.forEach(t),oEt=i(Oao),ASe=n(Oao,"SPAN",{});var D2a=s(ASe);rEt=r(D2a,"FlaxAutoModelForVision2Seq"),D2a.forEach(t),Oao.forEach(t),Lro=i(c),Rr=n(c,"DIV",{class:!0});var od=s(Rr);T(SP.$$.fragment,od),tEt=i(od),vf=n(od,"P",{});var gme=s(vf);aEt=r(gme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),lie=n(gme,"A",{href:!0});var G2a=s(lie);nEt=r(G2a,"from_pretrained()"),G2a.forEach(t),sEt=r(gme," class method or the "),iie=n(gme,"A",{href:!0});var O2a=s(iie);lEt=r(O2a,"from_config()"),O2a.forEach(t),iEt=r(gme,` class
method.`),gme.forEach(t),dEt=i(od),RP=n(od,"P",{});var Vao=s(RP);mEt=r(Vao,"This class cannot be instantiated directly using "),LSe=n(Vao,"CODE",{});var V2a=s(LSe);cEt=r(V2a,"__init__()"),V2a.forEach(t),fEt=r(Vao," (throws an error)."),Vao.forEach(t),gEt=i(od),_a=n(od,"DIV",{class:!0});var rx=s(_a);T(PP.$$.fragment,rx),hEt=i(rx),ySe=n(rx,"P",{});var X2a=s(ySe);uEt=r(X2a,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),X2a.forEach(t),pEt=i(rx),Ff=n(rx,"P",{});var hme=s(Ff);_Et=r(hme,`Note:
Loading a model from its configuration file does `),xSe=n(hme,"STRONG",{});var z2a=s(xSe);bEt=r(z2a,"not"),z2a.forEach(t),vEt=r(hme,` load the model weights. It only affects the
model\u2019s configuration. Use `),die=n(hme,"A",{href:!0});var Q2a=s(die);FEt=r(Q2a,"from_pretrained()"),Q2a.forEach(t),TEt=r(hme," to load the model weights."),hme.forEach(t),MEt=i(rx),T(wy.$$.fragment,rx),rx.forEach(t),EEt=i(od),dt=n(od,"DIV",{class:!0});var rd=s(dt);T(BP.$$.fragment,rd),CEt=i(rd),$Se=n(rd,"P",{});var W2a=s($Se);wEt=r(W2a,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),W2a.forEach(t),AEt=i(rd),Kn=n(rd,"P",{});var tx=s(Kn);LEt=r(tx,"The model class to instantiate is selected based on the "),kSe=n(tx,"CODE",{});var U2a=s(kSe);yEt=r(U2a,"model_type"),U2a.forEach(t),xEt=r(tx,` property of the config object (either
passed as an argument or loaded from `),SSe=n(tx,"CODE",{});var H2a=s(SSe);$Et=r(H2a,"pretrained_model_name_or_path"),H2a.forEach(t),kEt=r(tx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RSe=n(tx,"CODE",{});var J2a=s(RSe);SEt=r(J2a,"pretrained_model_name_or_path"),J2a.forEach(t),REt=r(tx,":"),tx.forEach(t),PEt=i(rd),PSe=n(rd,"UL",{});var Y2a=s(PSe);Ay=n(Y2a,"LI",{});var heo=s(Ay);BSe=n(heo,"STRONG",{});var K2a=s(BSe);BEt=r(K2a,"vision-encoder-decoder"),K2a.forEach(t),IEt=r(heo," \u2014 "),mie=n(heo,"A",{href:!0});var Z2a=s(mie);NEt=r(Z2a,"FlaxVisionEncoderDecoderModel"),Z2a.forEach(t),qEt=r(heo," (Vision Encoder decoder model)"),heo.forEach(t),Y2a.forEach(t),jEt=i(rd),T(Ly.$$.fragment,rd),rd.forEach(t),od.forEach(t),this.h()},h(){d(g,"name","hf:doc:metadata"),d(g,"content",JSON.stringify(gFa)),d(f,"id","auto-classes"),d(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(f,"href","#auto-classes"),d(u,"class","relative group"),d(es,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),d(rs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),d(ts,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),d(dd,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),d(yf,"id","extending-the-auto-classes"),d(yf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(yf,"href","#extending-the-auto-classes"),d(md,"class","relative group"),d($f,"id","transformers.AutoConfig"),d($f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d($f,"href","#transformers.AutoConfig"),d(cd,"class","relative group"),d(gI,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),d(hI,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),d(uI,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),d(pI,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),d(_I,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),d(bI,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),d(vI,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),d(FI,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),d(TI,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),d(MI,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),d(EI,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),d(CI,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),d(wI,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),d(AI,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),d(LI,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),d(yI,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig"),d(xI,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),d($I,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),d(kI,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),d(SI,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),d(RI,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),d(PI,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),d(BI,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),d(II,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),d(NI,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),d(qI,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),d(jI,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),d(DI,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),d(GI,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),d(OI,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),d(VI,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),d(XI,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),d(zI,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),d(QI,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),d(WI,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),d(UI,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),d(HI,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig"),d(JI,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),d(YI,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),d(KI,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),d(ZI,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),d(eN,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),d(oN,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),d(rN,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),d(tN,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),d(aN,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),d(nN,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig"),d(sN,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),d(lN,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),d(iN,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),d(dN,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),d(mN,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),d(cN,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),d(fN,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),d(gN,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),d(hN,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),d(uN,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),d(pN,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),d(_N,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),d(bN,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),d(vN,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),d(FN,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),d(TN,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),d(MN,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig"),d(EN,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),d(CN,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),d(wN,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),d(AN,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),d(LN,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),d(yN,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),d(xN,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),d($N,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),d(kN,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),d(SN,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),d(RN,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),d(PN,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),d(BN,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),d(IN,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),d(NN,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),d(qN,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),d(jN,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),d(DN,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),d(GN,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),d(ON,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),d(VN,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),d(XN,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),d(zN,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),d(QN,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),d(WN,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),d(UN,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),d(HN,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),d(JN,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),d(YN,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),d(KN,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),d(ZN,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),d(eq,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),d(oq,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),d(rq,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),d(tq,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),d(aq,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),d(nq,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),d(sq,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),d(lq,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),d(iq,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),d(dq,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),d(mq,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),d(cq,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig"),d(fq,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),d(gq,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),d(hq,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),d(uq,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),d(pq,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),d(_q,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),d(bq,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),d(vq,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),d(Fq,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),d(Tq,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),d(Mq,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),d(Eq,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),d(Cq,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),d(wq,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig"),d(Aq,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),d(Lq,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),d(yq,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),d(xq,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig"),d($q,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),d(kq,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),d(Sq,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),d(Rq,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),d(Pq,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),d(Bq,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),d(Iq,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),d(Nq,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),d(qq,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),d(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(au,"id","transformers.AutoTokenizer"),d(au,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(au,"href","#transformers.AutoTokenizer"),d(gd,"class","relative group"),d(jq,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),d(Dq,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(Gq,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(Oq,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),d(Vq,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),d(Xq,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),d(zq,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),d(Qq,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),d(Wq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(Uq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(Hq,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),d(Jq,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),d(Yq,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),d(Kq,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),d(Zq,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),d(ej,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(oj,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(rj,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),d(tj,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),d(aj,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),d(nj,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),d(sj,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),d(lj,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),d(ij,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),d(dj,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),d(mj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(cj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(fj,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),d(gj,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),d(hj,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),d(uj,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),d(pj,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),d(_j,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),d(bj,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),d(vj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d(Fj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(Tj,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),d(Mj,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),d(Ej,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),d(Cj,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),d(wj,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),d(Aj,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),d(Lj,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),d(yj,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),d(xj,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),d($j,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),d(kj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(Sj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(Rj,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),d(Pj,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),d(Bj,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),d(Ij,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),d(Nj,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),d(qj,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),d(jj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(Dj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(Gj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(Oj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(Vj,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),d(Xj,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer"),d(zj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(Qj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(Wj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(Uj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(Hj,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),d(Jj,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),d(Yj,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(Kj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d(Zj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(eD,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),d(oD,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),d(rD,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),d(tD,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),d(aD,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),d(nD,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),d(sD,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),d(lD,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),d(iD,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),d(dD,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),d(mD,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),d(cD,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),d(fD,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(gD,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(hD,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),d(uD,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),d(pD,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),d(_D,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),d(bD,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),d(vD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),d(FD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),d(TD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),d(MD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),d(ED,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(CD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(wD,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),d(AD,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),d(LD,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),d(yD,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),d(xD,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),d($D,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(kD,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(SD,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),d(RD,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),d(PD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(BD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(ID,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),d(ND,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),d(qD,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(jD,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(DD,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),d(GD,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),d(OD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(VD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(XD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(zD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(QD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(WD,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),d(UD,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),d(HD,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),d(JD,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),d(YD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(KD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(ZD,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),d(eG,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),d(oG,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),d(rG,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),d(tG,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),d(aG,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),d(nG,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),d(sG,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),d(lG,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),d(iG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d(dG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(mG,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),d(cG,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),d(fG,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),d(gG,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),d(hG,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),d(uG,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),d(pG,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),d(_G,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),d(bG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(vG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(FG,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),d(TG,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),d(MG,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),d(EG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(CG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(wG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(AG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(LG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(yG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(xG,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),d($G,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperTokenizer"),d(kG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(SG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(RG,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),d(PG,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),d(BG,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),d(IG,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),d(NG,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),d(qG,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),d(jG,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),d(DG,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),d(GG,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),d(OG,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),d(VG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(XG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Gu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ou,"id","transformers.AutoFeatureExtractor"),d(Ou,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ou,"href","#transformers.AutoFeatureExtractor"),d(hd,"class","relative group"),d(zG,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),d(QG,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),d(WG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),d(UG,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor"),d(HG,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(JG,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(YG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(KG,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),d(ZG,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor"),d(eO,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTFeatureExtractor"),d(oO,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),d(rO,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),d(tO,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTFeatureExtractor"),d(aO,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaFeatureExtractor"),d(nO,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),d(sO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),d(lO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(iO,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),d(dO,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),d(mO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),d(cO,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitFeatureExtractor"),d(fO,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),d(gO,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),d(hO,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),d(uO,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),d(pO,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),d(_O,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),d(bO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(vO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(FO,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),d(TO,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),d(MO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),d(EO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),d(CO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(wO,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor"),d(AO,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltFeatureExtractor"),d(LO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),d(yO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),d(xO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),d($O,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(kO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(SO,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperFeatureExtractor"),d(RO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),d(PO,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),d(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Pp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Bp,"id","transformers.AutoProcessor"),d(Bp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Bp,"href","#transformers.AutoProcessor"),d(ud,"class","relative group"),d(BO,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),d(IO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),d(NO,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutProcessor"),d(qO,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),d(jO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),d(DO,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),d(GO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),d(OO,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),d(VO,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMProcessor"),d(XO,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),d(zO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(QO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(WO,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),d(UO,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),d(HO,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),d(JO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(YO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(KO,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),d(ZO,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),d(eV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(oV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(rV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(tV,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperProcessor"),d(aV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),d(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(l_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(i_,"id","transformers.AutoModel"),d(i_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(i_,"href","#transformers.AutoModel"),d(_d,"class","relative group"),d(nV,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(sV,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(lV,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(iV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),d(dV,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),d(mV,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),d(cV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),d(fV,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),d(gV,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),d(hV,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),d(uV,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),d(pV,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),d(_V,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),d(bV,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),d(vV,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),d(FV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),d(TV,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),d(MV,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel"),d(EV,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),d(CV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),d(wV,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),d(AV,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),d(LV,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),d(yV,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),d(xV,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),d($V,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),d(kV,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),d(SV,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),d(RV,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),d(PV,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),d(BV,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),d(IV,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),d(NV,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),d(qV,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),d(jV,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),d(DV,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),d(GV,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),d(OV,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmModel"),d(VV,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),d(XV,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),d(zV,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),d(QV,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),d(WV,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),d(UV,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),d(HV,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),d(JV,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),d(YV,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),d(KV,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),d(ZV,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel"),d(eX,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),d(oX,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),d(rX,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),d(tX,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),d(aX,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),d(nX,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),d(sX,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),d(lX,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),d(iX,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),d(dX,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),d(mX,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),d(cX,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),d(fX,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),d(gX,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),d(hX,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),d(uX,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),d(pX,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel"),d(_X,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),d(bX,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),d(vX,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),d(FX,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),d(TX,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),d(MX,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),d(EX,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),d(CX,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),d(wX,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),d(AX,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),d(LX,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),d(yX,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),d(xX,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),d($X,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),d(kX,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),d(SX,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),d(RX,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),d(PX,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),d(BX,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),d(IX,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),d(NX,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),d(qX,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),d(jX,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),d(DX,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),d(GX,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),d(OX,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),d(VX,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),d(XX,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),d(zX,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),d(QX,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),d(WX,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),d(UX,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),d(HX,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),d(JX,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),d(YX,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),d(KX,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),d(ZX,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),d(ez,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),d(oz,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),d(rz,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel"),d(tz,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),d(az,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),d(nz,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),d(sz,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),d(lz,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),d(iz,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),d(dz,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),d(mz,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),d(cz,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),d(fz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),d(gz,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),d(hz,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel"),d(uz,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),d(pz,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),d(_z,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),d(bz,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel"),d(vz,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),d(Fz,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),d(Tz,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),d(Mz,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),d(Ez,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),d(Cz,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),d(wz,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),d(Az,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),d(Lz,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),d(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($2,"id","transformers.AutoModelForPreTraining"),d($2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d($2,"href","#transformers.AutoModelForPreTraining"),d(Fd,"class","relative group"),d(yz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(xz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d($z,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(kz,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),d(Sz,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(Rz,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),d(Pz,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),d(Bz,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),d(Iz,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(Nz,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(qz,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(jz,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(Dz,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(Gz,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(Oz,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),d(Vz,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),d(Xz,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(zz,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),d(Qz,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),d(Wz,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(Uz,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),d(Hz,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(Jz,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(Yz,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(Kz,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(Zz,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),d(eQ,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),d(oQ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),d(rQ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),d(tQ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(aQ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(nQ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),d(sQ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(lQ,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),d(iQ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(dQ,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),d(mQ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(cQ,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(fQ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(gQ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(hQ,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),d(uQ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),d(pQ,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),d(_Q,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),d(bQ,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),d(vQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),d(FQ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),d(TQ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(MQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(EQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(CQ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yb,"id","transformers.AutoModelForCausalLM"),d(yb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(yb,"href","#transformers.AutoModelForCausalLM"),d(Ed,"class","relative group"),d(wQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(AQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(LQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yQ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),d(xQ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),d($Q,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),d(kQ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),d(SQ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),d(RQ,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),d(PQ,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),d(BQ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),d(IQ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),d(NQ,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),d(qQ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(jQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),d(DQ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),d(GQ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),d(OQ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(VQ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),d(XQ,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),d(zQ,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM"),d(QQ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),d(WQ,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),d(UQ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),d(HQ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),d(JQ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),d(YQ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(KQ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),d(ZQ,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),d(eW,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),d(oW,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),d(rW,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),d(tW,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),d(aW,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),d(nW,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),d(sW,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),d(lW,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),d(iW,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(dW,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),d(mW,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),d(cW,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(fW,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),d(gW,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),d(hW,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),d(uW,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fv,"id","transformers.AutoModelForMaskedLM"),d(Fv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Fv,"href","#transformers.AutoModelForMaskedLM"),d(Ad,"class","relative group"),d(pW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_W,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(bW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vW,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),d(FW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(TW,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),d(MW,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),d(EW,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(CW,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),d(wW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(AW,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(LW,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(yW,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(xW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),d($W,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),d(kW,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(SW,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),d(RW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),d(PW,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(BW,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(IW,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(NW,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),d(qW,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(jW,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),d(DW,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),d(GW,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(OW,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(VW,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),d(XW,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),d(zW,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),d(QW,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),d(WW,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),d(UW,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),d(HW,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(JW,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),d(YW,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(KW,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(ZW,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(eU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(oU,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(rU,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),d(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dF,"id","transformers.AutoModelForSeq2SeqLM"),d(dF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(dF,"href","#transformers.AutoModelForSeq2SeqLM"),d(xd,"class","relative group"),d(tU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(aU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(nU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sU,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(lU,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),d(iU,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),d(dU,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),d(mU,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),d(cU,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(fU,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),d(gU,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),d(hU,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),d(uU,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),d(pU,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(_U,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),d(bU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(vU,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),d(FU,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),d(TU,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),d(MU,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),d(EU,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),d(CU,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(wU,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),d(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(RF,"id","transformers.AutoModelForSequenceClassification"),d(RF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(RF,"href","#transformers.AutoModelForSequenceClassification"),d(Sd,"class","relative group"),d(AU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(LU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(yU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xU,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),d($U,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),d(kU,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),d(SU,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),d(RU,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),d(PU,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),d(BU,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),d(IU,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),d(NU,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),d(qU,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),d(jU,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),d(DU,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),d(GU,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),d(OU,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),d(VU,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),d(XU,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),d(zU,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification"),d(QU,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),d(WU,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),d(UU,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),d(HU,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),d(JU,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),d(YU,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),d(KU,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),d(ZU,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),d(eH,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),d(oH,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),d(rH,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),d(tH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),d(aH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),d(nH,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification"),d(sH,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),d(lH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),d(iH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),d(dH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),d(mH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),d(cH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),d(fH,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),d(gH,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),d(hH,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),d(uH,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),d(pH,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),d(_H,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),d(bH,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),d(vH,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),d(FH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),d(TH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),d(MH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),d(EH,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),d(CH,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),d(wH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),d(AH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),d(LH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),d(yH,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),d(xH,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),d(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qT,"id","transformers.AutoModelForMultipleChoice"),d(qT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(qT,"href","#transformers.AutoModelForMultipleChoice"),d(Bd,"class","relative group"),d($H,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(kH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(SH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(RH,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),d(PH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),d(BH,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),d(IH,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),d(NH,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),d(qH,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),d(jH,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),d(DH,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),d(GH,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),d(OH,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),d(VH,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),d(XH,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),d(zH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),d(QH,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),d(WH,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),d(UH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),d(HH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),d(JH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),d(YH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),d(KH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),d(ZH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),d(eJ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),d(oJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),d(rJ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),d(tJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),d(aJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),d(nJ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),d(sJ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),d(lJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),d(iJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),d(dJ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),d(mJ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),d(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(FM,"id","transformers.AutoModelForNextSentencePrediction"),d(FM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(FM,"href","#transformers.AutoModelForNextSentencePrediction"),d(qd,"class","relative group"),d(cJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(fJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(gJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),d(uJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),d(pJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),d(_J,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),d(bJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),d(vJ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),d(FJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),d(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(kM,"id","transformers.AutoModelForTokenClassification"),d(kM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(kM,"href","#transformers.AutoModelForTokenClassification"),d(Gd,"class","relative group"),d(TJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(MJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(EJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(CJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),d(wJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),d(AJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),d(LJ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),d(yJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),d(xJ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),d($J,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),d(kJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),d(SJ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),d(RJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),d(PJ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),d(BJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),d(IJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),d(NJ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification"),d(qJ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),d(jJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),d(DJ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),d(GJ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),d(OJ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),d(VJ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),d(XJ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),d(zJ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),d(QJ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),d(WJ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),d(UJ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification"),d(HJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),d(JJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),d(YJ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),d(KJ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),d(ZJ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),d(eY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),d(oY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),d(rY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),d(tY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),d(aY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),d(nY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),d(sY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),d(lY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),d(iY,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),d(dY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),d(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(TE,"id","transformers.AutoModelForQuestionAnswering"),d(TE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(TE,"href","#transformers.AutoModelForQuestionAnswering"),d(Xd,"class","relative group"),d(mY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(cY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(fY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gY,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),d(hY,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),d(uY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),d(pY,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),d(_Y,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),d(bY,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering"),d(vY,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),d(FY,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),d(TY,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),d(MY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),d(EY,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),d(CY,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),d(wY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),d(AY,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),d(LY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),d(yY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),d(xY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),d($Y,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),d(kY,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),d(SY,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),d(RY,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),d(PY,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),d(BY,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),d(IY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),d(NY,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),d(qY,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),d(jY,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering"),d(DY,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),d(GY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),d(OY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),d(VY,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),d(XY,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),d(zY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),d(QY,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),d(WY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),d(UY,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),d(HY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),d(JY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),d(YY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),d(KY,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),d(ZY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),d(eK,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),d(oK,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),d(rK,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),d(tK,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),d(aK,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),d(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_4,"id","transformers.AutoModelForTableQuestionAnswering"),d(_4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(_4,"href","#transformers.AutoModelForTableQuestionAnswering"),d(Wd,"class","relative group"),d(nK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(sK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(lK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(iK,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),d(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(M4,"id","transformers.AutoModelForDocumentQuestionAnswering"),d(M4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(M4,"href","#transformers.AutoModelForDocumentQuestionAnswering"),d(Jd,"class","relative group"),d(dK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(mK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(cK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(fK,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),d(gK,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),d(hK,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),d(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(x4,"id","transformers.AutoModelForImageClassification"),d(x4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(x4,"href","#transformers.AutoModelForImageClassification"),d(em,"class","relative group"),d(uK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(_K,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(bK,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),d(vK,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),d(FK,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),d(TK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),d(MK,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),d(EK,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),d(CK,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),d(wK,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),d(AK,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),d(LK,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),d(yK,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),d(xK,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),d($K,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),d(kK,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),d(SK,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),d(RK,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),d(PK,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),d(BK,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),d(IK,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),d(NK,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),d(qK,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),d(jK,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification"),d(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(U4,"id","transformers.AutoModelForVideoClassification"),d(U4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(U4,"href","#transformers.AutoModelForVideoClassification"),d(tm,"class","relative group"),d(DK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(GK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(OK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(VK,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),d(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Z4,"id","transformers.AutoModelForVision2Seq"),d(Z4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Z4,"href","#transformers.AutoModelForVision2Seq"),d(sm,"class","relative group"),d(XK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(zK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(QK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(WK,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),d(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(aC,"id","transformers.AutoModelForVisualQuestionAnswering"),d(aC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(aC,"href","#transformers.AutoModelForVisualQuestionAnswering"),d(dm,"class","relative group"),d(UK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(HK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(JK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(YK,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),d(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dC,"id","transformers.AutoModelForAudioClassification"),d(dC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(dC,"href","#transformers.AutoModelForAudioClassification"),d(fm,"class","relative group"),d(KK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ZK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(eZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(oZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),d(rZ,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),d(tZ,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),d(aZ,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),d(nZ,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),d(sZ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),d(lZ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),d(iZ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),d(dZ,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),d(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(MC,"id","transformers.AutoModelForAudioFrameClassification"),d(MC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(MC,"href","#transformers.AutoModelForAudioFrameClassification"),d(um,"class","relative group"),d(mZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(cZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(fZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),d(hZ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),d(uZ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),d(pZ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),d(_Z,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),d(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(kC,"id","transformers.AutoModelForCTC"),d(kC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(kC,"href","#transformers.AutoModelForCTC"),d(bm,"class","relative group"),d(bZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(vZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(FZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(TZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),d(MZ,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),d(EZ,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),d(CZ,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),d(wZ,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),d(AZ,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),d(LZ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),d(yZ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),d(xZ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),d($Z,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),d(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zC,"id","transformers.AutoModelForSpeechSeq2Seq"),d(zC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(zC,"href","#transformers.AutoModelForSpeechSeq2Seq"),d(Tm,"class","relative group"),d(kZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(SZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(RZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(PZ,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),d(BZ,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),d(IZ,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration"),d(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(KC,"id","transformers.AutoModelForAudioXVector"),d(KC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(KC,"href","#transformers.AutoModelForAudioXVector"),d(wm,"class","relative group"),d(NZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(qZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(jZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(DZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),d(GZ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),d(OZ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),d(VZ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),d(XZ,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),d(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(l3,"id","transformers.AutoModelForMaskedImageModeling"),d(l3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(l3,"href","#transformers.AutoModelForMaskedImageModeling"),d(ym,"class","relative group"),d(zZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(QZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(WZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(UZ,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),d(HZ,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),d(JZ,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),d(YZ,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),d(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(u3,"id","transformers.AutoModelForObjectDetection"),d(u3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(u3,"href","#transformers.AutoModelForObjectDetection"),d(km,"class","relative group"),d(KZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ZZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(eee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(oee,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection"),d(ree,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),d(tee,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),d(aee,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),d(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(E3,"id","transformers.AutoModelForImageSegmentation"),d(E3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(E3,"href","#transformers.AutoModelForImageSegmentation"),d(Pm,"class","relative group"),d(nee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(see,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(lee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(iee,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),d(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(y3,"id","transformers.AutoModelForSemanticSegmentation"),d(y3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(y3,"href","#transformers.AutoModelForSemanticSegmentation"),d(Nm,"class","relative group"),d(dee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(mee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(cee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(fee,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),d(gee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),d(hee,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),d(uee,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),d(pee,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),d(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(N3,"id","transformers.AutoModelForInstanceSegmentation"),d(N3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(N3,"href","#transformers.AutoModelForInstanceSegmentation"),d(Dm,"class","relative group"),d(_ee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(bee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(vee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fee,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),d(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(O3,"id","transformers.TFAutoModel"),d(O3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(O3,"href","#transformers.TFAutoModel"),d(Vm,"class","relative group"),d(Tee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Mee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Eee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Cee,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),d(wee,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),d(Aee,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),d(Lee,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),d(yee,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),d(xee,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),d($ee,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),d(kee,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),d(See,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),d(Ree,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),d(Pee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),d(Bee,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),d(Iee,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),d(Nee,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),d(qee,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),d(jee,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),d(Dee,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),d(Gee,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),d(Oee,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),d(Vee,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),d(Xee,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),d(zee,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),d(Qee,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel"),d(Wee,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),d(Uee,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),d(Hee,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),d(Jee,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),d(Yee,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),d(Kee,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),d(Zee,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),d(eoe,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),d(ooe,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),d(roe,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),d(toe,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),d(aoe,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),d(noe,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),d(soe,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),d(loe,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),d(ioe,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),d(doe,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),d(moe,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),d(coe,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),d(foe,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),d(goe,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),d(hoe,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),d(uoe,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),d(poe,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),d(_oe,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),d(boe,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),d(voe,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),d(Foe,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),d(Toe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),d(Moe,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),d(Eoe,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),d(Coe,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),d(woe,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),d(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(z5,"id","transformers.TFAutoModelForPreTraining"),d(z5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(z5,"href","#transformers.TFAutoModelForPreTraining"),d(Qm,"class","relative group"),d(Aoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Loe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(yoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xoe,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),d($oe,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(koe,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),d(Soe,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(Roe,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(Poe,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d(Boe,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),d(Ioe,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(Noe,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),d(qoe,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(joe,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(Doe,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),d(Goe,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),d(Ooe,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(Voe,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(Xoe,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(zoe,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(Qoe,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(Woe,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(Uoe,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),d(Hoe,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(Joe,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(Yoe,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_0,"id","transformers.TFAutoModelForCausalLM"),d(_0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(_0,"href","#transformers.TFAutoModelForCausalLM"),d(Hm,"class","relative group"),d(Koe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Zoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(ere,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ore,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),d(rre,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),d(tre,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(are,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(nre,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),d(sre,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(lre,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),d(ire,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),d(dre,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),d(mre,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),d(cre,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(fre,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),d(gre,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(hre,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(P0,"id","transformers.TFAutoModelForImageClassification"),d(P0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(P0,"href","#transformers.TFAutoModelForImageClassification"),d(Km,"class","relative group"),d(ure,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(_re,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(bre,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),d(vre,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),d(Fre,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),d(Tre,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),d(Mre,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),d(Ere,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),d(Cre,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),d(wre,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),d(Are,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),d(Lre,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),d(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(z0,"id","transformers.TFAutoModelForSemanticSegmentation"),d(z0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(z0,"href","#transformers.TFAutoModelForSemanticSegmentation"),d(oc,"class","relative group"),d(yre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(xre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d($re,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(kre,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),d(Sre,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),d(Rre,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),d(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Y0,"id","transformers.TFAutoModelForMaskedLM"),d(Y0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Y0,"href","#transformers.TFAutoModelForMaskedLM"),d(nc,"class","relative group"),d(Pre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Bre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ire,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Nre,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),d(qre,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),d(jre,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(Dre,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),d(Gre,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),d(Ore,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),d(Vre,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d(Xre,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),d(zre,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(Qre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),d(Wre,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(Ure,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),d(Hre,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),d(Jre,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(Yre,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),d(Kre,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(Zre,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),d(ete,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(ote,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(rte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fw,"id","transformers.TFAutoModelForSeq2SeqLM"),d(Fw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Fw,"href","#transformers.TFAutoModelForSeq2SeqLM"),d(ic,"class","relative group"),d(tte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ate,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(nte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ste,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(lte,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),d(ite,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),d(dte,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),d(mte,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),d(cte,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),d(fte,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),d(gte,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),d(hte,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),d(ute,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Rw,"id","transformers.TFAutoModelForSequenceClassification"),d(Rw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Rw,"href","#transformers.TFAutoModelForSequenceClassification"),d(cc,"class","relative group"),d(pte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_te,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(bte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vte,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),d(Fte,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),d(Tte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),d(Mte,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),d(Ete,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),d(Cte,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),d(wte,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),d(Ate,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),d(Lte,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),d(yte,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),d(xte,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),d($te,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),d(kte,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),d(Ste,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),d(Rte,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),d(Pte,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),d(Bte,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),d(Ite,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),d(Nte,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),d(qte,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),d(jte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),d(Dte,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),d(Gte,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),d(Ote,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),d(Vte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),d(Xte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),d(zte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),d(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dA,"id","transformers.TFAutoModelForMultipleChoice"),d(dA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(dA,"href","#transformers.TFAutoModelForMultipleChoice"),d(hc,"class","relative group"),d(Qte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Wte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ute,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Hte,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),d(Jte,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),d(Yte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),d(Kte,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),d(Zte,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),d(eae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),d(oae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),d(rae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),d(tae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),d(aae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),d(nae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),d(sae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),d(lae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),d(iae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),d(dae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),d(mae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),d(cae,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),d(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xA,"id","transformers.TFAutoModelForNextSentencePrediction"),d(xA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(xA,"href","#transformers.TFAutoModelForNextSentencePrediction"),d(_c,"class","relative group"),d(fae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(gae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(hae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(uae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),d(pae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),d(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(PA,"id","transformers.TFAutoModelForTableQuestionAnswering"),d(PA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(PA,"href","#transformers.TFAutoModelForTableQuestionAnswering"),d(Fc,"class","relative group"),d(_ae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(bae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(vae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fae,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),d(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qA,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),d(qA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(qA,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),d(Ec,"class","relative group"),d(Tae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Mae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Eae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Cae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),d(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(OA,"id","transformers.TFAutoModelForTokenClassification"),d(OA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(OA,"href","#transformers.TFAutoModelForTokenClassification"),d(Ac,"class","relative group"),d(wae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Aae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Lae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),d(xae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),d($ae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),d(kae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),d(Sae,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),d(Rae,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),d(Pae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),d(Bae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),d(Iae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),d(Nae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),d(qae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),d(jae,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),d(Dae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),d(Gae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),d(Oae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),d(Vae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),d(Xae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),d(zae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),d(Qae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),d(Wae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),d(Uae,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),d(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(f6,"id","transformers.TFAutoModelForQuestionAnswering"),d(f6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(f6,"href","#transformers.TFAutoModelForQuestionAnswering"),d(xc,"class","relative group"),d(Hae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Jae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Yae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Kae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),d(Zae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),d(ene,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),d(one,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),d(rne,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),d(tne,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),d(ane,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),d(nne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),d(sne,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),d(lne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),d(ine,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),d(dne,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),d(mne,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),d(cne,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),d(fne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),d(gne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),d(hne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),d(une,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),d(pne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),d(_ne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),d(bne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),d(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(I6,"id","transformers.TFAutoModelForVision2Seq"),d(I6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(I6,"href","#transformers.TFAutoModelForVision2Seq"),d(Sc,"class","relative group"),d(vne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Fne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Tne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Mne,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),d(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(D6,"id","transformers.TFAutoModelForSpeechSeq2Seq"),d(D6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(D6,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),d(Bc,"class","relative group"),d(Ene,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Cne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(wne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ane,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),d(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(X6,"id","transformers.FlaxAutoModel"),d(X6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(X6,"href","#transformers.FlaxAutoModel"),d(qc,"class","relative group"),d(Lne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(xne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($ne,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),d(kne,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),d(Sne,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),d(Rne,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),d(Pne,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),d(Bne,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),d(Ine,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),d(Nne,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),d(qne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),d(jne,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),d(Dne,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),d(Gne,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),d(One,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),d(Vne,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),d(Xne,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),d(zne,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),d(Qne,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),d(Wne,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),d(Une,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),d(Hne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),d(Jne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),d(Yne,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),d(Kne,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),d(Zne,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),d(ese,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),d(ose,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),d(rse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),d(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(F7,"id","transformers.FlaxAutoModelForCausalLM"),d(F7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(F7,"href","#transformers.FlaxAutoModelForCausalLM"),d(Gc,"class","relative group"),d(tse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ase,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(nse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sse,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),d(lse,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),d(ise,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),d(dse,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),d(mse,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),d(cse,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),d(fse,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),d(gse,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),d(hse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),d(use,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),d(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(R7,"id","transformers.FlaxAutoModelForPreTraining"),d(R7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(R7,"href","#transformers.FlaxAutoModelForPreTraining"),d(Xc,"class","relative group"),d(pse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_se,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(bse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vse,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),d(Fse,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(Tse,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),d(Mse,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),d(Ese,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),d(Cse,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),d(wse,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(Ase,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(Lse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(yse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(xse,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d($se,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),d(kse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(H7,"id","transformers.FlaxAutoModelForMaskedLM"),d(H7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(H7,"href","#transformers.FlaxAutoModelForMaskedLM"),d(Wc,"class","relative group"),d(Sse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Rse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Pse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Bse,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),d(Ise,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(Nse,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),d(qse,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),d(jse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),d(Dse,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),d(Gse,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(Ose,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(Vse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(Xse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(iL,"id","transformers.FlaxAutoModelForSeq2SeqLM"),d(iL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(iL,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),d(Jc,"class","relative group"),d(zse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Qse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Wse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Use,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(Hse,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),d(Jse,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),d(Yse,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),d(Kse,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),d(Zse,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),d(ele,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(ole,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(rle,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),d(tle,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(TL,"id","transformers.FlaxAutoModelForSequenceClassification"),d(TL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(TL,"href","#transformers.FlaxAutoModelForSequenceClassification"),d(Zc,"class","relative group"),d(ale,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(nle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(sle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lle,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),d(ile,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),d(dle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),d(mle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),d(cle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),d(fle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),d(gle,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),d(hle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),d(ule,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),d(ple,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),d(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(PL,"id","transformers.FlaxAutoModelForQuestionAnswering"),d(PL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(PL,"href","#transformers.FlaxAutoModelForQuestionAnswering"),d(rf,"class","relative group"),d(_le,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ble,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(vle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fle,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),d(Tle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),d(Mle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),d(Ele,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),d(Cle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),d(wle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),d(Ale,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),d(Lle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),d(yle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),d(xle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),d(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(WL,"id","transformers.FlaxAutoModelForTokenClassification"),d(WL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(WL,"href","#transformers.FlaxAutoModelForTokenClassification"),d(nf,"class","relative group"),d($le,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(kle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Sle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Rle,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),d(Ple,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),d(Ble,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),d(Ile,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),d(Nle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),d(qle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),d(jle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),d(Dle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),d(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ay,"id","transformers.FlaxAutoModelForMultipleChoice"),d(ay,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ay,"href","#transformers.FlaxAutoModelForMultipleChoice"),d(df,"class","relative group"),d(Gle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ole,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Vle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Xle,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),d(zle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),d(Qle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),d(Wle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),d(Ule,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),d(Hle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),d(Jle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),d(Yle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),d(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(uy,"id","transformers.FlaxAutoModelForNextSentencePrediction"),d(uy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(uy,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),d(ff,"class","relative group"),d(Kle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Zle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(eie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(oie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),d(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vy,"id","transformers.FlaxAutoModelForImageClassification"),d(vy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(vy,"href","#transformers.FlaxAutoModelForImageClassification"),d(uf,"class","relative group"),d(rie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(tie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(aie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nie,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),d(sie,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),d(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Cy,"id","transformers.FlaxAutoModelForVision2Seq"),d(Cy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Cy,"href","#transformers.FlaxAutoModelForVision2Seq"),d(bf,"class","relative group"),d(lie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(iie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(die,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mie,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),d(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(c,_){e(document.head,g),b(c,v,_),b(c,u,_),e(u,f),e(f,p),M(m,p,null),e(u,h),e(u,yo),e(yo,td),b(c,Cf,_),b(c,pt,_),e(pt,ad),e(pt,nd),e(nd,ax),e(pt,wf),b(c,Ve,_),b(c,He,_),e(He,sd),e(He,es),e(es,nx),e(He,os),e(He,rs),e(rs,sx),e(He,ld),e(He,ts),e(ts,lx),e(He,id),b(c,Af,_),M(Qa,c,_),b(c,Je,_),b(c,Ae,_),e(Ae,lI),e(Ae,dd),e(dd,iI),e(Ae,dI),b(c,xo,_),b(c,Wa,_),e(Wa,mI),e(Wa,Lf),e(Lf,cI),e(Wa,Xao),b(c,ueo,_),b(c,md,_),e(md,yf),e(yf,ume),M(ix,ume,null),e(md,zao),e(md,pme),e(pme,Qao),b(c,peo,_),b(c,as,_),e(as,Wao),e(as,_me),e(_me,Uao),e(as,Hao),e(as,bme),e(bme,Jao),e(as,Yao),b(c,_eo,_),M(dx,c,_),b(c,beo,_),b(c,fI,_),e(fI,Kao),b(c,veo,_),M(xf,c,_),b(c,Feo,_),b(c,cd,_),e(cd,$f),e($f,vme),M(mx,vme,null),e(cd,Zao),e(cd,Fme),e(Fme,eno),b(c,Teo,_),b(c,$o,_),M(cx,$o,null),e($o,ono),e($o,fx),e(fx,rno),e(fx,gI),e(gI,tno),e(fx,ano),e($o,nno),e($o,gx),e(gx,sno),e(gx,Tme),e(Tme,lno),e(gx,ino),e($o,dno),e($o,Pr),M(hx,Pr,null),e(Pr,mno),e(Pr,Mme),e(Mme,cno),e(Pr,fno),e(Pr,fd),e(fd,gno),e(fd,Eme),e(Eme,hno),e(fd,uno),e(fd,Cme),e(Cme,pno),e(fd,_no),e(Pr,bno),e(Pr,A),e(A,kf),e(kf,wme),e(wme,vno),e(kf,Fno),e(kf,hI),e(hI,Tno),e(kf,Mno),e(A,Eno),e(A,Sf),e(Sf,Ame),e(Ame,Cno),e(Sf,wno),e(Sf,uI),e(uI,Ano),e(Sf,Lno),e(A,yno),e(A,Rf),e(Rf,Lme),e(Lme,xno),e(Rf,$no),e(Rf,pI),e(pI,kno),e(Rf,Sno),e(A,Rno),e(A,Pf),e(Pf,yme),e(yme,Pno),e(Pf,Bno),e(Pf,_I),e(_I,Ino),e(Pf,Nno),e(A,qno),e(A,Bf),e(Bf,xme),e(xme,jno),e(Bf,Dno),e(Bf,bI),e(bI,Gno),e(Bf,Ono),e(A,Vno),e(A,If),e(If,$me),e($me,Xno),e(If,zno),e(If,vI),e(vI,Qno),e(If,Wno),e(A,Uno),e(A,Nf),e(Nf,kme),e(kme,Hno),e(Nf,Jno),e(Nf,FI),e(FI,Yno),e(Nf,Kno),e(A,Zno),e(A,qf),e(qf,Sme),e(Sme,eso),e(qf,oso),e(qf,TI),e(TI,rso),e(qf,tso),e(A,aso),e(A,jf),e(jf,Rme),e(Rme,nso),e(jf,sso),e(jf,MI),e(MI,lso),e(jf,iso),e(A,dso),e(A,Df),e(Df,Pme),e(Pme,mso),e(Df,cso),e(Df,EI),e(EI,fso),e(Df,gso),e(A,hso),e(A,Gf),e(Gf,Bme),e(Bme,uso),e(Gf,pso),e(Gf,CI),e(CI,_so),e(Gf,bso),e(A,vso),e(A,Of),e(Of,Ime),e(Ime,Fso),e(Of,Tso),e(Of,wI),e(wI,Mso),e(Of,Eso),e(A,Cso),e(A,Vf),e(Vf,Nme),e(Nme,wso),e(Vf,Aso),e(Vf,AI),e(AI,Lso),e(Vf,yso),e(A,xso),e(A,Xf),e(Xf,qme),e(qme,$so),e(Xf,kso),e(Xf,LI),e(LI,Sso),e(Xf,Rso),e(A,Pso),e(A,zf),e(zf,jme),e(jme,Bso),e(zf,Iso),e(zf,yI),e(yI,Nso),e(zf,qso),e(A,jso),e(A,Qf),e(Qf,Dme),e(Dme,Dso),e(Qf,Gso),e(Qf,xI),e(xI,Oso),e(Qf,Vso),e(A,Xso),e(A,Wf),e(Wf,Gme),e(Gme,zso),e(Wf,Qso),e(Wf,$I),e($I,Wso),e(Wf,Uso),e(A,Hso),e(A,Uf),e(Uf,Ome),e(Ome,Jso),e(Uf,Yso),e(Uf,kI),e(kI,Kso),e(Uf,Zso),e(A,elo),e(A,Hf),e(Hf,Vme),e(Vme,olo),e(Hf,rlo),e(Hf,SI),e(SI,tlo),e(Hf,alo),e(A,nlo),e(A,Jf),e(Jf,Xme),e(Xme,slo),e(Jf,llo),e(Jf,RI),e(RI,ilo),e(Jf,dlo),e(A,mlo),e(A,Yf),e(Yf,zme),e(zme,clo),e(Yf,flo),e(Yf,PI),e(PI,glo),e(Yf,hlo),e(A,ulo),e(A,Kf),e(Kf,Qme),e(Qme,plo),e(Kf,_lo),e(Kf,BI),e(BI,blo),e(Kf,vlo),e(A,Flo),e(A,Zf),e(Zf,Wme),e(Wme,Tlo),e(Zf,Mlo),e(Zf,II),e(II,Elo),e(Zf,Clo),e(A,wlo),e(A,eg),e(eg,Ume),e(Ume,Alo),e(eg,Llo),e(eg,NI),e(NI,ylo),e(eg,xlo),e(A,$lo),e(A,og),e(og,Hme),e(Hme,klo),e(og,Slo),e(og,qI),e(qI,Rlo),e(og,Plo),e(A,Blo),e(A,rg),e(rg,Jme),e(Jme,Ilo),e(rg,Nlo),e(rg,jI),e(jI,qlo),e(rg,jlo),e(A,Dlo),e(A,tg),e(tg,Yme),e(Yme,Glo),e(tg,Olo),e(tg,DI),e(DI,Vlo),e(tg,Xlo),e(A,zlo),e(A,ag),e(ag,Kme),e(Kme,Qlo),e(ag,Wlo),e(ag,GI),e(GI,Ulo),e(ag,Hlo),e(A,Jlo),e(A,ng),e(ng,Zme),e(Zme,Ylo),e(ng,Klo),e(ng,OI),e(OI,Zlo),e(ng,eio),e(A,oio),e(A,sg),e(sg,ece),e(ece,rio),e(sg,tio),e(sg,VI),e(VI,aio),e(sg,nio),e(A,sio),e(A,lg),e(lg,oce),e(oce,lio),e(lg,iio),e(lg,XI),e(XI,dio),e(lg,mio),e(A,cio),e(A,ig),e(ig,rce),e(rce,fio),e(ig,gio),e(ig,zI),e(zI,hio),e(ig,uio),e(A,pio),e(A,dg),e(dg,tce),e(tce,_io),e(dg,bio),e(dg,QI),e(QI,vio),e(dg,Fio),e(A,Tio),e(A,mg),e(mg,ace),e(ace,Mio),e(mg,Eio),e(mg,WI),e(WI,Cio),e(mg,wio),e(A,Aio),e(A,cg),e(cg,nce),e(nce,Lio),e(cg,yio),e(cg,UI),e(UI,xio),e(cg,$io),e(A,kio),e(A,fg),e(fg,sce),e(sce,Sio),e(fg,Rio),e(fg,HI),e(HI,Pio),e(fg,Bio),e(A,Iio),e(A,gg),e(gg,lce),e(lce,Nio),e(gg,qio),e(gg,JI),e(JI,jio),e(gg,Dio),e(A,Gio),e(A,hg),e(hg,ice),e(ice,Oio),e(hg,Vio),e(hg,YI),e(YI,Xio),e(hg,zio),e(A,Qio),e(A,ug),e(ug,dce),e(dce,Wio),e(ug,Uio),e(ug,KI),e(KI,Hio),e(ug,Jio),e(A,Yio),e(A,pg),e(pg,mce),e(mce,Kio),e(pg,Zio),e(pg,ZI),e(ZI,edo),e(pg,odo),e(A,rdo),e(A,_g),e(_g,cce),e(cce,tdo),e(_g,ado),e(_g,eN),e(eN,ndo),e(_g,sdo),e(A,ldo),e(A,bg),e(bg,fce),e(fce,ido),e(bg,ddo),e(bg,oN),e(oN,mdo),e(bg,cdo),e(A,fdo),e(A,vg),e(vg,gce),e(gce,gdo),e(vg,hdo),e(vg,rN),e(rN,udo),e(vg,pdo),e(A,_do),e(A,Fg),e(Fg,hce),e(hce,bdo),e(Fg,vdo),e(Fg,tN),e(tN,Fdo),e(Fg,Tdo),e(A,Mdo),e(A,Tg),e(Tg,uce),e(uce,Edo),e(Tg,Cdo),e(Tg,aN),e(aN,wdo),e(Tg,Ado),e(A,Ldo),e(A,Mg),e(Mg,pce),e(pce,ydo),e(Mg,xdo),e(Mg,nN),e(nN,$do),e(Mg,kdo),e(A,Sdo),e(A,Eg),e(Eg,_ce),e(_ce,Rdo),e(Eg,Pdo),e(Eg,sN),e(sN,Bdo),e(Eg,Ido),e(A,Ndo),e(A,Cg),e(Cg,bce),e(bce,qdo),e(Cg,jdo),e(Cg,lN),e(lN,Ddo),e(Cg,Gdo),e(A,Odo),e(A,wg),e(wg,vce),e(vce,Vdo),e(wg,Xdo),e(wg,iN),e(iN,zdo),e(wg,Qdo),e(A,Wdo),e(A,Ag),e(Ag,Fce),e(Fce,Udo),e(Ag,Hdo),e(Ag,dN),e(dN,Jdo),e(Ag,Ydo),e(A,Kdo),e(A,Lg),e(Lg,Tce),e(Tce,Zdo),e(Lg,emo),e(Lg,mN),e(mN,omo),e(Lg,rmo),e(A,tmo),e(A,yg),e(yg,Mce),e(Mce,amo),e(yg,nmo),e(yg,cN),e(cN,smo),e(yg,lmo),e(A,imo),e(A,xg),e(xg,Ece),e(Ece,dmo),e(xg,mmo),e(xg,fN),e(fN,cmo),e(xg,fmo),e(A,gmo),e(A,$g),e($g,Cce),e(Cce,hmo),e($g,umo),e($g,gN),e(gN,pmo),e($g,_mo),e(A,bmo),e(A,kg),e(kg,wce),e(wce,vmo),e(kg,Fmo),e(kg,hN),e(hN,Tmo),e(kg,Mmo),e(A,Emo),e(A,Sg),e(Sg,Ace),e(Ace,Cmo),e(Sg,wmo),e(Sg,uN),e(uN,Amo),e(Sg,Lmo),e(A,ymo),e(A,Rg),e(Rg,Lce),e(Lce,xmo),e(Rg,$mo),e(Rg,pN),e(pN,kmo),e(Rg,Smo),e(A,Rmo),e(A,Pg),e(Pg,yce),e(yce,Pmo),e(Pg,Bmo),e(Pg,_N),e(_N,Imo),e(Pg,Nmo),e(A,qmo),e(A,Bg),e(Bg,xce),e(xce,jmo),e(Bg,Dmo),e(Bg,bN),e(bN,Gmo),e(Bg,Omo),e(A,Vmo),e(A,Ig),e(Ig,$ce),e($ce,Xmo),e(Ig,zmo),e(Ig,vN),e(vN,Qmo),e(Ig,Wmo),e(A,Umo),e(A,Ng),e(Ng,kce),e(kce,Hmo),e(Ng,Jmo),e(Ng,FN),e(FN,Ymo),e(Ng,Kmo),e(A,Zmo),e(A,qg),e(qg,Sce),e(Sce,eco),e(qg,oco),e(qg,TN),e(TN,rco),e(qg,tco),e(A,aco),e(A,jg),e(jg,Rce),e(Rce,nco),e(jg,sco),e(jg,MN),e(MN,lco),e(jg,ico),e(A,dco),e(A,Dg),e(Dg,Pce),e(Pce,mco),e(Dg,cco),e(Dg,EN),e(EN,fco),e(Dg,gco),e(A,hco),e(A,Gg),e(Gg,Bce),e(Bce,uco),e(Gg,pco),e(Gg,CN),e(CN,_co),e(Gg,bco),e(A,vco),e(A,Og),e(Og,Ice),e(Ice,Fco),e(Og,Tco),e(Og,wN),e(wN,Mco),e(Og,Eco),e(A,Cco),e(A,Vg),e(Vg,Nce),e(Nce,wco),e(Vg,Aco),e(Vg,AN),e(AN,Lco),e(Vg,yco),e(A,xco),e(A,Xg),e(Xg,qce),e(qce,$co),e(Xg,kco),e(Xg,LN),e(LN,Sco),e(Xg,Rco),e(A,Pco),e(A,zg),e(zg,jce),e(jce,Bco),e(zg,Ico),e(zg,yN),e(yN,Nco),e(zg,qco),e(A,jco),e(A,Qg),e(Qg,Dce),e(Dce,Dco),e(Qg,Gco),e(Qg,xN),e(xN,Oco),e(Qg,Vco),e(A,Xco),e(A,Wg),e(Wg,Gce),e(Gce,zco),e(Wg,Qco),e(Wg,$N),e($N,Wco),e(Wg,Uco),e(A,Hco),e(A,Ug),e(Ug,Oce),e(Oce,Jco),e(Ug,Yco),e(Ug,kN),e(kN,Kco),e(Ug,Zco),e(A,efo),e(A,Hg),e(Hg,Vce),e(Vce,ofo),e(Hg,rfo),e(Hg,SN),e(SN,tfo),e(Hg,afo),e(A,nfo),e(A,Jg),e(Jg,Xce),e(Xce,sfo),e(Jg,lfo),e(Jg,RN),e(RN,ifo),e(Jg,dfo),e(A,mfo),e(A,Yg),e(Yg,zce),e(zce,cfo),e(Yg,ffo),e(Yg,PN),e(PN,gfo),e(Yg,hfo),e(A,ufo),e(A,Kg),e(Kg,Qce),e(Qce,pfo),e(Kg,_fo),e(Kg,BN),e(BN,bfo),e(Kg,vfo),e(A,Ffo),e(A,Zg),e(Zg,Wce),e(Wce,Tfo),e(Zg,Mfo),e(Zg,IN),e(IN,Efo),e(Zg,Cfo),e(A,wfo),e(A,eh),e(eh,Uce),e(Uce,Afo),e(eh,Lfo),e(eh,NN),e(NN,yfo),e(eh,xfo),e(A,$fo),e(A,oh),e(oh,Hce),e(Hce,kfo),e(oh,Sfo),e(oh,qN),e(qN,Rfo),e(oh,Pfo),e(A,Bfo),e(A,rh),e(rh,Jce),e(Jce,Ifo),e(rh,Nfo),e(rh,jN),e(jN,qfo),e(rh,jfo),e(A,Dfo),e(A,th),e(th,Yce),e(Yce,Gfo),e(th,Ofo),e(th,DN),e(DN,Vfo),e(th,Xfo),e(A,zfo),e(A,ah),e(ah,Kce),e(Kce,Qfo),e(ah,Wfo),e(ah,GN),e(GN,Ufo),e(ah,Hfo),e(A,Jfo),e(A,nh),e(nh,Zce),e(Zce,Yfo),e(nh,Kfo),e(nh,ON),e(ON,Zfo),e(nh,ego),e(A,ogo),e(A,sh),e(sh,efe),e(efe,rgo),e(sh,tgo),e(sh,VN),e(VN,ago),e(sh,ngo),e(A,sgo),e(A,lh),e(lh,ofe),e(ofe,lgo),e(lh,igo),e(lh,XN),e(XN,dgo),e(lh,mgo),e(A,cgo),e(A,ih),e(ih,rfe),e(rfe,fgo),e(ih,ggo),e(ih,zN),e(zN,hgo),e(ih,ugo),e(A,pgo),e(A,dh),e(dh,tfe),e(tfe,_go),e(dh,bgo),e(dh,QN),e(QN,vgo),e(dh,Fgo),e(A,Tgo),e(A,mh),e(mh,afe),e(afe,Mgo),e(mh,Ego),e(mh,WN),e(WN,Cgo),e(mh,wgo),e(A,Ago),e(A,ch),e(ch,nfe),e(nfe,Lgo),e(ch,ygo),e(ch,UN),e(UN,xgo),e(ch,$go),e(A,kgo),e(A,fh),e(fh,sfe),e(sfe,Sgo),e(fh,Rgo),e(fh,HN),e(HN,Pgo),e(fh,Bgo),e(A,Igo),e(A,gh),e(gh,lfe),e(lfe,Ngo),e(gh,qgo),e(gh,JN),e(JN,jgo),e(gh,Dgo),e(A,Ggo),e(A,hh),e(hh,ife),e(ife,Ogo),e(hh,Vgo),e(hh,YN),e(YN,Xgo),e(hh,zgo),e(A,Qgo),e(A,uh),e(uh,dfe),e(dfe,Wgo),e(uh,Ugo),e(uh,KN),e(KN,Hgo),e(uh,Jgo),e(A,Ygo),e(A,ph),e(ph,mfe),e(mfe,Kgo),e(ph,Zgo),e(ph,ZN),e(ZN,eho),e(ph,oho),e(A,rho),e(A,_h),e(_h,cfe),e(cfe,tho),e(_h,aho),e(_h,eq),e(eq,nho),e(_h,sho),e(A,lho),e(A,bh),e(bh,ffe),e(ffe,iho),e(bh,dho),e(bh,oq),e(oq,mho),e(bh,cho),e(A,fho),e(A,vh),e(vh,gfe),e(gfe,gho),e(vh,hho),e(vh,rq),e(rq,uho),e(vh,pho),e(A,_ho),e(A,Fh),e(Fh,hfe),e(hfe,bho),e(Fh,vho),e(Fh,tq),e(tq,Fho),e(Fh,Tho),e(A,Mho),e(A,Th),e(Th,ufe),e(ufe,Eho),e(Th,Cho),e(Th,aq),e(aq,who),e(Th,Aho),e(A,Lho),e(A,Mh),e(Mh,pfe),e(pfe,yho),e(Mh,xho),e(Mh,nq),e(nq,$ho),e(Mh,kho),e(A,Sho),e(A,Eh),e(Eh,_fe),e(_fe,Rho),e(Eh,Pho),e(Eh,sq),e(sq,Bho),e(Eh,Iho),e(A,Nho),e(A,Ch),e(Ch,bfe),e(bfe,qho),e(Ch,jho),e(Ch,lq),e(lq,Dho),e(Ch,Gho),e(A,Oho),e(A,wh),e(wh,vfe),e(vfe,Vho),e(wh,Xho),e(wh,iq),e(iq,zho),e(wh,Qho),e(A,Who),e(A,Ah),e(Ah,Ffe),e(Ffe,Uho),e(Ah,Hho),e(Ah,dq),e(dq,Jho),e(Ah,Yho),e(A,Kho),e(A,Lh),e(Lh,Tfe),e(Tfe,Zho),e(Lh,euo),e(Lh,mq),e(mq,ouo),e(Lh,ruo),e(A,tuo),e(A,yh),e(yh,Mfe),e(Mfe,auo),e(yh,nuo),e(yh,cq),e(cq,suo),e(yh,luo),e(A,iuo),e(A,xh),e(xh,Efe),e(Efe,duo),e(xh,muo),e(xh,fq),e(fq,cuo),e(xh,fuo),e(A,guo),e(A,$h),e($h,Cfe),e(Cfe,huo),e($h,uuo),e($h,gq),e(gq,puo),e($h,_uo),e(A,buo),e(A,kh),e(kh,wfe),e(wfe,vuo),e(kh,Fuo),e(kh,hq),e(hq,Tuo),e(kh,Muo),e(A,Euo),e(A,Sh),e(Sh,Afe),e(Afe,Cuo),e(Sh,wuo),e(Sh,uq),e(uq,Auo),e(Sh,Luo),e(A,yuo),e(A,Rh),e(Rh,Lfe),e(Lfe,xuo),e(Rh,$uo),e(Rh,pq),e(pq,kuo),e(Rh,Suo),e(A,Ruo),e(A,Ph),e(Ph,yfe),e(yfe,Puo),e(Ph,Buo),e(Ph,_q),e(_q,Iuo),e(Ph,Nuo),e(A,quo),e(A,Bh),e(Bh,xfe),e(xfe,juo),e(Bh,Duo),e(Bh,bq),e(bq,Guo),e(Bh,Ouo),e(A,Vuo),e(A,Ih),e(Ih,$fe),e($fe,Xuo),e(Ih,zuo),e(Ih,vq),e(vq,Quo),e(Ih,Wuo),e(A,Uuo),e(A,Nh),e(Nh,kfe),e(kfe,Huo),e(Nh,Juo),e(Nh,Fq),e(Fq,Yuo),e(Nh,Kuo),e(A,Zuo),e(A,qh),e(qh,Sfe),e(Sfe,epo),e(qh,opo),e(qh,Tq),e(Tq,rpo),e(qh,tpo),e(A,apo),e(A,jh),e(jh,Rfe),e(Rfe,npo),e(jh,spo),e(jh,Mq),e(Mq,lpo),e(jh,ipo),e(A,dpo),e(A,Dh),e(Dh,Pfe),e(Pfe,mpo),e(Dh,cpo),e(Dh,Eq),e(Eq,fpo),e(Dh,gpo),e(A,hpo),e(A,Gh),e(Gh,Bfe),e(Bfe,upo),e(Gh,ppo),e(Gh,Cq),e(Cq,_po),e(Gh,bpo),e(A,vpo),e(A,Oh),e(Oh,Ife),e(Ife,Fpo),e(Oh,Tpo),e(Oh,wq),e(wq,Mpo),e(Oh,Epo),e(A,Cpo),e(A,Vh),e(Vh,Nfe),e(Nfe,wpo),e(Vh,Apo),e(Vh,Aq),e(Aq,Lpo),e(Vh,ypo),e(A,xpo),e(A,Xh),e(Xh,qfe),e(qfe,$po),e(Xh,kpo),e(Xh,Lq),e(Lq,Spo),e(Xh,Rpo),e(A,Ppo),e(A,zh),e(zh,jfe),e(jfe,Bpo),e(zh,Ipo),e(zh,yq),e(yq,Npo),e(zh,qpo),e(A,jpo),e(A,Qh),e(Qh,Dfe),e(Dfe,Dpo),e(Qh,Gpo),e(Qh,xq),e(xq,Opo),e(Qh,Vpo),e(A,Xpo),e(A,Wh),e(Wh,Gfe),e(Gfe,zpo),e(Wh,Qpo),e(Wh,$q),e($q,Wpo),e(Wh,Upo),e(A,Hpo),e(A,Uh),e(Uh,Ofe),e(Ofe,Jpo),e(Uh,Ypo),e(Uh,kq),e(kq,Kpo),e(Uh,Zpo),e(A,e_o),e(A,Hh),e(Hh,Vfe),e(Vfe,o_o),e(Hh,r_o),e(Hh,Sq),e(Sq,t_o),e(Hh,a_o),e(A,n_o),e(A,Jh),e(Jh,Xfe),e(Xfe,s_o),e(Jh,l_o),e(Jh,Rq),e(Rq,i_o),e(Jh,d_o),e(A,m_o),e(A,Yh),e(Yh,zfe),e(zfe,c_o),e(Yh,f_o),e(Yh,Pq),e(Pq,g_o),e(Yh,h_o),e(A,u_o),e(A,Kh),e(Kh,Qfe),e(Qfe,p_o),e(Kh,__o),e(Kh,Bq),e(Bq,b_o),e(Kh,v_o),e(A,F_o),e(A,Zh),e(Zh,Wfe),e(Wfe,T_o),e(Zh,M_o),e(Zh,Iq),e(Iq,E_o),e(Zh,C_o),e(A,w_o),e(A,eu),e(eu,Ufe),e(Ufe,A_o),e(eu,L_o),e(eu,Nq),e(Nq,y_o),e(eu,x_o),e(A,$_o),e(A,ou),e(ou,Hfe),e(Hfe,k_o),e(ou,S_o),e(ou,qq),e(qq,R_o),e(ou,P_o),e(Pr,B_o),M(ru,Pr,null),e($o,I_o),e($o,tu),M(ux,tu,null),e(tu,N_o),e(tu,Jfe),e(Jfe,q_o),b(c,Meo,_),b(c,gd,_),e(gd,au),e(au,Yfe),M(px,Yfe,null),e(gd,j_o),e(gd,Kfe),e(Kfe,D_o),b(c,Eeo,_),b(c,ko,_),M(_x,ko,null),e(ko,G_o),e(ko,bx),e(bx,O_o),e(bx,jq),e(jq,V_o),e(bx,X_o),e(ko,z_o),e(ko,vx),e(vx,Q_o),e(vx,Zfe),e(Zfe,W_o),e(vx,U_o),e(ko,H_o),e(ko,Br),M(Fx,Br,null),e(Br,J_o),e(Br,ege),e(ege,Y_o),e(Br,K_o),e(Br,Ua),e(Ua,Z_o),e(Ua,oge),e(oge,e1o),e(Ua,o1o),e(Ua,rge),e(rge,r1o),e(Ua,t1o),e(Ua,tge),e(tge,a1o),e(Ua,n1o),e(Br,s1o),e(Br,k),e(k,ns),e(ns,age),e(age,l1o),e(ns,i1o),e(ns,Dq),e(Dq,d1o),e(ns,m1o),e(ns,Gq),e(Gq,c1o),e(ns,f1o),e(k,g1o),e(k,ss),e(ss,nge),e(nge,h1o),e(ss,u1o),e(ss,Oq),e(Oq,p1o),e(ss,_1o),e(ss,Vq),e(Vq,b1o),e(ss,v1o),e(k,F1o),e(k,ls),e(ls,sge),e(sge,T1o),e(ls,M1o),e(ls,Xq),e(Xq,E1o),e(ls,C1o),e(ls,zq),e(zq,w1o),e(ls,A1o),e(k,L1o),e(k,nu),e(nu,lge),e(lge,y1o),e(nu,x1o),e(nu,Qq),e(Qq,$1o),e(nu,k1o),e(k,S1o),e(k,is),e(is,ige),e(ige,R1o),e(is,P1o),e(is,Wq),e(Wq,B1o),e(is,I1o),e(is,Uq),e(Uq,N1o),e(is,q1o),e(k,j1o),e(k,su),e(su,dge),e(dge,D1o),e(su,G1o),e(su,Hq),e(Hq,O1o),e(su,V1o),e(k,X1o),e(k,lu),e(lu,mge),e(mge,z1o),e(lu,Q1o),e(lu,Jq),e(Jq,W1o),e(lu,U1o),e(k,H1o),e(k,iu),e(iu,cge),e(cge,J1o),e(iu,Y1o),e(iu,Yq),e(Yq,K1o),e(iu,Z1o),e(k,e2o),e(k,ds),e(ds,fge),e(fge,o2o),e(ds,r2o),e(ds,Kq),e(Kq,t2o),e(ds,a2o),e(ds,Zq),e(Zq,n2o),e(ds,s2o),e(k,l2o),e(k,ms),e(ms,gge),e(gge,i2o),e(ms,d2o),e(ms,ej),e(ej,m2o),e(ms,c2o),e(ms,oj),e(oj,f2o),e(ms,g2o),e(k,h2o),e(k,cs),e(cs,hge),e(hge,u2o),e(cs,p2o),e(cs,rj),e(rj,_2o),e(cs,b2o),e(cs,tj),e(tj,v2o),e(cs,F2o),e(k,T2o),e(k,du),e(du,uge),e(uge,M2o),e(du,E2o),e(du,aj),e(aj,C2o),e(du,w2o),e(k,A2o),e(k,mu),e(mu,pge),e(pge,L2o),e(mu,y2o),e(mu,nj),e(nj,x2o),e(mu,$2o),e(k,k2o),e(k,cu),e(cu,_ge),e(_ge,S2o),e(cu,R2o),e(cu,sj),e(sj,P2o),e(cu,B2o),e(k,I2o),e(k,fs),e(fs,bge),e(bge,N2o),e(fs,q2o),e(fs,lj),e(lj,j2o),e(fs,D2o),e(fs,ij),e(ij,G2o),e(fs,O2o),e(k,V2o),e(k,fu),e(fu,vge),e(vge,X2o),e(fu,z2o),e(fu,dj),e(dj,Q2o),e(fu,W2o),e(k,U2o),e(k,gs),e(gs,Fge),e(Fge,H2o),e(gs,J2o),e(gs,mj),e(mj,Y2o),e(gs,K2o),e(gs,cj),e(cj,Z2o),e(gs,ebo),e(k,obo),e(k,hs),e(hs,Tge),e(Tge,rbo),e(hs,tbo),e(hs,fj),e(fj,abo),e(hs,nbo),e(hs,gj),e(gj,sbo),e(hs,lbo),e(k,ibo),e(k,us),e(us,Mge),e(Mge,dbo),e(us,mbo),e(us,hj),e(hj,cbo),e(us,fbo),e(us,uj),e(uj,gbo),e(us,hbo),e(k,ubo),e(k,ps),e(ps,Ege),e(Ege,pbo),e(ps,_bo),e(ps,pj),e(pj,bbo),e(ps,vbo),e(ps,_j),e(_j,Fbo),e(ps,Tbo),e(k,Mbo),e(k,gu),e(gu,Cge),e(Cge,Ebo),e(gu,Cbo),e(gu,bj),e(bj,wbo),e(gu,Abo),e(k,Lbo),e(k,_s),e(_s,wge),e(wge,ybo),e(_s,xbo),e(_s,vj),e(vj,$bo),e(_s,kbo),e(_s,Fj),e(Fj,Sbo),e(_s,Rbo),e(k,Pbo),e(k,bs),e(bs,Age),e(Age,Bbo),e(bs,Ibo),e(bs,Tj),e(Tj,Nbo),e(bs,qbo),e(bs,Mj),e(Mj,jbo),e(bs,Dbo),e(k,Gbo),e(k,vs),e(vs,Lge),e(Lge,Obo),e(vs,Vbo),e(vs,Ej),e(Ej,Xbo),e(vs,zbo),e(vs,Cj),e(Cj,Qbo),e(vs,Wbo),e(k,Ubo),e(k,Fs),e(Fs,yge),e(yge,Hbo),e(Fs,Jbo),e(Fs,wj),e(wj,Ybo),e(Fs,Kbo),e(Fs,Aj),e(Aj,Zbo),e(Fs,evo),e(k,ovo),e(k,Ts),e(Ts,xge),e(xge,rvo),e(Ts,tvo),e(Ts,Lj),e(Lj,avo),e(Ts,nvo),e(Ts,yj),e(yj,svo),e(Ts,lvo),e(k,ivo),e(k,Ms),e(Ms,$ge),e($ge,dvo),e(Ms,mvo),e(Ms,xj),e(xj,cvo),e(Ms,fvo),e(Ms,$j),e($j,gvo),e(Ms,hvo),e(k,uvo),e(k,Es),e(Es,kge),e(kge,pvo),e(Es,_vo),e(Es,kj),e(kj,bvo),e(Es,vvo),e(Es,Sj),e(Sj,Fvo),e(Es,Tvo),e(k,Mvo),e(k,hu),e(hu,Sge),e(Sge,Evo),e(hu,Cvo),e(hu,Rj),e(Rj,wvo),e(hu,Avo),e(k,Lvo),e(k,Cs),e(Cs,Rge),e(Rge,yvo),e(Cs,xvo),e(Cs,Pj),e(Pj,$vo),e(Cs,kvo),e(Cs,Bj),e(Bj,Svo),e(Cs,Rvo),e(k,Pvo),e(k,uu),e(uu,Pge),e(Pge,Bvo),e(uu,Ivo),e(uu,Ij),e(Ij,Nvo),e(uu,qvo),e(k,jvo),e(k,ws),e(ws,Bge),e(Bge,Dvo),e(ws,Gvo),e(ws,Nj),e(Nj,Ovo),e(ws,Vvo),e(ws,qj),e(qj,Xvo),e(ws,zvo),e(k,Qvo),e(k,As),e(As,Ige),e(Ige,Wvo),e(As,Uvo),e(As,jj),e(jj,Hvo),e(As,Jvo),e(As,Dj),e(Dj,Yvo),e(As,Kvo),e(k,Zvo),e(k,Ls),e(Ls,Nge),e(Nge,eFo),e(Ls,oFo),e(Ls,Gj),e(Gj,rFo),e(Ls,tFo),e(Ls,Oj),e(Oj,aFo),e(Ls,nFo),e(k,sFo),e(k,pu),e(pu,qge),e(qge,lFo),e(pu,iFo),e(pu,Vj),e(Vj,dFo),e(pu,mFo),e(k,cFo),e(k,_u),e(_u,jge),e(jge,fFo),e(_u,gFo),e(_u,Xj),e(Xj,hFo),e(_u,uFo),e(k,pFo),e(k,ys),e(ys,Dge),e(Dge,_Fo),e(ys,bFo),e(ys,zj),e(zj,vFo),e(ys,FFo),e(ys,Qj),e(Qj,TFo),e(ys,MFo),e(k,EFo),e(k,xs),e(xs,Gge),e(Gge,CFo),e(xs,wFo),e(xs,Wj),e(Wj,AFo),e(xs,LFo),e(xs,Uj),e(Uj,yFo),e(xs,xFo),e(k,$Fo),e(k,$s),e($s,Oge),e(Oge,kFo),e($s,SFo),e($s,Hj),e(Hj,RFo),e($s,PFo),e($s,Jj),e(Jj,BFo),e($s,IFo),e(k,NFo),e(k,bu),e(bu,Vge),e(Vge,qFo),e(bu,jFo),e(bu,Yj),e(Yj,DFo),e(bu,GFo),e(k,OFo),e(k,ks),e(ks,Xge),e(Xge,VFo),e(ks,XFo),e(ks,Kj),e(Kj,zFo),e(ks,QFo),e(ks,Zj),e(Zj,WFo),e(ks,UFo),e(k,HFo),e(k,Ss),e(Ss,zge),e(zge,JFo),e(Ss,YFo),e(Ss,eD),e(eD,KFo),e(Ss,ZFo),e(Ss,oD),e(oD,eTo),e(Ss,oTo),e(k,rTo),e(k,Rs),e(Rs,Qge),e(Qge,tTo),e(Rs,aTo),e(Rs,rD),e(rD,nTo),e(Rs,sTo),e(Rs,tD),e(tD,lTo),e(Rs,iTo),e(k,dTo),e(k,Ps),e(Ps,Wge),e(Wge,mTo),e(Ps,cTo),e(Ps,aD),e(aD,fTo),e(Ps,gTo),e(Ps,nD),e(nD,hTo),e(Ps,uTo),e(k,pTo),e(k,Bs),e(Bs,Uge),e(Uge,_To),e(Bs,bTo),e(Bs,sD),e(sD,vTo),e(Bs,FTo),e(Bs,lD),e(lD,TTo),e(Bs,MTo),e(k,ETo),e(k,Is),e(Is,Hge),e(Hge,CTo),e(Is,wTo),e(Is,iD),e(iD,ATo),e(Is,LTo),e(Is,dD),e(dD,yTo),e(Is,xTo),e(k,$To),e(k,Ns),e(Ns,Jge),e(Jge,kTo),e(Ns,STo),e(Ns,mD),e(mD,RTo),e(Ns,PTo),e(Ns,cD),e(cD,BTo),e(Ns,ITo),e(k,NTo),e(k,qs),e(qs,Yge),e(Yge,qTo),e(qs,jTo),e(qs,fD),e(fD,DTo),e(qs,GTo),e(qs,gD),e(gD,OTo),e(qs,VTo),e(k,XTo),e(k,vu),e(vu,Kge),e(Kge,zTo),e(vu,QTo),e(vu,hD),e(hD,WTo),e(vu,UTo),e(k,HTo),e(k,js),e(js,Zge),e(Zge,JTo),e(js,YTo),e(js,uD),e(uD,KTo),e(js,ZTo),e(js,pD),e(pD,eMo),e(js,oMo),e(k,rMo),e(k,Fu),e(Fu,ehe),e(ehe,tMo),e(Fu,aMo),e(Fu,_D),e(_D,nMo),e(Fu,sMo),e(k,lMo),e(k,Tu),e(Tu,ohe),e(ohe,iMo),e(Tu,dMo),e(Tu,bD),e(bD,mMo),e(Tu,cMo),e(k,fMo),e(k,Ds),e(Ds,rhe),e(rhe,gMo),e(Ds,hMo),e(Ds,vD),e(vD,uMo),e(Ds,pMo),e(Ds,FD),e(FD,_Mo),e(Ds,bMo),e(k,vMo),e(k,Gs),e(Gs,the),e(the,FMo),e(Gs,TMo),e(Gs,TD),e(TD,MMo),e(Gs,EMo),e(Gs,MD),e(MD,CMo),e(Gs,wMo),e(k,AMo),e(k,Os),e(Os,ahe),e(ahe,LMo),e(Os,yMo),e(Os,ED),e(ED,xMo),e(Os,$Mo),e(Os,CD),e(CD,kMo),e(Os,SMo),e(k,RMo),e(k,Mu),e(Mu,nhe),e(nhe,PMo),e(Mu,BMo),e(Mu,wD),e(wD,IMo),e(Mu,NMo),e(k,qMo),e(k,Vs),e(Vs,she),e(she,jMo),e(Vs,DMo),e(Vs,AD),e(AD,GMo),e(Vs,OMo),e(Vs,LD),e(LD,VMo),e(Vs,XMo),e(k,zMo),e(k,Xs),e(Xs,lhe),e(lhe,QMo),e(Xs,WMo),e(Xs,yD),e(yD,UMo),e(Xs,HMo),e(Xs,xD),e(xD,JMo),e(Xs,YMo),e(k,KMo),e(k,zs),e(zs,ihe),e(ihe,ZMo),e(zs,eEo),e(zs,$D),e($D,oEo),e(zs,rEo),e(zs,kD),e(kD,tEo),e(zs,aEo),e(k,nEo),e(k,Qs),e(Qs,dhe),e(dhe,sEo),e(Qs,lEo),e(Qs,SD),e(SD,iEo),e(Qs,dEo),e(Qs,RD),e(RD,mEo),e(Qs,cEo),e(k,fEo),e(k,Ws),e(Ws,mhe),e(mhe,gEo),e(Ws,hEo),e(Ws,PD),e(PD,uEo),e(Ws,pEo),e(Ws,BD),e(BD,_Eo),e(Ws,bEo),e(k,vEo),e(k,Us),e(Us,che),e(che,FEo),e(Us,TEo),e(Us,ID),e(ID,MEo),e(Us,EEo),e(Us,ND),e(ND,CEo),e(Us,wEo),e(k,AEo),e(k,Hs),e(Hs,fhe),e(fhe,LEo),e(Hs,yEo),e(Hs,qD),e(qD,xEo),e(Hs,$Eo),e(Hs,jD),e(jD,kEo),e(Hs,SEo),e(k,REo),e(k,Js),e(Js,ghe),e(ghe,PEo),e(Js,BEo),e(Js,DD),e(DD,IEo),e(Js,NEo),e(Js,GD),e(GD,qEo),e(Js,jEo),e(k,DEo),e(k,Eu),e(Eu,hhe),e(hhe,GEo),e(Eu,OEo),e(Eu,OD),e(OD,VEo),e(Eu,XEo),e(k,zEo),e(k,Ys),e(Ys,uhe),e(uhe,QEo),e(Ys,WEo),e(Ys,VD),e(VD,UEo),e(Ys,HEo),e(Ys,XD),e(XD,JEo),e(Ys,YEo),e(k,KEo),e(k,Ks),e(Ks,phe),e(phe,ZEo),e(Ks,e4o),e(Ks,zD),e(zD,o4o),e(Ks,r4o),e(Ks,QD),e(QD,t4o),e(Ks,a4o),e(k,n4o),e(k,Cu),e(Cu,_he),e(_he,s4o),e(Cu,l4o),e(Cu,WD),e(WD,i4o),e(Cu,d4o),e(k,m4o),e(k,wu),e(wu,bhe),e(bhe,c4o),e(wu,f4o),e(wu,UD),e(UD,g4o),e(wu,h4o),e(k,u4o),e(k,Au),e(Au,vhe),e(vhe,p4o),e(Au,_4o),e(Au,HD),e(HD,b4o),e(Au,v4o),e(k,F4o),e(k,Lu),e(Lu,Fhe),e(Fhe,T4o),e(Lu,M4o),e(Lu,JD),e(JD,E4o),e(Lu,C4o),e(k,w4o),e(k,Zs),e(Zs,The),e(The,A4o),e(Zs,L4o),e(Zs,YD),e(YD,y4o),e(Zs,x4o),e(Zs,KD),e(KD,$4o),e(Zs,k4o),e(k,S4o),e(k,yu),e(yu,Mhe),e(Mhe,R4o),e(yu,P4o),e(yu,ZD),e(ZD,B4o),e(yu,I4o),e(k,N4o),e(k,el),e(el,Ehe),e(Ehe,q4o),e(el,j4o),e(el,eG),e(eG,D4o),e(el,G4o),e(el,oG),e(oG,O4o),e(el,V4o),e(k,X4o),e(k,ol),e(ol,Che),e(Che,z4o),e(ol,Q4o),e(ol,rG),e(rG,W4o),e(ol,U4o),e(ol,tG),e(tG,H4o),e(ol,J4o),e(k,Y4o),e(k,rl),e(rl,whe),e(whe,K4o),e(rl,Z4o),e(rl,aG),e(aG,eCo),e(rl,oCo),e(rl,nG),e(nG,rCo),e(rl,tCo),e(k,aCo),e(k,tl),e(tl,Ahe),e(Ahe,nCo),e(tl,sCo),e(tl,sG),e(sG,lCo),e(tl,iCo),e(tl,lG),e(lG,dCo),e(tl,mCo),e(k,cCo),e(k,al),e(al,Lhe),e(Lhe,fCo),e(al,gCo),e(al,iG),e(iG,hCo),e(al,uCo),e(al,dG),e(dG,pCo),e(al,_Co),e(k,bCo),e(k,nl),e(nl,yhe),e(yhe,vCo),e(nl,FCo),e(nl,mG),e(mG,TCo),e(nl,MCo),e(nl,cG),e(cG,ECo),e(nl,CCo),e(k,wCo),e(k,xu),e(xu,xhe),e(xhe,ACo),e(xu,LCo),e(xu,fG),e(fG,yCo),e(xu,xCo),e(k,$Co),e(k,$u),e($u,$he),e($he,kCo),e($u,SCo),e($u,gG),e(gG,RCo),e($u,PCo),e(k,BCo),e(k,sl),e(sl,khe),e(khe,ICo),e(sl,NCo),e(sl,hG),e(hG,qCo),e(sl,jCo),e(sl,uG),e(uG,DCo),e(sl,GCo),e(k,OCo),e(k,ll),e(ll,She),e(She,VCo),e(ll,XCo),e(ll,pG),e(pG,zCo),e(ll,QCo),e(ll,_G),e(_G,WCo),e(ll,UCo),e(k,HCo),e(k,il),e(il,Rhe),e(Rhe,JCo),e(il,YCo),e(il,bG),e(bG,KCo),e(il,ZCo),e(il,vG),e(vG,e3o),e(il,o3o),e(k,r3o),e(k,ku),e(ku,Phe),e(Phe,t3o),e(ku,a3o),e(ku,FG),e(FG,n3o),e(ku,s3o),e(k,l3o),e(k,Su),e(Su,Bhe),e(Bhe,i3o),e(Su,d3o),e(Su,TG),e(TG,m3o),e(Su,c3o),e(k,f3o),e(k,Ru),e(Ru,Ihe),e(Ihe,g3o),e(Ru,h3o),e(Ru,MG),e(MG,u3o),e(Ru,p3o),e(k,_3o),e(k,dl),e(dl,Nhe),e(Nhe,b3o),e(dl,v3o),e(dl,EG),e(EG,F3o),e(dl,T3o),e(dl,CG),e(CG,M3o),e(dl,E3o),e(k,C3o),e(k,ml),e(ml,qhe),e(qhe,w3o),e(ml,A3o),e(ml,wG),e(wG,L3o),e(ml,y3o),e(ml,AG),e(AG,x3o),e(ml,$3o),e(k,k3o),e(k,Pu),e(Pu,jhe),e(jhe,S3o),e(Pu,R3o),e(Pu,LG),e(LG,P3o),e(Pu,B3o),e(k,I3o),e(k,Bu),e(Bu,Dhe),e(Dhe,N3o),e(Bu,q3o),e(Bu,yG),e(yG,j3o),e(Bu,D3o),e(k,G3o),e(k,Iu),e(Iu,Ghe),e(Ghe,O3o),e(Iu,V3o),e(Iu,xG),e(xG,X3o),e(Iu,z3o),e(k,Q3o),e(k,Nu),e(Nu,Ohe),e(Ohe,W3o),e(Nu,U3o),e(Nu,$G),e($G,H3o),e(Nu,J3o),e(k,Y3o),e(k,cl),e(cl,Vhe),e(Vhe,K3o),e(cl,Z3o),e(cl,kG),e(kG,e5o),e(cl,o5o),e(cl,SG),e(SG,r5o),e(cl,t5o),e(k,a5o),e(k,fl),e(fl,Xhe),e(Xhe,n5o),e(fl,s5o),e(fl,RG),e(RG,l5o),e(fl,i5o),e(fl,PG),e(PG,d5o),e(fl,m5o),e(k,c5o),e(k,qu),e(qu,zhe),e(zhe,f5o),e(qu,g5o),e(qu,BG),e(BG,h5o),e(qu,u5o),e(k,p5o),e(k,ju),e(ju,Qhe),e(Qhe,_5o),e(ju,b5o),e(ju,IG),e(IG,v5o),e(ju,F5o),e(k,T5o),e(k,gl),e(gl,Whe),e(Whe,M5o),e(gl,E5o),e(gl,NG),e(NG,C5o),e(gl,w5o),e(gl,qG),e(qG,A5o),e(gl,L5o),e(k,y5o),e(k,hl),e(hl,Uhe),e(Uhe,x5o),e(hl,$5o),e(hl,jG),e(jG,k5o),e(hl,S5o),e(hl,DG),e(DG,R5o),e(hl,P5o),e(k,B5o),e(k,ul),e(ul,Hhe),e(Hhe,I5o),e(ul,N5o),e(ul,GG),e(GG,q5o),e(ul,j5o),e(ul,OG),e(OG,D5o),e(ul,G5o),e(k,O5o),e(k,pl),e(pl,Jhe),e(Jhe,V5o),e(pl,X5o),e(pl,VG),e(VG,z5o),e(pl,Q5o),e(pl,XG),e(XG,W5o),e(pl,U5o),e(Br,H5o),M(Du,Br,null),e(ko,J5o),e(ko,Gu),M(Tx,Gu,null),e(Gu,Y5o),e(Gu,Yhe),e(Yhe,K5o),b(c,Ceo,_),b(c,hd,_),e(hd,Ou),e(Ou,Khe),M(Mx,Khe,null),e(hd,Z5o),e(hd,Zhe),e(Zhe,e0o),b(c,weo,_),b(c,So,_),M(Ex,So,null),e(So,o0o),e(So,Cx),e(Cx,r0o),e(Cx,zG),e(zG,t0o),e(Cx,a0o),e(So,n0o),e(So,wx),e(wx,s0o),e(wx,eue),e(eue,l0o),e(wx,i0o),e(So,d0o),e(So,Ye),M(Ax,Ye,null),e(Ye,m0o),e(Ye,oue),e(oue,c0o),e(Ye,f0o),e(Ye,Ha),e(Ha,g0o),e(Ha,rue),e(rue,h0o),e(Ha,u0o),e(Ha,tue),e(tue,p0o),e(Ha,_0o),e(Ha,aue),e(aue,b0o),e(Ha,v0o),e(Ye,F0o),e(Ye,z),e(z,Vu),e(Vu,nue),e(nue,T0o),e(Vu,M0o),e(Vu,QG),e(QG,E0o),e(Vu,C0o),e(z,w0o),e(z,Xu),e(Xu,sue),e(sue,A0o),e(Xu,L0o),e(Xu,WG),e(WG,y0o),e(Xu,x0o),e(z,$0o),e(z,zu),e(zu,lue),e(lue,k0o),e(zu,S0o),e(zu,UG),e(UG,R0o),e(zu,P0o),e(z,B0o),e(z,Qu),e(Qu,iue),e(iue,I0o),e(Qu,N0o),e(Qu,HG),e(HG,q0o),e(Qu,j0o),e(z,D0o),e(z,Wu),e(Wu,due),e(due,G0o),e(Wu,O0o),e(Wu,JG),e(JG,V0o),e(Wu,X0o),e(z,z0o),e(z,Uu),e(Uu,mue),e(mue,Q0o),e(Uu,W0o),e(Uu,YG),e(YG,U0o),e(Uu,H0o),e(z,J0o),e(z,Hu),e(Hu,cue),e(cue,Y0o),e(Hu,K0o),e(Hu,KG),e(KG,Z0o),e(Hu,ewo),e(z,owo),e(z,Ju),e(Ju,fue),e(fue,rwo),e(Ju,two),e(Ju,ZG),e(ZG,awo),e(Ju,nwo),e(z,swo),e(z,Yu),e(Yu,gue),e(gue,lwo),e(Yu,iwo),e(Yu,eO),e(eO,dwo),e(Yu,mwo),e(z,cwo),e(z,Ku),e(Ku,hue),e(hue,fwo),e(Ku,gwo),e(Ku,oO),e(oO,hwo),e(Ku,uwo),e(z,pwo),e(z,Zu),e(Zu,uue),e(uue,_wo),e(Zu,bwo),e(Zu,rO),e(rO,vwo),e(Zu,Fwo),e(z,Two),e(z,ep),e(ep,pue),e(pue,Mwo),e(ep,Ewo),e(ep,tO),e(tO,Cwo),e(ep,wwo),e(z,Awo),e(z,op),e(op,_ue),e(_ue,Lwo),e(op,ywo),e(op,aO),e(aO,xwo),e(op,$wo),e(z,kwo),e(z,rp),e(rp,bue),e(bue,Swo),e(rp,Rwo),e(rp,nO),e(nO,Pwo),e(rp,Bwo),e(z,Iwo),e(z,tp),e(tp,vue),e(vue,Nwo),e(tp,qwo),e(tp,sO),e(sO,jwo),e(tp,Dwo),e(z,Gwo),e(z,ap),e(ap,Fue),e(Fue,Owo),e(ap,Vwo),e(ap,lO),e(lO,Xwo),e(ap,zwo),e(z,Qwo),e(z,np),e(np,Tue),e(Tue,Wwo),e(np,Uwo),e(np,iO),e(iO,Hwo),e(np,Jwo),e(z,Ywo),e(z,sp),e(sp,Mue),e(Mue,Kwo),e(sp,Zwo),e(sp,dO),e(dO,eAo),e(sp,oAo),e(z,rAo),e(z,lp),e(lp,Eue),e(Eue,tAo),e(lp,aAo),e(lp,mO),e(mO,nAo),e(lp,sAo),e(z,lAo),e(z,ip),e(ip,Cue),e(Cue,iAo),e(ip,dAo),e(ip,cO),e(cO,mAo),e(ip,cAo),e(z,fAo),e(z,dp),e(dp,wue),e(wue,gAo),e(dp,hAo),e(dp,fO),e(fO,uAo),e(dp,pAo),e(z,_Ao),e(z,mp),e(mp,Aue),e(Aue,bAo),e(mp,vAo),e(mp,gO),e(gO,FAo),e(mp,TAo),e(z,MAo),e(z,cp),e(cp,Lue),e(Lue,EAo),e(cp,CAo),e(cp,hO),e(hO,wAo),e(cp,AAo),e(z,LAo),e(z,fp),e(fp,yue),e(yue,yAo),e(fp,xAo),e(fp,uO),e(uO,$Ao),e(fp,kAo),e(z,SAo),e(z,gp),e(gp,xue),e(xue,RAo),e(gp,PAo),e(gp,pO),e(pO,BAo),e(gp,IAo),e(z,NAo),e(z,hp),e(hp,$ue),e($ue,qAo),e(hp,jAo),e(hp,_O),e(_O,DAo),e(hp,GAo),e(z,OAo),e(z,up),e(up,kue),e(kue,VAo),e(up,XAo),e(up,bO),e(bO,zAo),e(up,QAo),e(z,WAo),e(z,pp),e(pp,Sue),e(Sue,UAo),e(pp,HAo),e(pp,vO),e(vO,JAo),e(pp,YAo),e(z,KAo),e(z,_p),e(_p,Rue),e(Rue,ZAo),e(_p,e6o),e(_p,FO),e(FO,o6o),e(_p,r6o),e(z,t6o),e(z,bp),e(bp,Pue),e(Pue,a6o),e(bp,n6o),e(bp,TO),e(TO,s6o),e(bp,l6o),e(z,i6o),e(z,vp),e(vp,Bue),e(Bue,d6o),e(vp,m6o),e(vp,MO),e(MO,c6o),e(vp,f6o),e(z,g6o),e(z,Fp),e(Fp,Iue),e(Iue,h6o),e(Fp,u6o),e(Fp,EO),e(EO,p6o),e(Fp,_6o),e(z,b6o),e(z,Tp),e(Tp,Nue),e(Nue,v6o),e(Tp,F6o),e(Tp,CO),e(CO,T6o),e(Tp,M6o),e(z,E6o),e(z,Mp),e(Mp,que),e(que,C6o),e(Mp,w6o),e(Mp,wO),e(wO,A6o),e(Mp,L6o),e(z,y6o),e(z,Ep),e(Ep,jue),e(jue,x6o),e(Ep,$6o),e(Ep,AO),e(AO,k6o),e(Ep,S6o),e(z,R6o),e(z,Cp),e(Cp,Due),e(Due,P6o),e(Cp,B6o),e(Cp,LO),e(LO,I6o),e(Cp,N6o),e(z,q6o),e(z,wp),e(wp,Gue),e(Gue,j6o),e(wp,D6o),e(wp,yO),e(yO,G6o),e(wp,O6o),e(z,V6o),e(z,Ap),e(Ap,Oue),e(Oue,X6o),e(Ap,z6o),e(Ap,xO),e(xO,Q6o),e(Ap,W6o),e(z,U6o),e(z,Lp),e(Lp,Vue),e(Vue,H6o),e(Lp,J6o),e(Lp,$O),e($O,Y6o),e(Lp,K6o),e(z,Z6o),e(z,yp),e(yp,Xue),e(Xue,e7o),e(yp,o7o),e(yp,kO),e(kO,r7o),e(yp,t7o),e(z,a7o),e(z,xp),e(xp,zue),e(zue,n7o),e(xp,s7o),e(xp,SO),e(SO,l7o),e(xp,i7o),e(z,d7o),e(z,$p),e($p,Que),e(Que,m7o),e($p,c7o),e($p,RO),e(RO,f7o),e($p,g7o),e(z,h7o),e(z,kp),e(kp,Wue),e(Wue,u7o),e(kp,p7o),e(kp,PO),e(PO,_7o),e(kp,b7o),e(Ye,v7o),M(Sp,Ye,null),e(Ye,F7o),M(Rp,Ye,null),e(So,T7o),e(So,Pp),M(Lx,Pp,null),e(Pp,M7o),e(Pp,Uue),e(Uue,E7o),b(c,Aeo,_),b(c,ud,_),e(ud,Bp),e(Bp,Hue),M(yx,Hue,null),e(ud,C7o),e(ud,Jue),e(Jue,w7o),b(c,Leo,_),b(c,Ro,_),M(xx,Ro,null),e(Ro,A7o),e(Ro,$x),e($x,L7o),e($x,BO),e(BO,y7o),e($x,x7o),e(Ro,$7o),e(Ro,kx),e(kx,k7o),e(kx,Yue),e(Yue,S7o),e(kx,R7o),e(Ro,P7o),e(Ro,Ke),M(Sx,Ke,null),e(Ke,B7o),e(Ke,Kue),e(Kue,I7o),e(Ke,N7o),e(Ke,pd),e(pd,q7o),e(pd,Zue),e(Zue,j7o),e(pd,D7o),e(pd,epe),e(epe,G7o),e(pd,O7o),e(Ke,V7o),e(Ke,se),e(se,Ip),e(Ip,ope),e(ope,X7o),e(Ip,z7o),e(Ip,IO),e(IO,Q7o),e(Ip,W7o),e(se,U7o),e(se,Np),e(Np,rpe),e(rpe,H7o),e(Np,J7o),e(Np,NO),e(NO,Y7o),e(Np,K7o),e(se,Z7o),e(se,qp),e(qp,tpe),e(tpe,eLo),e(qp,oLo),e(qp,qO),e(qO,rLo),e(qp,tLo),e(se,aLo),e(se,jp),e(jp,ape),e(ape,nLo),e(jp,sLo),e(jp,jO),e(jO,lLo),e(jp,iLo),e(se,dLo),e(se,Dp),e(Dp,npe),e(npe,mLo),e(Dp,cLo),e(Dp,DO),e(DO,fLo),e(Dp,gLo),e(se,hLo),e(se,Gp),e(Gp,spe),e(spe,uLo),e(Gp,pLo),e(Gp,GO),e(GO,_Lo),e(Gp,bLo),e(se,vLo),e(se,Op),e(Op,lpe),e(lpe,FLo),e(Op,TLo),e(Op,OO),e(OO,MLo),e(Op,ELo),e(se,CLo),e(se,Vp),e(Vp,ipe),e(ipe,wLo),e(Vp,ALo),e(Vp,VO),e(VO,LLo),e(Vp,yLo),e(se,xLo),e(se,Xp),e(Xp,dpe),e(dpe,$Lo),e(Xp,kLo),e(Xp,XO),e(XO,SLo),e(Xp,RLo),e(se,PLo),e(se,zp),e(zp,mpe),e(mpe,BLo),e(zp,ILo),e(zp,zO),e(zO,NLo),e(zp,qLo),e(se,jLo),e(se,Qp),e(Qp,cpe),e(cpe,DLo),e(Qp,GLo),e(Qp,QO),e(QO,OLo),e(Qp,VLo),e(se,XLo),e(se,Wp),e(Wp,fpe),e(fpe,zLo),e(Wp,QLo),e(Wp,WO),e(WO,WLo),e(Wp,ULo),e(se,HLo),e(se,Up),e(Up,gpe),e(gpe,JLo),e(Up,YLo),e(Up,UO),e(UO,KLo),e(Up,ZLo),e(se,eyo),e(se,Hp),e(Hp,hpe),e(hpe,oyo),e(Hp,ryo),e(Hp,HO),e(HO,tyo),e(Hp,ayo),e(se,nyo),e(se,Jp),e(Jp,upe),e(upe,syo),e(Jp,lyo),e(Jp,JO),e(JO,iyo),e(Jp,dyo),e(se,myo),e(se,Yp),e(Yp,ppe),e(ppe,cyo),e(Yp,fyo),e(Yp,YO),e(YO,gyo),e(Yp,hyo),e(se,uyo),e(se,Kp),e(Kp,_pe),e(_pe,pyo),e(Kp,_yo),e(Kp,KO),e(KO,byo),e(Kp,vyo),e(se,Fyo),e(se,Zp),e(Zp,bpe),e(bpe,Tyo),e(Zp,Myo),e(Zp,ZO),e(ZO,Eyo),e(Zp,Cyo),e(se,wyo),e(se,e_),e(e_,vpe),e(vpe,Ayo),e(e_,Lyo),e(e_,eV),e(eV,yyo),e(e_,xyo),e(se,$yo),e(se,o_),e(o_,Fpe),e(Fpe,kyo),e(o_,Syo),e(o_,oV),e(oV,Ryo),e(o_,Pyo),e(se,Byo),e(se,r_),e(r_,Tpe),e(Tpe,Iyo),e(r_,Nyo),e(r_,rV),e(rV,qyo),e(r_,jyo),e(se,Dyo),e(se,t_),e(t_,Mpe),e(Mpe,Gyo),e(t_,Oyo),e(t_,tV),e(tV,Vyo),e(t_,Xyo),e(se,zyo),e(se,a_),e(a_,Epe),e(Epe,Qyo),e(a_,Wyo),e(a_,aV),e(aV,Uyo),e(a_,Hyo),e(Ke,Jyo),M(n_,Ke,null),e(Ke,Yyo),M(s_,Ke,null),e(Ro,Kyo),e(Ro,l_),M(Rx,l_,null),e(l_,Zyo),e(l_,Cpe),e(Cpe,e8o),b(c,yeo,_),b(c,_d,_),e(_d,i_),e(i_,wpe),M(Px,wpe,null),e(_d,o8o),e(_d,Ape),e(Ape,r8o),b(c,xeo,_),b(c,Po,_),M(Bx,Po,null),e(Po,t8o),e(Po,bd),e(bd,a8o),e(bd,nV),e(nV,n8o),e(bd,s8o),e(bd,sV),e(sV,l8o),e(bd,i8o),e(Po,d8o),e(Po,Ix),e(Ix,m8o),e(Ix,Lpe),e(Lpe,c8o),e(Ix,f8o),e(Po,g8o),e(Po,_t),M(Nx,_t,null),e(_t,h8o),e(_t,ype),e(ype,u8o),e(_t,p8o),e(_t,vd),e(vd,_8o),e(vd,xpe),e(xpe,b8o),e(vd,v8o),e(vd,lV),e(lV,F8o),e(vd,T8o),e(_t,M8o),M(d_,_t,null),e(Po,E8o),e(Po,Ze),M(qx,Ze,null),e(Ze,C8o),e(Ze,$pe),e($pe,w8o),e(Ze,A8o),e(Ze,Ja),e(Ja,L8o),e(Ja,kpe),e(kpe,y8o),e(Ja,x8o),e(Ja,Spe),e(Spe,$8o),e(Ja,k8o),e(Ja,Rpe),e(Rpe,S8o),e(Ja,R8o),e(Ze,P8o),e(Ze,y),e(y,m_),e(m_,Ppe),e(Ppe,B8o),e(m_,I8o),e(m_,iV),e(iV,N8o),e(m_,q8o),e(y,j8o),e(y,c_),e(c_,Bpe),e(Bpe,D8o),e(c_,G8o),e(c_,dV),e(dV,O8o),e(c_,V8o),e(y,X8o),e(y,f_),e(f_,Ipe),e(Ipe,z8o),e(f_,Q8o),e(f_,mV),e(mV,W8o),e(f_,U8o),e(y,H8o),e(y,g_),e(g_,Npe),e(Npe,J8o),e(g_,Y8o),e(g_,cV),e(cV,K8o),e(g_,Z8o),e(y,e9o),e(y,h_),e(h_,qpe),e(qpe,o9o),e(h_,r9o),e(h_,fV),e(fV,t9o),e(h_,a9o),e(y,n9o),e(y,u_),e(u_,jpe),e(jpe,s9o),e(u_,l9o),e(u_,gV),e(gV,i9o),e(u_,d9o),e(y,m9o),e(y,p_),e(p_,Dpe),e(Dpe,c9o),e(p_,f9o),e(p_,hV),e(hV,g9o),e(p_,h9o),e(y,u9o),e(y,__),e(__,Gpe),e(Gpe,p9o),e(__,_9o),e(__,uV),e(uV,b9o),e(__,v9o),e(y,F9o),e(y,b_),e(b_,Ope),e(Ope,T9o),e(b_,M9o),e(b_,pV),e(pV,E9o),e(b_,C9o),e(y,w9o),e(y,v_),e(v_,Vpe),e(Vpe,A9o),e(v_,L9o),e(v_,_V),e(_V,y9o),e(v_,x9o),e(y,$9o),e(y,F_),e(F_,Xpe),e(Xpe,k9o),e(F_,S9o),e(F_,bV),e(bV,R9o),e(F_,P9o),e(y,B9o),e(y,T_),e(T_,zpe),e(zpe,I9o),e(T_,N9o),e(T_,vV),e(vV,q9o),e(T_,j9o),e(y,D9o),e(y,M_),e(M_,Qpe),e(Qpe,G9o),e(M_,O9o),e(M_,FV),e(FV,V9o),e(M_,X9o),e(y,z9o),e(y,E_),e(E_,Wpe),e(Wpe,Q9o),e(E_,W9o),e(E_,TV),e(TV,U9o),e(E_,H9o),e(y,J9o),e(y,C_),e(C_,Upe),e(Upe,Y9o),e(C_,K9o),e(C_,MV),e(MV,Z9o),e(C_,exo),e(y,oxo),e(y,w_),e(w_,Hpe),e(Hpe,rxo),e(w_,txo),e(w_,EV),e(EV,axo),e(w_,nxo),e(y,sxo),e(y,A_),e(A_,Jpe),e(Jpe,lxo),e(A_,ixo),e(A_,CV),e(CV,dxo),e(A_,mxo),e(y,cxo),e(y,L_),e(L_,Ype),e(Ype,fxo),e(L_,gxo),e(L_,wV),e(wV,hxo),e(L_,uxo),e(y,pxo),e(y,y_),e(y_,Kpe),e(Kpe,_xo),e(y_,bxo),e(y_,AV),e(AV,vxo),e(y_,Fxo),e(y,Txo),e(y,x_),e(x_,Zpe),e(Zpe,Mxo),e(x_,Exo),e(x_,LV),e(LV,Cxo),e(x_,wxo),e(y,Axo),e(y,$_),e($_,e_e),e(e_e,Lxo),e($_,yxo),e($_,yV),e(yV,xxo),e($_,$xo),e(y,kxo),e(y,k_),e(k_,o_e),e(o_e,Sxo),e(k_,Rxo),e(k_,xV),e(xV,Pxo),e(k_,Bxo),e(y,Ixo),e(y,S_),e(S_,r_e),e(r_e,Nxo),e(S_,qxo),e(S_,$V),e($V,jxo),e(S_,Dxo),e(y,Gxo),e(y,R_),e(R_,t_e),e(t_e,Oxo),e(R_,Vxo),e(R_,kV),e(kV,Xxo),e(R_,zxo),e(y,Qxo),e(y,P_),e(P_,a_e),e(a_e,Wxo),e(P_,Uxo),e(P_,SV),e(SV,Hxo),e(P_,Jxo),e(y,Yxo),e(y,B_),e(B_,n_e),e(n_e,Kxo),e(B_,Zxo),e(B_,RV),e(RV,e$o),e(B_,o$o),e(y,r$o),e(y,I_),e(I_,s_e),e(s_e,t$o),e(I_,a$o),e(I_,PV),e(PV,n$o),e(I_,s$o),e(y,l$o),e(y,N_),e(N_,l_e),e(l_e,i$o),e(N_,d$o),e(N_,BV),e(BV,m$o),e(N_,c$o),e(y,f$o),e(y,q_),e(q_,i_e),e(i_e,g$o),e(q_,h$o),e(q_,IV),e(IV,u$o),e(q_,p$o),e(y,_$o),e(y,j_),e(j_,d_e),e(d_e,b$o),e(j_,v$o),e(j_,NV),e(NV,F$o),e(j_,T$o),e(y,M$o),e(y,D_),e(D_,m_e),e(m_e,E$o),e(D_,C$o),e(D_,qV),e(qV,w$o),e(D_,A$o),e(y,L$o),e(y,G_),e(G_,c_e),e(c_e,y$o),e(G_,x$o),e(G_,jV),e(jV,$$o),e(G_,k$o),e(y,S$o),e(y,O_),e(O_,f_e),e(f_e,R$o),e(O_,P$o),e(O_,DV),e(DV,B$o),e(O_,I$o),e(y,N$o),e(y,V_),e(V_,g_e),e(g_e,q$o),e(V_,j$o),e(V_,GV),e(GV,D$o),e(V_,G$o),e(y,O$o),e(y,X_),e(X_,h_e),e(h_e,V$o),e(X_,X$o),e(X_,OV),e(OV,z$o),e(X_,Q$o),e(y,W$o),e(y,z_),e(z_,u_e),e(u_e,U$o),e(z_,H$o),e(z_,VV),e(VV,J$o),e(z_,Y$o),e(y,K$o),e(y,Q_),e(Q_,p_e),e(p_e,Z$o),e(Q_,eko),e(Q_,XV),e(XV,oko),e(Q_,rko),e(y,tko),e(y,W_),e(W_,__e),e(__e,ako),e(W_,nko),e(W_,zV),e(zV,sko),e(W_,lko),e(y,iko),e(y,U_),e(U_,b_e),e(b_e,dko),e(U_,mko),e(U_,QV),e(QV,cko),e(U_,fko),e(y,gko),e(y,_l),e(_l,v_e),e(v_e,hko),e(_l,uko),e(_l,WV),e(WV,pko),e(_l,_ko),e(_l,UV),e(UV,bko),e(_l,vko),e(y,Fko),e(y,H_),e(H_,F_e),e(F_e,Tko),e(H_,Mko),e(H_,HV),e(HV,Eko),e(H_,Cko),e(y,wko),e(y,J_),e(J_,T_e),e(T_e,Ako),e(J_,Lko),e(J_,JV),e(JV,yko),e(J_,xko),e(y,$ko),e(y,Y_),e(Y_,M_e),e(M_e,kko),e(Y_,Sko),e(Y_,YV),e(YV,Rko),e(Y_,Pko),e(y,Bko),e(y,K_),e(K_,E_e),e(E_e,Iko),e(K_,Nko),e(K_,KV),e(KV,qko),e(K_,jko),e(y,Dko),e(y,Z_),e(Z_,C_e),e(C_e,Gko),e(Z_,Oko),e(Z_,ZV),e(ZV,Vko),e(Z_,Xko),e(y,zko),e(y,e1),e(e1,w_e),e(w_e,Qko),e(e1,Wko),e(e1,eX),e(eX,Uko),e(e1,Hko),e(y,Jko),e(y,o1),e(o1,A_e),e(A_e,Yko),e(o1,Kko),e(o1,oX),e(oX,Zko),e(o1,eSo),e(y,oSo),e(y,r1),e(r1,L_e),e(L_e,rSo),e(r1,tSo),e(r1,rX),e(rX,aSo),e(r1,nSo),e(y,sSo),e(y,t1),e(t1,y_e),e(y_e,lSo),e(t1,iSo),e(t1,tX),e(tX,dSo),e(t1,mSo),e(y,cSo),e(y,a1),e(a1,x_e),e(x_e,fSo),e(a1,gSo),e(a1,aX),e(aX,hSo),e(a1,uSo),e(y,pSo),e(y,n1),e(n1,$_e),e($_e,_So),e(n1,bSo),e(n1,nX),e(nX,vSo),e(n1,FSo),e(y,TSo),e(y,s1),e(s1,k_e),e(k_e,MSo),e(s1,ESo),e(s1,sX),e(sX,CSo),e(s1,wSo),e(y,ASo),e(y,l1),e(l1,S_e),e(S_e,LSo),e(l1,ySo),e(l1,lX),e(lX,xSo),e(l1,$So),e(y,kSo),e(y,i1),e(i1,R_e),e(R_e,SSo),e(i1,RSo),e(i1,iX),e(iX,PSo),e(i1,BSo),e(y,ISo),e(y,d1),e(d1,P_e),e(P_e,NSo),e(d1,qSo),e(d1,dX),e(dX,jSo),e(d1,DSo),e(y,GSo),e(y,m1),e(m1,B_e),e(B_e,OSo),e(m1,VSo),e(m1,mX),e(mX,XSo),e(m1,zSo),e(y,QSo),e(y,c1),e(c1,I_e),e(I_e,WSo),e(c1,USo),e(c1,cX),e(cX,HSo),e(c1,JSo),e(y,YSo),e(y,f1),e(f1,N_e),e(N_e,KSo),e(f1,ZSo),e(f1,fX),e(fX,eRo),e(f1,oRo),e(y,rRo),e(y,g1),e(g1,q_e),e(q_e,tRo),e(g1,aRo),e(g1,gX),e(gX,nRo),e(g1,sRo),e(y,lRo),e(y,h1),e(h1,j_e),e(j_e,iRo),e(h1,dRo),e(h1,hX),e(hX,mRo),e(h1,cRo),e(y,fRo),e(y,u1),e(u1,D_e),e(D_e,gRo),e(u1,hRo),e(u1,uX),e(uX,uRo),e(u1,pRo),e(y,_Ro),e(y,p1),e(p1,G_e),e(G_e,bRo),e(p1,vRo),e(p1,pX),e(pX,FRo),e(p1,TRo),e(y,MRo),e(y,_1),e(_1,O_e),e(O_e,ERo),e(_1,CRo),e(_1,_X),e(_X,wRo),e(_1,ARo),e(y,LRo),e(y,b1),e(b1,V_e),e(V_e,yRo),e(b1,xRo),e(b1,bX),e(bX,$Ro),e(b1,kRo),e(y,SRo),e(y,v1),e(v1,X_e),e(X_e,RRo),e(v1,PRo),e(v1,vX),e(vX,BRo),e(v1,IRo),e(y,NRo),e(y,F1),e(F1,z_e),e(z_e,qRo),e(F1,jRo),e(F1,FX),e(FX,DRo),e(F1,GRo),e(y,ORo),e(y,T1),e(T1,Q_e),e(Q_e,VRo),e(T1,XRo),e(T1,TX),e(TX,zRo),e(T1,QRo),e(y,WRo),e(y,M1),e(M1,W_e),e(W_e,URo),e(M1,HRo),e(M1,MX),e(MX,JRo),e(M1,YRo),e(y,KRo),e(y,E1),e(E1,U_e),e(U_e,ZRo),e(E1,ePo),e(E1,EX),e(EX,oPo),e(E1,rPo),e(y,tPo),e(y,C1),e(C1,H_e),e(H_e,aPo),e(C1,nPo),e(C1,CX),e(CX,sPo),e(C1,lPo),e(y,iPo),e(y,w1),e(w1,J_e),e(J_e,dPo),e(w1,mPo),e(w1,wX),e(wX,cPo),e(w1,fPo),e(y,gPo),e(y,A1),e(A1,Y_e),e(Y_e,hPo),e(A1,uPo),e(A1,AX),e(AX,pPo),e(A1,_Po),e(y,bPo),e(y,L1),e(L1,K_e),e(K_e,vPo),e(L1,FPo),e(L1,LX),e(LX,TPo),e(L1,MPo),e(y,EPo),e(y,y1),e(y1,Z_e),e(Z_e,CPo),e(y1,wPo),e(y1,yX),e(yX,APo),e(y1,LPo),e(y,yPo),e(y,x1),e(x1,e1e),e(e1e,xPo),e(x1,$Po),e(x1,xX),e(xX,kPo),e(x1,SPo),e(y,RPo),e(y,$1),e($1,o1e),e(o1e,PPo),e($1,BPo),e($1,$X),e($X,IPo),e($1,NPo),e(y,qPo),e(y,k1),e(k1,r1e),e(r1e,jPo),e(k1,DPo),e(k1,kX),e(kX,GPo),e(k1,OPo),e(y,VPo),e(y,S1),e(S1,t1e),e(t1e,XPo),e(S1,zPo),e(S1,SX),e(SX,QPo),e(S1,WPo),e(y,UPo),e(y,R1),e(R1,a1e),e(a1e,HPo),e(R1,JPo),e(R1,RX),e(RX,YPo),e(R1,KPo),e(y,ZPo),e(y,P1),e(P1,n1e),e(n1e,eBo),e(P1,oBo),e(P1,PX),e(PX,rBo),e(P1,tBo),e(y,aBo),e(y,B1),e(B1,s1e),e(s1e,nBo),e(B1,sBo),e(B1,BX),e(BX,lBo),e(B1,iBo),e(y,dBo),e(y,I1),e(I1,l1e),e(l1e,mBo),e(I1,cBo),e(I1,IX),e(IX,fBo),e(I1,gBo),e(y,hBo),e(y,N1),e(N1,i1e),e(i1e,uBo),e(N1,pBo),e(N1,NX),e(NX,_Bo),e(N1,bBo),e(y,vBo),e(y,q1),e(q1,d1e),e(d1e,FBo),e(q1,TBo),e(q1,qX),e(qX,MBo),e(q1,EBo),e(y,CBo),e(y,j1),e(j1,m1e),e(m1e,wBo),e(j1,ABo),e(j1,jX),e(jX,LBo),e(j1,yBo),e(y,xBo),e(y,D1),e(D1,c1e),e(c1e,$Bo),e(D1,kBo),e(D1,DX),e(DX,SBo),e(D1,RBo),e(y,PBo),e(y,G1),e(G1,f1e),e(f1e,BBo),e(G1,IBo),e(G1,GX),e(GX,NBo),e(G1,qBo),e(y,jBo),e(y,O1),e(O1,g1e),e(g1e,DBo),e(O1,GBo),e(O1,OX),e(OX,OBo),e(O1,VBo),e(y,XBo),e(y,V1),e(V1,h1e),e(h1e,zBo),e(V1,QBo),e(V1,VX),e(VX,WBo),e(V1,UBo),e(y,HBo),e(y,X1),e(X1,u1e),e(u1e,JBo),e(X1,YBo),e(X1,XX),e(XX,KBo),e(X1,ZBo),e(y,eIo),e(y,z1),e(z1,p1e),e(p1e,oIo),e(z1,rIo),e(z1,zX),e(zX,tIo),e(z1,aIo),e(y,nIo),e(y,Q1),e(Q1,_1e),e(_1e,sIo),e(Q1,lIo),e(Q1,QX),e(QX,iIo),e(Q1,dIo),e(y,mIo),e(y,W1),e(W1,b1e),e(b1e,cIo),e(W1,fIo),e(W1,WX),e(WX,gIo),e(W1,hIo),e(y,uIo),e(y,U1),e(U1,v1e),e(v1e,pIo),e(U1,_Io),e(U1,UX),e(UX,bIo),e(U1,vIo),e(y,FIo),e(y,H1),e(H1,F1e),e(F1e,TIo),e(H1,MIo),e(H1,HX),e(HX,EIo),e(H1,CIo),e(y,wIo),e(y,J1),e(J1,T1e),e(T1e,AIo),e(J1,LIo),e(J1,JX),e(JX,yIo),e(J1,xIo),e(y,$Io),e(y,Y1),e(Y1,M1e),e(M1e,kIo),e(Y1,SIo),e(Y1,YX),e(YX,RIo),e(Y1,PIo),e(y,BIo),e(y,K1),e(K1,E1e),e(E1e,IIo),e(K1,NIo),e(K1,KX),e(KX,qIo),e(K1,jIo),e(y,DIo),e(y,Z1),e(Z1,C1e),e(C1e,GIo),e(Z1,OIo),e(Z1,ZX),e(ZX,VIo),e(Z1,XIo),e(y,zIo),e(y,e2),e(e2,w1e),e(w1e,QIo),e(e2,WIo),e(e2,ez),e(ez,UIo),e(e2,HIo),e(y,JIo),e(y,o2),e(o2,A1e),e(A1e,YIo),e(o2,KIo),e(o2,oz),e(oz,ZIo),e(o2,eNo),e(y,oNo),e(y,r2),e(r2,L1e),e(L1e,rNo),e(r2,tNo),e(r2,rz),e(rz,aNo),e(r2,nNo),e(y,sNo),e(y,t2),e(t2,y1e),e(y1e,lNo),e(t2,iNo),e(t2,tz),e(tz,dNo),e(t2,mNo),e(y,cNo),e(y,a2),e(a2,x1e),e(x1e,fNo),e(a2,gNo),e(a2,az),e(az,hNo),e(a2,uNo),e(y,pNo),e(y,n2),e(n2,$1e),e($1e,_No),e(n2,bNo),e(n2,nz),e(nz,vNo),e(n2,FNo),e(y,TNo),e(y,s2),e(s2,k1e),e(k1e,MNo),e(s2,ENo),e(s2,sz),e(sz,CNo),e(s2,wNo),e(y,ANo),e(y,l2),e(l2,S1e),e(S1e,LNo),e(l2,yNo),e(l2,lz),e(lz,xNo),e(l2,$No),e(y,kNo),e(y,i2),e(i2,R1e),e(R1e,SNo),e(i2,RNo),e(i2,iz),e(iz,PNo),e(i2,BNo),e(y,INo),e(y,d2),e(d2,P1e),e(P1e,NNo),e(d2,qNo),e(d2,dz),e(dz,jNo),e(d2,DNo),e(y,GNo),e(y,m2),e(m2,B1e),e(B1e,ONo),e(m2,VNo),e(m2,mz),e(mz,XNo),e(m2,zNo),e(y,QNo),e(y,c2),e(c2,I1e),e(I1e,WNo),e(c2,UNo),e(c2,cz),e(cz,HNo),e(c2,JNo),e(y,YNo),e(y,f2),e(f2,N1e),e(N1e,KNo),e(f2,ZNo),e(f2,fz),e(fz,eqo),e(f2,oqo),e(y,rqo),e(y,g2),e(g2,q1e),e(q1e,tqo),e(g2,aqo),e(g2,gz),e(gz,nqo),e(g2,sqo),e(y,lqo),e(y,h2),e(h2,j1e),e(j1e,iqo),e(h2,dqo),e(h2,hz),e(hz,mqo),e(h2,cqo),e(y,fqo),e(y,u2),e(u2,D1e),e(D1e,gqo),e(u2,hqo),e(u2,uz),e(uz,uqo),e(u2,pqo),e(y,_qo),e(y,p2),e(p2,G1e),e(G1e,bqo),e(p2,vqo),e(p2,pz),e(pz,Fqo),e(p2,Tqo),e(y,Mqo),e(y,_2),e(_2,O1e),e(O1e,Eqo),e(_2,Cqo),e(_2,_z),e(_z,wqo),e(_2,Aqo),e(y,Lqo),e(y,b2),e(b2,V1e),e(V1e,yqo),e(b2,xqo),e(b2,bz),e(bz,$qo),e(b2,kqo),e(y,Sqo),e(y,v2),e(v2,X1e),e(X1e,Rqo),e(v2,Pqo),e(v2,vz),e(vz,Bqo),e(v2,Iqo),e(y,Nqo),e(y,F2),e(F2,z1e),e(z1e,qqo),e(F2,jqo),e(F2,Fz),e(Fz,Dqo),e(F2,Gqo),e(y,Oqo),e(y,T2),e(T2,Q1e),e(Q1e,Vqo),e(T2,Xqo),e(T2,Tz),e(Tz,zqo),e(T2,Qqo),e(y,Wqo),e(y,M2),e(M2,W1e),e(W1e,Uqo),e(M2,Hqo),e(M2,Mz),e(Mz,Jqo),e(M2,Yqo),e(y,Kqo),e(y,E2),e(E2,U1e),e(U1e,Zqo),e(E2,ejo),e(E2,Ez),e(Ez,ojo),e(E2,rjo),e(y,tjo),e(y,C2),e(C2,H1e),e(H1e,ajo),e(C2,njo),e(C2,Cz),e(Cz,sjo),e(C2,ljo),e(y,ijo),e(y,w2),e(w2,J1e),e(J1e,djo),e(w2,mjo),e(w2,wz),e(wz,cjo),e(w2,fjo),e(y,gjo),e(y,A2),e(A2,Y1e),e(Y1e,hjo),e(A2,ujo),e(A2,Az),e(Az,pjo),e(A2,_jo),e(y,bjo),e(y,L2),e(L2,K1e),e(K1e,vjo),e(L2,Fjo),e(L2,Lz),e(Lz,Tjo),e(L2,Mjo),e(Ze,Ejo),e(Ze,y2),e(y2,Cjo),e(y2,Z1e),e(Z1e,wjo),e(y2,Ajo),e(y2,e2e),e(e2e,Ljo),e(Ze,yjo),M(x2,Ze,null),b(c,$eo,_),b(c,Fd,_),e(Fd,$2),e($2,o2e),M(jx,o2e,null),e(Fd,xjo),e(Fd,r2e),e(r2e,$jo),b(c,keo,_),b(c,Bo,_),M(Dx,Bo,null),e(Bo,kjo),e(Bo,Td),e(Td,Sjo),e(Td,yz),e(yz,Rjo),e(Td,Pjo),e(Td,xz),e(xz,Bjo),e(Td,Ijo),e(Bo,Njo),e(Bo,Gx),e(Gx,qjo),e(Gx,t2e),e(t2e,jjo),e(Gx,Djo),e(Bo,Gjo),e(Bo,bt),M(Ox,bt,null),e(bt,Ojo),e(bt,a2e),e(a2e,Vjo),e(bt,Xjo),e(bt,Md),e(Md,zjo),e(Md,n2e),e(n2e,Qjo),e(Md,Wjo),e(Md,$z),e($z,Ujo),e(Md,Hjo),e(bt,Jjo),M(k2,bt,null),e(Bo,Yjo),e(Bo,eo),M(Vx,eo,null),e(eo,Kjo),e(eo,s2e),e(s2e,Zjo),e(eo,eDo),e(eo,Ya),e(Ya,oDo),e(Ya,l2e),e(l2e,rDo),e(Ya,tDo),e(Ya,i2e),e(i2e,aDo),e(Ya,nDo),e(Ya,d2e),e(d2e,sDo),e(Ya,lDo),e(eo,iDo),e(eo,G),e(G,S2),e(S2,m2e),e(m2e,dDo),e(S2,mDo),e(S2,kz),e(kz,cDo),e(S2,fDo),e(G,gDo),e(G,R2),e(R2,c2e),e(c2e,hDo),e(R2,uDo),e(R2,Sz),e(Sz,pDo),e(R2,_Do),e(G,bDo),e(G,P2),e(P2,f2e),e(f2e,vDo),e(P2,FDo),e(P2,Rz),e(Rz,TDo),e(P2,MDo),e(G,EDo),e(G,B2),e(B2,g2e),e(g2e,CDo),e(B2,wDo),e(B2,Pz),e(Pz,ADo),e(B2,LDo),e(G,yDo),e(G,I2),e(I2,h2e),e(h2e,xDo),e(I2,$Do),e(I2,Bz),e(Bz,kDo),e(I2,SDo),e(G,RDo),e(G,N2),e(N2,u2e),e(u2e,PDo),e(N2,BDo),e(N2,Iz),e(Iz,IDo),e(N2,NDo),e(G,qDo),e(G,q2),e(q2,p2e),e(p2e,jDo),e(q2,DDo),e(q2,Nz),e(Nz,GDo),e(q2,ODo),e(G,VDo),e(G,j2),e(j2,_2e),e(_2e,XDo),e(j2,zDo),e(j2,qz),e(qz,QDo),e(j2,WDo),e(G,UDo),e(G,D2),e(D2,b2e),e(b2e,HDo),e(D2,JDo),e(D2,jz),e(jz,YDo),e(D2,KDo),e(G,ZDo),e(G,G2),e(G2,v2e),e(v2e,eGo),e(G2,oGo),e(G2,Dz),e(Dz,rGo),e(G2,tGo),e(G,aGo),e(G,O2),e(O2,F2e),e(F2e,nGo),e(O2,sGo),e(O2,Gz),e(Gz,lGo),e(O2,iGo),e(G,dGo),e(G,V2),e(V2,T2e),e(T2e,mGo),e(V2,cGo),e(V2,Oz),e(Oz,fGo),e(V2,gGo),e(G,hGo),e(G,X2),e(X2,M2e),e(M2e,uGo),e(X2,pGo),e(X2,Vz),e(Vz,_Go),e(X2,bGo),e(G,vGo),e(G,z2),e(z2,E2e),e(E2e,FGo),e(z2,TGo),e(z2,Xz),e(Xz,MGo),e(z2,EGo),e(G,CGo),e(G,Q2),e(Q2,C2e),e(C2e,wGo),e(Q2,AGo),e(Q2,zz),e(zz,LGo),e(Q2,yGo),e(G,xGo),e(G,W2),e(W2,w2e),e(w2e,$Go),e(W2,kGo),e(W2,Qz),e(Qz,SGo),e(W2,RGo),e(G,PGo),e(G,U2),e(U2,A2e),e(A2e,BGo),e(U2,IGo),e(U2,Wz),e(Wz,NGo),e(U2,qGo),e(G,jGo),e(G,H2),e(H2,L2e),e(L2e,DGo),e(H2,GGo),e(H2,Uz),e(Uz,OGo),e(H2,VGo),e(G,XGo),e(G,J2),e(J2,y2e),e(y2e,zGo),e(J2,QGo),e(J2,Hz),e(Hz,WGo),e(J2,UGo),e(G,HGo),e(G,Y2),e(Y2,x2e),e(x2e,JGo),e(Y2,YGo),e(Y2,Jz),e(Jz,KGo),e(Y2,ZGo),e(G,eOo),e(G,K2),e(K2,$2e),e($2e,oOo),e(K2,rOo),e(K2,Yz),e(Yz,tOo),e(K2,aOo),e(G,nOo),e(G,Z2),e(Z2,k2e),e(k2e,sOo),e(Z2,lOo),e(Z2,Kz),e(Kz,iOo),e(Z2,dOo),e(G,mOo),e(G,eb),e(eb,S2e),e(S2e,cOo),e(eb,fOo),e(eb,Zz),e(Zz,gOo),e(eb,hOo),e(G,uOo),e(G,ob),e(ob,R2e),e(R2e,pOo),e(ob,_Oo),e(ob,eQ),e(eQ,bOo),e(ob,vOo),e(G,FOo),e(G,rb),e(rb,P2e),e(P2e,TOo),e(rb,MOo),e(rb,oQ),e(oQ,EOo),e(rb,COo),e(G,wOo),e(G,tb),e(tb,B2e),e(B2e,AOo),e(tb,LOo),e(tb,rQ),e(rQ,yOo),e(tb,xOo),e(G,$Oo),e(G,ab),e(ab,I2e),e(I2e,kOo),e(ab,SOo),e(ab,tQ),e(tQ,ROo),e(ab,POo),e(G,BOo),e(G,nb),e(nb,N2e),e(N2e,IOo),e(nb,NOo),e(nb,aQ),e(aQ,qOo),e(nb,jOo),e(G,DOo),e(G,sb),e(sb,q2e),e(q2e,GOo),e(sb,OOo),e(sb,nQ),e(nQ,VOo),e(sb,XOo),e(G,zOo),e(G,lb),e(lb,j2e),e(j2e,QOo),e(lb,WOo),e(lb,sQ),e(sQ,UOo),e(lb,HOo),e(G,JOo),e(G,ib),e(ib,D2e),e(D2e,YOo),e(ib,KOo),e(ib,lQ),e(lQ,ZOo),e(ib,eVo),e(G,oVo),e(G,db),e(db,G2e),e(G2e,rVo),e(db,tVo),e(db,iQ),e(iQ,aVo),e(db,nVo),e(G,sVo),e(G,mb),e(mb,O2e),e(O2e,lVo),e(mb,iVo),e(mb,dQ),e(dQ,dVo),e(mb,mVo),e(G,cVo),e(G,cb),e(cb,V2e),e(V2e,fVo),e(cb,gVo),e(cb,mQ),e(mQ,hVo),e(cb,uVo),e(G,pVo),e(G,fb),e(fb,X2e),e(X2e,_Vo),e(fb,bVo),e(fb,cQ),e(cQ,vVo),e(fb,FVo),e(G,TVo),e(G,gb),e(gb,z2e),e(z2e,MVo),e(gb,EVo),e(gb,fQ),e(fQ,CVo),e(gb,wVo),e(G,AVo),e(G,hb),e(hb,Q2e),e(Q2e,LVo),e(hb,yVo),e(hb,gQ),e(gQ,xVo),e(hb,$Vo),e(G,kVo),e(G,ub),e(ub,W2e),e(W2e,SVo),e(ub,RVo),e(ub,hQ),e(hQ,PVo),e(ub,BVo),e(G,IVo),e(G,pb),e(pb,U2e),e(U2e,NVo),e(pb,qVo),e(pb,uQ),e(uQ,jVo),e(pb,DVo),e(G,GVo),e(G,_b),e(_b,H2e),e(H2e,OVo),e(_b,VVo),e(_b,pQ),e(pQ,XVo),e(_b,zVo),e(G,QVo),e(G,bb),e(bb,J2e),e(J2e,WVo),e(bb,UVo),e(bb,_Q),e(_Q,HVo),e(bb,JVo),e(G,YVo),e(G,vb),e(vb,Y2e),e(Y2e,KVo),e(vb,ZVo),e(vb,bQ),e(bQ,eXo),e(vb,oXo),e(G,rXo),e(G,Fb),e(Fb,K2e),e(K2e,tXo),e(Fb,aXo),e(Fb,vQ),e(vQ,nXo),e(Fb,sXo),e(G,lXo),e(G,Tb),e(Tb,Z2e),e(Z2e,iXo),e(Tb,dXo),e(Tb,FQ),e(FQ,mXo),e(Tb,cXo),e(G,fXo),e(G,Mb),e(Mb,ebe),e(ebe,gXo),e(Mb,hXo),e(Mb,TQ),e(TQ,uXo),e(Mb,pXo),e(G,_Xo),e(G,Eb),e(Eb,obe),e(obe,bXo),e(Eb,vXo),e(Eb,MQ),e(MQ,FXo),e(Eb,TXo),e(G,MXo),e(G,Cb),e(Cb,rbe),e(rbe,EXo),e(Cb,CXo),e(Cb,EQ),e(EQ,wXo),e(Cb,AXo),e(G,LXo),e(G,wb),e(wb,tbe),e(tbe,yXo),e(wb,xXo),e(wb,CQ),e(CQ,$Xo),e(wb,kXo),e(eo,SXo),e(eo,Ab),e(Ab,RXo),e(Ab,abe),e(abe,PXo),e(Ab,BXo),e(Ab,nbe),e(nbe,IXo),e(eo,NXo),M(Lb,eo,null),b(c,Seo,_),b(c,Ed,_),e(Ed,yb),e(yb,sbe),M(Xx,sbe,null),e(Ed,qXo),e(Ed,lbe),e(lbe,jXo),b(c,Reo,_),b(c,Io,_),M(zx,Io,null),e(Io,DXo),e(Io,Cd),e(Cd,GXo),e(Cd,wQ),e(wQ,OXo),e(Cd,VXo),e(Cd,AQ),e(AQ,XXo),e(Cd,zXo),e(Io,QXo),e(Io,Qx),e(Qx,WXo),e(Qx,ibe),e(ibe,UXo),e(Qx,HXo),e(Io,JXo),e(Io,vt),M(Wx,vt,null),e(vt,YXo),e(vt,dbe),e(dbe,KXo),e(vt,ZXo),e(vt,wd),e(wd,ezo),e(wd,mbe),e(mbe,ozo),e(wd,rzo),e(wd,LQ),e(LQ,tzo),e(wd,azo),e(vt,nzo),M(xb,vt,null),e(Io,szo),e(Io,oo),M(Ux,oo,null),e(oo,lzo),e(oo,cbe),e(cbe,izo),e(oo,dzo),e(oo,Ka),e(Ka,mzo),e(Ka,fbe),e(fbe,czo),e(Ka,fzo),e(Ka,gbe),e(gbe,gzo),e(Ka,hzo),e(Ka,hbe),e(hbe,uzo),e(Ka,pzo),e(oo,_zo),e(oo,Q),e(Q,$b),e($b,ube),e(ube,bzo),e($b,vzo),e($b,yQ),e(yQ,Fzo),e($b,Tzo),e(Q,Mzo),e(Q,kb),e(kb,pbe),e(pbe,Ezo),e(kb,Czo),e(kb,xQ),e(xQ,wzo),e(kb,Azo),e(Q,Lzo),e(Q,Sb),e(Sb,_be),e(_be,yzo),e(Sb,xzo),e(Sb,$Q),e($Q,$zo),e(Sb,kzo),e(Q,Szo),e(Q,Rb),e(Rb,bbe),e(bbe,Rzo),e(Rb,Pzo),e(Rb,kQ),e(kQ,Bzo),e(Rb,Izo),e(Q,Nzo),e(Q,Pb),e(Pb,vbe),e(vbe,qzo),e(Pb,jzo),e(Pb,SQ),e(SQ,Dzo),e(Pb,Gzo),e(Q,Ozo),e(Q,Bb),e(Bb,Fbe),e(Fbe,Vzo),e(Bb,Xzo),e(Bb,RQ),e(RQ,zzo),e(Bb,Qzo),e(Q,Wzo),e(Q,Ib),e(Ib,Tbe),e(Tbe,Uzo),e(Ib,Hzo),e(Ib,PQ),e(PQ,Jzo),e(Ib,Yzo),e(Q,Kzo),e(Q,Nb),e(Nb,Mbe),e(Mbe,Zzo),e(Nb,eQo),e(Nb,BQ),e(BQ,oQo),e(Nb,rQo),e(Q,tQo),e(Q,qb),e(qb,Ebe),e(Ebe,aQo),e(qb,nQo),e(qb,IQ),e(IQ,sQo),e(qb,lQo),e(Q,iQo),e(Q,jb),e(jb,Cbe),e(Cbe,dQo),e(jb,mQo),e(jb,NQ),e(NQ,cQo),e(jb,fQo),e(Q,gQo),e(Q,Db),e(Db,wbe),e(wbe,hQo),e(Db,uQo),e(Db,qQ),e(qQ,pQo),e(Db,_Qo),e(Q,bQo),e(Q,Gb),e(Gb,Abe),e(Abe,vQo),e(Gb,FQo),e(Gb,jQ),e(jQ,TQo),e(Gb,MQo),e(Q,EQo),e(Q,Ob),e(Ob,Lbe),e(Lbe,CQo),e(Ob,wQo),e(Ob,DQ),e(DQ,AQo),e(Ob,LQo),e(Q,yQo),e(Q,Vb),e(Vb,ybe),e(ybe,xQo),e(Vb,$Qo),e(Vb,GQ),e(GQ,kQo),e(Vb,SQo),e(Q,RQo),e(Q,Xb),e(Xb,xbe),e(xbe,PQo),e(Xb,BQo),e(Xb,OQ),e(OQ,IQo),e(Xb,NQo),e(Q,qQo),e(Q,zb),e(zb,$be),e($be,jQo),e(zb,DQo),e(zb,VQ),e(VQ,GQo),e(zb,OQo),e(Q,VQo),e(Q,Qb),e(Qb,kbe),e(kbe,XQo),e(Qb,zQo),e(Qb,XQ),e(XQ,QQo),e(Qb,WQo),e(Q,UQo),e(Q,Wb),e(Wb,Sbe),e(Sbe,HQo),e(Wb,JQo),e(Wb,zQ),e(zQ,YQo),e(Wb,KQo),e(Q,ZQo),e(Q,Ub),e(Ub,Rbe),e(Rbe,eWo),e(Ub,oWo),e(Ub,QQ),e(QQ,rWo),e(Ub,tWo),e(Q,aWo),e(Q,Hb),e(Hb,Pbe),e(Pbe,nWo),e(Hb,sWo),e(Hb,WQ),e(WQ,lWo),e(Hb,iWo),e(Q,dWo),e(Q,Jb),e(Jb,Bbe),e(Bbe,mWo),e(Jb,cWo),e(Jb,UQ),e(UQ,fWo),e(Jb,gWo),e(Q,hWo),e(Q,Yb),e(Yb,Ibe),e(Ibe,uWo),e(Yb,pWo),e(Yb,HQ),e(HQ,_Wo),e(Yb,bWo),e(Q,vWo),e(Q,Kb),e(Kb,Nbe),e(Nbe,FWo),e(Kb,TWo),e(Kb,JQ),e(JQ,MWo),e(Kb,EWo),e(Q,CWo),e(Q,Zb),e(Zb,qbe),e(qbe,wWo),e(Zb,AWo),e(Zb,YQ),e(YQ,LWo),e(Zb,yWo),e(Q,xWo),e(Q,ev),e(ev,jbe),e(jbe,$Wo),e(ev,kWo),e(ev,KQ),e(KQ,SWo),e(ev,RWo),e(Q,PWo),e(Q,ov),e(ov,Dbe),e(Dbe,BWo),e(ov,IWo),e(ov,ZQ),e(ZQ,NWo),e(ov,qWo),e(Q,jWo),e(Q,rv),e(rv,Gbe),e(Gbe,DWo),e(rv,GWo),e(rv,eW),e(eW,OWo),e(rv,VWo),e(Q,XWo),e(Q,tv),e(tv,Obe),e(Obe,zWo),e(tv,QWo),e(tv,oW),e(oW,WWo),e(tv,UWo),e(Q,HWo),e(Q,av),e(av,Vbe),e(Vbe,JWo),e(av,YWo),e(av,rW),e(rW,KWo),e(av,ZWo),e(Q,eUo),e(Q,nv),e(nv,Xbe),e(Xbe,oUo),e(nv,rUo),e(nv,tW),e(tW,tUo),e(nv,aUo),e(Q,nUo),e(Q,sv),e(sv,zbe),e(zbe,sUo),e(sv,lUo),e(sv,aW),e(aW,iUo),e(sv,dUo),e(Q,mUo),e(Q,lv),e(lv,Qbe),e(Qbe,cUo),e(lv,fUo),e(lv,nW),e(nW,gUo),e(lv,hUo),e(Q,uUo),e(Q,iv),e(iv,Wbe),e(Wbe,pUo),e(iv,_Uo),e(iv,sW),e(sW,bUo),e(iv,vUo),e(Q,FUo),e(Q,dv),e(dv,Ube),e(Ube,TUo),e(dv,MUo),e(dv,lW),e(lW,EUo),e(dv,CUo),e(Q,wUo),e(Q,mv),e(mv,Hbe),e(Hbe,AUo),e(mv,LUo),e(mv,iW),e(iW,yUo),e(mv,xUo),e(Q,$Uo),e(Q,cv),e(cv,Jbe),e(Jbe,kUo),e(cv,SUo),e(cv,dW),e(dW,RUo),e(cv,PUo),e(Q,BUo),e(Q,fv),e(fv,Ybe),e(Ybe,IUo),e(fv,NUo),e(fv,mW),e(mW,qUo),e(fv,jUo),e(Q,DUo),e(Q,gv),e(gv,Kbe),e(Kbe,GUo),e(gv,OUo),e(gv,cW),e(cW,VUo),e(gv,XUo),e(Q,zUo),e(Q,hv),e(hv,Zbe),e(Zbe,QUo),e(hv,WUo),e(hv,fW),e(fW,UUo),e(hv,HUo),e(Q,JUo),e(Q,uv),e(uv,eve),e(eve,YUo),e(uv,KUo),e(uv,gW),e(gW,ZUo),e(uv,eHo),e(Q,oHo),e(Q,pv),e(pv,ove),e(ove,rHo),e(pv,tHo),e(pv,hW),e(hW,aHo),e(pv,nHo),e(Q,sHo),e(Q,_v),e(_v,rve),e(rve,lHo),e(_v,iHo),e(_v,uW),e(uW,dHo),e(_v,mHo),e(oo,cHo),e(oo,bv),e(bv,fHo),e(bv,tve),e(tve,gHo),e(bv,hHo),e(bv,ave),e(ave,uHo),e(oo,pHo),M(vv,oo,null),b(c,Peo,_),b(c,Ad,_),e(Ad,Fv),e(Fv,nve),M(Hx,nve,null),e(Ad,_Ho),e(Ad,sve),e(sve,bHo),b(c,Beo,_),b(c,No,_),M(Jx,No,null),e(No,vHo),e(No,Ld),e(Ld,FHo),e(Ld,pW),e(pW,THo),e(Ld,MHo),e(Ld,_W),e(_W,EHo),e(Ld,CHo),e(No,wHo),e(No,Yx),e(Yx,AHo),e(Yx,lve),e(lve,LHo),e(Yx,yHo),e(No,xHo),e(No,Ft),M(Kx,Ft,null),e(Ft,$Ho),e(Ft,ive),e(ive,kHo),e(Ft,SHo),e(Ft,yd),e(yd,RHo),e(yd,dve),e(dve,PHo),e(yd,BHo),e(yd,bW),e(bW,IHo),e(yd,NHo),e(Ft,qHo),M(Tv,Ft,null),e(No,jHo),e(No,ro),M(Zx,ro,null),e(ro,DHo),e(ro,mve),e(mve,GHo),e(ro,OHo),e(ro,Za),e(Za,VHo),e(Za,cve),e(cve,XHo),e(Za,zHo),e(Za,fve),e(fve,QHo),e(Za,WHo),e(Za,gve),e(gve,UHo),e(Za,HHo),e(ro,JHo),e(ro,J),e(J,Mv),e(Mv,hve),e(hve,YHo),e(Mv,KHo),e(Mv,vW),e(vW,ZHo),e(Mv,eJo),e(J,oJo),e(J,Ev),e(Ev,uve),e(uve,rJo),e(Ev,tJo),e(Ev,FW),e(FW,aJo),e(Ev,nJo),e(J,sJo),e(J,Cv),e(Cv,pve),e(pve,lJo),e(Cv,iJo),e(Cv,TW),e(TW,dJo),e(Cv,mJo),e(J,cJo),e(J,wv),e(wv,_ve),e(_ve,fJo),e(wv,gJo),e(wv,MW),e(MW,hJo),e(wv,uJo),e(J,pJo),e(J,Av),e(Av,bve),e(bve,_Jo),e(Av,bJo),e(Av,EW),e(EW,vJo),e(Av,FJo),e(J,TJo),e(J,Lv),e(Lv,vve),e(vve,MJo),e(Lv,EJo),e(Lv,CW),e(CW,CJo),e(Lv,wJo),e(J,AJo),e(J,yv),e(yv,Fve),e(Fve,LJo),e(yv,yJo),e(yv,wW),e(wW,xJo),e(yv,$Jo),e(J,kJo),e(J,xv),e(xv,Tve),e(Tve,SJo),e(xv,RJo),e(xv,AW),e(AW,PJo),e(xv,BJo),e(J,IJo),e(J,$v),e($v,Mve),e(Mve,NJo),e($v,qJo),e($v,LW),e(LW,jJo),e($v,DJo),e(J,GJo),e(J,kv),e(kv,Eve),e(Eve,OJo),e(kv,VJo),e(kv,yW),e(yW,XJo),e(kv,zJo),e(J,QJo),e(J,Sv),e(Sv,Cve),e(Cve,WJo),e(Sv,UJo),e(Sv,xW),e(xW,HJo),e(Sv,JJo),e(J,YJo),e(J,Rv),e(Rv,wve),e(wve,KJo),e(Rv,ZJo),e(Rv,$W),e($W,eYo),e(Rv,oYo),e(J,rYo),e(J,Pv),e(Pv,Ave),e(Ave,tYo),e(Pv,aYo),e(Pv,kW),e(kW,nYo),e(Pv,sYo),e(J,lYo),e(J,Bv),e(Bv,Lve),e(Lve,iYo),e(Bv,dYo),e(Bv,SW),e(SW,mYo),e(Bv,cYo),e(J,fYo),e(J,Iv),e(Iv,yve),e(yve,gYo),e(Iv,hYo),e(Iv,RW),e(RW,uYo),e(Iv,pYo),e(J,_Yo),e(J,Nv),e(Nv,xve),e(xve,bYo),e(Nv,vYo),e(Nv,PW),e(PW,FYo),e(Nv,TYo),e(J,MYo),e(J,qv),e(qv,$ve),e($ve,EYo),e(qv,CYo),e(qv,BW),e(BW,wYo),e(qv,AYo),e(J,LYo),e(J,jv),e(jv,kve),e(kve,yYo),e(jv,xYo),e(jv,IW),e(IW,$Yo),e(jv,kYo),e(J,SYo),e(J,Dv),e(Dv,Sve),e(Sve,RYo),e(Dv,PYo),e(Dv,NW),e(NW,BYo),e(Dv,IYo),e(J,NYo),e(J,Gv),e(Gv,Rve),e(Rve,qYo),e(Gv,jYo),e(Gv,qW),e(qW,DYo),e(Gv,GYo),e(J,OYo),e(J,Ov),e(Ov,Pve),e(Pve,VYo),e(Ov,XYo),e(Ov,jW),e(jW,zYo),e(Ov,QYo),e(J,WYo),e(J,Vv),e(Vv,Bve),e(Bve,UYo),e(Vv,HYo),e(Vv,DW),e(DW,JYo),e(Vv,YYo),e(J,KYo),e(J,Xv),e(Xv,Ive),e(Ive,ZYo),e(Xv,eKo),e(Xv,GW),e(GW,oKo),e(Xv,rKo),e(J,tKo),e(J,zv),e(zv,Nve),e(Nve,aKo),e(zv,nKo),e(zv,OW),e(OW,sKo),e(zv,lKo),e(J,iKo),e(J,Qv),e(Qv,qve),e(qve,dKo),e(Qv,mKo),e(Qv,VW),e(VW,cKo),e(Qv,fKo),e(J,gKo),e(J,Wv),e(Wv,jve),e(jve,hKo),e(Wv,uKo),e(Wv,XW),e(XW,pKo),e(Wv,_Ko),e(J,bKo),e(J,Uv),e(Uv,Dve),e(Dve,vKo),e(Uv,FKo),e(Uv,zW),e(zW,TKo),e(Uv,MKo),e(J,EKo),e(J,Hv),e(Hv,Gve),e(Gve,CKo),e(Hv,wKo),e(Hv,QW),e(QW,AKo),e(Hv,LKo),e(J,yKo),e(J,Jv),e(Jv,Ove),e(Ove,xKo),e(Jv,$Ko),e(Jv,WW),e(WW,kKo),e(Jv,SKo),e(J,RKo),e(J,Yv),e(Yv,Vve),e(Vve,PKo),e(Yv,BKo),e(Yv,UW),e(UW,IKo),e(Yv,NKo),e(J,qKo),e(J,Kv),e(Kv,Xve),e(Xve,jKo),e(Kv,DKo),e(Kv,HW),e(HW,GKo),e(Kv,OKo),e(J,VKo),e(J,Zv),e(Zv,zve),e(zve,XKo),e(Zv,zKo),e(Zv,JW),e(JW,QKo),e(Zv,WKo),e(J,UKo),e(J,eF),e(eF,Qve),e(Qve,HKo),e(eF,JKo),e(eF,YW),e(YW,YKo),e(eF,KKo),e(J,ZKo),e(J,oF),e(oF,Wve),e(Wve,eZo),e(oF,oZo),e(oF,KW),e(KW,rZo),e(oF,tZo),e(J,aZo),e(J,rF),e(rF,Uve),e(Uve,nZo),e(rF,sZo),e(rF,Hve),e(Hve,lZo),e(rF,iZo),e(J,dZo),e(J,tF),e(tF,Jve),e(Jve,mZo),e(tF,cZo),e(tF,ZW),e(ZW,fZo),e(tF,gZo),e(J,hZo),e(J,aF),e(aF,Yve),e(Yve,uZo),e(aF,pZo),e(aF,eU),e(eU,_Zo),e(aF,bZo),e(J,vZo),e(J,nF),e(nF,Kve),e(Kve,FZo),e(nF,TZo),e(nF,oU),e(oU,MZo),e(nF,EZo),e(J,CZo),e(J,sF),e(sF,Zve),e(Zve,wZo),e(sF,AZo),e(sF,rU),e(rU,LZo),e(sF,yZo),e(ro,xZo),e(ro,lF),e(lF,$Zo),e(lF,eFe),e(eFe,kZo),e(lF,SZo),e(lF,oFe),e(oFe,RZo),e(ro,PZo),M(iF,ro,null),b(c,Ieo,_),b(c,xd,_),e(xd,dF),e(dF,rFe),M(e$,rFe,null),e(xd,BZo),e(xd,tFe),e(tFe,IZo),b(c,Neo,_),b(c,qo,_),M(o$,qo,null),e(qo,NZo),e(qo,$d),e($d,qZo),e($d,tU),e(tU,jZo),e($d,DZo),e($d,aU),e(aU,GZo),e($d,OZo),e(qo,VZo),e(qo,r$),e(r$,XZo),e(r$,aFe),e(aFe,zZo),e(r$,QZo),e(qo,WZo),e(qo,Tt),M(t$,Tt,null),e(Tt,UZo),e(Tt,nFe),e(nFe,HZo),e(Tt,JZo),e(Tt,kd),e(kd,YZo),e(kd,sFe),e(sFe,KZo),e(kd,ZZo),e(kd,nU),e(nU,eer),e(kd,oer),e(Tt,rer),M(mF,Tt,null),e(qo,ter),e(qo,to),M(a$,to,null),e(to,aer),e(to,lFe),e(lFe,ner),e(to,ser),e(to,en),e(en,ler),e(en,iFe),e(iFe,ier),e(en,der),e(en,dFe),e(dFe,mer),e(en,cer),e(en,mFe),e(mFe,fer),e(en,ger),e(to,her),e(to,fe),e(fe,cF),e(cF,cFe),e(cFe,uer),e(cF,per),e(cF,sU),e(sU,_er),e(cF,ber),e(fe,ver),e(fe,fF),e(fF,fFe),e(fFe,Fer),e(fF,Ter),e(fF,lU),e(lU,Mer),e(fF,Eer),e(fe,Cer),e(fe,gF),e(gF,gFe),e(gFe,wer),e(gF,Aer),e(gF,iU),e(iU,Ler),e(gF,yer),e(fe,xer),e(fe,hF),e(hF,hFe),e(hFe,$er),e(hF,ker),e(hF,dU),e(dU,Ser),e(hF,Rer),e(fe,Per),e(fe,uF),e(uF,uFe),e(uFe,Ber),e(uF,Ier),e(uF,mU),e(mU,Ner),e(uF,qer),e(fe,jer),e(fe,pF),e(pF,pFe),e(pFe,Der),e(pF,Ger),e(pF,cU),e(cU,Oer),e(pF,Ver),e(fe,Xer),e(fe,_F),e(_F,_Fe),e(_Fe,zer),e(_F,Qer),e(_F,fU),e(fU,Wer),e(_F,Uer),e(fe,Her),e(fe,bF),e(bF,bFe),e(bFe,Jer),e(bF,Yer),e(bF,gU),e(gU,Ker),e(bF,Zer),e(fe,eor),e(fe,vF),e(vF,vFe),e(vFe,oor),e(vF,ror),e(vF,hU),e(hU,tor),e(vF,aor),e(fe,nor),e(fe,FF),e(FF,FFe),e(FFe,sor),e(FF,lor),e(FF,uU),e(uU,ior),e(FF,dor),e(fe,mor),e(fe,TF),e(TF,TFe),e(TFe,cor),e(TF,gor),e(TF,pU),e(pU,hor),e(TF,uor),e(fe,por),e(fe,MF),e(MF,MFe),e(MFe,_or),e(MF,bor),e(MF,_U),e(_U,vor),e(MF,For),e(fe,Tor),e(fe,EF),e(EF,EFe),e(EFe,Mor),e(EF,Eor),e(EF,bU),e(bU,Cor),e(EF,wor),e(fe,Aor),e(fe,CF),e(CF,CFe),e(CFe,Lor),e(CF,yor),e(CF,vU),e(vU,xor),e(CF,$or),e(fe,kor),e(fe,wF),e(wF,wFe),e(wFe,Sor),e(wF,Ror),e(wF,FU),e(FU,Por),e(wF,Bor),e(fe,Ior),e(fe,AF),e(AF,AFe),e(AFe,Nor),e(AF,qor),e(AF,TU),e(TU,jor),e(AF,Dor),e(fe,Gor),e(fe,LF),e(LF,LFe),e(LFe,Oor),e(LF,Vor),e(LF,MU),e(MU,Xor),e(LF,zor),e(fe,Qor),e(fe,yF),e(yF,yFe),e(yFe,Wor),e(yF,Uor),e(yF,EU),e(EU,Hor),e(yF,Jor),e(fe,Yor),e(fe,xF),e(xF,xFe),e(xFe,Kor),e(xF,Zor),e(xF,CU),e(CU,err),e(xF,orr),e(fe,rrr),e(fe,$F),e($F,$Fe),e($Fe,trr),e($F,arr),e($F,wU),e(wU,nrr),e($F,srr),e(to,lrr),e(to,kF),e(kF,irr),e(kF,kFe),e(kFe,drr),e(kF,mrr),e(kF,SFe),e(SFe,crr),e(to,frr),M(SF,to,null),b(c,qeo,_),b(c,Sd,_),e(Sd,RF),e(RF,RFe),M(n$,RFe,null),e(Sd,grr),e(Sd,PFe),e(PFe,hrr),b(c,jeo,_),b(c,jo,_),M(s$,jo,null),e(jo,urr),e(jo,Rd),e(Rd,prr),e(Rd,AU),e(AU,_rr),e(Rd,brr),e(Rd,LU),e(LU,vrr),e(Rd,Frr),e(jo,Trr),e(jo,l$),e(l$,Mrr),e(l$,BFe),e(BFe,Err),e(l$,Crr),e(jo,wrr),e(jo,Mt),M(i$,Mt,null),e(Mt,Arr),e(Mt,IFe),e(IFe,Lrr),e(Mt,yrr),e(Mt,Pd),e(Pd,xrr),e(Pd,NFe),e(NFe,$rr),e(Pd,krr),e(Pd,yU),e(yU,Srr),e(Pd,Rrr),e(Mt,Prr),M(PF,Mt,null),e(jo,Brr),e(jo,ao),M(d$,ao,null),e(ao,Irr),e(ao,qFe),e(qFe,Nrr),e(ao,qrr),e(ao,on),e(on,jrr),e(on,jFe),e(jFe,Drr),e(on,Grr),e(on,DFe),e(DFe,Orr),e(on,Vrr),e(on,GFe),e(GFe,Xrr),e(on,zrr),e(ao,Qrr),e(ao,B),e(B,BF),e(BF,OFe),e(OFe,Wrr),e(BF,Urr),e(BF,xU),e(xU,Hrr),e(BF,Jrr),e(B,Yrr),e(B,IF),e(IF,VFe),e(VFe,Krr),e(IF,Zrr),e(IF,$U),e($U,etr),e(IF,otr),e(B,rtr),e(B,NF),e(NF,XFe),e(XFe,ttr),e(NF,atr),e(NF,kU),e(kU,ntr),e(NF,str),e(B,ltr),e(B,qF),e(qF,zFe),e(zFe,itr),e(qF,dtr),e(qF,SU),e(SU,mtr),e(qF,ctr),e(B,ftr),e(B,jF),e(jF,QFe),e(QFe,gtr),e(jF,htr),e(jF,RU),e(RU,utr),e(jF,ptr),e(B,_tr),e(B,DF),e(DF,WFe),e(WFe,btr),e(DF,vtr),e(DF,PU),e(PU,Ftr),e(DF,Ttr),e(B,Mtr),e(B,GF),e(GF,UFe),e(UFe,Etr),e(GF,Ctr),e(GF,BU),e(BU,wtr),e(GF,Atr),e(B,Ltr),e(B,OF),e(OF,HFe),e(HFe,ytr),e(OF,xtr),e(OF,IU),e(IU,$tr),e(OF,ktr),e(B,Str),e(B,VF),e(VF,JFe),e(JFe,Rtr),e(VF,Ptr),e(VF,NU),e(NU,Btr),e(VF,Itr),e(B,Ntr),e(B,XF),e(XF,YFe),e(YFe,qtr),e(XF,jtr),e(XF,qU),e(qU,Dtr),e(XF,Gtr),e(B,Otr),e(B,zF),e(zF,KFe),e(KFe,Vtr),e(zF,Xtr),e(zF,jU),e(jU,ztr),e(zF,Qtr),e(B,Wtr),e(B,QF),e(QF,ZFe),e(ZFe,Utr),e(QF,Htr),e(QF,DU),e(DU,Jtr),e(QF,Ytr),e(B,Ktr),e(B,WF),e(WF,eTe),e(eTe,Ztr),e(WF,ear),e(WF,GU),e(GU,oar),e(WF,rar),e(B,tar),e(B,UF),e(UF,oTe),e(oTe,aar),e(UF,nar),e(UF,OU),e(OU,sar),e(UF,lar),e(B,iar),e(B,HF),e(HF,rTe),e(rTe,dar),e(HF,mar),e(HF,VU),e(VU,car),e(HF,far),e(B,gar),e(B,JF),e(JF,tTe),e(tTe,har),e(JF,uar),e(JF,XU),e(XU,par),e(JF,_ar),e(B,bar),e(B,YF),e(YF,aTe),e(aTe,Far),e(YF,Tar),e(YF,zU),e(zU,Mar),e(YF,Ear),e(B,Car),e(B,KF),e(KF,nTe),e(nTe,war),e(KF,Aar),e(KF,QU),e(QU,Lar),e(KF,yar),e(B,xar),e(B,ZF),e(ZF,sTe),e(sTe,$ar),e(ZF,kar),e(ZF,WU),e(WU,Sar),e(ZF,Rar),e(B,Par),e(B,eT),e(eT,lTe),e(lTe,Bar),e(eT,Iar),e(eT,UU),e(UU,Nar),e(eT,qar),e(B,jar),e(B,oT),e(oT,iTe),e(iTe,Dar),e(oT,Gar),e(oT,HU),e(HU,Oar),e(oT,Var),e(B,Xar),e(B,rT),e(rT,dTe),e(dTe,zar),e(rT,Qar),e(rT,JU),e(JU,War),e(rT,Uar),e(B,Har),e(B,tT),e(tT,mTe),e(mTe,Jar),e(tT,Yar),e(tT,YU),e(YU,Kar),e(tT,Zar),e(B,enr),e(B,aT),e(aT,cTe),e(cTe,onr),e(aT,rnr),e(aT,KU),e(KU,tnr),e(aT,anr),e(B,nnr),e(B,nT),e(nT,fTe),e(fTe,snr),e(nT,lnr),e(nT,ZU),e(ZU,inr),e(nT,dnr),e(B,mnr),e(B,sT),e(sT,gTe),e(gTe,cnr),e(sT,fnr),e(sT,eH),e(eH,gnr),e(sT,hnr),e(B,unr),e(B,lT),e(lT,hTe),e(hTe,pnr),e(lT,_nr),e(lT,oH),e(oH,bnr),e(lT,vnr),e(B,Fnr),e(B,iT),e(iT,uTe),e(uTe,Tnr),e(iT,Mnr),e(iT,rH),e(rH,Enr),e(iT,Cnr),e(B,wnr),e(B,dT),e(dT,pTe),e(pTe,Anr),e(dT,Lnr),e(dT,tH),e(tH,ynr),e(dT,xnr),e(B,$nr),e(B,mT),e(mT,_Te),e(_Te,knr),e(mT,Snr),e(mT,aH),e(aH,Rnr),e(mT,Pnr),e(B,Bnr),e(B,cT),e(cT,bTe),e(bTe,Inr),e(cT,Nnr),e(cT,nH),e(nH,qnr),e(cT,jnr),e(B,Dnr),e(B,fT),e(fT,vTe),e(vTe,Gnr),e(fT,Onr),e(fT,sH),e(sH,Vnr),e(fT,Xnr),e(B,znr),e(B,gT),e(gT,FTe),e(FTe,Qnr),e(gT,Wnr),e(gT,lH),e(lH,Unr),e(gT,Hnr),e(B,Jnr),e(B,hT),e(hT,TTe),e(TTe,Ynr),e(hT,Knr),e(hT,iH),e(iH,Znr),e(hT,esr),e(B,osr),e(B,uT),e(uT,MTe),e(MTe,rsr),e(uT,tsr),e(uT,dH),e(dH,asr),e(uT,nsr),e(B,ssr),e(B,pT),e(pT,ETe),e(ETe,lsr),e(pT,isr),e(pT,mH),e(mH,dsr),e(pT,msr),e(B,csr),e(B,_T),e(_T,CTe),e(CTe,fsr),e(_T,gsr),e(_T,cH),e(cH,hsr),e(_T,usr),e(B,psr),e(B,bT),e(bT,wTe),e(wTe,_sr),e(bT,bsr),e(bT,fH),e(fH,vsr),e(bT,Fsr),e(B,Tsr),e(B,vT),e(vT,ATe),e(ATe,Msr),e(vT,Esr),e(vT,gH),e(gH,Csr),e(vT,wsr),e(B,Asr),e(B,FT),e(FT,LTe),e(LTe,Lsr),e(FT,ysr),e(FT,hH),e(hH,xsr),e(FT,$sr),e(B,ksr),e(B,TT),e(TT,yTe),e(yTe,Ssr),e(TT,Rsr),e(TT,uH),e(uH,Psr),e(TT,Bsr),e(B,Isr),e(B,MT),e(MT,xTe),e(xTe,Nsr),e(MT,qsr),e(MT,pH),e(pH,jsr),e(MT,Dsr),e(B,Gsr),e(B,ET),e(ET,$Te),e($Te,Osr),e(ET,Vsr),e(ET,_H),e(_H,Xsr),e(ET,zsr),e(B,Qsr),e(B,CT),e(CT,kTe),e(kTe,Wsr),e(CT,Usr),e(CT,bH),e(bH,Hsr),e(CT,Jsr),e(B,Ysr),e(B,wT),e(wT,STe),e(STe,Ksr),e(wT,Zsr),e(wT,vH),e(vH,elr),e(wT,olr),e(B,rlr),e(B,AT),e(AT,RTe),e(RTe,tlr),e(AT,alr),e(AT,FH),e(FH,nlr),e(AT,slr),e(B,llr),e(B,LT),e(LT,PTe),e(PTe,ilr),e(LT,dlr),e(LT,TH),e(TH,mlr),e(LT,clr),e(B,flr),e(B,yT),e(yT,BTe),e(BTe,glr),e(yT,hlr),e(yT,MH),e(MH,ulr),e(yT,plr),e(B,_lr),e(B,xT),e(xT,ITe),e(ITe,blr),e(xT,vlr),e(xT,EH),e(EH,Flr),e(xT,Tlr),e(B,Mlr),e(B,$T),e($T,NTe),e(NTe,Elr),e($T,Clr),e($T,CH),e(CH,wlr),e($T,Alr),e(B,Llr),e(B,kT),e(kT,qTe),e(qTe,ylr),e(kT,xlr),e(kT,wH),e(wH,$lr),e(kT,klr),e(B,Slr),e(B,ST),e(ST,jTe),e(jTe,Rlr),e(ST,Plr),e(ST,AH),e(AH,Blr),e(ST,Ilr),e(B,Nlr),e(B,RT),e(RT,DTe),e(DTe,qlr),e(RT,jlr),e(RT,LH),e(LH,Dlr),e(RT,Glr),e(B,Olr),e(B,PT),e(PT,GTe),e(GTe,Vlr),e(PT,Xlr),e(PT,yH),e(yH,zlr),e(PT,Qlr),e(B,Wlr),e(B,BT),e(BT,OTe),e(OTe,Ulr),e(BT,Hlr),e(BT,xH),e(xH,Jlr),e(BT,Ylr),e(ao,Klr),e(ao,IT),e(IT,Zlr),e(IT,VTe),e(VTe,eir),e(IT,oir),e(IT,XTe),e(XTe,rir),e(ao,tir),M(NT,ao,null),b(c,Deo,_),b(c,Bd,_),e(Bd,qT),e(qT,zTe),M(m$,zTe,null),e(Bd,air),e(Bd,QTe),e(QTe,nir),b(c,Geo,_),b(c,Do,_),M(c$,Do,null),e(Do,sir),e(Do,Id),e(Id,lir),e(Id,$H),e($H,iir),e(Id,dir),e(Id,kH),e(kH,mir),e(Id,cir),e(Do,fir),e(Do,f$),e(f$,gir),e(f$,WTe),e(WTe,hir),e(f$,uir),e(Do,pir),e(Do,Et),M(g$,Et,null),e(Et,_ir),e(Et,UTe),e(UTe,bir),e(Et,vir),e(Et,Nd),e(Nd,Fir),e(Nd,HTe),e(HTe,Tir),e(Nd,Mir),e(Nd,SH),e(SH,Eir),e(Nd,Cir),e(Et,wir),M(jT,Et,null),e(Do,Air),e(Do,no),M(h$,no,null),e(no,Lir),e(no,JTe),e(JTe,yir),e(no,xir),e(no,rn),e(rn,$ir),e(rn,YTe),e(YTe,kir),e(rn,Sir),e(rn,KTe),e(KTe,Rir),e(rn,Pir),e(rn,ZTe),e(ZTe,Bir),e(rn,Iir),e(no,Nir),e(no,Z),e(Z,DT),e(DT,eMe),e(eMe,qir),e(DT,jir),e(DT,RH),e(RH,Dir),e(DT,Gir),e(Z,Oir),e(Z,GT),e(GT,oMe),e(oMe,Vir),e(GT,Xir),e(GT,PH),e(PH,zir),e(GT,Qir),e(Z,Wir),e(Z,OT),e(OT,rMe),e(rMe,Uir),e(OT,Hir),e(OT,BH),e(BH,Jir),e(OT,Yir),e(Z,Kir),e(Z,VT),e(VT,tMe),e(tMe,Zir),e(VT,edr),e(VT,IH),e(IH,odr),e(VT,rdr),e(Z,tdr),e(Z,XT),e(XT,aMe),e(aMe,adr),e(XT,ndr),e(XT,NH),e(NH,sdr),e(XT,ldr),e(Z,idr),e(Z,zT),e(zT,nMe),e(nMe,ddr),e(zT,mdr),e(zT,qH),e(qH,cdr),e(zT,fdr),e(Z,gdr),e(Z,QT),e(QT,sMe),e(sMe,hdr),e(QT,udr),e(QT,jH),e(jH,pdr),e(QT,_dr),e(Z,bdr),e(Z,WT),e(WT,lMe),e(lMe,vdr),e(WT,Fdr),e(WT,DH),e(DH,Tdr),e(WT,Mdr),e(Z,Edr),e(Z,UT),e(UT,iMe),e(iMe,Cdr),e(UT,wdr),e(UT,GH),e(GH,Adr),e(UT,Ldr),e(Z,ydr),e(Z,HT),e(HT,dMe),e(dMe,xdr),e(HT,$dr),e(HT,OH),e(OH,kdr),e(HT,Sdr),e(Z,Rdr),e(Z,JT),e(JT,mMe),e(mMe,Pdr),e(JT,Bdr),e(JT,VH),e(VH,Idr),e(JT,Ndr),e(Z,qdr),e(Z,YT),e(YT,cMe),e(cMe,jdr),e(YT,Ddr),e(YT,XH),e(XH,Gdr),e(YT,Odr),e(Z,Vdr),e(Z,KT),e(KT,fMe),e(fMe,Xdr),e(KT,zdr),e(KT,zH),e(zH,Qdr),e(KT,Wdr),e(Z,Udr),e(Z,ZT),e(ZT,gMe),e(gMe,Hdr),e(ZT,Jdr),e(ZT,QH),e(QH,Ydr),e(ZT,Kdr),e(Z,Zdr),e(Z,eM),e(eM,hMe),e(hMe,emr),e(eM,omr),e(eM,WH),e(WH,rmr),e(eM,tmr),e(Z,amr),e(Z,oM),e(oM,uMe),e(uMe,nmr),e(oM,smr),e(oM,UH),e(UH,lmr),e(oM,imr),e(Z,dmr),e(Z,rM),e(rM,pMe),e(pMe,mmr),e(rM,cmr),e(rM,HH),e(HH,fmr),e(rM,gmr),e(Z,hmr),e(Z,tM),e(tM,_Me),e(_Me,umr),e(tM,pmr),e(tM,JH),e(JH,_mr),e(tM,bmr),e(Z,vmr),e(Z,aM),e(aM,bMe),e(bMe,Fmr),e(aM,Tmr),e(aM,YH),e(YH,Mmr),e(aM,Emr),e(Z,Cmr),e(Z,nM),e(nM,vMe),e(vMe,wmr),e(nM,Amr),e(nM,KH),e(KH,Lmr),e(nM,ymr),e(Z,xmr),e(Z,sM),e(sM,FMe),e(FMe,$mr),e(sM,kmr),e(sM,ZH),e(ZH,Smr),e(sM,Rmr),e(Z,Pmr),e(Z,lM),e(lM,TMe),e(TMe,Bmr),e(lM,Imr),e(lM,eJ),e(eJ,Nmr),e(lM,qmr),e(Z,jmr),e(Z,iM),e(iM,MMe),e(MMe,Dmr),e(iM,Gmr),e(iM,oJ),e(oJ,Omr),e(iM,Vmr),e(Z,Xmr),e(Z,dM),e(dM,EMe),e(EMe,zmr),e(dM,Qmr),e(dM,rJ),e(rJ,Wmr),e(dM,Umr),e(Z,Hmr),e(Z,mM),e(mM,CMe),e(CMe,Jmr),e(mM,Ymr),e(mM,tJ),e(tJ,Kmr),e(mM,Zmr),e(Z,ecr),e(Z,cM),e(cM,wMe),e(wMe,ocr),e(cM,rcr),e(cM,aJ),e(aJ,tcr),e(cM,acr),e(Z,ncr),e(Z,fM),e(fM,AMe),e(AMe,scr),e(fM,lcr),e(fM,nJ),e(nJ,icr),e(fM,dcr),e(Z,mcr),e(Z,gM),e(gM,LMe),e(LMe,ccr),e(gM,fcr),e(gM,sJ),e(sJ,gcr),e(gM,hcr),e(Z,ucr),e(Z,hM),e(hM,yMe),e(yMe,pcr),e(hM,_cr),e(hM,lJ),e(lJ,bcr),e(hM,vcr),e(Z,Fcr),e(Z,uM),e(uM,xMe),e(xMe,Tcr),e(uM,Mcr),e(uM,iJ),e(iJ,Ecr),e(uM,Ccr),e(Z,wcr),e(Z,pM),e(pM,$Me),e($Me,Acr),e(pM,Lcr),e(pM,dJ),e(dJ,ycr),e(pM,xcr),e(Z,$cr),e(Z,_M),e(_M,kMe),e(kMe,kcr),e(_M,Scr),e(_M,mJ),e(mJ,Rcr),e(_M,Pcr),e(no,Bcr),e(no,bM),e(bM,Icr),e(bM,SMe),e(SMe,Ncr),e(bM,qcr),e(bM,RMe),e(RMe,jcr),e(no,Dcr),M(vM,no,null),b(c,Oeo,_),b(c,qd,_),e(qd,FM),e(FM,PMe),M(u$,PMe,null),e(qd,Gcr),e(qd,BMe),e(BMe,Ocr),b(c,Veo,_),b(c,Go,_),M(p$,Go,null),e(Go,Vcr),e(Go,jd),e(jd,Xcr),e(jd,cJ),e(cJ,zcr),e(jd,Qcr),e(jd,fJ),e(fJ,Wcr),e(jd,Ucr),e(Go,Hcr),e(Go,_$),e(_$,Jcr),e(_$,IMe),e(IMe,Ycr),e(_$,Kcr),e(Go,Zcr),e(Go,Ct),M(b$,Ct,null),e(Ct,efr),e(Ct,NMe),e(NMe,ofr),e(Ct,rfr),e(Ct,Dd),e(Dd,tfr),e(Dd,qMe),e(qMe,afr),e(Dd,nfr),e(Dd,gJ),e(gJ,sfr),e(Dd,lfr),e(Ct,ifr),M(TM,Ct,null),e(Go,dfr),e(Go,so),M(v$,so,null),e(so,mfr),e(so,jMe),e(jMe,cfr),e(so,ffr),e(so,tn),e(tn,gfr),e(tn,DMe),e(DMe,hfr),e(tn,ufr),e(tn,GMe),e(GMe,pfr),e(tn,_fr),e(tn,OMe),e(OMe,bfr),e(tn,vfr),e(so,Ffr),e(so,Ue),e(Ue,MM),e(MM,VMe),e(VMe,Tfr),e(MM,Mfr),e(MM,hJ),e(hJ,Efr),e(MM,Cfr),e(Ue,wfr),e(Ue,EM),e(EM,XMe),e(XMe,Afr),e(EM,Lfr),e(EM,uJ),e(uJ,yfr),e(EM,xfr),e(Ue,$fr),e(Ue,CM),e(CM,zMe),e(zMe,kfr),e(CM,Sfr),e(CM,pJ),e(pJ,Rfr),e(CM,Pfr),e(Ue,Bfr),e(Ue,wM),e(wM,QMe),e(QMe,Ifr),e(wM,Nfr),e(wM,_J),e(_J,qfr),e(wM,jfr),e(Ue,Dfr),e(Ue,AM),e(AM,WMe),e(WMe,Gfr),e(AM,Ofr),e(AM,bJ),e(bJ,Vfr),e(AM,Xfr),e(Ue,zfr),e(Ue,LM),e(LM,UMe),e(UMe,Qfr),e(LM,Wfr),e(LM,vJ),e(vJ,Ufr),e(LM,Hfr),e(Ue,Jfr),e(Ue,yM),e(yM,HMe),e(HMe,Yfr),e(yM,Kfr),e(yM,FJ),e(FJ,Zfr),e(yM,egr),e(so,ogr),e(so,xM),e(xM,rgr),e(xM,JMe),e(JMe,tgr),e(xM,agr),e(xM,YMe),e(YMe,ngr),e(so,sgr),M($M,so,null),b(c,Xeo,_),b(c,Gd,_),e(Gd,kM),e(kM,KMe),M(F$,KMe,null),e(Gd,lgr),e(Gd,ZMe),e(ZMe,igr),b(c,zeo,_),b(c,Oo,_),M(T$,Oo,null),e(Oo,dgr),e(Oo,Od),e(Od,mgr),e(Od,TJ),e(TJ,cgr),e(Od,fgr),e(Od,MJ),e(MJ,ggr),e(Od,hgr),e(Oo,ugr),e(Oo,M$),e(M$,pgr),e(M$,eEe),e(eEe,_gr),e(M$,bgr),e(Oo,vgr),e(Oo,wt),M(E$,wt,null),e(wt,Fgr),e(wt,oEe),e(oEe,Tgr),e(wt,Mgr),e(wt,Vd),e(Vd,Egr),e(Vd,rEe),e(rEe,Cgr),e(Vd,wgr),e(Vd,EJ),e(EJ,Agr),e(Vd,Lgr),e(wt,ygr),M(SM,wt,null),e(Oo,xgr),e(Oo,lo),M(C$,lo,null),e(lo,$gr),e(lo,tEe),e(tEe,kgr),e(lo,Sgr),e(lo,an),e(an,Rgr),e(an,aEe),e(aEe,Pgr),e(an,Bgr),e(an,nEe),e(nEe,Igr),e(an,Ngr),e(an,sEe),e(sEe,qgr),e(an,jgr),e(lo,Dgr),e(lo,H),e(H,RM),e(RM,lEe),e(lEe,Ggr),e(RM,Ogr),e(RM,CJ),e(CJ,Vgr),e(RM,Xgr),e(H,zgr),e(H,PM),e(PM,iEe),e(iEe,Qgr),e(PM,Wgr),e(PM,wJ),e(wJ,Ugr),e(PM,Hgr),e(H,Jgr),e(H,BM),e(BM,dEe),e(dEe,Ygr),e(BM,Kgr),e(BM,AJ),e(AJ,Zgr),e(BM,ehr),e(H,ohr),e(H,IM),e(IM,mEe),e(mEe,rhr),e(IM,thr),e(IM,LJ),e(LJ,ahr),e(IM,nhr),e(H,shr),e(H,NM),e(NM,cEe),e(cEe,lhr),e(NM,ihr),e(NM,yJ),e(yJ,dhr),e(NM,mhr),e(H,chr),e(H,qM),e(qM,fEe),e(fEe,fhr),e(qM,ghr),e(qM,xJ),e(xJ,hhr),e(qM,uhr),e(H,phr),e(H,jM),e(jM,gEe),e(gEe,_hr),e(jM,bhr),e(jM,$J),e($J,vhr),e(jM,Fhr),e(H,Thr),e(H,DM),e(DM,hEe),e(hEe,Mhr),e(DM,Ehr),e(DM,kJ),e(kJ,Chr),e(DM,whr),e(H,Ahr),e(H,GM),e(GM,uEe),e(uEe,Lhr),e(GM,yhr),e(GM,SJ),e(SJ,xhr),e(GM,$hr),e(H,khr),e(H,OM),e(OM,pEe),e(pEe,Shr),e(OM,Rhr),e(OM,RJ),e(RJ,Phr),e(OM,Bhr),e(H,Ihr),e(H,VM),e(VM,_Ee),e(_Ee,Nhr),e(VM,qhr),e(VM,PJ),e(PJ,jhr),e(VM,Dhr),e(H,Ghr),e(H,XM),e(XM,bEe),e(bEe,Ohr),e(XM,Vhr),e(XM,BJ),e(BJ,Xhr),e(XM,zhr),e(H,Qhr),e(H,zM),e(zM,vEe),e(vEe,Whr),e(zM,Uhr),e(zM,IJ),e(IJ,Hhr),e(zM,Jhr),e(H,Yhr),e(H,QM),e(QM,FEe),e(FEe,Khr),e(QM,Zhr),e(QM,NJ),e(NJ,eur),e(QM,our),e(H,rur),e(H,WM),e(WM,TEe),e(TEe,tur),e(WM,aur),e(WM,qJ),e(qJ,nur),e(WM,sur),e(H,lur),e(H,UM),e(UM,MEe),e(MEe,iur),e(UM,dur),e(UM,jJ),e(jJ,mur),e(UM,cur),e(H,fur),e(H,HM),e(HM,EEe),e(EEe,gur),e(HM,hur),e(HM,DJ),e(DJ,uur),e(HM,pur),e(H,_ur),e(H,JM),e(JM,CEe),e(CEe,bur),e(JM,vur),e(JM,GJ),e(GJ,Fur),e(JM,Tur),e(H,Mur),e(H,YM),e(YM,wEe),e(wEe,Eur),e(YM,Cur),e(YM,OJ),e(OJ,wur),e(YM,Aur),e(H,Lur),e(H,KM),e(KM,AEe),e(AEe,yur),e(KM,xur),e(KM,VJ),e(VJ,$ur),e(KM,kur),e(H,Sur),e(H,ZM),e(ZM,LEe),e(LEe,Rur),e(ZM,Pur),e(ZM,XJ),e(XJ,Bur),e(ZM,Iur),e(H,Nur),e(H,eE),e(eE,yEe),e(yEe,qur),e(eE,jur),e(eE,zJ),e(zJ,Dur),e(eE,Gur),e(H,Our),e(H,oE),e(oE,xEe),e(xEe,Vur),e(oE,Xur),e(oE,QJ),e(QJ,zur),e(oE,Qur),e(H,Wur),e(H,rE),e(rE,$Ee),e($Ee,Uur),e(rE,Hur),e(rE,WJ),e(WJ,Jur),e(rE,Yur),e(H,Kur),e(H,tE),e(tE,kEe),e(kEe,Zur),e(tE,epr),e(tE,UJ),e(UJ,opr),e(tE,rpr),e(H,tpr),e(H,aE),e(aE,SEe),e(SEe,apr),e(aE,npr),e(aE,HJ),e(HJ,spr),e(aE,lpr),e(H,ipr),e(H,nE),e(nE,REe),e(REe,dpr),e(nE,mpr),e(nE,JJ),e(JJ,cpr),e(nE,fpr),e(H,gpr),e(H,sE),e(sE,PEe),e(PEe,hpr),e(sE,upr),e(sE,YJ),e(YJ,ppr),e(sE,_pr),e(H,bpr),e(H,lE),e(lE,BEe),e(BEe,vpr),e(lE,Fpr),e(lE,KJ),e(KJ,Tpr),e(lE,Mpr),e(H,Epr),e(H,iE),e(iE,IEe),e(IEe,Cpr),e(iE,wpr),e(iE,ZJ),e(ZJ,Apr),e(iE,Lpr),e(H,ypr),e(H,dE),e(dE,NEe),e(NEe,xpr),e(dE,$pr),e(dE,eY),e(eY,kpr),e(dE,Spr),e(H,Rpr),e(H,mE),e(mE,qEe),e(qEe,Ppr),e(mE,Bpr),e(mE,oY),e(oY,Ipr),e(mE,Npr),e(H,qpr),e(H,cE),e(cE,jEe),e(jEe,jpr),e(cE,Dpr),e(cE,rY),e(rY,Gpr),e(cE,Opr),e(H,Vpr),e(H,fE),e(fE,DEe),e(DEe,Xpr),e(fE,zpr),e(fE,tY),e(tY,Qpr),e(fE,Wpr),e(H,Upr),e(H,gE),e(gE,GEe),e(GEe,Hpr),e(gE,Jpr),e(gE,aY),e(aY,Ypr),e(gE,Kpr),e(H,Zpr),e(H,hE),e(hE,OEe),e(OEe,e_r),e(hE,o_r),e(hE,nY),e(nY,r_r),e(hE,t_r),e(H,a_r),e(H,uE),e(uE,VEe),e(VEe,n_r),e(uE,s_r),e(uE,sY),e(sY,l_r),e(uE,i_r),e(H,d_r),e(H,pE),e(pE,XEe),e(XEe,m_r),e(pE,c_r),e(pE,lY),e(lY,f_r),e(pE,g_r),e(H,h_r),e(H,_E),e(_E,zEe),e(zEe,u_r),e(_E,p_r),e(_E,iY),e(iY,__r),e(_E,b_r),e(H,v_r),e(H,bE),e(bE,QEe),e(QEe,F_r),e(bE,T_r),e(bE,dY),e(dY,M_r),e(bE,E_r),e(lo,C_r),e(lo,vE),e(vE,w_r),e(vE,WEe),e(WEe,A_r),e(vE,L_r),e(vE,UEe),e(UEe,y_r),e(lo,x_r),M(FE,lo,null),b(c,Qeo,_),b(c,Xd,_),e(Xd,TE),e(TE,HEe),M(w$,HEe,null),e(Xd,$_r),e(Xd,JEe),e(JEe,k_r),b(c,Weo,_),b(c,Vo,_),M(A$,Vo,null),e(Vo,S_r),e(Vo,zd),e(zd,R_r),e(zd,mY),e(mY,P_r),e(zd,B_r),e(zd,cY),e(cY,I_r),e(zd,N_r),e(Vo,q_r),e(Vo,L$),e(L$,j_r),e(L$,YEe),e(YEe,D_r),e(L$,G_r),e(Vo,O_r),e(Vo,At),M(y$,At,null),e(At,V_r),e(At,KEe),e(KEe,X_r),e(At,z_r),e(At,Qd),e(Qd,Q_r),e(Qd,ZEe),e(ZEe,W_r),e(Qd,U_r),e(Qd,fY),e(fY,H_r),e(Qd,J_r),e(At,Y_r),M(ME,At,null),e(Vo,K_r),e(Vo,io),M(x$,io,null),e(io,Z_r),e(io,e4e),e(e4e,e1r),e(io,o1r),e(io,nn),e(nn,r1r),e(nn,o4e),e(o4e,t1r),e(nn,a1r),e(nn,r4e),e(r4e,n1r),e(nn,s1r),e(nn,t4e),e(t4e,l1r),e(nn,i1r),e(io,d1r),e(io,V),e(V,EE),e(EE,a4e),e(a4e,m1r),e(EE,c1r),e(EE,gY),e(gY,f1r),e(EE,g1r),e(V,h1r),e(V,CE),e(CE,n4e),e(n4e,u1r),e(CE,p1r),e(CE,hY),e(hY,_1r),e(CE,b1r),e(V,v1r),e(V,wE),e(wE,s4e),e(s4e,F1r),e(wE,T1r),e(wE,uY),e(uY,M1r),e(wE,E1r),e(V,C1r),e(V,AE),e(AE,l4e),e(l4e,w1r),e(AE,A1r),e(AE,pY),e(pY,L1r),e(AE,y1r),e(V,x1r),e(V,LE),e(LE,i4e),e(i4e,$1r),e(LE,k1r),e(LE,_Y),e(_Y,S1r),e(LE,R1r),e(V,P1r),e(V,yE),e(yE,d4e),e(d4e,B1r),e(yE,I1r),e(yE,bY),e(bY,N1r),e(yE,q1r),e(V,j1r),e(V,xE),e(xE,m4e),e(m4e,D1r),e(xE,G1r),e(xE,vY),e(vY,O1r),e(xE,V1r),e(V,X1r),e(V,$E),e($E,c4e),e(c4e,z1r),e($E,Q1r),e($E,FY),e(FY,W1r),e($E,U1r),e(V,H1r),e(V,kE),e(kE,f4e),e(f4e,J1r),e(kE,Y1r),e(kE,TY),e(TY,K1r),e(kE,Z1r),e(V,e2r),e(V,SE),e(SE,g4e),e(g4e,o2r),e(SE,r2r),e(SE,MY),e(MY,t2r),e(SE,a2r),e(V,n2r),e(V,RE),e(RE,h4e),e(h4e,s2r),e(RE,l2r),e(RE,EY),e(EY,i2r),e(RE,d2r),e(V,m2r),e(V,PE),e(PE,u4e),e(u4e,c2r),e(PE,f2r),e(PE,CY),e(CY,g2r),e(PE,h2r),e(V,u2r),e(V,BE),e(BE,p4e),e(p4e,p2r),e(BE,_2r),e(BE,wY),e(wY,b2r),e(BE,v2r),e(V,F2r),e(V,IE),e(IE,_4e),e(_4e,T2r),e(IE,M2r),e(IE,AY),e(AY,E2r),e(IE,C2r),e(V,w2r),e(V,NE),e(NE,b4e),e(b4e,A2r),e(NE,L2r),e(NE,LY),e(LY,y2r),e(NE,x2r),e(V,$2r),e(V,qE),e(qE,v4e),e(v4e,k2r),e(qE,S2r),e(qE,yY),e(yY,R2r),e(qE,P2r),e(V,B2r),e(V,jE),e(jE,F4e),e(F4e,I2r),e(jE,N2r),e(jE,xY),e(xY,q2r),e(jE,j2r),e(V,D2r),e(V,DE),e(DE,T4e),e(T4e,G2r),e(DE,O2r),e(DE,$Y),e($Y,V2r),e(DE,X2r),e(V,z2r),e(V,GE),e(GE,M4e),e(M4e,Q2r),e(GE,W2r),e(GE,kY),e(kY,U2r),e(GE,H2r),e(V,J2r),e(V,OE),e(OE,E4e),e(E4e,Y2r),e(OE,K2r),e(OE,SY),e(SY,Z2r),e(OE,ebr),e(V,obr),e(V,VE),e(VE,C4e),e(C4e,rbr),e(VE,tbr),e(VE,RY),e(RY,abr),e(VE,nbr),e(V,sbr),e(V,XE),e(XE,w4e),e(w4e,lbr),e(XE,ibr),e(XE,PY),e(PY,dbr),e(XE,mbr),e(V,cbr),e(V,zE),e(zE,A4e),e(A4e,fbr),e(zE,gbr),e(zE,BY),e(BY,hbr),e(zE,ubr),e(V,pbr),e(V,QE),e(QE,L4e),e(L4e,_br),e(QE,bbr),e(QE,IY),e(IY,vbr),e(QE,Fbr),e(V,Tbr),e(V,WE),e(WE,y4e),e(y4e,Mbr),e(WE,Ebr),e(WE,NY),e(NY,Cbr),e(WE,wbr),e(V,Abr),e(V,UE),e(UE,x4e),e(x4e,Lbr),e(UE,ybr),e(UE,qY),e(qY,xbr),e(UE,$br),e(V,kbr),e(V,HE),e(HE,$4e),e($4e,Sbr),e(HE,Rbr),e(HE,jY),e(jY,Pbr),e(HE,Bbr),e(V,Ibr),e(V,JE),e(JE,k4e),e(k4e,Nbr),e(JE,qbr),e(JE,DY),e(DY,jbr),e(JE,Dbr),e(V,Gbr),e(V,YE),e(YE,S4e),e(S4e,Obr),e(YE,Vbr),e(YE,GY),e(GY,Xbr),e(YE,zbr),e(V,Qbr),e(V,KE),e(KE,R4e),e(R4e,Wbr),e(KE,Ubr),e(KE,OY),e(OY,Hbr),e(KE,Jbr),e(V,Ybr),e(V,ZE),e(ZE,P4e),e(P4e,Kbr),e(ZE,Zbr),e(ZE,VY),e(VY,evr),e(ZE,ovr),e(V,rvr),e(V,e4),e(e4,B4e),e(B4e,tvr),e(e4,avr),e(e4,XY),e(XY,nvr),e(e4,svr),e(V,lvr),e(V,o4),e(o4,I4e),e(I4e,ivr),e(o4,dvr),e(o4,zY),e(zY,mvr),e(o4,cvr),e(V,fvr),e(V,r4),e(r4,N4e),e(N4e,gvr),e(r4,hvr),e(r4,QY),e(QY,uvr),e(r4,pvr),e(V,_vr),e(V,t4),e(t4,q4e),e(q4e,bvr),e(t4,vvr),e(t4,WY),e(WY,Fvr),e(t4,Tvr),e(V,Mvr),e(V,a4),e(a4,j4e),e(j4e,Evr),e(a4,Cvr),e(a4,UY),e(UY,wvr),e(a4,Avr),e(V,Lvr),e(V,n4),e(n4,D4e),e(D4e,yvr),e(n4,xvr),e(n4,HY),e(HY,$vr),e(n4,kvr),e(V,Svr),e(V,s4),e(s4,G4e),e(G4e,Rvr),e(s4,Pvr),e(s4,JY),e(JY,Bvr),e(s4,Ivr),e(V,Nvr),e(V,l4),e(l4,O4e),e(O4e,qvr),e(l4,jvr),e(l4,YY),e(YY,Dvr),e(l4,Gvr),e(V,Ovr),e(V,i4),e(i4,V4e),e(V4e,Vvr),e(i4,Xvr),e(i4,KY),e(KY,zvr),e(i4,Qvr),e(V,Wvr),e(V,d4),e(d4,X4e),e(X4e,Uvr),e(d4,Hvr),e(d4,ZY),e(ZY,Jvr),e(d4,Yvr),e(V,Kvr),e(V,m4),e(m4,z4e),e(z4e,Zvr),e(m4,eFr),e(m4,eK),e(eK,oFr),e(m4,rFr),e(V,tFr),e(V,c4),e(c4,Q4e),e(Q4e,aFr),e(c4,nFr),e(c4,oK),e(oK,sFr),e(c4,lFr),e(V,iFr),e(V,f4),e(f4,W4e),e(W4e,dFr),e(f4,mFr),e(f4,rK),e(rK,cFr),e(f4,fFr),e(V,gFr),e(V,g4),e(g4,U4e),e(U4e,hFr),e(g4,uFr),e(g4,tK),e(tK,pFr),e(g4,_Fr),e(V,bFr),e(V,h4),e(h4,H4e),e(H4e,vFr),e(h4,FFr),e(h4,aK),e(aK,TFr),e(h4,MFr),e(io,EFr),e(io,u4),e(u4,CFr),e(u4,J4e),e(J4e,wFr),e(u4,AFr),e(u4,Y4e),e(Y4e,LFr),e(io,yFr),M(p4,io,null),b(c,Ueo,_),b(c,Wd,_),e(Wd,_4),e(_4,K4e),M($$,K4e,null),e(Wd,xFr),e(Wd,Z4e),e(Z4e,$Fr),b(c,Heo,_),b(c,Xo,_),M(k$,Xo,null),e(Xo,kFr),e(Xo,Ud),e(Ud,SFr),e(Ud,nK),e(nK,RFr),e(Ud,PFr),e(Ud,sK),e(sK,BFr),e(Ud,IFr),e(Xo,NFr),e(Xo,S$),e(S$,qFr),e(S$,eCe),e(eCe,jFr),e(S$,DFr),e(Xo,GFr),e(Xo,Lt),M(R$,Lt,null),e(Lt,OFr),e(Lt,oCe),e(oCe,VFr),e(Lt,XFr),e(Lt,Hd),e(Hd,zFr),e(Hd,rCe),e(rCe,QFr),e(Hd,WFr),e(Hd,lK),e(lK,UFr),e(Hd,HFr),e(Lt,JFr),M(b4,Lt,null),e(Xo,YFr),e(Xo,mo),M(P$,mo,null),e(mo,KFr),e(mo,tCe),e(tCe,ZFr),e(mo,eTr),e(mo,sn),e(sn,oTr),e(sn,aCe),e(aCe,rTr),e(sn,tTr),e(sn,nCe),e(nCe,aTr),e(sn,nTr),e(sn,sCe),e(sCe,sTr),e(sn,lTr),e(mo,iTr),e(mo,lCe),e(lCe,v4),e(v4,iCe),e(iCe,dTr),e(v4,mTr),e(v4,iK),e(iK,cTr),e(v4,fTr),e(mo,gTr),e(mo,F4),e(F4,hTr),e(F4,dCe),e(dCe,uTr),e(F4,pTr),e(F4,mCe),e(mCe,_Tr),e(mo,bTr),M(T4,mo,null),b(c,Jeo,_),b(c,Jd,_),e(Jd,M4),e(M4,cCe),M(B$,cCe,null),e(Jd,vTr),e(Jd,fCe),e(fCe,FTr),b(c,Yeo,_),b(c,zo,_),M(I$,zo,null),e(zo,TTr),e(zo,Yd),e(Yd,MTr),e(Yd,dK),e(dK,ETr),e(Yd,CTr),e(Yd,mK),e(mK,wTr),e(Yd,ATr),e(zo,LTr),e(zo,N$),e(N$,yTr),e(N$,gCe),e(gCe,xTr),e(N$,$Tr),e(zo,kTr),e(zo,yt),M(q$,yt,null),e(yt,STr),e(yt,hCe),e(hCe,RTr),e(yt,PTr),e(yt,Kd),e(Kd,BTr),e(Kd,uCe),e(uCe,ITr),e(Kd,NTr),e(Kd,cK),e(cK,qTr),e(Kd,jTr),e(yt,DTr),M(E4,yt,null),e(zo,GTr),e(zo,co),M(j$,co,null),e(co,OTr),e(co,pCe),e(pCe,VTr),e(co,XTr),e(co,ln),e(ln,zTr),e(ln,_Ce),e(_Ce,QTr),e(ln,WTr),e(ln,bCe),e(bCe,UTr),e(ln,HTr),e(ln,vCe),e(vCe,JTr),e(ln,YTr),e(co,KTr),e(co,Zd),e(Zd,C4),e(C4,FCe),e(FCe,ZTr),e(C4,eMr),e(C4,fK),e(fK,oMr),e(C4,rMr),e(Zd,tMr),e(Zd,w4),e(w4,TCe),e(TCe,aMr),e(w4,nMr),e(w4,gK),e(gK,sMr),e(w4,lMr),e(Zd,iMr),e(Zd,A4),e(A4,MCe),e(MCe,dMr),e(A4,mMr),e(A4,hK),e(hK,cMr),e(A4,fMr),e(co,gMr),e(co,L4),e(L4,hMr),e(L4,ECe),e(ECe,uMr),e(L4,pMr),e(L4,CCe),e(CCe,_Mr),e(co,bMr),M(y4,co,null),b(c,Keo,_),b(c,em,_),e(em,x4),e(x4,wCe),M(D$,wCe,null),e(em,vMr),e(em,ACe),e(ACe,FMr),b(c,Zeo,_),b(c,Qo,_),M(G$,Qo,null),e(Qo,TMr),e(Qo,om),e(om,MMr),e(om,uK),e(uK,EMr),e(om,CMr),e(om,pK),e(pK,wMr),e(om,AMr),e(Qo,LMr),e(Qo,O$),e(O$,yMr),e(O$,LCe),e(LCe,xMr),e(O$,$Mr),e(Qo,kMr),e(Qo,xt),M(V$,xt,null),e(xt,SMr),e(xt,yCe),e(yCe,RMr),e(xt,PMr),e(xt,rm),e(rm,BMr),e(rm,xCe),e(xCe,IMr),e(rm,NMr),e(rm,_K),e(_K,qMr),e(rm,jMr),e(xt,DMr),M($4,xt,null),e(Qo,GMr),e(Qo,fo),M(X$,fo,null),e(fo,OMr),e(fo,$Ce),e($Ce,VMr),e(fo,XMr),e(fo,dn),e(dn,zMr),e(dn,kCe),e(kCe,QMr),e(dn,WMr),e(dn,SCe),e(SCe,UMr),e(dn,HMr),e(dn,RCe),e(RCe,JMr),e(dn,YMr),e(fo,KMr),e(fo,be),e(be,k4),e(k4,PCe),e(PCe,ZMr),e(k4,eEr),e(k4,bK),e(bK,oEr),e(k4,rEr),e(be,tEr),e(be,S4),e(S4,BCe),e(BCe,aEr),e(S4,nEr),e(S4,vK),e(vK,sEr),e(S4,lEr),e(be,iEr),e(be,R4),e(R4,ICe),e(ICe,dEr),e(R4,mEr),e(R4,FK),e(FK,cEr),e(R4,fEr),e(be,gEr),e(be,P4),e(P4,NCe),e(NCe,hEr),e(P4,uEr),e(P4,TK),e(TK,pEr),e(P4,_Er),e(be,bEr),e(be,bl),e(bl,qCe),e(qCe,vEr),e(bl,FEr),e(bl,MK),e(MK,TEr),e(bl,MEr),e(bl,EK),e(EK,EEr),e(bl,CEr),e(be,wEr),e(be,B4),e(B4,jCe),e(jCe,AEr),e(B4,LEr),e(B4,CK),e(CK,yEr),e(B4,xEr),e(be,$Er),e(be,vl),e(vl,DCe),e(DCe,kEr),e(vl,SEr),e(vl,wK),e(wK,REr),e(vl,PEr),e(vl,AK),e(AK,BEr),e(vl,IEr),e(be,NEr),e(be,I4),e(I4,GCe),e(GCe,qEr),e(I4,jEr),e(I4,LK),e(LK,DEr),e(I4,GEr),e(be,OEr),e(be,$t),e($t,OCe),e(OCe,VEr),e($t,XEr),e($t,yK),e(yK,zEr),e($t,QEr),e($t,xK),e(xK,WEr),e($t,UEr),e($t,$K),e($K,HEr),e($t,JEr),e(be,YEr),e(be,N4),e(N4,VCe),e(VCe,KEr),e(N4,ZEr),e(N4,kK),e(kK,e4r),e(N4,o4r),e(be,r4r),e(be,q4),e(q4,XCe),e(XCe,t4r),e(q4,a4r),e(q4,SK),e(SK,n4r),e(q4,s4r),e(be,l4r),e(be,j4),e(j4,zCe),e(zCe,i4r),e(j4,d4r),e(j4,RK),e(RK,m4r),e(j4,c4r),e(be,f4r),e(be,D4),e(D4,QCe),e(QCe,g4r),e(D4,h4r),e(D4,PK),e(PK,u4r),e(D4,p4r),e(be,_4r),e(be,G4),e(G4,WCe),e(WCe,b4r),e(G4,v4r),e(G4,BK),e(BK,F4r),e(G4,T4r),e(be,M4r),e(be,O4),e(O4,UCe),e(UCe,E4r),e(O4,C4r),e(O4,IK),e(IK,w4r),e(O4,A4r),e(be,L4r),e(be,V4),e(V4,HCe),e(HCe,y4r),e(V4,x4r),e(V4,NK),e(NK,$4r),e(V4,k4r),e(be,S4r),e(be,X4),e(X4,JCe),e(JCe,R4r),e(X4,P4r),e(X4,qK),e(qK,B4r),e(X4,I4r),e(be,N4r),e(be,z4),e(z4,YCe),e(YCe,q4r),e(z4,j4r),e(z4,jK),e(jK,D4r),e(z4,G4r),e(fo,O4r),e(fo,Q4),e(Q4,V4r),e(Q4,KCe),e(KCe,X4r),e(Q4,z4r),e(Q4,ZCe),e(ZCe,Q4r),e(fo,W4r),M(W4,fo,null),b(c,eoo,_),b(c,tm,_),e(tm,U4),e(U4,e3e),M(z$,e3e,null),e(tm,U4r),e(tm,o3e),e(o3e,H4r),b(c,ooo,_),b(c,Wo,_),M(Q$,Wo,null),e(Wo,J4r),e(Wo,am),e(am,Y4r),e(am,DK),e(DK,K4r),e(am,Z4r),e(am,GK),e(GK,eCr),e(am,oCr),e(Wo,rCr),e(Wo,W$),e(W$,tCr),e(W$,r3e),e(r3e,aCr),e(W$,nCr),e(Wo,sCr),e(Wo,kt),M(U$,kt,null),e(kt,lCr),e(kt,t3e),e(t3e,iCr),e(kt,dCr),e(kt,nm),e(nm,mCr),e(nm,a3e),e(a3e,cCr),e(nm,fCr),e(nm,OK),e(OK,gCr),e(nm,hCr),e(kt,uCr),M(H4,kt,null),e(Wo,pCr),e(Wo,go),M(H$,go,null),e(go,_Cr),e(go,n3e),e(n3e,bCr),e(go,vCr),e(go,mn),e(mn,FCr),e(mn,s3e),e(s3e,TCr),e(mn,MCr),e(mn,l3e),e(l3e,ECr),e(mn,CCr),e(mn,i3e),e(i3e,wCr),e(mn,ACr),e(go,LCr),e(go,d3e),e(d3e,J4),e(J4,m3e),e(m3e,yCr),e(J4,xCr),e(J4,VK),e(VK,$Cr),e(J4,kCr),e(go,SCr),e(go,Y4),e(Y4,RCr),e(Y4,c3e),e(c3e,PCr),e(Y4,BCr),e(Y4,f3e),e(f3e,ICr),e(go,NCr),M(K4,go,null),b(c,roo,_),b(c,sm,_),e(sm,Z4),e(Z4,g3e),M(J$,g3e,null),e(sm,qCr),e(sm,h3e),e(h3e,jCr),b(c,too,_),b(c,Uo,_),M(Y$,Uo,null),e(Uo,DCr),e(Uo,lm),e(lm,GCr),e(lm,XK),e(XK,OCr),e(lm,VCr),e(lm,zK),e(zK,XCr),e(lm,zCr),e(Uo,QCr),e(Uo,K$),e(K$,WCr),e(K$,u3e),e(u3e,UCr),e(K$,HCr),e(Uo,JCr),e(Uo,St),M(Z$,St,null),e(St,YCr),e(St,p3e),e(p3e,KCr),e(St,ZCr),e(St,im),e(im,e3r),e(im,_3e),e(_3e,o3r),e(im,r3r),e(im,QK),e(QK,t3r),e(im,a3r),e(St,n3r),M(eC,St,null),e(Uo,s3r),e(Uo,ho),M(ek,ho,null),e(ho,l3r),e(ho,b3e),e(b3e,i3r),e(ho,d3r),e(ho,cn),e(cn,m3r),e(cn,v3e),e(v3e,c3r),e(cn,f3r),e(cn,F3e),e(F3e,g3r),e(cn,h3r),e(cn,T3e),e(T3e,u3r),e(cn,p3r),e(ho,_3r),e(ho,M3e),e(M3e,oC),e(oC,E3e),e(E3e,b3r),e(oC,v3r),e(oC,WK),e(WK,F3r),e(oC,T3r),e(ho,M3r),e(ho,rC),e(rC,E3r),e(rC,C3e),e(C3e,C3r),e(rC,w3r),e(rC,w3e),e(w3e,A3r),e(ho,L3r),M(tC,ho,null),b(c,aoo,_),b(c,dm,_),e(dm,aC),e(aC,A3e),M(ok,A3e,null),e(dm,y3r),e(dm,L3e),e(L3e,x3r),b(c,noo,_),b(c,Ho,_),M(rk,Ho,null),e(Ho,$3r),e(Ho,mm),e(mm,k3r),e(mm,UK),e(UK,S3r),e(mm,R3r),e(mm,HK),e(HK,P3r),e(mm,B3r),e(Ho,I3r),e(Ho,tk),e(tk,N3r),e(tk,y3e),e(y3e,q3r),e(tk,j3r),e(Ho,D3r),e(Ho,Rt),M(ak,Rt,null),e(Rt,G3r),e(Rt,x3e),e(x3e,O3r),e(Rt,V3r),e(Rt,cm),e(cm,X3r),e(cm,$3e),e($3e,z3r),e(cm,Q3r),e(cm,JK),e(JK,W3r),e(cm,U3r),e(Rt,H3r),M(nC,Rt,null),e(Ho,J3r),e(Ho,uo),M(nk,uo,null),e(uo,Y3r),e(uo,k3e),e(k3e,K3r),e(uo,Z3r),e(uo,fn),e(fn,e5r),e(fn,S3e),e(S3e,o5r),e(fn,r5r),e(fn,R3e),e(R3e,t5r),e(fn,a5r),e(fn,P3e),e(P3e,n5r),e(fn,s5r),e(uo,l5r),e(uo,B3e),e(B3e,sC),e(sC,I3e),e(I3e,i5r),e(sC,d5r),e(sC,YK),e(YK,m5r),e(sC,c5r),e(uo,f5r),e(uo,lC),e(lC,g5r),e(lC,N3e),e(N3e,h5r),e(lC,u5r),e(lC,q3e),e(q3e,p5r),e(uo,_5r),M(iC,uo,null),b(c,soo,_),b(c,fm,_),e(fm,dC),e(dC,j3e),M(sk,j3e,null),e(fm,b5r),e(fm,D3e),e(D3e,v5r),b(c,loo,_),b(c,Jo,_),M(lk,Jo,null),e(Jo,F5r),e(Jo,gm),e(gm,T5r),e(gm,KK),e(KK,M5r),e(gm,E5r),e(gm,ZK),e(ZK,C5r),e(gm,w5r),e(Jo,A5r),e(Jo,ik),e(ik,L5r),e(ik,G3e),e(G3e,y5r),e(ik,x5r),e(Jo,$5r),e(Jo,Pt),M(dk,Pt,null),e(Pt,k5r),e(Pt,O3e),e(O3e,S5r),e(Pt,R5r),e(Pt,hm),e(hm,P5r),e(hm,V3e),e(V3e,B5r),e(hm,I5r),e(hm,eZ),e(eZ,N5r),e(hm,q5r),e(Pt,j5r),M(mC,Pt,null),e(Jo,D5r),e(Jo,po),M(mk,po,null),e(po,G5r),e(po,X3e),e(X3e,O5r),e(po,V5r),e(po,gn),e(gn,X5r),e(gn,z3e),e(z3e,z5r),e(gn,Q5r),e(gn,Q3e),e(Q3e,W5r),e(gn,U5r),e(gn,W3e),e(W3e,H5r),e(gn,J5r),e(po,Y5r),e(po,Pe),e(Pe,cC),e(cC,U3e),e(U3e,K5r),e(cC,Z5r),e(cC,oZ),e(oZ,e0r),e(cC,o0r),e(Pe,r0r),e(Pe,fC),e(fC,H3e),e(H3e,t0r),e(fC,a0r),e(fC,rZ),e(rZ,n0r),e(fC,s0r),e(Pe,l0r),e(Pe,gC),e(gC,J3e),e(J3e,i0r),e(gC,d0r),e(gC,tZ),e(tZ,m0r),e(gC,c0r),e(Pe,f0r),e(Pe,hC),e(hC,Y3e),e(Y3e,g0r),e(hC,h0r),e(hC,aZ),e(aZ,u0r),e(hC,p0r),e(Pe,_0r),e(Pe,uC),e(uC,K3e),e(K3e,b0r),e(uC,v0r),e(uC,nZ),e(nZ,F0r),e(uC,T0r),e(Pe,M0r),e(Pe,pC),e(pC,Z3e),e(Z3e,E0r),e(pC,C0r),e(pC,sZ),e(sZ,w0r),e(pC,A0r),e(Pe,L0r),e(Pe,_C),e(_C,e5e),e(e5e,y0r),e(_C,x0r),e(_C,lZ),e(lZ,$0r),e(_C,k0r),e(Pe,S0r),e(Pe,bC),e(bC,o5e),e(o5e,R0r),e(bC,P0r),e(bC,iZ),e(iZ,B0r),e(bC,I0r),e(Pe,N0r),e(Pe,vC),e(vC,r5e),e(r5e,q0r),e(vC,j0r),e(vC,dZ),e(dZ,D0r),e(vC,G0r),e(po,O0r),e(po,FC),e(FC,V0r),e(FC,t5e),e(t5e,X0r),e(FC,z0r),e(FC,a5e),e(a5e,Q0r),e(po,W0r),M(TC,po,null),b(c,ioo,_),b(c,um,_),e(um,MC),e(MC,n5e),M(ck,n5e,null),e(um,U0r),e(um,s5e),e(s5e,H0r),b(c,doo,_),b(c,Yo,_),M(fk,Yo,null),e(Yo,J0r),e(Yo,pm),e(pm,Y0r),e(pm,mZ),e(mZ,K0r),e(pm,Z0r),e(pm,cZ),e(cZ,ewr),e(pm,owr),e(Yo,rwr),e(Yo,gk),e(gk,twr),e(gk,l5e),e(l5e,awr),e(gk,nwr),e(Yo,swr),e(Yo,Bt),M(hk,Bt,null),e(Bt,lwr),e(Bt,i5e),e(i5e,iwr),e(Bt,dwr),e(Bt,_m),e(_m,mwr),e(_m,d5e),e(d5e,cwr),e(_m,fwr),e(_m,fZ),e(fZ,gwr),e(_m,hwr),e(Bt,uwr),M(EC,Bt,null),e(Yo,pwr),e(Yo,_o),M(uk,_o,null),e(_o,_wr),e(_o,m5e),e(m5e,bwr),e(_o,vwr),e(_o,hn),e(hn,Fwr),e(hn,c5e),e(c5e,Twr),e(hn,Mwr),e(hn,f5e),e(f5e,Ewr),e(hn,Cwr),e(hn,g5e),e(g5e,wwr),e(hn,Awr),e(_o,Lwr),e(_o,ct),e(ct,CC),e(CC,h5e),e(h5e,ywr),e(CC,xwr),e(CC,gZ),e(gZ,$wr),e(CC,kwr),e(ct,Swr),e(ct,wC),e(wC,u5e),e(u5e,Rwr),e(wC,Pwr),e(wC,hZ),e(hZ,Bwr),e(wC,Iwr),e(ct,Nwr),e(ct,AC),e(AC,p5e),e(p5e,qwr),e(AC,jwr),e(AC,uZ),e(uZ,Dwr),e(AC,Gwr),e(ct,Owr),e(ct,LC),e(LC,_5e),e(_5e,Vwr),e(LC,Xwr),e(LC,pZ),e(pZ,zwr),e(LC,Qwr),e(ct,Wwr),e(ct,yC),e(yC,b5e),e(b5e,Uwr),e(yC,Hwr),e(yC,_Z),e(_Z,Jwr),e(yC,Ywr),e(_o,Kwr),e(_o,xC),e(xC,Zwr),e(xC,v5e),e(v5e,eAr),e(xC,oAr),e(xC,F5e),e(F5e,rAr),e(_o,tAr),M($C,_o,null),b(c,moo,_),b(c,bm,_),e(bm,kC),e(kC,T5e),M(pk,T5e,null),e(bm,aAr),e(bm,M5e),e(M5e,nAr),b(c,coo,_),b(c,Ko,_),M(_k,Ko,null),e(Ko,sAr),e(Ko,vm),e(vm,lAr),e(vm,bZ),e(bZ,iAr),e(vm,dAr),e(vm,vZ),e(vZ,mAr),e(vm,cAr),e(Ko,fAr),e(Ko,bk),e(bk,gAr),e(bk,E5e),e(E5e,hAr),e(bk,uAr),e(Ko,pAr),e(Ko,It),M(vk,It,null),e(It,_Ar),e(It,C5e),e(C5e,bAr),e(It,vAr),e(It,Fm),e(Fm,FAr),e(Fm,w5e),e(w5e,TAr),e(Fm,MAr),e(Fm,FZ),e(FZ,EAr),e(Fm,CAr),e(It,wAr),M(SC,It,null),e(Ko,AAr),e(Ko,bo),M(Fk,bo,null),e(bo,LAr),e(bo,A5e),e(A5e,yAr),e(bo,xAr),e(bo,un),e(un,$Ar),e(un,L5e),e(L5e,kAr),e(un,SAr),e(un,y5e),e(y5e,RAr),e(un,PAr),e(un,x5e),e(x5e,BAr),e(un,IAr),e(bo,NAr),e(bo,Le),e(Le,RC),e(RC,$5e),e($5e,qAr),e(RC,jAr),e(RC,TZ),e(TZ,DAr),e(RC,GAr),e(Le,OAr),e(Le,PC),e(PC,k5e),e(k5e,VAr),e(PC,XAr),e(PC,MZ),e(MZ,zAr),e(PC,QAr),e(Le,WAr),e(Le,BC),e(BC,S5e),e(S5e,UAr),e(BC,HAr),e(BC,EZ),e(EZ,JAr),e(BC,YAr),e(Le,KAr),e(Le,IC),e(IC,R5e),e(R5e,ZAr),e(IC,e6r),e(IC,CZ),e(CZ,o6r),e(IC,r6r),e(Le,t6r),e(Le,NC),e(NC,P5e),e(P5e,a6r),e(NC,n6r),e(NC,wZ),e(wZ,s6r),e(NC,l6r),e(Le,i6r),e(Le,qC),e(qC,B5e),e(B5e,d6r),e(qC,m6r),e(qC,AZ),e(AZ,c6r),e(qC,f6r),e(Le,g6r),e(Le,jC),e(jC,I5e),e(I5e,h6r),e(jC,u6r),e(jC,LZ),e(LZ,p6r),e(jC,_6r),e(Le,b6r),e(Le,DC),e(DC,N5e),e(N5e,v6r),e(DC,F6r),e(DC,yZ),e(yZ,T6r),e(DC,M6r),e(Le,E6r),e(Le,GC),e(GC,q5e),e(q5e,C6r),e(GC,w6r),e(GC,xZ),e(xZ,A6r),e(GC,L6r),e(Le,y6r),e(Le,OC),e(OC,j5e),e(j5e,x6r),e(OC,$6r),e(OC,$Z),e($Z,k6r),e(OC,S6r),e(bo,R6r),e(bo,VC),e(VC,P6r),e(VC,D5e),e(D5e,B6r),e(VC,I6r),e(VC,G5e),e(G5e,N6r),e(bo,q6r),M(XC,bo,null),b(c,foo,_),b(c,Tm,_),e(Tm,zC),e(zC,O5e),M(Tk,O5e,null),e(Tm,j6r),e(Tm,V5e),e(V5e,D6r),b(c,goo,_),b(c,Zo,_),M(Mk,Zo,null),e(Zo,G6r),e(Zo,Mm),e(Mm,O6r),e(Mm,kZ),e(kZ,V6r),e(Mm,X6r),e(Mm,SZ),e(SZ,z6r),e(Mm,Q6r),e(Zo,W6r),e(Zo,Ek),e(Ek,U6r),e(Ek,X5e),e(X5e,H6r),e(Ek,J6r),e(Zo,Y6r),e(Zo,Nt),M(Ck,Nt,null),e(Nt,K6r),e(Nt,z5e),e(z5e,Z6r),e(Nt,e7r),e(Nt,Em),e(Em,o7r),e(Em,Q5e),e(Q5e,r7r),e(Em,t7r),e(Em,RZ),e(RZ,a7r),e(Em,n7r),e(Nt,s7r),M(QC,Nt,null),e(Zo,l7r),e(Zo,vo),M(wk,vo,null),e(vo,i7r),e(vo,W5e),e(W5e,d7r),e(vo,m7r),e(vo,pn),e(pn,c7r),e(pn,U5e),e(U5e,f7r),e(pn,g7r),e(pn,H5e),e(H5e,h7r),e(pn,u7r),e(pn,J5e),e(J5e,p7r),e(pn,_7r),e(vo,b7r),e(vo,Cm),e(Cm,WC),e(WC,Y5e),e(Y5e,v7r),e(WC,F7r),e(WC,PZ),e(PZ,T7r),e(WC,M7r),e(Cm,E7r),e(Cm,UC),e(UC,K5e),e(K5e,C7r),e(UC,w7r),e(UC,BZ),e(BZ,A7r),e(UC,L7r),e(Cm,y7r),e(Cm,HC),e(HC,Z5e),e(Z5e,x7r),e(HC,$7r),e(HC,IZ),e(IZ,k7r),e(HC,S7r),e(vo,R7r),e(vo,JC),e(JC,P7r),e(JC,e0e),e(e0e,B7r),e(JC,I7r),e(JC,o0e),e(o0e,N7r),e(vo,q7r),M(YC,vo,null),b(c,hoo,_),b(c,wm,_),e(wm,KC),e(KC,r0e),M(Ak,r0e,null),e(wm,j7r),e(wm,t0e),e(t0e,D7r),b(c,uoo,_),b(c,er,_),M(Lk,er,null),e(er,G7r),e(er,Am),e(Am,O7r),e(Am,NZ),e(NZ,V7r),e(Am,X7r),e(Am,qZ),e(qZ,z7r),e(Am,Q7r),e(er,W7r),e(er,yk),e(yk,U7r),e(yk,a0e),e(a0e,H7r),e(yk,J7r),e(er,Y7r),e(er,qt),M(xk,qt,null),e(qt,K7r),e(qt,n0e),e(n0e,Z7r),e(qt,eLr),e(qt,Lm),e(Lm,oLr),e(Lm,s0e),e(s0e,rLr),e(Lm,tLr),e(Lm,jZ),e(jZ,aLr),e(Lm,nLr),e(qt,sLr),M(ZC,qt,null),e(er,lLr),e(er,Fo),M($k,Fo,null),e(Fo,iLr),e(Fo,l0e),e(l0e,dLr),e(Fo,mLr),e(Fo,_n),e(_n,cLr),e(_n,i0e),e(i0e,fLr),e(_n,gLr),e(_n,d0e),e(d0e,hLr),e(_n,uLr),e(_n,m0e),e(m0e,pLr),e(_n,_Lr),e(Fo,bLr),e(Fo,ft),e(ft,e3),e(e3,c0e),e(c0e,vLr),e(e3,FLr),e(e3,DZ),e(DZ,TLr),e(e3,MLr),e(ft,ELr),e(ft,o3),e(o3,f0e),e(f0e,CLr),e(o3,wLr),e(o3,GZ),e(GZ,ALr),e(o3,LLr),e(ft,yLr),e(ft,r3),e(r3,g0e),e(g0e,xLr),e(r3,$Lr),e(r3,OZ),e(OZ,kLr),e(r3,SLr),e(ft,RLr),e(ft,t3),e(t3,h0e),e(h0e,PLr),e(t3,BLr),e(t3,VZ),e(VZ,ILr),e(t3,NLr),e(ft,qLr),e(ft,a3),e(a3,u0e),e(u0e,jLr),e(a3,DLr),e(a3,XZ),e(XZ,GLr),e(a3,OLr),e(Fo,VLr),e(Fo,n3),e(n3,XLr),e(n3,p0e),e(p0e,zLr),e(n3,QLr),e(n3,_0e),e(_0e,WLr),e(Fo,ULr),M(s3,Fo,null),b(c,poo,_),b(c,ym,_),e(ym,l3),e(l3,b0e),M(kk,b0e,null),e(ym,HLr),e(ym,v0e),e(v0e,JLr),b(c,_oo,_),b(c,or,_),M(Sk,or,null),e(or,YLr),e(or,xm),e(xm,KLr),e(xm,zZ),e(zZ,ZLr),e(xm,eyr),e(xm,QZ),e(QZ,oyr),e(xm,ryr),e(or,tyr),e(or,Rk),e(Rk,ayr),e(Rk,F0e),e(F0e,nyr),e(Rk,syr),e(or,lyr),e(or,jt),M(Pk,jt,null),e(jt,iyr),e(jt,T0e),e(T0e,dyr),e(jt,myr),e(jt,$m),e($m,cyr),e($m,M0e),e(M0e,fyr),e($m,gyr),e($m,WZ),e(WZ,hyr),e($m,uyr),e(jt,pyr),M(i3,jt,null),e(or,_yr),e(or,To),M(Bk,To,null),e(To,byr),e(To,E0e),e(E0e,vyr),e(To,Fyr),e(To,bn),e(bn,Tyr),e(bn,C0e),e(C0e,Myr),e(bn,Eyr),e(bn,w0e),e(w0e,Cyr),e(bn,wyr),e(bn,A0e),e(A0e,Ayr),e(bn,Lyr),e(To,yyr),e(To,vn),e(vn,d3),e(d3,L0e),e(L0e,xyr),e(d3,$yr),e(d3,UZ),e(UZ,kyr),e(d3,Syr),e(vn,Ryr),e(vn,m3),e(m3,y0e),e(y0e,Pyr),e(m3,Byr),e(m3,HZ),e(HZ,Iyr),e(m3,Nyr),e(vn,qyr),e(vn,c3),e(c3,x0e),e(x0e,jyr),e(c3,Dyr),e(c3,JZ),e(JZ,Gyr),e(c3,Oyr),e(vn,Vyr),e(vn,f3),e(f3,$0e),e($0e,Xyr),e(f3,zyr),e(f3,YZ),e(YZ,Qyr),e(f3,Wyr),e(To,Uyr),e(To,g3),e(g3,Hyr),e(g3,k0e),e(k0e,Jyr),e(g3,Yyr),e(g3,S0e),e(S0e,Kyr),e(To,Zyr),M(h3,To,null),b(c,boo,_),b(c,km,_),e(km,u3),e(u3,R0e),M(Ik,R0e,null),e(km,e8r),e(km,P0e),e(P0e,o8r),b(c,voo,_),b(c,rr,_),M(Nk,rr,null),e(rr,r8r),e(rr,Sm),e(Sm,t8r),e(Sm,KZ),e(KZ,a8r),e(Sm,n8r),e(Sm,ZZ),e(ZZ,s8r),e(Sm,l8r),e(rr,i8r),e(rr,qk),e(qk,d8r),e(qk,B0e),e(B0e,m8r),e(qk,c8r),e(rr,f8r),e(rr,Dt),M(jk,Dt,null),e(Dt,g8r),e(Dt,I0e),e(I0e,h8r),e(Dt,u8r),e(Dt,Rm),e(Rm,p8r),e(Rm,N0e),e(N0e,_8r),e(Rm,b8r),e(Rm,eee),e(eee,v8r),e(Rm,F8r),e(Dt,T8r),M(p3,Dt,null),e(rr,M8r),e(rr,Mo),M(Dk,Mo,null),e(Mo,E8r),e(Mo,q0e),e(q0e,C8r),e(Mo,w8r),e(Mo,Fn),e(Fn,A8r),e(Fn,j0e),e(j0e,L8r),e(Fn,y8r),e(Fn,D0e),e(D0e,x8r),e(Fn,$8r),e(Fn,G0e),e(G0e,k8r),e(Fn,S8r),e(Mo,R8r),e(Mo,Tn),e(Tn,_3),e(_3,O0e),e(O0e,P8r),e(_3,B8r),e(_3,oee),e(oee,I8r),e(_3,N8r),e(Tn,q8r),e(Tn,b3),e(b3,V0e),e(V0e,j8r),e(b3,D8r),e(b3,ree),e(ree,G8r),e(b3,O8r),e(Tn,V8r),e(Tn,v3),e(v3,X0e),e(X0e,X8r),e(v3,z8r),e(v3,tee),e(tee,Q8r),e(v3,W8r),e(Tn,U8r),e(Tn,F3),e(F3,z0e),e(z0e,H8r),e(F3,J8r),e(F3,aee),e(aee,Y8r),e(F3,K8r),e(Mo,Z8r),e(Mo,T3),e(T3,e9r),e(T3,Q0e),e(Q0e,o9r),e(T3,r9r),e(T3,W0e),e(W0e,t9r),e(Mo,a9r),M(M3,Mo,null),b(c,Foo,_),b(c,Pm,_),e(Pm,E3),e(E3,U0e),M(Gk,U0e,null),e(Pm,n9r),e(Pm,H0e),e(H0e,s9r),b(c,Too,_),b(c,tr,_),M(Ok,tr,null),e(tr,l9r),e(tr,Bm),e(Bm,i9r),e(Bm,nee),e(nee,d9r),e(Bm,m9r),e(Bm,see),e(see,c9r),e(Bm,f9r),e(tr,g9r),e(tr,Vk),e(Vk,h9r),e(Vk,J0e),e(J0e,u9r),e(Vk,p9r),e(tr,_9r),e(tr,Gt),M(Xk,Gt,null),e(Gt,b9r),e(Gt,Y0e),e(Y0e,v9r),e(Gt,F9r),e(Gt,Im),e(Im,T9r),e(Im,K0e),e(K0e,M9r),e(Im,E9r),e(Im,lee),e(lee,C9r),e(Im,w9r),e(Gt,A9r),M(C3,Gt,null),e(tr,L9r),e(tr,Eo),M(zk,Eo,null),e(Eo,y9r),e(Eo,Z0e),e(Z0e,x9r),e(Eo,$9r),e(Eo,Mn),e(Mn,k9r),e(Mn,ewe),e(ewe,S9r),e(Mn,R9r),e(Mn,owe),e(owe,P9r),e(Mn,B9r),e(Mn,rwe),e(rwe,I9r),e(Mn,N9r),e(Eo,q9r),e(Eo,twe),e(twe,w3),e(w3,awe),e(awe,j9r),e(w3,D9r),e(w3,iee),e(iee,G9r),e(w3,O9r),e(Eo,V9r),e(Eo,A3),e(A3,X9r),e(A3,nwe),e(nwe,z9r),e(A3,Q9r),e(A3,swe),e(swe,W9r),e(Eo,U9r),M(L3,Eo,null),b(c,Moo,_),b(c,Nm,_),e(Nm,y3),e(y3,lwe),M(Qk,lwe,null),e(Nm,H9r),e(Nm,iwe),e(iwe,J9r),b(c,Eoo,_),b(c,ar,_),M(Wk,ar,null),e(ar,Y9r),e(ar,qm),e(qm,K9r),e(qm,dee),e(dee,Z9r),e(qm,exr),e(qm,mee),e(mee,oxr),e(qm,rxr),e(ar,txr),e(ar,Uk),e(Uk,axr),e(Uk,dwe),e(dwe,nxr),e(Uk,sxr),e(ar,lxr),e(ar,Ot),M(Hk,Ot,null),e(Ot,ixr),e(Ot,mwe),e(mwe,dxr),e(Ot,mxr),e(Ot,jm),e(jm,cxr),e(jm,cwe),e(cwe,fxr),e(jm,gxr),e(jm,cee),e(cee,hxr),e(jm,uxr),e(Ot,pxr),M(x3,Ot,null),e(ar,_xr),e(ar,Co),M(Jk,Co,null),e(Co,bxr),e(Co,fwe),e(fwe,vxr),e(Co,Fxr),e(Co,En),e(En,Txr),e(En,gwe),e(gwe,Mxr),e(En,Exr),e(En,hwe),e(hwe,Cxr),e(En,wxr),e(En,uwe),e(uwe,Axr),e(En,Lxr),e(Co,yxr),e(Co,gt),e(gt,$3),e($3,pwe),e(pwe,xxr),e($3,$xr),e($3,fee),e(fee,kxr),e($3,Sxr),e(gt,Rxr),e(gt,k3),e(k3,_we),e(_we,Pxr),e(k3,Bxr),e(k3,gee),e(gee,Ixr),e(k3,Nxr),e(gt,qxr),e(gt,S3),e(S3,bwe),e(bwe,jxr),e(S3,Dxr),e(S3,hee),e(hee,Gxr),e(S3,Oxr),e(gt,Vxr),e(gt,R3),e(R3,vwe),e(vwe,Xxr),e(R3,zxr),e(R3,uee),e(uee,Qxr),e(R3,Wxr),e(gt,Uxr),e(gt,P3),e(P3,Fwe),e(Fwe,Hxr),e(P3,Jxr),e(P3,pee),e(pee,Yxr),e(P3,Kxr),e(Co,Zxr),e(Co,B3),e(B3,e$r),e(B3,Twe),e(Twe,o$r),e(B3,r$r),e(B3,Mwe),e(Mwe,t$r),e(Co,a$r),M(I3,Co,null),b(c,Coo,_),b(c,Dm,_),e(Dm,N3),e(N3,Ewe),M(Yk,Ewe,null),e(Dm,n$r),e(Dm,Cwe),e(Cwe,s$r),b(c,woo,_),b(c,nr,_),M(Kk,nr,null),e(nr,l$r),e(nr,Gm),e(Gm,i$r),e(Gm,_ee),e(_ee,d$r),e(Gm,m$r),e(Gm,bee),e(bee,c$r),e(Gm,f$r),e(nr,g$r),e(nr,Zk),e(Zk,h$r),e(Zk,wwe),e(wwe,u$r),e(Zk,p$r),e(nr,_$r),e(nr,Vt),M(eS,Vt,null),e(Vt,b$r),e(Vt,Awe),e(Awe,v$r),e(Vt,F$r),e(Vt,Om),e(Om,T$r),e(Om,Lwe),e(Lwe,M$r),e(Om,E$r),e(Om,vee),e(vee,C$r),e(Om,w$r),e(Vt,A$r),M(q3,Vt,null),e(nr,L$r),e(nr,wo),M(oS,wo,null),e(wo,y$r),e(wo,ywe),e(ywe,x$r),e(wo,$$r),e(wo,Cn),e(Cn,k$r),e(Cn,xwe),e(xwe,S$r),e(Cn,R$r),e(Cn,$we),e($we,P$r),e(Cn,B$r),e(Cn,kwe),e(kwe,I$r),e(Cn,N$r),e(wo,q$r),e(wo,Swe),e(Swe,j3),e(j3,Rwe),e(Rwe,j$r),e(j3,D$r),e(j3,Fee),e(Fee,G$r),e(j3,O$r),e(wo,V$r),e(wo,D3),e(D3,X$r),e(D3,Pwe),e(Pwe,z$r),e(D3,Q$r),e(D3,Bwe),e(Bwe,W$r),e(wo,U$r),M(G3,wo,null),b(c,Aoo,_),b(c,Vm,_),e(Vm,O3),e(O3,Iwe),M(rS,Iwe,null),e(Vm,H$r),e(Vm,Nwe),e(Nwe,J$r),b(c,Loo,_),b(c,sr,_),M(tS,sr,null),e(sr,Y$r),e(sr,Xm),e(Xm,K$r),e(Xm,Tee),e(Tee,Z$r),e(Xm,ekr),e(Xm,Mee),e(Mee,okr),e(Xm,rkr),e(sr,tkr),e(sr,aS),e(aS,akr),e(aS,qwe),e(qwe,nkr),e(aS,skr),e(sr,lkr),e(sr,Xt),M(nS,Xt,null),e(Xt,ikr),e(Xt,jwe),e(jwe,dkr),e(Xt,mkr),e(Xt,zm),e(zm,ckr),e(zm,Dwe),e(Dwe,fkr),e(zm,gkr),e(zm,Eee),e(Eee,hkr),e(zm,ukr),e(Xt,pkr),M(V3,Xt,null),e(sr,_kr),e(sr,Ir),M(sS,Ir,null),e(Ir,bkr),e(Ir,Gwe),e(Gwe,vkr),e(Ir,Fkr),e(Ir,wn),e(wn,Tkr),e(wn,Owe),e(Owe,Mkr),e(wn,Ekr),e(wn,Vwe),e(Vwe,Ckr),e(wn,wkr),e(wn,Xwe),e(Xwe,Akr),e(wn,Lkr),e(Ir,ykr),e(Ir,I),e(I,X3),e(X3,zwe),e(zwe,xkr),e(X3,$kr),e(X3,Cee),e(Cee,kkr),e(X3,Skr),e(I,Rkr),e(I,z3),e(z3,Qwe),e(Qwe,Pkr),e(z3,Bkr),e(z3,wee),e(wee,Ikr),e(z3,Nkr),e(I,qkr),e(I,Q3),e(Q3,Wwe),e(Wwe,jkr),e(Q3,Dkr),e(Q3,Aee),e(Aee,Gkr),e(Q3,Okr),e(I,Vkr),e(I,W3),e(W3,Uwe),e(Uwe,Xkr),e(W3,zkr),e(W3,Lee),e(Lee,Qkr),e(W3,Wkr),e(I,Ukr),e(I,U3),e(U3,Hwe),e(Hwe,Hkr),e(U3,Jkr),e(U3,yee),e(yee,Ykr),e(U3,Kkr),e(I,Zkr),e(I,H3),e(H3,Jwe),e(Jwe,eSr),e(H3,oSr),e(H3,xee),e(xee,rSr),e(H3,tSr),e(I,aSr),e(I,J3),e(J3,Ywe),e(Ywe,nSr),e(J3,sSr),e(J3,$ee),e($ee,lSr),e(J3,iSr),e(I,dSr),e(I,Y3),e(Y3,Kwe),e(Kwe,mSr),e(Y3,cSr),e(Y3,kee),e(kee,fSr),e(Y3,gSr),e(I,hSr),e(I,K3),e(K3,Zwe),e(Zwe,uSr),e(K3,pSr),e(K3,See),e(See,_Sr),e(K3,bSr),e(I,vSr),e(I,Z3),e(Z3,eAe),e(eAe,FSr),e(Z3,TSr),e(Z3,Ree),e(Ree,MSr),e(Z3,ESr),e(I,CSr),e(I,e5),e(e5,oAe),e(oAe,wSr),e(e5,ASr),e(e5,Pee),e(Pee,LSr),e(e5,ySr),e(I,xSr),e(I,o5),e(o5,rAe),e(rAe,$Sr),e(o5,kSr),e(o5,Bee),e(Bee,SSr),e(o5,RSr),e(I,PSr),e(I,r5),e(r5,tAe),e(tAe,BSr),e(r5,ISr),e(r5,Iee),e(Iee,NSr),e(r5,qSr),e(I,jSr),e(I,t5),e(t5,aAe),e(aAe,DSr),e(t5,GSr),e(t5,Nee),e(Nee,OSr),e(t5,VSr),e(I,XSr),e(I,a5),e(a5,nAe),e(nAe,zSr),e(a5,QSr),e(a5,qee),e(qee,WSr),e(a5,USr),e(I,HSr),e(I,n5),e(n5,sAe),e(sAe,JSr),e(n5,YSr),e(n5,jee),e(jee,KSr),e(n5,ZSr),e(I,eRr),e(I,s5),e(s5,lAe),e(lAe,oRr),e(s5,rRr),e(s5,Dee),e(Dee,tRr),e(s5,aRr),e(I,nRr),e(I,l5),e(l5,iAe),e(iAe,sRr),e(l5,lRr),e(l5,Gee),e(Gee,iRr),e(l5,dRr),e(I,mRr),e(I,Fl),e(Fl,dAe),e(dAe,cRr),e(Fl,fRr),e(Fl,Oee),e(Oee,gRr),e(Fl,hRr),e(Fl,Vee),e(Vee,uRr),e(Fl,pRr),e(I,_Rr),e(I,i5),e(i5,mAe),e(mAe,bRr),e(i5,vRr),e(i5,Xee),e(Xee,FRr),e(i5,TRr),e(I,MRr),e(I,d5),e(d5,cAe),e(cAe,ERr),e(d5,CRr),e(d5,zee),e(zee,wRr),e(d5,ARr),e(I,LRr),e(I,m5),e(m5,fAe),e(fAe,yRr),e(m5,xRr),e(m5,Qee),e(Qee,$Rr),e(m5,kRr),e(I,SRr),e(I,c5),e(c5,gAe),e(gAe,RRr),e(c5,PRr),e(c5,Wee),e(Wee,BRr),e(c5,IRr),e(I,NRr),e(I,f5),e(f5,hAe),e(hAe,qRr),e(f5,jRr),e(f5,Uee),e(Uee,DRr),e(f5,GRr),e(I,ORr),e(I,g5),e(g5,uAe),e(uAe,VRr),e(g5,XRr),e(g5,Hee),e(Hee,zRr),e(g5,QRr),e(I,WRr),e(I,h5),e(h5,pAe),e(pAe,URr),e(h5,HRr),e(h5,Jee),e(Jee,JRr),e(h5,YRr),e(I,KRr),e(I,u5),e(u5,_Ae),e(_Ae,ZRr),e(u5,ePr),e(u5,Yee),e(Yee,oPr),e(u5,rPr),e(I,tPr),e(I,p5),e(p5,bAe),e(bAe,aPr),e(p5,nPr),e(p5,Kee),e(Kee,sPr),e(p5,lPr),e(I,iPr),e(I,_5),e(_5,vAe),e(vAe,dPr),e(_5,mPr),e(_5,Zee),e(Zee,cPr),e(_5,fPr),e(I,gPr),e(I,b5),e(b5,FAe),e(FAe,hPr),e(b5,uPr),e(b5,eoe),e(eoe,pPr),e(b5,_Pr),e(I,bPr),e(I,v5),e(v5,TAe),e(TAe,vPr),e(v5,FPr),e(v5,ooe),e(ooe,TPr),e(v5,MPr),e(I,EPr),e(I,F5),e(F5,MAe),e(MAe,CPr),e(F5,wPr),e(F5,roe),e(roe,APr),e(F5,LPr),e(I,yPr),e(I,T5),e(T5,EAe),e(EAe,xPr),e(T5,$Pr),e(T5,toe),e(toe,kPr),e(T5,SPr),e(I,RPr),e(I,M5),e(M5,CAe),e(CAe,PPr),e(M5,BPr),e(M5,aoe),e(aoe,IPr),e(M5,NPr),e(I,qPr),e(I,E5),e(E5,wAe),e(wAe,jPr),e(E5,DPr),e(E5,noe),e(noe,GPr),e(E5,OPr),e(I,VPr),e(I,C5),e(C5,AAe),e(AAe,XPr),e(C5,zPr),e(C5,soe),e(soe,QPr),e(C5,WPr),e(I,UPr),e(I,w5),e(w5,LAe),e(LAe,HPr),e(w5,JPr),e(w5,loe),e(loe,YPr),e(w5,KPr),e(I,ZPr),e(I,A5),e(A5,yAe),e(yAe,eBr),e(A5,oBr),e(A5,ioe),e(ioe,rBr),e(A5,tBr),e(I,aBr),e(I,L5),e(L5,xAe),e(xAe,nBr),e(L5,sBr),e(L5,doe),e(doe,lBr),e(L5,iBr),e(I,dBr),e(I,y5),e(y5,$Ae),e($Ae,mBr),e(y5,cBr),e(y5,moe),e(moe,fBr),e(y5,gBr),e(I,hBr),e(I,x5),e(x5,kAe),e(kAe,uBr),e(x5,pBr),e(x5,coe),e(coe,_Br),e(x5,bBr),e(I,vBr),e(I,$5),e($5,SAe),e(SAe,FBr),e($5,TBr),e($5,foe),e(foe,MBr),e($5,EBr),e(I,CBr),e(I,k5),e(k5,RAe),e(RAe,wBr),e(k5,ABr),e(k5,goe),e(goe,LBr),e(k5,yBr),e(I,xBr),e(I,S5),e(S5,PAe),e(PAe,$Br),e(S5,kBr),e(S5,hoe),e(hoe,SBr),e(S5,RBr),e(I,PBr),e(I,R5),e(R5,BAe),e(BAe,BBr),e(R5,IBr),e(R5,uoe),e(uoe,NBr),e(R5,qBr),e(I,jBr),e(I,P5),e(P5,IAe),e(IAe,DBr),e(P5,GBr),e(P5,poe),e(poe,OBr),e(P5,VBr),e(I,XBr),e(I,B5),e(B5,NAe),e(NAe,zBr),e(B5,QBr),e(B5,_oe),e(_oe,WBr),e(B5,UBr),e(I,HBr),e(I,I5),e(I5,qAe),e(qAe,JBr),e(I5,YBr),e(I5,boe),e(boe,KBr),e(I5,ZBr),e(I,eIr),e(I,N5),e(N5,jAe),e(jAe,oIr),e(N5,rIr),e(N5,voe),e(voe,tIr),e(N5,aIr),e(I,nIr),e(I,q5),e(q5,DAe),e(DAe,sIr),e(q5,lIr),e(q5,Foe),e(Foe,iIr),e(q5,dIr),e(I,mIr),e(I,j5),e(j5,GAe),e(GAe,cIr),e(j5,fIr),e(j5,Toe),e(Toe,gIr),e(j5,hIr),e(I,uIr),e(I,D5),e(D5,OAe),e(OAe,pIr),e(D5,_Ir),e(D5,Moe),e(Moe,bIr),e(D5,vIr),e(I,FIr),e(I,G5),e(G5,VAe),e(VAe,TIr),e(G5,MIr),e(G5,Eoe),e(Eoe,EIr),e(G5,CIr),e(I,wIr),e(I,O5),e(O5,XAe),e(XAe,AIr),e(O5,LIr),e(O5,Coe),e(Coe,yIr),e(O5,xIr),e(I,$Ir),e(I,V5),e(V5,zAe),e(zAe,kIr),e(V5,SIr),e(V5,woe),e(woe,RIr),e(V5,PIr),e(Ir,BIr),M(X5,Ir,null),b(c,yoo,_),b(c,Qm,_),e(Qm,z5),e(z5,QAe),M(lS,QAe,null),e(Qm,IIr),e(Qm,WAe),e(WAe,NIr),b(c,xoo,_),b(c,lr,_),M(iS,lr,null),e(lr,qIr),e(lr,Wm),e(Wm,jIr),e(Wm,Aoe),e(Aoe,DIr),e(Wm,GIr),e(Wm,Loe),e(Loe,OIr),e(Wm,VIr),e(lr,XIr),e(lr,dS),e(dS,zIr),e(dS,UAe),e(UAe,QIr),e(dS,WIr),e(lr,UIr),e(lr,zt),M(mS,zt,null),e(zt,HIr),e(zt,HAe),e(HAe,JIr),e(zt,YIr),e(zt,Um),e(Um,KIr),e(Um,JAe),e(JAe,ZIr),e(Um,eNr),e(Um,yoe),e(yoe,oNr),e(Um,rNr),e(zt,tNr),M(Q5,zt,null),e(lr,aNr),e(lr,Nr),M(cS,Nr,null),e(Nr,nNr),e(Nr,YAe),e(YAe,sNr),e(Nr,lNr),e(Nr,An),e(An,iNr),e(An,KAe),e(KAe,dNr),e(An,mNr),e(An,ZAe),e(ZAe,cNr),e(An,fNr),e(An,e6e),e(e6e,gNr),e(An,hNr),e(Nr,uNr),e(Nr,le),e(le,W5),e(W5,o6e),e(o6e,pNr),e(W5,_Nr),e(W5,xoe),e(xoe,bNr),e(W5,vNr),e(le,FNr),e(le,U5),e(U5,r6e),e(r6e,TNr),e(U5,MNr),e(U5,$oe),e($oe,ENr),e(U5,CNr),e(le,wNr),e(le,H5),e(H5,t6e),e(t6e,ANr),e(H5,LNr),e(H5,koe),e(koe,yNr),e(H5,xNr),e(le,$Nr),e(le,J5),e(J5,a6e),e(a6e,kNr),e(J5,SNr),e(J5,Soe),e(Soe,RNr),e(J5,PNr),e(le,BNr),e(le,Y5),e(Y5,n6e),e(n6e,INr),e(Y5,NNr),e(Y5,Roe),e(Roe,qNr),e(Y5,jNr),e(le,DNr),e(le,K5),e(K5,s6e),e(s6e,GNr),e(K5,ONr),e(K5,Poe),e(Poe,VNr),e(K5,XNr),e(le,zNr),e(le,Z5),e(Z5,l6e),e(l6e,QNr),e(Z5,WNr),e(Z5,Boe),e(Boe,UNr),e(Z5,HNr),e(le,JNr),e(le,e0),e(e0,i6e),e(i6e,YNr),e(e0,KNr),e(e0,Ioe),e(Ioe,ZNr),e(e0,eqr),e(le,oqr),e(le,o0),e(o0,d6e),e(d6e,rqr),e(o0,tqr),e(o0,Noe),e(Noe,aqr),e(o0,nqr),e(le,sqr),e(le,r0),e(r0,m6e),e(m6e,lqr),e(r0,iqr),e(r0,qoe),e(qoe,dqr),e(r0,mqr),e(le,cqr),e(le,t0),e(t0,c6e),e(c6e,fqr),e(t0,gqr),e(t0,joe),e(joe,hqr),e(t0,uqr),e(le,pqr),e(le,a0),e(a0,f6e),e(f6e,_qr),e(a0,bqr),e(a0,Doe),e(Doe,vqr),e(a0,Fqr),e(le,Tqr),e(le,n0),e(n0,g6e),e(g6e,Mqr),e(n0,Eqr),e(n0,Goe),e(Goe,Cqr),e(n0,wqr),e(le,Aqr),e(le,s0),e(s0,h6e),e(h6e,Lqr),e(s0,yqr),e(s0,Ooe),e(Ooe,xqr),e(s0,$qr),e(le,kqr),e(le,l0),e(l0,u6e),e(u6e,Sqr),e(l0,Rqr),e(l0,Voe),e(Voe,Pqr),e(l0,Bqr),e(le,Iqr),e(le,i0),e(i0,p6e),e(p6e,Nqr),e(i0,qqr),e(i0,Xoe),e(Xoe,jqr),e(i0,Dqr),e(le,Gqr),e(le,d0),e(d0,_6e),e(_6e,Oqr),e(d0,Vqr),e(d0,zoe),e(zoe,Xqr),e(d0,zqr),e(le,Qqr),e(le,m0),e(m0,b6e),e(b6e,Wqr),e(m0,Uqr),e(m0,Qoe),e(Qoe,Hqr),e(m0,Jqr),e(le,Yqr),e(le,c0),e(c0,v6e),e(v6e,Kqr),e(c0,Zqr),e(c0,Woe),e(Woe,ejr),e(c0,ojr),e(le,rjr),e(le,f0),e(f0,F6e),e(F6e,tjr),e(f0,ajr),e(f0,Uoe),e(Uoe,njr),e(f0,sjr),e(le,ljr),e(le,g0),e(g0,T6e),e(T6e,ijr),e(g0,djr),e(g0,Hoe),e(Hoe,mjr),e(g0,cjr),e(le,fjr),e(le,h0),e(h0,M6e),e(M6e,gjr),e(h0,hjr),e(h0,Joe),e(Joe,ujr),e(h0,pjr),e(le,_jr),e(le,u0),e(u0,E6e),e(E6e,bjr),e(u0,vjr),e(u0,Yoe),e(Yoe,Fjr),e(u0,Tjr),e(Nr,Mjr),M(p0,Nr,null),b(c,$oo,_),b(c,Hm,_),e(Hm,_0),e(_0,C6e),M(fS,C6e,null),e(Hm,Ejr),e(Hm,w6e),e(w6e,Cjr),b(c,koo,_),b(c,ir,_),M(gS,ir,null),e(ir,wjr),e(ir,Jm),e(Jm,Ajr),e(Jm,Koe),e(Koe,Ljr),e(Jm,yjr),e(Jm,Zoe),e(Zoe,xjr),e(Jm,$jr),e(ir,kjr),e(ir,hS),e(hS,Sjr),e(hS,A6e),e(A6e,Rjr),e(hS,Pjr),e(ir,Bjr),e(ir,Qt),M(uS,Qt,null),e(Qt,Ijr),e(Qt,L6e),e(L6e,Njr),e(Qt,qjr),e(Qt,Ym),e(Ym,jjr),e(Ym,y6e),e(y6e,Djr),e(Ym,Gjr),e(Ym,ere),e(ere,Ojr),e(Ym,Vjr),e(Qt,Xjr),M(b0,Qt,null),e(ir,zjr),e(ir,qr),M(pS,qr,null),e(qr,Qjr),e(qr,x6e),e(x6e,Wjr),e(qr,Ujr),e(qr,Ln),e(Ln,Hjr),e(Ln,$6e),e($6e,Jjr),e(Ln,Yjr),e(Ln,k6e),e(k6e,Kjr),e(Ln,Zjr),e(Ln,S6e),e(S6e,eDr),e(Ln,oDr),e(qr,rDr),e(qr,Me),e(Me,v0),e(v0,R6e),e(R6e,tDr),e(v0,aDr),e(v0,ore),e(ore,nDr),e(v0,sDr),e(Me,lDr),e(Me,F0),e(F0,P6e),e(P6e,iDr),e(F0,dDr),e(F0,rre),e(rre,mDr),e(F0,cDr),e(Me,fDr),e(Me,T0),e(T0,B6e),e(B6e,gDr),e(T0,hDr),e(T0,tre),e(tre,uDr),e(T0,pDr),e(Me,_Dr),e(Me,M0),e(M0,I6e),e(I6e,bDr),e(M0,vDr),e(M0,are),e(are,FDr),e(M0,TDr),e(Me,MDr),e(Me,E0),e(E0,N6e),e(N6e,EDr),e(E0,CDr),e(E0,nre),e(nre,wDr),e(E0,ADr),e(Me,LDr),e(Me,C0),e(C0,q6e),e(q6e,yDr),e(C0,xDr),e(C0,sre),e(sre,$Dr),e(C0,kDr),e(Me,SDr),e(Me,w0),e(w0,j6e),e(j6e,RDr),e(w0,PDr),e(w0,lre),e(lre,BDr),e(w0,IDr),e(Me,NDr),e(Me,A0),e(A0,D6e),e(D6e,qDr),e(A0,jDr),e(A0,ire),e(ire,DDr),e(A0,GDr),e(Me,ODr),e(Me,L0),e(L0,G6e),e(G6e,VDr),e(L0,XDr),e(L0,dre),e(dre,zDr),e(L0,QDr),e(Me,WDr),e(Me,y0),e(y0,O6e),e(O6e,UDr),e(y0,HDr),e(y0,mre),e(mre,JDr),e(y0,YDr),e(Me,KDr),e(Me,x0),e(x0,V6e),e(V6e,ZDr),e(x0,eGr),e(x0,cre),e(cre,oGr),e(x0,rGr),e(Me,tGr),e(Me,$0),e($0,X6e),e(X6e,aGr),e($0,nGr),e($0,fre),e(fre,sGr),e($0,lGr),e(Me,iGr),e(Me,k0),e(k0,z6e),e(z6e,dGr),e(k0,mGr),e(k0,gre),e(gre,cGr),e(k0,fGr),e(Me,gGr),e(Me,S0),e(S0,Q6e),e(Q6e,hGr),e(S0,uGr),e(S0,hre),e(hre,pGr),e(S0,_Gr),e(qr,bGr),M(R0,qr,null),b(c,Soo,_),b(c,Km,_),e(Km,P0),e(P0,W6e),M(_S,W6e,null),e(Km,vGr),e(Km,U6e),e(U6e,FGr),b(c,Roo,_),b(c,dr,_),M(bS,dr,null),e(dr,TGr),e(dr,Zm),e(Zm,MGr),e(Zm,ure),e(ure,EGr),e(Zm,CGr),e(Zm,pre),e(pre,wGr),e(Zm,AGr),e(dr,LGr),e(dr,vS),e(vS,yGr),e(vS,H6e),e(H6e,xGr),e(vS,$Gr),e(dr,kGr),e(dr,Wt),M(FS,Wt,null),e(Wt,SGr),e(Wt,J6e),e(J6e,RGr),e(Wt,PGr),e(Wt,ec),e(ec,BGr),e(ec,Y6e),e(Y6e,IGr),e(ec,NGr),e(ec,_re),e(_re,qGr),e(ec,jGr),e(Wt,DGr),M(B0,Wt,null),e(dr,GGr),e(dr,jr),M(TS,jr,null),e(jr,OGr),e(jr,K6e),e(K6e,VGr),e(jr,XGr),e(jr,yn),e(yn,zGr),e(yn,Z6e),e(Z6e,QGr),e(yn,WGr),e(yn,e7e),e(e7e,UGr),e(yn,HGr),e(yn,o7e),e(o7e,JGr),e(yn,YGr),e(jr,KGr),e(jr,Be),e(Be,I0),e(I0,r7e),e(r7e,ZGr),e(I0,eOr),e(I0,bre),e(bre,oOr),e(I0,rOr),e(Be,tOr),e(Be,N0),e(N0,t7e),e(t7e,aOr),e(N0,nOr),e(N0,vre),e(vre,sOr),e(N0,lOr),e(Be,iOr),e(Be,Tl),e(Tl,a7e),e(a7e,dOr),e(Tl,mOr),e(Tl,Fre),e(Fre,cOr),e(Tl,fOr),e(Tl,Tre),e(Tre,gOr),e(Tl,hOr),e(Be,uOr),e(Be,q0),e(q0,n7e),e(n7e,pOr),e(q0,_Or),e(q0,Mre),e(Mre,bOr),e(q0,vOr),e(Be,FOr),e(Be,j0),e(j0,s7e),e(s7e,TOr),e(j0,MOr),e(j0,Ere),e(Ere,EOr),e(j0,COr),e(Be,wOr),e(Be,D0),e(D0,l7e),e(l7e,AOr),e(D0,LOr),e(D0,Cre),e(Cre,yOr),e(D0,xOr),e(Be,$Or),e(Be,G0),e(G0,i7e),e(i7e,kOr),e(G0,SOr),e(G0,wre),e(wre,ROr),e(G0,POr),e(Be,BOr),e(Be,O0),e(O0,d7e),e(d7e,IOr),e(O0,NOr),e(O0,Are),e(Are,qOr),e(O0,jOr),e(Be,DOr),e(Be,V0),e(V0,m7e),e(m7e,GOr),e(V0,OOr),e(V0,Lre),e(Lre,VOr),e(V0,XOr),e(jr,zOr),M(X0,jr,null),b(c,Poo,_),b(c,oc,_),e(oc,z0),e(z0,c7e),M(MS,c7e,null),e(oc,QOr),e(oc,f7e),e(f7e,WOr),b(c,Boo,_),b(c,mr,_),M(ES,mr,null),e(mr,UOr),e(mr,rc),e(rc,HOr),e(rc,yre),e(yre,JOr),e(rc,YOr),e(rc,xre),e(xre,KOr),e(rc,ZOr),e(mr,eVr),e(mr,CS),e(CS,oVr),e(CS,g7e),e(g7e,rVr),e(CS,tVr),e(mr,aVr),e(mr,Ut),M(wS,Ut,null),e(Ut,nVr),e(Ut,h7e),e(h7e,sVr),e(Ut,lVr),e(Ut,tc),e(tc,iVr),e(tc,u7e),e(u7e,dVr),e(tc,mVr),e(tc,$re),e($re,cVr),e(tc,fVr),e(Ut,gVr),M(Q0,Ut,null),e(mr,hVr),e(mr,Dr),M(AS,Dr,null),e(Dr,uVr),e(Dr,p7e),e(p7e,pVr),e(Dr,_Vr),e(Dr,xn),e(xn,bVr),e(xn,_7e),e(_7e,vVr),e(xn,FVr),e(xn,b7e),e(b7e,TVr),e(xn,MVr),e(xn,v7e),e(v7e,EVr),e(xn,CVr),e(Dr,wVr),e(Dr,ac),e(ac,W0),e(W0,F7e),e(F7e,AVr),e(W0,LVr),e(W0,kre),e(kre,yVr),e(W0,xVr),e(ac,$Vr),e(ac,U0),e(U0,T7e),e(T7e,kVr),e(U0,SVr),e(U0,Sre),e(Sre,RVr),e(U0,PVr),e(ac,BVr),e(ac,H0),e(H0,M7e),e(M7e,IVr),e(H0,NVr),e(H0,Rre),e(Rre,qVr),e(H0,jVr),e(Dr,DVr),M(J0,Dr,null),b(c,Ioo,_),b(c,nc,_),e(nc,Y0),e(Y0,E7e),M(LS,E7e,null),e(nc,GVr),e(nc,C7e),e(C7e,OVr),b(c,Noo,_),b(c,cr,_),M(yS,cr,null),e(cr,VVr),e(cr,sc),e(sc,XVr),e(sc,Pre),e(Pre,zVr),e(sc,QVr),e(sc,Bre),e(Bre,WVr),e(sc,UVr),e(cr,HVr),e(cr,xS),e(xS,JVr),e(xS,w7e),e(w7e,YVr),e(xS,KVr),e(cr,ZVr),e(cr,Ht),M($S,Ht,null),e(Ht,eXr),e(Ht,A7e),e(A7e,oXr),e(Ht,rXr),e(Ht,lc),e(lc,tXr),e(lc,L7e),e(L7e,aXr),e(lc,nXr),e(lc,Ire),e(Ire,sXr),e(lc,lXr),e(Ht,iXr),M(K0,Ht,null),e(cr,dXr),e(cr,Gr),M(kS,Gr,null),e(Gr,mXr),e(Gr,y7e),e(y7e,cXr),e(Gr,fXr),e(Gr,$n),e($n,gXr),e($n,x7e),e(x7e,hXr),e($n,uXr),e($n,$7e),e($7e,pXr),e($n,_Xr),e($n,k7e),e(k7e,bXr),e($n,vXr),e(Gr,FXr),e(Gr,ge),e(ge,Z0),e(Z0,S7e),e(S7e,TXr),e(Z0,MXr),e(Z0,Nre),e(Nre,EXr),e(Z0,CXr),e(ge,wXr),e(ge,ew),e(ew,R7e),e(R7e,AXr),e(ew,LXr),e(ew,qre),e(qre,yXr),e(ew,xXr),e(ge,$Xr),e(ge,ow),e(ow,P7e),e(P7e,kXr),e(ow,SXr),e(ow,jre),e(jre,RXr),e(ow,PXr),e(ge,BXr),e(ge,rw),e(rw,B7e),e(B7e,IXr),e(rw,NXr),e(rw,Dre),e(Dre,qXr),e(rw,jXr),e(ge,DXr),e(ge,tw),e(tw,I7e),e(I7e,GXr),e(tw,OXr),e(tw,Gre),e(Gre,VXr),e(tw,XXr),e(ge,zXr),e(ge,aw),e(aw,N7e),e(N7e,QXr),e(aw,WXr),e(aw,Ore),e(Ore,UXr),e(aw,HXr),e(ge,JXr),e(ge,nw),e(nw,q7e),e(q7e,YXr),e(nw,KXr),e(nw,Vre),e(Vre,ZXr),e(nw,ezr),e(ge,ozr),e(ge,sw),e(sw,j7e),e(j7e,rzr),e(sw,tzr),e(sw,Xre),e(Xre,azr),e(sw,nzr),e(ge,szr),e(ge,lw),e(lw,D7e),e(D7e,lzr),e(lw,izr),e(lw,zre),e(zre,dzr),e(lw,mzr),e(ge,czr),e(ge,iw),e(iw,G7e),e(G7e,fzr),e(iw,gzr),e(iw,Qre),e(Qre,hzr),e(iw,uzr),e(ge,pzr),e(ge,dw),e(dw,O7e),e(O7e,_zr),e(dw,bzr),e(dw,Wre),e(Wre,vzr),e(dw,Fzr),e(ge,Tzr),e(ge,mw),e(mw,V7e),e(V7e,Mzr),e(mw,Ezr),e(mw,Ure),e(Ure,Czr),e(mw,wzr),e(ge,Azr),e(ge,cw),e(cw,X7e),e(X7e,Lzr),e(cw,yzr),e(cw,Hre),e(Hre,xzr),e(cw,$zr),e(ge,kzr),e(ge,fw),e(fw,z7e),e(z7e,Szr),e(fw,Rzr),e(fw,Jre),e(Jre,Pzr),e(fw,Bzr),e(ge,Izr),e(ge,gw),e(gw,Q7e),e(Q7e,Nzr),e(gw,qzr),e(gw,Yre),e(Yre,jzr),e(gw,Dzr),e(ge,Gzr),e(ge,hw),e(hw,W7e),e(W7e,Ozr),e(hw,Vzr),e(hw,Kre),e(Kre,Xzr),e(hw,zzr),e(ge,Qzr),e(ge,uw),e(uw,U7e),e(U7e,Wzr),e(uw,Uzr),e(uw,Zre),e(Zre,Hzr),e(uw,Jzr),e(ge,Yzr),e(ge,pw),e(pw,H7e),e(H7e,Kzr),e(pw,Zzr),e(pw,ete),e(ete,eQr),e(pw,oQr),e(ge,rQr),e(ge,_w),e(_w,J7e),e(J7e,tQr),e(_w,aQr),e(_w,ote),e(ote,nQr),e(_w,sQr),e(ge,lQr),e(ge,bw),e(bw,Y7e),e(Y7e,iQr),e(bw,dQr),e(bw,rte),e(rte,mQr),e(bw,cQr),e(Gr,fQr),M(vw,Gr,null),b(c,qoo,_),b(c,ic,_),e(ic,Fw),e(Fw,K7e),M(SS,K7e,null),e(ic,gQr),e(ic,Z7e),e(Z7e,hQr),b(c,joo,_),b(c,fr,_),M(RS,fr,null),e(fr,uQr),e(fr,dc),e(dc,pQr),e(dc,tte),e(tte,_Qr),e(dc,bQr),e(dc,ate),e(ate,vQr),e(dc,FQr),e(fr,TQr),e(fr,PS),e(PS,MQr),e(PS,eLe),e(eLe,EQr),e(PS,CQr),e(fr,wQr),e(fr,Jt),M(BS,Jt,null),e(Jt,AQr),e(Jt,oLe),e(oLe,LQr),e(Jt,yQr),e(Jt,mc),e(mc,xQr),e(mc,rLe),e(rLe,$Qr),e(mc,kQr),e(mc,nte),e(nte,SQr),e(mc,RQr),e(Jt,PQr),M(Tw,Jt,null),e(fr,BQr),e(fr,Or),M(IS,Or,null),e(Or,IQr),e(Or,tLe),e(tLe,NQr),e(Or,qQr),e(Or,kn),e(kn,jQr),e(kn,aLe),e(aLe,DQr),e(kn,GQr),e(kn,nLe),e(nLe,OQr),e(kn,VQr),e(kn,sLe),e(sLe,XQr),e(kn,zQr),e(Or,QQr),e(Or,ye),e(ye,Mw),e(Mw,lLe),e(lLe,WQr),e(Mw,UQr),e(Mw,ste),e(ste,HQr),e(Mw,JQr),e(ye,YQr),e(ye,Ew),e(Ew,iLe),e(iLe,KQr),e(Ew,ZQr),e(Ew,lte),e(lte,eWr),e(Ew,oWr),e(ye,rWr),e(ye,Cw),e(Cw,dLe),e(dLe,tWr),e(Cw,aWr),e(Cw,ite),e(ite,nWr),e(Cw,sWr),e(ye,lWr),e(ye,ww),e(ww,mLe),e(mLe,iWr),e(ww,dWr),e(ww,dte),e(dte,mWr),e(ww,cWr),e(ye,fWr),e(ye,Aw),e(Aw,cLe),e(cLe,gWr),e(Aw,hWr),e(Aw,mte),e(mte,uWr),e(Aw,pWr),e(ye,_Wr),e(ye,Lw),e(Lw,fLe),e(fLe,bWr),e(Lw,vWr),e(Lw,cte),e(cte,FWr),e(Lw,TWr),e(ye,MWr),e(ye,yw),e(yw,gLe),e(gLe,EWr),e(yw,CWr),e(yw,fte),e(fte,wWr),e(yw,AWr),e(ye,LWr),e(ye,xw),e(xw,hLe),e(hLe,yWr),e(xw,xWr),e(xw,gte),e(gte,$Wr),e(xw,kWr),e(ye,SWr),e(ye,$w),e($w,uLe),e(uLe,RWr),e($w,PWr),e($w,hte),e(hte,BWr),e($w,IWr),e(ye,NWr),e(ye,kw),e(kw,pLe),e(pLe,qWr),e(kw,jWr),e(kw,ute),e(ute,DWr),e(kw,GWr),e(Or,OWr),M(Sw,Or,null),b(c,Doo,_),b(c,cc,_),e(cc,Rw),e(Rw,_Le),M(NS,_Le,null),e(cc,VWr),e(cc,bLe),e(bLe,XWr),b(c,Goo,_),b(c,gr,_),M(qS,gr,null),e(gr,zWr),e(gr,fc),e(fc,QWr),e(fc,pte),e(pte,WWr),e(fc,UWr),e(fc,_te),e(_te,HWr),e(fc,JWr),e(gr,YWr),e(gr,jS),e(jS,KWr),e(jS,vLe),e(vLe,ZWr),e(jS,eUr),e(gr,oUr),e(gr,Yt),M(DS,Yt,null),e(Yt,rUr),e(Yt,FLe),e(FLe,tUr),e(Yt,aUr),e(Yt,gc),e(gc,nUr),e(gc,TLe),e(TLe,sUr),e(gc,lUr),e(gc,bte),e(bte,iUr),e(gc,dUr),e(Yt,mUr),M(Pw,Yt,null),e(gr,cUr),e(gr,Vr),M(GS,Vr,null),e(Vr,fUr),e(Vr,MLe),e(MLe,gUr),e(Vr,hUr),e(Vr,Sn),e(Sn,uUr),e(Sn,ELe),e(ELe,pUr),e(Sn,_Ur),e(Sn,CLe),e(CLe,bUr),e(Sn,vUr),e(Sn,wLe),e(wLe,FUr),e(Sn,TUr),e(Vr,MUr),e(Vr,re),e(re,Bw),e(Bw,ALe),e(ALe,EUr),e(Bw,CUr),e(Bw,vte),e(vte,wUr),e(Bw,AUr),e(re,LUr),e(re,Iw),e(Iw,LLe),e(LLe,yUr),e(Iw,xUr),e(Iw,Fte),e(Fte,$Ur),e(Iw,kUr),e(re,SUr),e(re,Nw),e(Nw,yLe),e(yLe,RUr),e(Nw,PUr),e(Nw,Tte),e(Tte,BUr),e(Nw,IUr),e(re,NUr),e(re,qw),e(qw,xLe),e(xLe,qUr),e(qw,jUr),e(qw,Mte),e(Mte,DUr),e(qw,GUr),e(re,OUr),e(re,jw),e(jw,$Le),e($Le,VUr),e(jw,XUr),e(jw,Ete),e(Ete,zUr),e(jw,QUr),e(re,WUr),e(re,Dw),e(Dw,kLe),e(kLe,UUr),e(Dw,HUr),e(Dw,Cte),e(Cte,JUr),e(Dw,YUr),e(re,KUr),e(re,Gw),e(Gw,SLe),e(SLe,ZUr),e(Gw,eHr),e(Gw,wte),e(wte,oHr),e(Gw,rHr),e(re,tHr),e(re,Ow),e(Ow,RLe),e(RLe,aHr),e(Ow,nHr),e(Ow,Ate),e(Ate,sHr),e(Ow,lHr),e(re,iHr),e(re,Vw),e(Vw,PLe),e(PLe,dHr),e(Vw,mHr),e(Vw,Lte),e(Lte,cHr),e(Vw,fHr),e(re,gHr),e(re,Xw),e(Xw,BLe),e(BLe,hHr),e(Xw,uHr),e(Xw,yte),e(yte,pHr),e(Xw,_Hr),e(re,bHr),e(re,zw),e(zw,ILe),e(ILe,vHr),e(zw,FHr),e(zw,xte),e(xte,THr),e(zw,MHr),e(re,EHr),e(re,Qw),e(Qw,NLe),e(NLe,CHr),e(Qw,wHr),e(Qw,$te),e($te,AHr),e(Qw,LHr),e(re,yHr),e(re,Ww),e(Ww,qLe),e(qLe,xHr),e(Ww,$Hr),e(Ww,kte),e(kte,kHr),e(Ww,SHr),e(re,RHr),e(re,Uw),e(Uw,jLe),e(jLe,PHr),e(Uw,BHr),e(Uw,Ste),e(Ste,IHr),e(Uw,NHr),e(re,qHr),e(re,Hw),e(Hw,DLe),e(DLe,jHr),e(Hw,DHr),e(Hw,Rte),e(Rte,GHr),e(Hw,OHr),e(re,VHr),e(re,Jw),e(Jw,GLe),e(GLe,XHr),e(Jw,zHr),e(Jw,Pte),e(Pte,QHr),e(Jw,WHr),e(re,UHr),e(re,Yw),e(Yw,OLe),e(OLe,HHr),e(Yw,JHr),e(Yw,Bte),e(Bte,YHr),e(Yw,KHr),e(re,ZHr),e(re,Kw),e(Kw,VLe),e(VLe,eJr),e(Kw,oJr),e(Kw,Ite),e(Ite,rJr),e(Kw,tJr),e(re,aJr),e(re,Zw),e(Zw,XLe),e(XLe,nJr),e(Zw,sJr),e(Zw,Nte),e(Nte,lJr),e(Zw,iJr),e(re,dJr),e(re,eA),e(eA,zLe),e(zLe,mJr),e(eA,cJr),e(eA,qte),e(qte,fJr),e(eA,gJr),e(re,hJr),e(re,oA),e(oA,QLe),e(QLe,uJr),e(oA,pJr),e(oA,jte),e(jte,_Jr),e(oA,bJr),e(re,vJr),e(re,rA),e(rA,WLe),e(WLe,FJr),e(rA,TJr),e(rA,Dte),e(Dte,MJr),e(rA,EJr),e(re,CJr),e(re,tA),e(tA,ULe),e(ULe,wJr),e(tA,AJr),e(tA,Gte),e(Gte,LJr),e(tA,yJr),e(re,xJr),e(re,aA),e(aA,HLe),e(HLe,$Jr),e(aA,kJr),e(aA,Ote),e(Ote,SJr),e(aA,RJr),e(re,PJr),e(re,nA),e(nA,JLe),e(JLe,BJr),e(nA,IJr),e(nA,Vte),e(Vte,NJr),e(nA,qJr),e(re,jJr),e(re,sA),e(sA,YLe),e(YLe,DJr),e(sA,GJr),e(sA,Xte),e(Xte,OJr),e(sA,VJr),e(re,XJr),e(re,lA),e(lA,KLe),e(KLe,zJr),e(lA,QJr),e(lA,zte),e(zte,WJr),e(lA,UJr),e(Vr,HJr),M(iA,Vr,null),b(c,Ooo,_),b(c,hc,_),e(hc,dA),e(dA,ZLe),M(OS,ZLe,null),e(hc,JJr),e(hc,eye),e(eye,YJr),b(c,Voo,_),b(c,hr,_),M(VS,hr,null),e(hr,KJr),e(hr,uc),e(uc,ZJr),e(uc,Qte),e(Qte,eYr),e(uc,oYr),e(uc,Wte),e(Wte,rYr),e(uc,tYr),e(hr,aYr),e(hr,XS),e(XS,nYr),e(XS,oye),e(oye,sYr),e(XS,lYr),e(hr,iYr),e(hr,Kt),M(zS,Kt,null),e(Kt,dYr),e(Kt,rye),e(rye,mYr),e(Kt,cYr),e(Kt,pc),e(pc,fYr),e(pc,tye),e(tye,gYr),e(pc,hYr),e(pc,Ute),e(Ute,uYr),e(pc,pYr),e(Kt,_Yr),M(mA,Kt,null),e(hr,bYr),e(hr,Xr),M(QS,Xr,null),e(Xr,vYr),e(Xr,aye),e(aye,FYr),e(Xr,TYr),e(Xr,Rn),e(Rn,MYr),e(Rn,nye),e(nye,EYr),e(Rn,CYr),e(Rn,sye),e(sye,wYr),e(Rn,AYr),e(Rn,lye),e(lye,LYr),e(Rn,yYr),e(Xr,xYr),e(Xr,ve),e(ve,cA),e(cA,iye),e(iye,$Yr),e(cA,kYr),e(cA,Hte),e(Hte,SYr),e(cA,RYr),e(ve,PYr),e(ve,fA),e(fA,dye),e(dye,BYr),e(fA,IYr),e(fA,Jte),e(Jte,NYr),e(fA,qYr),e(ve,jYr),e(ve,gA),e(gA,mye),e(mye,DYr),e(gA,GYr),e(gA,Yte),e(Yte,OYr),e(gA,VYr),e(ve,XYr),e(ve,hA),e(hA,cye),e(cye,zYr),e(hA,QYr),e(hA,Kte),e(Kte,WYr),e(hA,UYr),e(ve,HYr),e(ve,uA),e(uA,fye),e(fye,JYr),e(uA,YYr),e(uA,Zte),e(Zte,KYr),e(uA,ZYr),e(ve,eKr),e(ve,pA),e(pA,gye),e(gye,oKr),e(pA,rKr),e(pA,eae),e(eae,tKr),e(pA,aKr),e(ve,nKr),e(ve,_A),e(_A,hye),e(hye,sKr),e(_A,lKr),e(_A,oae),e(oae,iKr),e(_A,dKr),e(ve,mKr),e(ve,bA),e(bA,uye),e(uye,cKr),e(bA,fKr),e(bA,rae),e(rae,gKr),e(bA,hKr),e(ve,uKr),e(ve,vA),e(vA,pye),e(pye,pKr),e(vA,_Kr),e(vA,tae),e(tae,bKr),e(vA,vKr),e(ve,FKr),e(ve,FA),e(FA,_ye),e(_ye,TKr),e(FA,MKr),e(FA,aae),e(aae,EKr),e(FA,CKr),e(ve,wKr),e(ve,TA),e(TA,bye),e(bye,AKr),e(TA,LKr),e(TA,nae),e(nae,yKr),e(TA,xKr),e(ve,$Kr),e(ve,MA),e(MA,vye),e(vye,kKr),e(MA,SKr),e(MA,sae),e(sae,RKr),e(MA,PKr),e(ve,BKr),e(ve,EA),e(EA,Fye),e(Fye,IKr),e(EA,NKr),e(EA,lae),e(lae,qKr),e(EA,jKr),e(ve,DKr),e(ve,CA),e(CA,Tye),e(Tye,GKr),e(CA,OKr),e(CA,iae),e(iae,VKr),e(CA,XKr),e(ve,zKr),e(ve,wA),e(wA,Mye),e(Mye,QKr),e(wA,WKr),e(wA,dae),e(dae,UKr),e(wA,HKr),e(ve,JKr),e(ve,AA),e(AA,Eye),e(Eye,YKr),e(AA,KKr),e(AA,mae),e(mae,ZKr),e(AA,eZr),e(ve,oZr),e(ve,LA),e(LA,Cye),e(Cye,rZr),e(LA,tZr),e(LA,cae),e(cae,aZr),e(LA,nZr),e(Xr,sZr),M(yA,Xr,null),b(c,Xoo,_),b(c,_c,_),e(_c,xA),e(xA,wye),M(WS,wye,null),e(_c,lZr),e(_c,Aye),e(Aye,iZr),b(c,zoo,_),b(c,ur,_),M(US,ur,null),e(ur,dZr),e(ur,bc),e(bc,mZr),e(bc,fae),e(fae,cZr),e(bc,fZr),e(bc,gae),e(gae,gZr),e(bc,hZr),e(ur,uZr),e(ur,HS),e(HS,pZr),e(HS,Lye),e(Lye,_Zr),e(HS,bZr),e(ur,vZr),e(ur,Zt),M(JS,Zt,null),e(Zt,FZr),e(Zt,yye),e(yye,TZr),e(Zt,MZr),e(Zt,vc),e(vc,EZr),e(vc,xye),e(xye,CZr),e(vc,wZr),e(vc,hae),e(hae,AZr),e(vc,LZr),e(Zt,yZr),M($A,Zt,null),e(ur,xZr),e(ur,zr),M(YS,zr,null),e(zr,$Zr),e(zr,$ye),e($ye,kZr),e(zr,SZr),e(zr,Pn),e(Pn,RZr),e(Pn,kye),e(kye,PZr),e(Pn,BZr),e(Pn,Sye),e(Sye,IZr),e(Pn,NZr),e(Pn,Rye),e(Rye,qZr),e(Pn,jZr),e(zr,DZr),e(zr,KS),e(KS,kA),e(kA,Pye),e(Pye,GZr),e(kA,OZr),e(kA,uae),e(uae,VZr),e(kA,XZr),e(KS,zZr),e(KS,SA),e(SA,Bye),e(Bye,QZr),e(SA,WZr),e(SA,pae),e(pae,UZr),e(SA,HZr),e(zr,JZr),M(RA,zr,null),b(c,Qoo,_),b(c,Fc,_),e(Fc,PA),e(PA,Iye),M(ZS,Iye,null),e(Fc,YZr),e(Fc,Nye),e(Nye,KZr),b(c,Woo,_),b(c,pr,_),M(eR,pr,null),e(pr,ZZr),e(pr,Tc),e(Tc,eet),e(Tc,_ae),e(_ae,oet),e(Tc,ret),e(Tc,bae),e(bae,tet),e(Tc,aet),e(pr,net),e(pr,oR),e(oR,set),e(oR,qye),e(qye,iet),e(oR,det),e(pr,met),e(pr,ea),M(rR,ea,null),e(ea,cet),e(ea,jye),e(jye,fet),e(ea,get),e(ea,Mc),e(Mc,het),e(Mc,Dye),e(Dye,uet),e(Mc,pet),e(Mc,vae),e(vae,_et),e(Mc,bet),e(ea,vet),M(BA,ea,null),e(pr,Fet),e(pr,Qr),M(tR,Qr,null),e(Qr,Tet),e(Qr,Gye),e(Gye,Met),e(Qr,Eet),e(Qr,Bn),e(Bn,Cet),e(Bn,Oye),e(Oye,wet),e(Bn,Aet),e(Bn,Vye),e(Vye,Let),e(Bn,yet),e(Bn,Xye),e(Xye,xet),e(Bn,$et),e(Qr,ket),e(Qr,zye),e(zye,IA),e(IA,Qye),e(Qye,Set),e(IA,Ret),e(IA,Fae),e(Fae,Pet),e(IA,Bet),e(Qr,Iet),M(NA,Qr,null),b(c,Uoo,_),b(c,Ec,_),e(Ec,qA),e(qA,Wye),M(aR,Wye,null),e(Ec,Net),e(Ec,Uye),e(Uye,qet),b(c,Hoo,_),b(c,_r,_),M(nR,_r,null),e(_r,jet),e(_r,Cc),e(Cc,Det),e(Cc,Tae),e(Tae,Get),e(Cc,Oet),e(Cc,Mae),e(Mae,Vet),e(Cc,Xet),e(_r,zet),e(_r,sR),e(sR,Qet),e(sR,Hye),e(Hye,Wet),e(sR,Uet),e(_r,Het),e(_r,oa),M(lR,oa,null),e(oa,Jet),e(oa,Jye),e(Jye,Yet),e(oa,Ket),e(oa,wc),e(wc,Zet),e(wc,Yye),e(Yye,eot),e(wc,oot),e(wc,Eae),e(Eae,rot),e(wc,tot),e(oa,aot),M(jA,oa,null),e(_r,not),e(_r,Wr),M(iR,Wr,null),e(Wr,sot),e(Wr,Kye),e(Kye,lot),e(Wr,iot),e(Wr,In),e(In,dot),e(In,Zye),e(Zye,mot),e(In,cot),e(In,e8e),e(e8e,fot),e(In,got),e(In,o8e),e(o8e,hot),e(In,uot),e(Wr,pot),e(Wr,r8e),e(r8e,DA),e(DA,t8e),e(t8e,_ot),e(DA,bot),e(DA,Cae),e(Cae,vot),e(DA,Fot),e(Wr,Tot),M(GA,Wr,null),b(c,Joo,_),b(c,Ac,_),e(Ac,OA),e(OA,a8e),M(dR,a8e,null),e(Ac,Mot),e(Ac,n8e),e(n8e,Eot),b(c,Yoo,_),b(c,br,_),M(mR,br,null),e(br,Cot),e(br,Lc),e(Lc,wot),e(Lc,wae),e(wae,Aot),e(Lc,Lot),e(Lc,Aae),e(Aae,yot),e(Lc,xot),e(br,$ot),e(br,cR),e(cR,kot),e(cR,s8e),e(s8e,Sot),e(cR,Rot),e(br,Pot),e(br,ra),M(fR,ra,null),e(ra,Bot),e(ra,l8e),e(l8e,Iot),e(ra,Not),e(ra,yc),e(yc,qot),e(yc,i8e),e(i8e,jot),e(yc,Dot),e(yc,Lae),e(Lae,Got),e(yc,Oot),e(ra,Vot),M(VA,ra,null),e(br,Xot),e(br,Ur),M(gR,Ur,null),e(Ur,zot),e(Ur,d8e),e(d8e,Qot),e(Ur,Wot),e(Ur,Nn),e(Nn,Uot),e(Nn,m8e),e(m8e,Hot),e(Nn,Jot),e(Nn,c8e),e(c8e,Yot),e(Nn,Kot),e(Nn,f8e),e(f8e,Zot),e(Nn,ert),e(Ur,ort),e(Ur,me),e(me,XA),e(XA,g8e),e(g8e,rrt),e(XA,trt),e(XA,yae),e(yae,art),e(XA,nrt),e(me,srt),e(me,zA),e(zA,h8e),e(h8e,lrt),e(zA,irt),e(zA,xae),e(xae,drt),e(zA,mrt),e(me,crt),e(me,QA),e(QA,u8e),e(u8e,frt),e(QA,grt),e(QA,$ae),e($ae,hrt),e(QA,urt),e(me,prt),e(me,WA),e(WA,p8e),e(p8e,_rt),e(WA,brt),e(WA,kae),e(kae,vrt),e(WA,Frt),e(me,Trt),e(me,UA),e(UA,_8e),e(_8e,Mrt),e(UA,Ert),e(UA,Sae),e(Sae,Crt),e(UA,wrt),e(me,Art),e(me,HA),e(HA,b8e),e(b8e,Lrt),e(HA,yrt),e(HA,Rae),e(Rae,xrt),e(HA,$rt),e(me,krt),e(me,JA),e(JA,v8e),e(v8e,Srt),e(JA,Rrt),e(JA,Pae),e(Pae,Prt),e(JA,Brt),e(me,Irt),e(me,YA),e(YA,F8e),e(F8e,Nrt),e(YA,qrt),e(YA,Bae),e(Bae,jrt),e(YA,Drt),e(me,Grt),e(me,KA),e(KA,T8e),e(T8e,Ort),e(KA,Vrt),e(KA,Iae),e(Iae,Xrt),e(KA,zrt),e(me,Qrt),e(me,ZA),e(ZA,M8e),e(M8e,Wrt),e(ZA,Urt),e(ZA,Nae),e(Nae,Hrt),e(ZA,Jrt),e(me,Yrt),e(me,e6),e(e6,E8e),e(E8e,Krt),e(e6,Zrt),e(e6,qae),e(qae,ett),e(e6,ott),e(me,rtt),e(me,o6),e(o6,C8e),e(C8e,ttt),e(o6,att),e(o6,jae),e(jae,ntt),e(o6,stt),e(me,ltt),e(me,r6),e(r6,w8e),e(w8e,itt),e(r6,dtt),e(r6,Dae),e(Dae,mtt),e(r6,ctt),e(me,ftt),e(me,t6),e(t6,A8e),e(A8e,gtt),e(t6,htt),e(t6,Gae),e(Gae,utt),e(t6,ptt),e(me,_tt),e(me,a6),e(a6,L8e),e(L8e,btt),e(a6,vtt),e(a6,Oae),e(Oae,Ftt),e(a6,Ttt),e(me,Mtt),e(me,n6),e(n6,y8e),e(y8e,Ett),e(n6,Ctt),e(n6,Vae),e(Vae,wtt),e(n6,Att),e(me,Ltt),e(me,s6),e(s6,x8e),e(x8e,ytt),e(s6,xtt),e(s6,Xae),e(Xae,$tt),e(s6,ktt),e(me,Stt),e(me,l6),e(l6,$8e),e($8e,Rtt),e(l6,Ptt),e(l6,zae),e(zae,Btt),e(l6,Itt),e(me,Ntt),e(me,i6),e(i6,k8e),e(k8e,qtt),e(i6,jtt),e(i6,Qae),e(Qae,Dtt),e(i6,Gtt),e(me,Ott),e(me,d6),e(d6,S8e),e(S8e,Vtt),e(d6,Xtt),e(d6,Wae),e(Wae,ztt),e(d6,Qtt),e(me,Wtt),e(me,m6),e(m6,R8e),e(R8e,Utt),e(m6,Htt),e(m6,Uae),e(Uae,Jtt),e(m6,Ytt),e(Ur,Ktt),M(c6,Ur,null),b(c,Koo,_),b(c,xc,_),e(xc,f6),e(f6,P8e),M(hR,P8e,null),e(xc,Ztt),e(xc,B8e),e(B8e,eat),b(c,Zoo,_),b(c,vr,_),M(uR,vr,null),e(vr,oat),e(vr,$c),e($c,rat),e($c,Hae),e(Hae,tat),e($c,aat),e($c,Jae),e(Jae,nat),e($c,sat),e(vr,lat),e(vr,pR),e(pR,iat),e(pR,I8e),e(I8e,dat),e(pR,mat),e(vr,cat),e(vr,ta),M(_R,ta,null),e(ta,fat),e(ta,N8e),e(N8e,gat),e(ta,hat),e(ta,kc),e(kc,uat),e(kc,q8e),e(q8e,pat),e(kc,_at),e(kc,Yae),e(Yae,bat),e(kc,vat),e(ta,Fat),M(g6,ta,null),e(vr,Tat),e(vr,Hr),M(bR,Hr,null),e(Hr,Mat),e(Hr,j8e),e(j8e,Eat),e(Hr,Cat),e(Hr,qn),e(qn,wat),e(qn,D8e),e(D8e,Aat),e(qn,Lat),e(qn,G8e),e(G8e,yat),e(qn,xat),e(qn,O8e),e(O8e,$at),e(qn,kat),e(Hr,Sat),e(Hr,ce),e(ce,h6),e(h6,V8e),e(V8e,Rat),e(h6,Pat),e(h6,Kae),e(Kae,Bat),e(h6,Iat),e(ce,Nat),e(ce,u6),e(u6,X8e),e(X8e,qat),e(u6,jat),e(u6,Zae),e(Zae,Dat),e(u6,Gat),e(ce,Oat),e(ce,p6),e(p6,z8e),e(z8e,Vat),e(p6,Xat),e(p6,ene),e(ene,zat),e(p6,Qat),e(ce,Wat),e(ce,_6),e(_6,Q8e),e(Q8e,Uat),e(_6,Hat),e(_6,one),e(one,Jat),e(_6,Yat),e(ce,Kat),e(ce,b6),e(b6,W8e),e(W8e,Zat),e(b6,ent),e(b6,rne),e(rne,ont),e(b6,rnt),e(ce,tnt),e(ce,v6),e(v6,U8e),e(U8e,ant),e(v6,nnt),e(v6,tne),e(tne,snt),e(v6,lnt),e(ce,int),e(ce,F6),e(F6,H8e),e(H8e,dnt),e(F6,mnt),e(F6,ane),e(ane,cnt),e(F6,fnt),e(ce,gnt),e(ce,T6),e(T6,J8e),e(J8e,hnt),e(T6,unt),e(T6,nne),e(nne,pnt),e(T6,_nt),e(ce,bnt),e(ce,M6),e(M6,Y8e),e(Y8e,vnt),e(M6,Fnt),e(M6,sne),e(sne,Tnt),e(M6,Mnt),e(ce,Ent),e(ce,E6),e(E6,K8e),e(K8e,Cnt),e(E6,wnt),e(E6,lne),e(lne,Ant),e(E6,Lnt),e(ce,ynt),e(ce,C6),e(C6,Z8e),e(Z8e,xnt),e(C6,$nt),e(C6,ine),e(ine,knt),e(C6,Snt),e(ce,Rnt),e(ce,w6),e(w6,e9e),e(e9e,Pnt),e(w6,Bnt),e(w6,dne),e(dne,Int),e(w6,Nnt),e(ce,qnt),e(ce,A6),e(A6,o9e),e(o9e,jnt),e(A6,Dnt),e(A6,mne),e(mne,Gnt),e(A6,Ont),e(ce,Vnt),e(ce,L6),e(L6,r9e),e(r9e,Xnt),e(L6,znt),e(L6,cne),e(cne,Qnt),e(L6,Wnt),e(ce,Unt),e(ce,y6),e(y6,t9e),e(t9e,Hnt),e(y6,Jnt),e(y6,fne),e(fne,Ynt),e(y6,Knt),e(ce,Znt),e(ce,x6),e(x6,a9e),e(a9e,est),e(x6,ost),e(x6,gne),e(gne,rst),e(x6,tst),e(ce,ast),e(ce,$6),e($6,n9e),e(n9e,nst),e($6,sst),e($6,hne),e(hne,lst),e($6,ist),e(ce,dst),e(ce,k6),e(k6,s9e),e(s9e,mst),e(k6,cst),e(k6,une),e(une,fst),e(k6,gst),e(ce,hst),e(ce,S6),e(S6,l9e),e(l9e,ust),e(S6,pst),e(S6,pne),e(pne,_st),e(S6,bst),e(ce,vst),e(ce,R6),e(R6,i9e),e(i9e,Fst),e(R6,Tst),e(R6,_ne),e(_ne,Mst),e(R6,Est),e(ce,Cst),e(ce,P6),e(P6,d9e),e(d9e,wst),e(P6,Ast),e(P6,bne),e(bne,Lst),e(P6,yst),e(Hr,xst),M(B6,Hr,null),b(c,ero,_),b(c,Sc,_),e(Sc,I6),e(I6,m9e),M(vR,m9e,null),e(Sc,$st),e(Sc,c9e),e(c9e,kst),b(c,oro,_),b(c,Fr,_),M(FR,Fr,null),e(Fr,Sst),e(Fr,Rc),e(Rc,Rst),e(Rc,vne),e(vne,Pst),e(Rc,Bst),e(Rc,Fne),e(Fne,Ist),e(Rc,Nst),e(Fr,qst),e(Fr,TR),e(TR,jst),e(TR,f9e),e(f9e,Dst),e(TR,Gst),e(Fr,Ost),e(Fr,aa),M(MR,aa,null),e(aa,Vst),e(aa,g9e),e(g9e,Xst),e(aa,zst),e(aa,Pc),e(Pc,Qst),e(Pc,h9e),e(h9e,Wst),e(Pc,Ust),e(Pc,Tne),e(Tne,Hst),e(Pc,Jst),e(aa,Yst),M(N6,aa,null),e(Fr,Kst),e(Fr,Jr),M(ER,Jr,null),e(Jr,Zst),e(Jr,u9e),e(u9e,elt),e(Jr,olt),e(Jr,jn),e(jn,rlt),e(jn,p9e),e(p9e,tlt),e(jn,alt),e(jn,_9e),e(_9e,nlt),e(jn,slt),e(jn,b9e),e(b9e,llt),e(jn,ilt),e(Jr,dlt),e(Jr,v9e),e(v9e,q6),e(q6,F9e),e(F9e,mlt),e(q6,clt),e(q6,Mne),e(Mne,flt),e(q6,glt),e(Jr,hlt),M(j6,Jr,null),b(c,rro,_),b(c,Bc,_),e(Bc,D6),e(D6,T9e),M(CR,T9e,null),e(Bc,ult),e(Bc,M9e),e(M9e,plt),b(c,tro,_),b(c,Tr,_),M(wR,Tr,null),e(Tr,_lt),e(Tr,Ic),e(Ic,blt),e(Ic,Ene),e(Ene,vlt),e(Ic,Flt),e(Ic,Cne),e(Cne,Tlt),e(Ic,Mlt),e(Tr,Elt),e(Tr,AR),e(AR,Clt),e(AR,E9e),e(E9e,wlt),e(AR,Alt),e(Tr,Llt),e(Tr,na),M(LR,na,null),e(na,ylt),e(na,C9e),e(C9e,xlt),e(na,$lt),e(na,Nc),e(Nc,klt),e(Nc,w9e),e(w9e,Slt),e(Nc,Rlt),e(Nc,wne),e(wne,Plt),e(Nc,Blt),e(na,Ilt),M(G6,na,null),e(Tr,Nlt),e(Tr,Yr),M(yR,Yr,null),e(Yr,qlt),e(Yr,A9e),e(A9e,jlt),e(Yr,Dlt),e(Yr,Dn),e(Dn,Glt),e(Dn,L9e),e(L9e,Olt),e(Dn,Vlt),e(Dn,y9e),e(y9e,Xlt),e(Dn,zlt),e(Dn,x9e),e(x9e,Qlt),e(Dn,Wlt),e(Yr,Ult),e(Yr,$9e),e($9e,O6),e(O6,k9e),e(k9e,Hlt),e(O6,Jlt),e(O6,Ane),e(Ane,Ylt),e(O6,Klt),e(Yr,Zlt),M(V6,Yr,null),b(c,aro,_),b(c,qc,_),e(qc,X6),e(X6,S9e),M(xR,S9e,null),e(qc,eit),e(qc,R9e),e(R9e,oit),b(c,nro,_),b(c,Mr,_),M($R,Mr,null),e(Mr,rit),e(Mr,jc),e(jc,tit),e(jc,Lne),e(Lne,ait),e(jc,nit),e(jc,yne),e(yne,sit),e(jc,lit),e(Mr,iit),e(Mr,kR),e(kR,dit),e(kR,P9e),e(P9e,mit),e(kR,cit),e(Mr,fit),e(Mr,sa),M(SR,sa,null),e(sa,git),e(sa,B9e),e(B9e,hit),e(sa,uit),e(sa,Dc),e(Dc,pit),e(Dc,I9e),e(I9e,_it),e(Dc,bit),e(Dc,xne),e(xne,vit),e(Dc,Fit),e(sa,Tit),M(z6,sa,null),e(Mr,Mit),e(Mr,Kr),M(RR,Kr,null),e(Kr,Eit),e(Kr,N9e),e(N9e,Cit),e(Kr,wit),e(Kr,Gn),e(Gn,Ait),e(Gn,q9e),e(q9e,Lit),e(Gn,yit),e(Gn,j9e),e(j9e,xit),e(Gn,$it),e(Gn,D9e),e(D9e,kit),e(Gn,Sit),e(Kr,Rit),e(Kr,te),e(te,Q6),e(Q6,G9e),e(G9e,Pit),e(Q6,Bit),e(Q6,$ne),e($ne,Iit),e(Q6,Nit),e(te,qit),e(te,W6),e(W6,O9e),e(O9e,jit),e(W6,Dit),e(W6,kne),e(kne,Git),e(W6,Oit),e(te,Vit),e(te,U6),e(U6,V9e),e(V9e,Xit),e(U6,zit),e(U6,Sne),e(Sne,Qit),e(U6,Wit),e(te,Uit),e(te,H6),e(H6,X9e),e(X9e,Hit),e(H6,Jit),e(H6,Rne),e(Rne,Yit),e(H6,Kit),e(te,Zit),e(te,J6),e(J6,z9e),e(z9e,edt),e(J6,odt),e(J6,Pne),e(Pne,rdt),e(J6,tdt),e(te,adt),e(te,Y6),e(Y6,Q9e),e(Q9e,ndt),e(Y6,sdt),e(Y6,Bne),e(Bne,ldt),e(Y6,idt),e(te,ddt),e(te,K6),e(K6,W9e),e(W9e,mdt),e(K6,cdt),e(K6,Ine),e(Ine,fdt),e(K6,gdt),e(te,hdt),e(te,Z6),e(Z6,U9e),e(U9e,udt),e(Z6,pdt),e(Z6,Nne),e(Nne,_dt),e(Z6,bdt),e(te,vdt),e(te,e7),e(e7,H9e),e(H9e,Fdt),e(e7,Tdt),e(e7,qne),e(qne,Mdt),e(e7,Edt),e(te,Cdt),e(te,o7),e(o7,J9e),e(J9e,wdt),e(o7,Adt),e(o7,jne),e(jne,Ldt),e(o7,ydt),e(te,xdt),e(te,r7),e(r7,Y9e),e(Y9e,$dt),e(r7,kdt),e(r7,Dne),e(Dne,Sdt),e(r7,Rdt),e(te,Pdt),e(te,t7),e(t7,K9e),e(K9e,Bdt),e(t7,Idt),e(t7,Gne),e(Gne,Ndt),e(t7,qdt),e(te,jdt),e(te,a7),e(a7,Z9e),e(Z9e,Ddt),e(a7,Gdt),e(a7,One),e(One,Odt),e(a7,Vdt),e(te,Xdt),e(te,n7),e(n7,exe),e(exe,zdt),e(n7,Qdt),e(n7,Vne),e(Vne,Wdt),e(n7,Udt),e(te,Hdt),e(te,s7),e(s7,oxe),e(oxe,Jdt),e(s7,Ydt),e(s7,Xne),e(Xne,Kdt),e(s7,Zdt),e(te,emt),e(te,l7),e(l7,rxe),e(rxe,omt),e(l7,rmt),e(l7,zne),e(zne,tmt),e(l7,amt),e(te,nmt),e(te,i7),e(i7,txe),e(txe,smt),e(i7,lmt),e(i7,Qne),e(Qne,imt),e(i7,dmt),e(te,mmt),e(te,d7),e(d7,axe),e(axe,cmt),e(d7,fmt),e(d7,Wne),e(Wne,gmt),e(d7,hmt),e(te,umt),e(te,m7),e(m7,nxe),e(nxe,pmt),e(m7,_mt),e(m7,Une),e(Une,bmt),e(m7,vmt),e(te,Fmt),e(te,c7),e(c7,sxe),e(sxe,Tmt),e(c7,Mmt),e(c7,Hne),e(Hne,Emt),e(c7,Cmt),e(te,wmt),e(te,f7),e(f7,lxe),e(lxe,Amt),e(f7,Lmt),e(f7,Jne),e(Jne,ymt),e(f7,xmt),e(te,$mt),e(te,g7),e(g7,ixe),e(ixe,kmt),e(g7,Smt),e(g7,Yne),e(Yne,Rmt),e(g7,Pmt),e(te,Bmt),e(te,h7),e(h7,dxe),e(dxe,Imt),e(h7,Nmt),e(h7,Kne),e(Kne,qmt),e(h7,jmt),e(te,Dmt),e(te,u7),e(u7,mxe),e(mxe,Gmt),e(u7,Omt),e(u7,Zne),e(Zne,Vmt),e(u7,Xmt),e(te,zmt),e(te,p7),e(p7,cxe),e(cxe,Qmt),e(p7,Wmt),e(p7,ese),e(ese,Umt),e(p7,Hmt),e(te,Jmt),e(te,_7),e(_7,fxe),e(fxe,Ymt),e(_7,Kmt),e(_7,ose),e(ose,Zmt),e(_7,ect),e(te,oct),e(te,b7),e(b7,gxe),e(gxe,rct),e(b7,tct),e(b7,rse),e(rse,act),e(b7,nct),e(Kr,sct),M(v7,Kr,null),b(c,sro,_),b(c,Gc,_),e(Gc,F7),e(F7,hxe),M(PR,hxe,null),e(Gc,lct),e(Gc,uxe),e(uxe,ict),b(c,lro,_),b(c,Er,_),M(BR,Er,null),e(Er,dct),e(Er,Oc),e(Oc,mct),e(Oc,tse),e(tse,cct),e(Oc,fct),e(Oc,ase),e(ase,gct),e(Oc,hct),e(Er,uct),e(Er,IR),e(IR,pct),e(IR,pxe),e(pxe,_ct),e(IR,bct),e(Er,vct),e(Er,la),M(NR,la,null),e(la,Fct),e(la,_xe),e(_xe,Tct),e(la,Mct),e(la,Vc),e(Vc,Ect),e(Vc,bxe),e(bxe,Cct),e(Vc,wct),e(Vc,nse),e(nse,Act),e(Vc,Lct),e(la,yct),M(T7,la,null),e(Er,xct),e(Er,Zr),M(qR,Zr,null),e(Zr,$ct),e(Zr,vxe),e(vxe,kct),e(Zr,Sct),e(Zr,On),e(On,Rct),e(On,Fxe),e(Fxe,Pct),e(On,Bct),e(On,Txe),e(Txe,Ict),e(On,Nct),e(On,Mxe),e(Mxe,qct),e(On,jct),e(Zr,Dct),e(Zr,xe),e(xe,M7),e(M7,Exe),e(Exe,Gct),e(M7,Oct),e(M7,sse),e(sse,Vct),e(M7,Xct),e(xe,zct),e(xe,E7),e(E7,Cxe),e(Cxe,Qct),e(E7,Wct),e(E7,lse),e(lse,Uct),e(E7,Hct),e(xe,Jct),e(xe,C7),e(C7,wxe),e(wxe,Yct),e(C7,Kct),e(C7,ise),e(ise,Zct),e(C7,eft),e(xe,oft),e(xe,w7),e(w7,Axe),e(Axe,rft),e(w7,tft),e(w7,dse),e(dse,aft),e(w7,nft),e(xe,sft),e(xe,A7),e(A7,Lxe),e(Lxe,lft),e(A7,ift),e(A7,mse),e(mse,dft),e(A7,mft),e(xe,cft),e(xe,L7),e(L7,yxe),e(yxe,fft),e(L7,gft),e(L7,cse),e(cse,hft),e(L7,uft),e(xe,pft),e(xe,y7),e(y7,xxe),e(xxe,_ft),e(y7,bft),e(y7,fse),e(fse,vft),e(y7,Fft),e(xe,Tft),e(xe,x7),e(x7,$xe),e($xe,Mft),e(x7,Eft),e(x7,gse),e(gse,Cft),e(x7,wft),e(xe,Aft),e(xe,$7),e($7,kxe),e(kxe,Lft),e($7,yft),e($7,hse),e(hse,xft),e($7,$ft),e(xe,kft),e(xe,k7),e(k7,Sxe),e(Sxe,Sft),e(k7,Rft),e(k7,use),e(use,Pft),e(k7,Bft),e(Zr,Ift),M(S7,Zr,null),b(c,iro,_),b(c,Xc,_),e(Xc,R7),e(R7,Rxe),M(jR,Rxe,null),e(Xc,Nft),e(Xc,Pxe),e(Pxe,qft),b(c,dro,_),b(c,Cr,_),M(DR,Cr,null),e(Cr,jft),e(Cr,zc),e(zc,Dft),e(zc,pse),e(pse,Gft),e(zc,Oft),e(zc,_se),e(_se,Vft),e(zc,Xft),e(Cr,zft),e(Cr,GR),e(GR,Qft),e(GR,Bxe),e(Bxe,Wft),e(GR,Uft),e(Cr,Hft),e(Cr,ia),M(OR,ia,null),e(ia,Jft),e(ia,Ixe),e(Ixe,Yft),e(ia,Kft),e(ia,Qc),e(Qc,Zft),e(Qc,Nxe),e(Nxe,egt),e(Qc,ogt),e(Qc,bse),e(bse,rgt),e(Qc,tgt),e(ia,agt),M(P7,ia,null),e(Cr,ngt),e(Cr,et),M(VR,et,null),e(et,sgt),e(et,qxe),e(qxe,lgt),e(et,igt),e(et,Vn),e(Vn,dgt),e(Vn,jxe),e(jxe,mgt),e(Vn,cgt),e(Vn,Dxe),e(Dxe,fgt),e(Vn,ggt),e(Vn,Gxe),e(Gxe,hgt),e(Vn,ugt),e(et,pgt),e(et,Ee),e(Ee,B7),e(B7,Oxe),e(Oxe,_gt),e(B7,bgt),e(B7,vse),e(vse,vgt),e(B7,Fgt),e(Ee,Tgt),e(Ee,I7),e(I7,Vxe),e(Vxe,Mgt),e(I7,Egt),e(I7,Fse),e(Fse,Cgt),e(I7,wgt),e(Ee,Agt),e(Ee,N7),e(N7,Xxe),e(Xxe,Lgt),e(N7,ygt),e(N7,Tse),e(Tse,xgt),e(N7,$gt),e(Ee,kgt),e(Ee,q7),e(q7,zxe),e(zxe,Sgt),e(q7,Rgt),e(q7,Mse),e(Mse,Pgt),e(q7,Bgt),e(Ee,Igt),e(Ee,j7),e(j7,Qxe),e(Qxe,Ngt),e(j7,qgt),e(j7,Ese),e(Ese,jgt),e(j7,Dgt),e(Ee,Ggt),e(Ee,D7),e(D7,Wxe),e(Wxe,Ogt),e(D7,Vgt),e(D7,Cse),e(Cse,Xgt),e(D7,zgt),e(Ee,Qgt),e(Ee,G7),e(G7,Uxe),e(Uxe,Wgt),e(G7,Ugt),e(G7,wse),e(wse,Hgt),e(G7,Jgt),e(Ee,Ygt),e(Ee,O7),e(O7,Hxe),e(Hxe,Kgt),e(O7,Zgt),e(O7,Ase),e(Ase,eht),e(O7,oht),e(Ee,rht),e(Ee,V7),e(V7,Jxe),e(Jxe,tht),e(V7,aht),e(V7,Lse),e(Lse,nht),e(V7,sht),e(Ee,lht),e(Ee,X7),e(X7,Yxe),e(Yxe,iht),e(X7,dht),e(X7,yse),e(yse,mht),e(X7,cht),e(Ee,fht),e(Ee,z7),e(z7,Kxe),e(Kxe,ght),e(z7,hht),e(z7,xse),e(xse,uht),e(z7,pht),e(Ee,_ht),e(Ee,Q7),e(Q7,Zxe),e(Zxe,bht),e(Q7,vht),e(Q7,$se),e($se,Fht),e(Q7,Tht),e(Ee,Mht),e(Ee,W7),e(W7,e$e),e(e$e,Eht),e(W7,Cht),e(W7,kse),e(kse,wht),e(W7,Aht),e(et,Lht),M(U7,et,null),b(c,mro,_),b(c,Wc,_),e(Wc,H7),e(H7,o$e),M(XR,o$e,null),e(Wc,yht),e(Wc,r$e),e(r$e,xht),b(c,cro,_),b(c,wr,_),M(zR,wr,null),e(wr,$ht),e(wr,Uc),e(Uc,kht),e(Uc,Sse),e(Sse,Sht),e(Uc,Rht),e(Uc,Rse),e(Rse,Pht),e(Uc,Bht),e(wr,Iht),e(wr,QR),e(QR,Nht),e(QR,t$e),e(t$e,qht),e(QR,jht),e(wr,Dht),e(wr,da),M(WR,da,null),e(da,Ght),e(da,a$e),e(a$e,Oht),e(da,Vht),e(da,Hc),e(Hc,Xht),e(Hc,n$e),e(n$e,zht),e(Hc,Qht),e(Hc,Pse),e(Pse,Wht),e(Hc,Uht),e(da,Hht),M(J7,da,null),e(wr,Jht),e(wr,ot),M(UR,ot,null),e(ot,Yht),e(ot,s$e),e(s$e,Kht),e(ot,Zht),e(ot,Xn),e(Xn,eut),e(Xn,l$e),e(l$e,out),e(Xn,rut),e(Xn,i$e),e(i$e,tut),e(Xn,aut),e(Xn,d$e),e(d$e,nut),e(Xn,sut),e(ot,lut),e(ot,$e),e($e,Y7),e(Y7,m$e),e(m$e,iut),e(Y7,dut),e(Y7,Bse),e(Bse,mut),e(Y7,cut),e($e,fut),e($e,K7),e(K7,c$e),e(c$e,gut),e(K7,hut),e(K7,Ise),e(Ise,uut),e(K7,put),e($e,_ut),e($e,Z7),e(Z7,f$e),e(f$e,but),e(Z7,vut),e(Z7,Nse),e(Nse,Fut),e(Z7,Tut),e($e,Mut),e($e,eL),e(eL,g$e),e(g$e,Eut),e(eL,Cut),e(eL,qse),e(qse,wut),e(eL,Aut),e($e,Lut),e($e,oL),e(oL,h$e),e(h$e,yut),e(oL,xut),e(oL,jse),e(jse,$ut),e(oL,kut),e($e,Sut),e($e,rL),e(rL,u$e),e(u$e,Rut),e(rL,Put),e(rL,Dse),e(Dse,But),e(rL,Iut),e($e,Nut),e($e,tL),e(tL,p$e),e(p$e,qut),e(tL,jut),e(tL,Gse),e(Gse,Dut),e(tL,Gut),e($e,Out),e($e,aL),e(aL,_$e),e(_$e,Vut),e(aL,Xut),e(aL,Ose),e(Ose,zut),e(aL,Qut),e($e,Wut),e($e,nL),e(nL,b$e),e(b$e,Uut),e(nL,Hut),e(nL,Vse),e(Vse,Jut),e(nL,Yut),e($e,Kut),e($e,sL),e(sL,v$e),e(v$e,Zut),e(sL,ept),e(sL,Xse),e(Xse,opt),e(sL,rpt),e(ot,tpt),M(lL,ot,null),b(c,fro,_),b(c,Jc,_),e(Jc,iL),e(iL,F$e),M(HR,F$e,null),e(Jc,apt),e(Jc,T$e),e(T$e,npt),b(c,gro,_),b(c,Ar,_),M(JR,Ar,null),e(Ar,spt),e(Ar,Yc),e(Yc,lpt),e(Yc,zse),e(zse,ipt),e(Yc,dpt),e(Yc,Qse),e(Qse,mpt),e(Yc,cpt),e(Ar,fpt),e(Ar,YR),e(YR,gpt),e(YR,M$e),e(M$e,hpt),e(YR,upt),e(Ar,ppt),e(Ar,ma),M(KR,ma,null),e(ma,_pt),e(ma,E$e),e(E$e,bpt),e(ma,vpt),e(ma,Kc),e(Kc,Fpt),e(Kc,C$e),e(C$e,Tpt),e(Kc,Mpt),e(Kc,Wse),e(Wse,Ept),e(Kc,Cpt),e(ma,wpt),M(dL,ma,null),e(Ar,Apt),e(Ar,rt),M(ZR,rt,null),e(rt,Lpt),e(rt,w$e),e(w$e,ypt),e(rt,xpt),e(rt,zn),e(zn,$pt),e(zn,A$e),e(A$e,kpt),e(zn,Spt),e(zn,L$e),e(L$e,Rpt),e(zn,Ppt),e(zn,y$e),e(y$e,Bpt),e(zn,Ipt),e(rt,Npt),e(rt,ke),e(ke,mL),e(mL,x$e),e(x$e,qpt),e(mL,jpt),e(mL,Use),e(Use,Dpt),e(mL,Gpt),e(ke,Opt),e(ke,cL),e(cL,$$e),e($$e,Vpt),e(cL,Xpt),e(cL,Hse),e(Hse,zpt),e(cL,Qpt),e(ke,Wpt),e(ke,fL),e(fL,k$e),e(k$e,Upt),e(fL,Hpt),e(fL,Jse),e(Jse,Jpt),e(fL,Ypt),e(ke,Kpt),e(ke,gL),e(gL,S$e),e(S$e,Zpt),e(gL,e_t),e(gL,Yse),e(Yse,o_t),e(gL,r_t),e(ke,t_t),e(ke,hL),e(hL,R$e),e(R$e,a_t),e(hL,n_t),e(hL,Kse),e(Kse,s_t),e(hL,l_t),e(ke,i_t),e(ke,uL),e(uL,P$e),e(P$e,d_t),e(uL,m_t),e(uL,Zse),e(Zse,c_t),e(uL,f_t),e(ke,g_t),e(ke,pL),e(pL,B$e),e(B$e,h_t),e(pL,u_t),e(pL,ele),e(ele,p_t),e(pL,__t),e(ke,b_t),e(ke,_L),e(_L,I$e),e(I$e,v_t),e(_L,F_t),e(_L,ole),e(ole,T_t),e(_L,M_t),e(ke,E_t),e(ke,bL),e(bL,N$e),e(N$e,C_t),e(bL,w_t),e(bL,rle),e(rle,A_t),e(bL,L_t),e(ke,y_t),e(ke,vL),e(vL,q$e),e(q$e,x_t),e(vL,$_t),e(vL,tle),e(tle,k_t),e(vL,S_t),e(rt,R_t),M(FL,rt,null),b(c,hro,_),b(c,Zc,_),e(Zc,TL),e(TL,j$e),M(eP,j$e,null),e(Zc,P_t),e(Zc,D$e),e(D$e,B_t),b(c,uro,_),b(c,Lr,_),M(oP,Lr,null),e(Lr,I_t),e(Lr,ef),e(ef,N_t),e(ef,ale),e(ale,q_t),e(ef,j_t),e(ef,nle),e(nle,D_t),e(ef,G_t),e(Lr,O_t),e(Lr,rP),e(rP,V_t),e(rP,G$e),e(G$e,X_t),e(rP,z_t),e(Lr,Q_t),e(Lr,ca),M(tP,ca,null),e(ca,W_t),e(ca,O$e),e(O$e,U_t),e(ca,H_t),e(ca,of),e(of,J_t),e(of,V$e),e(V$e,Y_t),e(of,K_t),e(of,sle),e(sle,Z_t),e(of,e1t),e(ca,o1t),M(ML,ca,null),e(Lr,r1t),e(Lr,tt),M(aP,tt,null),e(tt,t1t),e(tt,X$e),e(X$e,a1t),e(tt,n1t),e(tt,Qn),e(Qn,s1t),e(Qn,z$e),e(z$e,l1t),e(Qn,i1t),e(Qn,Q$e),e(Q$e,d1t),e(Qn,m1t),e(Qn,W$e),e(W$e,c1t),e(Qn,f1t),e(tt,g1t),e(tt,Se),e(Se,EL),e(EL,U$e),e(U$e,h1t),e(EL,u1t),e(EL,lle),e(lle,p1t),e(EL,_1t),e(Se,b1t),e(Se,CL),e(CL,H$e),e(H$e,v1t),e(CL,F1t),e(CL,ile),e(ile,T1t),e(CL,M1t),e(Se,E1t),e(Se,wL),e(wL,J$e),e(J$e,C1t),e(wL,w1t),e(wL,dle),e(dle,A1t),e(wL,L1t),e(Se,y1t),e(Se,AL),e(AL,Y$e),e(Y$e,x1t),e(AL,$1t),e(AL,mle),e(mle,k1t),e(AL,S1t),e(Se,R1t),e(Se,LL),e(LL,K$e),e(K$e,P1t),e(LL,B1t),e(LL,cle),e(cle,I1t),e(LL,N1t),e(Se,q1t),e(Se,yL),e(yL,Z$e),e(Z$e,j1t),e(yL,D1t),e(yL,fle),e(fle,G1t),e(yL,O1t),e(Se,V1t),e(Se,xL),e(xL,eke),e(eke,X1t),e(xL,z1t),e(xL,gle),e(gle,Q1t),e(xL,W1t),e(Se,U1t),e(Se,$L),e($L,oke),e(oke,H1t),e($L,J1t),e($L,hle),e(hle,Y1t),e($L,K1t),e(Se,Z1t),e(Se,kL),e(kL,rke),e(rke,e2t),e(kL,o2t),e(kL,ule),e(ule,r2t),e(kL,t2t),e(Se,a2t),e(Se,SL),e(SL,tke),e(tke,n2t),e(SL,s2t),e(SL,ple),e(ple,l2t),e(SL,i2t),e(tt,d2t),M(RL,tt,null),b(c,pro,_),b(c,rf,_),e(rf,PL),e(PL,ake),M(nP,ake,null),e(rf,m2t),e(rf,nke),e(nke,c2t),b(c,_ro,_),b(c,yr,_),M(sP,yr,null),e(yr,f2t),e(yr,tf),e(tf,g2t),e(tf,_le),e(_le,h2t),e(tf,u2t),e(tf,ble),e(ble,p2t),e(tf,_2t),e(yr,b2t),e(yr,lP),e(lP,v2t),e(lP,ske),e(ske,F2t),e(lP,T2t),e(yr,M2t),e(yr,fa),M(iP,fa,null),e(fa,E2t),e(fa,lke),e(lke,C2t),e(fa,w2t),e(fa,af),e(af,A2t),e(af,ike),e(ike,L2t),e(af,y2t),e(af,vle),e(vle,x2t),e(af,$2t),e(fa,k2t),M(BL,fa,null),e(yr,S2t),e(yr,at),M(dP,at,null),e(at,R2t),e(at,dke),e(dke,P2t),e(at,B2t),e(at,Wn),e(Wn,I2t),e(Wn,mke),e(mke,N2t),e(Wn,q2t),e(Wn,cke),e(cke,j2t),e(Wn,D2t),e(Wn,fke),e(fke,G2t),e(Wn,O2t),e(at,V2t),e(at,Re),e(Re,IL),e(IL,gke),e(gke,X2t),e(IL,z2t),e(IL,Fle),e(Fle,Q2t),e(IL,W2t),e(Re,U2t),e(Re,NL),e(NL,hke),e(hke,H2t),e(NL,J2t),e(NL,Tle),e(Tle,Y2t),e(NL,K2t),e(Re,Z2t),e(Re,qL),e(qL,uke),e(uke,ebt),e(qL,obt),e(qL,Mle),e(Mle,rbt),e(qL,tbt),e(Re,abt),e(Re,jL),e(jL,pke),e(pke,nbt),e(jL,sbt),e(jL,Ele),e(Ele,lbt),e(jL,ibt),e(Re,dbt),e(Re,DL),e(DL,_ke),e(_ke,mbt),e(DL,cbt),e(DL,Cle),e(Cle,fbt),e(DL,gbt),e(Re,hbt),e(Re,GL),e(GL,bke),e(bke,ubt),e(GL,pbt),e(GL,wle),e(wle,_bt),e(GL,bbt),e(Re,vbt),e(Re,OL),e(OL,vke),e(vke,Fbt),e(OL,Tbt),e(OL,Ale),e(Ale,Mbt),e(OL,Ebt),e(Re,Cbt),e(Re,VL),e(VL,Fke),e(Fke,wbt),e(VL,Abt),e(VL,Lle),e(Lle,Lbt),e(VL,ybt),e(Re,xbt),e(Re,XL),e(XL,Tke),e(Tke,$bt),e(XL,kbt),e(XL,yle),e(yle,Sbt),e(XL,Rbt),e(Re,Pbt),e(Re,zL),e(zL,Mke),e(Mke,Bbt),e(zL,Ibt),e(zL,xle),e(xle,Nbt),e(zL,qbt),e(at,jbt),M(QL,at,null),b(c,bro,_),b(c,nf,_),e(nf,WL),e(WL,Eke),M(mP,Eke,null),e(nf,Dbt),e(nf,Cke),e(Cke,Gbt),b(c,vro,_),b(c,xr,_),M(cP,xr,null),e(xr,Obt),e(xr,sf),e(sf,Vbt),e(sf,$le),e($le,Xbt),e(sf,zbt),e(sf,kle),e(kle,Qbt),e(sf,Wbt),e(xr,Ubt),e(xr,fP),e(fP,Hbt),e(fP,wke),e(wke,Jbt),e(fP,Ybt),e(xr,Kbt),e(xr,ga),M(gP,ga,null),e(ga,Zbt),e(ga,Ake),e(Ake,evt),e(ga,ovt),e(ga,lf),e(lf,rvt),e(lf,Lke),e(Lke,tvt),e(lf,avt),e(lf,Sle),e(Sle,nvt),e(lf,svt),e(ga,lvt),M(UL,ga,null),e(xr,ivt),e(xr,nt),M(hP,nt,null),e(nt,dvt),e(nt,yke),e(yke,mvt),e(nt,cvt),e(nt,Un),e(Un,fvt),e(Un,xke),e(xke,gvt),e(Un,hvt),e(Un,$ke),e($ke,uvt),e(Un,pvt),e(Un,kke),e(kke,_vt),e(Un,bvt),e(nt,vvt),e(nt,Xe),e(Xe,HL),e(HL,Ske),e(Ske,Fvt),e(HL,Tvt),e(HL,Rle),e(Rle,Mvt),e(HL,Evt),e(Xe,Cvt),e(Xe,JL),e(JL,Rke),e(Rke,wvt),e(JL,Avt),e(JL,Ple),e(Ple,Lvt),e(JL,yvt),e(Xe,xvt),e(Xe,YL),e(YL,Pke),e(Pke,$vt),e(YL,kvt),e(YL,Ble),e(Ble,Svt),e(YL,Rvt),e(Xe,Pvt),e(Xe,KL),e(KL,Bke),e(Bke,Bvt),e(KL,Ivt),e(KL,Ile),e(Ile,Nvt),e(KL,qvt),e(Xe,jvt),e(Xe,ZL),e(ZL,Ike),e(Ike,Dvt),e(ZL,Gvt),e(ZL,Nle),e(Nle,Ovt),e(ZL,Vvt),e(Xe,Xvt),e(Xe,ey),e(ey,Nke),e(Nke,zvt),e(ey,Qvt),e(ey,qle),e(qle,Wvt),e(ey,Uvt),e(Xe,Hvt),e(Xe,oy),e(oy,qke),e(qke,Jvt),e(oy,Yvt),e(oy,jle),e(jle,Kvt),e(oy,Zvt),e(Xe,eFt),e(Xe,ry),e(ry,jke),e(jke,oFt),e(ry,rFt),e(ry,Dle),e(Dle,tFt),e(ry,aFt),e(nt,nFt),M(ty,nt,null),b(c,Fro,_),b(c,df,_),e(df,ay),e(ay,Dke),M(uP,Dke,null),e(df,sFt),e(df,Gke),e(Gke,lFt),b(c,Tro,_),b(c,$r,_),M(pP,$r,null),e($r,iFt),e($r,mf),e(mf,dFt),e(mf,Gle),e(Gle,mFt),e(mf,cFt),e(mf,Ole),e(Ole,fFt),e(mf,gFt),e($r,hFt),e($r,_P),e(_P,uFt),e(_P,Oke),e(Oke,pFt),e(_P,_Ft),e($r,bFt),e($r,ha),M(bP,ha,null),e(ha,vFt),e(ha,Vke),e(Vke,FFt),e(ha,TFt),e(ha,cf),e(cf,MFt),e(cf,Xke),e(Xke,EFt),e(cf,CFt),e(cf,Vle),e(Vle,wFt),e(cf,AFt),e(ha,LFt),M(ny,ha,null),e($r,yFt),e($r,st),M(vP,st,null),e(st,xFt),e(st,zke),e(zke,$Ft),e(st,kFt),e(st,Hn),e(Hn,SFt),e(Hn,Qke),e(Qke,RFt),e(Hn,PFt),e(Hn,Wke),e(Wke,BFt),e(Hn,IFt),e(Hn,Uke),e(Uke,NFt),e(Hn,qFt),e(st,jFt),e(st,ze),e(ze,sy),e(sy,Hke),e(Hke,DFt),e(sy,GFt),e(sy,Xle),e(Xle,OFt),e(sy,VFt),e(ze,XFt),e(ze,ly),e(ly,Jke),e(Jke,zFt),e(ly,QFt),e(ly,zle),e(zle,WFt),e(ly,UFt),e(ze,HFt),e(ze,iy),e(iy,Yke),e(Yke,JFt),e(iy,YFt),e(iy,Qle),e(Qle,KFt),e(iy,ZFt),e(ze,eTt),e(ze,dy),e(dy,Kke),e(Kke,oTt),e(dy,rTt),e(dy,Wle),e(Wle,tTt),e(dy,aTt),e(ze,nTt),e(ze,my),e(my,Zke),e(Zke,sTt),e(my,lTt),e(my,Ule),e(Ule,iTt),e(my,dTt),e(ze,mTt),e(ze,cy),e(cy,eSe),e(eSe,cTt),e(cy,fTt),e(cy,Hle),e(Hle,gTt),e(cy,hTt),e(ze,uTt),e(ze,fy),e(fy,oSe),e(oSe,pTt),e(fy,_Tt),e(fy,Jle),e(Jle,bTt),e(fy,vTt),e(ze,FTt),e(ze,gy),e(gy,rSe),e(rSe,TTt),e(gy,MTt),e(gy,Yle),e(Yle,ETt),e(gy,CTt),e(st,wTt),M(hy,st,null),b(c,Mro,_),b(c,ff,_),e(ff,uy),e(uy,tSe),M(FP,tSe,null),e(ff,ATt),e(ff,aSe),e(aSe,LTt),b(c,Ero,_),b(c,kr,_),M(TP,kr,null),e(kr,yTt),e(kr,gf),e(gf,xTt),e(gf,Kle),e(Kle,$Tt),e(gf,kTt),e(gf,Zle),e(Zle,STt),e(gf,RTt),e(kr,PTt),e(kr,MP),e(MP,BTt),e(MP,nSe),e(nSe,ITt),e(MP,NTt),e(kr,qTt),e(kr,ua),M(EP,ua,null),e(ua,jTt),e(ua,sSe),e(sSe,DTt),e(ua,GTt),e(ua,hf),e(hf,OTt),e(hf,lSe),e(lSe,VTt),e(hf,XTt),e(hf,eie),e(eie,zTt),e(hf,QTt),e(ua,WTt),M(py,ua,null),e(kr,UTt),e(kr,lt),M(CP,lt,null),e(lt,HTt),e(lt,iSe),e(iSe,JTt),e(lt,YTt),e(lt,Jn),e(Jn,KTt),e(Jn,dSe),e(dSe,ZTt),e(Jn,eMt),e(Jn,mSe),e(mSe,oMt),e(Jn,rMt),e(Jn,cSe),e(cSe,tMt),e(Jn,aMt),e(lt,nMt),e(lt,fSe),e(fSe,_y),e(_y,gSe),e(gSe,sMt),e(_y,lMt),e(_y,oie),e(oie,iMt),e(_y,dMt),e(lt,mMt),M(by,lt,null),b(c,Cro,_),b(c,uf,_),e(uf,vy),e(vy,hSe),M(wP,hSe,null),e(uf,cMt),e(uf,uSe),e(uSe,fMt),b(c,wro,_),b(c,Sr,_),M(AP,Sr,null),e(Sr,gMt),e(Sr,pf),e(pf,hMt),e(pf,rie),e(rie,uMt),e(pf,pMt),e(pf,tie),e(tie,_Mt),e(pf,bMt),e(Sr,vMt),e(Sr,LP),e(LP,FMt),e(LP,pSe),e(pSe,TMt),e(LP,MMt),e(Sr,EMt),e(Sr,pa),M(yP,pa,null),e(pa,CMt),e(pa,_Se),e(_Se,wMt),e(pa,AMt),e(pa,_f),e(_f,LMt),e(_f,bSe),e(bSe,yMt),e(_f,xMt),e(_f,aie),e(aie,$Mt),e(_f,kMt),e(pa,SMt),M(Fy,pa,null),e(Sr,RMt),e(Sr,it),M(xP,it,null),e(it,PMt),e(it,vSe),e(vSe,BMt),e(it,IMt),e(it,Yn),e(Yn,NMt),e(Yn,FSe),e(FSe,qMt),e(Yn,jMt),e(Yn,TSe),e(TSe,DMt),e(Yn,GMt),e(Yn,MSe),e(MSe,OMt),e(Yn,VMt),e(it,XMt),e(it,$P),e($P,Ty),e(Ty,ESe),e(ESe,zMt),e(Ty,QMt),e(Ty,nie),e(nie,WMt),e(Ty,UMt),e($P,HMt),e($P,My),e(My,CSe),e(CSe,JMt),e(My,YMt),e(My,sie),e(sie,KMt),e(My,ZMt),e(it,eEt),M(Ey,it,null),b(c,Aro,_),b(c,bf,_),e(bf,Cy),e(Cy,wSe),M(kP,wSe,null),e(bf,oEt),e(bf,ASe),e(ASe,rEt),b(c,Lro,_),b(c,Rr,_),M(SP,Rr,null),e(Rr,tEt),e(Rr,vf),e(vf,aEt),e(vf,lie),e(lie,nEt),e(vf,sEt),e(vf,iie),e(iie,lEt),e(vf,iEt),e(Rr,dEt),e(Rr,RP),e(RP,mEt),e(RP,LSe),e(LSe,cEt),e(RP,fEt),e(Rr,gEt),e(Rr,_a),M(PP,_a,null),e(_a,hEt),e(_a,ySe),e(ySe,uEt),e(_a,pEt),e(_a,Ff),e(Ff,_Et),e(Ff,xSe),e(xSe,bEt),e(Ff,vEt),e(Ff,die),e(die,FEt),e(Ff,TEt),e(_a,MEt),M(wy,_a,null),e(Rr,EEt),e(Rr,dt),M(BP,dt,null),e(dt,CEt),e(dt,$Se),e($Se,wEt),e(dt,AEt),e(dt,Kn),e(Kn,LEt),e(Kn,kSe),e(kSe,yEt),e(Kn,xEt),e(Kn,SSe),e(SSe,$Et),e(Kn,kEt),e(Kn,RSe),e(RSe,SEt),e(Kn,REt),e(dt,PEt),e(dt,PSe),e(PSe,Ay),e(Ay,BSe),e(BSe,BEt),e(Ay,IEt),e(Ay,mie),e(mie,NEt),e(Ay,qEt),e(dt,jEt),M(Ly,dt,null),yro=!0},p(c,[_]){const IP={};_&2&&(IP.$$scope={dirty:_,ctx:c}),xf.$set(IP);const ISe={};_&2&&(ISe.$$scope={dirty:_,ctx:c}),ru.$set(ISe);const NSe={};_&2&&(NSe.$$scope={dirty:_,ctx:c}),Du.$set(NSe);const qSe={};_&2&&(qSe.$$scope={dirty:_,ctx:c}),Sp.$set(qSe);const NP={};_&2&&(NP.$$scope={dirty:_,ctx:c}),Rp.$set(NP);const jSe={};_&2&&(jSe.$$scope={dirty:_,ctx:c}),n_.$set(jSe);const Zn={};_&2&&(Zn.$$scope={dirty:_,ctx:c}),s_.$set(Zn);const DSe={};_&2&&(DSe.$$scope={dirty:_,ctx:c}),d_.$set(DSe);const GSe={};_&2&&(GSe.$$scope={dirty:_,ctx:c}),x2.$set(GSe);const OSe={};_&2&&(OSe.$$scope={dirty:_,ctx:c}),k2.$set(OSe);const qP={};_&2&&(qP.$$scope={dirty:_,ctx:c}),Lb.$set(qP);const VSe={};_&2&&(VSe.$$scope={dirty:_,ctx:c}),xb.$set(VSe);const jP={};_&2&&(jP.$$scope={dirty:_,ctx:c}),vv.$set(jP);const XSe={};_&2&&(XSe.$$scope={dirty:_,ctx:c}),Tv.$set(XSe);const DP={};_&2&&(DP.$$scope={dirty:_,ctx:c}),iF.$set(DP);const zSe={};_&2&&(zSe.$$scope={dirty:_,ctx:c}),mF.$set(zSe);const QSe={};_&2&&(QSe.$$scope={dirty:_,ctx:c}),SF.$set(QSe);const WSe={};_&2&&(WSe.$$scope={dirty:_,ctx:c}),PF.$set(WSe);const Tf={};_&2&&(Tf.$$scope={dirty:_,ctx:c}),NT.$set(Tf);const USe={};_&2&&(USe.$$scope={dirty:_,ctx:c}),jT.$set(USe);const HSe={};_&2&&(HSe.$$scope={dirty:_,ctx:c}),vM.$set(HSe);const JSe={};_&2&&(JSe.$$scope={dirty:_,ctx:c}),TM.$set(JSe);const GP={};_&2&&(GP.$$scope={dirty:_,ctx:c}),$M.$set(GP);const YSe={};_&2&&(YSe.$$scope={dirty:_,ctx:c}),SM.$set(YSe);const KSe={};_&2&&(KSe.$$scope={dirty:_,ctx:c}),FE.$set(KSe);const ZSe={};_&2&&(ZSe.$$scope={dirty:_,ctx:c}),ME.$set(ZSe);const ht={};_&2&&(ht.$$scope={dirty:_,ctx:c}),p4.$set(ht);const OP={};_&2&&(OP.$$scope={dirty:_,ctx:c}),b4.$set(OP);const eRe={};_&2&&(eRe.$$scope={dirty:_,ctx:c}),T4.$set(eRe);const VP={};_&2&&(VP.$$scope={dirty:_,ctx:c}),E4.$set(VP);const oRe={};_&2&&(oRe.$$scope={dirty:_,ctx:c}),y4.$set(oRe);const ut={};_&2&&(ut.$$scope={dirty:_,ctx:c}),$4.$set(ut);const rRe={};_&2&&(rRe.$$scope={dirty:_,ctx:c}),W4.$set(rRe);const Mf={};_&2&&(Mf.$$scope={dirty:_,ctx:c}),H4.$set(Mf);const tRe={};_&2&&(tRe.$$scope={dirty:_,ctx:c}),K4.$set(tRe);const aRe={};_&2&&(aRe.$$scope={dirty:_,ctx:c}),eC.$set(aRe);const L={};_&2&&(L.$$scope={dirty:_,ctx:c}),tC.$set(L);const yy={};_&2&&(yy.$$scope={dirty:_,ctx:c}),nC.$set(yy);const nRe={};_&2&&(nRe.$$scope={dirty:_,ctx:c}),iC.$set(nRe);const sRe={};_&2&&(sRe.$$scope={dirty:_,ctx:c}),mC.$set(sRe);const xy={};_&2&&(xy.$$scope={dirty:_,ctx:c}),TC.$set(xy);const lRe={};_&2&&(lRe.$$scope={dirty:_,ctx:c}),EC.$set(lRe);const iRe={};_&2&&(iRe.$$scope={dirty:_,ctx:c}),$C.$set(iRe);const $y={};_&2&&($y.$$scope={dirty:_,ctx:c}),SC.$set($y);const dRe={};_&2&&(dRe.$$scope={dirty:_,ctx:c}),XC.$set(dRe);const mRe={};_&2&&(mRe.$$scope={dirty:_,ctx:c}),QC.$set(mRe);const ky={};_&2&&(ky.$$scope={dirty:_,ctx:c}),YC.$set(ky);const cRe={};_&2&&(cRe.$$scope={dirty:_,ctx:c}),ZC.$set(cRe);const fRe={};_&2&&(fRe.$$scope={dirty:_,ctx:c}),s3.$set(fRe);const Sy={};_&2&&(Sy.$$scope={dirty:_,ctx:c}),i3.$set(Sy);const gRe={};_&2&&(gRe.$$scope={dirty:_,ctx:c}),h3.$set(gRe);const hRe={};_&2&&(hRe.$$scope={dirty:_,ctx:c}),p3.$set(hRe);const Ry={};_&2&&(Ry.$$scope={dirty:_,ctx:c}),M3.$set(Ry);const uRe={};_&2&&(uRe.$$scope={dirty:_,ctx:c}),C3.$set(uRe);const pRe={};_&2&&(pRe.$$scope={dirty:_,ctx:c}),L3.$set(pRe);const Py={};_&2&&(Py.$$scope={dirty:_,ctx:c}),x3.$set(Py);const _Re={};_&2&&(_Re.$$scope={dirty:_,ctx:c}),I3.$set(_Re);const bRe={};_&2&&(bRe.$$scope={dirty:_,ctx:c}),q3.$set(bRe);const By={};_&2&&(By.$$scope={dirty:_,ctx:c}),G3.$set(By);const vRe={};_&2&&(vRe.$$scope={dirty:_,ctx:c}),V3.$set(vRe);const FRe={};_&2&&(FRe.$$scope={dirty:_,ctx:c}),X5.$set(FRe);const Iy={};_&2&&(Iy.$$scope={dirty:_,ctx:c}),Q5.$set(Iy);const TRe={};_&2&&(TRe.$$scope={dirty:_,ctx:c}),p0.$set(TRe);const MRe={};_&2&&(MRe.$$scope={dirty:_,ctx:c}),b0.$set(MRe);const Ny={};_&2&&(Ny.$$scope={dirty:_,ctx:c}),R0.$set(Ny);const ERe={};_&2&&(ERe.$$scope={dirty:_,ctx:c}),B0.$set(ERe);const CRe={};_&2&&(CRe.$$scope={dirty:_,ctx:c}),X0.$set(CRe);const qy={};_&2&&(qy.$$scope={dirty:_,ctx:c}),Q0.$set(qy);const wRe={};_&2&&(wRe.$$scope={dirty:_,ctx:c}),J0.$set(wRe);const ARe={};_&2&&(ARe.$$scope={dirty:_,ctx:c}),K0.$set(ARe);const jy={};_&2&&(jy.$$scope={dirty:_,ctx:c}),vw.$set(jy);const LRe={};_&2&&(LRe.$$scope={dirty:_,ctx:c}),Tw.$set(LRe);const yRe={};_&2&&(yRe.$$scope={dirty:_,ctx:c}),Sw.$set(yRe);const Dy={};_&2&&(Dy.$$scope={dirty:_,ctx:c}),Pw.$set(Dy);const xRe={};_&2&&(xRe.$$scope={dirty:_,ctx:c}),iA.$set(xRe);const $Re={};_&2&&($Re.$$scope={dirty:_,ctx:c}),mA.$set($Re);const Gy={};_&2&&(Gy.$$scope={dirty:_,ctx:c}),yA.$set(Gy);const kRe={};_&2&&(kRe.$$scope={dirty:_,ctx:c}),$A.$set(kRe);const SRe={};_&2&&(SRe.$$scope={dirty:_,ctx:c}),RA.$set(SRe);const Oy={};_&2&&(Oy.$$scope={dirty:_,ctx:c}),BA.$set(Oy);const RRe={};_&2&&(RRe.$$scope={dirty:_,ctx:c}),NA.$set(RRe);const PRe={};_&2&&(PRe.$$scope={dirty:_,ctx:c}),jA.$set(PRe);const Vy={};_&2&&(Vy.$$scope={dirty:_,ctx:c}),GA.$set(Vy);const BRe={};_&2&&(BRe.$$scope={dirty:_,ctx:c}),VA.$set(BRe);const IRe={};_&2&&(IRe.$$scope={dirty:_,ctx:c}),c6.$set(IRe);const Xy={};_&2&&(Xy.$$scope={dirty:_,ctx:c}),g6.$set(Xy);const NRe={};_&2&&(NRe.$$scope={dirty:_,ctx:c}),B6.$set(NRe);const qRe={};_&2&&(qRe.$$scope={dirty:_,ctx:c}),N6.$set(qRe);const zy={};_&2&&(zy.$$scope={dirty:_,ctx:c}),j6.$set(zy);const jRe={};_&2&&(jRe.$$scope={dirty:_,ctx:c}),G6.$set(jRe);const DRe={};_&2&&(DRe.$$scope={dirty:_,ctx:c}),V6.$set(DRe);const Qy={};_&2&&(Qy.$$scope={dirty:_,ctx:c}),z6.$set(Qy);const GRe={};_&2&&(GRe.$$scope={dirty:_,ctx:c}),v7.$set(GRe);const ORe={};_&2&&(ORe.$$scope={dirty:_,ctx:c}),T7.$set(ORe);const Wy={};_&2&&(Wy.$$scope={dirty:_,ctx:c}),S7.$set(Wy);const VRe={};_&2&&(VRe.$$scope={dirty:_,ctx:c}),P7.$set(VRe);const XRe={};_&2&&(XRe.$$scope={dirty:_,ctx:c}),U7.$set(XRe);const Uy={};_&2&&(Uy.$$scope={dirty:_,ctx:c}),J7.$set(Uy);const zRe={};_&2&&(zRe.$$scope={dirty:_,ctx:c}),lL.$set(zRe);const QRe={};_&2&&(QRe.$$scope={dirty:_,ctx:c}),dL.$set(QRe);const Hy={};_&2&&(Hy.$$scope={dirty:_,ctx:c}),FL.$set(Hy);const WRe={};_&2&&(WRe.$$scope={dirty:_,ctx:c}),ML.$set(WRe);const URe={};_&2&&(URe.$$scope={dirty:_,ctx:c}),RL.$set(URe);const Jy={};_&2&&(Jy.$$scope={dirty:_,ctx:c}),BL.$set(Jy);const HRe={};_&2&&(HRe.$$scope={dirty:_,ctx:c}),QL.$set(HRe);const JRe={};_&2&&(JRe.$$scope={dirty:_,ctx:c}),UL.$set(JRe);const Yy={};_&2&&(Yy.$$scope={dirty:_,ctx:c}),ty.$set(Yy);const YRe={};_&2&&(YRe.$$scope={dirty:_,ctx:c}),ny.$set(YRe);const KRe={};_&2&&(KRe.$$scope={dirty:_,ctx:c}),hy.$set(KRe);const Ky={};_&2&&(Ky.$$scope={dirty:_,ctx:c}),py.$set(Ky);const ZRe={};_&2&&(ZRe.$$scope={dirty:_,ctx:c}),by.$set(ZRe);const ePe={};_&2&&(ePe.$$scope={dirty:_,ctx:c}),Fy.$set(ePe);const Zy={};_&2&&(Zy.$$scope={dirty:_,ctx:c}),Ey.$set(Zy);const oPe={};_&2&&(oPe.$$scope={dirty:_,ctx:c}),wy.$set(oPe);const rPe={};_&2&&(rPe.$$scope={dirty:_,ctx:c}),Ly.$set(rPe)},i(c){yro||(E(m.$$.fragment,c),E(Qa.$$.fragment,c),E(ix.$$.fragment,c),E(dx.$$.fragment,c),E(xf.$$.fragment,c),E(mx.$$.fragment,c),E(cx.$$.fragment,c),E(hx.$$.fragment,c),E(ru.$$.fragment,c),E(ux.$$.fragment,c),E(px.$$.fragment,c),E(_x.$$.fragment,c),E(Fx.$$.fragment,c),E(Du.$$.fragment,c),E(Tx.$$.fragment,c),E(Mx.$$.fragment,c),E(Ex.$$.fragment,c),E(Ax.$$.fragment,c),E(Sp.$$.fragment,c),E(Rp.$$.fragment,c),E(Lx.$$.fragment,c),E(yx.$$.fragment,c),E(xx.$$.fragment,c),E(Sx.$$.fragment,c),E(n_.$$.fragment,c),E(s_.$$.fragment,c),E(Rx.$$.fragment,c),E(Px.$$.fragment,c),E(Bx.$$.fragment,c),E(Nx.$$.fragment,c),E(d_.$$.fragment,c),E(qx.$$.fragment,c),E(x2.$$.fragment,c),E(jx.$$.fragment,c),E(Dx.$$.fragment,c),E(Ox.$$.fragment,c),E(k2.$$.fragment,c),E(Vx.$$.fragment,c),E(Lb.$$.fragment,c),E(Xx.$$.fragment,c),E(zx.$$.fragment,c),E(Wx.$$.fragment,c),E(xb.$$.fragment,c),E(Ux.$$.fragment,c),E(vv.$$.fragment,c),E(Hx.$$.fragment,c),E(Jx.$$.fragment,c),E(Kx.$$.fragment,c),E(Tv.$$.fragment,c),E(Zx.$$.fragment,c),E(iF.$$.fragment,c),E(e$.$$.fragment,c),E(o$.$$.fragment,c),E(t$.$$.fragment,c),E(mF.$$.fragment,c),E(a$.$$.fragment,c),E(SF.$$.fragment,c),E(n$.$$.fragment,c),E(s$.$$.fragment,c),E(i$.$$.fragment,c),E(PF.$$.fragment,c),E(d$.$$.fragment,c),E(NT.$$.fragment,c),E(m$.$$.fragment,c),E(c$.$$.fragment,c),E(g$.$$.fragment,c),E(jT.$$.fragment,c),E(h$.$$.fragment,c),E(vM.$$.fragment,c),E(u$.$$.fragment,c),E(p$.$$.fragment,c),E(b$.$$.fragment,c),E(TM.$$.fragment,c),E(v$.$$.fragment,c),E($M.$$.fragment,c),E(F$.$$.fragment,c),E(T$.$$.fragment,c),E(E$.$$.fragment,c),E(SM.$$.fragment,c),E(C$.$$.fragment,c),E(FE.$$.fragment,c),E(w$.$$.fragment,c),E(A$.$$.fragment,c),E(y$.$$.fragment,c),E(ME.$$.fragment,c),E(x$.$$.fragment,c),E(p4.$$.fragment,c),E($$.$$.fragment,c),E(k$.$$.fragment,c),E(R$.$$.fragment,c),E(b4.$$.fragment,c),E(P$.$$.fragment,c),E(T4.$$.fragment,c),E(B$.$$.fragment,c),E(I$.$$.fragment,c),E(q$.$$.fragment,c),E(E4.$$.fragment,c),E(j$.$$.fragment,c),E(y4.$$.fragment,c),E(D$.$$.fragment,c),E(G$.$$.fragment,c),E(V$.$$.fragment,c),E($4.$$.fragment,c),E(X$.$$.fragment,c),E(W4.$$.fragment,c),E(z$.$$.fragment,c),E(Q$.$$.fragment,c),E(U$.$$.fragment,c),E(H4.$$.fragment,c),E(H$.$$.fragment,c),E(K4.$$.fragment,c),E(J$.$$.fragment,c),E(Y$.$$.fragment,c),E(Z$.$$.fragment,c),E(eC.$$.fragment,c),E(ek.$$.fragment,c),E(tC.$$.fragment,c),E(ok.$$.fragment,c),E(rk.$$.fragment,c),E(ak.$$.fragment,c),E(nC.$$.fragment,c),E(nk.$$.fragment,c),E(iC.$$.fragment,c),E(sk.$$.fragment,c),E(lk.$$.fragment,c),E(dk.$$.fragment,c),E(mC.$$.fragment,c),E(mk.$$.fragment,c),E(TC.$$.fragment,c),E(ck.$$.fragment,c),E(fk.$$.fragment,c),E(hk.$$.fragment,c),E(EC.$$.fragment,c),E(uk.$$.fragment,c),E($C.$$.fragment,c),E(pk.$$.fragment,c),E(_k.$$.fragment,c),E(vk.$$.fragment,c),E(SC.$$.fragment,c),E(Fk.$$.fragment,c),E(XC.$$.fragment,c),E(Tk.$$.fragment,c),E(Mk.$$.fragment,c),E(Ck.$$.fragment,c),E(QC.$$.fragment,c),E(wk.$$.fragment,c),E(YC.$$.fragment,c),E(Ak.$$.fragment,c),E(Lk.$$.fragment,c),E(xk.$$.fragment,c),E(ZC.$$.fragment,c),E($k.$$.fragment,c),E(s3.$$.fragment,c),E(kk.$$.fragment,c),E(Sk.$$.fragment,c),E(Pk.$$.fragment,c),E(i3.$$.fragment,c),E(Bk.$$.fragment,c),E(h3.$$.fragment,c),E(Ik.$$.fragment,c),E(Nk.$$.fragment,c),E(jk.$$.fragment,c),E(p3.$$.fragment,c),E(Dk.$$.fragment,c),E(M3.$$.fragment,c),E(Gk.$$.fragment,c),E(Ok.$$.fragment,c),E(Xk.$$.fragment,c),E(C3.$$.fragment,c),E(zk.$$.fragment,c),E(L3.$$.fragment,c),E(Qk.$$.fragment,c),E(Wk.$$.fragment,c),E(Hk.$$.fragment,c),E(x3.$$.fragment,c),E(Jk.$$.fragment,c),E(I3.$$.fragment,c),E(Yk.$$.fragment,c),E(Kk.$$.fragment,c),E(eS.$$.fragment,c),E(q3.$$.fragment,c),E(oS.$$.fragment,c),E(G3.$$.fragment,c),E(rS.$$.fragment,c),E(tS.$$.fragment,c),E(nS.$$.fragment,c),E(V3.$$.fragment,c),E(sS.$$.fragment,c),E(X5.$$.fragment,c),E(lS.$$.fragment,c),E(iS.$$.fragment,c),E(mS.$$.fragment,c),E(Q5.$$.fragment,c),E(cS.$$.fragment,c),E(p0.$$.fragment,c),E(fS.$$.fragment,c),E(gS.$$.fragment,c),E(uS.$$.fragment,c),E(b0.$$.fragment,c),E(pS.$$.fragment,c),E(R0.$$.fragment,c),E(_S.$$.fragment,c),E(bS.$$.fragment,c),E(FS.$$.fragment,c),E(B0.$$.fragment,c),E(TS.$$.fragment,c),E(X0.$$.fragment,c),E(MS.$$.fragment,c),E(ES.$$.fragment,c),E(wS.$$.fragment,c),E(Q0.$$.fragment,c),E(AS.$$.fragment,c),E(J0.$$.fragment,c),E(LS.$$.fragment,c),E(yS.$$.fragment,c),E($S.$$.fragment,c),E(K0.$$.fragment,c),E(kS.$$.fragment,c),E(vw.$$.fragment,c),E(SS.$$.fragment,c),E(RS.$$.fragment,c),E(BS.$$.fragment,c),E(Tw.$$.fragment,c),E(IS.$$.fragment,c),E(Sw.$$.fragment,c),E(NS.$$.fragment,c),E(qS.$$.fragment,c),E(DS.$$.fragment,c),E(Pw.$$.fragment,c),E(GS.$$.fragment,c),E(iA.$$.fragment,c),E(OS.$$.fragment,c),E(VS.$$.fragment,c),E(zS.$$.fragment,c),E(mA.$$.fragment,c),E(QS.$$.fragment,c),E(yA.$$.fragment,c),E(WS.$$.fragment,c),E(US.$$.fragment,c),E(JS.$$.fragment,c),E($A.$$.fragment,c),E(YS.$$.fragment,c),E(RA.$$.fragment,c),E(ZS.$$.fragment,c),E(eR.$$.fragment,c),E(rR.$$.fragment,c),E(BA.$$.fragment,c),E(tR.$$.fragment,c),E(NA.$$.fragment,c),E(aR.$$.fragment,c),E(nR.$$.fragment,c),E(lR.$$.fragment,c),E(jA.$$.fragment,c),E(iR.$$.fragment,c),E(GA.$$.fragment,c),E(dR.$$.fragment,c),E(mR.$$.fragment,c),E(fR.$$.fragment,c),E(VA.$$.fragment,c),E(gR.$$.fragment,c),E(c6.$$.fragment,c),E(hR.$$.fragment,c),E(uR.$$.fragment,c),E(_R.$$.fragment,c),E(g6.$$.fragment,c),E(bR.$$.fragment,c),E(B6.$$.fragment,c),E(vR.$$.fragment,c),E(FR.$$.fragment,c),E(MR.$$.fragment,c),E(N6.$$.fragment,c),E(ER.$$.fragment,c),E(j6.$$.fragment,c),E(CR.$$.fragment,c),E(wR.$$.fragment,c),E(LR.$$.fragment,c),E(G6.$$.fragment,c),E(yR.$$.fragment,c),E(V6.$$.fragment,c),E(xR.$$.fragment,c),E($R.$$.fragment,c),E(SR.$$.fragment,c),E(z6.$$.fragment,c),E(RR.$$.fragment,c),E(v7.$$.fragment,c),E(PR.$$.fragment,c),E(BR.$$.fragment,c),E(NR.$$.fragment,c),E(T7.$$.fragment,c),E(qR.$$.fragment,c),E(S7.$$.fragment,c),E(jR.$$.fragment,c),E(DR.$$.fragment,c),E(OR.$$.fragment,c),E(P7.$$.fragment,c),E(VR.$$.fragment,c),E(U7.$$.fragment,c),E(XR.$$.fragment,c),E(zR.$$.fragment,c),E(WR.$$.fragment,c),E(J7.$$.fragment,c),E(UR.$$.fragment,c),E(lL.$$.fragment,c),E(HR.$$.fragment,c),E(JR.$$.fragment,c),E(KR.$$.fragment,c),E(dL.$$.fragment,c),E(ZR.$$.fragment,c),E(FL.$$.fragment,c),E(eP.$$.fragment,c),E(oP.$$.fragment,c),E(tP.$$.fragment,c),E(ML.$$.fragment,c),E(aP.$$.fragment,c),E(RL.$$.fragment,c),E(nP.$$.fragment,c),E(sP.$$.fragment,c),E(iP.$$.fragment,c),E(BL.$$.fragment,c),E(dP.$$.fragment,c),E(QL.$$.fragment,c),E(mP.$$.fragment,c),E(cP.$$.fragment,c),E(gP.$$.fragment,c),E(UL.$$.fragment,c),E(hP.$$.fragment,c),E(ty.$$.fragment,c),E(uP.$$.fragment,c),E(pP.$$.fragment,c),E(bP.$$.fragment,c),E(ny.$$.fragment,c),E(vP.$$.fragment,c),E(hy.$$.fragment,c),E(FP.$$.fragment,c),E(TP.$$.fragment,c),E(EP.$$.fragment,c),E(py.$$.fragment,c),E(CP.$$.fragment,c),E(by.$$.fragment,c),E(wP.$$.fragment,c),E(AP.$$.fragment,c),E(yP.$$.fragment,c),E(Fy.$$.fragment,c),E(xP.$$.fragment,c),E(Ey.$$.fragment,c),E(kP.$$.fragment,c),E(SP.$$.fragment,c),E(PP.$$.fragment,c),E(wy.$$.fragment,c),E(BP.$$.fragment,c),E(Ly.$$.fragment,c),yro=!0)},o(c){C(m.$$.fragment,c),C(Qa.$$.fragment,c),C(ix.$$.fragment,c),C(dx.$$.fragment,c),C(xf.$$.fragment,c),C(mx.$$.fragment,c),C(cx.$$.fragment,c),C(hx.$$.fragment,c),C(ru.$$.fragment,c),C(ux.$$.fragment,c),C(px.$$.fragment,c),C(_x.$$.fragment,c),C(Fx.$$.fragment,c),C(Du.$$.fragment,c),C(Tx.$$.fragment,c),C(Mx.$$.fragment,c),C(Ex.$$.fragment,c),C(Ax.$$.fragment,c),C(Sp.$$.fragment,c),C(Rp.$$.fragment,c),C(Lx.$$.fragment,c),C(yx.$$.fragment,c),C(xx.$$.fragment,c),C(Sx.$$.fragment,c),C(n_.$$.fragment,c),C(s_.$$.fragment,c),C(Rx.$$.fragment,c),C(Px.$$.fragment,c),C(Bx.$$.fragment,c),C(Nx.$$.fragment,c),C(d_.$$.fragment,c),C(qx.$$.fragment,c),C(x2.$$.fragment,c),C(jx.$$.fragment,c),C(Dx.$$.fragment,c),C(Ox.$$.fragment,c),C(k2.$$.fragment,c),C(Vx.$$.fragment,c),C(Lb.$$.fragment,c),C(Xx.$$.fragment,c),C(zx.$$.fragment,c),C(Wx.$$.fragment,c),C(xb.$$.fragment,c),C(Ux.$$.fragment,c),C(vv.$$.fragment,c),C(Hx.$$.fragment,c),C(Jx.$$.fragment,c),C(Kx.$$.fragment,c),C(Tv.$$.fragment,c),C(Zx.$$.fragment,c),C(iF.$$.fragment,c),C(e$.$$.fragment,c),C(o$.$$.fragment,c),C(t$.$$.fragment,c),C(mF.$$.fragment,c),C(a$.$$.fragment,c),C(SF.$$.fragment,c),C(n$.$$.fragment,c),C(s$.$$.fragment,c),C(i$.$$.fragment,c),C(PF.$$.fragment,c),C(d$.$$.fragment,c),C(NT.$$.fragment,c),C(m$.$$.fragment,c),C(c$.$$.fragment,c),C(g$.$$.fragment,c),C(jT.$$.fragment,c),C(h$.$$.fragment,c),C(vM.$$.fragment,c),C(u$.$$.fragment,c),C(p$.$$.fragment,c),C(b$.$$.fragment,c),C(TM.$$.fragment,c),C(v$.$$.fragment,c),C($M.$$.fragment,c),C(F$.$$.fragment,c),C(T$.$$.fragment,c),C(E$.$$.fragment,c),C(SM.$$.fragment,c),C(C$.$$.fragment,c),C(FE.$$.fragment,c),C(w$.$$.fragment,c),C(A$.$$.fragment,c),C(y$.$$.fragment,c),C(ME.$$.fragment,c),C(x$.$$.fragment,c),C(p4.$$.fragment,c),C($$.$$.fragment,c),C(k$.$$.fragment,c),C(R$.$$.fragment,c),C(b4.$$.fragment,c),C(P$.$$.fragment,c),C(T4.$$.fragment,c),C(B$.$$.fragment,c),C(I$.$$.fragment,c),C(q$.$$.fragment,c),C(E4.$$.fragment,c),C(j$.$$.fragment,c),C(y4.$$.fragment,c),C(D$.$$.fragment,c),C(G$.$$.fragment,c),C(V$.$$.fragment,c),C($4.$$.fragment,c),C(X$.$$.fragment,c),C(W4.$$.fragment,c),C(z$.$$.fragment,c),C(Q$.$$.fragment,c),C(U$.$$.fragment,c),C(H4.$$.fragment,c),C(H$.$$.fragment,c),C(K4.$$.fragment,c),C(J$.$$.fragment,c),C(Y$.$$.fragment,c),C(Z$.$$.fragment,c),C(eC.$$.fragment,c),C(ek.$$.fragment,c),C(tC.$$.fragment,c),C(ok.$$.fragment,c),C(rk.$$.fragment,c),C(ak.$$.fragment,c),C(nC.$$.fragment,c),C(nk.$$.fragment,c),C(iC.$$.fragment,c),C(sk.$$.fragment,c),C(lk.$$.fragment,c),C(dk.$$.fragment,c),C(mC.$$.fragment,c),C(mk.$$.fragment,c),C(TC.$$.fragment,c),C(ck.$$.fragment,c),C(fk.$$.fragment,c),C(hk.$$.fragment,c),C(EC.$$.fragment,c),C(uk.$$.fragment,c),C($C.$$.fragment,c),C(pk.$$.fragment,c),C(_k.$$.fragment,c),C(vk.$$.fragment,c),C(SC.$$.fragment,c),C(Fk.$$.fragment,c),C(XC.$$.fragment,c),C(Tk.$$.fragment,c),C(Mk.$$.fragment,c),C(Ck.$$.fragment,c),C(QC.$$.fragment,c),C(wk.$$.fragment,c),C(YC.$$.fragment,c),C(Ak.$$.fragment,c),C(Lk.$$.fragment,c),C(xk.$$.fragment,c),C(ZC.$$.fragment,c),C($k.$$.fragment,c),C(s3.$$.fragment,c),C(kk.$$.fragment,c),C(Sk.$$.fragment,c),C(Pk.$$.fragment,c),C(i3.$$.fragment,c),C(Bk.$$.fragment,c),C(h3.$$.fragment,c),C(Ik.$$.fragment,c),C(Nk.$$.fragment,c),C(jk.$$.fragment,c),C(p3.$$.fragment,c),C(Dk.$$.fragment,c),C(M3.$$.fragment,c),C(Gk.$$.fragment,c),C(Ok.$$.fragment,c),C(Xk.$$.fragment,c),C(C3.$$.fragment,c),C(zk.$$.fragment,c),C(L3.$$.fragment,c),C(Qk.$$.fragment,c),C(Wk.$$.fragment,c),C(Hk.$$.fragment,c),C(x3.$$.fragment,c),C(Jk.$$.fragment,c),C(I3.$$.fragment,c),C(Yk.$$.fragment,c),C(Kk.$$.fragment,c),C(eS.$$.fragment,c),C(q3.$$.fragment,c),C(oS.$$.fragment,c),C(G3.$$.fragment,c),C(rS.$$.fragment,c),C(tS.$$.fragment,c),C(nS.$$.fragment,c),C(V3.$$.fragment,c),C(sS.$$.fragment,c),C(X5.$$.fragment,c),C(lS.$$.fragment,c),C(iS.$$.fragment,c),C(mS.$$.fragment,c),C(Q5.$$.fragment,c),C(cS.$$.fragment,c),C(p0.$$.fragment,c),C(fS.$$.fragment,c),C(gS.$$.fragment,c),C(uS.$$.fragment,c),C(b0.$$.fragment,c),C(pS.$$.fragment,c),C(R0.$$.fragment,c),C(_S.$$.fragment,c),C(bS.$$.fragment,c),C(FS.$$.fragment,c),C(B0.$$.fragment,c),C(TS.$$.fragment,c),C(X0.$$.fragment,c),C(MS.$$.fragment,c),C(ES.$$.fragment,c),C(wS.$$.fragment,c),C(Q0.$$.fragment,c),C(AS.$$.fragment,c),C(J0.$$.fragment,c),C(LS.$$.fragment,c),C(yS.$$.fragment,c),C($S.$$.fragment,c),C(K0.$$.fragment,c),C(kS.$$.fragment,c),C(vw.$$.fragment,c),C(SS.$$.fragment,c),C(RS.$$.fragment,c),C(BS.$$.fragment,c),C(Tw.$$.fragment,c),C(IS.$$.fragment,c),C(Sw.$$.fragment,c),C(NS.$$.fragment,c),C(qS.$$.fragment,c),C(DS.$$.fragment,c),C(Pw.$$.fragment,c),C(GS.$$.fragment,c),C(iA.$$.fragment,c),C(OS.$$.fragment,c),C(VS.$$.fragment,c),C(zS.$$.fragment,c),C(mA.$$.fragment,c),C(QS.$$.fragment,c),C(yA.$$.fragment,c),C(WS.$$.fragment,c),C(US.$$.fragment,c),C(JS.$$.fragment,c),C($A.$$.fragment,c),C(YS.$$.fragment,c),C(RA.$$.fragment,c),C(ZS.$$.fragment,c),C(eR.$$.fragment,c),C(rR.$$.fragment,c),C(BA.$$.fragment,c),C(tR.$$.fragment,c),C(NA.$$.fragment,c),C(aR.$$.fragment,c),C(nR.$$.fragment,c),C(lR.$$.fragment,c),C(jA.$$.fragment,c),C(iR.$$.fragment,c),C(GA.$$.fragment,c),C(dR.$$.fragment,c),C(mR.$$.fragment,c),C(fR.$$.fragment,c),C(VA.$$.fragment,c),C(gR.$$.fragment,c),C(c6.$$.fragment,c),C(hR.$$.fragment,c),C(uR.$$.fragment,c),C(_R.$$.fragment,c),C(g6.$$.fragment,c),C(bR.$$.fragment,c),C(B6.$$.fragment,c),C(vR.$$.fragment,c),C(FR.$$.fragment,c),C(MR.$$.fragment,c),C(N6.$$.fragment,c),C(ER.$$.fragment,c),C(j6.$$.fragment,c),C(CR.$$.fragment,c),C(wR.$$.fragment,c),C(LR.$$.fragment,c),C(G6.$$.fragment,c),C(yR.$$.fragment,c),C(V6.$$.fragment,c),C(xR.$$.fragment,c),C($R.$$.fragment,c),C(SR.$$.fragment,c),C(z6.$$.fragment,c),C(RR.$$.fragment,c),C(v7.$$.fragment,c),C(PR.$$.fragment,c),C(BR.$$.fragment,c),C(NR.$$.fragment,c),C(T7.$$.fragment,c),C(qR.$$.fragment,c),C(S7.$$.fragment,c),C(jR.$$.fragment,c),C(DR.$$.fragment,c),C(OR.$$.fragment,c),C(P7.$$.fragment,c),C(VR.$$.fragment,c),C(U7.$$.fragment,c),C(XR.$$.fragment,c),C(zR.$$.fragment,c),C(WR.$$.fragment,c),C(J7.$$.fragment,c),C(UR.$$.fragment,c),C(lL.$$.fragment,c),C(HR.$$.fragment,c),C(JR.$$.fragment,c),C(KR.$$.fragment,c),C(dL.$$.fragment,c),C(ZR.$$.fragment,c),C(FL.$$.fragment,c),C(eP.$$.fragment,c),C(oP.$$.fragment,c),C(tP.$$.fragment,c),C(ML.$$.fragment,c),C(aP.$$.fragment,c),C(RL.$$.fragment,c),C(nP.$$.fragment,c),C(sP.$$.fragment,c),C(iP.$$.fragment,c),C(BL.$$.fragment,c),C(dP.$$.fragment,c),C(QL.$$.fragment,c),C(mP.$$.fragment,c),C(cP.$$.fragment,c),C(gP.$$.fragment,c),C(UL.$$.fragment,c),C(hP.$$.fragment,c),C(ty.$$.fragment,c),C(uP.$$.fragment,c),C(pP.$$.fragment,c),C(bP.$$.fragment,c),C(ny.$$.fragment,c),C(vP.$$.fragment,c),C(hy.$$.fragment,c),C(FP.$$.fragment,c),C(TP.$$.fragment,c),C(EP.$$.fragment,c),C(py.$$.fragment,c),C(CP.$$.fragment,c),C(by.$$.fragment,c),C(wP.$$.fragment,c),C(AP.$$.fragment,c),C(yP.$$.fragment,c),C(Fy.$$.fragment,c),C(xP.$$.fragment,c),C(Ey.$$.fragment,c),C(kP.$$.fragment,c),C(SP.$$.fragment,c),C(PP.$$.fragment,c),C(wy.$$.fragment,c),C(BP.$$.fragment,c),C(Ly.$$.fragment,c),yro=!1},d(c){t(g),c&&t(v),c&&t(u),w(m),c&&t(Cf),c&&t(pt),c&&t(Ve),c&&t(He),c&&t(Af),w(Qa,c),c&&t(Je),c&&t(Ae),c&&t(xo),c&&t(Wa),c&&t(ueo),c&&t(md),w(ix),c&&t(peo),c&&t(as),c&&t(_eo),w(dx,c),c&&t(beo),c&&t(fI),c&&t(veo),w(xf,c),c&&t(Feo),c&&t(cd),w(mx),c&&t(Teo),c&&t($o),w(cx),w(hx),w(ru),w(ux),c&&t(Meo),c&&t(gd),w(px),c&&t(Eeo),c&&t(ko),w(_x),w(Fx),w(Du),w(Tx),c&&t(Ceo),c&&t(hd),w(Mx),c&&t(weo),c&&t(So),w(Ex),w(Ax),w(Sp),w(Rp),w(Lx),c&&t(Aeo),c&&t(ud),w(yx),c&&t(Leo),c&&t(Ro),w(xx),w(Sx),w(n_),w(s_),w(Rx),c&&t(yeo),c&&t(_d),w(Px),c&&t(xeo),c&&t(Po),w(Bx),w(Nx),w(d_),w(qx),w(x2),c&&t($eo),c&&t(Fd),w(jx),c&&t(keo),c&&t(Bo),w(Dx),w(Ox),w(k2),w(Vx),w(Lb),c&&t(Seo),c&&t(Ed),w(Xx),c&&t(Reo),c&&t(Io),w(zx),w(Wx),w(xb),w(Ux),w(vv),c&&t(Peo),c&&t(Ad),w(Hx),c&&t(Beo),c&&t(No),w(Jx),w(Kx),w(Tv),w(Zx),w(iF),c&&t(Ieo),c&&t(xd),w(e$),c&&t(Neo),c&&t(qo),w(o$),w(t$),w(mF),w(a$),w(SF),c&&t(qeo),c&&t(Sd),w(n$),c&&t(jeo),c&&t(jo),w(s$),w(i$),w(PF),w(d$),w(NT),c&&t(Deo),c&&t(Bd),w(m$),c&&t(Geo),c&&t(Do),w(c$),w(g$),w(jT),w(h$),w(vM),c&&t(Oeo),c&&t(qd),w(u$),c&&t(Veo),c&&t(Go),w(p$),w(b$),w(TM),w(v$),w($M),c&&t(Xeo),c&&t(Gd),w(F$),c&&t(zeo),c&&t(Oo),w(T$),w(E$),w(SM),w(C$),w(FE),c&&t(Qeo),c&&t(Xd),w(w$),c&&t(Weo),c&&t(Vo),w(A$),w(y$),w(ME),w(x$),w(p4),c&&t(Ueo),c&&t(Wd),w($$),c&&t(Heo),c&&t(Xo),w(k$),w(R$),w(b4),w(P$),w(T4),c&&t(Jeo),c&&t(Jd),w(B$),c&&t(Yeo),c&&t(zo),w(I$),w(q$),w(E4),w(j$),w(y4),c&&t(Keo),c&&t(em),w(D$),c&&t(Zeo),c&&t(Qo),w(G$),w(V$),w($4),w(X$),w(W4),c&&t(eoo),c&&t(tm),w(z$),c&&t(ooo),c&&t(Wo),w(Q$),w(U$),w(H4),w(H$),w(K4),c&&t(roo),c&&t(sm),w(J$),c&&t(too),c&&t(Uo),w(Y$),w(Z$),w(eC),w(ek),w(tC),c&&t(aoo),c&&t(dm),w(ok),c&&t(noo),c&&t(Ho),w(rk),w(ak),w(nC),w(nk),w(iC),c&&t(soo),c&&t(fm),w(sk),c&&t(loo),c&&t(Jo),w(lk),w(dk),w(mC),w(mk),w(TC),c&&t(ioo),c&&t(um),w(ck),c&&t(doo),c&&t(Yo),w(fk),w(hk),w(EC),w(uk),w($C),c&&t(moo),c&&t(bm),w(pk),c&&t(coo),c&&t(Ko),w(_k),w(vk),w(SC),w(Fk),w(XC),c&&t(foo),c&&t(Tm),w(Tk),c&&t(goo),c&&t(Zo),w(Mk),w(Ck),w(QC),w(wk),w(YC),c&&t(hoo),c&&t(wm),w(Ak),c&&t(uoo),c&&t(er),w(Lk),w(xk),w(ZC),w($k),w(s3),c&&t(poo),c&&t(ym),w(kk),c&&t(_oo),c&&t(or),w(Sk),w(Pk),w(i3),w(Bk),w(h3),c&&t(boo),c&&t(km),w(Ik),c&&t(voo),c&&t(rr),w(Nk),w(jk),w(p3),w(Dk),w(M3),c&&t(Foo),c&&t(Pm),w(Gk),c&&t(Too),c&&t(tr),w(Ok),w(Xk),w(C3),w(zk),w(L3),c&&t(Moo),c&&t(Nm),w(Qk),c&&t(Eoo),c&&t(ar),w(Wk),w(Hk),w(x3),w(Jk),w(I3),c&&t(Coo),c&&t(Dm),w(Yk),c&&t(woo),c&&t(nr),w(Kk),w(eS),w(q3),w(oS),w(G3),c&&t(Aoo),c&&t(Vm),w(rS),c&&t(Loo),c&&t(sr),w(tS),w(nS),w(V3),w(sS),w(X5),c&&t(yoo),c&&t(Qm),w(lS),c&&t(xoo),c&&t(lr),w(iS),w(mS),w(Q5),w(cS),w(p0),c&&t($oo),c&&t(Hm),w(fS),c&&t(koo),c&&t(ir),w(gS),w(uS),w(b0),w(pS),w(R0),c&&t(Soo),c&&t(Km),w(_S),c&&t(Roo),c&&t(dr),w(bS),w(FS),w(B0),w(TS),w(X0),c&&t(Poo),c&&t(oc),w(MS),c&&t(Boo),c&&t(mr),w(ES),w(wS),w(Q0),w(AS),w(J0),c&&t(Ioo),c&&t(nc),w(LS),c&&t(Noo),c&&t(cr),w(yS),w($S),w(K0),w(kS),w(vw),c&&t(qoo),c&&t(ic),w(SS),c&&t(joo),c&&t(fr),w(RS),w(BS),w(Tw),w(IS),w(Sw),c&&t(Doo),c&&t(cc),w(NS),c&&t(Goo),c&&t(gr),w(qS),w(DS),w(Pw),w(GS),w(iA),c&&t(Ooo),c&&t(hc),w(OS),c&&t(Voo),c&&t(hr),w(VS),w(zS),w(mA),w(QS),w(yA),c&&t(Xoo),c&&t(_c),w(WS),c&&t(zoo),c&&t(ur),w(US),w(JS),w($A),w(YS),w(RA),c&&t(Qoo),c&&t(Fc),w(ZS),c&&t(Woo),c&&t(pr),w(eR),w(rR),w(BA),w(tR),w(NA),c&&t(Uoo),c&&t(Ec),w(aR),c&&t(Hoo),c&&t(_r),w(nR),w(lR),w(jA),w(iR),w(GA),c&&t(Joo),c&&t(Ac),w(dR),c&&t(Yoo),c&&t(br),w(mR),w(fR),w(VA),w(gR),w(c6),c&&t(Koo),c&&t(xc),w(hR),c&&t(Zoo),c&&t(vr),w(uR),w(_R),w(g6),w(bR),w(B6),c&&t(ero),c&&t(Sc),w(vR),c&&t(oro),c&&t(Fr),w(FR),w(MR),w(N6),w(ER),w(j6),c&&t(rro),c&&t(Bc),w(CR),c&&t(tro),c&&t(Tr),w(wR),w(LR),w(G6),w(yR),w(V6),c&&t(aro),c&&t(qc),w(xR),c&&t(nro),c&&t(Mr),w($R),w(SR),w(z6),w(RR),w(v7),c&&t(sro),c&&t(Gc),w(PR),c&&t(lro),c&&t(Er),w(BR),w(NR),w(T7),w(qR),w(S7),c&&t(iro),c&&t(Xc),w(jR),c&&t(dro),c&&t(Cr),w(DR),w(OR),w(P7),w(VR),w(U7),c&&t(mro),c&&t(Wc),w(XR),c&&t(cro),c&&t(wr),w(zR),w(WR),w(J7),w(UR),w(lL),c&&t(fro),c&&t(Jc),w(HR),c&&t(gro),c&&t(Ar),w(JR),w(KR),w(dL),w(ZR),w(FL),c&&t(hro),c&&t(Zc),w(eP),c&&t(uro),c&&t(Lr),w(oP),w(tP),w(ML),w(aP),w(RL),c&&t(pro),c&&t(rf),w(nP),c&&t(_ro),c&&t(yr),w(sP),w(iP),w(BL),w(dP),w(QL),c&&t(bro),c&&t(nf),w(mP),c&&t(vro),c&&t(xr),w(cP),w(gP),w(UL),w(hP),w(ty),c&&t(Fro),c&&t(df),w(uP),c&&t(Tro),c&&t($r),w(pP),w(bP),w(ny),w(vP),w(hy),c&&t(Mro),c&&t(ff),w(FP),c&&t(Ero),c&&t(kr),w(TP),w(EP),w(py),w(CP),w(by),c&&t(Cro),c&&t(uf),w(wP),c&&t(wro),c&&t(Sr),w(AP),w(yP),w(Fy),w(xP),w(Ey),c&&t(Aro),c&&t(bf),w(kP),c&&t(Lro),c&&t(Rr),w(SP),w(PP),w(wy),w(BP),w(Ly)}}}const gFa={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function hFa($){return aba(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class TFa extends eba{constructor(g){super();oba(this,g,hFa,fFa,rba,{})}}export{TFa as default,gFa as metadata};
