import{S as ho,i as go,s as _o,e as a,k as l,w as b,t as s,M as xo,c as o,d as r,m as d,a as n,x as y,h as i,b as f,G as e,g as _,y as $,q as E,o as w,B as F,v as vo,L as po}from"../../chunks/vendor-hf-doc-builder.js";import{T as mo}from"../../chunks/Tip-hf-doc-builder.js";import{D as I}from"../../chunks/Docstring-hf-doc-builder.js";import{C as uo}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as Pa}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as fo}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function bo(q){let m,k,h,p,T;return{c(){m=a("p"),k=s("Passing "),h=a("code"),p=s("use_auth_token=True"),T=s(" is required when you want to use a private model.")},l(c){m=o(c,"P",{});var x=n(m);k=i(x,"Passing "),h=o(x,"CODE",{});var J=n(h);p=i(J,"use_auth_token=True"),J.forEach(r),T=i(x," is required when you want to use a private model."),x.forEach(r)},m(c,x){_(c,m,x),e(m,k),e(m,h),e(h,p),e(m,T)},d(c){c&&r(m)}}}function yo(q){let m,k,h,p,T;return p=new uo({props:{code:`# We can't instantiate directly the base class *FeatureExtractionMixin* nor *SequenceFeatureExtractor* so let's show the examples on a
# derived class: *Wav2Vec2FeatureExtractor*
feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(
    "facebook/wav2vec2-base-960h"
)  # Download feature_extraction_config from huggingface.co and cache.
feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(
    "./test/saved_model/"
)  # E.g. feature_extractor (or model) was saved using *save_pretrained('./test/saved_model/')*
feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained("./test/saved_model/preprocessor_config.json")
feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(
    "facebook/wav2vec2-base-960h", return_attention_mask=False, foo=False
)
assert feature_extractor.return_attention_mask is False
feature_extractor, unused_kwargs = Wav2Vec2FeatureExtractor.from_pretrained(
    "facebook/wav2vec2-base-960h", return_attention_mask=False, foo=False, return_unused_kwargs=True
)
assert feature_extractor.return_attention_mask is False
assert unused_kwargs == {"foo": False}`,highlighted:`<span class="hljs-comment"># We can&#x27;t instantiate directly the base class *FeatureExtractionMixin* nor *SequenceFeatureExtractor* so let&#x27;s show the examples on a</span>
<span class="hljs-comment"># derived class: *Wav2Vec2FeatureExtractor*</span>
feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(
    <span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>
)  <span class="hljs-comment"># Download feature_extraction_config from huggingface.co and cache.</span>
feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(
    <span class="hljs-string">&quot;./test/saved_model/&quot;</span>
)  <span class="hljs-comment"># E.g. feature_extractor (or model) was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*</span>
feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/preprocessor_config.json&quot;</span>)
feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(
    <span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>, return_attention_mask=<span class="hljs-literal">False</span>, foo=<span class="hljs-literal">False</span>
)
<span class="hljs-keyword">assert</span> feature_extractor.return_attention_mask <span class="hljs-keyword">is</span> <span class="hljs-literal">False</span>
feature_extractor, unused_kwargs = Wav2Vec2FeatureExtractor.from_pretrained(
    <span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>, return_attention_mask=<span class="hljs-literal">False</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
)
<span class="hljs-keyword">assert</span> feature_extractor.return_attention_mask <span class="hljs-keyword">is</span> <span class="hljs-literal">False</span>
<span class="hljs-keyword">assert</span> unused_kwargs == {<span class="hljs-string">&quot;foo&quot;</span>: <span class="hljs-literal">False</span>}`}}),{c(){m=a("p"),k=s("Examples:"),h=l(),b(p.$$.fragment)},l(c){m=o(c,"P",{});var x=n(m);k=i(x,"Examples:"),x.forEach(r),h=d(c),y(p.$$.fragment,c)},m(c,x){_(c,m,x),e(m,k),_(c,h,x),$(p,c,x),T=!0},p:po,i(c){T||(E(p.$$.fragment,c),T=!0)},o(c){w(p.$$.fragment,c),T=!1},d(c){c&&r(m),c&&r(h),F(p,c)}}}function $o(q){let m,k,h,p,T;return p=new uo({props:{code:`from transformers import AutoFeatureExtractor

feature extractor = AutoFeatureExtractor.from_pretrained("bert-base-cased")

# Push the feature extractor to your namespace with the name "my-finetuned-bert".
feature extractor.push_to_hub("my-finetuned-bert")

# Push the feature extractor to an organization with the name "my-finetuned-bert".
feature extractor.push_to_hub("huggingface/my-finetuned-bert")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

feature extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-comment"># Push the feature extractor to your namespace with the name &quot;my-finetuned-bert&quot;.</span>
feature extractor.push_to_hub(<span class="hljs-string">&quot;my-finetuned-bert&quot;</span>)

<span class="hljs-comment"># Push the feature extractor to an organization with the name &quot;my-finetuned-bert&quot;.</span>
feature extractor.push_to_hub(<span class="hljs-string">&quot;huggingface/my-finetuned-bert&quot;</span>)`}}),{c(){m=a("p"),k=s("Examples:"),h=l(),b(p.$$.fragment)},l(c){m=o(c,"P",{});var x=n(m);k=i(x,"Examples:"),x.forEach(r),h=d(c),y(p.$$.fragment,c)},m(c,x){_(c,m,x),e(m,k),_(c,h,x),$(p,c,x),T=!0},p:po,i(c){T||(E(p.$$.fragment,c),T=!0)},o(c){w(p.$$.fragment,c),T=!1},d(c){c&&r(m),c&&r(h),F(p,c)}}}function Eo(q){let m,k;return{c(){m=a("p"),k=s("This API is experimental and may have some slight breaking changes in the next releases.")},l(h){m=o(h,"P",{});var p=n(m);k=i(p,"This API is experimental and may have some slight breaking changes in the next releases."),p.forEach(r)},m(h,p){_(h,m,p),e(m,k)},d(h){h&&r(m)}}}function wo(q){let m,k,h,p,T,c,x,J,Jt,xt,je,Ht,vt,ze,Bt,bt,O,H,He,le,Gt,Be,Yt,yt,P,de,Kt,D,Qt,Ge,Xt,Zt,Ye,er,tr,Ke,rr,ar,or,Qe,nr,$t,S,me,sr,N,ir,Xe,cr,lr,Ze,dr,mr,Et,C,fe,fr,V,pr,et,ur,hr,tt,gr,_r,wt,W,pe,xr,ue,vr,rt,br,yr,Ft,U,B,at,he,$r,ot,Er,kt,g,ge,wr,nt,Fr,kr,G,_e,Tr,xe,Ir,qe,Mr,Pr,Dr,Y,ve,jr,be,zr,Le,qr,Lr,Ar,M,ye,Or,j,Sr,Ae,Nr,Cr,st,Vr,Wr,Oe,Ur,Rr,Jr,K,Hr,Q,Br,X,$e,Gr,z,Yr,it,Kr,Qr,Se,Xr,Zr,ct,ea,ta,ra,L,Ee,aa,we,oa,lt,na,sa,ia,Z,ca,A,Fe,la,ke,da,dt,ma,fa,pa,ee,ua,te,Te,ha,R,ga,mt,_a,xa,Ne,va,ba,ya,re,Ie,$a,ft,Ea,wa,ae,Me,Fa,pt,ka,Ta,oe,Pe,Ia,ut,Ma,Tt;return c=new Pa({}),le=new Pa({}),de=new I({props:{name:"transformers.image_transforms.normalize",anchor:"transformers.image_transforms.normalize",parameters:[{name:"image",val:": ndarray"},{name:"mean",val:": typing.Union[float, typing.Iterable[float]]"},{name:"std",val:": typing.Union[float, typing.Iterable[float]]"},{name:"data_format",val:": typing.Optional[transformers.image_utils.ChannelDimension] = None"}],parametersDescription:[{anchor:"transformers.image_transforms.normalize.image",description:`<strong>image</strong> (<code>np.ndarray</code>) &#x2014;
The image to normalize.`,name:"image"},{anchor:"transformers.image_transforms.normalize.mean",description:`<strong>mean</strong> (<code>float</code> or <code>Iterable[float]</code>) &#x2014;
The mean to use for normalization.`,name:"mean"},{anchor:"transformers.image_transforms.normalize.std",description:`<strong>std</strong> (<code>float</code> or <code>Iterable[float]</code>) &#x2014;
The standard deviation to use for normalization.`,name:"std"},{anchor:"transformers.image_transforms.normalize.data_format",description:`<strong>data_format</strong> (<code>ChannelDimension</code>, <em>optional</em>) &#x2014;
The channel dimension format of the output image. If <code>None</code>, will use the inferred format from the input.`,name:"data_format"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_transforms.py#L266"}}),me=new I({props:{name:"transformers.rescale",anchor:"transformers.rescale",parameters:[{name:"image",val:": ndarray"},{name:"scale",val:": float"},{name:"data_format",val:": typing.Optional[transformers.image_utils.ChannelDimension] = None"},{name:"dtype",val:" = <class 'numpy.float32'>"}],parametersDescription:[{anchor:"transformers.rescale.image",description:`<strong>image</strong> (<code>np.ndarray</code>) &#x2014;
The image to rescale.`,name:"image"},{anchor:"transformers.rescale.scale",description:`<strong>scale</strong> (<code>float</code>) &#x2014;
The scale to use for rescaling the image.`,name:"scale"},{anchor:"transformers.rescale.data_format",description:`<strong>data_format</strong> (<code>ChannelDimension</code>, <em>optional</em>) &#x2014;
The channel dimension format of the image. If not provided, it will be the same as the input image.`,name:"data_format"},{anchor:"transformers.rescale.dtype",description:`<strong>dtype</strong> (<code>np.dtype</code>, <em>optional</em>, defaults to <code>np.float32</code>) &#x2014;
The dtype of the output image. Defaults to <code>np.float32</code>. Used for backwards compatibility with feature
extractors.`,name:"dtype"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_transforms.py#L80",returnDescription:`
<p>The rescaled image.</p>
`,returnType:`
<p><code>np.ndarray</code></p>
`}}),fe=new I({props:{name:"transformers.resize",anchor:"transformers.resize",parameters:[{name:"image",val:""},{name:"size",val:": typing.Tuple[int, int]"},{name:"resample",val:" = <Resampling.BILINEAR: 2>"},{name:"data_format",val:": typing.Optional[transformers.image_utils.ChannelDimension] = None"},{name:"return_numpy",val:": bool = True"}],parametersDescription:[{anchor:"transformers.resize.image",description:`<strong>image</strong> (<code>PIL.Image.Image</code> or <code>np.ndarray</code> or <code>torch.Tensor</code>) &#x2014;
The image to resize.`,name:"image"},{anchor:"transformers.resize.size",description:`<strong>size</strong> (<code>Tuple[int, int]</code>) &#x2014;
The size to use for resizing the image.`,name:"size"},{anchor:"transformers.resize.resample",description:`<strong>resample</strong> (<code>int</code>, <em>optional</em>, defaults to <code>PIL.Image.Resampling.BILINEAR</code>) &#x2014;
The filter to user for resampling.`,name:"resample"},{anchor:"transformers.resize.data_format",description:`<strong>data_format</strong> (<code>ChannelDimension</code>, <em>optional</em>) &#x2014;
The channel dimension format of the output image. If <code>None</code>, will use the inferred format from the input.`,name:"data_format"},{anchor:"transformers.resize.return_numpy",description:`<strong>return_numpy</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to return the resized image as a numpy array. If False a <code>PIL.Image.Image</code> object is
returned.`,name:"return_numpy"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_transforms.py#L217",returnDescription:`
<p>The resized image.</p>
`,returnType:`
<p><code>np.ndarray</code></p>
`}}),pe=new I({props:{name:"transformers.to_pil_image",anchor:"transformers.to_pil_image",parameters:[{name:"image",val:": typing.Union[numpy.ndarray, PIL.Image.Image, ForwardRef('torch.Tensor'), ForwardRef('tf.Tensor'), ForwardRef('jnp.Tensor')]"},{name:"do_rescale",val:": typing.Optional[bool] = None"}],parametersDescription:[{anchor:"transformers.to_pil_image.image",description:`<strong>image</strong> (<code>PIL.Image.Image</code> or <code>numpy.ndarray</code> or <code>torch.Tensor</code> or <code>tf.Tensor</code>) &#x2014;
The image to convert to the <code>PIL.Image</code> format.`,name:"image"},{anchor:"transformers.to_pil_image.do_rescale",description:`<strong>do_rescale</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to apply the scaling factor (to make pixel values integers between 0 and 255). Will default
to <code>True</code> if the image type is a floating type, <code>False</code> otherwise.`,name:"do_rescale"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_transforms.py#L110",returnDescription:`
<p>The converted image.</p>
`,returnType:`
<p><code>PIL.Image.Image</code></p>
`}}),he=new Pa({}),ge=new I({props:{name:"class transformers.FeatureExtractionMixin",anchor:"transformers.FeatureExtractionMixin",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/feature_extraction_utils.py#L198"}}),_e=new I({props:{name:"from_dict",anchor:"transformers.FeatureExtractionMixin.from_dict",parameters:[{name:"feature_extractor_dict",val:": typing.Dict[str, typing.Any]"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FeatureExtractionMixin.from_dict.feature_extractor_dict",description:`<strong>feature_extractor_dict</strong> (<code>Dict[str, Any]</code>) &#x2014;
Dictionary that will be used to instantiate the feature extractor object. Such a dictionary can be
retrieved from a pretrained checkpoint by leveraging the
<a href="/docs/transformers/main/en/internal/image_processing_utils#transformers.FeatureExtractionMixin.to_dict">to_dict()</a> method.`,name:"feature_extractor_dict"},{anchor:"transformers.FeatureExtractionMixin.from_dict.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>) &#x2014;
Additional parameters from which to initialize the feature extractor object.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/feature_extraction_utils.py#L443",returnDescription:`
<p>The feature extractor object instantiated from those
parameters.</p>
`,returnType:`
<p><a
  href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin"
>FeatureExtractionMixin</a></p>
`}}),ve=new I({props:{name:"from_json_file",anchor:"transformers.FeatureExtractionMixin.from_json_file",parameters:[{name:"json_file",val:": typing.Union[str, os.PathLike]"}],parametersDescription:[{anchor:"transformers.FeatureExtractionMixin.from_json_file.json_file",description:`<strong>json_file</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Path to the JSON file containing the parameters.`,name:"json_file"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/feature_extraction_utils.py#L492",returnDescription:`
<p>The feature_extractor
object instantiated from that JSON file.</p>
`,returnType:`
<p>A feature extractor of type <a
  href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin"
>FeatureExtractionMixin</a></p>
`}}),ye=new I({props:{name:"from_pretrained",anchor:"transformers.FeatureExtractionMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": typing.Union[str, os.PathLike]"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FeatureExtractionMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FeatureExtractionMixin.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FeatureExtractionMixin.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.FeatureExtractionMixin.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.FeatureExtractionMixin.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FeatureExtractionMixin.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.FeatureExtractionMixin.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FeatureExtractionMixin.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.FeatureExtractionMixin.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/feature_extraction_utils.py#L222",returnDescription:`
<p>A feature extractor of type <a
  href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin"
>FeatureExtractionMixin</a>.</p>
`}}),K=new mo({props:{$$slots:{default:[bo]},$$scope:{ctx:q}}}),Q=new fo({props:{anchor:"transformers.FeatureExtractionMixin.from_pretrained.example",$$slots:{default:[yo]},$$scope:{ctx:q}}}),$e=new I({props:{name:"get_feature_extractor_dict",anchor:"transformers.FeatureExtractionMixin.get_feature_extractor_dict",parameters:[{name:"pretrained_model_name_or_path",val:": typing.Union[str, os.PathLike]"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FeatureExtractionMixin.get_feature_extractor_dict.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
The identifier of the pre-trained checkpoint from which we want the dictionary of parameters.`,name:"pretrained_model_name_or_path"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/feature_extraction_utils.py#L350",returnDescription:`
<p>The dictionary(ies) that will be used to instantiate the feature extractor object.</p>
`,returnType:`
<p><code>Tuple[Dict, Dict]</code></p>
`}}),Ee=new I({props:{name:"push_to_hub",anchor:"transformers.FeatureExtractionMixin.push_to_hub",parameters:[{name:"repo_id",val:": str"},{name:"use_temp_dir",val:": typing.Optional[bool] = None"},{name:"commit_message",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"max_shard_size",val:": typing.Union[int, str, NoneType] = '10GB'"},{name:"create_pr",val:": bool = False"},{name:"**deprecated_kwargs",val:""}],parametersDescription:[{anchor:"transformers.FeatureExtractionMixin.push_to_hub.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
The name of the repository you want to push your feature extractor to. It should contain your organization name
when pushing to a given organization.`,name:"repo_id"},{anchor:"transformers.FeatureExtractionMixin.push_to_hub.use_temp_dir",description:`<strong>use_temp_dir</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to use a temporary directory to store the files saved before they are pushed to the Hub.
Will default to <code>True</code> if there is no directory named like <code>repo_id</code>, <code>False</code> otherwise.`,name:"use_temp_dir"},{anchor:"transformers.FeatureExtractionMixin.push_to_hub.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Message to commit while pushing. Will default to <code>&quot;Upload feature extractor&quot;</code>.`,name:"commit_message"},{anchor:"transformers.FeatureExtractionMixin.push_to_hub.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not the repository created should be private (requires a paying subscription).`,name:"private"},{anchor:"transformers.FeatureExtractionMixin.push_to_hub.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>). Will default to <code>True</code> if <code>repo_url</code>
is not specified.`,name:"use_auth_token"},{anchor:"transformers.FeatureExtractionMixin.push_to_hub.max_shard_size",description:`<strong>max_shard_size</strong> (<code>int</code> or <code>str</code>, <em>optional</em>, defaults to <code>&quot;10GB&quot;</code>) &#x2014;
Only applicable for models. The maximum size for a checkpoint before being sharded. Checkpoints shard
will then be each of size lower than this size. If expressed as a string, needs to be digits followed
by a unit (like <code>&quot;5MB&quot;</code>).`,name:"max_shard_size"},{anchor:"transformers.FeatureExtractionMixin.push_to_hub.create_pr",description:`<strong>create_pr</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to create a PR with the uploaded files or directly commit.`,name:"create_pr"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/utils/hub.py#L712"}}),Z=new fo({props:{anchor:"transformers.FeatureExtractionMixin.push_to_hub.example",$$slots:{default:[$o]},$$scope:{ctx:q}}}),Fe=new I({props:{name:"register_for_auto_class",anchor:"transformers.FeatureExtractionMixin.register_for_auto_class",parameters:[{name:"auto_class",val:" = 'AutoFeatureExtractor'"}],parametersDescription:[{anchor:"transformers.FeatureExtractionMixin.register_for_auto_class.auto_class",description:`<strong>auto_class</strong> (<code>str</code> or <code>type</code>, <em>optional</em>, defaults to <code>&quot;AutoFeatureExtractor&quot;</code>) &#x2014;
The auto class to register this new feature extractor with.`,name:"auto_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/feature_extraction_utils.py#L546"}}),ee=new mo({props:{warning:!0,$$slots:{default:[Eo]},$$scope:{ctx:q}}}),Te=new I({props:{name:"save_pretrained",anchor:"transformers.FeatureExtractionMixin.save_pretrained",parameters:[{name:"save_directory",val:": typing.Union[str, os.PathLike]"},{name:"push_to_hub",val:": bool = False"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FeatureExtractionMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Directory where the feature extractor JSON file will be saved (will be created if it does not exist).`,name:"save_directory"},{anchor:"transformers.FeatureExtractionMixin.save_pretrained.push_to_hub",description:`<strong>push_to_hub</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to push your model to the Hugging Face model hub after saving it. You can specify the
repository you want to push to with <code>repo_id</code> (will default to the name of <code>save_directory</code> in your
namespace).
kwargs &#x2014;
Additional key word arguments passed along to the <a href="/docs/transformers/main/en/main_classes/model#transformers.utils.PushToHubMixin.push_to_hub">push_to_hub()</a> method.`,name:"push_to_hub"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/feature_extraction_utils.py#L306"}}),Ie=new I({props:{name:"to_dict",anchor:"transformers.FeatureExtractionMixin.to_dict",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/feature_extraction_utils.py#L480",returnDescription:`
<p>Dictionary of all the attributes that make up this feature extractor instance.</p>
`,returnType:`
<p><code>Dict[str, Any]</code></p>
`}}),Me=new I({props:{name:"to_json_file",anchor:"transformers.FeatureExtractionMixin.to_json_file",parameters:[{name:"json_file_path",val:": typing.Union[str, os.PathLike]"}],parametersDescription:[{anchor:"transformers.FeatureExtractionMixin.to_json_file.json_file_path",description:`<strong>json_file_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Path to the JSON file in which this feature_extractor instance&#x2019;s parameters will be saved.`,name:"json_file_path"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/feature_extraction_utils.py#L532"}}),Pe=new I({props:{name:"to_json_string",anchor:"transformers.FeatureExtractionMixin.to_json_string",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/feature_extraction_utils.py#L511",returnDescription:`
<p>String containing all the attributes that make up this feature_extractor instance in JSON format.</p>
`,returnType:`
<p><code>str</code></p>
`}}),{c(){m=a("meta"),k=l(),h=a("h1"),p=a("a"),T=a("span"),b(c.$$.fragment),x=l(),J=a("span"),Jt=s("Utilities for Image Processors"),xt=l(),je=a("p"),Ht=s(`This page lists all the utility functions used by the image processors, mainly the functional
transformations used to process the images.`),vt=l(),ze=a("p"),Bt=s("Most of those are only useful if you are studying the code of the image processors in the library."),bt=l(),O=a("h2"),H=a("a"),He=a("span"),b(le.$$.fragment),Gt=l(),Be=a("span"),Yt=s("Image Transformations"),yt=l(),P=a("div"),b(de.$$.fragment),Kt=l(),D=a("p"),Qt=s("Normalizes "),Ge=a("code"),Xt=s("image"),Zt=s(" using the mean and standard deviation specified by "),Ye=a("code"),er=s("mean"),tr=s(" and "),Ke=a("code"),rr=s("std"),ar=s("."),or=l(),Qe=a("p"),nr=s("image = (image - mean) / std"),$t=l(),S=a("div"),b(me.$$.fragment),sr=l(),N=a("p"),ir=s("Rescales "),Xe=a("code"),cr=s("image"),lr=s(" by "),Ze=a("code"),dr=s("scale"),mr=s("."),Et=l(),C=a("div"),b(fe.$$.fragment),fr=l(),V=a("p"),pr=s("Resizes "),et=a("code"),ur=s("image"),hr=s(" to (h, w) specified by "),tt=a("code"),gr=s("size"),_r=s(" using the PIL library."),wt=l(),W=a("div"),b(pe.$$.fragment),xr=l(),ue=a("p"),vr=s("Converts "),rt=a("code"),br=s("image"),yr=s(` to a PIL Image. Optionally rescales it and puts the channel dimension back as the last axis if
needed.`),Ft=l(),U=a("h2"),B=a("a"),at=a("span"),b(he.$$.fragment),$r=l(),ot=a("span"),Er=s("ImageProcessorMixin"),kt=l(),g=a("div"),b(ge.$$.fragment),wr=l(),nt=a("p"),Fr=s(`This is a feature extraction mixin used to provide saving/loading functionality for sequential and image feature
extractors.`),kr=l(),G=a("div"),b(_e.$$.fragment),Tr=l(),xe=a("p"),Ir=s("Instantiates a type of "),qe=a("a"),Mr=s("FeatureExtractionMixin"),Pr=s(` from a Python dictionary of
parameters.`),Dr=l(),Y=a("div"),b(ve.$$.fragment),jr=l(),be=a("p"),zr=s("Instantiates a feature extractor of type "),Le=a("a"),qr=s("FeatureExtractionMixin"),Lr=s(` from the path to
a JSON file of parameters.`),Ar=l(),M=a("div"),b(ye.$$.fragment),Or=l(),j=a("p"),Sr=s("Instantiate a type of "),Ae=a("a"),Nr=s("FeatureExtractionMixin"),Cr=s(" from a feature extractor, "),st=a("em"),Vr=s("e.g."),Wr=s(` a
derived class of `),Oe=a("a"),Ur=s("SequenceFeatureExtractor"),Rr=s("."),Jr=l(),b(K.$$.fragment),Hr=l(),b(Q.$$.fragment),Br=l(),X=a("div"),b($e.$$.fragment),Gr=l(),z=a("p"),Yr=s("From a "),it=a("code"),Kr=s("pretrained_model_name_or_path"),Qr=s(`, resolve to a dictionary of parameters, to be used for instantiating a
feature extractor of type `),Se=a("a"),Xr=s("FeatureExtractionMixin"),Zr=s(" using "),ct=a("code"),ea=s("from_dict"),ta=s("."),ra=l(),L=a("div"),b(Ee.$$.fragment),aa=l(),we=a("p"),oa=s(`Upload the feature extractor file to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),lt=a("code"),na=s("repo_path_or_name"),sa=s("."),ia=l(),b(Z.$$.fragment),ca=l(),A=a("div"),b(Fe.$$.fragment),la=l(),ke=a("p"),da=s(`Register this class with a given auto class. This should only be used for custom feature extractors as the ones
in the library are already mapped with `),dt=a("code"),ma=s("AutoFeatureExtractor"),fa=s("."),pa=l(),b(ee.$$.fragment),ua=l(),te=a("div"),b(Te.$$.fragment),ha=l(),R=a("p"),ga=s("Save a feature_extractor object to the directory "),mt=a("code"),_a=s("save_directory"),xa=s(`, so that it can be re-loaded using the
`),Ne=a("a"),va=s("from_pretrained()"),ba=s(" class method."),ya=l(),re=a("div"),b(Ie.$$.fragment),$a=l(),ft=a("p"),Ea=s("Serializes this instance to a Python dictionary."),wa=l(),ae=a("div"),b(Me.$$.fragment),Fa=l(),pt=a("p"),ka=s("Save this instance to a JSON file."),Ta=l(),oe=a("div"),b(Pe.$$.fragment),Ia=l(),ut=a("p"),Ma=s("Serializes this instance to a JSON string."),this.h()},l(t){const u=xo('[data-svelte="svelte-1phssyn"]',document.head);m=o(u,"META",{name:!0,content:!0}),u.forEach(r),k=d(t),h=o(t,"H1",{class:!0});var De=n(h);p=o(De,"A",{id:!0,class:!0,href:!0});var ht=n(p);T=o(ht,"SPAN",{});var gt=n(T);y(c.$$.fragment,gt),gt.forEach(r),ht.forEach(r),x=d(De),J=o(De,"SPAN",{});var _t=n(J);Jt=i(_t,"Utilities for Image Processors"),_t.forEach(r),De.forEach(r),xt=d(t),je=o(t,"P",{});var Da=n(je);Ht=i(Da,`This page lists all the utility functions used by the image processors, mainly the functional
transformations used to process the images.`),Da.forEach(r),vt=d(t),ze=o(t,"P",{});var ja=n(ze);Bt=i(ja,"Most of those are only useful if you are studying the code of the image processors in the library."),ja.forEach(r),bt=d(t),O=o(t,"H2",{class:!0});var It=n(O);H=o(It,"A",{id:!0,class:!0,href:!0});var za=n(H);He=o(za,"SPAN",{});var qa=n(He);y(le.$$.fragment,qa),qa.forEach(r),za.forEach(r),Gt=d(It),Be=o(It,"SPAN",{});var La=n(Be);Yt=i(La,"Image Transformations"),La.forEach(r),It.forEach(r),yt=d(t),P=o(t,"DIV",{class:!0});var Ce=n(P);y(de.$$.fragment,Ce),Kt=d(Ce),D=o(Ce,"P",{});var ne=n(D);Qt=i(ne,"Normalizes "),Ge=o(ne,"CODE",{});var Aa=n(Ge);Xt=i(Aa,"image"),Aa.forEach(r),Zt=i(ne," using the mean and standard deviation specified by "),Ye=o(ne,"CODE",{});var Oa=n(Ye);er=i(Oa,"mean"),Oa.forEach(r),tr=i(ne," and "),Ke=o(ne,"CODE",{});var Sa=n(Ke);rr=i(Sa,"std"),Sa.forEach(r),ar=i(ne,"."),ne.forEach(r),or=d(Ce),Qe=o(Ce,"P",{});var Na=n(Qe);nr=i(Na,"image = (image - mean) / std"),Na.forEach(r),Ce.forEach(r),$t=d(t),S=o(t,"DIV",{class:!0});var Mt=n(S);y(me.$$.fragment,Mt),sr=d(Mt),N=o(Mt,"P",{});var Ve=n(N);ir=i(Ve,"Rescales "),Xe=o(Ve,"CODE",{});var Ca=n(Xe);cr=i(Ca,"image"),Ca.forEach(r),lr=i(Ve," by "),Ze=o(Ve,"CODE",{});var Va=n(Ze);dr=i(Va,"scale"),Va.forEach(r),mr=i(Ve,"."),Ve.forEach(r),Mt.forEach(r),Et=d(t),C=o(t,"DIV",{class:!0});var Pt=n(C);y(fe.$$.fragment,Pt),fr=d(Pt),V=o(Pt,"P",{});var We=n(V);pr=i(We,"Resizes "),et=o(We,"CODE",{});var Wa=n(et);ur=i(Wa,"image"),Wa.forEach(r),hr=i(We," to (h, w) specified by "),tt=o(We,"CODE",{});var Ua=n(tt);gr=i(Ua,"size"),Ua.forEach(r),_r=i(We," using the PIL library."),We.forEach(r),Pt.forEach(r),wt=d(t),W=o(t,"DIV",{class:!0});var Dt=n(W);y(pe.$$.fragment,Dt),xr=d(Dt),ue=o(Dt,"P",{});var jt=n(ue);vr=i(jt,"Converts "),rt=o(jt,"CODE",{});var Ra=n(rt);br=i(Ra,"image"),Ra.forEach(r),yr=i(jt,` to a PIL Image. Optionally rescales it and puts the channel dimension back as the last axis if
needed.`),jt.forEach(r),Dt.forEach(r),Ft=d(t),U=o(t,"H2",{class:!0});var zt=n(U);B=o(zt,"A",{id:!0,class:!0,href:!0});var Ja=n(B);at=o(Ja,"SPAN",{});var Ha=n(at);y(he.$$.fragment,Ha),Ha.forEach(r),Ja.forEach(r),$r=d(zt),ot=o(zt,"SPAN",{});var Ba=n(ot);Er=i(Ba,"ImageProcessorMixin"),Ba.forEach(r),zt.forEach(r),kt=d(t),g=o(t,"DIV",{class:!0});var v=n(g);y(ge.$$.fragment,v),wr=d(v),nt=o(v,"P",{});var Ga=n(nt);Fr=i(Ga,`This is a feature extraction mixin used to provide saving/loading functionality for sequential and image feature
extractors.`),Ga.forEach(r),kr=d(v),G=o(v,"DIV",{class:!0});var qt=n(G);y(_e.$$.fragment,qt),Tr=d(qt),xe=o(qt,"P",{});var Lt=n(xe);Ir=i(Lt,"Instantiates a type of "),qe=o(Lt,"A",{href:!0});var Ya=n(qe);Mr=i(Ya,"FeatureExtractionMixin"),Ya.forEach(r),Pr=i(Lt,` from a Python dictionary of
parameters.`),Lt.forEach(r),qt.forEach(r),Dr=d(v),Y=o(v,"DIV",{class:!0});var At=n(Y);y(ve.$$.fragment,At),jr=d(At),be=o(At,"P",{});var Ot=n(be);zr=i(Ot,"Instantiates a feature extractor of type "),Le=o(Ot,"A",{href:!0});var Ka=n(Le);qr=i(Ka,"FeatureExtractionMixin"),Ka.forEach(r),Lr=i(Ot,` from the path to
a JSON file of parameters.`),Ot.forEach(r),At.forEach(r),Ar=d(v),M=o(v,"DIV",{class:!0});var se=n(M);y(ye.$$.fragment,se),Or=d(se),j=o(se,"P",{});var ie=n(j);Sr=i(ie,"Instantiate a type of "),Ae=o(ie,"A",{href:!0});var Qa=n(Ae);Nr=i(Qa,"FeatureExtractionMixin"),Qa.forEach(r),Cr=i(ie," from a feature extractor, "),st=o(ie,"EM",{});var Xa=n(st);Vr=i(Xa,"e.g."),Xa.forEach(r),Wr=i(ie,` a
derived class of `),Oe=o(ie,"A",{href:!0});var Za=n(Oe);Ur=i(Za,"SequenceFeatureExtractor"),Za.forEach(r),Rr=i(ie,"."),ie.forEach(r),Jr=d(se),y(K.$$.fragment,se),Hr=d(se),y(Q.$$.fragment,se),se.forEach(r),Br=d(v),X=o(v,"DIV",{class:!0});var St=n(X);y($e.$$.fragment,St),Gr=d(St),z=o(St,"P",{});var ce=n(z);Yr=i(ce,"From a "),it=o(ce,"CODE",{});var eo=n(it);Kr=i(eo,"pretrained_model_name_or_path"),eo.forEach(r),Qr=i(ce,`, resolve to a dictionary of parameters, to be used for instantiating a
feature extractor of type `),Se=o(ce,"A",{href:!0});var to=n(Se);Xr=i(to,"FeatureExtractionMixin"),to.forEach(r),Zr=i(ce," using "),ct=o(ce,"CODE",{});var ro=n(ct);ea=i(ro,"from_dict"),ro.forEach(r),ta=i(ce,"."),ce.forEach(r),St.forEach(r),ra=d(v),L=o(v,"DIV",{class:!0});var Ue=n(L);y(Ee.$$.fragment,Ue),aa=d(Ue),we=o(Ue,"P",{});var Nt=n(we);oa=i(Nt,`Upload the feature extractor file to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),lt=o(Nt,"CODE",{});var ao=n(lt);na=i(ao,"repo_path_or_name"),ao.forEach(r),sa=i(Nt,"."),Nt.forEach(r),ia=d(Ue),y(Z.$$.fragment,Ue),Ue.forEach(r),ca=d(v),A=o(v,"DIV",{class:!0});var Re=n(A);y(Fe.$$.fragment,Re),la=d(Re),ke=o(Re,"P",{});var Ct=n(ke);da=i(Ct,`Register this class with a given auto class. This should only be used for custom feature extractors as the ones
in the library are already mapped with `),dt=o(Ct,"CODE",{});var oo=n(dt);ma=i(oo,"AutoFeatureExtractor"),oo.forEach(r),fa=i(Ct,"."),Ct.forEach(r),pa=d(Re),y(ee.$$.fragment,Re),Re.forEach(r),ua=d(v),te=o(v,"DIV",{class:!0});var Vt=n(te);y(Te.$$.fragment,Vt),ha=d(Vt),R=o(Vt,"P",{});var Je=n(R);ga=i(Je,"Save a feature_extractor object to the directory "),mt=o(Je,"CODE",{});var no=n(mt);_a=i(no,"save_directory"),no.forEach(r),xa=i(Je,`, so that it can be re-loaded using the
`),Ne=o(Je,"A",{href:!0});var so=n(Ne);va=i(so,"from_pretrained()"),so.forEach(r),ba=i(Je," class method."),Je.forEach(r),Vt.forEach(r),ya=d(v),re=o(v,"DIV",{class:!0});var Wt=n(re);y(Ie.$$.fragment,Wt),$a=d(Wt),ft=o(Wt,"P",{});var io=n(ft);Ea=i(io,"Serializes this instance to a Python dictionary."),io.forEach(r),Wt.forEach(r),wa=d(v),ae=o(v,"DIV",{class:!0});var Ut=n(ae);y(Me.$$.fragment,Ut),Fa=d(Ut),pt=o(Ut,"P",{});var co=n(pt);ka=i(co,"Save this instance to a JSON file."),co.forEach(r),Ut.forEach(r),Ta=d(v),oe=o(v,"DIV",{class:!0});var Rt=n(oe);y(Pe.$$.fragment,Rt),Ia=d(Rt),ut=o(Rt,"P",{});var lo=n(ut);Ma=i(lo,"Serializes this instance to a JSON string."),lo.forEach(r),Rt.forEach(r),v.forEach(r),this.h()},h(){f(m,"name","hf:doc:metadata"),f(m,"content",JSON.stringify(Fo)),f(p,"id","utilities-for-image-processors"),f(p,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(p,"href","#utilities-for-image-processors"),f(h,"class","relative group"),f(H,"id","transformers.image_transforms.normalize"),f(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(H,"href","#transformers.image_transforms.normalize"),f(O,"class","relative group"),f(P,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),f(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),f(C,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),f(W,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),f(B,"id","transformers.FeatureExtractionMixin"),f(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(B,"href","#transformers.FeatureExtractionMixin"),f(U,"class","relative group"),f(qe,"href","/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin"),f(G,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),f(Le,"href","/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin"),f(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),f(Ae,"href","/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin"),f(Oe,"href","/docs/transformers/main/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor"),f(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),f(Se,"href","/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin"),f(X,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),f(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),f(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),f(Ne,"href","/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained"),f(te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),f(re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),f(ae,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),f(oe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),f(g,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(t,u){e(document.head,m),_(t,k,u),_(t,h,u),e(h,p),e(p,T),$(c,T,null),e(h,x),e(h,J),e(J,Jt),_(t,xt,u),_(t,je,u),e(je,Ht),_(t,vt,u),_(t,ze,u),e(ze,Bt),_(t,bt,u),_(t,O,u),e(O,H),e(H,He),$(le,He,null),e(O,Gt),e(O,Be),e(Be,Yt),_(t,yt,u),_(t,P,u),$(de,P,null),e(P,Kt),e(P,D),e(D,Qt),e(D,Ge),e(Ge,Xt),e(D,Zt),e(D,Ye),e(Ye,er),e(D,tr),e(D,Ke),e(Ke,rr),e(D,ar),e(P,or),e(P,Qe),e(Qe,nr),_(t,$t,u),_(t,S,u),$(me,S,null),e(S,sr),e(S,N),e(N,ir),e(N,Xe),e(Xe,cr),e(N,lr),e(N,Ze),e(Ze,dr),e(N,mr),_(t,Et,u),_(t,C,u),$(fe,C,null),e(C,fr),e(C,V),e(V,pr),e(V,et),e(et,ur),e(V,hr),e(V,tt),e(tt,gr),e(V,_r),_(t,wt,u),_(t,W,u),$(pe,W,null),e(W,xr),e(W,ue),e(ue,vr),e(ue,rt),e(rt,br),e(ue,yr),_(t,Ft,u),_(t,U,u),e(U,B),e(B,at),$(he,at,null),e(U,$r),e(U,ot),e(ot,Er),_(t,kt,u),_(t,g,u),$(ge,g,null),e(g,wr),e(g,nt),e(nt,Fr),e(g,kr),e(g,G),$(_e,G,null),e(G,Tr),e(G,xe),e(xe,Ir),e(xe,qe),e(qe,Mr),e(xe,Pr),e(g,Dr),e(g,Y),$(ve,Y,null),e(Y,jr),e(Y,be),e(be,zr),e(be,Le),e(Le,qr),e(be,Lr),e(g,Ar),e(g,M),$(ye,M,null),e(M,Or),e(M,j),e(j,Sr),e(j,Ae),e(Ae,Nr),e(j,Cr),e(j,st),e(st,Vr),e(j,Wr),e(j,Oe),e(Oe,Ur),e(j,Rr),e(M,Jr),$(K,M,null),e(M,Hr),$(Q,M,null),e(g,Br),e(g,X),$($e,X,null),e(X,Gr),e(X,z),e(z,Yr),e(z,it),e(it,Kr),e(z,Qr),e(z,Se),e(Se,Xr),e(z,Zr),e(z,ct),e(ct,ea),e(z,ta),e(g,ra),e(g,L),$(Ee,L,null),e(L,aa),e(L,we),e(we,oa),e(we,lt),e(lt,na),e(we,sa),e(L,ia),$(Z,L,null),e(g,ca),e(g,A),$(Fe,A,null),e(A,la),e(A,ke),e(ke,da),e(ke,dt),e(dt,ma),e(ke,fa),e(A,pa),$(ee,A,null),e(g,ua),e(g,te),$(Te,te,null),e(te,ha),e(te,R),e(R,ga),e(R,mt),e(mt,_a),e(R,xa),e(R,Ne),e(Ne,va),e(R,ba),e(g,ya),e(g,re),$(Ie,re,null),e(re,$a),e(re,ft),e(ft,Ea),e(g,wa),e(g,ae),$(Me,ae,null),e(ae,Fa),e(ae,pt),e(pt,ka),e(g,Ta),e(g,oe),$(Pe,oe,null),e(oe,Ia),e(oe,ut),e(ut,Ma),Tt=!0},p(t,[u]){const De={};u&2&&(De.$$scope={dirty:u,ctx:t}),K.$set(De);const ht={};u&2&&(ht.$$scope={dirty:u,ctx:t}),Q.$set(ht);const gt={};u&2&&(gt.$$scope={dirty:u,ctx:t}),Z.$set(gt);const _t={};u&2&&(_t.$$scope={dirty:u,ctx:t}),ee.$set(_t)},i(t){Tt||(E(c.$$.fragment,t),E(le.$$.fragment,t),E(de.$$.fragment,t),E(me.$$.fragment,t),E(fe.$$.fragment,t),E(pe.$$.fragment,t),E(he.$$.fragment,t),E(ge.$$.fragment,t),E(_e.$$.fragment,t),E(ve.$$.fragment,t),E(ye.$$.fragment,t),E(K.$$.fragment,t),E(Q.$$.fragment,t),E($e.$$.fragment,t),E(Ee.$$.fragment,t),E(Z.$$.fragment,t),E(Fe.$$.fragment,t),E(ee.$$.fragment,t),E(Te.$$.fragment,t),E(Ie.$$.fragment,t),E(Me.$$.fragment,t),E(Pe.$$.fragment,t),Tt=!0)},o(t){w(c.$$.fragment,t),w(le.$$.fragment,t),w(de.$$.fragment,t),w(me.$$.fragment,t),w(fe.$$.fragment,t),w(pe.$$.fragment,t),w(he.$$.fragment,t),w(ge.$$.fragment,t),w(_e.$$.fragment,t),w(ve.$$.fragment,t),w(ye.$$.fragment,t),w(K.$$.fragment,t),w(Q.$$.fragment,t),w($e.$$.fragment,t),w(Ee.$$.fragment,t),w(Z.$$.fragment,t),w(Fe.$$.fragment,t),w(ee.$$.fragment,t),w(Te.$$.fragment,t),w(Ie.$$.fragment,t),w(Me.$$.fragment,t),w(Pe.$$.fragment,t),Tt=!1},d(t){r(m),t&&r(k),t&&r(h),F(c),t&&r(xt),t&&r(je),t&&r(vt),t&&r(ze),t&&r(bt),t&&r(O),F(le),t&&r(yt),t&&r(P),F(de),t&&r($t),t&&r(S),F(me),t&&r(Et),t&&r(C),F(fe),t&&r(wt),t&&r(W),F(pe),t&&r(Ft),t&&r(U),F(he),t&&r(kt),t&&r(g),F(ge),F(_e),F(ve),F(ye),F(K),F(Q),F($e),F(Ee),F(Z),F(Fe),F(ee),F(Te),F(Ie),F(Me),F(Pe)}}}const Fo={local:"utilities-for-image-processors",sections:[{local:"transformers.image_transforms.normalize",title:"Image Transformations"},{local:"transformers.FeatureExtractionMixin",title:"ImageProcessorMixin"}],title:"Utilities for Image Processors"};function ko(q){return vo(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class zo extends ho{constructor(m){super();go(this,m,ko,wo,_o,{})}}export{zo as default,Fo as metadata};
