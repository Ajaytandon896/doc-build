import{S as Np,i as Dp,s as Hp,e as l,k as h,w as b,t as o,M as Lp,c as i,d as s,m as d,a as f,x as A,h as n,b as $,G as t,g as u,y as E,q as T,o as j,B as x,v as Wp,L as ge}from"../chunks/vendor-hf-doc-builder.js";import{T as Ks}from"../chunks/Tip-hf-doc-builder.js";import{Y as Op}from"../chunks/Youtube-hf-doc-builder.js";import{I as Me}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as L}from"../chunks/CodeBlock-hf-doc-builder.js";import{D as Up}from"../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as rs,M as ce}from"../chunks/Markdown-hf-doc-builder.js";function Rp(P){let a,m;return{c(){a=l("p"),m=o(`All code examples presented in the documentation have a toggle on the top left for PyTorch and TensorFlow. If
not, the code is expected to work for both backends without any change.`)},l(r){a=i(r,"P",{});var c=f(a);m=n(c,`All code examples presented in the documentation have a toggle on the top left for PyTorch and TensorFlow. If
not, the code is expected to work for both backends without any change.`),c.forEach(s)},m(r,c){u(r,a,c),t(a,m)},d(r){r&&s(a)}}}function Gp(P){let a,m,r,c,_,w,k,F;return{c(){a=l("p"),m=o("For more details about the "),r=l("a"),c=o("pipeline()"),_=o(" and associated tasks, refer to the documentation "),w=l("a"),k=o("here"),F=o("."),this.h()},l(g){a=i(g,"P",{});var y=f(a);m=n(y,"For more details about the "),r=i(y,"A",{href:!0});var I=f(r);c=n(I,"pipeline()"),I.forEach(s),_=n(y," and associated tasks, refer to the documentation "),w=i(y,"A",{href:!0});var O=f(w);k=n(O,"here"),O.forEach(s),F=n(y,"."),y.forEach(s),this.h()},h(){$(r,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),$(w,"href","./main_classes/pipelines")},m(g,y){u(g,a,y),t(a,m),t(a,r),t(r,c),t(a,_),t(a,w),t(w,k),t(a,F)},d(g){g&&s(a)}}}function Yp(P){let a,m;return a=new L({props:{code:"pip install torch",highlighted:"pip install torch"}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p:ge,i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function Jp(P){let a,m;return a=new ce({props:{$$slots:{default:[Yp]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function Qp(P){let a,m;return a=new L({props:{code:"pip install tensorflow",highlighted:"pip install tensorflow"}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p:ge,i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function Vp(P){let a,m;return a=new ce({props:{$$slots:{default:[Qp]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function Bp(P){let a,m,r,c,_,w,k,F,g,y,I,O,D,W;return D=new L({props:{code:`from transformers import AutoTokenizer, AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){a=l("p"),m=o("Use the "),r=l("a"),c=o("AutoModelForSequenceClassification"),_=o(" and "),w=l("a"),k=o("AutoTokenizer"),F=o(" to load the pretrained model and it\u2019s associated tokenizer (more on an "),g=l("code"),y=o("AutoClass"),I=o(" below):"),O=h(),b(D.$$.fragment),this.h()},l(z){a=i(z,"P",{});var C=f(a);m=n(C,"Use the "),r=i(C,"A",{href:!0});var v=f(r);c=n(v,"AutoModelForSequenceClassification"),v.forEach(s),_=n(C," and "),w=i(C,"A",{href:!0});var S=f(w);k=n(S,"AutoTokenizer"),S.forEach(s),F=n(C," to load the pretrained model and it\u2019s associated tokenizer (more on an "),g=i(C,"CODE",{});var R=f(g);y=n(R,"AutoClass"),R.forEach(s),I=n(C," below):"),C.forEach(s),O=d(z),A(D.$$.fragment,z),this.h()},h(){$(r,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSequenceClassification"),$(w,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer")},m(z,C){u(z,a,C),t(a,m),t(a,r),t(r,c),t(a,_),t(a,w),t(w,k),t(a,F),t(a,g),t(g,y),t(a,I),u(z,O,C),E(D,z,C),W=!0},p:ge,i(z){W||(T(D.$$.fragment,z),W=!0)},o(z){j(D.$$.fragment,z),W=!1},d(z){z&&s(a),z&&s(O),x(D,z)}}}function Kp(P){let a,m;return a=new ce({props:{$$slots:{default:[Bp]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function Zp(P){let a,m,r,c,_,w,k,F,g,y,I,O,D,W;return D=new L({props:{code:`from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){a=l("p"),m=o("Use the "),r=l("a"),c=o("TFAutoModelForSequenceClassification"),_=o(" and "),w=l("a"),k=o("AutoTokenizer"),F=o(" to load the pretrained model and it\u2019s associated tokenizer (more on an "),g=l("code"),y=o("TFAutoClass"),I=o(" below):"),O=h(),b(D.$$.fragment),this.h()},l(z){a=i(z,"P",{});var C=f(a);m=n(C,"Use the "),r=i(C,"A",{href:!0});var v=f(r);c=n(v,"TFAutoModelForSequenceClassification"),v.forEach(s),_=n(C," and "),w=i(C,"A",{href:!0});var S=f(w);k=n(S,"AutoTokenizer"),S.forEach(s),F=n(C," to load the pretrained model and it\u2019s associated tokenizer (more on an "),g=i(C,"CODE",{});var R=f(g);y=n(R,"TFAutoClass"),R.forEach(s),I=n(C," below):"),C.forEach(s),O=d(z),A(D.$$.fragment,z),this.h()},h(){$(r,"href","/docs/transformers/main/en/model_doc/auto#transformers.TFAutoModelForSequenceClassification"),$(w,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer")},m(z,C){u(z,a,C),t(a,m),t(a,r),t(r,c),t(a,_),t(a,w),t(w,k),t(a,F),t(a,g),t(g,y),t(a,I),u(z,O,C),E(D,z,C),W=!0},p:ge,i(z){W||(T(D.$$.fragment,z),W=!0)},o(z){j(D.$$.fragment,z),W=!1},d(z){z&&s(a),z&&s(O),x(D,z)}}}function Xp(P){let a,m;return a=new ce({props:{$$slots:{default:[Zp]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function eu(P){let a,m;return a=new L({props:{code:`pt_batch = tokenizer(
    ["We are very happy to show you the \u{1F917} Transformers library.", "We hope you don't hate it."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="pt",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;pt&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p:ge,i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function tu(P){let a,m;return a=new ce({props:{$$slots:{default:[eu]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function su(P){let a,m;return a=new L({props:{code:`tf_batch = tokenizer(
    ["We are very happy to show you the \u{1F917} Transformers library.", "We hope you don't hate it."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="tf",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;tf&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p:ge,i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function au(P){let a,m;return a=new ce({props:{$$slots:{default:[su]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function ru(P){let a,m,r,c,_,w,k,F;return{c(){a=l("p"),m=o("See the "),r=l("a"),c=o("task summary"),_=o(" for which "),w=l("a"),k=o("AutoModel"),F=o(" class to use for which task."),this.h()},l(g){a=i(g,"P",{});var y=f(a);m=n(y,"See the "),r=i(y,"A",{href:!0});var I=f(r);c=n(I,"task summary"),I.forEach(s),_=n(y," for which "),w=i(y,"A",{href:!0});var O=f(w);k=n(O,"AutoModel"),O.forEach(s),F=n(y," class to use for which task."),y.forEach(s),this.h()},h(){$(r,"href","./task_summary"),$(w,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel")},m(g,y){u(g,a,y),t(a,m),t(a,r),t(r,c),t(a,_),t(a,w),t(w,k),t(a,F)},d(g){g&&s(a)}}}function ou(P){let a,m,r,c,_,w,k,F,g,y,I,O,D,W,z,C,v,S,R,U,Q,J,se,V,G,ee,B,K,he,re,$e,oe,te,ne,_e,M,N,le;return C=new L({props:{code:`from transformers import AutoModelForSequenceClassification

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`}}),S=new Ks({props:{$$slots:{default:[ru]},$$scope:{ctx:P}}}),ee=new L({props:{code:"pt_outputs = pt_model(**pt_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_outputs = pt_model(**pt_batch)'}}),N=new L({props:{code:`from torch import nn

pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)
print(pt_predictions)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn

<span class="hljs-meta">&gt;&gt;&gt; </span>pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(pt_predictions)
tensor([[<span class="hljs-number">0.0021</span>, <span class="hljs-number">0.0018</span>, <span class="hljs-number">0.0115</span>, <span class="hljs-number">0.2121</span>, <span class="hljs-number">0.7725</span>],
        [<span class="hljs-number">0.2084</span>, <span class="hljs-number">0.1826</span>, <span class="hljs-number">0.1969</span>, <span class="hljs-number">0.1755</span>, <span class="hljs-number">0.2365</span>]], grad_fn=&lt;SoftmaxBackward0&gt;)`}}),{c(){a=l("p"),m=o("\u{1F917} Transformers provides a simple and unified way to load pretrained instances. This means you can load an "),r=l("a"),c=o("AutoModel"),_=o(" like you would load an "),w=l("a"),k=o("AutoTokenizer"),F=o(". The only difference is selecting the correct "),g=l("a"),y=o("AutoModel"),I=o(" for the task. Since you are doing text - or sequence - classification, load "),O=l("a"),D=o("AutoModelForSequenceClassification"),W=o(":"),z=h(),b(C.$$.fragment),v=h(),b(S.$$.fragment),R=h(),U=l("p"),Q=o("Now you can pass your preprocessed batch of inputs directly to the model. You just have to unpack the dictionary by adding "),J=l("code"),se=o("**"),V=o(":"),G=h(),b(ee.$$.fragment),B=h(),K=l("p"),he=o("The model outputs the final activations in the "),re=l("code"),$e=o("logits"),oe=o(" attribute. Apply the softmax function to the "),te=l("code"),ne=o("logits"),_e=o(" to retrieve the probabilities:"),M=h(),b(N.$$.fragment),this.h()},l(q){a=i(q,"P",{});var H=f(a);m=n(H,"\u{1F917} Transformers provides a simple and unified way to load pretrained instances. This means you can load an "),r=i(H,"A",{href:!0});var ie=f(r);c=n(ie,"AutoModel"),ie.forEach(s),_=n(H," like you would load an "),w=i(H,"A",{href:!0});var Fe=f(w);k=n(Fe,"AutoTokenizer"),Fe.forEach(s),F=n(H,". The only difference is selecting the correct "),g=i(H,"A",{href:!0});var de=f(g);y=n(de,"AutoModel"),de.forEach(s),I=n(H," for the task. Since you are doing text - or sequence - classification, load "),O=i(H,"A",{href:!0});var we=f(O);D=n(we,"AutoModelForSequenceClassification"),we.forEach(s),W=n(H,":"),H.forEach(s),z=d(q),A(C.$$.fragment,q),v=d(q),A(S.$$.fragment,q),R=d(q),U=i(q,"P",{});var fe=f(U);Q=n(fe,"Now you can pass your preprocessed batch of inputs directly to the model. You just have to unpack the dictionary by adding "),J=i(fe,"CODE",{});var Ue=f(J);se=n(Ue,"**"),Ue.forEach(s),V=n(fe,":"),fe.forEach(s),G=d(q),A(ee.$$.fragment,q),B=d(q),K=i(q,"P",{});var ve=f(K);he=n(ve,"The model outputs the final activations in the "),re=i(ve,"CODE",{});var os=f(re);$e=n(os,"logits"),os.forEach(s),oe=n(ve," attribute. Apply the softmax function to the "),te=i(ve,"CODE",{});var yt=f(te);ne=n(yt,"logits"),yt.forEach(s),_e=n(ve," to retrieve the probabilities:"),ve.forEach(s),M=d(q),A(N.$$.fragment,q),this.h()},h(){$(r,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),$(w,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),$(g,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),$(O,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSequenceClassification")},m(q,H){u(q,a,H),t(a,m),t(a,r),t(r,c),t(a,_),t(a,w),t(w,k),t(a,F),t(a,g),t(g,y),t(a,I),t(a,O),t(O,D),t(a,W),u(q,z,H),E(C,q,H),u(q,v,H),E(S,q,H),u(q,R,H),u(q,U,H),t(U,Q),t(U,J),t(J,se),t(U,V),u(q,G,H),E(ee,q,H),u(q,B,H),u(q,K,H),t(K,he),t(K,re),t(re,$e),t(K,oe),t(K,te),t(te,ne),t(K,_e),u(q,M,H),E(N,q,H),le=!0},p(q,H){const ie={};H&2&&(ie.$$scope={dirty:H,ctx:q}),S.$set(ie)},i(q){le||(T(C.$$.fragment,q),T(S.$$.fragment,q),T(ee.$$.fragment,q),T(N.$$.fragment,q),le=!0)},o(q){j(C.$$.fragment,q),j(S.$$.fragment,q),j(ee.$$.fragment,q),j(N.$$.fragment,q),le=!1},d(q){q&&s(a),q&&s(z),x(C,q),q&&s(v),x(S,q),q&&s(R),q&&s(U),q&&s(G),x(ee,q),q&&s(B),q&&s(K),q&&s(M),x(N,q)}}}function nu(P){let a,m;return a=new ce({props:{$$slots:{default:[ou]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function lu(P){let a,m,r,c,_,w,k,F;return{c(){a=l("p"),m=o("See the "),r=l("a"),c=o("task summary"),_=o(" for which "),w=l("a"),k=o("AutoModel"),F=o(" class to use for which task."),this.h()},l(g){a=i(g,"P",{});var y=f(a);m=n(y,"See the "),r=i(y,"A",{href:!0});var I=f(r);c=n(I,"task summary"),I.forEach(s),_=n(y," for which "),w=i(y,"A",{href:!0});var O=f(w);k=n(O,"AutoModel"),O.forEach(s),F=n(y," class to use for which task."),y.forEach(s),this.h()},h(){$(r,"href","./task_summary"),$(w,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel")},m(g,y){u(g,a,y),t(a,m),t(a,r),t(r,c),t(a,_),t(a,w),t(w,k),t(a,F)},d(g){g&&s(a)}}}function iu(P){let a,m,r,c,_,w,k,F,g,y,I,O,D,W,z,C,v,S,R,U,Q,J,se,V,G,ee,B,K,he,re,$e,oe,te,ne,_e;return C=new L({props:{code:`from transformers import TFAutoModelForSequenceClassification

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)`}}),S=new Ks({props:{$$slots:{default:[lu]},$$scope:{ctx:P}}}),se=new L({props:{code:"tf_outputs = tf_model(tf_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_outputs = tf_model(tf_batch)'}}),ne=new L({props:{code:`import tensorflow as tf

tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)
tf_predictions`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions`}}),{c(){a=l("p"),m=o("\u{1F917} Transformers provides a simple and unified way to load pretrained instances. This means you can load an "),r=l("a"),c=o("TFAutoModel"),_=o(" like you would load an "),w=l("a"),k=o("AutoTokenizer"),F=o(". The only difference is selecting the correct "),g=l("a"),y=o("TFAutoModel"),I=o(" for the task. Since you are doing text - or sequence - classification, load "),O=l("a"),D=o("TFAutoModelForSequenceClassification"),W=o(":"),z=h(),b(C.$$.fragment),v=h(),b(S.$$.fragment),R=h(),U=l("p"),Q=o("Now you can pass your preprocessed batch of inputs directly to the model by passing the dictionary keys directly to the tensors:"),J=h(),b(se.$$.fragment),V=h(),G=l("p"),ee=o("The model outputs the final activations in the "),B=l("code"),K=o("logits"),he=o(" attribute. Apply the softmax function to the "),re=l("code"),$e=o("logits"),oe=o(" to retrieve the probabilities:"),te=h(),b(ne.$$.fragment),this.h()},l(M){a=i(M,"P",{});var N=f(a);m=n(N,"\u{1F917} Transformers provides a simple and unified way to load pretrained instances. This means you can load an "),r=i(N,"A",{href:!0});var le=f(r);c=n(le,"TFAutoModel"),le.forEach(s),_=n(N," like you would load an "),w=i(N,"A",{href:!0});var q=f(w);k=n(q,"AutoTokenizer"),q.forEach(s),F=n(N,". The only difference is selecting the correct "),g=i(N,"A",{href:!0});var H=f(g);y=n(H,"TFAutoModel"),H.forEach(s),I=n(N," for the task. Since you are doing text - or sequence - classification, load "),O=i(N,"A",{href:!0});var ie=f(O);D=n(ie,"TFAutoModelForSequenceClassification"),ie.forEach(s),W=n(N,":"),N.forEach(s),z=d(M),A(C.$$.fragment,M),v=d(M),A(S.$$.fragment,M),R=d(M),U=i(M,"P",{});var Fe=f(U);Q=n(Fe,"Now you can pass your preprocessed batch of inputs directly to the model by passing the dictionary keys directly to the tensors:"),Fe.forEach(s),J=d(M),A(se.$$.fragment,M),V=d(M),G=i(M,"P",{});var de=f(G);ee=n(de,"The model outputs the final activations in the "),B=i(de,"CODE",{});var we=f(B);K=n(we,"logits"),we.forEach(s),he=n(de," attribute. Apply the softmax function to the "),re=i(de,"CODE",{});var fe=f(re);$e=n(fe,"logits"),fe.forEach(s),oe=n(de," to retrieve the probabilities:"),de.forEach(s),te=d(M),A(ne.$$.fragment,M),this.h()},h(){$(r,"href","/docs/transformers/main/en/model_doc/auto#transformers.TFAutoModel"),$(w,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),$(g,"href","/docs/transformers/main/en/model_doc/auto#transformers.TFAutoModel"),$(O,"href","/docs/transformers/main/en/model_doc/auto#transformers.TFAutoModelForSequenceClassification")},m(M,N){u(M,a,N),t(a,m),t(a,r),t(r,c),t(a,_),t(a,w),t(w,k),t(a,F),t(a,g),t(g,y),t(a,I),t(a,O),t(O,D),t(a,W),u(M,z,N),E(C,M,N),u(M,v,N),E(S,M,N),u(M,R,N),u(M,U,N),t(U,Q),u(M,J,N),E(se,M,N),u(M,V,N),u(M,G,N),t(G,ee),t(G,B),t(B,K),t(G,he),t(G,re),t(re,$e),t(G,oe),u(M,te,N),E(ne,M,N),_e=!0},p(M,N){const le={};N&2&&(le.$$scope={dirty:N,ctx:M}),S.$set(le)},i(M){_e||(T(C.$$.fragment,M),T(S.$$.fragment,M),T(se.$$.fragment,M),T(ne.$$.fragment,M),_e=!0)},o(M){j(C.$$.fragment,M),j(S.$$.fragment,M),j(se.$$.fragment,M),j(ne.$$.fragment,M),_e=!1},d(M){M&&s(a),M&&s(z),x(C,M),M&&s(v),x(S,M),M&&s(R),M&&s(U),M&&s(J),x(se,M),M&&s(V),M&&s(G),M&&s(te),x(ne,M)}}}function fu(P){let a,m;return a=new ce({props:{$$slots:{default:[iu]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function pu(P){let a,m,r,c,_;return{c(){a=l("p"),m=o("All \u{1F917} Transformers models (PyTorch or TensorFlow) outputs the tensors "),r=l("em"),c=o("before"),_=o(` the final activation
function (like softmax) because the final activation function is often fused with the loss.`)},l(w){a=i(w,"P",{});var k=f(a);m=n(k,"All \u{1F917} Transformers models (PyTorch or TensorFlow) outputs the tensors "),r=i(k,"EM",{});var F=f(r);c=n(F,"before"),F.forEach(s),_=n(k,` the final activation
function (like softmax) because the final activation function is often fused with the loss.`),k.forEach(s)},m(w,k){u(w,a,k),t(a,m),t(a,r),t(r,c),t(a,_)},d(w){w&&s(a)}}}function uu(P){let a,m,r,c,_;return{c(){a=l("p"),m=o(`\u{1F917} Transformers model outputs are special dataclasses so their attributes are autocompleted in an IDE.
The model outputs also behave like a tuple or a dictionary (e.g., you can index with an integer, a slice or a string) in which case the attributes that are `),r=l("code"),c=o("None"),_=o(" are ignored.")},l(w){a=i(w,"P",{});var k=f(a);m=n(k,`\u{1F917} Transformers model outputs are special dataclasses so their attributes are autocompleted in an IDE.
The model outputs also behave like a tuple or a dictionary (e.g., you can index with an integer, a slice or a string) in which case the attributes that are `),r=i(k,"CODE",{});var F=f(r);c=n(F,"None"),F.forEach(s),_=n(k," are ignored."),k.forEach(s)},m(w,k){u(w,a,k),t(a,m),t(a,r),t(r,c),t(a,_)},d(w){w&&s(a)}}}function mu(P){let a,m,r,c,_,w,k,F,g,y,I,O,D,W,z,C;return k=new L({props:{code:`pt_save_directory = "./pt_save_pretrained"
tokenizer.save_pretrained(pt_save_directory)
pt_model.save_pretrained(pt_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_save_directory = <span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(pt_save_directory)`}}),z=new L({props:{code:'pt_model = AutoModelForSequenceClassification.from_pretrained("./pt_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>)'}}),{c(){a=l("p"),m=o("Once your model is fine-tuned, you can save it with its tokenizer using "),r=l("a"),c=o("PreTrainedModel.save_pretrained()"),_=o(":"),w=h(),b(k.$$.fragment),F=h(),g=l("p"),y=o("When you are ready to use the model again, reload it with "),I=l("a"),O=o("PreTrainedModel.from_pretrained()"),D=o(":"),W=h(),b(z.$$.fragment),this.h()},l(v){a=i(v,"P",{});var S=f(a);m=n(S,"Once your model is fine-tuned, you can save it with its tokenizer using "),r=i(S,"A",{href:!0});var R=f(r);c=n(R,"PreTrainedModel.save_pretrained()"),R.forEach(s),_=n(S,":"),S.forEach(s),w=d(v),A(k.$$.fragment,v),F=d(v),g=i(v,"P",{});var U=f(g);y=n(U,"When you are ready to use the model again, reload it with "),I=i(U,"A",{href:!0});var Q=f(I);O=n(Q,"PreTrainedModel.from_pretrained()"),Q.forEach(s),D=n(U,":"),U.forEach(s),W=d(v),A(z.$$.fragment,v),this.h()},h(){$(r,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained"),$(I,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained")},m(v,S){u(v,a,S),t(a,m),t(a,r),t(r,c),t(a,_),u(v,w,S),E(k,v,S),u(v,F,S),u(v,g,S),t(g,y),t(g,I),t(I,O),t(g,D),u(v,W,S),E(z,v,S),C=!0},p:ge,i(v){C||(T(k.$$.fragment,v),T(z.$$.fragment,v),C=!0)},o(v){j(k.$$.fragment,v),j(z.$$.fragment,v),C=!1},d(v){v&&s(a),v&&s(w),x(k,v),v&&s(F),v&&s(g),v&&s(W),x(z,v)}}}function cu(P){let a,m;return a=new ce({props:{$$slots:{default:[mu]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function hu(P){let a,m,r,c,_,w,k,F,g,y,I,O,D,W,z,C;return k=new L({props:{code:`tf_save_directory = "./tf_save_pretrained"
tokenizer.save_pretrained(tf_save_directory)
tf_model.save_pretrained(tf_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_save_directory = <span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(tf_save_directory)`}}),z=new L({props:{code:'tf_model = TFAutoModelForSequenceClassification.from_pretrained("./tf_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>)'}}),{c(){a=l("p"),m=o("Once your model is fine-tuned, you can save it with its tokenizer using "),r=l("a"),c=o("TFPreTrainedModel.save_pretrained()"),_=o(":"),w=h(),b(k.$$.fragment),F=h(),g=l("p"),y=o("When you are ready to use the model again, reload it with "),I=l("a"),O=o("TFPreTrainedModel.from_pretrained()"),D=o(":"),W=h(),b(z.$$.fragment),this.h()},l(v){a=i(v,"P",{});var S=f(a);m=n(S,"Once your model is fine-tuned, you can save it with its tokenizer using "),r=i(S,"A",{href:!0});var R=f(r);c=n(R,"TFPreTrainedModel.save_pretrained()"),R.forEach(s),_=n(S,":"),S.forEach(s),w=d(v),A(k.$$.fragment,v),F=d(v),g=i(v,"P",{});var U=f(g);y=n(U,"When you are ready to use the model again, reload it with "),I=i(U,"A",{href:!0});var Q=f(I);O=n(Q,"TFPreTrainedModel.from_pretrained()"),Q.forEach(s),D=n(U,":"),U.forEach(s),W=d(v),A(z.$$.fragment,v),this.h()},h(){$(r,"href","/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.save_pretrained"),$(I,"href","/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained")},m(v,S){u(v,a,S),t(a,m),t(a,r),t(r,c),t(a,_),u(v,w,S),E(k,v,S),u(v,F,S),u(v,g,S),t(g,y),t(g,I),t(I,O),t(g,D),u(v,W,S),E(z,v,S),C=!0},p:ge,i(v){C||(T(k.$$.fragment,v),T(z.$$.fragment,v),C=!0)},o(v){j(k.$$.fragment,v),j(z.$$.fragment,v),C=!1},d(v){v&&s(a),v&&s(w),x(k,v),v&&s(F),v&&s(g),v&&s(W),x(z,v)}}}function du(P){let a,m;return a=new ce({props:{$$slots:{default:[hu]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function $u(P){let a,m;return a=new L({props:{code:`from transformers import AutoModel

tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=<span class="hljs-literal">True</span>)`}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p:ge,i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function _u(P){let a,m;return a=new ce({props:{$$slots:{default:[$u]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function gu(P){let a,m;return a=new L({props:{code:`from transformers import TFAutoModel

tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=<span class="hljs-literal">True</span>)`}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p:ge,i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function wu(P){let a,m;return a=new ce({props:{$$slots:{default:[gu]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function vu(P){let a,m,r,c,_,w,k,F;return k=new L({props:{code:`from transformers import AutoModel

my_model = AutoModel.from_config(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_model = AutoModel.from_config(my_config)`}}),{c(){a=l("p"),m=o("Create a model from your custom configuration with "),r=l("a"),c=o("AutoModel.from_config()"),_=o(":"),w=h(),b(k.$$.fragment),this.h()},l(g){a=i(g,"P",{});var y=f(a);m=n(y,"Create a model from your custom configuration with "),r=i(y,"A",{href:!0});var I=f(r);c=n(I,"AutoModel.from_config()"),I.forEach(s),_=n(y,":"),y.forEach(s),w=d(g),A(k.$$.fragment,g),this.h()},h(){$(r,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config")},m(g,y){u(g,a,y),t(a,m),t(a,r),t(r,c),t(a,_),u(g,w,y),E(k,g,y),F=!0},p:ge,i(g){F||(T(k.$$.fragment,g),F=!0)},o(g){j(k.$$.fragment,g),F=!1},d(g){g&&s(a),g&&s(w),x(k,g)}}}function ku(P){let a,m;return a=new ce({props:{$$slots:{default:[vu]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function yu(P){let a,m,r,c,_,w,k,F;return k=new L({props:{code:`from transformers import TFAutoModel

my_model = TFAutoModel.from_config(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_model = TFAutoModel.from_config(my_config)`}}),{c(){a=l("p"),m=o("Create a model from your custom configuration with "),r=l("a"),c=o("TFAutoModel.from_config()"),_=o(":"),w=h(),b(k.$$.fragment),this.h()},l(g){a=i(g,"P",{});var y=f(a);m=n(y,"Create a model from your custom configuration with "),r=i(y,"A",{href:!0});var I=f(r);c=n(I,"TFAutoModel.from_config()"),I.forEach(s),_=n(y,":"),y.forEach(s),w=d(g),A(k.$$.fragment,g),this.h()},h(){$(r,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config")},m(g,y){u(g,a,y),t(a,m),t(a,r),t(r,c),t(a,_),u(g,w,y),E(k,g,y),F=!0},p:ge,i(g){F||(T(k.$$.fragment,g),F=!0)},o(g){j(k.$$.fragment,g),F=!1},d(g){g&&s(a),g&&s(w),x(k,g)}}}function bu(P){let a,m;return a=new ce({props:{$$slots:{default:[yu]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function Au(P){let a,m,r,c,_,w,k,F,g,y,I,O,D,W,z,C,v,S,R,U,Q,J,se,V,G,ee,B,K,he,re,$e,oe,te,ne,_e,M,N,le,q,H,ie,Fe,de,we,fe,Ue,ve,os,yt,Y,Zs,Fo,So,Xs,Co,Io,ea,Oo,No,ta,Do,Ho,sa,Lo,Wo,aa,Uo,Ro,ra,Go,Yo,oa,Jo,Ba,bt,na,Qo,Vo,Ka,ke,la,Bo,Ko,ia,Zo,Xo,fa,en,Za,At,pa,tn,sn,Xa,Re,ua,an,rn,ma,on,er,Ge,tr,Se,Ye,ca,Et,nn,ha,ln,sr,Je,fn,ns,pn,un,ar,ls,mn,rr,Qe,or,Ve,cn,is,hn,dn,nr,Tt,lr,ye,$n,jt,_n,gn,da,wn,vn,ir,xt,fr,Be,kn,fs,yn,bn,pr,qt,ur,be,An,ps,En,Tn,zt,jn,xn,mr,Pt,cr,Ke,qn,us,zn,Pn,hr,Mt,dr,Ae,Mn,Ft,Fn,Sn,St,Cn,In,$r,Ct,_r,Ze,On,$a,Nn,Dn,gr,It,wr,Xe,Hn,_a,Ln,Wn,vr,Ot,kr,et,Un,ms,Rn,Gn,yr,Ce,tt,ga,Nt,Yn,wa,Jn,br,pe,Qn,cs,Vn,Bn,Dt,Kn,Zn,hs,Xn,el,Ht,tl,sl,Ar,Lt,Er,st,Tr,Ee,al,ds,rl,ol,va,nl,ll,jr,Wt,xr,Te,il,$s,fl,pl,_s,ul,ml,qr,Ie,at,ka,Ut,cl,ya,hl,zr,Rt,Pr,Z,dl,gs,$l,_l,ws,gl,wl,vs,vl,kl,ks,yl,bl,ba,Al,El,ys,Tl,jl,Mr,je,xl,Aa,ql,zl,bs,Pl,Ml,Fr,Oe,rt,Ea,Gt,Fl,Ta,Sl,Sr,xe,Cl,ja,Il,Ol,As,Nl,Dl,Cr,ot,Hl,Es,Ll,Wl,Ir,Yt,Or,nt,Ul,xa,Rl,Gl,Nr,Ts,Yl,Dr,Jt,Hr,js,Jl,Lr,lt,xs,qs,Ql,Vl,Bl,zs,Ps,Kl,Zl,Wr,it,Xl,Ms,ei,ti,Ur,ft,Rr,pt,si,Fs,ai,ri,Gr,Ne,ut,qa,Qt,oi,za,ni,Yr,mt,Jr,ct,Qr,X,li,Vt,Pa,ii,fi,Bt,Ma,pi,ui,Ss,mi,ci,Fa,hi,di,Kt,$i,_i,Cs,gi,wi,Vr,ht,Br,De,dt,Sa,Zt,vi,Ca,ki,Kr,$t,Zr,qe,yi,Ia,bi,Ai,Oa,Ei,Ti,Xr,_t,eo,He,gt,Na,Xt,ji,Da,xi,to,Is,qi,so,ze,zi,Os,Pi,Mi,Ns,Fi,Si,ao,es,ro,wt,oo,vt,Ci,Ds,Ii,Oi,no,Le,kt,Ha,ts,Ni,La,Di,lo,Hs,Hi,io;return w=new Me({}),I=new Up({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/quicktour.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/quicktour.ipynb"}]}}),J=new Ks({props:{$$slots:{default:[Rp]},$$scope:{ctx:P}}}),B=new Me({}),N=new Op({props:{id:"tiZFewofSLM"}}),Ge=new Ks({props:{$$slots:{default:[Gp]},$$scope:{ctx:P}}}),Et=new Me({}),Qe=new rs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Vp],pytorch:[Jp]},$$scope:{ctx:P}}}),Tt=new L({props:{code:`from transformers import pipeline

classifier = pipeline("sentiment-analysis")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>)`}}),xt=new L({props:{code:'classifier("We are very happy to show you the \u{1F917} Transformers library.")',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;POSITIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9998</span>}]`}}),qt=new L({props:{code:`results = classifier(["We are very happy to show you the \u{1F917} Transformers library.", "We hope you don't hate it."])
for result in results:
    print(f"label: {result['label']}, with score: {round(result['score'], 4)}")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>results = classifier([<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> result <span class="hljs-keyword">in</span> results:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;label: <span class="hljs-subst">{result[<span class="hljs-string">&#x27;label&#x27;</span>]}</span>, with score: <span class="hljs-subst">{<span class="hljs-built_in">round</span>(result[<span class="hljs-string">&#x27;score&#x27;</span>], <span class="hljs-number">4</span>)}</span>&quot;</span>)
label: POSITIVE, <span class="hljs-keyword">with</span> score: <span class="hljs-number">0.9998</span>
label: NEGATIVE, <span class="hljs-keyword">with</span> score: <span class="hljs-number">0.5309</span>`}}),Pt=new L({props:{code:"pip install datasets ",highlighted:"pip install datasets "}}),Mt=new L({props:{code:`import torch
from transformers import pipeline

speech_recognizer = pipeline("automatic-speech-recognition", model="facebook/wav2vec2-base-960h")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>speech_recognizer = pipeline(<span class="hljs-string">&quot;automatic-speech-recognition&quot;</span>, model=<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)`}}),Ct=new L({props:{code:`from datasets import load_dataset, Audio

dataset = load_dataset("PolyAI/minds14", name="en-US", split="train")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`}}),It=new L({props:{code:'dataset = dataset.cast_column("audio", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))'}}),Ot=new L({props:{code:`result = speech_recognizer(dataset[:4]["audio"])
print([d["text"] for d in result])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>result = speech_recognizer(dataset[:<span class="hljs-number">4</span>][<span class="hljs-string">&quot;audio&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>([d[<span class="hljs-string">&quot;text&quot;</span>] <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> result])
[<span class="hljs-string">&#x27;I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT&#x27;</span>, <span class="hljs-string">&quot;FODING HOW I&#x27;D SET UP A JOIN TO HET WITH MY WIFE AND WHERE THE AP MIGHT BE&quot;</span>, <span class="hljs-string">&quot;I I&#x27;D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I&#x27;M NOT SEEING THE OPTION TO DO IT ON THE AP SO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AND I&#x27;M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS&quot;</span>, <span class="hljs-string">&#x27;HOW DO I THURN A JOIN A COUNT&#x27;</span>]`}}),Nt=new Me({}),Lt=new L({props:{code:'model_name = "nlptown/bert-base-multilingual-uncased-sentiment"',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>'}}),st=new rs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Xp],pytorch:[Kp]},$$scope:{ctx:P}}}),Wt=new L({props:{code:`classifier = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
classifier("Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=model, tokenizer=tokenizer)
<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;5 stars&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.7273</span>}]`}}),Ut=new Me({}),Rt=new Op({props:{id:"AhChOFRegn4"}}),Gt=new Me({}),Yt=new L({props:{code:`from transformers import AutoTokenizer

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),Jt=new L({props:{code:`encoding = tokenizer("We are very happy to show you the \u{1F917} Transformers library.")
print(encoding)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoding = tokenizer(<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoding)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">11312</span>, <span class="hljs-number">10320</span>, <span class="hljs-number">12495</span>, <span class="hljs-number">19308</span>, <span class="hljs-number">10114</span>, <span class="hljs-number">11391</span>, <span class="hljs-number">10855</span>, <span class="hljs-number">10103</span>, <span class="hljs-number">100</span>, <span class="hljs-number">58263</span>, <span class="hljs-number">13299</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),ft=new rs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[au],pytorch:[tu]},$$scope:{ctx:P}}}),Qt=new Me({}),mt=new rs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[fu],pytorch:[nu]},$$scope:{ctx:P}}}),ct=new Ks({props:{$$slots:{default:[pu]},$$scope:{ctx:P}}}),ht=new Ks({props:{$$slots:{default:[uu]},$$scope:{ctx:P}}}),Zt=new Me({}),$t=new rs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[du],pytorch:[cu]},$$scope:{ctx:P}}}),_t=new rs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[wu],pytorch:[_u]},$$scope:{ctx:P}}}),Xt=new Me({}),es=new L({props:{code:`from transformers import AutoConfig

my_config = AutoConfig.from_pretrained("distilbert-base-uncased", n_heads=12)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, n_heads=<span class="hljs-number">12</span>)`}}),wt=new rs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[bu],pytorch:[ku]},$$scope:{ctx:P}}}),ts=new Me({}),{c(){a=l("meta"),m=h(),r=l("h1"),c=l("a"),_=l("span"),b(w.$$.fragment),k=h(),F=l("span"),g=o("Quick tour"),y=h(),b(I.$$.fragment),O=h(),D=l("p"),W=o("Get up and running with \u{1F917} Transformers! Start using the "),z=l("a"),C=o("pipeline()"),v=o(" for rapid inference, and quickly load a pretrained model and tokenizer with an "),S=l("a"),R=o("AutoClass"),U=o(" to solve your text, vision or audio task."),Q=h(),b(J.$$.fragment),se=h(),V=l("h2"),G=l("a"),ee=l("span"),b(B.$$.fragment),K=h(),he=l("span"),re=o("Pipeline"),$e=h(),oe=l("p"),te=l("a"),ne=o("pipeline()"),_e=o(" is the easiest way to use a pretrained model for a given task."),M=h(),b(N.$$.fragment),le=h(),q=l("p"),H=o("The "),ie=l("a"),Fe=o("pipeline()"),de=o(" supports many common tasks out-of-the-box:"),we=h(),fe=l("p"),Ue=l("strong"),ve=o("Text"),os=o(":"),yt=h(),Y=l("ul"),Zs=l("li"),Fo=o("Sentiment analysis: classify the polarity of a given text."),So=h(),Xs=l("li"),Co=o("Text generation (in English): generate text from a given input."),Io=h(),ea=l("li"),Oo=o("Name entity recognition (NER): label each word with the entity it represents (person, date, location, etc.)."),No=h(),ta=l("li"),Do=o("Question answering: extract the answer from the context, given some context and a question."),Ho=h(),sa=l("li"),Lo=o("Fill-mask: fill in the blank given a text with masked words."),Wo=h(),aa=l("li"),Uo=o("Summarization: generate a summary of a long sequence of text or document."),Ro=h(),ra=l("li"),Go=o("Translation: translate text into another language."),Yo=h(),oa=l("li"),Jo=o("Feature extraction: create a tensor representation of the text."),Ba=h(),bt=l("p"),na=l("strong"),Qo=o("Image"),Vo=o(":"),Ka=h(),ke=l("ul"),la=l("li"),Bo=o("Image classification: classify an image."),Ko=h(),ia=l("li"),Zo=o("Image segmentation: classify every pixel in an image."),Xo=h(),fa=l("li"),en=o("Object detection: detect objects within an image."),Za=h(),At=l("p"),pa=l("strong"),tn=o("Audio"),sn=o(":"),Xa=h(),Re=l("ul"),ua=l("li"),an=o("Audio classification: assign a label to a given segment of audio."),rn=h(),ma=l("li"),on=o("Automatic speech recognition (ASR): transcribe audio data into text."),er=h(),b(Ge.$$.fragment),tr=h(),Se=l("h3"),Ye=l("a"),ca=l("span"),b(Et.$$.fragment),nn=h(),ha=l("span"),ln=o("Pipeline usage"),sr=h(),Je=l("p"),fn=o("In the following example, you will use the "),ns=l("a"),pn=o("pipeline()"),un=o(" for sentiment analysis."),ar=h(),ls=l("p"),mn=o("Install the following dependencies if you haven\u2019t already:"),rr=h(),b(Qe.$$.fragment),or=h(),Ve=l("p"),cn=o("Import "),is=l("a"),hn=o("pipeline()"),dn=o(" and specify the task you want to complete:"),nr=h(),b(Tt.$$.fragment),lr=h(),ye=l("p"),$n=o("The pipeline downloads and caches a default "),jt=l("a"),_n=o("pretrained model"),gn=o(" and tokenizer for sentiment analysis. Now you can use the "),da=l("code"),wn=o("classifier"),vn=o(" on your target text:"),ir=h(),b(xt.$$.fragment),fr=h(),Be=l("p"),kn=o("For more than one sentence, pass a list of sentences to the "),fs=l("a"),yn=o("pipeline()"),bn=o(" which returns a list of dictionaries:"),pr=h(),b(qt.$$.fragment),ur=h(),be=l("p"),An=o("The "),ps=l("a"),En=o("pipeline()"),Tn=o(" can also iterate over an entire dataset. Start by installing the "),zt=l("a"),jn=o("\u{1F917} Datasets"),xn=o(" library:"),mr=h(),b(Pt.$$.fragment),cr=h(),Ke=l("p"),qn=o("Create a "),us=l("a"),zn=o("pipeline()"),Pn=o(" with the task you want to solve for and the model you want to use."),hr=h(),b(Mt.$$.fragment),dr=h(),Ae=l("p"),Mn=o("Next, load a dataset (see the \u{1F917} Datasets "),Ft=l("a"),Fn=o("Quick Start"),Sn=o(" for more details) you\u2019d like to iterate over. For example, let\u2019s load the "),St=l("a"),Cn=o("MInDS-14"),In=o(" dataset:"),$r=h(),b(Ct.$$.fragment),_r=h(),Ze=l("p"),On=o(`We need to make sure that the sampling rate of the dataset matches the sampling
rate `),$a=l("code"),Nn=o("facebook/wav2vec2-base-960h"),Dn=o(" was trained on."),gr=h(),b(It.$$.fragment),wr=h(),Xe=l("p"),Hn=o("Audio files are automatically loaded and resampled when calling the "),_a=l("code"),Ln=o('"audio"'),Wn=o(` column.
Let\u2019s extract the raw waveform arrays of the first 4 samples and pass it as a list to the pipeline:`),vr=h(),b(Ot.$$.fragment),kr=h(),et=l("p"),Un=o("For a larger dataset where the inputs are big (like in speech or vision), you will want to pass along a generator instead of a list that loads all the inputs in memory. See the "),ms=l("a"),Rn=o("pipeline documentation"),Gn=o(" for more information."),yr=h(),Ce=l("h3"),tt=l("a"),ga=l("span"),b(Nt.$$.fragment),Yn=h(),wa=l("span"),Jn=o("Use another model and tokenizer in the pipeline"),br=h(),pe=l("p"),Qn=o("The "),cs=l("a"),Vn=o("pipeline()"),Bn=o(" can accommodate any model from the "),Dt=l("a"),Kn=o("Model Hub"),Zn=o(", making it easy to adapt the "),hs=l("a"),Xn=o("pipeline()"),el=o(" for other use-cases. For example, if you\u2019d like a model capable of handling French text, use the tags on the Model Hub to filter for an appropriate model. The top filtered result returns a multilingual "),Ht=l("a"),tl=o("BERT model"),sl=o(" fine-tuned for sentiment analysis. Great, let\u2019s use this model!"),Ar=h(),b(Lt.$$.fragment),Er=h(),b(st.$$.fragment),Tr=h(),Ee=l("p"),al=o("Then you can specify the model and tokenizer in the "),ds=l("a"),rl=o("pipeline()"),ol=o(", and apply the "),va=l("code"),nl=o("classifier"),ll=o(" on your target text:"),jr=h(),b(Wt.$$.fragment),xr=h(),Te=l("p"),il=o("If you can\u2019t find a model for your use-case, you will need to fine-tune a pretrained model on your data. Take a look at our "),$s=l("a"),fl=o("fine-tuning tutorial"),pl=o(" to learn how. Finally, after you\u2019ve fine-tuned your pretrained model, please consider sharing it (see tutorial "),_s=l("a"),ul=o("here"),ml=o(") with the community on the Model Hub to democratize NLP for everyone! \u{1F917}"),qr=h(),Ie=l("h2"),at=l("a"),ka=l("span"),b(Ut.$$.fragment),cl=h(),ya=l("span"),hl=o("AutoClass"),zr=h(),b(Rt.$$.fragment),Pr=h(),Z=l("p"),dl=o("Under the hood, the "),gs=l("a"),$l=o("AutoModelForSequenceClassification"),_l=o(" and "),ws=l("a"),gl=o("AutoTokenizer"),wl=o(" classes work together to power the "),vs=l("a"),vl=o("pipeline()"),kl=o(". An "),ks=l("a"),yl=o("AutoClass"),bl=o(" is a shortcut that automatically retrieves the architecture of a pretrained model from it\u2019s name or path. You only need to select the appropriate "),ba=l("code"),Al=o("AutoClass"),El=o(" for your task and it\u2019s associated tokenizer with "),ys=l("a"),Tl=o("AutoTokenizer"),jl=o("."),Mr=h(),je=l("p"),xl=o("Let\u2019s return to our example and see how you can use the "),Aa=l("code"),ql=o("AutoClass"),zl=o(" to replicate the results of the "),bs=l("a"),Pl=o("pipeline()"),Ml=o("."),Fr=h(),Oe=l("h3"),rt=l("a"),Ea=l("span"),b(Gt.$$.fragment),Fl=h(),Ta=l("span"),Sl=o("AutoTokenizer"),Sr=h(),xe=l("p"),Cl=o("A tokenizer is responsible for preprocessing text into a format that is understandable to the model. First, the tokenizer will split the text into words called "),ja=l("em"),Il=o("tokens"),Ol=o(". There are multiple rules that govern the tokenization process, including how to split a word and at what level (learn more about tokenization "),As=l("a"),Nl=o("here"),Dl=o("). The most important thing to remember though is you need to instantiate the tokenizer with the same model name to ensure you\u2019re using the same tokenization rules a model was pretrained with."),Cr=h(),ot=l("p"),Hl=o("Load a tokenizer with "),Es=l("a"),Ll=o("AutoTokenizer"),Wl=o(":"),Ir=h(),b(Yt.$$.fragment),Or=h(),nt=l("p"),Ul=o("Next, the tokenizer converts the tokens into numbers in order to construct a tensor as input to the model. This is known as the model\u2019s "),xa=l("em"),Rl=o("vocabulary"),Gl=o("."),Nr=h(),Ts=l("p"),Yl=o("Pass your text to the tokenizer:"),Dr=h(),b(Jt.$$.fragment),Hr=h(),js=l("p"),Jl=o("The tokenizer will return a dictionary containing:"),Lr=h(),lt=l("ul"),xs=l("li"),qs=l("a"),Ql=o("input_ids"),Vl=o(": numerical representions of your tokens."),Bl=h(),zs=l("li"),Ps=l("a"),Kl=o("atttention_mask"),Zl=o(": indicates which tokens should be attended to."),Wr=h(),it=l("p"),Xl=o("Just like the "),Ms=l("a"),ei=o("pipeline()"),ti=o(", the tokenizer will accept a list of inputs. In addition, the tokenizer can also pad and truncate the text to return a batch with uniform length:"),Ur=h(),b(ft.$$.fragment),Rr=h(),pt=l("p"),si=o("Read the "),Fs=l("a"),ai=o("preprocessing"),ri=o(" tutorial for more details about tokenization."),Gr=h(),Ne=l("h3"),ut=l("a"),qa=l("span"),b(Qt.$$.fragment),oi=h(),za=l("span"),ni=o("AutoModel"),Yr=h(),b(mt.$$.fragment),Jr=h(),b(ct.$$.fragment),Qr=h(),X=l("p"),li=o("Models are a standard "),Vt=l("a"),Pa=l("code"),ii=o("torch.nn.Module"),fi=o(" or a "),Bt=l("a"),Ma=l("code"),pi=o("tf.keras.Model"),ui=o(" so you can use them in your usual training loop. However, to make things easier, \u{1F917} Transformers provides a "),Ss=l("a"),mi=o("Trainer"),ci=o(" class for PyTorch that adds functionality for distributed training, mixed precision, and more. For TensorFlow, you can use the "),Fa=l("code"),hi=o("fit"),di=o(" method from "),Kt=l("a"),$i=o("Keras"),_i=o(". Refer to the "),Cs=l("a"),gi=o("training tutorial"),wi=o(" for more details."),Vr=h(),b(ht.$$.fragment),Br=h(),De=l("h3"),dt=l("a"),Sa=l("span"),b(Zt.$$.fragment),vi=h(),Ca=l("span"),ki=o("Save a model"),Kr=h(),b($t.$$.fragment),Zr=h(),qe=l("p"),yi=o("One particularly cool \u{1F917} Transformers feature is the ability to save a model and reload it as either a PyTorch or TensorFlow model. The "),Ia=l("code"),bi=o("from_pt"),Ai=o(" or "),Oa=l("code"),Ei=o("from_tf"),Ti=o(" parameter can convert the model from one framework to the other:"),Xr=h(),b(_t.$$.fragment),eo=h(),He=l("h2"),gt=l("a"),Na=l("span"),b(Xt.$$.fragment),ji=h(),Da=l("span"),xi=o("Custom model builds"),to=h(),Is=l("p"),qi=o("You can modify the model\u2019s configuration class to change how a model is built. The configuration specifies a model\u2019s attributes, such as the number of hidden layers or attention heads. You start from scratch when you initialize a model from a custom configuration class. The model attributes are randomly initialized, and you\u2019ll need to train the model before you can use it to get meaningful results."),so=h(),ze=l("p"),zi=o("Start by importing "),Os=l("a"),Pi=o("AutoConfig"),Mi=o(", and then load the pretrained model you want to modify. Within "),Ns=l("a"),Fi=o("AutoConfig.from_pretrained()"),Si=o(", you can specify the attribute you want to change, such as the number of attention heads:"),ao=h(),b(es.$$.fragment),ro=h(),b(wt.$$.fragment),oo=h(),vt=l("p"),Ci=o("Take a look at the "),Ds=l("a"),Ii=o("Create a custom architecture"),Oi=o(" guide for more information about building custom configurations."),no=h(),Le=l("h2"),kt=l("a"),Ha=l("span"),b(ts.$$.fragment),Ni=h(),La=l("span"),Di=o("What's next?"),lo=h(),Hs=l("p"),Hi=o("Now that you\u2019ve completed the \u{1F917} Transformers quick tour, check out our guides and learn how to do more specific things like writing a custom model, fine-tuning a model for a task, and how to train a model with a script. If you\u2019re interested in learning more about \u{1F917} Transformers core concepts, grab a cup of coffee and take a look at our Conceptual Guides!"),this.h()},l(e){const p=Lp('[data-svelte="svelte-1phssyn"]',document.head);a=i(p,"META",{name:!0,content:!0}),p.forEach(s),m=d(e),r=i(e,"H1",{class:!0});var ss=f(r);c=i(ss,"A",{id:!0,class:!0,href:!0});var Wa=f(c);_=i(Wa,"SPAN",{});var Ua=f(_);A(w.$$.fragment,Ua),Ua.forEach(s),Wa.forEach(s),k=d(ss),F=i(ss,"SPAN",{});var Ra=f(F);g=n(Ra,"Quick tour"),Ra.forEach(s),ss.forEach(s),y=d(e),A(I.$$.fragment,e),O=d(e),D=i(e,"P",{});var We=f(D);W=n(We,"Get up and running with \u{1F917} Transformers! Start using the "),z=i(We,"A",{href:!0});var Ga=f(z);C=n(Ga,"pipeline()"),Ga.forEach(s),v=n(We," for rapid inference, and quickly load a pretrained model and tokenizer with an "),S=i(We,"A",{href:!0});var Ya=f(S);R=n(Ya,"AutoClass"),Ya.forEach(s),U=n(We," to solve your text, vision or audio task."),We.forEach(s),Q=d(e),A(J.$$.fragment,e),se=d(e),V=i(e,"H2",{class:!0});var as=f(V);G=i(as,"A",{id:!0,class:!0,href:!0});var Ja=f(G);ee=i(Ja,"SPAN",{});var Qa=f(ee);A(B.$$.fragment,Qa),Qa.forEach(s),Ja.forEach(s),K=d(as),he=i(as,"SPAN",{});var Va=f(he);re=n(Va,"Pipeline"),Va.forEach(s),as.forEach(s),$e=d(e),oe=i(e,"P",{});var Li=f(oe);te=i(Li,"A",{href:!0});var Ji=f(te);ne=n(Ji,"pipeline()"),Ji.forEach(s),_e=n(Li," is the easiest way to use a pretrained model for a given task."),Li.forEach(s),M=d(e),A(N.$$.fragment,e),le=d(e),q=i(e,"P",{});var fo=f(q);H=n(fo,"The "),ie=i(fo,"A",{href:!0});var Qi=f(ie);Fe=n(Qi,"pipeline()"),Qi.forEach(s),de=n(fo," supports many common tasks out-of-the-box:"),fo.forEach(s),we=d(e),fe=i(e,"P",{});var Wi=f(fe);Ue=i(Wi,"STRONG",{});var Vi=f(Ue);ve=n(Vi,"Text"),Vi.forEach(s),os=n(Wi,":"),Wi.forEach(s),yt=d(e),Y=i(e,"UL",{});var ae=f(Y);Zs=i(ae,"LI",{});var Bi=f(Zs);Fo=n(Bi,"Sentiment analysis: classify the polarity of a given text."),Bi.forEach(s),So=d(ae),Xs=i(ae,"LI",{});var Ki=f(Xs);Co=n(Ki,"Text generation (in English): generate text from a given input."),Ki.forEach(s),Io=d(ae),ea=i(ae,"LI",{});var Zi=f(ea);Oo=n(Zi,"Name entity recognition (NER): label each word with the entity it represents (person, date, location, etc.)."),Zi.forEach(s),No=d(ae),ta=i(ae,"LI",{});var Xi=f(ta);Do=n(Xi,"Question answering: extract the answer from the context, given some context and a question."),Xi.forEach(s),Ho=d(ae),sa=i(ae,"LI",{});var ef=f(sa);Lo=n(ef,"Fill-mask: fill in the blank given a text with masked words."),ef.forEach(s),Wo=d(ae),aa=i(ae,"LI",{});var tf=f(aa);Uo=n(tf,"Summarization: generate a summary of a long sequence of text or document."),tf.forEach(s),Ro=d(ae),ra=i(ae,"LI",{});var sf=f(ra);Go=n(sf,"Translation: translate text into another language."),sf.forEach(s),Yo=d(ae),oa=i(ae,"LI",{});var af=f(oa);Jo=n(af,"Feature extraction: create a tensor representation of the text."),af.forEach(s),ae.forEach(s),Ba=d(e),bt=i(e,"P",{});var Ui=f(bt);na=i(Ui,"STRONG",{});var rf=f(na);Qo=n(rf,"Image"),rf.forEach(s),Vo=n(Ui,":"),Ui.forEach(s),Ka=d(e),ke=i(e,"UL",{});var Ls=f(ke);la=i(Ls,"LI",{});var of=f(la);Bo=n(of,"Image classification: classify an image."),of.forEach(s),Ko=d(Ls),ia=i(Ls,"LI",{});var nf=f(ia);Zo=n(nf,"Image segmentation: classify every pixel in an image."),nf.forEach(s),Xo=d(Ls),fa=i(Ls,"LI",{});var lf=f(fa);en=n(lf,"Object detection: detect objects within an image."),lf.forEach(s),Ls.forEach(s),Za=d(e),At=i(e,"P",{});var Ri=f(At);pa=i(Ri,"STRONG",{});var ff=f(pa);tn=n(ff,"Audio"),ff.forEach(s),sn=n(Ri,":"),Ri.forEach(s),Xa=d(e),Re=i(e,"UL",{});var po=f(Re);ua=i(po,"LI",{});var pf=f(ua);an=n(pf,"Audio classification: assign a label to a given segment of audio."),pf.forEach(s),rn=d(po),ma=i(po,"LI",{});var uf=f(ma);on=n(uf,"Automatic speech recognition (ASR): transcribe audio data into text."),uf.forEach(s),po.forEach(s),er=d(e),A(Ge.$$.fragment,e),tr=d(e),Se=i(e,"H3",{class:!0});var uo=f(Se);Ye=i(uo,"A",{id:!0,class:!0,href:!0});var mf=f(Ye);ca=i(mf,"SPAN",{});var cf=f(ca);A(Et.$$.fragment,cf),cf.forEach(s),mf.forEach(s),nn=d(uo),ha=i(uo,"SPAN",{});var hf=f(ha);ln=n(hf,"Pipeline usage"),hf.forEach(s),uo.forEach(s),sr=d(e),Je=i(e,"P",{});var mo=f(Je);fn=n(mo,"In the following example, you will use the "),ns=i(mo,"A",{href:!0});var df=f(ns);pn=n(df,"pipeline()"),df.forEach(s),un=n(mo," for sentiment analysis."),mo.forEach(s),ar=d(e),ls=i(e,"P",{});var $f=f(ls);mn=n($f,"Install the following dependencies if you haven\u2019t already:"),$f.forEach(s),rr=d(e),A(Qe.$$.fragment,e),or=d(e),Ve=i(e,"P",{});var co=f(Ve);cn=n(co,"Import "),is=i(co,"A",{href:!0});var _f=f(is);hn=n(_f,"pipeline()"),_f.forEach(s),dn=n(co," and specify the task you want to complete:"),co.forEach(s),nr=d(e),A(Tt.$$.fragment,e),lr=d(e),ye=i(e,"P",{});var Ws=f(ye);$n=n(Ws,"The pipeline downloads and caches a default "),jt=i(Ws,"A",{href:!0,rel:!0});var gf=f(jt);_n=n(gf,"pretrained model"),gf.forEach(s),gn=n(Ws," and tokenizer for sentiment analysis. Now you can use the "),da=i(Ws,"CODE",{});var wf=f(da);wn=n(wf,"classifier"),wf.forEach(s),vn=n(Ws," on your target text:"),Ws.forEach(s),ir=d(e),A(xt.$$.fragment,e),fr=d(e),Be=i(e,"P",{});var ho=f(Be);kn=n(ho,"For more than one sentence, pass a list of sentences to the "),fs=i(ho,"A",{href:!0});var vf=f(fs);yn=n(vf,"pipeline()"),vf.forEach(s),bn=n(ho," which returns a list of dictionaries:"),ho.forEach(s),pr=d(e),A(qt.$$.fragment,e),ur=d(e),be=i(e,"P",{});var Us=f(be);An=n(Us,"The "),ps=i(Us,"A",{href:!0});var kf=f(ps);En=n(kf,"pipeline()"),kf.forEach(s),Tn=n(Us," can also iterate over an entire dataset. Start by installing the "),zt=i(Us,"A",{href:!0,rel:!0});var yf=f(zt);jn=n(yf,"\u{1F917} Datasets"),yf.forEach(s),xn=n(Us," library:"),Us.forEach(s),mr=d(e),A(Pt.$$.fragment,e),cr=d(e),Ke=i(e,"P",{});var $o=f(Ke);qn=n($o,"Create a "),us=i($o,"A",{href:!0});var bf=f(us);zn=n(bf,"pipeline()"),bf.forEach(s),Pn=n($o," with the task you want to solve for and the model you want to use."),$o.forEach(s),hr=d(e),A(Mt.$$.fragment,e),dr=d(e),Ae=i(e,"P",{});var Rs=f(Ae);Mn=n(Rs,"Next, load a dataset (see the \u{1F917} Datasets "),Ft=i(Rs,"A",{href:!0,rel:!0});var Af=f(Ft);Fn=n(Af,"Quick Start"),Af.forEach(s),Sn=n(Rs," for more details) you\u2019d like to iterate over. For example, let\u2019s load the "),St=i(Rs,"A",{href:!0,rel:!0});var Ef=f(St);Cn=n(Ef,"MInDS-14"),Ef.forEach(s),In=n(Rs," dataset:"),Rs.forEach(s),$r=d(e),A(Ct.$$.fragment,e),_r=d(e),Ze=i(e,"P",{});var _o=f(Ze);On=n(_o,`We need to make sure that the sampling rate of the dataset matches the sampling
rate `),$a=i(_o,"CODE",{});var Tf=f($a);Nn=n(Tf,"facebook/wav2vec2-base-960h"),Tf.forEach(s),Dn=n(_o," was trained on."),_o.forEach(s),gr=d(e),A(It.$$.fragment,e),wr=d(e),Xe=i(e,"P",{});var go=f(Xe);Hn=n(go,"Audio files are automatically loaded and resampled when calling the "),_a=i(go,"CODE",{});var jf=f(_a);Ln=n(jf,'"audio"'),jf.forEach(s),Wn=n(go,` column.
Let\u2019s extract the raw waveform arrays of the first 4 samples and pass it as a list to the pipeline:`),go.forEach(s),vr=d(e),A(Ot.$$.fragment,e),kr=d(e),et=i(e,"P",{});var wo=f(et);Un=n(wo,"For a larger dataset where the inputs are big (like in speech or vision), you will want to pass along a generator instead of a list that loads all the inputs in memory. See the "),ms=i(wo,"A",{href:!0});var xf=f(ms);Rn=n(xf,"pipeline documentation"),xf.forEach(s),Gn=n(wo," for more information."),wo.forEach(s),yr=d(e),Ce=i(e,"H3",{class:!0});var vo=f(Ce);tt=i(vo,"A",{id:!0,class:!0,href:!0});var qf=f(tt);ga=i(qf,"SPAN",{});var zf=f(ga);A(Nt.$$.fragment,zf),zf.forEach(s),qf.forEach(s),Yn=d(vo),wa=i(vo,"SPAN",{});var Pf=f(wa);Jn=n(Pf,"Use another model and tokenizer in the pipeline"),Pf.forEach(s),vo.forEach(s),br=d(e),pe=i(e,"P",{});var Pe=f(pe);Qn=n(Pe,"The "),cs=i(Pe,"A",{href:!0});var Mf=f(cs);Vn=n(Mf,"pipeline()"),Mf.forEach(s),Bn=n(Pe," can accommodate any model from the "),Dt=i(Pe,"A",{href:!0,rel:!0});var Ff=f(Dt);Kn=n(Ff,"Model Hub"),Ff.forEach(s),Zn=n(Pe,", making it easy to adapt the "),hs=i(Pe,"A",{href:!0});var Sf=f(hs);Xn=n(Sf,"pipeline()"),Sf.forEach(s),el=n(Pe," for other use-cases. For example, if you\u2019d like a model capable of handling French text, use the tags on the Model Hub to filter for an appropriate model. The top filtered result returns a multilingual "),Ht=i(Pe,"A",{href:!0,rel:!0});var Cf=f(Ht);tl=n(Cf,"BERT model"),Cf.forEach(s),sl=n(Pe," fine-tuned for sentiment analysis. Great, let\u2019s use this model!"),Pe.forEach(s),Ar=d(e),A(Lt.$$.fragment,e),Er=d(e),A(st.$$.fragment,e),Tr=d(e),Ee=i(e,"P",{});var Gs=f(Ee);al=n(Gs,"Then you can specify the model and tokenizer in the "),ds=i(Gs,"A",{href:!0});var If=f(ds);rl=n(If,"pipeline()"),If.forEach(s),ol=n(Gs,", and apply the "),va=i(Gs,"CODE",{});var Of=f(va);nl=n(Of,"classifier"),Of.forEach(s),ll=n(Gs," on your target text:"),Gs.forEach(s),jr=d(e),A(Wt.$$.fragment,e),xr=d(e),Te=i(e,"P",{});var Ys=f(Te);il=n(Ys,"If you can\u2019t find a model for your use-case, you will need to fine-tune a pretrained model on your data. Take a look at our "),$s=i(Ys,"A",{href:!0});var Nf=f($s);fl=n(Nf,"fine-tuning tutorial"),Nf.forEach(s),pl=n(Ys," to learn how. Finally, after you\u2019ve fine-tuned your pretrained model, please consider sharing it (see tutorial "),_s=i(Ys,"A",{href:!0});var Df=f(_s);ul=n(Df,"here"),Df.forEach(s),ml=n(Ys,") with the community on the Model Hub to democratize NLP for everyone! \u{1F917}"),Ys.forEach(s),qr=d(e),Ie=i(e,"H2",{class:!0});var ko=f(Ie);at=i(ko,"A",{id:!0,class:!0,href:!0});var Hf=f(at);ka=i(Hf,"SPAN",{});var Lf=f(ka);A(Ut.$$.fragment,Lf),Lf.forEach(s),Hf.forEach(s),cl=d(ko),ya=i(ko,"SPAN",{});var Wf=f(ya);hl=n(Wf,"AutoClass"),Wf.forEach(s),ko.forEach(s),zr=d(e),A(Rt.$$.fragment,e),Pr=d(e),Z=i(e,"P",{});var ue=f(Z);dl=n(ue,"Under the hood, the "),gs=i(ue,"A",{href:!0});var Uf=f(gs);$l=n(Uf,"AutoModelForSequenceClassification"),Uf.forEach(s),_l=n(ue," and "),ws=i(ue,"A",{href:!0});var Rf=f(ws);gl=n(Rf,"AutoTokenizer"),Rf.forEach(s),wl=n(ue," classes work together to power the "),vs=i(ue,"A",{href:!0});var Gf=f(vs);vl=n(Gf,"pipeline()"),Gf.forEach(s),kl=n(ue,". An "),ks=i(ue,"A",{href:!0});var Yf=f(ks);yl=n(Yf,"AutoClass"),Yf.forEach(s),bl=n(ue," is a shortcut that automatically retrieves the architecture of a pretrained model from it\u2019s name or path. You only need to select the appropriate "),ba=i(ue,"CODE",{});var Jf=f(ba);Al=n(Jf,"AutoClass"),Jf.forEach(s),El=n(ue," for your task and it\u2019s associated tokenizer with "),ys=i(ue,"A",{href:!0});var Qf=f(ys);Tl=n(Qf,"AutoTokenizer"),Qf.forEach(s),jl=n(ue,"."),ue.forEach(s),Mr=d(e),je=i(e,"P",{});var Js=f(je);xl=n(Js,"Let\u2019s return to our example and see how you can use the "),Aa=i(Js,"CODE",{});var Vf=f(Aa);ql=n(Vf,"AutoClass"),Vf.forEach(s),zl=n(Js," to replicate the results of the "),bs=i(Js,"A",{href:!0});var Bf=f(bs);Pl=n(Bf,"pipeline()"),Bf.forEach(s),Ml=n(Js,"."),Js.forEach(s),Fr=d(e),Oe=i(e,"H3",{class:!0});var yo=f(Oe);rt=i(yo,"A",{id:!0,class:!0,href:!0});var Kf=f(rt);Ea=i(Kf,"SPAN",{});var Zf=f(Ea);A(Gt.$$.fragment,Zf),Zf.forEach(s),Kf.forEach(s),Fl=d(yo),Ta=i(yo,"SPAN",{});var Xf=f(Ta);Sl=n(Xf,"AutoTokenizer"),Xf.forEach(s),yo.forEach(s),Sr=d(e),xe=i(e,"P",{});var Qs=f(xe);Cl=n(Qs,"A tokenizer is responsible for preprocessing text into a format that is understandable to the model. First, the tokenizer will split the text into words called "),ja=i(Qs,"EM",{});var ep=f(ja);Il=n(ep,"tokens"),ep.forEach(s),Ol=n(Qs,". There are multiple rules that govern the tokenization process, including how to split a word and at what level (learn more about tokenization "),As=i(Qs,"A",{href:!0});var tp=f(As);Nl=n(tp,"here"),tp.forEach(s),Dl=n(Qs,"). The most important thing to remember though is you need to instantiate the tokenizer with the same model name to ensure you\u2019re using the same tokenization rules a model was pretrained with."),Qs.forEach(s),Cr=d(e),ot=i(e,"P",{});var bo=f(ot);Hl=n(bo,"Load a tokenizer with "),Es=i(bo,"A",{href:!0});var sp=f(Es);Ll=n(sp,"AutoTokenizer"),sp.forEach(s),Wl=n(bo,":"),bo.forEach(s),Ir=d(e),A(Yt.$$.fragment,e),Or=d(e),nt=i(e,"P",{});var Ao=f(nt);Ul=n(Ao,"Next, the tokenizer converts the tokens into numbers in order to construct a tensor as input to the model. This is known as the model\u2019s "),xa=i(Ao,"EM",{});var ap=f(xa);Rl=n(ap,"vocabulary"),ap.forEach(s),Gl=n(Ao,"."),Ao.forEach(s),Nr=d(e),Ts=i(e,"P",{});var rp=f(Ts);Yl=n(rp,"Pass your text to the tokenizer:"),rp.forEach(s),Dr=d(e),A(Jt.$$.fragment,e),Hr=d(e),js=i(e,"P",{});var op=f(js);Jl=n(op,"The tokenizer will return a dictionary containing:"),op.forEach(s),Lr=d(e),lt=i(e,"UL",{});var Eo=f(lt);xs=i(Eo,"LI",{});var Gi=f(xs);qs=i(Gi,"A",{href:!0});var np=f(qs);Ql=n(np,"input_ids"),np.forEach(s),Vl=n(Gi,": numerical representions of your tokens."),Gi.forEach(s),Bl=d(Eo),zs=i(Eo,"LI",{});var Yi=f(zs);Ps=i(Yi,"A",{href:!0});var lp=f(Ps);Kl=n(lp,"atttention_mask"),lp.forEach(s),Zl=n(Yi,": indicates which tokens should be attended to."),Yi.forEach(s),Eo.forEach(s),Wr=d(e),it=i(e,"P",{});var To=f(it);Xl=n(To,"Just like the "),Ms=i(To,"A",{href:!0});var ip=f(Ms);ei=n(ip,"pipeline()"),ip.forEach(s),ti=n(To,", the tokenizer will accept a list of inputs. In addition, the tokenizer can also pad and truncate the text to return a batch with uniform length:"),To.forEach(s),Ur=d(e),A(ft.$$.fragment,e),Rr=d(e),pt=i(e,"P",{});var jo=f(pt);si=n(jo,"Read the "),Fs=i(jo,"A",{href:!0});var fp=f(Fs);ai=n(fp,"preprocessing"),fp.forEach(s),ri=n(jo," tutorial for more details about tokenization."),jo.forEach(s),Gr=d(e),Ne=i(e,"H3",{class:!0});var xo=f(Ne);ut=i(xo,"A",{id:!0,class:!0,href:!0});var pp=f(ut);qa=i(pp,"SPAN",{});var up=f(qa);A(Qt.$$.fragment,up),up.forEach(s),pp.forEach(s),oi=d(xo),za=i(xo,"SPAN",{});var mp=f(za);ni=n(mp,"AutoModel"),mp.forEach(s),xo.forEach(s),Yr=d(e),A(mt.$$.fragment,e),Jr=d(e),A(ct.$$.fragment,e),Qr=d(e),X=i(e,"P",{});var me=f(X);li=n(me,"Models are a standard "),Vt=i(me,"A",{href:!0,rel:!0});var cp=f(Vt);Pa=i(cp,"CODE",{});var hp=f(Pa);ii=n(hp,"torch.nn.Module"),hp.forEach(s),cp.forEach(s),fi=n(me," or a "),Bt=i(me,"A",{href:!0,rel:!0});var dp=f(Bt);Ma=i(dp,"CODE",{});var $p=f(Ma);pi=n($p,"tf.keras.Model"),$p.forEach(s),dp.forEach(s),ui=n(me," so you can use them in your usual training loop. However, to make things easier, \u{1F917} Transformers provides a "),Ss=i(me,"A",{href:!0});var _p=f(Ss);mi=n(_p,"Trainer"),_p.forEach(s),ci=n(me," class for PyTorch that adds functionality for distributed training, mixed precision, and more. For TensorFlow, you can use the "),Fa=i(me,"CODE",{});var gp=f(Fa);hi=n(gp,"fit"),gp.forEach(s),di=n(me," method from "),Kt=i(me,"A",{href:!0,rel:!0});var wp=f(Kt);$i=n(wp,"Keras"),wp.forEach(s),_i=n(me,". Refer to the "),Cs=i(me,"A",{href:!0});var vp=f(Cs);gi=n(vp,"training tutorial"),vp.forEach(s),wi=n(me," for more details."),me.forEach(s),Vr=d(e),A(ht.$$.fragment,e),Br=d(e),De=i(e,"H3",{class:!0});var qo=f(De);dt=i(qo,"A",{id:!0,class:!0,href:!0});var kp=f(dt);Sa=i(kp,"SPAN",{});var yp=f(Sa);A(Zt.$$.fragment,yp),yp.forEach(s),kp.forEach(s),vi=d(qo),Ca=i(qo,"SPAN",{});var bp=f(Ca);ki=n(bp,"Save a model"),bp.forEach(s),qo.forEach(s),Kr=d(e),A($t.$$.fragment,e),Zr=d(e),qe=i(e,"P",{});var Vs=f(qe);yi=n(Vs,"One particularly cool \u{1F917} Transformers feature is the ability to save a model and reload it as either a PyTorch or TensorFlow model. The "),Ia=i(Vs,"CODE",{});var Ap=f(Ia);bi=n(Ap,"from_pt"),Ap.forEach(s),Ai=n(Vs," or "),Oa=i(Vs,"CODE",{});var Ep=f(Oa);Ei=n(Ep,"from_tf"),Ep.forEach(s),Ti=n(Vs," parameter can convert the model from one framework to the other:"),Vs.forEach(s),Xr=d(e),A(_t.$$.fragment,e),eo=d(e),He=i(e,"H2",{class:!0});var zo=f(He);gt=i(zo,"A",{id:!0,class:!0,href:!0});var Tp=f(gt);Na=i(Tp,"SPAN",{});var jp=f(Na);A(Xt.$$.fragment,jp),jp.forEach(s),Tp.forEach(s),ji=d(zo),Da=i(zo,"SPAN",{});var xp=f(Da);xi=n(xp,"Custom model builds"),xp.forEach(s),zo.forEach(s),to=d(e),Is=i(e,"P",{});var qp=f(Is);qi=n(qp,"You can modify the model\u2019s configuration class to change how a model is built. The configuration specifies a model\u2019s attributes, such as the number of hidden layers or attention heads. You start from scratch when you initialize a model from a custom configuration class. The model attributes are randomly initialized, and you\u2019ll need to train the model before you can use it to get meaningful results."),qp.forEach(s),so=d(e),ze=i(e,"P",{});var Bs=f(ze);zi=n(Bs,"Start by importing "),Os=i(Bs,"A",{href:!0});var zp=f(Os);Pi=n(zp,"AutoConfig"),zp.forEach(s),Mi=n(Bs,", and then load the pretrained model you want to modify. Within "),Ns=i(Bs,"A",{href:!0});var Pp=f(Ns);Fi=n(Pp,"AutoConfig.from_pretrained()"),Pp.forEach(s),Si=n(Bs,", you can specify the attribute you want to change, such as the number of attention heads:"),Bs.forEach(s),ao=d(e),A(es.$$.fragment,e),ro=d(e),A(wt.$$.fragment,e),oo=d(e),vt=i(e,"P",{});var Po=f(vt);Ci=n(Po,"Take a look at the "),Ds=i(Po,"A",{href:!0});var Mp=f(Ds);Ii=n(Mp,"Create a custom architecture"),Mp.forEach(s),Oi=n(Po," guide for more information about building custom configurations."),Po.forEach(s),no=d(e),Le=i(e,"H2",{class:!0});var Mo=f(Le);kt=i(Mo,"A",{id:!0,class:!0,href:!0});var Fp=f(kt);Ha=i(Fp,"SPAN",{});var Sp=f(Ha);A(ts.$$.fragment,Sp),Sp.forEach(s),Fp.forEach(s),Ni=d(Mo),La=i(Mo,"SPAN",{});var Cp=f(La);Di=n(Cp,"What's next?"),Cp.forEach(s),Mo.forEach(s),lo=d(e),Hs=i(e,"P",{});var Ip=f(Hs);Hi=n(Ip,"Now that you\u2019ve completed the \u{1F917} Transformers quick tour, check out our guides and learn how to do more specific things like writing a custom model, fine-tuning a model for a task, and how to train a model with a script. If you\u2019re interested in learning more about \u{1F917} Transformers core concepts, grab a cup of coffee and take a look at our Conceptual Guides!"),Ip.forEach(s),this.h()},h(){$(a,"name","hf:doc:metadata"),$(a,"content",JSON.stringify(Eu)),$(c,"id","quick-tour"),$(c,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(c,"href","#quick-tour"),$(r,"class","relative group"),$(z,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),$(S,"href","./model_doc/auto"),$(G,"id","pipeline"),$(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(G,"href","#pipeline"),$(V,"class","relative group"),$(te,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),$(ie,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),$(Ye,"id","pipeline-usage"),$(Ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(Ye,"href","#pipeline-usage"),$(Se,"class","relative group"),$(ns,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),$(is,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),$(jt,"href","https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english"),$(jt,"rel","nofollow"),$(fs,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),$(ps,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),$(zt,"href","https://huggingface.co/docs/datasets/"),$(zt,"rel","nofollow"),$(us,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),$(Ft,"href","https://huggingface.co/docs/datasets/quickstart.html"),$(Ft,"rel","nofollow"),$(St,"href","https://huggingface.co/datasets/PolyAI/minds14"),$(St,"rel","nofollow"),$(ms,"href","./main_classes/pipelines"),$(tt,"id","use-another-model-and-tokenizer-in-the-pipeline"),$(tt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(tt,"href","#use-another-model-and-tokenizer-in-the-pipeline"),$(Ce,"class","relative group"),$(cs,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),$(Dt,"href","https://huggingface.co/models"),$(Dt,"rel","nofollow"),$(hs,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),$(Ht,"href","https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment"),$(Ht,"rel","nofollow"),$(ds,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),$($s,"href","./training"),$(_s,"href","./model_sharing"),$(at,"id","autoclass"),$(at,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(at,"href","#autoclass"),$(Ie,"class","relative group"),$(gs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSequenceClassification"),$(ws,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),$(vs,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),$(ks,"href","./model_doc/auto"),$(ys,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),$(bs,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),$(rt,"id","autotokenizer"),$(rt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(rt,"href","#autotokenizer"),$(Oe,"class","relative group"),$(As,"href","./tokenizer_summary"),$(Es,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),$(qs,"href","./glossary#input-ids"),$(Ps,"href",".glossary#attention-mask"),$(Ms,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),$(Fs,"href","./preprocessing"),$(ut,"id","automodel"),$(ut,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(ut,"href","#automodel"),$(Ne,"class","relative group"),$(Vt,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),$(Vt,"rel","nofollow"),$(Bt,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),$(Bt,"rel","nofollow"),$(Ss,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Trainer"),$(Kt,"href","https://keras.io/"),$(Kt,"rel","nofollow"),$(Cs,"href","./training"),$(dt,"id","save-a-model"),$(dt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(dt,"href","#save-a-model"),$(De,"class","relative group"),$(gt,"id","custom-model-builds"),$(gt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(gt,"href","#custom-model-builds"),$(He,"class","relative group"),$(Os,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),$(Ns,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),$(Ds,"href","./create_a_model"),$(kt,"id","whats-next"),$(kt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(kt,"href","#whats-next"),$(Le,"class","relative group")},m(e,p){t(document.head,a),u(e,m,p),u(e,r,p),t(r,c),t(c,_),E(w,_,null),t(r,k),t(r,F),t(F,g),u(e,y,p),E(I,e,p),u(e,O,p),u(e,D,p),t(D,W),t(D,z),t(z,C),t(D,v),t(D,S),t(S,R),t(D,U),u(e,Q,p),E(J,e,p),u(e,se,p),u(e,V,p),t(V,G),t(G,ee),E(B,ee,null),t(V,K),t(V,he),t(he,re),u(e,$e,p),u(e,oe,p),t(oe,te),t(te,ne),t(oe,_e),u(e,M,p),E(N,e,p),u(e,le,p),u(e,q,p),t(q,H),t(q,ie),t(ie,Fe),t(q,de),u(e,we,p),u(e,fe,p),t(fe,Ue),t(Ue,ve),t(fe,os),u(e,yt,p),u(e,Y,p),t(Y,Zs),t(Zs,Fo),t(Y,So),t(Y,Xs),t(Xs,Co),t(Y,Io),t(Y,ea),t(ea,Oo),t(Y,No),t(Y,ta),t(ta,Do),t(Y,Ho),t(Y,sa),t(sa,Lo),t(Y,Wo),t(Y,aa),t(aa,Uo),t(Y,Ro),t(Y,ra),t(ra,Go),t(Y,Yo),t(Y,oa),t(oa,Jo),u(e,Ba,p),u(e,bt,p),t(bt,na),t(na,Qo),t(bt,Vo),u(e,Ka,p),u(e,ke,p),t(ke,la),t(la,Bo),t(ke,Ko),t(ke,ia),t(ia,Zo),t(ke,Xo),t(ke,fa),t(fa,en),u(e,Za,p),u(e,At,p),t(At,pa),t(pa,tn),t(At,sn),u(e,Xa,p),u(e,Re,p),t(Re,ua),t(ua,an),t(Re,rn),t(Re,ma),t(ma,on),u(e,er,p),E(Ge,e,p),u(e,tr,p),u(e,Se,p),t(Se,Ye),t(Ye,ca),E(Et,ca,null),t(Se,nn),t(Se,ha),t(ha,ln),u(e,sr,p),u(e,Je,p),t(Je,fn),t(Je,ns),t(ns,pn),t(Je,un),u(e,ar,p),u(e,ls,p),t(ls,mn),u(e,rr,p),E(Qe,e,p),u(e,or,p),u(e,Ve,p),t(Ve,cn),t(Ve,is),t(is,hn),t(Ve,dn),u(e,nr,p),E(Tt,e,p),u(e,lr,p),u(e,ye,p),t(ye,$n),t(ye,jt),t(jt,_n),t(ye,gn),t(ye,da),t(da,wn),t(ye,vn),u(e,ir,p),E(xt,e,p),u(e,fr,p),u(e,Be,p),t(Be,kn),t(Be,fs),t(fs,yn),t(Be,bn),u(e,pr,p),E(qt,e,p),u(e,ur,p),u(e,be,p),t(be,An),t(be,ps),t(ps,En),t(be,Tn),t(be,zt),t(zt,jn),t(be,xn),u(e,mr,p),E(Pt,e,p),u(e,cr,p),u(e,Ke,p),t(Ke,qn),t(Ke,us),t(us,zn),t(Ke,Pn),u(e,hr,p),E(Mt,e,p),u(e,dr,p),u(e,Ae,p),t(Ae,Mn),t(Ae,Ft),t(Ft,Fn),t(Ae,Sn),t(Ae,St),t(St,Cn),t(Ae,In),u(e,$r,p),E(Ct,e,p),u(e,_r,p),u(e,Ze,p),t(Ze,On),t(Ze,$a),t($a,Nn),t(Ze,Dn),u(e,gr,p),E(It,e,p),u(e,wr,p),u(e,Xe,p),t(Xe,Hn),t(Xe,_a),t(_a,Ln),t(Xe,Wn),u(e,vr,p),E(Ot,e,p),u(e,kr,p),u(e,et,p),t(et,Un),t(et,ms),t(ms,Rn),t(et,Gn),u(e,yr,p),u(e,Ce,p),t(Ce,tt),t(tt,ga),E(Nt,ga,null),t(Ce,Yn),t(Ce,wa),t(wa,Jn),u(e,br,p),u(e,pe,p),t(pe,Qn),t(pe,cs),t(cs,Vn),t(pe,Bn),t(pe,Dt),t(Dt,Kn),t(pe,Zn),t(pe,hs),t(hs,Xn),t(pe,el),t(pe,Ht),t(Ht,tl),t(pe,sl),u(e,Ar,p),E(Lt,e,p),u(e,Er,p),E(st,e,p),u(e,Tr,p),u(e,Ee,p),t(Ee,al),t(Ee,ds),t(ds,rl),t(Ee,ol),t(Ee,va),t(va,nl),t(Ee,ll),u(e,jr,p),E(Wt,e,p),u(e,xr,p),u(e,Te,p),t(Te,il),t(Te,$s),t($s,fl),t(Te,pl),t(Te,_s),t(_s,ul),t(Te,ml),u(e,qr,p),u(e,Ie,p),t(Ie,at),t(at,ka),E(Ut,ka,null),t(Ie,cl),t(Ie,ya),t(ya,hl),u(e,zr,p),E(Rt,e,p),u(e,Pr,p),u(e,Z,p),t(Z,dl),t(Z,gs),t(gs,$l),t(Z,_l),t(Z,ws),t(ws,gl),t(Z,wl),t(Z,vs),t(vs,vl),t(Z,kl),t(Z,ks),t(ks,yl),t(Z,bl),t(Z,ba),t(ba,Al),t(Z,El),t(Z,ys),t(ys,Tl),t(Z,jl),u(e,Mr,p),u(e,je,p),t(je,xl),t(je,Aa),t(Aa,ql),t(je,zl),t(je,bs),t(bs,Pl),t(je,Ml),u(e,Fr,p),u(e,Oe,p),t(Oe,rt),t(rt,Ea),E(Gt,Ea,null),t(Oe,Fl),t(Oe,Ta),t(Ta,Sl),u(e,Sr,p),u(e,xe,p),t(xe,Cl),t(xe,ja),t(ja,Il),t(xe,Ol),t(xe,As),t(As,Nl),t(xe,Dl),u(e,Cr,p),u(e,ot,p),t(ot,Hl),t(ot,Es),t(Es,Ll),t(ot,Wl),u(e,Ir,p),E(Yt,e,p),u(e,Or,p),u(e,nt,p),t(nt,Ul),t(nt,xa),t(xa,Rl),t(nt,Gl),u(e,Nr,p),u(e,Ts,p),t(Ts,Yl),u(e,Dr,p),E(Jt,e,p),u(e,Hr,p),u(e,js,p),t(js,Jl),u(e,Lr,p),u(e,lt,p),t(lt,xs),t(xs,qs),t(qs,Ql),t(xs,Vl),t(lt,Bl),t(lt,zs),t(zs,Ps),t(Ps,Kl),t(zs,Zl),u(e,Wr,p),u(e,it,p),t(it,Xl),t(it,Ms),t(Ms,ei),t(it,ti),u(e,Ur,p),E(ft,e,p),u(e,Rr,p),u(e,pt,p),t(pt,si),t(pt,Fs),t(Fs,ai),t(pt,ri),u(e,Gr,p),u(e,Ne,p),t(Ne,ut),t(ut,qa),E(Qt,qa,null),t(Ne,oi),t(Ne,za),t(za,ni),u(e,Yr,p),E(mt,e,p),u(e,Jr,p),E(ct,e,p),u(e,Qr,p),u(e,X,p),t(X,li),t(X,Vt),t(Vt,Pa),t(Pa,ii),t(X,fi),t(X,Bt),t(Bt,Ma),t(Ma,pi),t(X,ui),t(X,Ss),t(Ss,mi),t(X,ci),t(X,Fa),t(Fa,hi),t(X,di),t(X,Kt),t(Kt,$i),t(X,_i),t(X,Cs),t(Cs,gi),t(X,wi),u(e,Vr,p),E(ht,e,p),u(e,Br,p),u(e,De,p),t(De,dt),t(dt,Sa),E(Zt,Sa,null),t(De,vi),t(De,Ca),t(Ca,ki),u(e,Kr,p),E($t,e,p),u(e,Zr,p),u(e,qe,p),t(qe,yi),t(qe,Ia),t(Ia,bi),t(qe,Ai),t(qe,Oa),t(Oa,Ei),t(qe,Ti),u(e,Xr,p),E(_t,e,p),u(e,eo,p),u(e,He,p),t(He,gt),t(gt,Na),E(Xt,Na,null),t(He,ji),t(He,Da),t(Da,xi),u(e,to,p),u(e,Is,p),t(Is,qi),u(e,so,p),u(e,ze,p),t(ze,zi),t(ze,Os),t(Os,Pi),t(ze,Mi),t(ze,Ns),t(Ns,Fi),t(ze,Si),u(e,ao,p),E(es,e,p),u(e,ro,p),E(wt,e,p),u(e,oo,p),u(e,vt,p),t(vt,Ci),t(vt,Ds),t(Ds,Ii),t(vt,Oi),u(e,no,p),u(e,Le,p),t(Le,kt),t(kt,Ha),E(ts,Ha,null),t(Le,Ni),t(Le,La),t(La,Di),u(e,lo,p),u(e,Hs,p),t(Hs,Hi),io=!0},p(e,[p]){const ss={};p&2&&(ss.$$scope={dirty:p,ctx:e}),J.$set(ss);const Wa={};p&2&&(Wa.$$scope={dirty:p,ctx:e}),Ge.$set(Wa);const Ua={};p&2&&(Ua.$$scope={dirty:p,ctx:e}),Qe.$set(Ua);const Ra={};p&2&&(Ra.$$scope={dirty:p,ctx:e}),st.$set(Ra);const We={};p&2&&(We.$$scope={dirty:p,ctx:e}),ft.$set(We);const Ga={};p&2&&(Ga.$$scope={dirty:p,ctx:e}),mt.$set(Ga);const Ya={};p&2&&(Ya.$$scope={dirty:p,ctx:e}),ct.$set(Ya);const as={};p&2&&(as.$$scope={dirty:p,ctx:e}),ht.$set(as);const Ja={};p&2&&(Ja.$$scope={dirty:p,ctx:e}),$t.$set(Ja);const Qa={};p&2&&(Qa.$$scope={dirty:p,ctx:e}),_t.$set(Qa);const Va={};p&2&&(Va.$$scope={dirty:p,ctx:e}),wt.$set(Va)},i(e){io||(T(w.$$.fragment,e),T(I.$$.fragment,e),T(J.$$.fragment,e),T(B.$$.fragment,e),T(N.$$.fragment,e),T(Ge.$$.fragment,e),T(Et.$$.fragment,e),T(Qe.$$.fragment,e),T(Tt.$$.fragment,e),T(xt.$$.fragment,e),T(qt.$$.fragment,e),T(Pt.$$.fragment,e),T(Mt.$$.fragment,e),T(Ct.$$.fragment,e),T(It.$$.fragment,e),T(Ot.$$.fragment,e),T(Nt.$$.fragment,e),T(Lt.$$.fragment,e),T(st.$$.fragment,e),T(Wt.$$.fragment,e),T(Ut.$$.fragment,e),T(Rt.$$.fragment,e),T(Gt.$$.fragment,e),T(Yt.$$.fragment,e),T(Jt.$$.fragment,e),T(ft.$$.fragment,e),T(Qt.$$.fragment,e),T(mt.$$.fragment,e),T(ct.$$.fragment,e),T(ht.$$.fragment,e),T(Zt.$$.fragment,e),T($t.$$.fragment,e),T(_t.$$.fragment,e),T(Xt.$$.fragment,e),T(es.$$.fragment,e),T(wt.$$.fragment,e),T(ts.$$.fragment,e),io=!0)},o(e){j(w.$$.fragment,e),j(I.$$.fragment,e),j(J.$$.fragment,e),j(B.$$.fragment,e),j(N.$$.fragment,e),j(Ge.$$.fragment,e),j(Et.$$.fragment,e),j(Qe.$$.fragment,e),j(Tt.$$.fragment,e),j(xt.$$.fragment,e),j(qt.$$.fragment,e),j(Pt.$$.fragment,e),j(Mt.$$.fragment,e),j(Ct.$$.fragment,e),j(It.$$.fragment,e),j(Ot.$$.fragment,e),j(Nt.$$.fragment,e),j(Lt.$$.fragment,e),j(st.$$.fragment,e),j(Wt.$$.fragment,e),j(Ut.$$.fragment,e),j(Rt.$$.fragment,e),j(Gt.$$.fragment,e),j(Yt.$$.fragment,e),j(Jt.$$.fragment,e),j(ft.$$.fragment,e),j(Qt.$$.fragment,e),j(mt.$$.fragment,e),j(ct.$$.fragment,e),j(ht.$$.fragment,e),j(Zt.$$.fragment,e),j($t.$$.fragment,e),j(_t.$$.fragment,e),j(Xt.$$.fragment,e),j(es.$$.fragment,e),j(wt.$$.fragment,e),j(ts.$$.fragment,e),io=!1},d(e){s(a),e&&s(m),e&&s(r),x(w),e&&s(y),x(I,e),e&&s(O),e&&s(D),e&&s(Q),x(J,e),e&&s(se),e&&s(V),x(B),e&&s($e),e&&s(oe),e&&s(M),x(N,e),e&&s(le),e&&s(q),e&&s(we),e&&s(fe),e&&s(yt),e&&s(Y),e&&s(Ba),e&&s(bt),e&&s(Ka),e&&s(ke),e&&s(Za),e&&s(At),e&&s(Xa),e&&s(Re),e&&s(er),x(Ge,e),e&&s(tr),e&&s(Se),x(Et),e&&s(sr),e&&s(Je),e&&s(ar),e&&s(ls),e&&s(rr),x(Qe,e),e&&s(or),e&&s(Ve),e&&s(nr),x(Tt,e),e&&s(lr),e&&s(ye),e&&s(ir),x(xt,e),e&&s(fr),e&&s(Be),e&&s(pr),x(qt,e),e&&s(ur),e&&s(be),e&&s(mr),x(Pt,e),e&&s(cr),e&&s(Ke),e&&s(hr),x(Mt,e),e&&s(dr),e&&s(Ae),e&&s($r),x(Ct,e),e&&s(_r),e&&s(Ze),e&&s(gr),x(It,e),e&&s(wr),e&&s(Xe),e&&s(vr),x(Ot,e),e&&s(kr),e&&s(et),e&&s(yr),e&&s(Ce),x(Nt),e&&s(br),e&&s(pe),e&&s(Ar),x(Lt,e),e&&s(Er),x(st,e),e&&s(Tr),e&&s(Ee),e&&s(jr),x(Wt,e),e&&s(xr),e&&s(Te),e&&s(qr),e&&s(Ie),x(Ut),e&&s(zr),x(Rt,e),e&&s(Pr),e&&s(Z),e&&s(Mr),e&&s(je),e&&s(Fr),e&&s(Oe),x(Gt),e&&s(Sr),e&&s(xe),e&&s(Cr),e&&s(ot),e&&s(Ir),x(Yt,e),e&&s(Or),e&&s(nt),e&&s(Nr),e&&s(Ts),e&&s(Dr),x(Jt,e),e&&s(Hr),e&&s(js),e&&s(Lr),e&&s(lt),e&&s(Wr),e&&s(it),e&&s(Ur),x(ft,e),e&&s(Rr),e&&s(pt),e&&s(Gr),e&&s(Ne),x(Qt),e&&s(Yr),x(mt,e),e&&s(Jr),x(ct,e),e&&s(Qr),e&&s(X),e&&s(Vr),x(ht,e),e&&s(Br),e&&s(De),x(Zt),e&&s(Kr),x($t,e),e&&s(Zr),e&&s(qe),e&&s(Xr),x(_t,e),e&&s(eo),e&&s(He),x(Xt),e&&s(to),e&&s(Is),e&&s(so),e&&s(ze),e&&s(ao),x(es,e),e&&s(ro),x(wt,e),e&&s(oo),e&&s(vt),e&&s(no),e&&s(Le),x(ts),e&&s(lo),e&&s(Hs)}}}const Eu={local:"quick-tour",sections:[{local:"pipeline",sections:[{local:"pipeline-usage",title:"Pipeline usage"},{local:"use-another-model-and-tokenizer-in-the-pipeline",title:"Use another model and tokenizer in the pipeline"}],title:"Pipeline"},{local:"autoclass",sections:[{local:"autotokenizer",title:"AutoTokenizer"},{local:"automodel",title:"AutoModel"},{local:"save-a-model",title:"Save a model"}],title:"AutoClass"},{local:"custom-model-builds",title:"Custom model builds"},{local:"whats-next",title:"What's next?"}],title:"Quick tour"};function Tu(P){return Wp(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Su extends Np{constructor(a){super();Dp(this,a,Tu,Au,Hp,{})}}export{Su as default,Eu as metadata};
