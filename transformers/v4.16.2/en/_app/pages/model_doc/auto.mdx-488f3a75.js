import{S as Grt,i as zrt,s as Vrt,e as a,k as l,w as f,t as o,L as Xrt,c as n,d as t,m as i,a as s,x as m,h as r,b as c,J as e,g as v,y as g,q as h,o as u,B as p}from"../../chunks/vendor-b1433968.js";import{T as s4r}from"../../chunks/Tip-c3840994.js";import{D as y}from"../../chunks/Docstring-ff504c58.js";import{C as w}from"../../chunks/CodeBlock-5eeb61a8.js";import{I as X}from"../../chunks/IconCopyLink-7029626d.js";import"../../chunks/CopyButton-40b92840.js";function Wrt(ei){let J,we,se,me,Ze,de,_e,$o,oi,zc,Ut,ri,ti,kE,Vc,Me,no,ai,vn,xE,bn,Tn,RE,ni,Fn,SE,si,Xc,Ea;return{c(){J=a("p"),we=o("If your "),se=a("code"),me=o("NewModelConfig"),Ze=o(" is a subclass of "),de=a("code"),_e=o("PretrainedConfig"),$o=o(`, make sure its
`),oi=a("code"),zc=o("model_type"),Ut=o(" attribute is set to the same key you use when registering the config (here "),ri=a("code"),ti=o('"new-model"'),kE=o(")."),Vc=l(),Me=a("p"),no=o("Likewise, if your "),ai=a("code"),vn=o("NewModel"),xE=o(" is a subclass of "),bn=a("a"),Tn=o("PreTrainedModel"),RE=o(`, make sure its
`),ni=a("code"),Fn=o("config_class"),SE=o(` attribute is set to the same class you use when registering the model (here
`),si=a("code"),Xc=o("NewModelConfig"),Ea=o(")."),this.h()},l(so){J=n(so,"P",{});var ge=s(J);we=r(ge,"If your "),se=n(ge,"CODE",{});var z0=s(se);me=r(z0,"NewModelConfig"),z0.forEach(t),Ze=r(ge," is a subclass of "),de=n(ge,"CODE",{});var li=s(de);_e=r(li,"PretrainedConfig"),li.forEach(t),$o=r(ge,`, make sure its
`),oi=n(ge,"CODE",{});var V0=s(oi);zc=r(V0,"model_type"),V0.forEach(t),Ut=r(ge," attribute is set to the same key you use when registering the config (here "),ri=n(ge,"CODE",{});var X0=s(ri);ti=r(X0,'"new-model"'),X0.forEach(t),kE=r(ge,")."),ge.forEach(t),Vc=i(so),Me=n(so,"P",{});var Io=s(Me);no=r(Io,"Likewise, if your "),ai=n(Io,"CODE",{});var Ma=s(ai);vn=r(Ma,"NewModel"),Ma.forEach(t),xE=r(Io," is a subclass of "),bn=n(Io,"A",{href:!0});var W0=s(bn);Tn=r(W0,"PreTrainedModel"),W0.forEach(t),RE=r(Io,`, make sure its
`),ni=n(Io,"CODE",{});var Wc=s(ni);Fn=r(Wc,"config_class"),Wc.forEach(t),SE=r(Io,` attribute is set to the same class you use when registering the model (here
`),si=n(Io,"CODE",{});var Q0=s(si);Xc=r(Q0,"NewModelConfig"),Q0.forEach(t),Ea=r(Io,")."),Io.forEach(t),this.h()},h(){c(bn,"href","/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel")},m(so,ge){v(so,J,ge),e(J,we),e(J,se),e(se,me),e(J,Ze),e(J,de),e(de,_e),e(J,$o),e(J,oi),e(oi,zc),e(J,Ut),e(J,ri),e(ri,ti),e(J,kE),v(so,Vc,ge),v(so,Me,ge),e(Me,no),e(Me,ai),e(ai,vn),e(Me,xE),e(Me,bn),e(bn,Tn),e(Me,RE),e(Me,ni),e(ni,Fn),e(Me,SE),e(Me,si),e(si,Xc),e(Me,Ea)},d(so){so&&t(J),so&&t(Vc),so&&t(Me)}}}function Qrt(ei){let J,we,se,me,Ze;return{c(){J=a("p"),we=o("Passing "),se=a("code"),me=o("use_auth_token=True"),Ze=o(" is required when you want to use a private model.")},l(de){J=n(de,"P",{});var _e=s(J);we=r(_e,"Passing "),se=n(_e,"CODE",{});var $o=s(se);me=r($o,"use_auth_token=True"),$o.forEach(t),Ze=r(_e," is required when you want to use a private model."),_e.forEach(t)},m(de,_e){v(de,J,_e),e(J,we),e(J,se),e(se,me),e(J,Ze)},d(de){de&&t(J)}}}function Hrt(ei){let J,we,se,me,Ze;return{c(){J=a("p"),we=o("Passing "),se=a("code"),me=o("use_auth_token=True"),Ze=o(" is required when you want to use a private model.")},l(de){J=n(de,"P",{});var _e=s(J);we=r(_e,"Passing "),se=n(_e,"CODE",{});var $o=s(se);me=r($o,"use_auth_token=True"),$o.forEach(t),Ze=r(_e," is required when you want to use a private model."),_e.forEach(t)},m(de,_e){v(de,J,_e),e(J,we),e(J,se),e(se,me),e(J,Ze)},d(de){de&&t(J)}}}function Urt(ei){let J,we,se,me,Ze,de,_e,$o,oi,zc,Ut,ri,ti,kE,Vc,Me,no,ai,vn,xE,bn,Tn,RE,ni,Fn,SE,si,Xc,Ea,so,ge,z0,li,V0,X0,Io,Ma,W0,Wc,Q0,U7e,owe,ii,Qc,UG,PE,J7e,JG,Y7e,rwe,Cn,K7e,YG,Z7e,eLe,KG,oLe,rLe,twe,$E,awe,H0,tLe,nwe,Hc,swe,di,Uc,ZG,IE,aLe,ez,nLe,lwe,jo,jE,sLe,NE,lLe,U0,iLe,dLe,cLe,DE,fLe,oz,mLe,gLe,hLe,lo,qE,uLe,rz,pLe,_Le,ci,vLe,tz,bLe,TLe,az,FLe,CLe,ELe,b,Jc,nz,MLe,yLe,J0,wLe,ALe,LLe,Yc,sz,BLe,kLe,Y0,xLe,RLe,SLe,Kc,lz,PLe,$Le,K0,ILe,jLe,NLe,Zc,iz,DLe,qLe,Z0,OLe,GLe,zLe,ef,dz,VLe,XLe,e7,WLe,QLe,HLe,of,cz,ULe,JLe,o7,YLe,KLe,ZLe,rf,fz,e8e,o8e,r7,r8e,t8e,a8e,tf,mz,n8e,s8e,t7,l8e,i8e,d8e,af,gz,c8e,f8e,a7,m8e,g8e,h8e,nf,hz,u8e,p8e,n7,_8e,v8e,b8e,sf,uz,T8e,F8e,s7,C8e,E8e,M8e,lf,pz,y8e,w8e,l7,A8e,L8e,B8e,df,_z,k8e,x8e,i7,R8e,S8e,P8e,cf,vz,$8e,I8e,d7,j8e,N8e,D8e,ff,bz,q8e,O8e,c7,G8e,z8e,V8e,mf,Tz,X8e,W8e,f7,Q8e,H8e,U8e,gf,Fz,J8e,Y8e,m7,K8e,Z8e,eBe,hf,Cz,oBe,rBe,g7,tBe,aBe,nBe,uf,Ez,sBe,lBe,h7,iBe,dBe,cBe,pf,Mz,fBe,mBe,u7,gBe,hBe,uBe,_f,yz,pBe,_Be,p7,vBe,bBe,TBe,vf,wz,FBe,CBe,_7,EBe,MBe,yBe,bf,Az,wBe,ABe,v7,LBe,BBe,kBe,Tf,Lz,xBe,RBe,b7,SBe,PBe,$Be,Ff,Bz,IBe,jBe,T7,NBe,DBe,qBe,Cf,kz,OBe,GBe,F7,zBe,VBe,XBe,Ef,xz,WBe,QBe,C7,HBe,UBe,JBe,Mf,Rz,YBe,KBe,E7,ZBe,e9e,o9e,yf,Sz,r9e,t9e,M7,a9e,n9e,s9e,wf,Pz,l9e,i9e,y7,d9e,c9e,f9e,Af,$z,m9e,g9e,w7,h9e,u9e,p9e,Lf,Iz,_9e,v9e,A7,b9e,T9e,F9e,Bf,jz,C9e,E9e,L7,M9e,y9e,w9e,kf,Nz,A9e,L9e,B7,B9e,k9e,x9e,xf,Dz,R9e,S9e,k7,P9e,$9e,I9e,Rf,qz,j9e,N9e,x7,D9e,q9e,O9e,Sf,Oz,G9e,z9e,R7,V9e,X9e,W9e,Pf,Gz,Q9e,H9e,S7,U9e,J9e,Y9e,$f,zz,K9e,Z9e,P7,eke,oke,rke,If,Vz,tke,ake,$7,nke,ske,lke,jf,Xz,ike,dke,I7,cke,fke,mke,Nf,Wz,gke,hke,j7,uke,pke,_ke,Df,Qz,vke,bke,N7,Tke,Fke,Cke,qf,Hz,Eke,Mke,D7,yke,wke,Ake,Of,Uz,Lke,Bke,q7,kke,xke,Rke,Gf,Jz,Ske,Pke,O7,$ke,Ike,jke,zf,Yz,Nke,Dke,G7,qke,Oke,Gke,Vf,Kz,zke,Vke,z7,Xke,Wke,Qke,Xf,Zz,Hke,Uke,V7,Jke,Yke,Kke,Wf,eV,Zke,exe,X7,oxe,rxe,txe,Qf,oV,axe,nxe,W7,sxe,lxe,ixe,Hf,rV,dxe,cxe,Q7,fxe,mxe,gxe,Uf,tV,hxe,uxe,H7,pxe,_xe,vxe,Jf,aV,bxe,Txe,U7,Fxe,Cxe,Exe,Yf,nV,Mxe,yxe,J7,wxe,Axe,Lxe,Kf,sV,Bxe,kxe,Y7,xxe,Rxe,Sxe,Zf,lV,Pxe,$xe,K7,Ixe,jxe,Nxe,em,iV,Dxe,qxe,Z7,Oxe,Gxe,zxe,om,dV,Vxe,Xxe,eL,Wxe,Qxe,Hxe,rm,cV,Uxe,Jxe,oL,Yxe,Kxe,Zxe,tm,fV,eRe,oRe,rL,rRe,tRe,aRe,am,mV,nRe,sRe,tL,lRe,iRe,dRe,nm,gV,cRe,fRe,aL,mRe,gRe,hRe,sm,hV,uRe,pRe,nL,_Re,vRe,bRe,lm,uV,TRe,FRe,sL,CRe,ERe,MRe,im,pV,yRe,wRe,lL,ARe,LRe,BRe,dm,_V,kRe,xRe,iL,RRe,SRe,PRe,cm,vV,$Re,IRe,dL,jRe,NRe,DRe,fm,bV,qRe,ORe,cL,GRe,zRe,VRe,mm,TV,XRe,WRe,fL,QRe,HRe,URe,gm,FV,JRe,YRe,mL,KRe,ZRe,eSe,hm,CV,oSe,rSe,gL,tSe,aSe,nSe,um,EV,sSe,lSe,hL,iSe,dSe,cSe,pm,MV,fSe,mSe,uL,gSe,hSe,uSe,_m,yV,pSe,_Se,pL,vSe,bSe,TSe,vm,wV,FSe,CSe,_L,ESe,MSe,ySe,bm,AV,wSe,ASe,vL,LSe,BSe,kSe,Tm,LV,xSe,RSe,bL,SSe,PSe,$Se,Fm,BV,ISe,jSe,TL,NSe,DSe,qSe,Cm,kV,OSe,GSe,FL,zSe,VSe,XSe,Em,xV,WSe,QSe,CL,HSe,USe,JSe,Mm,RV,YSe,KSe,EL,ZSe,ePe,oPe,ym,SV,rPe,tPe,ML,aPe,nPe,sPe,wm,PV,lPe,iPe,yL,dPe,cPe,fPe,Am,$V,mPe,gPe,wL,hPe,uPe,pPe,Lm,IV,_Pe,vPe,AL,bPe,TPe,FPe,jV,CPe,EPe,OE,MPe,Bm,GE,yPe,NV,wPe,iwe,fi,km,DV,zE,APe,qV,LPe,dwe,No,VE,BPe,XE,kPe,LL,xPe,RPe,SPe,WE,PPe,OV,$Pe,IPe,jPe,io,QE,NPe,GV,DPe,qPe,ya,OPe,zV,GPe,zPe,VV,VPe,XPe,XV,WPe,QPe,HPe,E,En,WV,UPe,JPe,BL,YPe,KPe,kL,ZPe,e$e,o$e,Mn,QV,r$e,t$e,xL,a$e,n$e,RL,s$e,l$e,i$e,yn,HV,d$e,c$e,SL,f$e,m$e,PL,g$e,h$e,u$e,xm,UV,p$e,_$e,$L,v$e,b$e,T$e,wn,JV,F$e,C$e,IL,E$e,M$e,jL,y$e,w$e,A$e,Rm,YV,L$e,B$e,NL,k$e,x$e,R$e,Sm,KV,S$e,P$e,DL,$$e,I$e,j$e,Pm,ZV,N$e,D$e,qL,q$e,O$e,G$e,An,eX,z$e,V$e,OL,X$e,W$e,GL,Q$e,H$e,U$e,Ln,oX,J$e,Y$e,zL,K$e,Z$e,VL,eIe,oIe,rIe,Bn,rX,tIe,aIe,XL,nIe,sIe,WL,lIe,iIe,dIe,$m,tX,cIe,fIe,QL,mIe,gIe,hIe,Im,aX,uIe,pIe,HL,_Ie,vIe,bIe,kn,nX,TIe,FIe,UL,CIe,EIe,JL,MIe,yIe,wIe,jm,sX,AIe,LIe,YL,BIe,kIe,xIe,xn,lX,RIe,SIe,KL,PIe,$Ie,ZL,IIe,jIe,NIe,Rn,iX,DIe,qIe,e8,OIe,GIe,o8,zIe,VIe,XIe,Sn,dX,WIe,QIe,r8,HIe,UIe,cX,JIe,YIe,KIe,Nm,fX,ZIe,eje,t8,oje,rje,tje,Pn,mX,aje,nje,a8,sje,lje,n8,ije,dje,cje,Dm,gX,fje,mje,s8,gje,hje,uje,$n,hX,pje,_je,l8,vje,bje,i8,Tje,Fje,Cje,In,uX,Eje,Mje,d8,yje,wje,c8,Aje,Lje,Bje,jn,pX,kje,xje,f8,Rje,Sje,m8,Pje,$je,Ije,qm,_X,jje,Nje,g8,Dje,qje,Oje,Nn,vX,Gje,zje,h8,Vje,Xje,u8,Wje,Qje,Hje,Om,bX,Uje,Jje,p8,Yje,Kje,Zje,Dn,TX,eNe,oNe,_8,rNe,tNe,v8,aNe,nNe,sNe,qn,FX,lNe,iNe,b8,dNe,cNe,T8,fNe,mNe,gNe,On,CX,hNe,uNe,F8,pNe,_Ne,C8,vNe,bNe,TNe,Gn,EX,FNe,CNe,E8,ENe,MNe,M8,yNe,wNe,ANe,Gm,MX,LNe,BNe,y8,kNe,xNe,RNe,zn,yX,SNe,PNe,w8,$Ne,INe,A8,jNe,NNe,DNe,Vn,wX,qNe,ONe,L8,GNe,zNe,B8,VNe,XNe,WNe,Xn,AX,QNe,HNe,k8,UNe,JNe,x8,YNe,KNe,ZNe,Wn,LX,eDe,oDe,R8,rDe,tDe,S8,aDe,nDe,sDe,Qn,BX,lDe,iDe,P8,dDe,cDe,$8,fDe,mDe,gDe,Hn,kX,hDe,uDe,I8,pDe,_De,j8,vDe,bDe,TDe,zm,xX,FDe,CDe,N8,EDe,MDe,yDe,Un,RX,wDe,ADe,D8,LDe,BDe,q8,kDe,xDe,RDe,Vm,SX,SDe,PDe,O8,$De,IDe,jDe,Xm,PX,NDe,DDe,G8,qDe,ODe,GDe,Jn,$X,zDe,VDe,z8,XDe,WDe,V8,QDe,HDe,UDe,Yn,IX,JDe,YDe,X8,KDe,ZDe,W8,eqe,oqe,rqe,Wm,jX,tqe,aqe,Q8,nqe,sqe,lqe,Kn,NX,iqe,dqe,H8,cqe,fqe,U8,mqe,gqe,hqe,Zn,DX,uqe,pqe,J8,_qe,vqe,Y8,bqe,Tqe,Fqe,es,qX,Cqe,Eqe,K8,Mqe,yqe,Z8,wqe,Aqe,Lqe,os,OX,Bqe,kqe,eB,xqe,Rqe,oB,Sqe,Pqe,$qe,rs,GX,Iqe,jqe,rB,Nqe,Dqe,tB,qqe,Oqe,Gqe,Qm,zX,zqe,Vqe,aB,Xqe,Wqe,Qqe,Hm,VX,Hqe,Uqe,nB,Jqe,Yqe,Kqe,Um,XX,Zqe,eOe,sB,oOe,rOe,tOe,ts,WX,aOe,nOe,lB,sOe,lOe,iB,iOe,dOe,cOe,Jm,QX,fOe,mOe,dB,gOe,hOe,uOe,as,HX,pOe,_Oe,cB,vOe,bOe,fB,TOe,FOe,COe,ns,UX,EOe,MOe,mB,yOe,wOe,gB,AOe,LOe,BOe,ss,JX,kOe,xOe,hB,ROe,SOe,uB,POe,$Oe,IOe,ls,YX,jOe,NOe,pB,DOe,qOe,_B,OOe,GOe,zOe,is,KX,VOe,XOe,vB,WOe,QOe,bB,HOe,UOe,JOe,Ym,ZX,YOe,KOe,TB,ZOe,eGe,oGe,Km,eW,rGe,tGe,FB,aGe,nGe,sGe,ds,oW,lGe,iGe,CB,dGe,cGe,EB,fGe,mGe,gGe,cs,rW,hGe,uGe,MB,pGe,_Ge,yB,vGe,bGe,TGe,fs,tW,FGe,CGe,wB,EGe,MGe,AB,yGe,wGe,AGe,Zm,aW,LGe,BGe,LB,kGe,xGe,RGe,eg,nW,SGe,PGe,BB,$Ge,IGe,jGe,og,sW,NGe,DGe,kB,qGe,OGe,GGe,rg,lW,zGe,VGe,xB,XGe,WGe,QGe,tg,iW,HGe,UGe,RB,JGe,YGe,KGe,ag,dW,ZGe,eze,SB,oze,rze,tze,ms,cW,aze,nze,PB,sze,lze,$B,ize,dze,cze,gs,fW,fze,mze,IB,gze,hze,jB,uze,pze,_ze,mW,vze,bze,HE,Tze,ng,UE,Fze,gW,Cze,cwe,mi,sg,hW,JE,Eze,uW,Mze,fwe,Wt,YE,yze,KE,wze,NB,Aze,Lze,Bze,ZE,kze,pW,xze,Rze,Sze,Ae,eM,Pze,_W,$ze,Ize,wa,jze,vW,Nze,Dze,bW,qze,Oze,TW,Gze,zze,Vze,ie,lg,FW,Xze,Wze,DB,Qze,Hze,Uze,ig,CW,Jze,Yze,qB,Kze,Zze,eVe,dg,EW,oVe,rVe,OB,tVe,aVe,nVe,cg,MW,sVe,lVe,GB,iVe,dVe,cVe,fg,yW,fVe,mVe,zB,gVe,hVe,uVe,mg,wW,pVe,_Ve,VB,vVe,bVe,TVe,gg,AW,FVe,CVe,XB,EVe,MVe,yVe,hg,LW,wVe,AVe,WB,LVe,BVe,kVe,ug,BW,xVe,RVe,QB,SVe,PVe,$Ve,pg,kW,IVe,jVe,HB,NVe,DVe,qVe,_g,xW,OVe,GVe,UB,zVe,VVe,XVe,vg,RW,WVe,QVe,JB,HVe,UVe,JVe,bg,YVe,SW,KVe,ZVe,oM,mwe,gi,Tg,PW,rM,eXe,$W,oXe,gwe,Qt,tM,rXe,aM,tXe,YB,aXe,nXe,sXe,nM,lXe,IW,iXe,dXe,cXe,Le,sM,fXe,jW,mXe,gXe,hi,hXe,NW,uXe,pXe,DW,_Xe,vXe,bXe,ye,Fg,qW,TXe,FXe,KB,CXe,EXe,MXe,Cg,OW,yXe,wXe,ZB,AXe,LXe,BXe,Eg,GW,kXe,xXe,e9,RXe,SXe,PXe,Mg,zW,$Xe,IXe,o9,jXe,NXe,DXe,yg,VW,qXe,OXe,r9,GXe,zXe,VXe,wg,XW,XXe,WXe,t9,QXe,HXe,UXe,Ag,WW,JXe,YXe,a9,KXe,ZXe,eWe,Lg,QW,oWe,rWe,n9,tWe,aWe,nWe,Bg,sWe,HW,lWe,iWe,lM,hwe,ui,kg,UW,iM,dWe,JW,cWe,uwe,Do,dM,fWe,pi,mWe,YW,gWe,hWe,KW,uWe,pWe,_We,cM,vWe,ZW,bWe,TWe,FWe,Br,fM,CWe,eQ,EWe,MWe,_i,yWe,oQ,wWe,AWe,rQ,LWe,BWe,kWe,tQ,xWe,RWe,mM,SWe,Be,gM,PWe,aQ,$We,IWe,Aa,jWe,nQ,NWe,DWe,sQ,qWe,OWe,lQ,GWe,zWe,VWe,F,xg,iQ,XWe,WWe,s9,QWe,HWe,UWe,Rg,dQ,JWe,YWe,l9,KWe,ZWe,eQe,Sg,cQ,oQe,rQe,i9,tQe,aQe,nQe,Pg,fQ,sQe,lQe,d9,iQe,dQe,cQe,$g,mQ,fQe,mQe,c9,gQe,hQe,uQe,Ig,gQ,pQe,_Qe,f9,vQe,bQe,TQe,jg,hQ,FQe,CQe,m9,EQe,MQe,yQe,Ng,uQ,wQe,AQe,g9,LQe,BQe,kQe,Dg,pQ,xQe,RQe,h9,SQe,PQe,$Qe,qg,_Q,IQe,jQe,u9,NQe,DQe,qQe,Og,vQ,OQe,GQe,p9,zQe,VQe,XQe,Gg,bQ,WQe,QQe,_9,HQe,UQe,JQe,zg,TQ,YQe,KQe,v9,ZQe,eHe,oHe,Vg,FQ,rHe,tHe,b9,aHe,nHe,sHe,Xg,CQ,lHe,iHe,T9,dHe,cHe,fHe,Wg,EQ,mHe,gHe,F9,hHe,uHe,pHe,Qg,MQ,_He,vHe,C9,bHe,THe,FHe,Hg,yQ,CHe,EHe,E9,MHe,yHe,wHe,Ug,wQ,AHe,LHe,M9,BHe,kHe,xHe,Jg,AQ,RHe,SHe,y9,PHe,$He,IHe,Yg,LQ,jHe,NHe,w9,DHe,qHe,OHe,Kg,BQ,GHe,zHe,A9,VHe,XHe,WHe,Zg,kQ,QHe,HHe,L9,UHe,JHe,YHe,eh,xQ,KHe,ZHe,B9,eUe,oUe,rUe,hs,RQ,tUe,aUe,k9,nUe,sUe,x9,lUe,iUe,dUe,oh,SQ,cUe,fUe,R9,mUe,gUe,hUe,rh,PQ,uUe,pUe,S9,_Ue,vUe,bUe,th,$Q,TUe,FUe,P9,CUe,EUe,MUe,ah,IQ,yUe,wUe,$9,AUe,LUe,BUe,nh,jQ,kUe,xUe,I9,RUe,SUe,PUe,sh,NQ,$Ue,IUe,j9,jUe,NUe,DUe,lh,DQ,qUe,OUe,N9,GUe,zUe,VUe,ih,qQ,XUe,WUe,D9,QUe,HUe,UUe,dh,OQ,JUe,YUe,q9,KUe,ZUe,eJe,ch,GQ,oJe,rJe,O9,tJe,aJe,nJe,fh,zQ,sJe,lJe,G9,iJe,dJe,cJe,mh,VQ,fJe,mJe,z9,gJe,hJe,uJe,gh,XQ,pJe,_Je,V9,vJe,bJe,TJe,hh,WQ,FJe,CJe,X9,EJe,MJe,yJe,uh,QQ,wJe,AJe,W9,LJe,BJe,kJe,ph,HQ,xJe,RJe,Q9,SJe,PJe,$Je,_h,UQ,IJe,jJe,H9,NJe,DJe,qJe,vh,JQ,OJe,GJe,U9,zJe,VJe,XJe,bh,YQ,WJe,QJe,J9,HJe,UJe,JJe,Th,KQ,YJe,KJe,Y9,ZJe,eYe,oYe,Fh,ZQ,rYe,tYe,K9,aYe,nYe,sYe,Ch,eH,lYe,iYe,Z9,dYe,cYe,fYe,Eh,oH,mYe,gYe,ek,hYe,uYe,pYe,Mh,rH,_Ye,vYe,ok,bYe,TYe,FYe,yh,tH,CYe,EYe,rk,MYe,yYe,wYe,wh,aH,AYe,LYe,tk,BYe,kYe,xYe,Ah,nH,RYe,SYe,ak,PYe,$Ye,IYe,Lh,sH,jYe,NYe,nk,DYe,qYe,OYe,Bh,lH,GYe,zYe,sk,VYe,XYe,WYe,kh,iH,QYe,HYe,lk,UYe,JYe,YYe,xh,dH,KYe,ZYe,ik,eKe,oKe,rKe,Rh,cH,tKe,aKe,dk,nKe,sKe,lKe,Sh,fH,iKe,dKe,ck,cKe,fKe,mKe,Ph,mH,gKe,hKe,fk,uKe,pKe,_Ke,$h,gH,vKe,bKe,mk,TKe,FKe,CKe,Ih,hH,EKe,MKe,gk,yKe,wKe,AKe,jh,uH,LKe,BKe,hk,kKe,xKe,RKe,Nh,pH,SKe,PKe,uk,$Ke,IKe,jKe,Dh,_H,NKe,DKe,pk,qKe,OKe,GKe,qh,vH,zKe,VKe,_k,XKe,WKe,QKe,Oh,bH,HKe,UKe,vk,JKe,YKe,KKe,Gh,TH,ZKe,eZe,bk,oZe,rZe,tZe,zh,FH,aZe,nZe,Tk,sZe,lZe,iZe,Vh,CH,dZe,cZe,Fk,fZe,mZe,gZe,Xh,EH,hZe,uZe,Ck,pZe,_Ze,vZe,Wh,MH,bZe,TZe,Ek,FZe,CZe,EZe,Qh,yH,MZe,yZe,Mk,wZe,AZe,LZe,Hh,wH,BZe,kZe,yk,xZe,RZe,SZe,Uh,AH,PZe,$Ze,wk,IZe,jZe,NZe,Jh,LH,DZe,qZe,Ak,OZe,GZe,zZe,Yh,BH,VZe,XZe,Lk,WZe,QZe,HZe,Kh,kH,UZe,JZe,Bk,YZe,KZe,ZZe,Zh,xH,eeo,oeo,kk,reo,teo,aeo,eu,RH,neo,seo,xk,leo,ieo,deo,ou,ceo,SH,feo,meo,PH,geo,heo,$H,ueo,peo,hM,pwe,vi,ru,IH,uM,_eo,jH,veo,_we,qo,pM,beo,bi,Teo,NH,Feo,Ceo,DH,Eeo,Meo,yeo,_M,weo,qH,Aeo,Leo,Beo,kr,vM,keo,OH,xeo,Reo,Ti,Seo,GH,Peo,$eo,zH,Ieo,jeo,Neo,VH,Deo,qeo,bM,Oeo,ke,TM,Geo,XH,zeo,Veo,La,Xeo,WH,Weo,Qeo,QH,Heo,Ueo,HH,Jeo,Yeo,Keo,x,tu,UH,Zeo,eoo,Rk,ooo,roo,too,au,JH,aoo,noo,Sk,soo,loo,ioo,nu,YH,doo,coo,Pk,foo,moo,goo,su,KH,hoo,uoo,$k,poo,_oo,voo,lu,ZH,boo,Too,Ik,Foo,Coo,Eoo,iu,eU,Moo,yoo,jk,woo,Aoo,Loo,du,oU,Boo,koo,Nk,xoo,Roo,Soo,cu,rU,Poo,$oo,Dk,Ioo,joo,Noo,fu,tU,Doo,qoo,qk,Ooo,Goo,zoo,mu,aU,Voo,Xoo,Ok,Woo,Qoo,Hoo,gu,nU,Uoo,Joo,Gk,Yoo,Koo,Zoo,hu,sU,ero,oro,zk,rro,tro,aro,uu,lU,nro,sro,Vk,lro,iro,dro,pu,iU,cro,fro,Xk,mro,gro,hro,_u,dU,uro,pro,Wk,_ro,vro,bro,vu,cU,Tro,Fro,Qk,Cro,Ero,Mro,bu,fU,yro,wro,Hk,Aro,Lro,Bro,Tu,mU,kro,xro,Uk,Rro,Sro,Pro,Fu,gU,$ro,Iro,Jk,jro,Nro,Dro,Cu,hU,qro,Oro,Yk,Gro,zro,Vro,Eu,uU,Xro,Wro,Kk,Qro,Hro,Uro,Mu,pU,Jro,Yro,Zk,Kro,Zro,eto,yu,_U,oto,rto,ex,tto,ato,nto,wu,vU,sto,lto,ox,ito,dto,cto,Au,bU,fto,mto,rx,gto,hto,uto,Lu,TU,pto,_to,tx,vto,bto,Tto,Bu,FU,Fto,Cto,ax,Eto,Mto,yto,ku,CU,wto,Ato,nx,Lto,Bto,kto,xu,EU,xto,Rto,sx,Sto,Pto,$to,Ru,MU,Ito,jto,lx,Nto,Dto,qto,Su,yU,Oto,Gto,ix,zto,Vto,Xto,Pu,wU,Wto,Qto,dx,Hto,Uto,Jto,$u,AU,Yto,Kto,cx,Zto,eao,oao,Iu,LU,rao,tao,fx,aao,nao,sao,ju,BU,lao,iao,mx,dao,cao,fao,Nu,kU,mao,gao,gx,hao,uao,pao,Du,xU,_ao,vao,hx,bao,Tao,Fao,qu,Cao,RU,Eao,Mao,SU,yao,wao,PU,Aao,Lao,FM,vwe,Fi,Ou,$U,CM,Bao,IU,kao,bwe,Oo,EM,xao,Ci,Rao,jU,Sao,Pao,NU,$ao,Iao,jao,MM,Nao,DU,Dao,qao,Oao,xr,yM,Gao,qU,zao,Vao,Ei,Xao,OU,Wao,Qao,GU,Hao,Uao,Jao,zU,Yao,Kao,wM,Zao,xe,AM,eno,VU,ono,rno,Ba,tno,XU,ano,nno,WU,sno,lno,QU,ino,dno,cno,j,Gu,HU,fno,mno,ux,gno,hno,uno,zu,UU,pno,_no,px,vno,bno,Tno,Vu,JU,Fno,Cno,_x,Eno,Mno,yno,Xu,YU,wno,Ano,vx,Lno,Bno,kno,Wu,KU,xno,Rno,bx,Sno,Pno,$no,Qu,ZU,Ino,jno,Tx,Nno,Dno,qno,Hu,eJ,Ono,Gno,Fx,zno,Vno,Xno,Uu,oJ,Wno,Qno,Cx,Hno,Uno,Jno,Ju,rJ,Yno,Kno,Ex,Zno,eso,oso,Yu,tJ,rso,tso,Mx,aso,nso,sso,Ku,aJ,lso,iso,yx,dso,cso,fso,Zu,nJ,mso,gso,wx,hso,uso,pso,ep,sJ,_so,vso,Ax,bso,Tso,Fso,op,lJ,Cso,Eso,Lx,Mso,yso,wso,rp,iJ,Aso,Lso,Bx,Bso,kso,xso,tp,dJ,Rso,Sso,kx,Pso,$so,Iso,ap,cJ,jso,Nso,xx,Dso,qso,Oso,np,fJ,Gso,zso,Rx,Vso,Xso,Wso,sp,mJ,Qso,Hso,Sx,Uso,Jso,Yso,lp,gJ,Kso,Zso,Px,elo,olo,rlo,ip,hJ,tlo,alo,$x,nlo,slo,llo,dp,uJ,ilo,dlo,Ix,clo,flo,mlo,cp,pJ,glo,hlo,jx,ulo,plo,_lo,fp,_J,vlo,blo,Nx,Tlo,Flo,Clo,mp,vJ,Elo,Mlo,Dx,ylo,wlo,Alo,gp,bJ,Llo,Blo,qx,klo,xlo,Rlo,hp,TJ,Slo,Plo,Ox,$lo,Ilo,jlo,up,FJ,Nlo,Dlo,Gx,qlo,Olo,Glo,pp,CJ,zlo,Vlo,zx,Xlo,Wlo,Qlo,_p,EJ,Hlo,Ulo,Vx,Jlo,Ylo,Klo,vp,MJ,Zlo,eio,Xx,oio,rio,tio,bp,aio,yJ,nio,sio,wJ,lio,iio,AJ,dio,cio,LM,Twe,Mi,Tp,LJ,BM,fio,BJ,mio,Fwe,Go,kM,gio,yi,hio,kJ,uio,pio,xJ,_io,vio,bio,xM,Tio,RJ,Fio,Cio,Eio,Rr,RM,Mio,SJ,yio,wio,wi,Aio,PJ,Lio,Bio,$J,kio,xio,Rio,IJ,Sio,Pio,SM,$io,Re,PM,Iio,jJ,jio,Nio,ka,Dio,NJ,qio,Oio,DJ,Gio,zio,qJ,Vio,Xio,Wio,$,Fp,OJ,Qio,Hio,Wx,Uio,Jio,Yio,Cp,GJ,Kio,Zio,Qx,edo,odo,rdo,Ep,zJ,tdo,ado,Hx,ndo,sdo,ldo,Mp,VJ,ido,ddo,Ux,cdo,fdo,mdo,yp,XJ,gdo,hdo,Jx,udo,pdo,_do,wp,WJ,vdo,bdo,Yx,Tdo,Fdo,Cdo,Ap,QJ,Edo,Mdo,Kx,ydo,wdo,Ado,Lp,HJ,Ldo,Bdo,Zx,kdo,xdo,Rdo,Bp,UJ,Sdo,Pdo,eR,$do,Ido,jdo,kp,JJ,Ndo,Ddo,oR,qdo,Odo,Gdo,xp,YJ,zdo,Vdo,rR,Xdo,Wdo,Qdo,Rp,KJ,Hdo,Udo,tR,Jdo,Ydo,Kdo,Sp,ZJ,Zdo,eco,aR,oco,rco,tco,Pp,eY,aco,nco,nR,sco,lco,ico,$p,oY,dco,cco,sR,fco,mco,gco,Ip,rY,hco,uco,lR,pco,_co,vco,jp,tY,bco,Tco,iR,Fco,Cco,Eco,Np,aY,Mco,yco,dR,wco,Aco,Lco,Dp,nY,Bco,kco,cR,xco,Rco,Sco,qp,sY,Pco,$co,fR,Ico,jco,Nco,Op,lY,Dco,qco,mR,Oco,Gco,zco,Gp,iY,Vco,Xco,gR,Wco,Qco,Hco,zp,dY,Uco,Jco,hR,Yco,Kco,Zco,Vp,cY,efo,ofo,uR,rfo,tfo,afo,Xp,fY,nfo,sfo,pR,lfo,ifo,dfo,Wp,mY,cfo,ffo,_R,mfo,gfo,hfo,Qp,gY,ufo,pfo,vR,_fo,vfo,bfo,Hp,hY,Tfo,Ffo,bR,Cfo,Efo,Mfo,Up,uY,yfo,wfo,TR,Afo,Lfo,Bfo,Jp,pY,kfo,xfo,_Y,Rfo,Sfo,Pfo,Yp,vY,$fo,Ifo,FR,jfo,Nfo,Dfo,Kp,bY,qfo,Ofo,CR,Gfo,zfo,Vfo,Zp,TY,Xfo,Wfo,ER,Qfo,Hfo,Ufo,e_,Jfo,FY,Yfo,Kfo,CY,Zfo,emo,EY,omo,rmo,$M,Cwe,Ai,o_,MY,IM,tmo,yY,amo,Ewe,zo,jM,nmo,Li,smo,wY,lmo,imo,AY,dmo,cmo,fmo,NM,mmo,LY,gmo,hmo,umo,Sr,DM,pmo,BY,_mo,vmo,Bi,bmo,kY,Tmo,Fmo,xY,Cmo,Emo,Mmo,RY,ymo,wmo,qM,Amo,Se,OM,Lmo,SY,Bmo,kmo,xa,xmo,PY,Rmo,Smo,$Y,Pmo,$mo,IY,Imo,jmo,Nmo,ne,r_,jY,Dmo,qmo,MR,Omo,Gmo,zmo,t_,NY,Vmo,Xmo,yR,Wmo,Qmo,Hmo,a_,DY,Umo,Jmo,wR,Ymo,Kmo,Zmo,n_,qY,ego,ogo,AR,rgo,tgo,ago,s_,OY,ngo,sgo,LR,lgo,igo,dgo,l_,GY,cgo,fgo,BR,mgo,ggo,hgo,i_,zY,ugo,pgo,kR,_go,vgo,bgo,d_,VY,Tgo,Fgo,xR,Cgo,Ego,Mgo,c_,XY,ygo,wgo,RR,Ago,Lgo,Bgo,f_,WY,kgo,xgo,SR,Rgo,Sgo,Pgo,m_,QY,$go,Igo,PR,jgo,Ngo,Dgo,g_,HY,qgo,Ogo,$R,Ggo,zgo,Vgo,h_,UY,Xgo,Wgo,IR,Qgo,Hgo,Ugo,u_,JY,Jgo,Ygo,jR,Kgo,Zgo,eho,p_,YY,oho,rho,NR,tho,aho,nho,__,sho,KY,lho,iho,ZY,dho,cho,eK,fho,mho,GM,Mwe,ki,v_,oK,zM,gho,rK,hho,ywe,Vo,VM,uho,xi,pho,tK,_ho,vho,aK,bho,Tho,Fho,XM,Cho,nK,Eho,Mho,yho,Pr,WM,who,sK,Aho,Lho,Ri,Bho,lK,kho,xho,iK,Rho,Sho,Pho,dK,$ho,Iho,QM,jho,Pe,HM,Nho,cK,Dho,qho,Ra,Oho,fK,Gho,zho,mK,Vho,Xho,gK,Who,Qho,Hho,A,b_,hK,Uho,Jho,DR,Yho,Kho,Zho,T_,uK,euo,ouo,qR,ruo,tuo,auo,F_,pK,nuo,suo,OR,luo,iuo,duo,C_,_K,cuo,fuo,GR,muo,guo,huo,E_,vK,uuo,puo,zR,_uo,vuo,buo,M_,bK,Tuo,Fuo,VR,Cuo,Euo,Muo,y_,TK,yuo,wuo,XR,Auo,Luo,Buo,w_,FK,kuo,xuo,WR,Ruo,Suo,Puo,A_,CK,$uo,Iuo,QR,juo,Nuo,Duo,L_,EK,quo,Ouo,HR,Guo,zuo,Vuo,B_,MK,Xuo,Wuo,UR,Quo,Huo,Uuo,k_,yK,Juo,Yuo,JR,Kuo,Zuo,epo,x_,wK,opo,rpo,YR,tpo,apo,npo,R_,AK,spo,lpo,KR,ipo,dpo,cpo,S_,LK,fpo,mpo,ZR,gpo,hpo,upo,P_,BK,ppo,_po,eS,vpo,bpo,Tpo,$_,kK,Fpo,Cpo,oS,Epo,Mpo,ypo,I_,xK,wpo,Apo,rS,Lpo,Bpo,kpo,j_,RK,xpo,Rpo,tS,Spo,Ppo,$po,N_,SK,Ipo,jpo,aS,Npo,Dpo,qpo,D_,PK,Opo,Gpo,nS,zpo,Vpo,Xpo,q_,$K,Wpo,Qpo,sS,Hpo,Upo,Jpo,O_,IK,Ypo,Kpo,lS,Zpo,e_o,o_o,G_,jK,r_o,t_o,iS,a_o,n_o,s_o,z_,NK,l_o,i_o,dS,d_o,c_o,f_o,V_,DK,m_o,g_o,cS,h_o,u_o,p_o,X_,qK,__o,v_o,fS,b_o,T_o,F_o,W_,OK,C_o,E_o,mS,M_o,y_o,w_o,Q_,GK,A_o,L_o,gS,B_o,k_o,x_o,H_,zK,R_o,S_o,hS,P_o,$_o,I_o,U_,VK,j_o,N_o,uS,D_o,q_o,O_o,J_,XK,G_o,z_o,pS,V_o,X_o,W_o,Y_,WK,Q_o,H_o,_S,U_o,J_o,Y_o,K_,QK,K_o,Z_o,vS,e2o,o2o,r2o,Z_,HK,t2o,a2o,bS,n2o,s2o,l2o,e2,UK,i2o,d2o,TS,c2o,f2o,m2o,o2,JK,g2o,h2o,FS,u2o,p2o,_2o,r2,YK,v2o,b2o,CS,T2o,F2o,C2o,t2,KK,E2o,M2o,ES,y2o,w2o,A2o,a2,ZK,L2o,B2o,MS,k2o,x2o,R2o,n2,eZ,S2o,P2o,yS,$2o,I2o,j2o,s2,oZ,N2o,D2o,wS,q2o,O2o,G2o,l2,rZ,z2o,V2o,AS,X2o,W2o,Q2o,i2,H2o,tZ,U2o,J2o,aZ,Y2o,K2o,nZ,Z2o,evo,UM,wwe,Si,d2,sZ,JM,ovo,lZ,rvo,Awe,Xo,YM,tvo,Pi,avo,iZ,nvo,svo,dZ,lvo,ivo,dvo,KM,cvo,cZ,fvo,mvo,gvo,$r,ZM,hvo,fZ,uvo,pvo,$i,_vo,mZ,vvo,bvo,gZ,Tvo,Fvo,Cvo,hZ,Evo,Mvo,e3,yvo,$e,o3,wvo,uZ,Avo,Lvo,Sa,Bvo,pZ,kvo,xvo,_Z,Rvo,Svo,vZ,Pvo,$vo,Ivo,O,c2,bZ,jvo,Nvo,LS,Dvo,qvo,Ovo,f2,TZ,Gvo,zvo,BS,Vvo,Xvo,Wvo,m2,FZ,Qvo,Hvo,kS,Uvo,Jvo,Yvo,g2,CZ,Kvo,Zvo,xS,e1o,o1o,r1o,h2,EZ,t1o,a1o,RS,n1o,s1o,l1o,u2,MZ,i1o,d1o,SS,c1o,f1o,m1o,p2,yZ,g1o,h1o,PS,u1o,p1o,_1o,_2,wZ,v1o,b1o,$S,T1o,F1o,C1o,v2,AZ,E1o,M1o,IS,y1o,w1o,A1o,b2,LZ,L1o,B1o,jS,k1o,x1o,R1o,T2,BZ,S1o,P1o,NS,$1o,I1o,j1o,F2,kZ,N1o,D1o,DS,q1o,O1o,G1o,C2,xZ,z1o,V1o,qS,X1o,W1o,Q1o,E2,RZ,H1o,U1o,OS,J1o,Y1o,K1o,M2,SZ,Z1o,e4o,GS,o4o,r4o,t4o,y2,PZ,a4o,n4o,zS,s4o,l4o,i4o,w2,$Z,d4o,c4o,VS,f4o,m4o,g4o,A2,IZ,h4o,u4o,XS,p4o,_4o,v4o,L2,jZ,b4o,T4o,WS,F4o,C4o,E4o,B2,NZ,M4o,y4o,QS,w4o,A4o,L4o,k2,DZ,B4o,k4o,HS,x4o,R4o,S4o,x2,qZ,P4o,$4o,US,I4o,j4o,N4o,R2,OZ,D4o,q4o,JS,O4o,G4o,z4o,S2,GZ,V4o,X4o,YS,W4o,Q4o,H4o,P2,zZ,U4o,J4o,KS,Y4o,K4o,Z4o,$2,VZ,ebo,obo,ZS,rbo,tbo,abo,I2,nbo,XZ,sbo,lbo,WZ,ibo,dbo,QZ,cbo,fbo,r3,Lwe,Ii,j2,HZ,t3,mbo,UZ,gbo,Bwe,Wo,a3,hbo,ji,ubo,JZ,pbo,_bo,YZ,vbo,bbo,Tbo,n3,Fbo,KZ,Cbo,Ebo,Mbo,Ir,s3,ybo,ZZ,wbo,Abo,Ni,Lbo,eee,Bbo,kbo,oee,xbo,Rbo,Sbo,ree,Pbo,$bo,l3,Ibo,Ie,i3,jbo,tee,Nbo,Dbo,Pa,qbo,aee,Obo,Gbo,nee,zbo,Vbo,see,Xbo,Wbo,Qbo,Ht,N2,lee,Hbo,Ubo,eP,Jbo,Ybo,Kbo,D2,iee,Zbo,eTo,oP,oTo,rTo,tTo,q2,dee,aTo,nTo,rP,sTo,lTo,iTo,O2,cee,dTo,cTo,tP,fTo,mTo,gTo,G2,fee,hTo,uTo,aP,pTo,_To,vTo,z2,bTo,mee,TTo,FTo,gee,CTo,ETo,hee,MTo,yTo,d3,kwe,Di,V2,uee,c3,wTo,pee,ATo,xwe,Qo,f3,LTo,qi,BTo,_ee,kTo,xTo,vee,RTo,STo,PTo,m3,$To,bee,ITo,jTo,NTo,jr,g3,DTo,Tee,qTo,OTo,Oi,GTo,Fee,zTo,VTo,Cee,XTo,WTo,QTo,Eee,HTo,UTo,h3,JTo,je,u3,YTo,Mee,KTo,ZTo,$a,e6o,yee,o6o,r6o,wee,t6o,a6o,Aee,n6o,s6o,l6o,N,X2,Lee,i6o,d6o,nP,c6o,f6o,m6o,W2,Bee,g6o,h6o,sP,u6o,p6o,_6o,Q2,kee,v6o,b6o,lP,T6o,F6o,C6o,H2,xee,E6o,M6o,iP,y6o,w6o,A6o,U2,Ree,L6o,B6o,dP,k6o,x6o,R6o,J2,See,S6o,P6o,cP,$6o,I6o,j6o,Y2,Pee,N6o,D6o,fP,q6o,O6o,G6o,K2,$ee,z6o,V6o,mP,X6o,W6o,Q6o,Z2,Iee,H6o,U6o,gP,J6o,Y6o,K6o,ev,jee,Z6o,eFo,hP,oFo,rFo,tFo,ov,Nee,aFo,nFo,uP,sFo,lFo,iFo,rv,Dee,dFo,cFo,pP,fFo,mFo,gFo,tv,qee,hFo,uFo,_P,pFo,_Fo,vFo,av,Oee,bFo,TFo,vP,FFo,CFo,EFo,nv,Gee,MFo,yFo,bP,wFo,AFo,LFo,sv,zee,BFo,kFo,TP,xFo,RFo,SFo,lv,Vee,PFo,$Fo,FP,IFo,jFo,NFo,iv,Xee,DFo,qFo,CP,OFo,GFo,zFo,dv,Wee,VFo,XFo,EP,WFo,QFo,HFo,cv,Qee,UFo,JFo,MP,YFo,KFo,ZFo,fv,Hee,eCo,oCo,yP,rCo,tCo,aCo,mv,Uee,nCo,sCo,wP,lCo,iCo,dCo,gv,Jee,cCo,fCo,AP,mCo,gCo,hCo,hv,Yee,uCo,pCo,LP,_Co,vCo,bCo,uv,Kee,TCo,FCo,BP,CCo,ECo,MCo,pv,Zee,yCo,wCo,kP,ACo,LCo,BCo,_v,eoe,kCo,xCo,xP,RCo,SCo,PCo,vv,ooe,$Co,ICo,RP,jCo,NCo,DCo,bv,roe,qCo,OCo,SP,GCo,zCo,VCo,Tv,toe,XCo,WCo,PP,QCo,HCo,UCo,Fv,aoe,JCo,YCo,$P,KCo,ZCo,eEo,Cv,oEo,noe,rEo,tEo,soe,aEo,nEo,loe,sEo,lEo,p3,Rwe,Gi,Ev,ioe,_3,iEo,doe,dEo,Swe,Ho,v3,cEo,zi,fEo,coe,mEo,gEo,foe,hEo,uEo,pEo,b3,_Eo,moe,vEo,bEo,TEo,Nr,T3,FEo,goe,CEo,EEo,Vi,MEo,hoe,yEo,wEo,uoe,AEo,LEo,BEo,poe,kEo,xEo,F3,REo,Ne,C3,SEo,_oe,PEo,$Eo,Ia,IEo,voe,jEo,NEo,boe,DEo,qEo,Toe,OEo,GEo,zEo,R,Mv,Foe,VEo,XEo,IP,WEo,QEo,HEo,yv,Coe,UEo,JEo,jP,YEo,KEo,ZEo,wv,Eoe,eMo,oMo,NP,rMo,tMo,aMo,Av,Moe,nMo,sMo,DP,lMo,iMo,dMo,Lv,yoe,cMo,fMo,qP,mMo,gMo,hMo,Bv,woe,uMo,pMo,OP,_Mo,vMo,bMo,kv,Aoe,TMo,FMo,GP,CMo,EMo,MMo,xv,Loe,yMo,wMo,zP,AMo,LMo,BMo,Rv,Boe,kMo,xMo,VP,RMo,SMo,PMo,Sv,koe,$Mo,IMo,XP,jMo,NMo,DMo,Pv,xoe,qMo,OMo,WP,GMo,zMo,VMo,$v,Roe,XMo,WMo,QP,QMo,HMo,UMo,Iv,Soe,JMo,YMo,HP,KMo,ZMo,e3o,jv,Poe,o3o,r3o,UP,t3o,a3o,n3o,Nv,$oe,s3o,l3o,JP,i3o,d3o,c3o,Dv,Ioe,f3o,m3o,YP,g3o,h3o,u3o,qv,joe,p3o,_3o,KP,v3o,b3o,T3o,Ov,Noe,F3o,C3o,ZP,E3o,M3o,y3o,Gv,Doe,w3o,A3o,e$,L3o,B3o,k3o,zv,qoe,x3o,R3o,o$,S3o,P3o,$3o,Vv,Ooe,I3o,j3o,r$,N3o,D3o,q3o,Xv,Goe,O3o,G3o,t$,z3o,V3o,X3o,Wv,zoe,W3o,Q3o,a$,H3o,U3o,J3o,Qv,Voe,Y3o,K3o,n$,Z3o,e5o,o5o,Hv,Xoe,r5o,t5o,s$,a5o,n5o,s5o,Uv,Woe,l5o,i5o,l$,d5o,c5o,f5o,Jv,Qoe,m5o,g5o,i$,h5o,u5o,p5o,Yv,Hoe,_5o,v5o,d$,b5o,T5o,F5o,Kv,Uoe,C5o,E5o,c$,M5o,y5o,w5o,Zv,Joe,A5o,L5o,f$,B5o,k5o,x5o,e1,Yoe,R5o,S5o,m$,P5o,$5o,I5o,o1,Koe,j5o,N5o,g$,D5o,q5o,O5o,r1,Zoe,G5o,z5o,h$,V5o,X5o,W5o,t1,ere,Q5o,H5o,u$,U5o,J5o,Y5o,a1,ore,K5o,Z5o,p$,eyo,oyo,ryo,n1,rre,tyo,ayo,_$,nyo,syo,lyo,s1,tre,iyo,dyo,v$,cyo,fyo,myo,l1,gyo,are,hyo,uyo,nre,pyo,_yo,sre,vyo,byo,E3,Pwe,Xi,i1,lre,M3,Tyo,ire,Fyo,$we,Uo,y3,Cyo,Wi,Eyo,dre,Myo,yyo,cre,wyo,Ayo,Lyo,w3,Byo,fre,kyo,xyo,Ryo,Dr,A3,Syo,mre,Pyo,$yo,Qi,Iyo,gre,jyo,Nyo,hre,Dyo,qyo,Oyo,ure,Gyo,zyo,L3,Vyo,De,B3,Xyo,pre,Wyo,Qyo,ja,Hyo,_re,Uyo,Jyo,vre,Yyo,Kyo,bre,Zyo,ewo,owo,Tre,d1,Fre,rwo,two,b$,awo,nwo,swo,c1,lwo,Cre,iwo,dwo,Ere,cwo,fwo,Mre,mwo,gwo,k3,Iwe,Hi,f1,yre,x3,hwo,wre,uwo,jwe,Jo,R3,pwo,Ui,_wo,Are,vwo,bwo,Lre,Two,Fwo,Cwo,S3,Ewo,Bre,Mwo,ywo,wwo,qr,P3,Awo,kre,Lwo,Bwo,Ji,kwo,xre,xwo,Rwo,Rre,Swo,Pwo,$wo,Sre,Iwo,jwo,$3,Nwo,qe,I3,Dwo,Pre,qwo,Owo,Na,Gwo,$re,zwo,Vwo,Ire,Xwo,Wwo,jre,Qwo,Hwo,Uwo,eo,m1,Nre,Jwo,Ywo,T$,Kwo,Zwo,eAo,us,Dre,oAo,rAo,F$,tAo,aAo,C$,nAo,sAo,lAo,g1,qre,iAo,dAo,E$,cAo,fAo,mAo,Jt,Ore,gAo,hAo,M$,uAo,pAo,y$,_Ao,vAo,w$,bAo,TAo,FAo,h1,Gre,CAo,EAo,A$,MAo,yAo,wAo,u1,zre,AAo,LAo,L$,BAo,kAo,xAo,p1,Vre,RAo,SAo,B$,PAo,$Ao,IAo,_1,jAo,Xre,NAo,DAo,Wre,qAo,OAo,Qre,GAo,zAo,j3,Nwe,Yi,v1,Hre,N3,VAo,Ure,XAo,Dwe,Yo,D3,WAo,Ki,QAo,Jre,HAo,UAo,Yre,JAo,YAo,KAo,q3,ZAo,Kre,e0o,o0o,r0o,Or,O3,t0o,Zre,a0o,n0o,Zi,s0o,ete,l0o,i0o,ote,d0o,c0o,f0o,rte,m0o,g0o,G3,h0o,Oe,z3,u0o,tte,p0o,_0o,Da,v0o,ate,b0o,T0o,nte,F0o,C0o,ste,E0o,M0o,y0o,lte,b1,ite,w0o,A0o,k$,L0o,B0o,k0o,T1,x0o,dte,R0o,S0o,cte,P0o,$0o,fte,I0o,j0o,V3,qwe,ed,F1,mte,X3,N0o,gte,D0o,Owe,Ko,W3,q0o,od,O0o,hte,G0o,z0o,ute,V0o,X0o,W0o,Q3,Q0o,pte,H0o,U0o,J0o,Gr,H3,Y0o,_te,K0o,Z0o,rd,e7o,vte,o7o,r7o,bte,t7o,a7o,n7o,Tte,s7o,l7o,U3,i7o,Ge,J3,d7o,Fte,c7o,f7o,qa,m7o,Cte,g7o,h7o,Ete,u7o,p7o,Mte,_7o,v7o,b7o,oo,C1,yte,T7o,F7o,x$,C7o,E7o,M7o,E1,wte,y7o,w7o,R$,A7o,L7o,B7o,M1,Ate,k7o,x7o,S$,R7o,S7o,P7o,y1,Lte,$7o,I7o,P$,j7o,N7o,D7o,w1,Bte,q7o,O7o,$$,G7o,z7o,V7o,A1,kte,X7o,W7o,I$,Q7o,H7o,U7o,L1,xte,J7o,Y7o,j$,K7o,Z7o,eLo,B1,oLo,Rte,rLo,tLo,Ste,aLo,nLo,Pte,sLo,lLo,Y3,Gwe,td,k1,$te,K3,iLo,Ite,dLo,zwe,Zo,Z3,cLo,ad,fLo,jte,mLo,gLo,Nte,hLo,uLo,pLo,e5,_Lo,Dte,vLo,bLo,TLo,zr,o5,FLo,qte,CLo,ELo,nd,MLo,Ote,yLo,wLo,Gte,ALo,LLo,BLo,zte,kLo,xLo,r5,RLo,ze,t5,SLo,Vte,PLo,$Lo,Oa,ILo,Xte,jLo,NLo,Wte,DLo,qLo,Qte,OLo,GLo,zLo,sd,x1,Hte,VLo,XLo,N$,WLo,QLo,HLo,R1,Ute,ULo,JLo,D$,YLo,KLo,ZLo,S1,Jte,e8o,o8o,q$,r8o,t8o,a8o,P1,n8o,Yte,s8o,l8o,Kte,i8o,d8o,Zte,c8o,f8o,a5,Vwe,ld,$1,eae,n5,m8o,oae,g8o,Xwe,er,s5,h8o,id,u8o,rae,p8o,_8o,tae,v8o,b8o,T8o,l5,F8o,aae,C8o,E8o,M8o,Vr,i5,y8o,nae,w8o,A8o,dd,L8o,sae,B8o,k8o,lae,x8o,R8o,S8o,iae,P8o,$8o,d5,I8o,Ve,c5,j8o,dae,N8o,D8o,Ga,q8o,cae,O8o,G8o,fae,z8o,V8o,mae,X8o,W8o,Q8o,ro,I1,gae,H8o,U8o,O$,J8o,Y8o,K8o,j1,hae,Z8o,eBo,G$,oBo,rBo,tBo,N1,uae,aBo,nBo,z$,sBo,lBo,iBo,D1,pae,dBo,cBo,V$,fBo,mBo,gBo,q1,_ae,hBo,uBo,X$,pBo,_Bo,vBo,O1,vae,bBo,TBo,W$,FBo,CBo,EBo,G1,bae,MBo,yBo,Q$,wBo,ABo,LBo,z1,BBo,Tae,kBo,xBo,Fae,RBo,SBo,Cae,PBo,$Bo,f5,Wwe,cd,V1,Eae,m5,IBo,Mae,jBo,Qwe,or,g5,NBo,fd,DBo,yae,qBo,OBo,wae,GBo,zBo,VBo,h5,XBo,Aae,WBo,QBo,HBo,Xr,u5,UBo,Lae,JBo,YBo,md,KBo,Bae,ZBo,e9o,kae,o9o,r9o,t9o,xae,a9o,n9o,p5,s9o,Xe,_5,l9o,Rae,i9o,d9o,za,c9o,Sae,f9o,m9o,Pae,g9o,h9o,$ae,u9o,p9o,_9o,v5,X1,Iae,v9o,b9o,H$,T9o,F9o,C9o,W1,jae,E9o,M9o,U$,y9o,w9o,A9o,Q1,L9o,Nae,B9o,k9o,Dae,x9o,R9o,qae,S9o,P9o,b5,Hwe,gd,H1,Oae,T5,$9o,Gae,I9o,Uwe,rr,F5,j9o,hd,N9o,zae,D9o,q9o,Vae,O9o,G9o,z9o,C5,V9o,Xae,X9o,W9o,Q9o,Wr,E5,H9o,Wae,U9o,J9o,ud,Y9o,Qae,K9o,Z9o,Hae,eko,oko,rko,Uae,tko,ako,M5,nko,We,y5,sko,Jae,lko,iko,Va,dko,Yae,cko,fko,Kae,mko,gko,Zae,hko,uko,pko,pd,U1,ene,_ko,vko,J$,bko,Tko,Fko,J1,one,Cko,Eko,Y$,Mko,yko,wko,Y1,rne,Ako,Lko,K$,Bko,kko,xko,K1,Rko,tne,Sko,Pko,ane,$ko,Iko,nne,jko,Nko,w5,Jwe,_d,Z1,sne,A5,Dko,lne,qko,Ywe,tr,L5,Oko,vd,Gko,ine,zko,Vko,dne,Xko,Wko,Qko,B5,Hko,cne,Uko,Jko,Yko,Qr,k5,Kko,fne,Zko,exo,bd,oxo,mne,rxo,txo,gne,axo,nxo,sxo,hne,lxo,ixo,x5,dxo,Qe,R5,cxo,une,fxo,mxo,Xa,gxo,pne,hxo,uxo,_ne,pxo,_xo,vne,vxo,bxo,Txo,bne,e4,Tne,Fxo,Cxo,Z$,Exo,Mxo,yxo,o4,wxo,Fne,Axo,Lxo,Cne,Bxo,kxo,Ene,xxo,Rxo,S5,Kwe,Td,r4,Mne,P5,Sxo,yne,Pxo,Zwe,ar,$5,$xo,Fd,Ixo,wne,jxo,Nxo,Ane,Dxo,qxo,Oxo,I5,Gxo,Lne,zxo,Vxo,Xxo,Hr,j5,Wxo,Bne,Qxo,Hxo,Cd,Uxo,kne,Jxo,Yxo,xne,Kxo,Zxo,eRo,Rne,oRo,rRo,N5,tRo,He,D5,aRo,Sne,nRo,sRo,Wa,lRo,Pne,iRo,dRo,$ne,cRo,fRo,Ine,mRo,gRo,hRo,jne,t4,Nne,uRo,pRo,eI,_Ro,vRo,bRo,a4,TRo,Dne,FRo,CRo,qne,ERo,MRo,One,yRo,wRo,q5,eAe,Ed,n4,Gne,O5,ARo,zne,LRo,oAe,nr,G5,BRo,Md,kRo,Vne,xRo,RRo,Xne,SRo,PRo,$Ro,z5,IRo,Wne,jRo,NRo,DRo,Ur,V5,qRo,Qne,ORo,GRo,yd,zRo,Hne,VRo,XRo,Une,WRo,QRo,HRo,Jne,URo,JRo,X5,YRo,co,W5,KRo,Yne,ZRo,eSo,Qa,oSo,Kne,rSo,tSo,Zne,aSo,nSo,ese,sSo,lSo,iSo,B,s4,ose,dSo,cSo,oI,fSo,mSo,gSo,l4,rse,hSo,uSo,rI,pSo,_So,vSo,i4,tse,bSo,TSo,tI,FSo,CSo,ESo,d4,ase,MSo,ySo,aI,wSo,ASo,LSo,c4,nse,BSo,kSo,nI,xSo,RSo,SSo,f4,sse,PSo,$So,sI,ISo,jSo,NSo,m4,lse,DSo,qSo,lI,OSo,GSo,zSo,g4,ise,VSo,XSo,iI,WSo,QSo,HSo,h4,dse,USo,JSo,dI,YSo,KSo,ZSo,u4,cse,ePo,oPo,cI,rPo,tPo,aPo,p4,fse,nPo,sPo,fI,lPo,iPo,dPo,_4,mse,cPo,fPo,mI,mPo,gPo,hPo,v4,gse,uPo,pPo,gI,_Po,vPo,bPo,b4,hse,TPo,FPo,hI,CPo,EPo,MPo,T4,use,yPo,wPo,uI,APo,LPo,BPo,ps,pse,kPo,xPo,pI,RPo,SPo,_I,PPo,$Po,IPo,F4,_se,jPo,NPo,vI,DPo,qPo,OPo,C4,vse,GPo,zPo,bI,VPo,XPo,WPo,E4,bse,QPo,HPo,TI,UPo,JPo,YPo,M4,Tse,KPo,ZPo,FI,e$o,o$o,r$o,y4,Fse,t$o,a$o,CI,n$o,s$o,l$o,w4,Cse,i$o,d$o,EI,c$o,f$o,m$o,A4,Ese,g$o,h$o,MI,u$o,p$o,_$o,L4,Mse,v$o,b$o,yI,T$o,F$o,C$o,B4,yse,E$o,M$o,wI,y$o,w$o,A$o,k4,wse,L$o,B$o,AI,k$o,x$o,R$o,x4,Ase,S$o,P$o,LI,$$o,I$o,j$o,R4,Lse,N$o,D$o,BI,q$o,O$o,G$o,S4,Bse,z$o,V$o,kI,X$o,W$o,Q$o,P4,kse,H$o,U$o,xI,J$o,Y$o,K$o,$4,xse,Z$o,eIo,RI,oIo,rIo,tIo,I4,Rse,aIo,nIo,SI,sIo,lIo,iIo,j4,Sse,dIo,cIo,PI,fIo,mIo,gIo,N4,Pse,hIo,uIo,$I,pIo,_Io,vIo,D4,$se,bIo,TIo,II,FIo,CIo,EIo,q4,Ise,MIo,yIo,jI,wIo,AIo,LIo,O4,jse,BIo,kIo,NI,xIo,RIo,SIo,G4,Nse,PIo,$Io,DI,IIo,jIo,NIo,z4,Dse,DIo,qIo,qI,OIo,GIo,zIo,V4,qse,VIo,XIo,OI,WIo,QIo,HIo,Ose,UIo,JIo,Q5,rAe,wd,X4,Gse,H5,YIo,zse,KIo,tAe,sr,U5,ZIo,Ad,ejo,Vse,ojo,rjo,Xse,tjo,ajo,njo,J5,sjo,Wse,ljo,ijo,djo,Jr,Y5,cjo,Qse,fjo,mjo,Ld,gjo,Hse,hjo,ujo,Use,pjo,_jo,vjo,Jse,bjo,Tjo,K5,Fjo,fo,Z5,Cjo,Yse,Ejo,Mjo,Ha,yjo,Kse,wjo,Ajo,Zse,Ljo,Bjo,ele,kjo,xjo,Rjo,Q,W4,ole,Sjo,Pjo,GI,$jo,Ijo,jjo,Q4,rle,Njo,Djo,zI,qjo,Ojo,Gjo,H4,tle,zjo,Vjo,VI,Xjo,Wjo,Qjo,U4,ale,Hjo,Ujo,XI,Jjo,Yjo,Kjo,J4,nle,Zjo,eNo,WI,oNo,rNo,tNo,Y4,sle,aNo,nNo,QI,sNo,lNo,iNo,K4,lle,dNo,cNo,HI,fNo,mNo,gNo,Z4,ile,hNo,uNo,UI,pNo,_No,vNo,eb,dle,bNo,TNo,JI,FNo,CNo,ENo,ob,cle,MNo,yNo,YI,wNo,ANo,LNo,rb,fle,BNo,kNo,KI,xNo,RNo,SNo,tb,mle,PNo,$No,ZI,INo,jNo,NNo,ab,gle,DNo,qNo,ej,ONo,GNo,zNo,nb,hle,VNo,XNo,oj,WNo,QNo,HNo,sb,ule,UNo,JNo,rj,YNo,KNo,ZNo,lb,ple,eDo,oDo,tj,rDo,tDo,aDo,ib,_le,nDo,sDo,aj,lDo,iDo,dDo,db,vle,cDo,fDo,nj,mDo,gDo,hDo,cb,ble,uDo,pDo,sj,_Do,vDo,bDo,fb,Tle,TDo,FDo,lj,CDo,EDo,MDo,mb,Fle,yDo,wDo,ij,ADo,LDo,BDo,gb,Cle,kDo,xDo,dj,RDo,SDo,PDo,Ele,$Do,IDo,ey,aAe,Bd,hb,Mle,oy,jDo,yle,NDo,nAe,lr,ry,DDo,kd,qDo,wle,ODo,GDo,Ale,zDo,VDo,XDo,ty,WDo,Lle,QDo,HDo,UDo,Yr,ay,JDo,Ble,YDo,KDo,xd,ZDo,kle,eqo,oqo,xle,rqo,tqo,aqo,Rle,nqo,sqo,ny,lqo,mo,sy,iqo,Sle,dqo,cqo,Ua,fqo,Ple,mqo,gqo,$le,hqo,uqo,Ile,pqo,_qo,vqo,he,ub,jle,bqo,Tqo,cj,Fqo,Cqo,Eqo,pb,Nle,Mqo,yqo,fj,wqo,Aqo,Lqo,_b,Dle,Bqo,kqo,mj,xqo,Rqo,Sqo,vb,qle,Pqo,$qo,gj,Iqo,jqo,Nqo,bb,Ole,Dqo,qqo,hj,Oqo,Gqo,zqo,Tb,Gle,Vqo,Xqo,uj,Wqo,Qqo,Hqo,Fb,zle,Uqo,Jqo,pj,Yqo,Kqo,Zqo,Cb,Vle,eOo,oOo,_j,rOo,tOo,aOo,Eb,Xle,nOo,sOo,vj,lOo,iOo,dOo,Mb,Wle,cOo,fOo,bj,mOo,gOo,hOo,Qle,uOo,pOo,ly,sAe,Rd,yb,Hle,iy,_Oo,Ule,vOo,lAe,ir,dy,bOo,Sd,TOo,Jle,FOo,COo,Yle,EOo,MOo,yOo,cy,wOo,Kle,AOo,LOo,BOo,Kr,fy,kOo,Zle,xOo,ROo,Pd,SOo,eie,POo,$Oo,oie,IOo,jOo,NOo,rie,DOo,qOo,my,OOo,go,gy,GOo,tie,zOo,VOo,Ja,XOo,aie,WOo,QOo,nie,HOo,UOo,sie,JOo,YOo,KOo,lie,wb,iie,ZOo,eGo,Tj,oGo,rGo,tGo,die,aGo,nGo,hy,iAe,$d,Ab,cie,uy,sGo,fie,lGo,dAe,dr,py,iGo,Id,dGo,mie,cGo,fGo,gie,mGo,gGo,hGo,_y,uGo,hie,pGo,_Go,vGo,Zr,vy,bGo,uie,TGo,FGo,jd,CGo,pie,EGo,MGo,_ie,yGo,wGo,AGo,vie,LGo,BGo,by,kGo,ho,Ty,xGo,bie,RGo,SGo,Ya,PGo,Tie,$Go,IGo,Fie,jGo,NGo,Cie,DGo,qGo,OGo,Y,Lb,Eie,GGo,zGo,Fj,VGo,XGo,WGo,Bb,Mie,QGo,HGo,Cj,UGo,JGo,YGo,kb,yie,KGo,ZGo,Ej,ezo,ozo,rzo,xb,wie,tzo,azo,Mj,nzo,szo,lzo,Rb,Aie,izo,dzo,yj,czo,fzo,mzo,Sb,Lie,gzo,hzo,wj,uzo,pzo,_zo,Pb,Bie,vzo,bzo,Aj,Tzo,Fzo,Czo,$b,kie,Ezo,Mzo,Lj,yzo,wzo,Azo,Ib,xie,Lzo,Bzo,Bj,kzo,xzo,Rzo,jb,Rie,Szo,Pzo,kj,$zo,Izo,jzo,Nb,Sie,Nzo,Dzo,xj,qzo,Ozo,Gzo,Db,Pie,zzo,Vzo,Rj,Xzo,Wzo,Qzo,qb,$ie,Hzo,Uzo,Sj,Jzo,Yzo,Kzo,Ob,Iie,Zzo,eVo,Pj,oVo,rVo,tVo,Gb,jie,aVo,nVo,$j,sVo,lVo,iVo,zb,Nie,dVo,cVo,Ij,fVo,mVo,gVo,Vb,Die,hVo,uVo,jj,pVo,_Vo,vVo,Xb,qie,bVo,TVo,Nj,FVo,CVo,EVo,Wb,Oie,MVo,yVo,Dj,wVo,AVo,LVo,Qb,Gie,BVo,kVo,qj,xVo,RVo,SVo,zie,PVo,$Vo,Fy,cAe,Nd,Hb,Vie,Cy,IVo,Xie,jVo,fAe,cr,Ey,NVo,Dd,DVo,Wie,qVo,OVo,Qie,GVo,zVo,VVo,My,XVo,Hie,WVo,QVo,HVo,et,yy,UVo,Uie,JVo,YVo,qd,KVo,Jie,ZVo,eXo,Yie,oXo,rXo,tXo,Kie,aXo,nXo,wy,sXo,uo,Ay,lXo,Zie,iXo,dXo,Ka,cXo,ede,fXo,mXo,ode,gXo,hXo,rde,uXo,pXo,_Xo,ue,Ub,tde,vXo,bXo,Oj,TXo,FXo,CXo,Jb,ade,EXo,MXo,Gj,yXo,wXo,AXo,Yb,nde,LXo,BXo,zj,kXo,xXo,RXo,Kb,sde,SXo,PXo,Vj,$Xo,IXo,jXo,Zb,lde,NXo,DXo,Xj,qXo,OXo,GXo,eT,ide,zXo,VXo,Wj,XXo,WXo,QXo,oT,dde,HXo,UXo,Qj,JXo,YXo,KXo,rT,cde,ZXo,eWo,Hj,oWo,rWo,tWo,tT,fde,aWo,nWo,Uj,sWo,lWo,iWo,aT,mde,dWo,cWo,Jj,fWo,mWo,gWo,gde,hWo,uWo,Ly,mAe,Od,nT,hde,By,pWo,ude,_Wo,gAe,fr,ky,vWo,Gd,bWo,pde,TWo,FWo,_de,CWo,EWo,MWo,xy,yWo,vde,wWo,AWo,LWo,ot,Ry,BWo,bde,kWo,xWo,zd,RWo,Tde,SWo,PWo,Fde,$Wo,IWo,jWo,Cde,NWo,DWo,Sy,qWo,po,Py,OWo,Ede,GWo,zWo,Za,VWo,Mde,XWo,WWo,yde,QWo,HWo,wde,UWo,JWo,YWo,G,sT,Ade,KWo,ZWo,Yj,eQo,oQo,rQo,lT,Lde,tQo,aQo,Kj,nQo,sQo,lQo,iT,Bde,iQo,dQo,Zj,cQo,fQo,mQo,dT,kde,gQo,hQo,eN,uQo,pQo,_Qo,cT,xde,vQo,bQo,oN,TQo,FQo,CQo,fT,Rde,EQo,MQo,rN,yQo,wQo,AQo,mT,Sde,LQo,BQo,tN,kQo,xQo,RQo,gT,Pde,SQo,PQo,aN,$Qo,IQo,jQo,hT,$de,NQo,DQo,nN,qQo,OQo,GQo,uT,Ide,zQo,VQo,sN,XQo,WQo,QQo,pT,jde,HQo,UQo,lN,JQo,YQo,KQo,_T,Nde,ZQo,eHo,iN,oHo,rHo,tHo,vT,Dde,aHo,nHo,dN,sHo,lHo,iHo,bT,qde,dHo,cHo,cN,fHo,mHo,gHo,TT,Ode,hHo,uHo,fN,pHo,_Ho,vHo,FT,Gde,bHo,THo,mN,FHo,CHo,EHo,CT,zde,MHo,yHo,gN,wHo,AHo,LHo,ET,Vde,BHo,kHo,hN,xHo,RHo,SHo,MT,Xde,PHo,$Ho,uN,IHo,jHo,NHo,yT,Wde,DHo,qHo,pN,OHo,GHo,zHo,wT,Qde,VHo,XHo,_N,WHo,QHo,HHo,AT,Hde,UHo,JHo,vN,YHo,KHo,ZHo,LT,Ude,eUo,oUo,bN,rUo,tUo,aUo,BT,Jde,nUo,sUo,TN,lUo,iUo,dUo,kT,Yde,cUo,fUo,FN,mUo,gUo,hUo,Kde,uUo,pUo,$y,hAe,Vd,xT,Zde,Iy,_Uo,ece,vUo,uAe,mr,jy,bUo,Xd,TUo,oce,FUo,CUo,rce,EUo,MUo,yUo,Ny,wUo,tce,AUo,LUo,BUo,rt,Dy,kUo,ace,xUo,RUo,Wd,SUo,nce,PUo,$Uo,sce,IUo,jUo,NUo,lce,DUo,qUo,qy,OUo,_o,Oy,GUo,ice,zUo,VUo,en,XUo,dce,WUo,QUo,cce,HUo,UUo,fce,JUo,YUo,KUo,te,RT,mce,ZUo,eJo,CN,oJo,rJo,tJo,ST,gce,aJo,nJo,EN,sJo,lJo,iJo,PT,hce,dJo,cJo,MN,fJo,mJo,gJo,$T,uce,hJo,uJo,yN,pJo,_Jo,vJo,IT,pce,bJo,TJo,wN,FJo,CJo,EJo,jT,_ce,MJo,yJo,AN,wJo,AJo,LJo,NT,vce,BJo,kJo,LN,xJo,RJo,SJo,DT,bce,PJo,$Jo,BN,IJo,jJo,NJo,qT,Tce,DJo,qJo,kN,OJo,GJo,zJo,OT,Fce,VJo,XJo,xN,WJo,QJo,HJo,GT,Cce,UJo,JJo,RN,YJo,KJo,ZJo,zT,Ece,eYo,oYo,SN,rYo,tYo,aYo,VT,Mce,nYo,sYo,PN,lYo,iYo,dYo,XT,yce,cYo,fYo,$N,mYo,gYo,hYo,WT,wce,uYo,pYo,IN,_Yo,vYo,bYo,QT,Ace,TYo,FYo,jN,CYo,EYo,MYo,HT,Lce,yYo,wYo,NN,AYo,LYo,BYo,Bce,kYo,xYo,Gy,pAe,Qd,UT,kce,zy,RYo,xce,SYo,_Ae,gr,Vy,PYo,Hd,$Yo,Rce,IYo,jYo,Sce,NYo,DYo,qYo,Xy,OYo,Pce,GYo,zYo,VYo,tt,Wy,XYo,$ce,WYo,QYo,Ud,HYo,Ice,UYo,JYo,jce,YYo,KYo,ZYo,Nce,eKo,oKo,Qy,rKo,vo,Hy,tKo,Dce,aKo,nKo,on,sKo,qce,lKo,iKo,Oce,dKo,cKo,Gce,fKo,mKo,gKo,zce,JT,Vce,hKo,uKo,DN,pKo,_Ko,vKo,Xce,bKo,TKo,Uy,vAe,Jd,YT,Wce,Jy,FKo,Qce,CKo,bAe,hr,Yy,EKo,Yd,MKo,Hce,yKo,wKo,Uce,AKo,LKo,BKo,Ky,kKo,Jce,xKo,RKo,SKo,at,Zy,PKo,Yce,$Ko,IKo,Kd,jKo,Kce,NKo,DKo,Zce,qKo,OKo,GKo,efe,zKo,VKo,ew,XKo,bo,ow,WKo,ofe,QKo,HKo,rn,UKo,rfe,JKo,YKo,tfe,KKo,ZKo,afe,eZo,oZo,rZo,K,KT,nfe,tZo,aZo,qN,nZo,sZo,lZo,ZT,sfe,iZo,dZo,ON,cZo,fZo,mZo,e6,lfe,gZo,hZo,GN,uZo,pZo,_Zo,o6,ife,vZo,bZo,zN,TZo,FZo,CZo,r6,dfe,EZo,MZo,VN,yZo,wZo,AZo,t6,cfe,LZo,BZo,XN,kZo,xZo,RZo,a6,ffe,SZo,PZo,WN,$Zo,IZo,jZo,n6,mfe,NZo,DZo,QN,qZo,OZo,GZo,s6,gfe,zZo,VZo,HN,XZo,WZo,QZo,l6,hfe,HZo,UZo,UN,JZo,YZo,KZo,i6,ufe,ZZo,eer,JN,oer,rer,ter,d6,pfe,aer,ner,YN,ser,ler,ier,c6,_fe,der,cer,KN,fer,mer,ger,f6,vfe,her,uer,ZN,per,_er,ver,m6,bfe,ber,Ter,eD,Fer,Cer,Eer,g6,Tfe,Mer,yer,oD,wer,Aer,Ler,h6,Ffe,Ber,ker,rD,xer,Rer,Ser,u6,Cfe,Per,$er,tD,Ier,jer,Ner,p6,Efe,Der,qer,aD,Oer,Ger,zer,_6,Mfe,Ver,Xer,nD,Wer,Qer,Her,yfe,Uer,Jer,rw,TAe,Zd,v6,wfe,tw,Yer,Afe,Ker,FAe,ur,aw,Zer,ec,eor,Lfe,oor,ror,Bfe,tor,aor,nor,nw,sor,kfe,lor,ior,dor,nt,sw,cor,xfe,mor,gor,oc,hor,Rfe,uor,por,Sfe,_or,vor,bor,Pfe,Tor,For,lw,Cor,To,iw,Eor,$fe,Mor,yor,tn,wor,Ife,Aor,Lor,jfe,Bor,kor,Nfe,xor,Ror,Sor,Z,b6,Dfe,Por,$or,sD,Ior,jor,Nor,T6,qfe,Dor,qor,lD,Oor,Gor,zor,F6,Ofe,Vor,Xor,iD,Wor,Qor,Hor,C6,Gfe,Uor,Jor,dD,Yor,Kor,Zor,E6,zfe,err,orr,cD,rrr,trr,arr,M6,Vfe,nrr,srr,fD,lrr,irr,drr,y6,Xfe,crr,frr,mD,mrr,grr,hrr,w6,Wfe,urr,prr,gD,_rr,vrr,brr,A6,Qfe,Trr,Frr,hD,Crr,Err,Mrr,L6,Hfe,yrr,wrr,uD,Arr,Lrr,Brr,B6,Ufe,krr,xrr,pD,Rrr,Srr,Prr,k6,Jfe,$rr,Irr,_D,jrr,Nrr,Drr,x6,Yfe,qrr,Orr,vD,Grr,zrr,Vrr,R6,Kfe,Xrr,Wrr,bD,Qrr,Hrr,Urr,S6,Zfe,Jrr,Yrr,TD,Krr,Zrr,etr,P6,eme,otr,rtr,FD,ttr,atr,ntr,$6,ome,str,ltr,CD,itr,dtr,ctr,I6,rme,ftr,mtr,ED,gtr,htr,utr,j6,tme,ptr,_tr,MD,vtr,btr,Ttr,ame,Ftr,Ctr,dw,CAe,rc,N6,nme,cw,Etr,sme,Mtr,EAe,pr,fw,ytr,tc,wtr,lme,Atr,Ltr,ime,Btr,ktr,xtr,mw,Rtr,dme,Str,Ptr,$tr,st,gw,Itr,cme,jtr,Ntr,ac,Dtr,fme,qtr,Otr,mme,Gtr,ztr,Vtr,gme,Xtr,Wtr,hw,Qtr,Fo,uw,Htr,hme,Utr,Jtr,an,Ytr,ume,Ktr,Ztr,pme,ear,oar,_me,rar,tar,aar,vme,D6,bme,nar,sar,yD,lar,iar,dar,Tme,car,far,pw,MAe,nc,q6,Fme,_w,mar,Cme,gar,yAe,_r,vw,har,sc,uar,Eme,par,_ar,Mme,bar,Tar,Far,bw,Car,yme,Ear,Mar,yar,lt,Tw,war,wme,Aar,Lar,lc,Bar,Ame,kar,xar,Lme,Rar,Sar,Par,Bme,$ar,Iar,Fw,jar,Co,Cw,Nar,kme,Dar,qar,nn,Oar,xme,Gar,zar,Rme,Var,Xar,Sme,War,Qar,Har,W,O6,Pme,Uar,Jar,wD,Yar,Kar,Zar,G6,$me,enr,onr,AD,rnr,tnr,anr,z6,Ime,nnr,snr,LD,lnr,inr,dnr,V6,jme,cnr,fnr,BD,mnr,gnr,hnr,X6,Nme,unr,pnr,kD,_nr,vnr,bnr,W6,Dme,Tnr,Fnr,xD,Cnr,Enr,Mnr,Q6,qme,ynr,wnr,RD,Anr,Lnr,Bnr,H6,Ome,knr,xnr,SD,Rnr,Snr,Pnr,U6,Gme,$nr,Inr,PD,jnr,Nnr,Dnr,J6,zme,qnr,Onr,$D,Gnr,znr,Vnr,Y6,Vme,Xnr,Wnr,ID,Qnr,Hnr,Unr,K6,Xme,Jnr,Ynr,jD,Knr,Znr,esr,Z6,Wme,osr,rsr,ND,tsr,asr,nsr,eF,Qme,ssr,lsr,DD,isr,dsr,csr,oF,Hme,fsr,msr,qD,gsr,hsr,usr,rF,Ume,psr,_sr,OD,vsr,bsr,Tsr,tF,Jme,Fsr,Csr,GD,Esr,Msr,ysr,aF,Yme,wsr,Asr,zD,Lsr,Bsr,ksr,nF,Kme,xsr,Rsr,VD,Ssr,Psr,$sr,sF,Zme,Isr,jsr,XD,Nsr,Dsr,qsr,lF,ege,Osr,Gsr,WD,zsr,Vsr,Xsr,iF,oge,Wsr,Qsr,QD,Hsr,Usr,Jsr,dF,rge,Ysr,Ksr,HD,Zsr,elr,olr,tge,rlr,tlr,Ew,wAe,ic,cF,age,Mw,alr,nge,nlr,AAe,vr,yw,slr,dc,llr,sge,ilr,dlr,lge,clr,flr,mlr,ww,glr,ige,hlr,ulr,plr,it,Aw,_lr,dge,vlr,blr,cc,Tlr,cge,Flr,Clr,fge,Elr,Mlr,ylr,mge,wlr,Alr,Lw,Llr,Eo,Bw,Blr,gge,klr,xlr,sn,Rlr,hge,Slr,Plr,uge,$lr,Ilr,pge,jlr,Nlr,Dlr,fc,fF,_ge,qlr,Olr,UD,Glr,zlr,Vlr,mF,vge,Xlr,Wlr,JD,Qlr,Hlr,Ulr,gF,bge,Jlr,Ylr,YD,Klr,Zlr,eir,Tge,oir,rir,kw,LAe,mc,hF,Fge,xw,tir,Cge,air,BAe,br,Rw,nir,gc,sir,Ege,lir,iir,Mge,dir,cir,fir,Sw,mir,yge,gir,hir,uir,dt,Pw,pir,wge,_ir,vir,hc,bir,Age,Tir,Fir,Lge,Cir,Eir,Mir,Bge,yir,wir,$w,Air,Mo,Iw,Lir,kge,Bir,kir,ln,xir,xge,Rir,Sir,Rge,Pir,$ir,Sge,Iir,jir,Nir,ce,uF,Pge,Dir,qir,KD,Oir,Gir,zir,pF,$ge,Vir,Xir,ZD,Wir,Qir,Hir,_F,Ige,Uir,Jir,eq,Yir,Kir,Zir,vF,jge,edr,odr,oq,rdr,tdr,adr,bF,Nge,ndr,sdr,rq,ldr,idr,ddr,TF,Dge,cdr,fdr,tq,mdr,gdr,hdr,FF,qge,udr,pdr,aq,_dr,vdr,bdr,CF,Oge,Tdr,Fdr,nq,Cdr,Edr,Mdr,EF,Gge,ydr,wdr,sq,Adr,Ldr,Bdr,MF,zge,kdr,xdr,lq,Rdr,Sdr,Pdr,yF,Vge,$dr,Idr,iq,jdr,Ndr,Ddr,Xge,qdr,Odr,jw,kAe,uc,wF,Wge,Nw,Gdr,Qge,zdr,xAe,Tr,Dw,Vdr,pc,Xdr,Hge,Wdr,Qdr,Uge,Hdr,Udr,Jdr,qw,Ydr,Jge,Kdr,Zdr,ecr,ct,Ow,ocr,Yge,rcr,tcr,_c,acr,Kge,ncr,scr,Zge,lcr,icr,dcr,ehe,ccr,fcr,Gw,mcr,yo,zw,gcr,ohe,hcr,ucr,dn,pcr,rhe,_cr,vcr,the,bcr,Tcr,ahe,Fcr,Ccr,Ecr,ve,AF,nhe,Mcr,ycr,dq,wcr,Acr,Lcr,LF,she,Bcr,kcr,cq,xcr,Rcr,Scr,BF,lhe,Pcr,$cr,fq,Icr,jcr,Ncr,kF,ihe,Dcr,qcr,mq,Ocr,Gcr,zcr,xF,dhe,Vcr,Xcr,gq,Wcr,Qcr,Hcr,RF,che,Ucr,Jcr,hq,Ycr,Kcr,Zcr,SF,fhe,efr,ofr,uq,rfr,tfr,afr,PF,mhe,nfr,sfr,pq,lfr,ifr,dfr,$F,ghe,cfr,ffr,_q,mfr,gfr,hfr,hhe,ufr,pfr,Vw,RAe,vc,IF,uhe,Xw,_fr,phe,vfr,SAe,Fr,Ww,bfr,bc,Tfr,_he,Ffr,Cfr,vhe,Efr,Mfr,yfr,Qw,wfr,bhe,Afr,Lfr,Bfr,ft,Hw,kfr,The,xfr,Rfr,Tc,Sfr,Fhe,Pfr,$fr,Che,Ifr,jfr,Nfr,Ehe,Dfr,qfr,Uw,Ofr,wo,Jw,Gfr,Mhe,zfr,Vfr,cn,Xfr,yhe,Wfr,Qfr,whe,Hfr,Ufr,Ahe,Jfr,Yfr,Kfr,be,jF,Lhe,Zfr,emr,vq,omr,rmr,tmr,NF,Bhe,amr,nmr,bq,smr,lmr,imr,DF,khe,dmr,cmr,Tq,fmr,mmr,gmr,qF,xhe,hmr,umr,Fq,pmr,_mr,vmr,OF,Rhe,bmr,Tmr,Cq,Fmr,Cmr,Emr,GF,She,Mmr,ymr,Eq,wmr,Amr,Lmr,zF,Phe,Bmr,kmr,Mq,xmr,Rmr,Smr,VF,$he,Pmr,$mr,yq,Imr,jmr,Nmr,XF,Ihe,Dmr,qmr,wq,Omr,Gmr,zmr,jhe,Vmr,Xmr,Yw,PAe,Fc,WF,Nhe,Kw,Wmr,Dhe,Qmr,$Ae,Cr,Zw,Hmr,Cc,Umr,qhe,Jmr,Ymr,Ohe,Kmr,Zmr,egr,eA,ogr,Ghe,rgr,tgr,agr,mt,oA,ngr,zhe,sgr,lgr,Ec,igr,Vhe,dgr,cgr,Xhe,fgr,mgr,ggr,Whe,hgr,ugr,rA,pgr,Ao,tA,_gr,Qhe,vgr,bgr,fn,Tgr,Hhe,Fgr,Cgr,Uhe,Egr,Mgr,Jhe,ygr,wgr,Agr,Te,QF,Yhe,Lgr,Bgr,Aq,kgr,xgr,Rgr,HF,Khe,Sgr,Pgr,Lq,$gr,Igr,jgr,UF,Zhe,Ngr,Dgr,Bq,qgr,Ogr,Ggr,JF,eue,zgr,Vgr,kq,Xgr,Wgr,Qgr,YF,oue,Hgr,Ugr,xq,Jgr,Ygr,Kgr,KF,rue,Zgr,ehr,Rq,ohr,rhr,thr,ZF,tue,ahr,nhr,Sq,shr,lhr,ihr,eC,aue,dhr,chr,Pq,fhr,mhr,ghr,oC,nue,hhr,uhr,$q,phr,_hr,vhr,sue,bhr,Thr,aA,IAe,Mc,rC,lue,nA,Fhr,iue,Chr,jAe,Er,sA,Ehr,yc,Mhr,due,yhr,whr,cue,Ahr,Lhr,Bhr,lA,khr,fue,xhr,Rhr,Shr,gt,iA,Phr,mue,$hr,Ihr,wc,jhr,gue,Nhr,Dhr,hue,qhr,Ohr,Ghr,uue,zhr,Vhr,dA,Xhr,Lo,cA,Whr,pue,Qhr,Hhr,mn,Uhr,_ue,Jhr,Yhr,vue,Khr,Zhr,bue,eur,our,rur,Fe,tC,Tue,tur,aur,Iq,nur,sur,lur,aC,Fue,iur,dur,jq,cur,fur,mur,nC,Cue,gur,hur,Nq,uur,pur,_ur,sC,Eue,vur,bur,Dq,Tur,Fur,Cur,lC,Mue,Eur,Mur,qq,yur,wur,Aur,iC,yue,Lur,Bur,Oq,kur,xur,Rur,dC,wue,Sur,Pur,Gq,$ur,Iur,jur,cC,Aue,Nur,Dur,zq,qur,Our,Gur,fC,Lue,zur,Vur,Vq,Xur,Wur,Qur,Bue,Hur,Uur,fA,NAe,Ac,mC,kue,mA,Jur,xue,Yur,DAe,Mr,gA,Kur,Lc,Zur,Rue,epr,opr,Sue,rpr,tpr,apr,hA,npr,Pue,spr,lpr,ipr,ht,uA,dpr,$ue,cpr,fpr,Bc,mpr,Iue,gpr,hpr,jue,upr,ppr,_pr,Nue,vpr,bpr,pA,Tpr,Bo,_A,Fpr,Due,Cpr,Epr,gn,Mpr,que,ypr,wpr,Oue,Apr,Lpr,Gue,Bpr,kpr,xpr,to,gC,zue,Rpr,Spr,Xq,Ppr,$pr,Ipr,hC,Vue,jpr,Npr,Wq,Dpr,qpr,Opr,uC,Xue,Gpr,zpr,Qq,Vpr,Xpr,Wpr,pC,Wue,Qpr,Hpr,Hq,Upr,Jpr,Ypr,_C,Que,Kpr,Zpr,Uq,e_r,o_r,r_r,vC,Hue,t_r,a_r,Jq,n_r,s_r,l_r,bC,Uue,i_r,d_r,Yq,c_r,f_r,m_r,Jue,g_r,h_r,vA,qAe,kc,TC,Yue,bA,u_r,Kue,p_r,OAe,yr,TA,__r,xc,v_r,Zue,b_r,T_r,epe,F_r,C_r,E_r,FA,M_r,ope,y_r,w_r,A_r,ut,CA,L_r,rpe,B_r,k_r,Rc,x_r,tpe,R_r,S_r,ape,P_r,$_r,I_r,npe,j_r,N_r,EA,D_r,ko,MA,q_r,spe,O_r,G_r,hn,z_r,lpe,V_r,X_r,ipe,W_r,Q_r,dpe,H_r,U_r,J_r,ao,FC,cpe,Y_r,K_r,Kq,Z_r,e2r,o2r,CC,fpe,r2r,t2r,Zq,a2r,n2r,s2r,EC,mpe,l2r,i2r,eO,d2r,c2r,f2r,MC,gpe,m2r,g2r,oO,h2r,u2r,p2r,yC,hpe,_2r,v2r,rO,b2r,T2r,F2r,wC,upe,C2r,E2r,tO,M2r,y2r,w2r,AC,ppe,A2r,L2r,aO,B2r,k2r,x2r,_pe,R2r,S2r,yA,GAe,Sc,LC,vpe,wA,P2r,bpe,$2r,zAe,wr,AA,I2r,Pc,j2r,Tpe,N2r,D2r,Fpe,q2r,O2r,G2r,LA,z2r,Cpe,V2r,X2r,W2r,pt,BA,Q2r,Epe,H2r,U2r,$c,J2r,Mpe,Y2r,K2r,ype,Z2r,evr,ovr,wpe,rvr,tvr,kA,avr,xo,xA,nvr,Ape,svr,lvr,un,ivr,Lpe,dvr,cvr,Bpe,fvr,mvr,kpe,gvr,hvr,uvr,xpe,BC,Rpe,pvr,_vr,nO,vvr,bvr,Tvr,Spe,Fvr,Cvr,RA,VAe,Ic,kC,Ppe,SA,Evr,$pe,Mvr,XAe,Ar,PA,yvr,jc,wvr,Ipe,Avr,Lvr,jpe,Bvr,kvr,xvr,$A,Rvr,Npe,Svr,Pvr,$vr,_t,IA,Ivr,Dpe,jvr,Nvr,Nc,Dvr,qpe,qvr,Ovr,Ope,Gvr,zvr,Vvr,Gpe,Xvr,Wvr,jA,Qvr,Ro,NA,Hvr,zpe,Uvr,Jvr,pn,Yvr,Vpe,Kvr,Zvr,Xpe,e1r,o1r,Wpe,r1r,t1r,a1r,DA,xC,Qpe,n1r,s1r,sO,l1r,i1r,d1r,RC,Hpe,c1r,f1r,lO,m1r,g1r,h1r,Upe,u1r,p1r,qA,WAe,Dc,SC,Jpe,OA,_1r,Ype,v1r,QAe,Lr,GA,b1r,qc,T1r,Kpe,F1r,C1r,Zpe,E1r,M1r,y1r,zA,w1r,e_e,A1r,L1r,B1r,vt,VA,k1r,o_e,x1r,R1r,Oc,S1r,r_e,P1r,$1r,t_e,I1r,j1r,N1r,a_e,D1r,q1r,XA,O1r,So,WA,G1r,n_e,z1r,V1r,_n,X1r,s_e,W1r,Q1r,l_e,H1r,U1r,i_e,J1r,Y1r,K1r,d_e,PC,c_e,Z1r,e4r,iO,o4r,r4r,t4r,f_e,a4r,n4r,QA,HAe;return de=new X({}),Ea=new w({props:{code:'model = AutoModel.from_pretrained("bert-base-cased"),',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),PE=new X({}),$E=new w({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel),`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Hc=new s4r({props:{warning:"&lcub;true}",$$slots:{default:[Wrt]},$$scope:{ctx:ei}}}),IE=new X({}),jE=new y({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/configuration_auto.py#L501"}}),qE=new y({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/configuration_auto.py#L524",parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}]}}),OE=new w({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

config.unused_kwargs,`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config.unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),GE=new y({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/configuration_auto.py#L646",parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}]}}),zE=new X({}),VE=new y({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/tokenization_auto.py#L343"}}),QE=new y({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/tokenization_auto.py#L357",parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}]}}),HE=new w({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/"),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)`}}),UE=new y({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/tokenization_auto.py#L547",parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}]}}),JE=new X({}),YE=new y({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/feature_extraction_auto.py#L67"}}),eM=new y({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/feature_extraction_auto.py#L81",parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/v4.16.2/en/main_classes/feature_extractor#transformers.feature_extraction_utils.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}]}}),bg=new s4r({props:{$$slots:{default:[Qrt]},$$scope:{ctx:ei}}}),oM=new w({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/"),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),rM=new X({}),tM=new y({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/processing_auto.py#L65"}}),sM=new y({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/processing_auto.py#L79",parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}]}}),Bg=new s4r({props:{$$slots:{default:[Hrt]},$$scope:{ctx:ei}}}),lM=new w({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/"),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),iM=new X({}),dM=new y({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L628"}}),fM=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (Canine model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),mM=new w({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),gM=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),hM=new w({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),uM=new X({}),pM=new y({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L635"}}),vM=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),bM=new w({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),TM=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),FM=new w({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),CM=new X({}),EM=new y({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L650"}}),yM=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),wM=new w({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),AM=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),LM=new w({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),BM=new X({}),kM=new y({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L657"}}),RM=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code>(Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),SM=new w({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),PM=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),$M=new w({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),IM=new X({}),jM=new y({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L664"}}),DM=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLMProphetNet model)</li>
</ul>`,name:"config"}]}}),qM=new w({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),OM=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),GM=new w({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),zM=new X({}),VM=new y({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L673"}}),WM=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),QM=new w({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),HM=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),UM=new w({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),JM=new X({}),YM=new y({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L707"}}),ZM=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (Canine model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),e3=new w({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),o3=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),r3=new w({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),t3=new X({}),a3=new y({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L714"}}),s3=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}]}}),l3=new w({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),i3=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),d3=new w({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),c3=new X({}),f3=new y({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L700"}}),g3=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),h3=new w({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),u3=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),p3=new w({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),_3=new X({}),v3=new y({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L682"}}),T3=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (Canine model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),F3=new w({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),C3=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),E3=new w({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),M3=new X({}),y3=new y({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L689"}}),A3=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}]}}),L3=new w({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),B3=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),k3=new w({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),x3=new X({}),R3=new y({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L723"}}),P3=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/v4.16.2/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}]}}),$3=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),I3=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),j3=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),N3=new X({}),D3=new y({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L744"}}),O3=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}]}}),G3=new w({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),z3=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),V3=new w({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),X3=new X({}),W3=new y({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L751"}}),H3=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),U3=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),J3=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Y3=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),K3=new X({}),Z3=new y({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L774"}}),o5=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),r5=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),t5=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),a5=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),n5=new X({}),s5=new y({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L758"}}),i5=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),d5=new w({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),c5=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),f5=new w({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),m5=new X({}),g5=new y({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L765"}}),u5=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}]}}),p5=new w({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),_5=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),b5=new w({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),T5=new X({}),F5=new y({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L783"}}),E5=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),M5=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),y5=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),w5=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),A5=new X({}),L5=new y({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L737"}}),k5=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
</ul>`,name:"config"}]}}),x5=new w({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),R5=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),S5=new w({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),P5=new X({}),$5=new y({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_auto.py#L730"}}),j5=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}]}}),N5=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),D5=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),q5=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),O5=new X({}),G5=new y({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_tf_auto.py#L360"}}),V5=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),X5=new w({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),W5=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Q5=new w({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),H5=new X({}),U5=new y({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_tf_auto.py#L367"}}),Y5=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),K5=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),Z5=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),ey=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),oy=new X({}),ry=new y({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_tf_auto.py#L382"}}),ay=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),ny=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),sy=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),ly=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),iy=new X({}),dy=new y({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_tf_auto.py#L389"}}),fy=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}]}}),my=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),gy=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),hy=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),uy=new X({}),py=new y({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_tf_auto.py#L403"}}),vy=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),by=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),Ty=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Fy=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Cy=new X({}),Ey=new y({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_tf_auto.py#L410"}}),yy=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}]}}),wy=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),Ay=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Ly=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),By=new X({}),ky=new y({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_tf_auto.py#L419"}}),Ry=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),Sy=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),Py=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),$y=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Iy=new X({}),jy=new y({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_tf_auto.py#L455"}}),Dy=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),qy=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),Oy=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Gy=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),zy=new X({}),Vy=new y({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_tf_auto.py#L435"}}),Wy=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}]}}),Qy=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),Hy=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Uy=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Jy=new X({}),Yy=new y({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_tf_auto.py#L446"}}),Zy=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),ew=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),ow=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),rw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),tw=new X({}),aw=new y({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_tf_auto.py#L428"}}),sw=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),lw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),iw=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),dw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),cw=new X({}),fw=new y({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_tf_auto.py#L396"}}),gw=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}]}}),hw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),uw=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),pw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),_w=new X({}),vw=new y({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_flax_auto.py#L218"}}),Tw=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
</ul>`,name:"config"}]}}),Fw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),Cw=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Ew=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Mw=new X({}),yw=new y({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_flax_auto.py#L232"}}),Aw=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
</ul>`,name:"config"}]}}),Lw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),Bw=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),kw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),xw=new X({}),Rw=new y({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_flax_auto.py#L225"}}),Pw=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
</ul>`,name:"config"}]}}),$w=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),Iw=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),jw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Nw=new X({}),Dw=new y({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_flax_auto.py#L239"}}),Ow=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
</ul>`,name:"config"}]}}),Gw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),zw=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Vw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Xw=new X({}),Ww=new y({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),Hw=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}]}}),Uw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),Jw=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Yw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Kw=new X({}),Zw=new y({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_flax_auto.py#L255"}}),oA=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
</ul>`,name:"config"}]}}),rA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),tA=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),aA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),nA=new X({}),sA=new y({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_flax_auto.py#L264"}}),iA=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
</ul>`,name:"config"}]}}),dA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),cA=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),fA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),mA=new X({}),gA=new y({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_flax_auto.py#L271"}}),uA=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
</ul>`,name:"config"}]}}),pA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),_A=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),vA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),bA=new X({}),TA=new y({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_flax_auto.py#L280"}}),CA=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
</ul>`,name:"config"}]}}),EA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),MA=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),yA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),wA=new X({}),AA=new y({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_flax_auto.py#L287"}}),BA=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}]}}),kA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),xA=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),RA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),SA=new X({}),PA=new y({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_flax_auto.py#L296"}}),IA=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}]}}),jA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),NA=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),qA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),OA=new X({}),GA=new y({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/modeling_flax_auto.py#L305"}}),VA=new y({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.16.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.16.2/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}]}}),XA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),WA=new y({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.16.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),QA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){J=a("meta"),we=l(),se=a("h1"),me=a("a"),Ze=a("span"),f(de.$$.fragment),_e=l(),$o=a("span"),oi=o("Auto Classes"),zc=l(),Ut=a("p"),ri=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ti=a("code"),kE=o("from_pretrained()"),Vc=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Me=l(),no=a("p"),ai=o("Instantiating one of "),vn=a("a"),xE=o("AutoConfig"),bn=o(", "),Tn=a("a"),RE=o("AutoModel"),ni=o(`, and
`),Fn=a("a"),SE=o("AutoTokenizer"),si=o(" will directly create a class of the relevant architecture. For instance"),Xc=l(),f(Ea.$$.fragment),so=l(),ge=a("p"),z0=o("will create a model that is an instance of "),li=a("a"),V0=o("BertModel"),X0=o("."),Io=l(),Ma=a("p"),W0=o("There is one class of "),Wc=a("code"),Q0=o("AutoModel"),U7e=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),owe=l(),ii=a("h2"),Qc=a("a"),UG=a("span"),f(PE.$$.fragment),J7e=l(),JG=a("span"),Y7e=o("Extending the Auto Classes"),rwe=l(),Cn=a("p"),K7e=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),YG=a("code"),Z7e=o("NewModel"),eLe=o(", make sure you have a "),KG=a("code"),oLe=o("NewModelConfig"),rLe=o(` then you can add those to the auto
classes like this:`),twe=l(),f($E.$$.fragment),awe=l(),H0=a("p"),tLe=o("You will then be able to use the auto classes like you would usually do!"),nwe=l(),f(Hc.$$.fragment),swe=l(),di=a("h2"),Uc=a("a"),ZG=a("span"),f(IE.$$.fragment),aLe=l(),ez=a("span"),nLe=o("AutoConfig"),lwe=l(),jo=a("div"),f(jE.$$.fragment),sLe=l(),NE=a("p"),lLe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),U0=a("a"),iLe=o("from_pretrained()"),dLe=o(" class method."),cLe=l(),DE=a("p"),fLe=o("This class cannot be instantiated directly using "),oz=a("code"),mLe=o("__init__()"),gLe=o(" (throws an error)."),hLe=l(),lo=a("div"),f(qE.$$.fragment),uLe=l(),rz=a("p"),pLe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),_Le=l(),ci=a("p"),vLe=o("The configuration class to instantiate is selected based on the "),tz=a("code"),bLe=o("model_type"),TLe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),az=a("code"),FLe=o("pretrained_model_name_or_path"),CLe=o(":"),ELe=l(),b=a("ul"),Jc=a("li"),nz=a("strong"),MLe=o("albert"),yLe=o(" \u2014 "),J0=a("a"),wLe=o("AlbertConfig"),ALe=o(" (ALBERT model)"),LLe=l(),Yc=a("li"),sz=a("strong"),BLe=o("bart"),kLe=o(" \u2014 "),Y0=a("a"),xLe=o("BartConfig"),RLe=o(" (BART model)"),SLe=l(),Kc=a("li"),lz=a("strong"),PLe=o("beit"),$Le=o(" \u2014 "),K0=a("a"),ILe=o("BeitConfig"),jLe=o(" (BEiT model)"),NLe=l(),Zc=a("li"),iz=a("strong"),DLe=o("bert"),qLe=o(" \u2014 "),Z0=a("a"),OLe=o("BertConfig"),GLe=o(" (BERT model)"),zLe=l(),ef=a("li"),dz=a("strong"),VLe=o("bert-generation"),XLe=o(" \u2014 "),e7=a("a"),WLe=o("BertGenerationConfig"),QLe=o(" (Bert Generation model)"),HLe=l(),of=a("li"),cz=a("strong"),ULe=o("big_bird"),JLe=o(" \u2014 "),o7=a("a"),YLe=o("BigBirdConfig"),KLe=o(" (BigBird model)"),ZLe=l(),rf=a("li"),fz=a("strong"),e8e=o("bigbird_pegasus"),o8e=o(" \u2014 "),r7=a("a"),r8e=o("BigBirdPegasusConfig"),t8e=o(" (BigBirdPegasus model)"),a8e=l(),tf=a("li"),mz=a("strong"),n8e=o("blenderbot"),s8e=o(" \u2014 "),t7=a("a"),l8e=o("BlenderbotConfig"),i8e=o(" (Blenderbot model)"),d8e=l(),af=a("li"),gz=a("strong"),c8e=o("blenderbot-small"),f8e=o(" \u2014 "),a7=a("a"),m8e=o("BlenderbotSmallConfig"),g8e=o(" (BlenderbotSmall model)"),h8e=l(),nf=a("li"),hz=a("strong"),u8e=o("camembert"),p8e=o(" \u2014 "),n7=a("a"),_8e=o("CamembertConfig"),v8e=o(" (CamemBERT model)"),b8e=l(),sf=a("li"),uz=a("strong"),T8e=o("canine"),F8e=o(" \u2014 "),s7=a("a"),C8e=o("CanineConfig"),E8e=o(" (Canine model)"),M8e=l(),lf=a("li"),pz=a("strong"),y8e=o("clip"),w8e=o(" \u2014 "),l7=a("a"),A8e=o("CLIPConfig"),L8e=o(" (CLIP model)"),B8e=l(),df=a("li"),_z=a("strong"),k8e=o("convbert"),x8e=o(" \u2014 "),i7=a("a"),R8e=o("ConvBertConfig"),S8e=o(" (ConvBERT model)"),P8e=l(),cf=a("li"),vz=a("strong"),$8e=o("ctrl"),I8e=o(" \u2014 "),d7=a("a"),j8e=o("CTRLConfig"),N8e=o(" (CTRL model)"),D8e=l(),ff=a("li"),bz=a("strong"),q8e=o("deberta"),O8e=o(" \u2014 "),c7=a("a"),G8e=o("DebertaConfig"),z8e=o(" (DeBERTa model)"),V8e=l(),mf=a("li"),Tz=a("strong"),X8e=o("deberta-v2"),W8e=o(" \u2014 "),f7=a("a"),Q8e=o("DebertaV2Config"),H8e=o(" (DeBERTa-v2 model)"),U8e=l(),gf=a("li"),Fz=a("strong"),J8e=o("deit"),Y8e=o(" \u2014 "),m7=a("a"),K8e=o("DeiTConfig"),Z8e=o(" (DeiT model)"),eBe=l(),hf=a("li"),Cz=a("strong"),oBe=o("detr"),rBe=o(" \u2014 "),g7=a("a"),tBe=o("DetrConfig"),aBe=o(" (DETR model)"),nBe=l(),uf=a("li"),Ez=a("strong"),sBe=o("distilbert"),lBe=o(" \u2014 "),h7=a("a"),iBe=o("DistilBertConfig"),dBe=o(" (DistilBERT model)"),cBe=l(),pf=a("li"),Mz=a("strong"),fBe=o("dpr"),mBe=o(" \u2014 "),u7=a("a"),gBe=o("DPRConfig"),hBe=o(" (DPR model)"),uBe=l(),_f=a("li"),yz=a("strong"),pBe=o("electra"),_Be=o(" \u2014 "),p7=a("a"),vBe=o("ElectraConfig"),bBe=o(" (ELECTRA model)"),TBe=l(),vf=a("li"),wz=a("strong"),FBe=o("encoder-decoder"),CBe=o(" \u2014 "),_7=a("a"),EBe=o("EncoderDecoderConfig"),MBe=o(" (Encoder decoder model)"),yBe=l(),bf=a("li"),Az=a("strong"),wBe=o("flaubert"),ABe=o(" \u2014 "),v7=a("a"),LBe=o("FlaubertConfig"),BBe=o(" (FlauBERT model)"),kBe=l(),Tf=a("li"),Lz=a("strong"),xBe=o("fnet"),RBe=o(" \u2014 "),b7=a("a"),SBe=o("FNetConfig"),PBe=o(" (FNet model)"),$Be=l(),Ff=a("li"),Bz=a("strong"),IBe=o("fsmt"),jBe=o(" \u2014 "),T7=a("a"),NBe=o("FSMTConfig"),DBe=o(" (FairSeq Machine-Translation model)"),qBe=l(),Cf=a("li"),kz=a("strong"),OBe=o("funnel"),GBe=o(" \u2014 "),F7=a("a"),zBe=o("FunnelConfig"),VBe=o(" (Funnel Transformer model)"),XBe=l(),Ef=a("li"),xz=a("strong"),WBe=o("gpt2"),QBe=o(" \u2014 "),C7=a("a"),HBe=o("GPT2Config"),UBe=o(" (OpenAI GPT-2 model)"),JBe=l(),Mf=a("li"),Rz=a("strong"),YBe=o("gpt_neo"),KBe=o(" \u2014 "),E7=a("a"),ZBe=o("GPTNeoConfig"),e9e=o(" (GPT Neo model)"),o9e=l(),yf=a("li"),Sz=a("strong"),r9e=o("gptj"),t9e=o(" \u2014 "),M7=a("a"),a9e=o("GPTJConfig"),n9e=o(" (GPT-J model)"),s9e=l(),wf=a("li"),Pz=a("strong"),l9e=o("hubert"),i9e=o(" \u2014 "),y7=a("a"),d9e=o("HubertConfig"),c9e=o(" (Hubert model)"),f9e=l(),Af=a("li"),$z=a("strong"),m9e=o("ibert"),g9e=o(" \u2014 "),w7=a("a"),h9e=o("IBertConfig"),u9e=o(" (I-BERT model)"),p9e=l(),Lf=a("li"),Iz=a("strong"),_9e=o("imagegpt"),v9e=o(" \u2014 "),A7=a("a"),b9e=o("ImageGPTConfig"),T9e=o(" (ImageGPT model)"),F9e=l(),Bf=a("li"),jz=a("strong"),C9e=o("layoutlm"),E9e=o(" \u2014 "),L7=a("a"),M9e=o("LayoutLMConfig"),y9e=o(" (LayoutLM model)"),w9e=l(),kf=a("li"),Nz=a("strong"),A9e=o("layoutlmv2"),L9e=o(" \u2014 "),B7=a("a"),B9e=o("LayoutLMv2Config"),k9e=o(" (LayoutLMv2 model)"),x9e=l(),xf=a("li"),Dz=a("strong"),R9e=o("led"),S9e=o(" \u2014 "),k7=a("a"),P9e=o("LEDConfig"),$9e=o(" (LED model)"),I9e=l(),Rf=a("li"),qz=a("strong"),j9e=o("longformer"),N9e=o(" \u2014 "),x7=a("a"),D9e=o("LongformerConfig"),q9e=o(" (Longformer model)"),O9e=l(),Sf=a("li"),Oz=a("strong"),G9e=o("luke"),z9e=o(" \u2014 "),R7=a("a"),V9e=o("LukeConfig"),X9e=o(" (LUKE model)"),W9e=l(),Pf=a("li"),Gz=a("strong"),Q9e=o("lxmert"),H9e=o(" \u2014 "),S7=a("a"),U9e=o("LxmertConfig"),J9e=o(" (LXMERT model)"),Y9e=l(),$f=a("li"),zz=a("strong"),K9e=o("m2m_100"),Z9e=o(" \u2014 "),P7=a("a"),eke=o("M2M100Config"),oke=o(" (M2M100 model)"),rke=l(),If=a("li"),Vz=a("strong"),tke=o("marian"),ake=o(" \u2014 "),$7=a("a"),nke=o("MarianConfig"),ske=o(" (Marian model)"),lke=l(),jf=a("li"),Xz=a("strong"),ike=o("mbart"),dke=o(" \u2014 "),I7=a("a"),cke=o("MBartConfig"),fke=o(" (mBART model)"),mke=l(),Nf=a("li"),Wz=a("strong"),gke=o("megatron-bert"),hke=o(" \u2014 "),j7=a("a"),uke=o("MegatronBertConfig"),pke=o(" (MegatronBert model)"),_ke=l(),Df=a("li"),Qz=a("strong"),vke=o("mobilebert"),bke=o(" \u2014 "),N7=a("a"),Tke=o("MobileBertConfig"),Fke=o(" (MobileBERT model)"),Cke=l(),qf=a("li"),Hz=a("strong"),Eke=o("mpnet"),Mke=o(" \u2014 "),D7=a("a"),yke=o("MPNetConfig"),wke=o(" (MPNet model)"),Ake=l(),Of=a("li"),Uz=a("strong"),Lke=o("mt5"),Bke=o(" \u2014 "),q7=a("a"),kke=o("MT5Config"),xke=o(" (mT5 model)"),Rke=l(),Gf=a("li"),Jz=a("strong"),Ske=o("nystromformer"),Pke=o(" \u2014 "),O7=a("a"),$ke=o("NystromformerConfig"),Ike=o(" (Nystromformer model)"),jke=l(),zf=a("li"),Yz=a("strong"),Nke=o("openai-gpt"),Dke=o(" \u2014 "),G7=a("a"),qke=o("OpenAIGPTConfig"),Oke=o(" (OpenAI GPT model)"),Gke=l(),Vf=a("li"),Kz=a("strong"),zke=o("pegasus"),Vke=o(" \u2014 "),z7=a("a"),Xke=o("PegasusConfig"),Wke=o(" (Pegasus model)"),Qke=l(),Xf=a("li"),Zz=a("strong"),Hke=o("perceiver"),Uke=o(" \u2014 "),V7=a("a"),Jke=o("PerceiverConfig"),Yke=o(" (Perceiver model)"),Kke=l(),Wf=a("li"),eV=a("strong"),Zke=o("prophetnet"),exe=o(" \u2014 "),X7=a("a"),oxe=o("ProphetNetConfig"),rxe=o(" (ProphetNet model)"),txe=l(),Qf=a("li"),oV=a("strong"),axe=o("qdqbert"),nxe=o(" \u2014 "),W7=a("a"),sxe=o("QDQBertConfig"),lxe=o(" (QDQBert model)"),ixe=l(),Hf=a("li"),rV=a("strong"),dxe=o("rag"),cxe=o(" \u2014 "),Q7=a("a"),fxe=o("RagConfig"),mxe=o(" (RAG model)"),gxe=l(),Uf=a("li"),tV=a("strong"),hxe=o("realm"),uxe=o(" \u2014 "),H7=a("a"),pxe=o("RealmConfig"),_xe=o(" (Realm model)"),vxe=l(),Jf=a("li"),aV=a("strong"),bxe=o("reformer"),Txe=o(" \u2014 "),U7=a("a"),Fxe=o("ReformerConfig"),Cxe=o(" (Reformer model)"),Exe=l(),Yf=a("li"),nV=a("strong"),Mxe=o("rembert"),yxe=o(" \u2014 "),J7=a("a"),wxe=o("RemBertConfig"),Axe=o(" (RemBERT model)"),Lxe=l(),Kf=a("li"),sV=a("strong"),Bxe=o("retribert"),kxe=o(" \u2014 "),Y7=a("a"),xxe=o("RetriBertConfig"),Rxe=o(" (RetriBERT model)"),Sxe=l(),Zf=a("li"),lV=a("strong"),Pxe=o("roberta"),$xe=o(" \u2014 "),K7=a("a"),Ixe=o("RobertaConfig"),jxe=o(" (RoBERTa model)"),Nxe=l(),em=a("li"),iV=a("strong"),Dxe=o("roformer"),qxe=o(" \u2014 "),Z7=a("a"),Oxe=o("RoFormerConfig"),Gxe=o(" (RoFormer model)"),zxe=l(),om=a("li"),dV=a("strong"),Vxe=o("segformer"),Xxe=o(" \u2014 "),eL=a("a"),Wxe=o("SegformerConfig"),Qxe=o(" (SegFormer model)"),Hxe=l(),rm=a("li"),cV=a("strong"),Uxe=o("sew"),Jxe=o(" \u2014 "),oL=a("a"),Yxe=o("SEWConfig"),Kxe=o(" (SEW model)"),Zxe=l(),tm=a("li"),fV=a("strong"),eRe=o("sew-d"),oRe=o(" \u2014 "),rL=a("a"),rRe=o("SEWDConfig"),tRe=o(" (SEW-D model)"),aRe=l(),am=a("li"),mV=a("strong"),nRe=o("speech-encoder-decoder"),sRe=o(" \u2014 "),tL=a("a"),lRe=o("SpeechEncoderDecoderConfig"),iRe=o(" (Speech Encoder decoder model)"),dRe=l(),nm=a("li"),gV=a("strong"),cRe=o("speech_to_text"),fRe=o(" \u2014 "),aL=a("a"),mRe=o("Speech2TextConfig"),gRe=o(" (Speech2Text model)"),hRe=l(),sm=a("li"),hV=a("strong"),uRe=o("speech_to_text_2"),pRe=o(" \u2014 "),nL=a("a"),_Re=o("Speech2Text2Config"),vRe=o(" (Speech2Text2 model)"),bRe=l(),lm=a("li"),uV=a("strong"),TRe=o("splinter"),FRe=o(" \u2014 "),sL=a("a"),CRe=o("SplinterConfig"),ERe=o(" (Splinter model)"),MRe=l(),im=a("li"),pV=a("strong"),yRe=o("squeezebert"),wRe=o(" \u2014 "),lL=a("a"),ARe=o("SqueezeBertConfig"),LRe=o(" (SqueezeBERT model)"),BRe=l(),dm=a("li"),_V=a("strong"),kRe=o("swin"),xRe=o(" \u2014 "),iL=a("a"),RRe=o("SwinConfig"),SRe=o(" (Swin model)"),PRe=l(),cm=a("li"),vV=a("strong"),$Re=o("t5"),IRe=o(" \u2014 "),dL=a("a"),jRe=o("T5Config"),NRe=o(" (T5 model)"),DRe=l(),fm=a("li"),bV=a("strong"),qRe=o("tapas"),ORe=o(" \u2014 "),cL=a("a"),GRe=o("TapasConfig"),zRe=o(" (TAPAS model)"),VRe=l(),mm=a("li"),TV=a("strong"),XRe=o("transfo-xl"),WRe=o(" \u2014 "),fL=a("a"),QRe=o("TransfoXLConfig"),HRe=o(" (Transformer-XL model)"),URe=l(),gm=a("li"),FV=a("strong"),JRe=o("trocr"),YRe=o(" \u2014 "),mL=a("a"),KRe=o("TrOCRConfig"),ZRe=o(" (TrOCR model)"),eSe=l(),hm=a("li"),CV=a("strong"),oSe=o("unispeech"),rSe=o(" \u2014 "),gL=a("a"),tSe=o("UniSpeechConfig"),aSe=o(" (UniSpeech model)"),nSe=l(),um=a("li"),EV=a("strong"),sSe=o("unispeech-sat"),lSe=o(" \u2014 "),hL=a("a"),iSe=o("UniSpeechSatConfig"),dSe=o(" (UniSpeechSat model)"),cSe=l(),pm=a("li"),MV=a("strong"),fSe=o("vilt"),mSe=o(" \u2014 "),uL=a("a"),gSe=o("ViltConfig"),hSe=o(" (ViLT model)"),uSe=l(),_m=a("li"),yV=a("strong"),pSe=o("vision-encoder-decoder"),_Se=o(" \u2014 "),pL=a("a"),vSe=o("VisionEncoderDecoderConfig"),bSe=o(" (Vision Encoder decoder model)"),TSe=l(),vm=a("li"),wV=a("strong"),FSe=o("vision-text-dual-encoder"),CSe=o(" \u2014 "),_L=a("a"),ESe=o("VisionTextDualEncoderConfig"),MSe=o(" (VisionTextDualEncoder model)"),ySe=l(),bm=a("li"),AV=a("strong"),wSe=o("visual_bert"),ASe=o(" \u2014 "),vL=a("a"),LSe=o("VisualBertConfig"),BSe=o(" (VisualBert model)"),kSe=l(),Tm=a("li"),LV=a("strong"),xSe=o("vit"),RSe=o(" \u2014 "),bL=a("a"),SSe=o("ViTConfig"),PSe=o(" (ViT model)"),$Se=l(),Fm=a("li"),BV=a("strong"),ISe=o("vit_mae"),jSe=o(" \u2014 "),TL=a("a"),NSe=o("ViTMAEConfig"),DSe=o(" (ViTMAE model)"),qSe=l(),Cm=a("li"),kV=a("strong"),OSe=o("wav2vec2"),GSe=o(" \u2014 "),FL=a("a"),zSe=o("Wav2Vec2Config"),VSe=o(" (Wav2Vec2 model)"),XSe=l(),Em=a("li"),xV=a("strong"),WSe=o("wavlm"),QSe=o(" \u2014 "),CL=a("a"),HSe=o("WavLMConfig"),USe=o(" (WavLM model)"),JSe=l(),Mm=a("li"),RV=a("strong"),YSe=o("xlm"),KSe=o(" \u2014 "),EL=a("a"),ZSe=o("XLMConfig"),ePe=o(" (XLM model)"),oPe=l(),ym=a("li"),SV=a("strong"),rPe=o("xlm-prophetnet"),tPe=o(" \u2014 "),ML=a("a"),aPe=o("XLMProphetNetConfig"),nPe=o(" (XLMProphetNet model)"),sPe=l(),wm=a("li"),PV=a("strong"),lPe=o("xlm-roberta"),iPe=o(" \u2014 "),yL=a("a"),dPe=o("XLMRobertaConfig"),cPe=o(" (XLM-RoBERTa model)"),fPe=l(),Am=a("li"),$V=a("strong"),mPe=o("xlnet"),gPe=o(" \u2014 "),wL=a("a"),hPe=o("XLNetConfig"),uPe=o(" (XLNet model)"),pPe=l(),Lm=a("li"),IV=a("strong"),_Pe=o("yoso"),vPe=o(" \u2014 "),AL=a("a"),bPe=o("YosoConfig"),TPe=o(" (YOSO model)"),FPe=l(),jV=a("p"),CPe=o("Examples:"),EPe=l(),f(OE.$$.fragment),MPe=l(),Bm=a("div"),f(GE.$$.fragment),yPe=l(),NV=a("p"),wPe=o("Register a new configuration for this class."),iwe=l(),fi=a("h2"),km=a("a"),DV=a("span"),f(zE.$$.fragment),APe=l(),qV=a("span"),LPe=o("AutoTokenizer"),dwe=l(),No=a("div"),f(VE.$$.fragment),BPe=l(),XE=a("p"),kPe=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),LL=a("a"),xPe=o("AutoTokenizer.from_pretrained()"),RPe=o(" class method."),SPe=l(),WE=a("p"),PPe=o("This class cannot be instantiated directly using "),OV=a("code"),$Pe=o("__init__()"),IPe=o(" (throws an error)."),jPe=l(),io=a("div"),f(QE.$$.fragment),NPe=l(),GV=a("p"),DPe=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),qPe=l(),ya=a("p"),OPe=o("The tokenizer class to instantiate is selected based on the "),zV=a("code"),GPe=o("model_type"),zPe=o(` property of the config object (either
passed as an argument or loaded from `),VV=a("code"),VPe=o("pretrained_model_name_or_path"),XPe=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),XV=a("code"),WPe=o("pretrained_model_name_or_path"),QPe=o(":"),HPe=l(),E=a("ul"),En=a("li"),WV=a("strong"),UPe=o("albert"),JPe=o(" \u2014 "),BL=a("a"),YPe=o("AlbertTokenizer"),KPe=o(" or "),kL=a("a"),ZPe=o("AlbertTokenizerFast"),e$e=o(" (ALBERT model)"),o$e=l(),Mn=a("li"),QV=a("strong"),r$e=o("bart"),t$e=o(" \u2014 "),xL=a("a"),a$e=o("BartTokenizer"),n$e=o(" or "),RL=a("a"),s$e=o("BartTokenizerFast"),l$e=o(" (BART model)"),i$e=l(),yn=a("li"),HV=a("strong"),d$e=o("barthez"),c$e=o(" \u2014 "),SL=a("a"),f$e=o("BarthezTokenizer"),m$e=o(" or "),PL=a("a"),g$e=o("BarthezTokenizerFast"),h$e=o(" (BARThez model)"),u$e=l(),xm=a("li"),UV=a("strong"),p$e=o("bartpho"),_$e=o(" \u2014 "),$L=a("a"),v$e=o("BartphoTokenizer"),b$e=o(" (BARTpho model)"),T$e=l(),wn=a("li"),JV=a("strong"),F$e=o("bert"),C$e=o(" \u2014 "),IL=a("a"),E$e=o("BertTokenizer"),M$e=o(" or "),jL=a("a"),y$e=o("BertTokenizerFast"),w$e=o(" (BERT model)"),A$e=l(),Rm=a("li"),YV=a("strong"),L$e=o("bert-generation"),B$e=o(" \u2014 "),NL=a("a"),k$e=o("BertGenerationTokenizer"),x$e=o(" (Bert Generation model)"),R$e=l(),Sm=a("li"),KV=a("strong"),S$e=o("bert-japanese"),P$e=o(" \u2014 "),DL=a("a"),$$e=o("BertJapaneseTokenizer"),I$e=o(" (BertJapanese model)"),j$e=l(),Pm=a("li"),ZV=a("strong"),N$e=o("bertweet"),D$e=o(" \u2014 "),qL=a("a"),q$e=o("BertweetTokenizer"),O$e=o(" (Bertweet model)"),G$e=l(),An=a("li"),eX=a("strong"),z$e=o("big_bird"),V$e=o(" \u2014 "),OL=a("a"),X$e=o("BigBirdTokenizer"),W$e=o(" or "),GL=a("a"),Q$e=o("BigBirdTokenizerFast"),H$e=o(" (BigBird model)"),U$e=l(),Ln=a("li"),oX=a("strong"),J$e=o("bigbird_pegasus"),Y$e=o(" \u2014 "),zL=a("a"),K$e=o("PegasusTokenizer"),Z$e=o(" or "),VL=a("a"),eIe=o("PegasusTokenizerFast"),oIe=o(" (BigBirdPegasus model)"),rIe=l(),Bn=a("li"),rX=a("strong"),tIe=o("blenderbot"),aIe=o(" \u2014 "),XL=a("a"),nIe=o("BlenderbotTokenizer"),sIe=o(" or "),WL=a("a"),lIe=o("BlenderbotTokenizerFast"),iIe=o(" (Blenderbot model)"),dIe=l(),$m=a("li"),tX=a("strong"),cIe=o("blenderbot-small"),fIe=o(" \u2014 "),QL=a("a"),mIe=o("BlenderbotSmallTokenizer"),gIe=o(" (BlenderbotSmall model)"),hIe=l(),Im=a("li"),aX=a("strong"),uIe=o("byt5"),pIe=o(" \u2014 "),HL=a("a"),_Ie=o("ByT5Tokenizer"),vIe=o(" (ByT5 model)"),bIe=l(),kn=a("li"),nX=a("strong"),TIe=o("camembert"),FIe=o(" \u2014 "),UL=a("a"),CIe=o("CamembertTokenizer"),EIe=o(" or "),JL=a("a"),MIe=o("CamembertTokenizerFast"),yIe=o(" (CamemBERT model)"),wIe=l(),jm=a("li"),sX=a("strong"),AIe=o("canine"),LIe=o(" \u2014 "),YL=a("a"),BIe=o("CanineTokenizer"),kIe=o(" (Canine model)"),xIe=l(),xn=a("li"),lX=a("strong"),RIe=o("clip"),SIe=o(" \u2014 "),KL=a("a"),PIe=o("CLIPTokenizer"),$Ie=o(" or "),ZL=a("a"),IIe=o("CLIPTokenizerFast"),jIe=o(" (CLIP model)"),NIe=l(),Rn=a("li"),iX=a("strong"),DIe=o("convbert"),qIe=o(" \u2014 "),e8=a("a"),OIe=o("ConvBertTokenizer"),GIe=o(" or "),o8=a("a"),zIe=o("ConvBertTokenizerFast"),VIe=o(" (ConvBERT model)"),XIe=l(),Sn=a("li"),dX=a("strong"),WIe=o("cpm"),QIe=o(" \u2014 "),r8=a("a"),HIe=o("CpmTokenizer"),UIe=o(" or "),cX=a("code"),JIe=o("CpmTokenizerFast"),YIe=o(" (CPM model)"),KIe=l(),Nm=a("li"),fX=a("strong"),ZIe=o("ctrl"),eje=o(" \u2014 "),t8=a("a"),oje=o("CTRLTokenizer"),rje=o(" (CTRL model)"),tje=l(),Pn=a("li"),mX=a("strong"),aje=o("deberta"),nje=o(" \u2014 "),a8=a("a"),sje=o("DebertaTokenizer"),lje=o(" or "),n8=a("a"),ije=o("DebertaTokenizerFast"),dje=o(" (DeBERTa model)"),cje=l(),Dm=a("li"),gX=a("strong"),fje=o("deberta-v2"),mje=o(" \u2014 "),s8=a("a"),gje=o("DebertaV2Tokenizer"),hje=o(" (DeBERTa-v2 model)"),uje=l(),$n=a("li"),hX=a("strong"),pje=o("distilbert"),_je=o(" \u2014 "),l8=a("a"),vje=o("DistilBertTokenizer"),bje=o(" or "),i8=a("a"),Tje=o("DistilBertTokenizerFast"),Fje=o(" (DistilBERT model)"),Cje=l(),In=a("li"),uX=a("strong"),Eje=o("dpr"),Mje=o(" \u2014 "),d8=a("a"),yje=o("DPRQuestionEncoderTokenizer"),wje=o(" or "),c8=a("a"),Aje=o("DPRQuestionEncoderTokenizerFast"),Lje=o(" (DPR model)"),Bje=l(),jn=a("li"),pX=a("strong"),kje=o("electra"),xje=o(" \u2014 "),f8=a("a"),Rje=o("ElectraTokenizer"),Sje=o(" or "),m8=a("a"),Pje=o("ElectraTokenizerFast"),$je=o(" (ELECTRA model)"),Ije=l(),qm=a("li"),_X=a("strong"),jje=o("flaubert"),Nje=o(" \u2014 "),g8=a("a"),Dje=o("FlaubertTokenizer"),qje=o(" (FlauBERT model)"),Oje=l(),Nn=a("li"),vX=a("strong"),Gje=o("fnet"),zje=o(" \u2014 "),h8=a("a"),Vje=o("FNetTokenizer"),Xje=o(" or "),u8=a("a"),Wje=o("FNetTokenizerFast"),Qje=o(" (FNet model)"),Hje=l(),Om=a("li"),bX=a("strong"),Uje=o("fsmt"),Jje=o(" \u2014 "),p8=a("a"),Yje=o("FSMTTokenizer"),Kje=o(" (FairSeq Machine-Translation model)"),Zje=l(),Dn=a("li"),TX=a("strong"),eNe=o("funnel"),oNe=o(" \u2014 "),_8=a("a"),rNe=o("FunnelTokenizer"),tNe=o(" or "),v8=a("a"),aNe=o("FunnelTokenizerFast"),nNe=o(" (Funnel Transformer model)"),sNe=l(),qn=a("li"),FX=a("strong"),lNe=o("gpt2"),iNe=o(" \u2014 "),b8=a("a"),dNe=o("GPT2Tokenizer"),cNe=o(" or "),T8=a("a"),fNe=o("GPT2TokenizerFast"),mNe=o(" (OpenAI GPT-2 model)"),gNe=l(),On=a("li"),CX=a("strong"),hNe=o("gpt_neo"),uNe=o(" \u2014 "),F8=a("a"),pNe=o("GPT2Tokenizer"),_Ne=o(" or "),C8=a("a"),vNe=o("GPT2TokenizerFast"),bNe=o(" (GPT Neo model)"),TNe=l(),Gn=a("li"),EX=a("strong"),FNe=o("herbert"),CNe=o(" \u2014 "),E8=a("a"),ENe=o("HerbertTokenizer"),MNe=o(" or "),M8=a("a"),yNe=o("HerbertTokenizerFast"),wNe=o(" (HerBERT model)"),ANe=l(),Gm=a("li"),MX=a("strong"),LNe=o("hubert"),BNe=o(" \u2014 "),y8=a("a"),kNe=o("Wav2Vec2CTCTokenizer"),xNe=o(" (Hubert model)"),RNe=l(),zn=a("li"),yX=a("strong"),SNe=o("ibert"),PNe=o(" \u2014 "),w8=a("a"),$Ne=o("RobertaTokenizer"),INe=o(" or "),A8=a("a"),jNe=o("RobertaTokenizerFast"),NNe=o(" (I-BERT model)"),DNe=l(),Vn=a("li"),wX=a("strong"),qNe=o("layoutlm"),ONe=o(" \u2014 "),L8=a("a"),GNe=o("LayoutLMTokenizer"),zNe=o(" or "),B8=a("a"),VNe=o("LayoutLMTokenizerFast"),XNe=o(" (LayoutLM model)"),WNe=l(),Xn=a("li"),AX=a("strong"),QNe=o("layoutlmv2"),HNe=o(" \u2014 "),k8=a("a"),UNe=o("LayoutLMv2Tokenizer"),JNe=o(" or "),x8=a("a"),YNe=o("LayoutLMv2TokenizerFast"),KNe=o(" (LayoutLMv2 model)"),ZNe=l(),Wn=a("li"),LX=a("strong"),eDe=o("layoutxlm"),oDe=o(" \u2014 "),R8=a("a"),rDe=o("LayoutXLMTokenizer"),tDe=o(" or "),S8=a("a"),aDe=o("LayoutXLMTokenizerFast"),nDe=o(" (LayoutXLM model)"),sDe=l(),Qn=a("li"),BX=a("strong"),lDe=o("led"),iDe=o(" \u2014 "),P8=a("a"),dDe=o("LEDTokenizer"),cDe=o(" or "),$8=a("a"),fDe=o("LEDTokenizerFast"),mDe=o(" (LED model)"),gDe=l(),Hn=a("li"),kX=a("strong"),hDe=o("longformer"),uDe=o(" \u2014 "),I8=a("a"),pDe=o("LongformerTokenizer"),_De=o(" or "),j8=a("a"),vDe=o("LongformerTokenizerFast"),bDe=o(" (Longformer model)"),TDe=l(),zm=a("li"),xX=a("strong"),FDe=o("luke"),CDe=o(" \u2014 "),N8=a("a"),EDe=o("LukeTokenizer"),MDe=o(" (LUKE model)"),yDe=l(),Un=a("li"),RX=a("strong"),wDe=o("lxmert"),ADe=o(" \u2014 "),D8=a("a"),LDe=o("LxmertTokenizer"),BDe=o(" or "),q8=a("a"),kDe=o("LxmertTokenizerFast"),xDe=o(" (LXMERT model)"),RDe=l(),Vm=a("li"),SX=a("strong"),SDe=o("m2m_100"),PDe=o(" \u2014 "),O8=a("a"),$De=o("M2M100Tokenizer"),IDe=o(" (M2M100 model)"),jDe=l(),Xm=a("li"),PX=a("strong"),NDe=o("marian"),DDe=o(" \u2014 "),G8=a("a"),qDe=o("MarianTokenizer"),ODe=o(" (Marian model)"),GDe=l(),Jn=a("li"),$X=a("strong"),zDe=o("mbart"),VDe=o(" \u2014 "),z8=a("a"),XDe=o("MBartTokenizer"),WDe=o(" or "),V8=a("a"),QDe=o("MBartTokenizerFast"),HDe=o(" (mBART model)"),UDe=l(),Yn=a("li"),IX=a("strong"),JDe=o("mbart50"),YDe=o(" \u2014 "),X8=a("a"),KDe=o("MBart50Tokenizer"),ZDe=o(" or "),W8=a("a"),eqe=o("MBart50TokenizerFast"),oqe=o(" (mBART-50 model)"),rqe=l(),Wm=a("li"),jX=a("strong"),tqe=o("mluke"),aqe=o(" \u2014 "),Q8=a("a"),nqe=o("MLukeTokenizer"),sqe=o(" (mLUKE model)"),lqe=l(),Kn=a("li"),NX=a("strong"),iqe=o("mobilebert"),dqe=o(" \u2014 "),H8=a("a"),cqe=o("MobileBertTokenizer"),fqe=o(" or "),U8=a("a"),mqe=o("MobileBertTokenizerFast"),gqe=o(" (MobileBERT model)"),hqe=l(),Zn=a("li"),DX=a("strong"),uqe=o("mpnet"),pqe=o(" \u2014 "),J8=a("a"),_qe=o("MPNetTokenizer"),vqe=o(" or "),Y8=a("a"),bqe=o("MPNetTokenizerFast"),Tqe=o(" (MPNet model)"),Fqe=l(),es=a("li"),qX=a("strong"),Cqe=o("mt5"),Eqe=o(" \u2014 "),K8=a("a"),Mqe=o("MT5Tokenizer"),yqe=o(" or "),Z8=a("a"),wqe=o("MT5TokenizerFast"),Aqe=o(" (mT5 model)"),Lqe=l(),os=a("li"),OX=a("strong"),Bqe=o("openai-gpt"),kqe=o(" \u2014 "),eB=a("a"),xqe=o("OpenAIGPTTokenizer"),Rqe=o(" or "),oB=a("a"),Sqe=o("OpenAIGPTTokenizerFast"),Pqe=o(" (OpenAI GPT model)"),$qe=l(),rs=a("li"),GX=a("strong"),Iqe=o("pegasus"),jqe=o(" \u2014 "),rB=a("a"),Nqe=o("PegasusTokenizer"),Dqe=o(" or "),tB=a("a"),qqe=o("PegasusTokenizerFast"),Oqe=o(" (Pegasus model)"),Gqe=l(),Qm=a("li"),zX=a("strong"),zqe=o("perceiver"),Vqe=o(" \u2014 "),aB=a("a"),Xqe=o("PerceiverTokenizer"),Wqe=o(" (Perceiver model)"),Qqe=l(),Hm=a("li"),VX=a("strong"),Hqe=o("phobert"),Uqe=o(" \u2014 "),nB=a("a"),Jqe=o("PhobertTokenizer"),Yqe=o(" (PhoBERT model)"),Kqe=l(),Um=a("li"),XX=a("strong"),Zqe=o("prophetnet"),eOe=o(" \u2014 "),sB=a("a"),oOe=o("ProphetNetTokenizer"),rOe=o(" (ProphetNet model)"),tOe=l(),ts=a("li"),WX=a("strong"),aOe=o("qdqbert"),nOe=o(" \u2014 "),lB=a("a"),sOe=o("BertTokenizer"),lOe=o(" or "),iB=a("a"),iOe=o("BertTokenizerFast"),dOe=o(" (QDQBert model)"),cOe=l(),Jm=a("li"),QX=a("strong"),fOe=o("rag"),mOe=o(" \u2014 "),dB=a("a"),gOe=o("RagTokenizer"),hOe=o(" (RAG model)"),uOe=l(),as=a("li"),HX=a("strong"),pOe=o("reformer"),_Oe=o(" \u2014 "),cB=a("a"),vOe=o("ReformerTokenizer"),bOe=o(" or "),fB=a("a"),TOe=o("ReformerTokenizerFast"),FOe=o(" (Reformer model)"),COe=l(),ns=a("li"),UX=a("strong"),EOe=o("rembert"),MOe=o(" \u2014 "),mB=a("a"),yOe=o("RemBertTokenizer"),wOe=o(" or "),gB=a("a"),AOe=o("RemBertTokenizerFast"),LOe=o(" (RemBERT model)"),BOe=l(),ss=a("li"),JX=a("strong"),kOe=o("retribert"),xOe=o(" \u2014 "),hB=a("a"),ROe=o("RetriBertTokenizer"),SOe=o(" or "),uB=a("a"),POe=o("RetriBertTokenizerFast"),$Oe=o(" (RetriBERT model)"),IOe=l(),ls=a("li"),YX=a("strong"),jOe=o("roberta"),NOe=o(" \u2014 "),pB=a("a"),DOe=o("RobertaTokenizer"),qOe=o(" or "),_B=a("a"),OOe=o("RobertaTokenizerFast"),GOe=o(" (RoBERTa model)"),zOe=l(),is=a("li"),KX=a("strong"),VOe=o("roformer"),XOe=o(" \u2014 "),vB=a("a"),WOe=o("RoFormerTokenizer"),QOe=o(" or "),bB=a("a"),HOe=o("RoFormerTokenizerFast"),UOe=o(" (RoFormer model)"),JOe=l(),Ym=a("li"),ZX=a("strong"),YOe=o("speech_to_text"),KOe=o(" \u2014 "),TB=a("a"),ZOe=o("Speech2TextTokenizer"),eGe=o(" (Speech2Text model)"),oGe=l(),Km=a("li"),eW=a("strong"),rGe=o("speech_to_text_2"),tGe=o(" \u2014 "),FB=a("a"),aGe=o("Speech2Text2Tokenizer"),nGe=o(" (Speech2Text2 model)"),sGe=l(),ds=a("li"),oW=a("strong"),lGe=o("splinter"),iGe=o(" \u2014 "),CB=a("a"),dGe=o("SplinterTokenizer"),cGe=o(" or "),EB=a("a"),fGe=o("SplinterTokenizerFast"),mGe=o(" (Splinter model)"),gGe=l(),cs=a("li"),rW=a("strong"),hGe=o("squeezebert"),uGe=o(" \u2014 "),MB=a("a"),pGe=o("SqueezeBertTokenizer"),_Ge=o(" or "),yB=a("a"),vGe=o("SqueezeBertTokenizerFast"),bGe=o(" (SqueezeBERT model)"),TGe=l(),fs=a("li"),tW=a("strong"),FGe=o("t5"),CGe=o(" \u2014 "),wB=a("a"),EGe=o("T5Tokenizer"),MGe=o(" or "),AB=a("a"),yGe=o("T5TokenizerFast"),wGe=o(" (T5 model)"),AGe=l(),Zm=a("li"),aW=a("strong"),LGe=o("tapas"),BGe=o(" \u2014 "),LB=a("a"),kGe=o("TapasTokenizer"),xGe=o(" (TAPAS model)"),RGe=l(),eg=a("li"),nW=a("strong"),SGe=o("transfo-xl"),PGe=o(" \u2014 "),BB=a("a"),$Ge=o("TransfoXLTokenizer"),IGe=o(" (Transformer-XL model)"),jGe=l(),og=a("li"),sW=a("strong"),NGe=o("wav2vec2"),DGe=o(" \u2014 "),kB=a("a"),qGe=o("Wav2Vec2CTCTokenizer"),OGe=o(" (Wav2Vec2 model)"),GGe=l(),rg=a("li"),lW=a("strong"),zGe=o("wav2vec2_phoneme"),VGe=o(" \u2014 "),xB=a("a"),XGe=o("Wav2Vec2PhonemeCTCTokenizer"),WGe=o(" (Wav2Vec2Phoneme model)"),QGe=l(),tg=a("li"),iW=a("strong"),HGe=o("xlm"),UGe=o(" \u2014 "),RB=a("a"),JGe=o("XLMTokenizer"),YGe=o(" (XLM model)"),KGe=l(),ag=a("li"),dW=a("strong"),ZGe=o("xlm-prophetnet"),eze=o(" \u2014 "),SB=a("a"),oze=o("XLMProphetNetTokenizer"),rze=o(" (XLMProphetNet model)"),tze=l(),ms=a("li"),cW=a("strong"),aze=o("xlm-roberta"),nze=o(" \u2014 "),PB=a("a"),sze=o("XLMRobertaTokenizer"),lze=o(" or "),$B=a("a"),ize=o("XLMRobertaTokenizerFast"),dze=o(" (XLM-RoBERTa model)"),cze=l(),gs=a("li"),fW=a("strong"),fze=o("xlnet"),mze=o(" \u2014 "),IB=a("a"),gze=o("XLNetTokenizer"),hze=o(" or "),jB=a("a"),uze=o("XLNetTokenizerFast"),pze=o(" (XLNet model)"),_ze=l(),mW=a("p"),vze=o("Examples:"),bze=l(),f(HE.$$.fragment),Tze=l(),ng=a("div"),f(UE.$$.fragment),Fze=l(),gW=a("p"),Cze=o("Register a new tokenizer in this mapping."),cwe=l(),mi=a("h2"),sg=a("a"),hW=a("span"),f(JE.$$.fragment),Eze=l(),uW=a("span"),Mze=o("AutoFeatureExtractor"),fwe=l(),Wt=a("div"),f(YE.$$.fragment),yze=l(),KE=a("p"),wze=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),NB=a("a"),Aze=o("AutoFeatureExtractor.from_pretrained()"),Lze=o(" class method."),Bze=l(),ZE=a("p"),kze=o("This class cannot be instantiated directly using "),pW=a("code"),xze=o("__init__()"),Rze=o(" (throws an error)."),Sze=l(),Ae=a("div"),f(eM.$$.fragment),Pze=l(),_W=a("p"),$ze=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Ize=l(),wa=a("p"),jze=o("The feature extractor class to instantiate is selected based on the "),vW=a("code"),Nze=o("model_type"),Dze=o(` property of the config object
(either passed as an argument or loaded from `),bW=a("code"),qze=o("pretrained_model_name_or_path"),Oze=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),TW=a("code"),Gze=o("pretrained_model_name_or_path"),zze=o(":"),Vze=l(),ie=a("ul"),lg=a("li"),FW=a("strong"),Xze=o("beit"),Wze=o(" \u2014 "),DB=a("a"),Qze=o("BeitFeatureExtractor"),Hze=o(" (BEiT model)"),Uze=l(),ig=a("li"),CW=a("strong"),Jze=o("clip"),Yze=o(" \u2014 "),qB=a("a"),Kze=o("CLIPFeatureExtractor"),Zze=o(" (CLIP model)"),eVe=l(),dg=a("li"),EW=a("strong"),oVe=o("deit"),rVe=o(" \u2014 "),OB=a("a"),tVe=o("DeiTFeatureExtractor"),aVe=o(" (DeiT model)"),nVe=l(),cg=a("li"),MW=a("strong"),sVe=o("detr"),lVe=o(" \u2014 "),GB=a("a"),iVe=o("DetrFeatureExtractor"),dVe=o(" (DETR model)"),cVe=l(),fg=a("li"),yW=a("strong"),fVe=o("hubert"),mVe=o(" \u2014 "),zB=a("a"),gVe=o("Wav2Vec2FeatureExtractor"),hVe=o(" (Hubert model)"),uVe=l(),mg=a("li"),wW=a("strong"),pVe=o("layoutlmv2"),_Ve=o(" \u2014 "),VB=a("a"),vVe=o("LayoutLMv2FeatureExtractor"),bVe=o(" (LayoutLMv2 model)"),TVe=l(),gg=a("li"),AW=a("strong"),FVe=o("perceiver"),CVe=o(" \u2014 "),XB=a("a"),EVe=o("PerceiverFeatureExtractor"),MVe=o(" (Perceiver model)"),yVe=l(),hg=a("li"),LW=a("strong"),wVe=o("speech_to_text"),AVe=o(" \u2014 "),WB=a("a"),LVe=o("Speech2TextFeatureExtractor"),BVe=o(" (Speech2Text model)"),kVe=l(),ug=a("li"),BW=a("strong"),xVe=o("swin"),RVe=o(" \u2014 "),QB=a("a"),SVe=o("ViTFeatureExtractor"),PVe=o(" (Swin model)"),$Ve=l(),pg=a("li"),kW=a("strong"),IVe=o("vit"),jVe=o(" \u2014 "),HB=a("a"),NVe=o("ViTFeatureExtractor"),DVe=o(" (ViT model)"),qVe=l(),_g=a("li"),xW=a("strong"),OVe=o("vit_mae"),GVe=o(" \u2014 "),UB=a("a"),zVe=o("ViTFeatureExtractor"),VVe=o(" (ViTMAE model)"),XVe=l(),vg=a("li"),RW=a("strong"),WVe=o("wav2vec2"),QVe=o(" \u2014 "),JB=a("a"),HVe=o("Wav2Vec2FeatureExtractor"),UVe=o(" (Wav2Vec2 model)"),JVe=l(),f(bg.$$.fragment),YVe=l(),SW=a("p"),KVe=o("Examples:"),ZVe=l(),f(oM.$$.fragment),mwe=l(),gi=a("h2"),Tg=a("a"),PW=a("span"),f(rM.$$.fragment),eXe=l(),$W=a("span"),oXe=o("AutoProcessor"),gwe=l(),Qt=a("div"),f(tM.$$.fragment),rXe=l(),aM=a("p"),tXe=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),YB=a("a"),aXe=o("AutoProcessor.from_pretrained()"),nXe=o(" class method."),sXe=l(),nM=a("p"),lXe=o("This class cannot be instantiated directly using "),IW=a("code"),iXe=o("__init__()"),dXe=o(" (throws an error)."),cXe=l(),Le=a("div"),f(sM.$$.fragment),fXe=l(),jW=a("p"),mXe=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),gXe=l(),hi=a("p"),hXe=o("The processor class to instantiate is selected based on the "),NW=a("code"),uXe=o("model_type"),pXe=o(` property of the config object (either
passed as an argument or loaded from `),DW=a("code"),_Xe=o("pretrained_model_name_or_path"),vXe=o(" if possible):"),bXe=l(),ye=a("ul"),Fg=a("li"),qW=a("strong"),TXe=o("clip"),FXe=o(" \u2014 "),KB=a("a"),CXe=o("CLIPProcessor"),EXe=o(" (CLIP model)"),MXe=l(),Cg=a("li"),OW=a("strong"),yXe=o("layoutlmv2"),wXe=o(" \u2014 "),ZB=a("a"),AXe=o("LayoutLMv2Processor"),LXe=o(" (LayoutLMv2 model)"),BXe=l(),Eg=a("li"),GW=a("strong"),kXe=o("layoutxlm"),xXe=o(" \u2014 "),e9=a("a"),RXe=o("LayoutXLMProcessor"),SXe=o(" (LayoutXLM model)"),PXe=l(),Mg=a("li"),zW=a("strong"),$Xe=o("speech_to_text"),IXe=o(" \u2014 "),o9=a("a"),jXe=o("Speech2TextProcessor"),NXe=o(" (Speech2Text model)"),DXe=l(),yg=a("li"),VW=a("strong"),qXe=o("speech_to_text_2"),OXe=o(" \u2014 "),r9=a("a"),GXe=o("Speech2Text2Processor"),zXe=o(" (Speech2Text2 model)"),VXe=l(),wg=a("li"),XW=a("strong"),XXe=o("trocr"),WXe=o(" \u2014 "),t9=a("a"),QXe=o("TrOCRProcessor"),HXe=o(" (TrOCR model)"),UXe=l(),Ag=a("li"),WW=a("strong"),JXe=o("vision-text-dual-encoder"),YXe=o(" \u2014 "),a9=a("a"),KXe=o("VisionTextDualEncoderProcessor"),ZXe=o(" (VisionTextDualEncoder model)"),eWe=l(),Lg=a("li"),QW=a("strong"),oWe=o("wav2vec2"),rWe=o(" \u2014 "),n9=a("a"),tWe=o("Wav2Vec2Processor"),aWe=o(" (Wav2Vec2 model)"),nWe=l(),f(Bg.$$.fragment),sWe=l(),HW=a("p"),lWe=o("Examples:"),iWe=l(),f(lM.$$.fragment),hwe=l(),ui=a("h2"),kg=a("a"),UW=a("span"),f(iM.$$.fragment),dWe=l(),JW=a("span"),cWe=o("AutoModel"),uwe=l(),Do=a("div"),f(dM.$$.fragment),fWe=l(),pi=a("p"),mWe=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),YW=a("code"),gWe=o("from_pretrained()"),hWe=o("class method or the "),KW=a("code"),uWe=o("from_config()"),pWe=o(`class
method.`),_We=l(),cM=a("p"),vWe=o("This class cannot be instantiated directly using "),ZW=a("code"),bWe=o("__init__()"),TWe=o(" (throws an error)."),FWe=l(),Br=a("div"),f(fM.$$.fragment),CWe=l(),eQ=a("p"),EWe=o("Instantiates one of the base model classes of the library from a configuration."),MWe=l(),_i=a("p"),yWe=o(`Note:
Loading a model from its configuration file does `),oQ=a("strong"),wWe=o("not"),AWe=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rQ=a("code"),LWe=o("from_pretrained()"),BWe=o("to load the model weights."),kWe=l(),tQ=a("p"),xWe=o("Examples:"),RWe=l(),f(mM.$$.fragment),SWe=l(),Be=a("div"),f(gM.$$.fragment),PWe=l(),aQ=a("p"),$We=o("Instantiate one of the base model classes of the library from a pretrained model."),IWe=l(),Aa=a("p"),jWe=o("The model class to instantiate is selected based on the "),nQ=a("code"),NWe=o("model_type"),DWe=o(` property of the config object (either
passed as an argument or loaded from `),sQ=a("code"),qWe=o("pretrained_model_name_or_path"),OWe=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lQ=a("code"),GWe=o("pretrained_model_name_or_path"),zWe=o(":"),VWe=l(),F=a("ul"),xg=a("li"),iQ=a("strong"),XWe=o("albert"),WWe=o(" \u2014 "),s9=a("a"),QWe=o("AlbertModel"),HWe=o(" (ALBERT model)"),UWe=l(),Rg=a("li"),dQ=a("strong"),JWe=o("bart"),YWe=o(" \u2014 "),l9=a("a"),KWe=o("BartModel"),ZWe=o(" (BART model)"),eQe=l(),Sg=a("li"),cQ=a("strong"),oQe=o("beit"),rQe=o(" \u2014 "),i9=a("a"),tQe=o("BeitModel"),aQe=o(" (BEiT model)"),nQe=l(),Pg=a("li"),fQ=a("strong"),sQe=o("bert"),lQe=o(" \u2014 "),d9=a("a"),iQe=o("BertModel"),dQe=o(" (BERT model)"),cQe=l(),$g=a("li"),mQ=a("strong"),fQe=o("bert-generation"),mQe=o(" \u2014 "),c9=a("a"),gQe=o("BertGenerationEncoder"),hQe=o(" (Bert Generation model)"),uQe=l(),Ig=a("li"),gQ=a("strong"),pQe=o("big_bird"),_Qe=o(" \u2014 "),f9=a("a"),vQe=o("BigBirdModel"),bQe=o(" (BigBird model)"),TQe=l(),jg=a("li"),hQ=a("strong"),FQe=o("bigbird_pegasus"),CQe=o(" \u2014 "),m9=a("a"),EQe=o("BigBirdPegasusModel"),MQe=o(" (BigBirdPegasus model)"),yQe=l(),Ng=a("li"),uQ=a("strong"),wQe=o("blenderbot"),AQe=o(" \u2014 "),g9=a("a"),LQe=o("BlenderbotModel"),BQe=o(" (Blenderbot model)"),kQe=l(),Dg=a("li"),pQ=a("strong"),xQe=o("blenderbot-small"),RQe=o(" \u2014 "),h9=a("a"),SQe=o("BlenderbotSmallModel"),PQe=o(" (BlenderbotSmall model)"),$Qe=l(),qg=a("li"),_Q=a("strong"),IQe=o("camembert"),jQe=o(" \u2014 "),u9=a("a"),NQe=o("CamembertModel"),DQe=o(" (CamemBERT model)"),qQe=l(),Og=a("li"),vQ=a("strong"),OQe=o("canine"),GQe=o(" \u2014 "),p9=a("a"),zQe=o("CanineModel"),VQe=o(" (Canine model)"),XQe=l(),Gg=a("li"),bQ=a("strong"),WQe=o("clip"),QQe=o(" \u2014 "),_9=a("a"),HQe=o("CLIPModel"),UQe=o(" (CLIP model)"),JQe=l(),zg=a("li"),TQ=a("strong"),YQe=o("convbert"),KQe=o(" \u2014 "),v9=a("a"),ZQe=o("ConvBertModel"),eHe=o(" (ConvBERT model)"),oHe=l(),Vg=a("li"),FQ=a("strong"),rHe=o("ctrl"),tHe=o(" \u2014 "),b9=a("a"),aHe=o("CTRLModel"),nHe=o(" (CTRL model)"),sHe=l(),Xg=a("li"),CQ=a("strong"),lHe=o("deberta"),iHe=o(" \u2014 "),T9=a("a"),dHe=o("DebertaModel"),cHe=o(" (DeBERTa model)"),fHe=l(),Wg=a("li"),EQ=a("strong"),mHe=o("deberta-v2"),gHe=o(" \u2014 "),F9=a("a"),hHe=o("DebertaV2Model"),uHe=o(" (DeBERTa-v2 model)"),pHe=l(),Qg=a("li"),MQ=a("strong"),_He=o("deit"),vHe=o(" \u2014 "),C9=a("a"),bHe=o("DeiTModel"),THe=o(" (DeiT model)"),FHe=l(),Hg=a("li"),yQ=a("strong"),CHe=o("detr"),EHe=o(" \u2014 "),E9=a("a"),MHe=o("DetrModel"),yHe=o(" (DETR model)"),wHe=l(),Ug=a("li"),wQ=a("strong"),AHe=o("distilbert"),LHe=o(" \u2014 "),M9=a("a"),BHe=o("DistilBertModel"),kHe=o(" (DistilBERT model)"),xHe=l(),Jg=a("li"),AQ=a("strong"),RHe=o("dpr"),SHe=o(" \u2014 "),y9=a("a"),PHe=o("DPRQuestionEncoder"),$He=o(" (DPR model)"),IHe=l(),Yg=a("li"),LQ=a("strong"),jHe=o("electra"),NHe=o(" \u2014 "),w9=a("a"),DHe=o("ElectraModel"),qHe=o(" (ELECTRA model)"),OHe=l(),Kg=a("li"),BQ=a("strong"),GHe=o("flaubert"),zHe=o(" \u2014 "),A9=a("a"),VHe=o("FlaubertModel"),XHe=o(" (FlauBERT model)"),WHe=l(),Zg=a("li"),kQ=a("strong"),QHe=o("fnet"),HHe=o(" \u2014 "),L9=a("a"),UHe=o("FNetModel"),JHe=o(" (FNet model)"),YHe=l(),eh=a("li"),xQ=a("strong"),KHe=o("fsmt"),ZHe=o(" \u2014 "),B9=a("a"),eUe=o("FSMTModel"),oUe=o(" (FairSeq Machine-Translation model)"),rUe=l(),hs=a("li"),RQ=a("strong"),tUe=o("funnel"),aUe=o(" \u2014 "),k9=a("a"),nUe=o("FunnelModel"),sUe=o(" or "),x9=a("a"),lUe=o("FunnelBaseModel"),iUe=o(" (Funnel Transformer model)"),dUe=l(),oh=a("li"),SQ=a("strong"),cUe=o("gpt2"),fUe=o(" \u2014 "),R9=a("a"),mUe=o("GPT2Model"),gUe=o(" (OpenAI GPT-2 model)"),hUe=l(),rh=a("li"),PQ=a("strong"),uUe=o("gpt_neo"),pUe=o(" \u2014 "),S9=a("a"),_Ue=o("GPTNeoModel"),vUe=o(" (GPT Neo model)"),bUe=l(),th=a("li"),$Q=a("strong"),TUe=o("gptj"),FUe=o(" \u2014 "),P9=a("a"),CUe=o("GPTJModel"),EUe=o(" (GPT-J model)"),MUe=l(),ah=a("li"),IQ=a("strong"),yUe=o("hubert"),wUe=o(" \u2014 "),$9=a("a"),AUe=o("HubertModel"),LUe=o(" (Hubert model)"),BUe=l(),nh=a("li"),jQ=a("strong"),kUe=o("ibert"),xUe=o(" \u2014 "),I9=a("a"),RUe=o("IBertModel"),SUe=o(" (I-BERT model)"),PUe=l(),sh=a("li"),NQ=a("strong"),$Ue=o("imagegpt"),IUe=o(" \u2014 "),j9=a("a"),jUe=o("ImageGPTModel"),NUe=o(" (ImageGPT model)"),DUe=l(),lh=a("li"),DQ=a("strong"),qUe=o("layoutlm"),OUe=o(" \u2014 "),N9=a("a"),GUe=o("LayoutLMModel"),zUe=o(" (LayoutLM model)"),VUe=l(),ih=a("li"),qQ=a("strong"),XUe=o("layoutlmv2"),WUe=o(" \u2014 "),D9=a("a"),QUe=o("LayoutLMv2Model"),HUe=o(" (LayoutLMv2 model)"),UUe=l(),dh=a("li"),OQ=a("strong"),JUe=o("led"),YUe=o(" \u2014 "),q9=a("a"),KUe=o("LEDModel"),ZUe=o(" (LED model)"),eJe=l(),ch=a("li"),GQ=a("strong"),oJe=o("longformer"),rJe=o(" \u2014 "),O9=a("a"),tJe=o("LongformerModel"),aJe=o(" (Longformer model)"),nJe=l(),fh=a("li"),zQ=a("strong"),sJe=o("luke"),lJe=o(" \u2014 "),G9=a("a"),iJe=o("LukeModel"),dJe=o(" (LUKE model)"),cJe=l(),mh=a("li"),VQ=a("strong"),fJe=o("lxmert"),mJe=o(" \u2014 "),z9=a("a"),gJe=o("LxmertModel"),hJe=o(" (LXMERT model)"),uJe=l(),gh=a("li"),XQ=a("strong"),pJe=o("m2m_100"),_Je=o(" \u2014 "),V9=a("a"),vJe=o("M2M100Model"),bJe=o(" (M2M100 model)"),TJe=l(),hh=a("li"),WQ=a("strong"),FJe=o("marian"),CJe=o(" \u2014 "),X9=a("a"),EJe=o("MarianModel"),MJe=o(" (Marian model)"),yJe=l(),uh=a("li"),QQ=a("strong"),wJe=o("mbart"),AJe=o(" \u2014 "),W9=a("a"),LJe=o("MBartModel"),BJe=o(" (mBART model)"),kJe=l(),ph=a("li"),HQ=a("strong"),xJe=o("megatron-bert"),RJe=o(" \u2014 "),Q9=a("a"),SJe=o("MegatronBertModel"),PJe=o(" (MegatronBert model)"),$Je=l(),_h=a("li"),UQ=a("strong"),IJe=o("mobilebert"),jJe=o(" \u2014 "),H9=a("a"),NJe=o("MobileBertModel"),DJe=o(" (MobileBERT model)"),qJe=l(),vh=a("li"),JQ=a("strong"),OJe=o("mpnet"),GJe=o(" \u2014 "),U9=a("a"),zJe=o("MPNetModel"),VJe=o(" (MPNet model)"),XJe=l(),bh=a("li"),YQ=a("strong"),WJe=o("mt5"),QJe=o(" \u2014 "),J9=a("a"),HJe=o("MT5Model"),UJe=o(" (mT5 model)"),JJe=l(),Th=a("li"),KQ=a("strong"),YJe=o("nystromformer"),KJe=o(" \u2014 "),Y9=a("a"),ZJe=o("NystromformerModel"),eYe=o(" (Nystromformer model)"),oYe=l(),Fh=a("li"),ZQ=a("strong"),rYe=o("openai-gpt"),tYe=o(" \u2014 "),K9=a("a"),aYe=o("OpenAIGPTModel"),nYe=o(" (OpenAI GPT model)"),sYe=l(),Ch=a("li"),eH=a("strong"),lYe=o("pegasus"),iYe=o(" \u2014 "),Z9=a("a"),dYe=o("PegasusModel"),cYe=o(" (Pegasus model)"),fYe=l(),Eh=a("li"),oH=a("strong"),mYe=o("perceiver"),gYe=o(" \u2014 "),ek=a("a"),hYe=o("PerceiverModel"),uYe=o(" (Perceiver model)"),pYe=l(),Mh=a("li"),rH=a("strong"),_Ye=o("prophetnet"),vYe=o(" \u2014 "),ok=a("a"),bYe=o("ProphetNetModel"),TYe=o(" (ProphetNet model)"),FYe=l(),yh=a("li"),tH=a("strong"),CYe=o("qdqbert"),EYe=o(" \u2014 "),rk=a("a"),MYe=o("QDQBertModel"),yYe=o(" (QDQBert model)"),wYe=l(),wh=a("li"),aH=a("strong"),AYe=o("reformer"),LYe=o(" \u2014 "),tk=a("a"),BYe=o("ReformerModel"),kYe=o(" (Reformer model)"),xYe=l(),Ah=a("li"),nH=a("strong"),RYe=o("rembert"),SYe=o(" \u2014 "),ak=a("a"),PYe=o("RemBertModel"),$Ye=o(" (RemBERT model)"),IYe=l(),Lh=a("li"),sH=a("strong"),jYe=o("retribert"),NYe=o(" \u2014 "),nk=a("a"),DYe=o("RetriBertModel"),qYe=o(" (RetriBERT model)"),OYe=l(),Bh=a("li"),lH=a("strong"),GYe=o("roberta"),zYe=o(" \u2014 "),sk=a("a"),VYe=o("RobertaModel"),XYe=o(" (RoBERTa model)"),WYe=l(),kh=a("li"),iH=a("strong"),QYe=o("roformer"),HYe=o(" \u2014 "),lk=a("a"),UYe=o("RoFormerModel"),JYe=o(" (RoFormer model)"),YYe=l(),xh=a("li"),dH=a("strong"),KYe=o("segformer"),ZYe=o(" \u2014 "),ik=a("a"),eKe=o("SegformerModel"),oKe=o(" (SegFormer model)"),rKe=l(),Rh=a("li"),cH=a("strong"),tKe=o("sew"),aKe=o(" \u2014 "),dk=a("a"),nKe=o("SEWModel"),sKe=o(" (SEW model)"),lKe=l(),Sh=a("li"),fH=a("strong"),iKe=o("sew-d"),dKe=o(" \u2014 "),ck=a("a"),cKe=o("SEWDModel"),fKe=o(" (SEW-D model)"),mKe=l(),Ph=a("li"),mH=a("strong"),gKe=o("speech_to_text"),hKe=o(" \u2014 "),fk=a("a"),uKe=o("Speech2TextModel"),pKe=o(" (Speech2Text model)"),_Ke=l(),$h=a("li"),gH=a("strong"),vKe=o("splinter"),bKe=o(" \u2014 "),mk=a("a"),TKe=o("SplinterModel"),FKe=o(" (Splinter model)"),CKe=l(),Ih=a("li"),hH=a("strong"),EKe=o("squeezebert"),MKe=o(" \u2014 "),gk=a("a"),yKe=o("SqueezeBertModel"),wKe=o(" (SqueezeBERT model)"),AKe=l(),jh=a("li"),uH=a("strong"),LKe=o("swin"),BKe=o(" \u2014 "),hk=a("a"),kKe=o("SwinModel"),xKe=o(" (Swin model)"),RKe=l(),Nh=a("li"),pH=a("strong"),SKe=o("t5"),PKe=o(" \u2014 "),uk=a("a"),$Ke=o("T5Model"),IKe=o(" (T5 model)"),jKe=l(),Dh=a("li"),_H=a("strong"),NKe=o("tapas"),DKe=o(" \u2014 "),pk=a("a"),qKe=o("TapasModel"),OKe=o(" (TAPAS model)"),GKe=l(),qh=a("li"),vH=a("strong"),zKe=o("transfo-xl"),VKe=o(" \u2014 "),_k=a("a"),XKe=o("TransfoXLModel"),WKe=o(" (Transformer-XL model)"),QKe=l(),Oh=a("li"),bH=a("strong"),HKe=o("unispeech"),UKe=o(" \u2014 "),vk=a("a"),JKe=o("UniSpeechModel"),YKe=o(" (UniSpeech model)"),KKe=l(),Gh=a("li"),TH=a("strong"),ZKe=o("unispeech-sat"),eZe=o(" \u2014 "),bk=a("a"),oZe=o("UniSpeechSatModel"),rZe=o(" (UniSpeechSat model)"),tZe=l(),zh=a("li"),FH=a("strong"),aZe=o("vilt"),nZe=o(" \u2014 "),Tk=a("a"),sZe=o("ViltModel"),lZe=o(" (ViLT model)"),iZe=l(),Vh=a("li"),CH=a("strong"),dZe=o("vision-text-dual-encoder"),cZe=o(" \u2014 "),Fk=a("a"),fZe=o("VisionTextDualEncoderModel"),mZe=o(" (VisionTextDualEncoder model)"),gZe=l(),Xh=a("li"),EH=a("strong"),hZe=o("visual_bert"),uZe=o(" \u2014 "),Ck=a("a"),pZe=o("VisualBertModel"),_Ze=o(" (VisualBert model)"),vZe=l(),Wh=a("li"),MH=a("strong"),bZe=o("vit"),TZe=o(" \u2014 "),Ek=a("a"),FZe=o("ViTModel"),CZe=o(" (ViT model)"),EZe=l(),Qh=a("li"),yH=a("strong"),MZe=o("vit_mae"),yZe=o(" \u2014 "),Mk=a("a"),wZe=o("ViTMAEModel"),AZe=o(" (ViTMAE model)"),LZe=l(),Hh=a("li"),wH=a("strong"),BZe=o("wav2vec2"),kZe=o(" \u2014 "),yk=a("a"),xZe=o("Wav2Vec2Model"),RZe=o(" (Wav2Vec2 model)"),SZe=l(),Uh=a("li"),AH=a("strong"),PZe=o("wavlm"),$Ze=o(" \u2014 "),wk=a("a"),IZe=o("WavLMModel"),jZe=o(" (WavLM model)"),NZe=l(),Jh=a("li"),LH=a("strong"),DZe=o("xlm"),qZe=o(" \u2014 "),Ak=a("a"),OZe=o("XLMModel"),GZe=o(" (XLM model)"),zZe=l(),Yh=a("li"),BH=a("strong"),VZe=o("xlm-prophetnet"),XZe=o(" \u2014 "),Lk=a("a"),WZe=o("XLMProphetNetModel"),QZe=o(" (XLMProphetNet model)"),HZe=l(),Kh=a("li"),kH=a("strong"),UZe=o("xlm-roberta"),JZe=o(" \u2014 "),Bk=a("a"),YZe=o("XLMRobertaModel"),KZe=o(" (XLM-RoBERTa model)"),ZZe=l(),Zh=a("li"),xH=a("strong"),eeo=o("xlnet"),oeo=o(" \u2014 "),kk=a("a"),reo=o("XLNetModel"),teo=o(" (XLNet model)"),aeo=l(),eu=a("li"),RH=a("strong"),neo=o("yoso"),seo=o(" \u2014 "),xk=a("a"),leo=o("YosoModel"),ieo=o(" (YOSO model)"),deo=l(),ou=a("p"),ceo=o("The model is set in evaluation mode by default using "),SH=a("code"),feo=o("model.eval()"),meo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),PH=a("code"),geo=o("model.train()"),heo=l(),$H=a("p"),ueo=o("Examples:"),peo=l(),f(hM.$$.fragment),pwe=l(),vi=a("h2"),ru=a("a"),IH=a("span"),f(uM.$$.fragment),_eo=l(),jH=a("span"),veo=o("AutoModelForPreTraining"),_we=l(),qo=a("div"),f(pM.$$.fragment),beo=l(),bi=a("p"),Teo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),NH=a("code"),Feo=o("from_pretrained()"),Ceo=o("class method or the "),DH=a("code"),Eeo=o("from_config()"),Meo=o(`class
method.`),yeo=l(),_M=a("p"),weo=o("This class cannot be instantiated directly using "),qH=a("code"),Aeo=o("__init__()"),Leo=o(" (throws an error)."),Beo=l(),kr=a("div"),f(vM.$$.fragment),keo=l(),OH=a("p"),xeo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Reo=l(),Ti=a("p"),Seo=o(`Note:
Loading a model from its configuration file does `),GH=a("strong"),Peo=o("not"),$eo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zH=a("code"),Ieo=o("from_pretrained()"),jeo=o("to load the model weights."),Neo=l(),VH=a("p"),Deo=o("Examples:"),qeo=l(),f(bM.$$.fragment),Oeo=l(),ke=a("div"),f(TM.$$.fragment),Geo=l(),XH=a("p"),zeo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Veo=l(),La=a("p"),Xeo=o("The model class to instantiate is selected based on the "),WH=a("code"),Weo=o("model_type"),Qeo=o(` property of the config object (either
passed as an argument or loaded from `),QH=a("code"),Heo=o("pretrained_model_name_or_path"),Ueo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HH=a("code"),Jeo=o("pretrained_model_name_or_path"),Yeo=o(":"),Keo=l(),x=a("ul"),tu=a("li"),UH=a("strong"),Zeo=o("albert"),eoo=o(" \u2014 "),Rk=a("a"),ooo=o("AlbertForPreTraining"),roo=o(" (ALBERT model)"),too=l(),au=a("li"),JH=a("strong"),aoo=o("bart"),noo=o(" \u2014 "),Sk=a("a"),soo=o("BartForConditionalGeneration"),loo=o(" (BART model)"),ioo=l(),nu=a("li"),YH=a("strong"),doo=o("bert"),coo=o(" \u2014 "),Pk=a("a"),foo=o("BertForPreTraining"),moo=o(" (BERT model)"),goo=l(),su=a("li"),KH=a("strong"),hoo=o("big_bird"),uoo=o(" \u2014 "),$k=a("a"),poo=o("BigBirdForPreTraining"),_oo=o(" (BigBird model)"),voo=l(),lu=a("li"),ZH=a("strong"),boo=o("camembert"),Too=o(" \u2014 "),Ik=a("a"),Foo=o("CamembertForMaskedLM"),Coo=o(" (CamemBERT model)"),Eoo=l(),iu=a("li"),eU=a("strong"),Moo=o("ctrl"),yoo=o(" \u2014 "),jk=a("a"),woo=o("CTRLLMHeadModel"),Aoo=o(" (CTRL model)"),Loo=l(),du=a("li"),oU=a("strong"),Boo=o("deberta"),koo=o(" \u2014 "),Nk=a("a"),xoo=o("DebertaForMaskedLM"),Roo=o(" (DeBERTa model)"),Soo=l(),cu=a("li"),rU=a("strong"),Poo=o("deberta-v2"),$oo=o(" \u2014 "),Dk=a("a"),Ioo=o("DebertaV2ForMaskedLM"),joo=o(" (DeBERTa-v2 model)"),Noo=l(),fu=a("li"),tU=a("strong"),Doo=o("distilbert"),qoo=o(" \u2014 "),qk=a("a"),Ooo=o("DistilBertForMaskedLM"),Goo=o(" (DistilBERT model)"),zoo=l(),mu=a("li"),aU=a("strong"),Voo=o("electra"),Xoo=o(" \u2014 "),Ok=a("a"),Woo=o("ElectraForPreTraining"),Qoo=o(" (ELECTRA model)"),Hoo=l(),gu=a("li"),nU=a("strong"),Uoo=o("flaubert"),Joo=o(" \u2014 "),Gk=a("a"),Yoo=o("FlaubertWithLMHeadModel"),Koo=o(" (FlauBERT model)"),Zoo=l(),hu=a("li"),sU=a("strong"),ero=o("fnet"),oro=o(" \u2014 "),zk=a("a"),rro=o("FNetForPreTraining"),tro=o(" (FNet model)"),aro=l(),uu=a("li"),lU=a("strong"),nro=o("fsmt"),sro=o(" \u2014 "),Vk=a("a"),lro=o("FSMTForConditionalGeneration"),iro=o(" (FairSeq Machine-Translation model)"),dro=l(),pu=a("li"),iU=a("strong"),cro=o("funnel"),fro=o(" \u2014 "),Xk=a("a"),mro=o("FunnelForPreTraining"),gro=o(" (Funnel Transformer model)"),hro=l(),_u=a("li"),dU=a("strong"),uro=o("gpt2"),pro=o(" \u2014 "),Wk=a("a"),_ro=o("GPT2LMHeadModel"),vro=o(" (OpenAI GPT-2 model)"),bro=l(),vu=a("li"),cU=a("strong"),Tro=o("ibert"),Fro=o(" \u2014 "),Qk=a("a"),Cro=o("IBertForMaskedLM"),Ero=o(" (I-BERT model)"),Mro=l(),bu=a("li"),fU=a("strong"),yro=o("layoutlm"),wro=o(" \u2014 "),Hk=a("a"),Aro=o("LayoutLMForMaskedLM"),Lro=o(" (LayoutLM model)"),Bro=l(),Tu=a("li"),mU=a("strong"),kro=o("longformer"),xro=o(" \u2014 "),Uk=a("a"),Rro=o("LongformerForMaskedLM"),Sro=o(" (Longformer model)"),Pro=l(),Fu=a("li"),gU=a("strong"),$ro=o("lxmert"),Iro=o(" \u2014 "),Jk=a("a"),jro=o("LxmertForPreTraining"),Nro=o(" (LXMERT model)"),Dro=l(),Cu=a("li"),hU=a("strong"),qro=o("megatron-bert"),Oro=o(" \u2014 "),Yk=a("a"),Gro=o("MegatronBertForPreTraining"),zro=o(" (MegatronBert model)"),Vro=l(),Eu=a("li"),uU=a("strong"),Xro=o("mobilebert"),Wro=o(" \u2014 "),Kk=a("a"),Qro=o("MobileBertForPreTraining"),Hro=o(" (MobileBERT model)"),Uro=l(),Mu=a("li"),pU=a("strong"),Jro=o("mpnet"),Yro=o(" \u2014 "),Zk=a("a"),Kro=o("MPNetForMaskedLM"),Zro=o(" (MPNet model)"),eto=l(),yu=a("li"),_U=a("strong"),oto=o("openai-gpt"),rto=o(" \u2014 "),ex=a("a"),tto=o("OpenAIGPTLMHeadModel"),ato=o(" (OpenAI GPT model)"),nto=l(),wu=a("li"),vU=a("strong"),sto=o("retribert"),lto=o(" \u2014 "),ox=a("a"),ito=o("RetriBertModel"),dto=o(" (RetriBERT model)"),cto=l(),Au=a("li"),bU=a("strong"),fto=o("roberta"),mto=o(" \u2014 "),rx=a("a"),gto=o("RobertaForMaskedLM"),hto=o(" (RoBERTa model)"),uto=l(),Lu=a("li"),TU=a("strong"),pto=o("squeezebert"),_to=o(" \u2014 "),tx=a("a"),vto=o("SqueezeBertForMaskedLM"),bto=o(" (SqueezeBERT model)"),Tto=l(),Bu=a("li"),FU=a("strong"),Fto=o("t5"),Cto=o(" \u2014 "),ax=a("a"),Eto=o("T5ForConditionalGeneration"),Mto=o(" (T5 model)"),yto=l(),ku=a("li"),CU=a("strong"),wto=o("tapas"),Ato=o(" \u2014 "),nx=a("a"),Lto=o("TapasForMaskedLM"),Bto=o(" (TAPAS model)"),kto=l(),xu=a("li"),EU=a("strong"),xto=o("transfo-xl"),Rto=o(" \u2014 "),sx=a("a"),Sto=o("TransfoXLLMHeadModel"),Pto=o(" (Transformer-XL model)"),$to=l(),Ru=a("li"),MU=a("strong"),Ito=o("unispeech"),jto=o(" \u2014 "),lx=a("a"),Nto=o("UniSpeechForPreTraining"),Dto=o(" (UniSpeech model)"),qto=l(),Su=a("li"),yU=a("strong"),Oto=o("unispeech-sat"),Gto=o(" \u2014 "),ix=a("a"),zto=o("UniSpeechSatForPreTraining"),Vto=o(" (UniSpeechSat model)"),Xto=l(),Pu=a("li"),wU=a("strong"),Wto=o("visual_bert"),Qto=o(" \u2014 "),dx=a("a"),Hto=o("VisualBertForPreTraining"),Uto=o(" (VisualBert model)"),Jto=l(),$u=a("li"),AU=a("strong"),Yto=o("vit_mae"),Kto=o(" \u2014 "),cx=a("a"),Zto=o("ViTMAEForPreTraining"),eao=o(" (ViTMAE model)"),oao=l(),Iu=a("li"),LU=a("strong"),rao=o("wav2vec2"),tao=o(" \u2014 "),fx=a("a"),aao=o("Wav2Vec2ForPreTraining"),nao=o(" (Wav2Vec2 model)"),sao=l(),ju=a("li"),BU=a("strong"),lao=o("xlm"),iao=o(" \u2014 "),mx=a("a"),dao=o("XLMWithLMHeadModel"),cao=o(" (XLM model)"),fao=l(),Nu=a("li"),kU=a("strong"),mao=o("xlm-roberta"),gao=o(" \u2014 "),gx=a("a"),hao=o("XLMRobertaForMaskedLM"),uao=o(" (XLM-RoBERTa model)"),pao=l(),Du=a("li"),xU=a("strong"),_ao=o("xlnet"),vao=o(" \u2014 "),hx=a("a"),bao=o("XLNetLMHeadModel"),Tao=o(" (XLNet model)"),Fao=l(),qu=a("p"),Cao=o("The model is set in evaluation mode by default using "),RU=a("code"),Eao=o("model.eval()"),Mao=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),SU=a("code"),yao=o("model.train()"),wao=l(),PU=a("p"),Aao=o("Examples:"),Lao=l(),f(FM.$$.fragment),vwe=l(),Fi=a("h2"),Ou=a("a"),$U=a("span"),f(CM.$$.fragment),Bao=l(),IU=a("span"),kao=o("AutoModelForCausalLM"),bwe=l(),Oo=a("div"),f(EM.$$.fragment),xao=l(),Ci=a("p"),Rao=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),jU=a("code"),Sao=o("from_pretrained()"),Pao=o("class method or the "),NU=a("code"),$ao=o("from_config()"),Iao=o(`class
method.`),jao=l(),MM=a("p"),Nao=o("This class cannot be instantiated directly using "),DU=a("code"),Dao=o("__init__()"),qao=o(" (throws an error)."),Oao=l(),xr=a("div"),f(yM.$$.fragment),Gao=l(),qU=a("p"),zao=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Vao=l(),Ei=a("p"),Xao=o(`Note:
Loading a model from its configuration file does `),OU=a("strong"),Wao=o("not"),Qao=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GU=a("code"),Hao=o("from_pretrained()"),Uao=o("to load the model weights."),Jao=l(),zU=a("p"),Yao=o("Examples:"),Kao=l(),f(wM.$$.fragment),Zao=l(),xe=a("div"),f(AM.$$.fragment),eno=l(),VU=a("p"),ono=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),rno=l(),Ba=a("p"),tno=o("The model class to instantiate is selected based on the "),XU=a("code"),ano=o("model_type"),nno=o(` property of the config object (either
passed as an argument or loaded from `),WU=a("code"),sno=o("pretrained_model_name_or_path"),lno=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QU=a("code"),ino=o("pretrained_model_name_or_path"),dno=o(":"),cno=l(),j=a("ul"),Gu=a("li"),HU=a("strong"),fno=o("bart"),mno=o(" \u2014 "),ux=a("a"),gno=o("BartForCausalLM"),hno=o(" (BART model)"),uno=l(),zu=a("li"),UU=a("strong"),pno=o("bert"),_no=o(" \u2014 "),px=a("a"),vno=o("BertLMHeadModel"),bno=o(" (BERT model)"),Tno=l(),Vu=a("li"),JU=a("strong"),Fno=o("bert-generation"),Cno=o(" \u2014 "),_x=a("a"),Eno=o("BertGenerationDecoder"),Mno=o(" (Bert Generation model)"),yno=l(),Xu=a("li"),YU=a("strong"),wno=o("big_bird"),Ano=o(" \u2014 "),vx=a("a"),Lno=o("BigBirdForCausalLM"),Bno=o(" (BigBird model)"),kno=l(),Wu=a("li"),KU=a("strong"),xno=o("bigbird_pegasus"),Rno=o(" \u2014 "),bx=a("a"),Sno=o("BigBirdPegasusForCausalLM"),Pno=o(" (BigBirdPegasus model)"),$no=l(),Qu=a("li"),ZU=a("strong"),Ino=o("blenderbot"),jno=o(" \u2014 "),Tx=a("a"),Nno=o("BlenderbotForCausalLM"),Dno=o(" (Blenderbot model)"),qno=l(),Hu=a("li"),eJ=a("strong"),Ono=o("blenderbot-small"),Gno=o(" \u2014 "),Fx=a("a"),zno=o("BlenderbotSmallForCausalLM"),Vno=o(" (BlenderbotSmall model)"),Xno=l(),Uu=a("li"),oJ=a("strong"),Wno=o("camembert"),Qno=o(" \u2014 "),Cx=a("a"),Hno=o("CamembertForCausalLM"),Uno=o(" (CamemBERT model)"),Jno=l(),Ju=a("li"),rJ=a("strong"),Yno=o("ctrl"),Kno=o(" \u2014 "),Ex=a("a"),Zno=o("CTRLLMHeadModel"),eso=o(" (CTRL model)"),oso=l(),Yu=a("li"),tJ=a("strong"),rso=o("electra"),tso=o(" \u2014 "),Mx=a("a"),aso=o("ElectraForCausalLM"),nso=o(" (ELECTRA model)"),sso=l(),Ku=a("li"),aJ=a("strong"),lso=o("gpt2"),iso=o(" \u2014 "),yx=a("a"),dso=o("GPT2LMHeadModel"),cso=o(" (OpenAI GPT-2 model)"),fso=l(),Zu=a("li"),nJ=a("strong"),mso=o("gpt_neo"),gso=o(" \u2014 "),wx=a("a"),hso=o("GPTNeoForCausalLM"),uso=o(" (GPT Neo model)"),pso=l(),ep=a("li"),sJ=a("strong"),_so=o("gptj"),vso=o(" \u2014 "),Ax=a("a"),bso=o("GPTJForCausalLM"),Tso=o(" (GPT-J model)"),Fso=l(),op=a("li"),lJ=a("strong"),Cso=o("marian"),Eso=o(" \u2014 "),Lx=a("a"),Mso=o("MarianForCausalLM"),yso=o(" (Marian model)"),wso=l(),rp=a("li"),iJ=a("strong"),Aso=o("mbart"),Lso=o(" \u2014 "),Bx=a("a"),Bso=o("MBartForCausalLM"),kso=o(" (mBART model)"),xso=l(),tp=a("li"),dJ=a("strong"),Rso=o("megatron-bert"),Sso=o(" \u2014 "),kx=a("a"),Pso=o("MegatronBertForCausalLM"),$so=o(" (MegatronBert model)"),Iso=l(),ap=a("li"),cJ=a("strong"),jso=o("openai-gpt"),Nso=o(" \u2014 "),xx=a("a"),Dso=o("OpenAIGPTLMHeadModel"),qso=o(" (OpenAI GPT model)"),Oso=l(),np=a("li"),fJ=a("strong"),Gso=o("pegasus"),zso=o(" \u2014 "),Rx=a("a"),Vso=o("PegasusForCausalLM"),Xso=o(" (Pegasus model)"),Wso=l(),sp=a("li"),mJ=a("strong"),Qso=o("prophetnet"),Hso=o(" \u2014 "),Sx=a("a"),Uso=o("ProphetNetForCausalLM"),Jso=o(" (ProphetNet model)"),Yso=l(),lp=a("li"),gJ=a("strong"),Kso=o("qdqbert"),Zso=o(" \u2014 "),Px=a("a"),elo=o("QDQBertLMHeadModel"),olo=o(" (QDQBert model)"),rlo=l(),ip=a("li"),hJ=a("strong"),tlo=o("reformer"),alo=o(" \u2014 "),$x=a("a"),nlo=o("ReformerModelWithLMHead"),slo=o(" (Reformer model)"),llo=l(),dp=a("li"),uJ=a("strong"),ilo=o("rembert"),dlo=o(" \u2014 "),Ix=a("a"),clo=o("RemBertForCausalLM"),flo=o(" (RemBERT model)"),mlo=l(),cp=a("li"),pJ=a("strong"),glo=o("roberta"),hlo=o(" \u2014 "),jx=a("a"),ulo=o("RobertaForCausalLM"),plo=o(" (RoBERTa model)"),_lo=l(),fp=a("li"),_J=a("strong"),vlo=o("roformer"),blo=o(" \u2014 "),Nx=a("a"),Tlo=o("RoFormerForCausalLM"),Flo=o(" (RoFormer model)"),Clo=l(),mp=a("li"),vJ=a("strong"),Elo=o("speech_to_text_2"),Mlo=o(" \u2014 "),Dx=a("a"),ylo=o("Speech2Text2ForCausalLM"),wlo=o(" (Speech2Text2 model)"),Alo=l(),gp=a("li"),bJ=a("strong"),Llo=o("transfo-xl"),Blo=o(" \u2014 "),qx=a("a"),klo=o("TransfoXLLMHeadModel"),xlo=o(" (Transformer-XL model)"),Rlo=l(),hp=a("li"),TJ=a("strong"),Slo=o("trocr"),Plo=o(" \u2014 "),Ox=a("a"),$lo=o("TrOCRForCausalLM"),Ilo=o(" (TrOCR model)"),jlo=l(),up=a("li"),FJ=a("strong"),Nlo=o("xlm"),Dlo=o(" \u2014 "),Gx=a("a"),qlo=o("XLMWithLMHeadModel"),Olo=o(" (XLM model)"),Glo=l(),pp=a("li"),CJ=a("strong"),zlo=o("xlm-prophetnet"),Vlo=o(" \u2014 "),zx=a("a"),Xlo=o("XLMProphetNetForCausalLM"),Wlo=o(" (XLMProphetNet model)"),Qlo=l(),_p=a("li"),EJ=a("strong"),Hlo=o("xlm-roberta"),Ulo=o(" \u2014 "),Vx=a("a"),Jlo=o("XLMRobertaForCausalLM"),Ylo=o(" (XLM-RoBERTa model)"),Klo=l(),vp=a("li"),MJ=a("strong"),Zlo=o("xlnet"),eio=o(" \u2014 "),Xx=a("a"),oio=o("XLNetLMHeadModel"),rio=o(" (XLNet model)"),tio=l(),bp=a("p"),aio=o("The model is set in evaluation mode by default using "),yJ=a("code"),nio=o("model.eval()"),sio=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wJ=a("code"),lio=o("model.train()"),iio=l(),AJ=a("p"),dio=o("Examples:"),cio=l(),f(LM.$$.fragment),Twe=l(),Mi=a("h2"),Tp=a("a"),LJ=a("span"),f(BM.$$.fragment),fio=l(),BJ=a("span"),mio=o("AutoModelForMaskedLM"),Fwe=l(),Go=a("div"),f(kM.$$.fragment),gio=l(),yi=a("p"),hio=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),kJ=a("code"),uio=o("from_pretrained()"),pio=o("class method or the "),xJ=a("code"),_io=o("from_config()"),vio=o(`class
method.`),bio=l(),xM=a("p"),Tio=o("This class cannot be instantiated directly using "),RJ=a("code"),Fio=o("__init__()"),Cio=o(" (throws an error)."),Eio=l(),Rr=a("div"),f(RM.$$.fragment),Mio=l(),SJ=a("p"),yio=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),wio=l(),wi=a("p"),Aio=o(`Note:
Loading a model from its configuration file does `),PJ=a("strong"),Lio=o("not"),Bio=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$J=a("code"),kio=o("from_pretrained()"),xio=o("to load the model weights."),Rio=l(),IJ=a("p"),Sio=o("Examples:"),Pio=l(),f(SM.$$.fragment),$io=l(),Re=a("div"),f(PM.$$.fragment),Iio=l(),jJ=a("p"),jio=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Nio=l(),ka=a("p"),Dio=o("The model class to instantiate is selected based on the "),NJ=a("code"),qio=o("model_type"),Oio=o(` property of the config object (either
passed as an argument or loaded from `),DJ=a("code"),Gio=o("pretrained_model_name_or_path"),zio=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qJ=a("code"),Vio=o("pretrained_model_name_or_path"),Xio=o(":"),Wio=l(),$=a("ul"),Fp=a("li"),OJ=a("strong"),Qio=o("albert"),Hio=o(" \u2014 "),Wx=a("a"),Uio=o("AlbertForMaskedLM"),Jio=o(" (ALBERT model)"),Yio=l(),Cp=a("li"),GJ=a("strong"),Kio=o("bart"),Zio=o(" \u2014 "),Qx=a("a"),edo=o("BartForConditionalGeneration"),odo=o(" (BART model)"),rdo=l(),Ep=a("li"),zJ=a("strong"),tdo=o("bert"),ado=o(" \u2014 "),Hx=a("a"),ndo=o("BertForMaskedLM"),sdo=o(" (BERT model)"),ldo=l(),Mp=a("li"),VJ=a("strong"),ido=o("big_bird"),ddo=o(" \u2014 "),Ux=a("a"),cdo=o("BigBirdForMaskedLM"),fdo=o(" (BigBird model)"),mdo=l(),yp=a("li"),XJ=a("strong"),gdo=o("camembert"),hdo=o(" \u2014 "),Jx=a("a"),udo=o("CamembertForMaskedLM"),pdo=o(" (CamemBERT model)"),_do=l(),wp=a("li"),WJ=a("strong"),vdo=o("convbert"),bdo=o(" \u2014 "),Yx=a("a"),Tdo=o("ConvBertForMaskedLM"),Fdo=o(" (ConvBERT model)"),Cdo=l(),Ap=a("li"),QJ=a("strong"),Edo=o("deberta"),Mdo=o(" \u2014 "),Kx=a("a"),ydo=o("DebertaForMaskedLM"),wdo=o(" (DeBERTa model)"),Ado=l(),Lp=a("li"),HJ=a("strong"),Ldo=o("deberta-v2"),Bdo=o(" \u2014 "),Zx=a("a"),kdo=o("DebertaV2ForMaskedLM"),xdo=o(" (DeBERTa-v2 model)"),Rdo=l(),Bp=a("li"),UJ=a("strong"),Sdo=o("distilbert"),Pdo=o(" \u2014 "),eR=a("a"),$do=o("DistilBertForMaskedLM"),Ido=o(" (DistilBERT model)"),jdo=l(),kp=a("li"),JJ=a("strong"),Ndo=o("electra"),Ddo=o(" \u2014 "),oR=a("a"),qdo=o("ElectraForMaskedLM"),Odo=o(" (ELECTRA model)"),Gdo=l(),xp=a("li"),YJ=a("strong"),zdo=o("flaubert"),Vdo=o(" \u2014 "),rR=a("a"),Xdo=o("FlaubertWithLMHeadModel"),Wdo=o(" (FlauBERT model)"),Qdo=l(),Rp=a("li"),KJ=a("strong"),Hdo=o("fnet"),Udo=o(" \u2014 "),tR=a("a"),Jdo=o("FNetForMaskedLM"),Ydo=o(" (FNet model)"),Kdo=l(),Sp=a("li"),ZJ=a("strong"),Zdo=o("funnel"),eco=o(" \u2014 "),aR=a("a"),oco=o("FunnelForMaskedLM"),rco=o(" (Funnel Transformer model)"),tco=l(),Pp=a("li"),eY=a("strong"),aco=o("ibert"),nco=o(" \u2014 "),nR=a("a"),sco=o("IBertForMaskedLM"),lco=o(" (I-BERT model)"),ico=l(),$p=a("li"),oY=a("strong"),dco=o("layoutlm"),cco=o(" \u2014 "),sR=a("a"),fco=o("LayoutLMForMaskedLM"),mco=o(" (LayoutLM model)"),gco=l(),Ip=a("li"),rY=a("strong"),hco=o("longformer"),uco=o(" \u2014 "),lR=a("a"),pco=o("LongformerForMaskedLM"),_co=o(" (Longformer model)"),vco=l(),jp=a("li"),tY=a("strong"),bco=o("mbart"),Tco=o(" \u2014 "),iR=a("a"),Fco=o("MBartForConditionalGeneration"),Cco=o(" (mBART model)"),Eco=l(),Np=a("li"),aY=a("strong"),Mco=o("megatron-bert"),yco=o(" \u2014 "),dR=a("a"),wco=o("MegatronBertForMaskedLM"),Aco=o(" (MegatronBert model)"),Lco=l(),Dp=a("li"),nY=a("strong"),Bco=o("mobilebert"),kco=o(" \u2014 "),cR=a("a"),xco=o("MobileBertForMaskedLM"),Rco=o(" (MobileBERT model)"),Sco=l(),qp=a("li"),sY=a("strong"),Pco=o("mpnet"),$co=o(" \u2014 "),fR=a("a"),Ico=o("MPNetForMaskedLM"),jco=o(" (MPNet model)"),Nco=l(),Op=a("li"),lY=a("strong"),Dco=o("nystromformer"),qco=o(" \u2014 "),mR=a("a"),Oco=o("NystromformerForMaskedLM"),Gco=o(" (Nystromformer model)"),zco=l(),Gp=a("li"),iY=a("strong"),Vco=o("perceiver"),Xco=o(" \u2014 "),gR=a("a"),Wco=o("PerceiverForMaskedLM"),Qco=o(" (Perceiver model)"),Hco=l(),zp=a("li"),dY=a("strong"),Uco=o("qdqbert"),Jco=o(" \u2014 "),hR=a("a"),Yco=o("QDQBertForMaskedLM"),Kco=o(" (QDQBert model)"),Zco=l(),Vp=a("li"),cY=a("strong"),efo=o("reformer"),ofo=o(" \u2014 "),uR=a("a"),rfo=o("ReformerForMaskedLM"),tfo=o(" (Reformer model)"),afo=l(),Xp=a("li"),fY=a("strong"),nfo=o("rembert"),sfo=o(" \u2014 "),pR=a("a"),lfo=o("RemBertForMaskedLM"),ifo=o(" (RemBERT model)"),dfo=l(),Wp=a("li"),mY=a("strong"),cfo=o("roberta"),ffo=o(" \u2014 "),_R=a("a"),mfo=o("RobertaForMaskedLM"),gfo=o(" (RoBERTa model)"),hfo=l(),Qp=a("li"),gY=a("strong"),ufo=o("roformer"),pfo=o(" \u2014 "),vR=a("a"),_fo=o("RoFormerForMaskedLM"),vfo=o(" (RoFormer model)"),bfo=l(),Hp=a("li"),hY=a("strong"),Tfo=o("squeezebert"),Ffo=o(" \u2014 "),bR=a("a"),Cfo=o("SqueezeBertForMaskedLM"),Efo=o(" (SqueezeBERT model)"),Mfo=l(),Up=a("li"),uY=a("strong"),yfo=o("tapas"),wfo=o(" \u2014 "),TR=a("a"),Afo=o("TapasForMaskedLM"),Lfo=o(" (TAPAS model)"),Bfo=l(),Jp=a("li"),pY=a("strong"),kfo=o("wav2vec2"),xfo=o(" \u2014 "),_Y=a("code"),Rfo=o("Wav2Vec2ForMaskedLM"),Sfo=o("(Wav2Vec2 model)"),Pfo=l(),Yp=a("li"),vY=a("strong"),$fo=o("xlm"),Ifo=o(" \u2014 "),FR=a("a"),jfo=o("XLMWithLMHeadModel"),Nfo=o(" (XLM model)"),Dfo=l(),Kp=a("li"),bY=a("strong"),qfo=o("xlm-roberta"),Ofo=o(" \u2014 "),CR=a("a"),Gfo=o("XLMRobertaForMaskedLM"),zfo=o(" (XLM-RoBERTa model)"),Vfo=l(),Zp=a("li"),TY=a("strong"),Xfo=o("yoso"),Wfo=o(" \u2014 "),ER=a("a"),Qfo=o("YosoForMaskedLM"),Hfo=o(" (YOSO model)"),Ufo=l(),e_=a("p"),Jfo=o("The model is set in evaluation mode by default using "),FY=a("code"),Yfo=o("model.eval()"),Kfo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CY=a("code"),Zfo=o("model.train()"),emo=l(),EY=a("p"),omo=o("Examples:"),rmo=l(),f($M.$$.fragment),Cwe=l(),Ai=a("h2"),o_=a("a"),MY=a("span"),f(IM.$$.fragment),tmo=l(),yY=a("span"),amo=o("AutoModelForSeq2SeqLM"),Ewe=l(),zo=a("div"),f(jM.$$.fragment),nmo=l(),Li=a("p"),smo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),wY=a("code"),lmo=o("from_pretrained()"),imo=o("class method or the "),AY=a("code"),dmo=o("from_config()"),cmo=o(`class
method.`),fmo=l(),NM=a("p"),mmo=o("This class cannot be instantiated directly using "),LY=a("code"),gmo=o("__init__()"),hmo=o(" (throws an error)."),umo=l(),Sr=a("div"),f(DM.$$.fragment),pmo=l(),BY=a("p"),_mo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),vmo=l(),Bi=a("p"),bmo=o(`Note:
Loading a model from its configuration file does `),kY=a("strong"),Tmo=o("not"),Fmo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xY=a("code"),Cmo=o("from_pretrained()"),Emo=o("to load the model weights."),Mmo=l(),RY=a("p"),ymo=o("Examples:"),wmo=l(),f(qM.$$.fragment),Amo=l(),Se=a("div"),f(OM.$$.fragment),Lmo=l(),SY=a("p"),Bmo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),kmo=l(),xa=a("p"),xmo=o("The model class to instantiate is selected based on the "),PY=a("code"),Rmo=o("model_type"),Smo=o(` property of the config object (either
passed as an argument or loaded from `),$Y=a("code"),Pmo=o("pretrained_model_name_or_path"),$mo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IY=a("code"),Imo=o("pretrained_model_name_or_path"),jmo=o(":"),Nmo=l(),ne=a("ul"),r_=a("li"),jY=a("strong"),Dmo=o("bart"),qmo=o(" \u2014 "),MR=a("a"),Omo=o("BartForConditionalGeneration"),Gmo=o(" (BART model)"),zmo=l(),t_=a("li"),NY=a("strong"),Vmo=o("bigbird_pegasus"),Xmo=o(" \u2014 "),yR=a("a"),Wmo=o("BigBirdPegasusForConditionalGeneration"),Qmo=o(" (BigBirdPegasus model)"),Hmo=l(),a_=a("li"),DY=a("strong"),Umo=o("blenderbot"),Jmo=o(" \u2014 "),wR=a("a"),Ymo=o("BlenderbotForConditionalGeneration"),Kmo=o(" (Blenderbot model)"),Zmo=l(),n_=a("li"),qY=a("strong"),ego=o("blenderbot-small"),ogo=o(" \u2014 "),AR=a("a"),rgo=o("BlenderbotSmallForConditionalGeneration"),tgo=o(" (BlenderbotSmall model)"),ago=l(),s_=a("li"),OY=a("strong"),ngo=o("encoder-decoder"),sgo=o(" \u2014 "),LR=a("a"),lgo=o("EncoderDecoderModel"),igo=o(" (Encoder decoder model)"),dgo=l(),l_=a("li"),GY=a("strong"),cgo=o("fsmt"),fgo=o(" \u2014 "),BR=a("a"),mgo=o("FSMTForConditionalGeneration"),ggo=o(" (FairSeq Machine-Translation model)"),hgo=l(),i_=a("li"),zY=a("strong"),ugo=o("led"),pgo=o(" \u2014 "),kR=a("a"),_go=o("LEDForConditionalGeneration"),vgo=o(" (LED model)"),bgo=l(),d_=a("li"),VY=a("strong"),Tgo=o("m2m_100"),Fgo=o(" \u2014 "),xR=a("a"),Cgo=o("M2M100ForConditionalGeneration"),Ego=o(" (M2M100 model)"),Mgo=l(),c_=a("li"),XY=a("strong"),ygo=o("marian"),wgo=o(" \u2014 "),RR=a("a"),Ago=o("MarianMTModel"),Lgo=o(" (Marian model)"),Bgo=l(),f_=a("li"),WY=a("strong"),kgo=o("mbart"),xgo=o(" \u2014 "),SR=a("a"),Rgo=o("MBartForConditionalGeneration"),Sgo=o(" (mBART model)"),Pgo=l(),m_=a("li"),QY=a("strong"),$go=o("mt5"),Igo=o(" \u2014 "),PR=a("a"),jgo=o("MT5ForConditionalGeneration"),Ngo=o(" (mT5 model)"),Dgo=l(),g_=a("li"),HY=a("strong"),qgo=o("pegasus"),Ogo=o(" \u2014 "),$R=a("a"),Ggo=o("PegasusForConditionalGeneration"),zgo=o(" (Pegasus model)"),Vgo=l(),h_=a("li"),UY=a("strong"),Xgo=o("prophetnet"),Wgo=o(" \u2014 "),IR=a("a"),Qgo=o("ProphetNetForConditionalGeneration"),Hgo=o(" (ProphetNet model)"),Ugo=l(),u_=a("li"),JY=a("strong"),Jgo=o("t5"),Ygo=o(" \u2014 "),jR=a("a"),Kgo=o("T5ForConditionalGeneration"),Zgo=o(" (T5 model)"),eho=l(),p_=a("li"),YY=a("strong"),oho=o("xlm-prophetnet"),rho=o(" \u2014 "),NR=a("a"),tho=o("XLMProphetNetForConditionalGeneration"),aho=o(" (XLMProphetNet model)"),nho=l(),__=a("p"),sho=o("The model is set in evaluation mode by default using "),KY=a("code"),lho=o("model.eval()"),iho=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ZY=a("code"),dho=o("model.train()"),cho=l(),eK=a("p"),fho=o("Examples:"),mho=l(),f(GM.$$.fragment),Mwe=l(),ki=a("h2"),v_=a("a"),oK=a("span"),f(zM.$$.fragment),gho=l(),rK=a("span"),hho=o("AutoModelForSequenceClassification"),ywe=l(),Vo=a("div"),f(VM.$$.fragment),uho=l(),xi=a("p"),pho=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),tK=a("code"),_ho=o("from_pretrained()"),vho=o("class method or the "),aK=a("code"),bho=o("from_config()"),Tho=o(`class
method.`),Fho=l(),XM=a("p"),Cho=o("This class cannot be instantiated directly using "),nK=a("code"),Eho=o("__init__()"),Mho=o(" (throws an error)."),yho=l(),Pr=a("div"),f(WM.$$.fragment),who=l(),sK=a("p"),Aho=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Lho=l(),Ri=a("p"),Bho=o(`Note:
Loading a model from its configuration file does `),lK=a("strong"),kho=o("not"),xho=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iK=a("code"),Rho=o("from_pretrained()"),Sho=o("to load the model weights."),Pho=l(),dK=a("p"),$ho=o("Examples:"),Iho=l(),f(QM.$$.fragment),jho=l(),Pe=a("div"),f(HM.$$.fragment),Nho=l(),cK=a("p"),Dho=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),qho=l(),Ra=a("p"),Oho=o("The model class to instantiate is selected based on the "),fK=a("code"),Gho=o("model_type"),zho=o(` property of the config object (either
passed as an argument or loaded from `),mK=a("code"),Vho=o("pretrained_model_name_or_path"),Xho=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gK=a("code"),Who=o("pretrained_model_name_or_path"),Qho=o(":"),Hho=l(),A=a("ul"),b_=a("li"),hK=a("strong"),Uho=o("albert"),Jho=o(" \u2014 "),DR=a("a"),Yho=o("AlbertForSequenceClassification"),Kho=o(" (ALBERT model)"),Zho=l(),T_=a("li"),uK=a("strong"),euo=o("bart"),ouo=o(" \u2014 "),qR=a("a"),ruo=o("BartForSequenceClassification"),tuo=o(" (BART model)"),auo=l(),F_=a("li"),pK=a("strong"),nuo=o("bert"),suo=o(" \u2014 "),OR=a("a"),luo=o("BertForSequenceClassification"),iuo=o(" (BERT model)"),duo=l(),C_=a("li"),_K=a("strong"),cuo=o("big_bird"),fuo=o(" \u2014 "),GR=a("a"),muo=o("BigBirdForSequenceClassification"),guo=o(" (BigBird model)"),huo=l(),E_=a("li"),vK=a("strong"),uuo=o("bigbird_pegasus"),puo=o(" \u2014 "),zR=a("a"),_uo=o("BigBirdPegasusForSequenceClassification"),vuo=o(" (BigBirdPegasus model)"),buo=l(),M_=a("li"),bK=a("strong"),Tuo=o("camembert"),Fuo=o(" \u2014 "),VR=a("a"),Cuo=o("CamembertForSequenceClassification"),Euo=o(" (CamemBERT model)"),Muo=l(),y_=a("li"),TK=a("strong"),yuo=o("canine"),wuo=o(" \u2014 "),XR=a("a"),Auo=o("CanineForSequenceClassification"),Luo=o(" (Canine model)"),Buo=l(),w_=a("li"),FK=a("strong"),kuo=o("convbert"),xuo=o(" \u2014 "),WR=a("a"),Ruo=o("ConvBertForSequenceClassification"),Suo=o(" (ConvBERT model)"),Puo=l(),A_=a("li"),CK=a("strong"),$uo=o("ctrl"),Iuo=o(" \u2014 "),QR=a("a"),juo=o("CTRLForSequenceClassification"),Nuo=o(" (CTRL model)"),Duo=l(),L_=a("li"),EK=a("strong"),quo=o("deberta"),Ouo=o(" \u2014 "),HR=a("a"),Guo=o("DebertaForSequenceClassification"),zuo=o(" (DeBERTa model)"),Vuo=l(),B_=a("li"),MK=a("strong"),Xuo=o("deberta-v2"),Wuo=o(" \u2014 "),UR=a("a"),Quo=o("DebertaV2ForSequenceClassification"),Huo=o(" (DeBERTa-v2 model)"),Uuo=l(),k_=a("li"),yK=a("strong"),Juo=o("distilbert"),Yuo=o(" \u2014 "),JR=a("a"),Kuo=o("DistilBertForSequenceClassification"),Zuo=o(" (DistilBERT model)"),epo=l(),x_=a("li"),wK=a("strong"),opo=o("electra"),rpo=o(" \u2014 "),YR=a("a"),tpo=o("ElectraForSequenceClassification"),apo=o(" (ELECTRA model)"),npo=l(),R_=a("li"),AK=a("strong"),spo=o("flaubert"),lpo=o(" \u2014 "),KR=a("a"),ipo=o("FlaubertForSequenceClassification"),dpo=o(" (FlauBERT model)"),cpo=l(),S_=a("li"),LK=a("strong"),fpo=o("fnet"),mpo=o(" \u2014 "),ZR=a("a"),gpo=o("FNetForSequenceClassification"),hpo=o(" (FNet model)"),upo=l(),P_=a("li"),BK=a("strong"),ppo=o("funnel"),_po=o(" \u2014 "),eS=a("a"),vpo=o("FunnelForSequenceClassification"),bpo=o(" (Funnel Transformer model)"),Tpo=l(),$_=a("li"),kK=a("strong"),Fpo=o("gpt2"),Cpo=o(" \u2014 "),oS=a("a"),Epo=o("GPT2ForSequenceClassification"),Mpo=o(" (OpenAI GPT-2 model)"),ypo=l(),I_=a("li"),xK=a("strong"),wpo=o("gpt_neo"),Apo=o(" \u2014 "),rS=a("a"),Lpo=o("GPTNeoForSequenceClassification"),Bpo=o(" (GPT Neo model)"),kpo=l(),j_=a("li"),RK=a("strong"),xpo=o("gptj"),Rpo=o(" \u2014 "),tS=a("a"),Spo=o("GPTJForSequenceClassification"),Ppo=o(" (GPT-J model)"),$po=l(),N_=a("li"),SK=a("strong"),Ipo=o("ibert"),jpo=o(" \u2014 "),aS=a("a"),Npo=o("IBertForSequenceClassification"),Dpo=o(" (I-BERT model)"),qpo=l(),D_=a("li"),PK=a("strong"),Opo=o("layoutlm"),Gpo=o(" \u2014 "),nS=a("a"),zpo=o("LayoutLMForSequenceClassification"),Vpo=o(" (LayoutLM model)"),Xpo=l(),q_=a("li"),$K=a("strong"),Wpo=o("layoutlmv2"),Qpo=o(" \u2014 "),sS=a("a"),Hpo=o("LayoutLMv2ForSequenceClassification"),Upo=o(" (LayoutLMv2 model)"),Jpo=l(),O_=a("li"),IK=a("strong"),Ypo=o("led"),Kpo=o(" \u2014 "),lS=a("a"),Zpo=o("LEDForSequenceClassification"),e_o=o(" (LED model)"),o_o=l(),G_=a("li"),jK=a("strong"),r_o=o("longformer"),t_o=o(" \u2014 "),iS=a("a"),a_o=o("LongformerForSequenceClassification"),n_o=o(" (Longformer model)"),s_o=l(),z_=a("li"),NK=a("strong"),l_o=o("mbart"),i_o=o(" \u2014 "),dS=a("a"),d_o=o("MBartForSequenceClassification"),c_o=o(" (mBART model)"),f_o=l(),V_=a("li"),DK=a("strong"),m_o=o("megatron-bert"),g_o=o(" \u2014 "),cS=a("a"),h_o=o("MegatronBertForSequenceClassification"),u_o=o(" (MegatronBert model)"),p_o=l(),X_=a("li"),qK=a("strong"),__o=o("mobilebert"),v_o=o(" \u2014 "),fS=a("a"),b_o=o("MobileBertForSequenceClassification"),T_o=o(" (MobileBERT model)"),F_o=l(),W_=a("li"),OK=a("strong"),C_o=o("mpnet"),E_o=o(" \u2014 "),mS=a("a"),M_o=o("MPNetForSequenceClassification"),y_o=o(" (MPNet model)"),w_o=l(),Q_=a("li"),GK=a("strong"),A_o=o("nystromformer"),L_o=o(" \u2014 "),gS=a("a"),B_o=o("NystromformerForSequenceClassification"),k_o=o(" (Nystromformer model)"),x_o=l(),H_=a("li"),zK=a("strong"),R_o=o("openai-gpt"),S_o=o(" \u2014 "),hS=a("a"),P_o=o("OpenAIGPTForSequenceClassification"),$_o=o(" (OpenAI GPT model)"),I_o=l(),U_=a("li"),VK=a("strong"),j_o=o("perceiver"),N_o=o(" \u2014 "),uS=a("a"),D_o=o("PerceiverForSequenceClassification"),q_o=o(" (Perceiver model)"),O_o=l(),J_=a("li"),XK=a("strong"),G_o=o("qdqbert"),z_o=o(" \u2014 "),pS=a("a"),V_o=o("QDQBertForSequenceClassification"),X_o=o(" (QDQBert model)"),W_o=l(),Y_=a("li"),WK=a("strong"),Q_o=o("reformer"),H_o=o(" \u2014 "),_S=a("a"),U_o=o("ReformerForSequenceClassification"),J_o=o(" (Reformer model)"),Y_o=l(),K_=a("li"),QK=a("strong"),K_o=o("rembert"),Z_o=o(" \u2014 "),vS=a("a"),e2o=o("RemBertForSequenceClassification"),o2o=o(" (RemBERT model)"),r2o=l(),Z_=a("li"),HK=a("strong"),t2o=o("roberta"),a2o=o(" \u2014 "),bS=a("a"),n2o=o("RobertaForSequenceClassification"),s2o=o(" (RoBERTa model)"),l2o=l(),e2=a("li"),UK=a("strong"),i2o=o("roformer"),d2o=o(" \u2014 "),TS=a("a"),c2o=o("RoFormerForSequenceClassification"),f2o=o(" (RoFormer model)"),m2o=l(),o2=a("li"),JK=a("strong"),g2o=o("squeezebert"),h2o=o(" \u2014 "),FS=a("a"),u2o=o("SqueezeBertForSequenceClassification"),p2o=o(" (SqueezeBERT model)"),_2o=l(),r2=a("li"),YK=a("strong"),v2o=o("tapas"),b2o=o(" \u2014 "),CS=a("a"),T2o=o("TapasForSequenceClassification"),F2o=o(" (TAPAS model)"),C2o=l(),t2=a("li"),KK=a("strong"),E2o=o("transfo-xl"),M2o=o(" \u2014 "),ES=a("a"),y2o=o("TransfoXLForSequenceClassification"),w2o=o(" (Transformer-XL model)"),A2o=l(),a2=a("li"),ZK=a("strong"),L2o=o("xlm"),B2o=o(" \u2014 "),MS=a("a"),k2o=o("XLMForSequenceClassification"),x2o=o(" (XLM model)"),R2o=l(),n2=a("li"),eZ=a("strong"),S2o=o("xlm-roberta"),P2o=o(" \u2014 "),yS=a("a"),$2o=o("XLMRobertaForSequenceClassification"),I2o=o(" (XLM-RoBERTa model)"),j2o=l(),s2=a("li"),oZ=a("strong"),N2o=o("xlnet"),D2o=o(" \u2014 "),wS=a("a"),q2o=o("XLNetForSequenceClassification"),O2o=o(" (XLNet model)"),G2o=l(),l2=a("li"),rZ=a("strong"),z2o=o("yoso"),V2o=o(" \u2014 "),AS=a("a"),X2o=o("YosoForSequenceClassification"),W2o=o(" (YOSO model)"),Q2o=l(),i2=a("p"),H2o=o("The model is set in evaluation mode by default using "),tZ=a("code"),U2o=o("model.eval()"),J2o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),aZ=a("code"),Y2o=o("model.train()"),K2o=l(),nZ=a("p"),Z2o=o("Examples:"),evo=l(),f(UM.$$.fragment),wwe=l(),Si=a("h2"),d2=a("a"),sZ=a("span"),f(JM.$$.fragment),ovo=l(),lZ=a("span"),rvo=o("AutoModelForMultipleChoice"),Awe=l(),Xo=a("div"),f(YM.$$.fragment),tvo=l(),Pi=a("p"),avo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),iZ=a("code"),nvo=o("from_pretrained()"),svo=o("class method or the "),dZ=a("code"),lvo=o("from_config()"),ivo=o(`class
method.`),dvo=l(),KM=a("p"),cvo=o("This class cannot be instantiated directly using "),cZ=a("code"),fvo=o("__init__()"),mvo=o(" (throws an error)."),gvo=l(),$r=a("div"),f(ZM.$$.fragment),hvo=l(),fZ=a("p"),uvo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),pvo=l(),$i=a("p"),_vo=o(`Note:
Loading a model from its configuration file does `),mZ=a("strong"),vvo=o("not"),bvo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gZ=a("code"),Tvo=o("from_pretrained()"),Fvo=o("to load the model weights."),Cvo=l(),hZ=a("p"),Evo=o("Examples:"),Mvo=l(),f(e3.$$.fragment),yvo=l(),$e=a("div"),f(o3.$$.fragment),wvo=l(),uZ=a("p"),Avo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Lvo=l(),Sa=a("p"),Bvo=o("The model class to instantiate is selected based on the "),pZ=a("code"),kvo=o("model_type"),xvo=o(` property of the config object (either
passed as an argument or loaded from `),_Z=a("code"),Rvo=o("pretrained_model_name_or_path"),Svo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vZ=a("code"),Pvo=o("pretrained_model_name_or_path"),$vo=o(":"),Ivo=l(),O=a("ul"),c2=a("li"),bZ=a("strong"),jvo=o("albert"),Nvo=o(" \u2014 "),LS=a("a"),Dvo=o("AlbertForMultipleChoice"),qvo=o(" (ALBERT model)"),Ovo=l(),f2=a("li"),TZ=a("strong"),Gvo=o("bert"),zvo=o(" \u2014 "),BS=a("a"),Vvo=o("BertForMultipleChoice"),Xvo=o(" (BERT model)"),Wvo=l(),m2=a("li"),FZ=a("strong"),Qvo=o("big_bird"),Hvo=o(" \u2014 "),kS=a("a"),Uvo=o("BigBirdForMultipleChoice"),Jvo=o(" (BigBird model)"),Yvo=l(),g2=a("li"),CZ=a("strong"),Kvo=o("camembert"),Zvo=o(" \u2014 "),xS=a("a"),e1o=o("CamembertForMultipleChoice"),o1o=o(" (CamemBERT model)"),r1o=l(),h2=a("li"),EZ=a("strong"),t1o=o("canine"),a1o=o(" \u2014 "),RS=a("a"),n1o=o("CanineForMultipleChoice"),s1o=o(" (Canine model)"),l1o=l(),u2=a("li"),MZ=a("strong"),i1o=o("convbert"),d1o=o(" \u2014 "),SS=a("a"),c1o=o("ConvBertForMultipleChoice"),f1o=o(" (ConvBERT model)"),m1o=l(),p2=a("li"),yZ=a("strong"),g1o=o("distilbert"),h1o=o(" \u2014 "),PS=a("a"),u1o=o("DistilBertForMultipleChoice"),p1o=o(" (DistilBERT model)"),_1o=l(),_2=a("li"),wZ=a("strong"),v1o=o("electra"),b1o=o(" \u2014 "),$S=a("a"),T1o=o("ElectraForMultipleChoice"),F1o=o(" (ELECTRA model)"),C1o=l(),v2=a("li"),AZ=a("strong"),E1o=o("flaubert"),M1o=o(" \u2014 "),IS=a("a"),y1o=o("FlaubertForMultipleChoice"),w1o=o(" (FlauBERT model)"),A1o=l(),b2=a("li"),LZ=a("strong"),L1o=o("fnet"),B1o=o(" \u2014 "),jS=a("a"),k1o=o("FNetForMultipleChoice"),x1o=o(" (FNet model)"),R1o=l(),T2=a("li"),BZ=a("strong"),S1o=o("funnel"),P1o=o(" \u2014 "),NS=a("a"),$1o=o("FunnelForMultipleChoice"),I1o=o(" (Funnel Transformer model)"),j1o=l(),F2=a("li"),kZ=a("strong"),N1o=o("ibert"),D1o=o(" \u2014 "),DS=a("a"),q1o=o("IBertForMultipleChoice"),O1o=o(" (I-BERT model)"),G1o=l(),C2=a("li"),xZ=a("strong"),z1o=o("longformer"),V1o=o(" \u2014 "),qS=a("a"),X1o=o("LongformerForMultipleChoice"),W1o=o(" (Longformer model)"),Q1o=l(),E2=a("li"),RZ=a("strong"),H1o=o("megatron-bert"),U1o=o(" \u2014 "),OS=a("a"),J1o=o("MegatronBertForMultipleChoice"),Y1o=o(" (MegatronBert model)"),K1o=l(),M2=a("li"),SZ=a("strong"),Z1o=o("mobilebert"),e4o=o(" \u2014 "),GS=a("a"),o4o=o("MobileBertForMultipleChoice"),r4o=o(" (MobileBERT model)"),t4o=l(),y2=a("li"),PZ=a("strong"),a4o=o("mpnet"),n4o=o(" \u2014 "),zS=a("a"),s4o=o("MPNetForMultipleChoice"),l4o=o(" (MPNet model)"),i4o=l(),w2=a("li"),$Z=a("strong"),d4o=o("nystromformer"),c4o=o(" \u2014 "),VS=a("a"),f4o=o("NystromformerForMultipleChoice"),m4o=o(" (Nystromformer model)"),g4o=l(),A2=a("li"),IZ=a("strong"),h4o=o("qdqbert"),u4o=o(" \u2014 "),XS=a("a"),p4o=o("QDQBertForMultipleChoice"),_4o=o(" (QDQBert model)"),v4o=l(),L2=a("li"),jZ=a("strong"),b4o=o("rembert"),T4o=o(" \u2014 "),WS=a("a"),F4o=o("RemBertForMultipleChoice"),C4o=o(" (RemBERT model)"),E4o=l(),B2=a("li"),NZ=a("strong"),M4o=o("roberta"),y4o=o(" \u2014 "),QS=a("a"),w4o=o("RobertaForMultipleChoice"),A4o=o(" (RoBERTa model)"),L4o=l(),k2=a("li"),DZ=a("strong"),B4o=o("roformer"),k4o=o(" \u2014 "),HS=a("a"),x4o=o("RoFormerForMultipleChoice"),R4o=o(" (RoFormer model)"),S4o=l(),x2=a("li"),qZ=a("strong"),P4o=o("squeezebert"),$4o=o(" \u2014 "),US=a("a"),I4o=o("SqueezeBertForMultipleChoice"),j4o=o(" (SqueezeBERT model)"),N4o=l(),R2=a("li"),OZ=a("strong"),D4o=o("xlm"),q4o=o(" \u2014 "),JS=a("a"),O4o=o("XLMForMultipleChoice"),G4o=o(" (XLM model)"),z4o=l(),S2=a("li"),GZ=a("strong"),V4o=o("xlm-roberta"),X4o=o(" \u2014 "),YS=a("a"),W4o=o("XLMRobertaForMultipleChoice"),Q4o=o(" (XLM-RoBERTa model)"),H4o=l(),P2=a("li"),zZ=a("strong"),U4o=o("xlnet"),J4o=o(" \u2014 "),KS=a("a"),Y4o=o("XLNetForMultipleChoice"),K4o=o(" (XLNet model)"),Z4o=l(),$2=a("li"),VZ=a("strong"),ebo=o("yoso"),obo=o(" \u2014 "),ZS=a("a"),rbo=o("YosoForMultipleChoice"),tbo=o(" (YOSO model)"),abo=l(),I2=a("p"),nbo=o("The model is set in evaluation mode by default using "),XZ=a("code"),sbo=o("model.eval()"),lbo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),WZ=a("code"),ibo=o("model.train()"),dbo=l(),QZ=a("p"),cbo=o("Examples:"),fbo=l(),f(r3.$$.fragment),Lwe=l(),Ii=a("h2"),j2=a("a"),HZ=a("span"),f(t3.$$.fragment),mbo=l(),UZ=a("span"),gbo=o("AutoModelForNextSentencePrediction"),Bwe=l(),Wo=a("div"),f(a3.$$.fragment),hbo=l(),ji=a("p"),ubo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),JZ=a("code"),pbo=o("from_pretrained()"),_bo=o("class method or the "),YZ=a("code"),vbo=o("from_config()"),bbo=o(`class
method.`),Tbo=l(),n3=a("p"),Fbo=o("This class cannot be instantiated directly using "),KZ=a("code"),Cbo=o("__init__()"),Ebo=o(" (throws an error)."),Mbo=l(),Ir=a("div"),f(s3.$$.fragment),ybo=l(),ZZ=a("p"),wbo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Abo=l(),Ni=a("p"),Lbo=o(`Note:
Loading a model from its configuration file does `),eee=a("strong"),Bbo=o("not"),kbo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oee=a("code"),xbo=o("from_pretrained()"),Rbo=o("to load the model weights."),Sbo=l(),ree=a("p"),Pbo=o("Examples:"),$bo=l(),f(l3.$$.fragment),Ibo=l(),Ie=a("div"),f(i3.$$.fragment),jbo=l(),tee=a("p"),Nbo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Dbo=l(),Pa=a("p"),qbo=o("The model class to instantiate is selected based on the "),aee=a("code"),Obo=o("model_type"),Gbo=o(` property of the config object (either
passed as an argument or loaded from `),nee=a("code"),zbo=o("pretrained_model_name_or_path"),Vbo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),see=a("code"),Xbo=o("pretrained_model_name_or_path"),Wbo=o(":"),Qbo=l(),Ht=a("ul"),N2=a("li"),lee=a("strong"),Hbo=o("bert"),Ubo=o(" \u2014 "),eP=a("a"),Jbo=o("BertForNextSentencePrediction"),Ybo=o(" (BERT model)"),Kbo=l(),D2=a("li"),iee=a("strong"),Zbo=o("fnet"),eTo=o(" \u2014 "),oP=a("a"),oTo=o("FNetForNextSentencePrediction"),rTo=o(" (FNet model)"),tTo=l(),q2=a("li"),dee=a("strong"),aTo=o("megatron-bert"),nTo=o(" \u2014 "),rP=a("a"),sTo=o("MegatronBertForNextSentencePrediction"),lTo=o(" (MegatronBert model)"),iTo=l(),O2=a("li"),cee=a("strong"),dTo=o("mobilebert"),cTo=o(" \u2014 "),tP=a("a"),fTo=o("MobileBertForNextSentencePrediction"),mTo=o(" (MobileBERT model)"),gTo=l(),G2=a("li"),fee=a("strong"),hTo=o("qdqbert"),uTo=o(" \u2014 "),aP=a("a"),pTo=o("QDQBertForNextSentencePrediction"),_To=o(" (QDQBert model)"),vTo=l(),z2=a("p"),bTo=o("The model is set in evaluation mode by default using "),mee=a("code"),TTo=o("model.eval()"),FTo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gee=a("code"),CTo=o("model.train()"),ETo=l(),hee=a("p"),MTo=o("Examples:"),yTo=l(),f(d3.$$.fragment),kwe=l(),Di=a("h2"),V2=a("a"),uee=a("span"),f(c3.$$.fragment),wTo=l(),pee=a("span"),ATo=o("AutoModelForTokenClassification"),xwe=l(),Qo=a("div"),f(f3.$$.fragment),LTo=l(),qi=a("p"),BTo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),_ee=a("code"),kTo=o("from_pretrained()"),xTo=o("class method or the "),vee=a("code"),RTo=o("from_config()"),STo=o(`class
method.`),PTo=l(),m3=a("p"),$To=o("This class cannot be instantiated directly using "),bee=a("code"),ITo=o("__init__()"),jTo=o(" (throws an error)."),NTo=l(),jr=a("div"),f(g3.$$.fragment),DTo=l(),Tee=a("p"),qTo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),OTo=l(),Oi=a("p"),GTo=o(`Note:
Loading a model from its configuration file does `),Fee=a("strong"),zTo=o("not"),VTo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cee=a("code"),XTo=o("from_pretrained()"),WTo=o("to load the model weights."),QTo=l(),Eee=a("p"),HTo=o("Examples:"),UTo=l(),f(h3.$$.fragment),JTo=l(),je=a("div"),f(u3.$$.fragment),YTo=l(),Mee=a("p"),KTo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),ZTo=l(),$a=a("p"),e6o=o("The model class to instantiate is selected based on the "),yee=a("code"),o6o=o("model_type"),r6o=o(` property of the config object (either
passed as an argument or loaded from `),wee=a("code"),t6o=o("pretrained_model_name_or_path"),a6o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Aee=a("code"),n6o=o("pretrained_model_name_or_path"),s6o=o(":"),l6o=l(),N=a("ul"),X2=a("li"),Lee=a("strong"),i6o=o("albert"),d6o=o(" \u2014 "),nP=a("a"),c6o=o("AlbertForTokenClassification"),f6o=o(" (ALBERT model)"),m6o=l(),W2=a("li"),Bee=a("strong"),g6o=o("bert"),h6o=o(" \u2014 "),sP=a("a"),u6o=o("BertForTokenClassification"),p6o=o(" (BERT model)"),_6o=l(),Q2=a("li"),kee=a("strong"),v6o=o("big_bird"),b6o=o(" \u2014 "),lP=a("a"),T6o=o("BigBirdForTokenClassification"),F6o=o(" (BigBird model)"),C6o=l(),H2=a("li"),xee=a("strong"),E6o=o("camembert"),M6o=o(" \u2014 "),iP=a("a"),y6o=o("CamembertForTokenClassification"),w6o=o(" (CamemBERT model)"),A6o=l(),U2=a("li"),Ree=a("strong"),L6o=o("canine"),B6o=o(" \u2014 "),dP=a("a"),k6o=o("CanineForTokenClassification"),x6o=o(" (Canine model)"),R6o=l(),J2=a("li"),See=a("strong"),S6o=o("convbert"),P6o=o(" \u2014 "),cP=a("a"),$6o=o("ConvBertForTokenClassification"),I6o=o(" (ConvBERT model)"),j6o=l(),Y2=a("li"),Pee=a("strong"),N6o=o("deberta"),D6o=o(" \u2014 "),fP=a("a"),q6o=o("DebertaForTokenClassification"),O6o=o(" (DeBERTa model)"),G6o=l(),K2=a("li"),$ee=a("strong"),z6o=o("deberta-v2"),V6o=o(" \u2014 "),mP=a("a"),X6o=o("DebertaV2ForTokenClassification"),W6o=o(" (DeBERTa-v2 model)"),Q6o=l(),Z2=a("li"),Iee=a("strong"),H6o=o("distilbert"),U6o=o(" \u2014 "),gP=a("a"),J6o=o("DistilBertForTokenClassification"),Y6o=o(" (DistilBERT model)"),K6o=l(),ev=a("li"),jee=a("strong"),Z6o=o("electra"),eFo=o(" \u2014 "),hP=a("a"),oFo=o("ElectraForTokenClassification"),rFo=o(" (ELECTRA model)"),tFo=l(),ov=a("li"),Nee=a("strong"),aFo=o("flaubert"),nFo=o(" \u2014 "),uP=a("a"),sFo=o("FlaubertForTokenClassification"),lFo=o(" (FlauBERT model)"),iFo=l(),rv=a("li"),Dee=a("strong"),dFo=o("fnet"),cFo=o(" \u2014 "),pP=a("a"),fFo=o("FNetForTokenClassification"),mFo=o(" (FNet model)"),gFo=l(),tv=a("li"),qee=a("strong"),hFo=o("funnel"),uFo=o(" \u2014 "),_P=a("a"),pFo=o("FunnelForTokenClassification"),_Fo=o(" (Funnel Transformer model)"),vFo=l(),av=a("li"),Oee=a("strong"),bFo=o("gpt2"),TFo=o(" \u2014 "),vP=a("a"),FFo=o("GPT2ForTokenClassification"),CFo=o(" (OpenAI GPT-2 model)"),EFo=l(),nv=a("li"),Gee=a("strong"),MFo=o("ibert"),yFo=o(" \u2014 "),bP=a("a"),wFo=o("IBertForTokenClassification"),AFo=o(" (I-BERT model)"),LFo=l(),sv=a("li"),zee=a("strong"),BFo=o("layoutlm"),kFo=o(" \u2014 "),TP=a("a"),xFo=o("LayoutLMForTokenClassification"),RFo=o(" (LayoutLM model)"),SFo=l(),lv=a("li"),Vee=a("strong"),PFo=o("layoutlmv2"),$Fo=o(" \u2014 "),FP=a("a"),IFo=o("LayoutLMv2ForTokenClassification"),jFo=o(" (LayoutLMv2 model)"),NFo=l(),iv=a("li"),Xee=a("strong"),DFo=o("longformer"),qFo=o(" \u2014 "),CP=a("a"),OFo=o("LongformerForTokenClassification"),GFo=o(" (Longformer model)"),zFo=l(),dv=a("li"),Wee=a("strong"),VFo=o("megatron-bert"),XFo=o(" \u2014 "),EP=a("a"),WFo=o("MegatronBertForTokenClassification"),QFo=o(" (MegatronBert model)"),HFo=l(),cv=a("li"),Qee=a("strong"),UFo=o("mobilebert"),JFo=o(" \u2014 "),MP=a("a"),YFo=o("MobileBertForTokenClassification"),KFo=o(" (MobileBERT model)"),ZFo=l(),fv=a("li"),Hee=a("strong"),eCo=o("mpnet"),oCo=o(" \u2014 "),yP=a("a"),rCo=o("MPNetForTokenClassification"),tCo=o(" (MPNet model)"),aCo=l(),mv=a("li"),Uee=a("strong"),nCo=o("nystromformer"),sCo=o(" \u2014 "),wP=a("a"),lCo=o("NystromformerForTokenClassification"),iCo=o(" (Nystromformer model)"),dCo=l(),gv=a("li"),Jee=a("strong"),cCo=o("qdqbert"),fCo=o(" \u2014 "),AP=a("a"),mCo=o("QDQBertForTokenClassification"),gCo=o(" (QDQBert model)"),hCo=l(),hv=a("li"),Yee=a("strong"),uCo=o("rembert"),pCo=o(" \u2014 "),LP=a("a"),_Co=o("RemBertForTokenClassification"),vCo=o(" (RemBERT model)"),bCo=l(),uv=a("li"),Kee=a("strong"),TCo=o("roberta"),FCo=o(" \u2014 "),BP=a("a"),CCo=o("RobertaForTokenClassification"),ECo=o(" (RoBERTa model)"),MCo=l(),pv=a("li"),Zee=a("strong"),yCo=o("roformer"),wCo=o(" \u2014 "),kP=a("a"),ACo=o("RoFormerForTokenClassification"),LCo=o(" (RoFormer model)"),BCo=l(),_v=a("li"),eoe=a("strong"),kCo=o("squeezebert"),xCo=o(" \u2014 "),xP=a("a"),RCo=o("SqueezeBertForTokenClassification"),SCo=o(" (SqueezeBERT model)"),PCo=l(),vv=a("li"),ooe=a("strong"),$Co=o("xlm"),ICo=o(" \u2014 "),RP=a("a"),jCo=o("XLMForTokenClassification"),NCo=o(" (XLM model)"),DCo=l(),bv=a("li"),roe=a("strong"),qCo=o("xlm-roberta"),OCo=o(" \u2014 "),SP=a("a"),GCo=o("XLMRobertaForTokenClassification"),zCo=o(" (XLM-RoBERTa model)"),VCo=l(),Tv=a("li"),toe=a("strong"),XCo=o("xlnet"),WCo=o(" \u2014 "),PP=a("a"),QCo=o("XLNetForTokenClassification"),HCo=o(" (XLNet model)"),UCo=l(),Fv=a("li"),aoe=a("strong"),JCo=o("yoso"),YCo=o(" \u2014 "),$P=a("a"),KCo=o("YosoForTokenClassification"),ZCo=o(" (YOSO model)"),eEo=l(),Cv=a("p"),oEo=o("The model is set in evaluation mode by default using "),noe=a("code"),rEo=o("model.eval()"),tEo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),soe=a("code"),aEo=o("model.train()"),nEo=l(),loe=a("p"),sEo=o("Examples:"),lEo=l(),f(p3.$$.fragment),Rwe=l(),Gi=a("h2"),Ev=a("a"),ioe=a("span"),f(_3.$$.fragment),iEo=l(),doe=a("span"),dEo=o("AutoModelForQuestionAnswering"),Swe=l(),Ho=a("div"),f(v3.$$.fragment),cEo=l(),zi=a("p"),fEo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),coe=a("code"),mEo=o("from_pretrained()"),gEo=o("class method or the "),foe=a("code"),hEo=o("from_config()"),uEo=o(`class
method.`),pEo=l(),b3=a("p"),_Eo=o("This class cannot be instantiated directly using "),moe=a("code"),vEo=o("__init__()"),bEo=o(" (throws an error)."),TEo=l(),Nr=a("div"),f(T3.$$.fragment),FEo=l(),goe=a("p"),CEo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),EEo=l(),Vi=a("p"),MEo=o(`Note:
Loading a model from its configuration file does `),hoe=a("strong"),yEo=o("not"),wEo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uoe=a("code"),AEo=o("from_pretrained()"),LEo=o("to load the model weights."),BEo=l(),poe=a("p"),kEo=o("Examples:"),xEo=l(),f(F3.$$.fragment),REo=l(),Ne=a("div"),f(C3.$$.fragment),SEo=l(),_oe=a("p"),PEo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),$Eo=l(),Ia=a("p"),IEo=o("The model class to instantiate is selected based on the "),voe=a("code"),jEo=o("model_type"),NEo=o(` property of the config object (either
passed as an argument or loaded from `),boe=a("code"),DEo=o("pretrained_model_name_or_path"),qEo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Toe=a("code"),OEo=o("pretrained_model_name_or_path"),GEo=o(":"),zEo=l(),R=a("ul"),Mv=a("li"),Foe=a("strong"),VEo=o("albert"),XEo=o(" \u2014 "),IP=a("a"),WEo=o("AlbertForQuestionAnswering"),QEo=o(" (ALBERT model)"),HEo=l(),yv=a("li"),Coe=a("strong"),UEo=o("bart"),JEo=o(" \u2014 "),jP=a("a"),YEo=o("BartForQuestionAnswering"),KEo=o(" (BART model)"),ZEo=l(),wv=a("li"),Eoe=a("strong"),eMo=o("bert"),oMo=o(" \u2014 "),NP=a("a"),rMo=o("BertForQuestionAnswering"),tMo=o(" (BERT model)"),aMo=l(),Av=a("li"),Moe=a("strong"),nMo=o("big_bird"),sMo=o(" \u2014 "),DP=a("a"),lMo=o("BigBirdForQuestionAnswering"),iMo=o(" (BigBird model)"),dMo=l(),Lv=a("li"),yoe=a("strong"),cMo=o("bigbird_pegasus"),fMo=o(" \u2014 "),qP=a("a"),mMo=o("BigBirdPegasusForQuestionAnswering"),gMo=o(" (BigBirdPegasus model)"),hMo=l(),Bv=a("li"),woe=a("strong"),uMo=o("camembert"),pMo=o(" \u2014 "),OP=a("a"),_Mo=o("CamembertForQuestionAnswering"),vMo=o(" (CamemBERT model)"),bMo=l(),kv=a("li"),Aoe=a("strong"),TMo=o("canine"),FMo=o(" \u2014 "),GP=a("a"),CMo=o("CanineForQuestionAnswering"),EMo=o(" (Canine model)"),MMo=l(),xv=a("li"),Loe=a("strong"),yMo=o("convbert"),wMo=o(" \u2014 "),zP=a("a"),AMo=o("ConvBertForQuestionAnswering"),LMo=o(" (ConvBERT model)"),BMo=l(),Rv=a("li"),Boe=a("strong"),kMo=o("deberta"),xMo=o(" \u2014 "),VP=a("a"),RMo=o("DebertaForQuestionAnswering"),SMo=o(" (DeBERTa model)"),PMo=l(),Sv=a("li"),koe=a("strong"),$Mo=o("deberta-v2"),IMo=o(" \u2014 "),XP=a("a"),jMo=o("DebertaV2ForQuestionAnswering"),NMo=o(" (DeBERTa-v2 model)"),DMo=l(),Pv=a("li"),xoe=a("strong"),qMo=o("distilbert"),OMo=o(" \u2014 "),WP=a("a"),GMo=o("DistilBertForQuestionAnswering"),zMo=o(" (DistilBERT model)"),VMo=l(),$v=a("li"),Roe=a("strong"),XMo=o("electra"),WMo=o(" \u2014 "),QP=a("a"),QMo=o("ElectraForQuestionAnswering"),HMo=o(" (ELECTRA model)"),UMo=l(),Iv=a("li"),Soe=a("strong"),JMo=o("flaubert"),YMo=o(" \u2014 "),HP=a("a"),KMo=o("FlaubertForQuestionAnsweringSimple"),ZMo=o(" (FlauBERT model)"),e3o=l(),jv=a("li"),Poe=a("strong"),o3o=o("fnet"),r3o=o(" \u2014 "),UP=a("a"),t3o=o("FNetForQuestionAnswering"),a3o=o(" (FNet model)"),n3o=l(),Nv=a("li"),$oe=a("strong"),s3o=o("funnel"),l3o=o(" \u2014 "),JP=a("a"),i3o=o("FunnelForQuestionAnswering"),d3o=o(" (Funnel Transformer model)"),c3o=l(),Dv=a("li"),Ioe=a("strong"),f3o=o("gptj"),m3o=o(" \u2014 "),YP=a("a"),g3o=o("GPTJForQuestionAnswering"),h3o=o(" (GPT-J model)"),u3o=l(),qv=a("li"),joe=a("strong"),p3o=o("ibert"),_3o=o(" \u2014 "),KP=a("a"),v3o=o("IBertForQuestionAnswering"),b3o=o(" (I-BERT model)"),T3o=l(),Ov=a("li"),Noe=a("strong"),F3o=o("layoutlmv2"),C3o=o(" \u2014 "),ZP=a("a"),E3o=o("LayoutLMv2ForQuestionAnswering"),M3o=o(" (LayoutLMv2 model)"),y3o=l(),Gv=a("li"),Doe=a("strong"),w3o=o("led"),A3o=o(" \u2014 "),e$=a("a"),L3o=o("LEDForQuestionAnswering"),B3o=o(" (LED model)"),k3o=l(),zv=a("li"),qoe=a("strong"),x3o=o("longformer"),R3o=o(" \u2014 "),o$=a("a"),S3o=o("LongformerForQuestionAnswering"),P3o=o(" (Longformer model)"),$3o=l(),Vv=a("li"),Ooe=a("strong"),I3o=o("lxmert"),j3o=o(" \u2014 "),r$=a("a"),N3o=o("LxmertForQuestionAnswering"),D3o=o(" (LXMERT model)"),q3o=l(),Xv=a("li"),Goe=a("strong"),O3o=o("mbart"),G3o=o(" \u2014 "),t$=a("a"),z3o=o("MBartForQuestionAnswering"),V3o=o(" (mBART model)"),X3o=l(),Wv=a("li"),zoe=a("strong"),W3o=o("megatron-bert"),Q3o=o(" \u2014 "),a$=a("a"),H3o=o("MegatronBertForQuestionAnswering"),U3o=o(" (MegatronBert model)"),J3o=l(),Qv=a("li"),Voe=a("strong"),Y3o=o("mobilebert"),K3o=o(" \u2014 "),n$=a("a"),Z3o=o("MobileBertForQuestionAnswering"),e5o=o(" (MobileBERT model)"),o5o=l(),Hv=a("li"),Xoe=a("strong"),r5o=o("mpnet"),t5o=o(" \u2014 "),s$=a("a"),a5o=o("MPNetForQuestionAnswering"),n5o=o(" (MPNet model)"),s5o=l(),Uv=a("li"),Woe=a("strong"),l5o=o("nystromformer"),i5o=o(" \u2014 "),l$=a("a"),d5o=o("NystromformerForQuestionAnswering"),c5o=o(" (Nystromformer model)"),f5o=l(),Jv=a("li"),Qoe=a("strong"),m5o=o("qdqbert"),g5o=o(" \u2014 "),i$=a("a"),h5o=o("QDQBertForQuestionAnswering"),u5o=o(" (QDQBert model)"),p5o=l(),Yv=a("li"),Hoe=a("strong"),_5o=o("reformer"),v5o=o(" \u2014 "),d$=a("a"),b5o=o("ReformerForQuestionAnswering"),T5o=o(" (Reformer model)"),F5o=l(),Kv=a("li"),Uoe=a("strong"),C5o=o("rembert"),E5o=o(" \u2014 "),c$=a("a"),M5o=o("RemBertForQuestionAnswering"),y5o=o(" (RemBERT model)"),w5o=l(),Zv=a("li"),Joe=a("strong"),A5o=o("roberta"),L5o=o(" \u2014 "),f$=a("a"),B5o=o("RobertaForQuestionAnswering"),k5o=o(" (RoBERTa model)"),x5o=l(),e1=a("li"),Yoe=a("strong"),R5o=o("roformer"),S5o=o(" \u2014 "),m$=a("a"),P5o=o("RoFormerForQuestionAnswering"),$5o=o(" (RoFormer model)"),I5o=l(),o1=a("li"),Koe=a("strong"),j5o=o("splinter"),N5o=o(" \u2014 "),g$=a("a"),D5o=o("SplinterForQuestionAnswering"),q5o=o(" (Splinter model)"),O5o=l(),r1=a("li"),Zoe=a("strong"),G5o=o("squeezebert"),z5o=o(" \u2014 "),h$=a("a"),V5o=o("SqueezeBertForQuestionAnswering"),X5o=o(" (SqueezeBERT model)"),W5o=l(),t1=a("li"),ere=a("strong"),Q5o=o("xlm"),H5o=o(" \u2014 "),u$=a("a"),U5o=o("XLMForQuestionAnsweringSimple"),J5o=o(" (XLM model)"),Y5o=l(),a1=a("li"),ore=a("strong"),K5o=o("xlm-roberta"),Z5o=o(" \u2014 "),p$=a("a"),eyo=o("XLMRobertaForQuestionAnswering"),oyo=o(" (XLM-RoBERTa model)"),ryo=l(),n1=a("li"),rre=a("strong"),tyo=o("xlnet"),ayo=o(" \u2014 "),_$=a("a"),nyo=o("XLNetForQuestionAnsweringSimple"),syo=o(" (XLNet model)"),lyo=l(),s1=a("li"),tre=a("strong"),iyo=o("yoso"),dyo=o(" \u2014 "),v$=a("a"),cyo=o("YosoForQuestionAnswering"),fyo=o(" (YOSO model)"),myo=l(),l1=a("p"),gyo=o("The model is set in evaluation mode by default using "),are=a("code"),hyo=o("model.eval()"),uyo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nre=a("code"),pyo=o("model.train()"),_yo=l(),sre=a("p"),vyo=o("Examples:"),byo=l(),f(E3.$$.fragment),Pwe=l(),Xi=a("h2"),i1=a("a"),lre=a("span"),f(M3.$$.fragment),Tyo=l(),ire=a("span"),Fyo=o("AutoModelForTableQuestionAnswering"),$we=l(),Uo=a("div"),f(y3.$$.fragment),Cyo=l(),Wi=a("p"),Eyo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),dre=a("code"),Myo=o("from_pretrained()"),yyo=o("class method or the "),cre=a("code"),wyo=o("from_config()"),Ayo=o(`class
method.`),Lyo=l(),w3=a("p"),Byo=o("This class cannot be instantiated directly using "),fre=a("code"),kyo=o("__init__()"),xyo=o(" (throws an error)."),Ryo=l(),Dr=a("div"),f(A3.$$.fragment),Syo=l(),mre=a("p"),Pyo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),$yo=l(),Qi=a("p"),Iyo=o(`Note:
Loading a model from its configuration file does `),gre=a("strong"),jyo=o("not"),Nyo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hre=a("code"),Dyo=o("from_pretrained()"),qyo=o("to load the model weights."),Oyo=l(),ure=a("p"),Gyo=o("Examples:"),zyo=l(),f(L3.$$.fragment),Vyo=l(),De=a("div"),f(B3.$$.fragment),Xyo=l(),pre=a("p"),Wyo=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Qyo=l(),ja=a("p"),Hyo=o("The model class to instantiate is selected based on the "),_re=a("code"),Uyo=o("model_type"),Jyo=o(` property of the config object (either
passed as an argument or loaded from `),vre=a("code"),Yyo=o("pretrained_model_name_or_path"),Kyo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bre=a("code"),Zyo=o("pretrained_model_name_or_path"),ewo=o(":"),owo=l(),Tre=a("ul"),d1=a("li"),Fre=a("strong"),rwo=o("tapas"),two=o(" \u2014 "),b$=a("a"),awo=o("TapasForQuestionAnswering"),nwo=o(" (TAPAS model)"),swo=l(),c1=a("p"),lwo=o("The model is set in evaluation mode by default using "),Cre=a("code"),iwo=o("model.eval()"),dwo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ere=a("code"),cwo=o("model.train()"),fwo=l(),Mre=a("p"),mwo=o("Examples:"),gwo=l(),f(k3.$$.fragment),Iwe=l(),Hi=a("h2"),f1=a("a"),yre=a("span"),f(x3.$$.fragment),hwo=l(),wre=a("span"),uwo=o("AutoModelForImageClassification"),jwe=l(),Jo=a("div"),f(R3.$$.fragment),pwo=l(),Ui=a("p"),_wo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Are=a("code"),vwo=o("from_pretrained()"),bwo=o("class method or the "),Lre=a("code"),Two=o("from_config()"),Fwo=o(`class
method.`),Cwo=l(),S3=a("p"),Ewo=o("This class cannot be instantiated directly using "),Bre=a("code"),Mwo=o("__init__()"),ywo=o(" (throws an error)."),wwo=l(),qr=a("div"),f(P3.$$.fragment),Awo=l(),kre=a("p"),Lwo=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Bwo=l(),Ji=a("p"),kwo=o(`Note:
Loading a model from its configuration file does `),xre=a("strong"),xwo=o("not"),Rwo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rre=a("code"),Swo=o("from_pretrained()"),Pwo=o("to load the model weights."),$wo=l(),Sre=a("p"),Iwo=o("Examples:"),jwo=l(),f($3.$$.fragment),Nwo=l(),qe=a("div"),f(I3.$$.fragment),Dwo=l(),Pre=a("p"),qwo=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Owo=l(),Na=a("p"),Gwo=o("The model class to instantiate is selected based on the "),$re=a("code"),zwo=o("model_type"),Vwo=o(` property of the config object (either
passed as an argument or loaded from `),Ire=a("code"),Xwo=o("pretrained_model_name_or_path"),Wwo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jre=a("code"),Qwo=o("pretrained_model_name_or_path"),Hwo=o(":"),Uwo=l(),eo=a("ul"),m1=a("li"),Nre=a("strong"),Jwo=o("beit"),Ywo=o(" \u2014 "),T$=a("a"),Kwo=o("BeitForImageClassification"),Zwo=o(" (BEiT model)"),eAo=l(),us=a("li"),Dre=a("strong"),oAo=o("deit"),rAo=o(" \u2014 "),F$=a("a"),tAo=o("DeiTForImageClassification"),aAo=o(" or "),C$=a("a"),nAo=o("DeiTForImageClassificationWithTeacher"),sAo=o(" (DeiT model)"),lAo=l(),g1=a("li"),qre=a("strong"),iAo=o("imagegpt"),dAo=o(" \u2014 "),E$=a("a"),cAo=o("ImageGPTForImageClassification"),fAo=o(" (ImageGPT model)"),mAo=l(),Jt=a("li"),Ore=a("strong"),gAo=o("perceiver"),hAo=o(" \u2014 "),M$=a("a"),uAo=o("PerceiverForImageClassificationLearned"),pAo=o(" or "),y$=a("a"),_Ao=o("PerceiverForImageClassificationFourier"),vAo=o(" or "),w$=a("a"),bAo=o("PerceiverForImageClassificationConvProcessing"),TAo=o(" (Perceiver model)"),FAo=l(),h1=a("li"),Gre=a("strong"),CAo=o("segformer"),EAo=o(" \u2014 "),A$=a("a"),MAo=o("SegformerForImageClassification"),yAo=o(" (SegFormer model)"),wAo=l(),u1=a("li"),zre=a("strong"),AAo=o("swin"),LAo=o(" \u2014 "),L$=a("a"),BAo=o("SwinForImageClassification"),kAo=o(" (Swin model)"),xAo=l(),p1=a("li"),Vre=a("strong"),RAo=o("vit"),SAo=o(" \u2014 "),B$=a("a"),PAo=o("ViTForImageClassification"),$Ao=o(" (ViT model)"),IAo=l(),_1=a("p"),jAo=o("The model is set in evaluation mode by default using "),Xre=a("code"),NAo=o("model.eval()"),DAo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Wre=a("code"),qAo=o("model.train()"),OAo=l(),Qre=a("p"),GAo=o("Examples:"),zAo=l(),f(j3.$$.fragment),Nwe=l(),Yi=a("h2"),v1=a("a"),Hre=a("span"),f(N3.$$.fragment),VAo=l(),Ure=a("span"),XAo=o("AutoModelForVision2Seq"),Dwe=l(),Yo=a("div"),f(D3.$$.fragment),WAo=l(),Ki=a("p"),QAo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Jre=a("code"),HAo=o("from_pretrained()"),UAo=o("class method or the "),Yre=a("code"),JAo=o("from_config()"),YAo=o(`class
method.`),KAo=l(),q3=a("p"),ZAo=o("This class cannot be instantiated directly using "),Kre=a("code"),e0o=o("__init__()"),o0o=o(" (throws an error)."),r0o=l(),Or=a("div"),f(O3.$$.fragment),t0o=l(),Zre=a("p"),a0o=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),n0o=l(),Zi=a("p"),s0o=o(`Note:
Loading a model from its configuration file does `),ete=a("strong"),l0o=o("not"),i0o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ote=a("code"),d0o=o("from_pretrained()"),c0o=o("to load the model weights."),f0o=l(),rte=a("p"),m0o=o("Examples:"),g0o=l(),f(G3.$$.fragment),h0o=l(),Oe=a("div"),f(z3.$$.fragment),u0o=l(),tte=a("p"),p0o=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),_0o=l(),Da=a("p"),v0o=o("The model class to instantiate is selected based on the "),ate=a("code"),b0o=o("model_type"),T0o=o(` property of the config object (either
passed as an argument or loaded from `),nte=a("code"),F0o=o("pretrained_model_name_or_path"),C0o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ste=a("code"),E0o=o("pretrained_model_name_or_path"),M0o=o(":"),y0o=l(),lte=a("ul"),b1=a("li"),ite=a("strong"),w0o=o("vision-encoder-decoder"),A0o=o(" \u2014 "),k$=a("a"),L0o=o("VisionEncoderDecoderModel"),B0o=o(" (Vision Encoder decoder model)"),k0o=l(),T1=a("p"),x0o=o("The model is set in evaluation mode by default using "),dte=a("code"),R0o=o("model.eval()"),S0o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cte=a("code"),P0o=o("model.train()"),$0o=l(),fte=a("p"),I0o=o("Examples:"),j0o=l(),f(V3.$$.fragment),qwe=l(),ed=a("h2"),F1=a("a"),mte=a("span"),f(X3.$$.fragment),N0o=l(),gte=a("span"),D0o=o("AutoModelForAudioClassification"),Owe=l(),Ko=a("div"),f(W3.$$.fragment),q0o=l(),od=a("p"),O0o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),hte=a("code"),G0o=o("from_pretrained()"),z0o=o("class method or the "),ute=a("code"),V0o=o("from_config()"),X0o=o(`class
method.`),W0o=l(),Q3=a("p"),Q0o=o("This class cannot be instantiated directly using "),pte=a("code"),H0o=o("__init__()"),U0o=o(" (throws an error)."),J0o=l(),Gr=a("div"),f(H3.$$.fragment),Y0o=l(),_te=a("p"),K0o=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Z0o=l(),rd=a("p"),e7o=o(`Note:
Loading a model from its configuration file does `),vte=a("strong"),o7o=o("not"),r7o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bte=a("code"),t7o=o("from_pretrained()"),a7o=o("to load the model weights."),n7o=l(),Tte=a("p"),s7o=o("Examples:"),l7o=l(),f(U3.$$.fragment),i7o=l(),Ge=a("div"),f(J3.$$.fragment),d7o=l(),Fte=a("p"),c7o=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),f7o=l(),qa=a("p"),m7o=o("The model class to instantiate is selected based on the "),Cte=a("code"),g7o=o("model_type"),h7o=o(` property of the config object (either
passed as an argument or loaded from `),Ete=a("code"),u7o=o("pretrained_model_name_or_path"),p7o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mte=a("code"),_7o=o("pretrained_model_name_or_path"),v7o=o(":"),b7o=l(),oo=a("ul"),C1=a("li"),yte=a("strong"),T7o=o("hubert"),F7o=o(" \u2014 "),x$=a("a"),C7o=o("HubertForSequenceClassification"),E7o=o(" (Hubert model)"),M7o=l(),E1=a("li"),wte=a("strong"),y7o=o("sew"),w7o=o(" \u2014 "),R$=a("a"),A7o=o("SEWForSequenceClassification"),L7o=o(" (SEW model)"),B7o=l(),M1=a("li"),Ate=a("strong"),k7o=o("sew-d"),x7o=o(" \u2014 "),S$=a("a"),R7o=o("SEWDForSequenceClassification"),S7o=o(" (SEW-D model)"),P7o=l(),y1=a("li"),Lte=a("strong"),$7o=o("unispeech"),I7o=o(" \u2014 "),P$=a("a"),j7o=o("UniSpeechForSequenceClassification"),N7o=o(" (UniSpeech model)"),D7o=l(),w1=a("li"),Bte=a("strong"),q7o=o("unispeech-sat"),O7o=o(" \u2014 "),$$=a("a"),G7o=o("UniSpeechSatForSequenceClassification"),z7o=o(" (UniSpeechSat model)"),V7o=l(),A1=a("li"),kte=a("strong"),X7o=o("wav2vec2"),W7o=o(" \u2014 "),I$=a("a"),Q7o=o("Wav2Vec2ForSequenceClassification"),H7o=o(" (Wav2Vec2 model)"),U7o=l(),L1=a("li"),xte=a("strong"),J7o=o("wavlm"),Y7o=o(" \u2014 "),j$=a("a"),K7o=o("WavLMForSequenceClassification"),Z7o=o(" (WavLM model)"),eLo=l(),B1=a("p"),oLo=o("The model is set in evaluation mode by default using "),Rte=a("code"),rLo=o("model.eval()"),tLo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ste=a("code"),aLo=o("model.train()"),nLo=l(),Pte=a("p"),sLo=o("Examples:"),lLo=l(),f(Y3.$$.fragment),Gwe=l(),td=a("h2"),k1=a("a"),$te=a("span"),f(K3.$$.fragment),iLo=l(),Ite=a("span"),dLo=o("AutoModelForAudioFrameClassification"),zwe=l(),Zo=a("div"),f(Z3.$$.fragment),cLo=l(),ad=a("p"),fLo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),jte=a("code"),mLo=o("from_pretrained()"),gLo=o("class method or the "),Nte=a("code"),hLo=o("from_config()"),uLo=o(`class
method.`),pLo=l(),e5=a("p"),_Lo=o("This class cannot be instantiated directly using "),Dte=a("code"),vLo=o("__init__()"),bLo=o(" (throws an error)."),TLo=l(),zr=a("div"),f(o5.$$.fragment),FLo=l(),qte=a("p"),CLo=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),ELo=l(),nd=a("p"),MLo=o(`Note:
Loading a model from its configuration file does `),Ote=a("strong"),yLo=o("not"),wLo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gte=a("code"),ALo=o("from_pretrained()"),LLo=o("to load the model weights."),BLo=l(),zte=a("p"),kLo=o("Examples:"),xLo=l(),f(r5.$$.fragment),RLo=l(),ze=a("div"),f(t5.$$.fragment),SLo=l(),Vte=a("p"),PLo=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),$Lo=l(),Oa=a("p"),ILo=o("The model class to instantiate is selected based on the "),Xte=a("code"),jLo=o("model_type"),NLo=o(` property of the config object (either
passed as an argument or loaded from `),Wte=a("code"),DLo=o("pretrained_model_name_or_path"),qLo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qte=a("code"),OLo=o("pretrained_model_name_or_path"),GLo=o(":"),zLo=l(),sd=a("ul"),x1=a("li"),Hte=a("strong"),VLo=o("unispeech-sat"),XLo=o(" \u2014 "),N$=a("a"),WLo=o("UniSpeechSatForAudioFrameClassification"),QLo=o(" (UniSpeechSat model)"),HLo=l(),R1=a("li"),Ute=a("strong"),ULo=o("wav2vec2"),JLo=o(" \u2014 "),D$=a("a"),YLo=o("Wav2Vec2ForAudioFrameClassification"),KLo=o(" (Wav2Vec2 model)"),ZLo=l(),S1=a("li"),Jte=a("strong"),e8o=o("wavlm"),o8o=o(" \u2014 "),q$=a("a"),r8o=o("WavLMForAudioFrameClassification"),t8o=o(" (WavLM model)"),a8o=l(),P1=a("p"),n8o=o("The model is set in evaluation mode by default using "),Yte=a("code"),s8o=o("model.eval()"),l8o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Kte=a("code"),i8o=o("model.train()"),d8o=l(),Zte=a("p"),c8o=o("Examples:"),f8o=l(),f(a5.$$.fragment),Vwe=l(),ld=a("h2"),$1=a("a"),eae=a("span"),f(n5.$$.fragment),m8o=l(),oae=a("span"),g8o=o("AutoModelForCTC"),Xwe=l(),er=a("div"),f(s5.$$.fragment),h8o=l(),id=a("p"),u8o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),rae=a("code"),p8o=o("from_pretrained()"),_8o=o("class method or the "),tae=a("code"),v8o=o("from_config()"),b8o=o(`class
method.`),T8o=l(),l5=a("p"),F8o=o("This class cannot be instantiated directly using "),aae=a("code"),C8o=o("__init__()"),E8o=o(" (throws an error)."),M8o=l(),Vr=a("div"),f(i5.$$.fragment),y8o=l(),nae=a("p"),w8o=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),A8o=l(),dd=a("p"),L8o=o(`Note:
Loading a model from its configuration file does `),sae=a("strong"),B8o=o("not"),k8o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lae=a("code"),x8o=o("from_pretrained()"),R8o=o("to load the model weights."),S8o=l(),iae=a("p"),P8o=o("Examples:"),$8o=l(),f(d5.$$.fragment),I8o=l(),Ve=a("div"),f(c5.$$.fragment),j8o=l(),dae=a("p"),N8o=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),D8o=l(),Ga=a("p"),q8o=o("The model class to instantiate is selected based on the "),cae=a("code"),O8o=o("model_type"),G8o=o(` property of the config object (either
passed as an argument or loaded from `),fae=a("code"),z8o=o("pretrained_model_name_or_path"),V8o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mae=a("code"),X8o=o("pretrained_model_name_or_path"),W8o=o(":"),Q8o=l(),ro=a("ul"),I1=a("li"),gae=a("strong"),H8o=o("hubert"),U8o=o(" \u2014 "),O$=a("a"),J8o=o("HubertForCTC"),Y8o=o(" (Hubert model)"),K8o=l(),j1=a("li"),hae=a("strong"),Z8o=o("sew"),eBo=o(" \u2014 "),G$=a("a"),oBo=o("SEWForCTC"),rBo=o(" (SEW model)"),tBo=l(),N1=a("li"),uae=a("strong"),aBo=o("sew-d"),nBo=o(" \u2014 "),z$=a("a"),sBo=o("SEWDForCTC"),lBo=o(" (SEW-D model)"),iBo=l(),D1=a("li"),pae=a("strong"),dBo=o("unispeech"),cBo=o(" \u2014 "),V$=a("a"),fBo=o("UniSpeechForCTC"),mBo=o(" (UniSpeech model)"),gBo=l(),q1=a("li"),_ae=a("strong"),hBo=o("unispeech-sat"),uBo=o(" \u2014 "),X$=a("a"),pBo=o("UniSpeechSatForCTC"),_Bo=o(" (UniSpeechSat model)"),vBo=l(),O1=a("li"),vae=a("strong"),bBo=o("wav2vec2"),TBo=o(" \u2014 "),W$=a("a"),FBo=o("Wav2Vec2ForCTC"),CBo=o(" (Wav2Vec2 model)"),EBo=l(),G1=a("li"),bae=a("strong"),MBo=o("wavlm"),yBo=o(" \u2014 "),Q$=a("a"),wBo=o("WavLMForCTC"),ABo=o(" (WavLM model)"),LBo=l(),z1=a("p"),BBo=o("The model is set in evaluation mode by default using "),Tae=a("code"),kBo=o("model.eval()"),xBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fae=a("code"),RBo=o("model.train()"),SBo=l(),Cae=a("p"),PBo=o("Examples:"),$Bo=l(),f(f5.$$.fragment),Wwe=l(),cd=a("h2"),V1=a("a"),Eae=a("span"),f(m5.$$.fragment),IBo=l(),Mae=a("span"),jBo=o("AutoModelForSpeechSeq2Seq"),Qwe=l(),or=a("div"),f(g5.$$.fragment),NBo=l(),fd=a("p"),DBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeing head) when created
with the `),yae=a("code"),qBo=o("from_pretrained()"),OBo=o("class method or the "),wae=a("code"),GBo=o("from_config()"),zBo=o(`class
method.`),VBo=l(),h5=a("p"),XBo=o("This class cannot be instantiated directly using "),Aae=a("code"),WBo=o("__init__()"),QBo=o(" (throws an error)."),HBo=l(),Xr=a("div"),f(u5.$$.fragment),UBo=l(),Lae=a("p"),JBo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeing head) from a configuration."),YBo=l(),md=a("p"),KBo=o(`Note:
Loading a model from its configuration file does `),Bae=a("strong"),ZBo=o("not"),e9o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kae=a("code"),o9o=o("from_pretrained()"),r9o=o("to load the model weights."),t9o=l(),xae=a("p"),a9o=o("Examples:"),n9o=l(),f(p5.$$.fragment),s9o=l(),Xe=a("div"),f(_5.$$.fragment),l9o=l(),Rae=a("p"),i9o=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeing head) from a pretrained model."),d9o=l(),za=a("p"),c9o=o("The model class to instantiate is selected based on the "),Sae=a("code"),f9o=o("model_type"),m9o=o(` property of the config object (either
passed as an argument or loaded from `),Pae=a("code"),g9o=o("pretrained_model_name_or_path"),h9o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ae=a("code"),u9o=o("pretrained_model_name_or_path"),p9o=o(":"),_9o=l(),v5=a("ul"),X1=a("li"),Iae=a("strong"),v9o=o("speech-encoder-decoder"),b9o=o(" \u2014 "),H$=a("a"),T9o=o("SpeechEncoderDecoderModel"),F9o=o(" (Speech Encoder decoder model)"),C9o=l(),W1=a("li"),jae=a("strong"),E9o=o("speech_to_text"),M9o=o(" \u2014 "),U$=a("a"),y9o=o("Speech2TextForConditionalGeneration"),w9o=o(" (Speech2Text model)"),A9o=l(),Q1=a("p"),L9o=o("The model is set in evaluation mode by default using "),Nae=a("code"),B9o=o("model.eval()"),k9o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dae=a("code"),x9o=o("model.train()"),R9o=l(),qae=a("p"),S9o=o("Examples:"),P9o=l(),f(b5.$$.fragment),Hwe=l(),gd=a("h2"),H1=a("a"),Oae=a("span"),f(T5.$$.fragment),$9o=l(),Gae=a("span"),I9o=o("AutoModelForAudioXVector"),Uwe=l(),rr=a("div"),f(F5.$$.fragment),j9o=l(),hd=a("p"),N9o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),zae=a("code"),D9o=o("from_pretrained()"),q9o=o("class method or the "),Vae=a("code"),O9o=o("from_config()"),G9o=o(`class
method.`),z9o=l(),C5=a("p"),V9o=o("This class cannot be instantiated directly using "),Xae=a("code"),X9o=o("__init__()"),W9o=o(" (throws an error)."),Q9o=l(),Wr=a("div"),f(E5.$$.fragment),H9o=l(),Wae=a("p"),U9o=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),J9o=l(),ud=a("p"),Y9o=o(`Note:
Loading a model from its configuration file does `),Qae=a("strong"),K9o=o("not"),Z9o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Hae=a("code"),eko=o("from_pretrained()"),oko=o("to load the model weights."),rko=l(),Uae=a("p"),tko=o("Examples:"),ako=l(),f(M5.$$.fragment),nko=l(),We=a("div"),f(y5.$$.fragment),sko=l(),Jae=a("p"),lko=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),iko=l(),Va=a("p"),dko=o("The model class to instantiate is selected based on the "),Yae=a("code"),cko=o("model_type"),fko=o(` property of the config object (either
passed as an argument or loaded from `),Kae=a("code"),mko=o("pretrained_model_name_or_path"),gko=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zae=a("code"),hko=o("pretrained_model_name_or_path"),uko=o(":"),pko=l(),pd=a("ul"),U1=a("li"),ene=a("strong"),_ko=o("unispeech-sat"),vko=o(" \u2014 "),J$=a("a"),bko=o("UniSpeechSatForXVector"),Tko=o(" (UniSpeechSat model)"),Fko=l(),J1=a("li"),one=a("strong"),Cko=o("wav2vec2"),Eko=o(" \u2014 "),Y$=a("a"),Mko=o("Wav2Vec2ForXVector"),yko=o(" (Wav2Vec2 model)"),wko=l(),Y1=a("li"),rne=a("strong"),Ako=o("wavlm"),Lko=o(" \u2014 "),K$=a("a"),Bko=o("WavLMForXVector"),kko=o(" (WavLM model)"),xko=l(),K1=a("p"),Rko=o("The model is set in evaluation mode by default using "),tne=a("code"),Sko=o("model.eval()"),Pko=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ane=a("code"),$ko=o("model.train()"),Iko=l(),nne=a("p"),jko=o("Examples:"),Nko=l(),f(w5.$$.fragment),Jwe=l(),_d=a("h2"),Z1=a("a"),sne=a("span"),f(A5.$$.fragment),Dko=l(),lne=a("span"),qko=o("AutoModelForObjectDetection"),Ywe=l(),tr=a("div"),f(L5.$$.fragment),Oko=l(),vd=a("p"),Gko=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),ine=a("code"),zko=o("from_pretrained()"),Vko=o("class method or the "),dne=a("code"),Xko=o("from_config()"),Wko=o(`class
method.`),Qko=l(),B5=a("p"),Hko=o("This class cannot be instantiated directly using "),cne=a("code"),Uko=o("__init__()"),Jko=o(" (throws an error)."),Yko=l(),Qr=a("div"),f(k5.$$.fragment),Kko=l(),fne=a("p"),Zko=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),exo=l(),bd=a("p"),oxo=o(`Note:
Loading a model from its configuration file does `),mne=a("strong"),rxo=o("not"),txo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gne=a("code"),axo=o("from_pretrained()"),nxo=o("to load the model weights."),sxo=l(),hne=a("p"),lxo=o("Examples:"),ixo=l(),f(x5.$$.fragment),dxo=l(),Qe=a("div"),f(R5.$$.fragment),cxo=l(),une=a("p"),fxo=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),mxo=l(),Xa=a("p"),gxo=o("The model class to instantiate is selected based on the "),pne=a("code"),hxo=o("model_type"),uxo=o(` property of the config object (either
passed as an argument or loaded from `),_ne=a("code"),pxo=o("pretrained_model_name_or_path"),_xo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vne=a("code"),vxo=o("pretrained_model_name_or_path"),bxo=o(":"),Txo=l(),bne=a("ul"),e4=a("li"),Tne=a("strong"),Fxo=o("detr"),Cxo=o(" \u2014 "),Z$=a("a"),Exo=o("DetrForObjectDetection"),Mxo=o(" (DETR model)"),yxo=l(),o4=a("p"),wxo=o("The model is set in evaluation mode by default using "),Fne=a("code"),Axo=o("model.eval()"),Lxo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cne=a("code"),Bxo=o("model.train()"),kxo=l(),Ene=a("p"),xxo=o("Examples:"),Rxo=l(),f(S5.$$.fragment),Kwe=l(),Td=a("h2"),r4=a("a"),Mne=a("span"),f(P5.$$.fragment),Sxo=l(),yne=a("span"),Pxo=o("AutoModelForImageSegmentation"),Zwe=l(),ar=a("div"),f($5.$$.fragment),$xo=l(),Fd=a("p"),Ixo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),wne=a("code"),jxo=o("from_pretrained()"),Nxo=o("class method or the "),Ane=a("code"),Dxo=o("from_config()"),qxo=o(`class
method.`),Oxo=l(),I5=a("p"),Gxo=o("This class cannot be instantiated directly using "),Lne=a("code"),zxo=o("__init__()"),Vxo=o(" (throws an error)."),Xxo=l(),Hr=a("div"),f(j5.$$.fragment),Wxo=l(),Bne=a("p"),Qxo=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Hxo=l(),Cd=a("p"),Uxo=o(`Note:
Loading a model from its configuration file does `),kne=a("strong"),Jxo=o("not"),Yxo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xne=a("code"),Kxo=o("from_pretrained()"),Zxo=o("to load the model weights."),eRo=l(),Rne=a("p"),oRo=o("Examples:"),rRo=l(),f(N5.$$.fragment),tRo=l(),He=a("div"),f(D5.$$.fragment),aRo=l(),Sne=a("p"),nRo=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),sRo=l(),Wa=a("p"),lRo=o("The model class to instantiate is selected based on the "),Pne=a("code"),iRo=o("model_type"),dRo=o(` property of the config object (either
passed as an argument or loaded from `),$ne=a("code"),cRo=o("pretrained_model_name_or_path"),fRo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ine=a("code"),mRo=o("pretrained_model_name_or_path"),gRo=o(":"),hRo=l(),jne=a("ul"),t4=a("li"),Nne=a("strong"),uRo=o("detr"),pRo=o(" \u2014 "),eI=a("a"),_Ro=o("DetrForSegmentation"),vRo=o(" (DETR model)"),bRo=l(),a4=a("p"),TRo=o("The model is set in evaluation mode by default using "),Dne=a("code"),FRo=o("model.eval()"),CRo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qne=a("code"),ERo=o("model.train()"),MRo=l(),One=a("p"),yRo=o("Examples:"),wRo=l(),f(q5.$$.fragment),eAe=l(),Ed=a("h2"),n4=a("a"),Gne=a("span"),f(O5.$$.fragment),ARo=l(),zne=a("span"),LRo=o("TFAutoModel"),oAe=l(),nr=a("div"),f(G5.$$.fragment),BRo=l(),Md=a("p"),kRo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Vne=a("code"),xRo=o("from_pretrained()"),RRo=o("class method or the "),Xne=a("code"),SRo=o("from_config()"),PRo=o(`class
method.`),$Ro=l(),z5=a("p"),IRo=o("This class cannot be instantiated directly using "),Wne=a("code"),jRo=o("__init__()"),NRo=o(" (throws an error)."),DRo=l(),Ur=a("div"),f(V5.$$.fragment),qRo=l(),Qne=a("p"),ORo=o("Instantiates one of the base model classes of the library from a configuration."),GRo=l(),yd=a("p"),zRo=o(`Note:
Loading a model from its configuration file does `),Hne=a("strong"),VRo=o("not"),XRo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Une=a("code"),WRo=o("from_pretrained()"),QRo=o("to load the model weights."),HRo=l(),Jne=a("p"),URo=o("Examples:"),JRo=l(),f(X5.$$.fragment),YRo=l(),co=a("div"),f(W5.$$.fragment),KRo=l(),Yne=a("p"),ZRo=o("Instantiate one of the base model classes of the library from a pretrained model."),eSo=l(),Qa=a("p"),oSo=o("The model class to instantiate is selected based on the "),Kne=a("code"),rSo=o("model_type"),tSo=o(` property of the config object (either
passed as an argument or loaded from `),Zne=a("code"),aSo=o("pretrained_model_name_or_path"),nSo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ese=a("code"),sSo=o("pretrained_model_name_or_path"),lSo=o(":"),iSo=l(),B=a("ul"),s4=a("li"),ose=a("strong"),dSo=o("albert"),cSo=o(" \u2014 "),oI=a("a"),fSo=o("TFAlbertModel"),mSo=o(" (ALBERT model)"),gSo=l(),l4=a("li"),rse=a("strong"),hSo=o("bart"),uSo=o(" \u2014 "),rI=a("a"),pSo=o("TFBartModel"),_So=o(" (BART model)"),vSo=l(),i4=a("li"),tse=a("strong"),bSo=o("bert"),TSo=o(" \u2014 "),tI=a("a"),FSo=o("TFBertModel"),CSo=o(" (BERT model)"),ESo=l(),d4=a("li"),ase=a("strong"),MSo=o("blenderbot"),ySo=o(" \u2014 "),aI=a("a"),wSo=o("TFBlenderbotModel"),ASo=o(" (Blenderbot model)"),LSo=l(),c4=a("li"),nse=a("strong"),BSo=o("blenderbot-small"),kSo=o(" \u2014 "),nI=a("a"),xSo=o("TFBlenderbotSmallModel"),RSo=o(" (BlenderbotSmall model)"),SSo=l(),f4=a("li"),sse=a("strong"),PSo=o("camembert"),$So=o(" \u2014 "),sI=a("a"),ISo=o("TFCamembertModel"),jSo=o(" (CamemBERT model)"),NSo=l(),m4=a("li"),lse=a("strong"),DSo=o("clip"),qSo=o(" \u2014 "),lI=a("a"),OSo=o("TFCLIPModel"),GSo=o(" (CLIP model)"),zSo=l(),g4=a("li"),ise=a("strong"),VSo=o("convbert"),XSo=o(" \u2014 "),iI=a("a"),WSo=o("TFConvBertModel"),QSo=o(" (ConvBERT model)"),HSo=l(),h4=a("li"),dse=a("strong"),USo=o("ctrl"),JSo=o(" \u2014 "),dI=a("a"),YSo=o("TFCTRLModel"),KSo=o(" (CTRL model)"),ZSo=l(),u4=a("li"),cse=a("strong"),ePo=o("deberta"),oPo=o(" \u2014 "),cI=a("a"),rPo=o("TFDebertaModel"),tPo=o(" (DeBERTa model)"),aPo=l(),p4=a("li"),fse=a("strong"),nPo=o("deberta-v2"),sPo=o(" \u2014 "),fI=a("a"),lPo=o("TFDebertaV2Model"),iPo=o(" (DeBERTa-v2 model)"),dPo=l(),_4=a("li"),mse=a("strong"),cPo=o("distilbert"),fPo=o(" \u2014 "),mI=a("a"),mPo=o("TFDistilBertModel"),gPo=o(" (DistilBERT model)"),hPo=l(),v4=a("li"),gse=a("strong"),uPo=o("dpr"),pPo=o(" \u2014 "),gI=a("a"),_Po=o("TFDPRQuestionEncoder"),vPo=o(" (DPR model)"),bPo=l(),b4=a("li"),hse=a("strong"),TPo=o("electra"),FPo=o(" \u2014 "),hI=a("a"),CPo=o("TFElectraModel"),EPo=o(" (ELECTRA model)"),MPo=l(),T4=a("li"),use=a("strong"),yPo=o("flaubert"),wPo=o(" \u2014 "),uI=a("a"),APo=o("TFFlaubertModel"),LPo=o(" (FlauBERT model)"),BPo=l(),ps=a("li"),pse=a("strong"),kPo=o("funnel"),xPo=o(" \u2014 "),pI=a("a"),RPo=o("TFFunnelModel"),SPo=o(" or "),_I=a("a"),PPo=o("TFFunnelBaseModel"),$Po=o(" (Funnel Transformer model)"),IPo=l(),F4=a("li"),_se=a("strong"),jPo=o("gpt2"),NPo=o(" \u2014 "),vI=a("a"),DPo=o("TFGPT2Model"),qPo=o(" (OpenAI GPT-2 model)"),OPo=l(),C4=a("li"),vse=a("strong"),GPo=o("hubert"),zPo=o(" \u2014 "),bI=a("a"),VPo=o("TFHubertModel"),XPo=o(" (Hubert model)"),WPo=l(),E4=a("li"),bse=a("strong"),QPo=o("layoutlm"),HPo=o(" \u2014 "),TI=a("a"),UPo=o("TFLayoutLMModel"),JPo=o(" (LayoutLM model)"),YPo=l(),M4=a("li"),Tse=a("strong"),KPo=o("led"),ZPo=o(" \u2014 "),FI=a("a"),e$o=o("TFLEDModel"),o$o=o(" (LED model)"),r$o=l(),y4=a("li"),Fse=a("strong"),t$o=o("longformer"),a$o=o(" \u2014 "),CI=a("a"),n$o=o("TFLongformerModel"),s$o=o(" (Longformer model)"),l$o=l(),w4=a("li"),Cse=a("strong"),i$o=o("lxmert"),d$o=o(" \u2014 "),EI=a("a"),c$o=o("TFLxmertModel"),f$o=o(" (LXMERT model)"),m$o=l(),A4=a("li"),Ese=a("strong"),g$o=o("marian"),h$o=o(" \u2014 "),MI=a("a"),u$o=o("TFMarianModel"),p$o=o(" (Marian model)"),_$o=l(),L4=a("li"),Mse=a("strong"),v$o=o("mbart"),b$o=o(" \u2014 "),yI=a("a"),T$o=o("TFMBartModel"),F$o=o(" (mBART model)"),C$o=l(),B4=a("li"),yse=a("strong"),E$o=o("mobilebert"),M$o=o(" \u2014 "),wI=a("a"),y$o=o("TFMobileBertModel"),w$o=o(" (MobileBERT model)"),A$o=l(),k4=a("li"),wse=a("strong"),L$o=o("mpnet"),B$o=o(" \u2014 "),AI=a("a"),k$o=o("TFMPNetModel"),x$o=o(" (MPNet model)"),R$o=l(),x4=a("li"),Ase=a("strong"),S$o=o("mt5"),P$o=o(" \u2014 "),LI=a("a"),$$o=o("TFMT5Model"),I$o=o(" (mT5 model)"),j$o=l(),R4=a("li"),Lse=a("strong"),N$o=o("openai-gpt"),D$o=o(" \u2014 "),BI=a("a"),q$o=o("TFOpenAIGPTModel"),O$o=o(" (OpenAI GPT model)"),G$o=l(),S4=a("li"),Bse=a("strong"),z$o=o("pegasus"),V$o=o(" \u2014 "),kI=a("a"),X$o=o("TFPegasusModel"),W$o=o(" (Pegasus model)"),Q$o=l(),P4=a("li"),kse=a("strong"),H$o=o("rembert"),U$o=o(" \u2014 "),xI=a("a"),J$o=o("TFRemBertModel"),Y$o=o(" (RemBERT model)"),K$o=l(),$4=a("li"),xse=a("strong"),Z$o=o("roberta"),eIo=o(" \u2014 "),RI=a("a"),oIo=o("TFRobertaModel"),rIo=o(" (RoBERTa model)"),tIo=l(),I4=a("li"),Rse=a("strong"),aIo=o("roformer"),nIo=o(" \u2014 "),SI=a("a"),sIo=o("TFRoFormerModel"),lIo=o(" (RoFormer model)"),iIo=l(),j4=a("li"),Sse=a("strong"),dIo=o("t5"),cIo=o(" \u2014 "),PI=a("a"),fIo=o("TFT5Model"),mIo=o(" (T5 model)"),gIo=l(),N4=a("li"),Pse=a("strong"),hIo=o("tapas"),uIo=o(" \u2014 "),$I=a("a"),pIo=o("TFTapasModel"),_Io=o(" (TAPAS model)"),vIo=l(),D4=a("li"),$se=a("strong"),bIo=o("transfo-xl"),TIo=o(" \u2014 "),II=a("a"),FIo=o("TFTransfoXLModel"),CIo=o(" (Transformer-XL model)"),EIo=l(),q4=a("li"),Ise=a("strong"),MIo=o("vit"),yIo=o(" \u2014 "),jI=a("a"),wIo=o("TFViTModel"),AIo=o(" (ViT model)"),LIo=l(),O4=a("li"),jse=a("strong"),BIo=o("wav2vec2"),kIo=o(" \u2014 "),NI=a("a"),xIo=o("TFWav2Vec2Model"),RIo=o(" (Wav2Vec2 model)"),SIo=l(),G4=a("li"),Nse=a("strong"),PIo=o("xlm"),$Io=o(" \u2014 "),DI=a("a"),IIo=o("TFXLMModel"),jIo=o(" (XLM model)"),NIo=l(),z4=a("li"),Dse=a("strong"),DIo=o("xlm-roberta"),qIo=o(" \u2014 "),qI=a("a"),OIo=o("TFXLMRobertaModel"),GIo=o(" (XLM-RoBERTa model)"),zIo=l(),V4=a("li"),qse=a("strong"),VIo=o("xlnet"),XIo=o(" \u2014 "),OI=a("a"),WIo=o("TFXLNetModel"),QIo=o(" (XLNet model)"),HIo=l(),Ose=a("p"),UIo=o("Examples:"),JIo=l(),f(Q5.$$.fragment),rAe=l(),wd=a("h2"),X4=a("a"),Gse=a("span"),f(H5.$$.fragment),YIo=l(),zse=a("span"),KIo=o("TFAutoModelForPreTraining"),tAe=l(),sr=a("div"),f(U5.$$.fragment),ZIo=l(),Ad=a("p"),ejo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Vse=a("code"),ojo=o("from_pretrained()"),rjo=o("class method or the "),Xse=a("code"),tjo=o("from_config()"),ajo=o(`class
method.`),njo=l(),J5=a("p"),sjo=o("This class cannot be instantiated directly using "),Wse=a("code"),ljo=o("__init__()"),ijo=o(" (throws an error)."),djo=l(),Jr=a("div"),f(Y5.$$.fragment),cjo=l(),Qse=a("p"),fjo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),mjo=l(),Ld=a("p"),gjo=o(`Note:
Loading a model from its configuration file does `),Hse=a("strong"),hjo=o("not"),ujo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Use=a("code"),pjo=o("from_pretrained()"),_jo=o("to load the model weights."),vjo=l(),Jse=a("p"),bjo=o("Examples:"),Tjo=l(),f(K5.$$.fragment),Fjo=l(),fo=a("div"),f(Z5.$$.fragment),Cjo=l(),Yse=a("p"),Ejo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Mjo=l(),Ha=a("p"),yjo=o("The model class to instantiate is selected based on the "),Kse=a("code"),wjo=o("model_type"),Ajo=o(` property of the config object (either
passed as an argument or loaded from `),Zse=a("code"),Ljo=o("pretrained_model_name_or_path"),Bjo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ele=a("code"),kjo=o("pretrained_model_name_or_path"),xjo=o(":"),Rjo=l(),Q=a("ul"),W4=a("li"),ole=a("strong"),Sjo=o("albert"),Pjo=o(" \u2014 "),GI=a("a"),$jo=o("TFAlbertForPreTraining"),Ijo=o(" (ALBERT model)"),jjo=l(),Q4=a("li"),rle=a("strong"),Njo=o("bart"),Djo=o(" \u2014 "),zI=a("a"),qjo=o("TFBartForConditionalGeneration"),Ojo=o(" (BART model)"),Gjo=l(),H4=a("li"),tle=a("strong"),zjo=o("bert"),Vjo=o(" \u2014 "),VI=a("a"),Xjo=o("TFBertForPreTraining"),Wjo=o(" (BERT model)"),Qjo=l(),U4=a("li"),ale=a("strong"),Hjo=o("camembert"),Ujo=o(" \u2014 "),XI=a("a"),Jjo=o("TFCamembertForMaskedLM"),Yjo=o(" (CamemBERT model)"),Kjo=l(),J4=a("li"),nle=a("strong"),Zjo=o("ctrl"),eNo=o(" \u2014 "),WI=a("a"),oNo=o("TFCTRLLMHeadModel"),rNo=o(" (CTRL model)"),tNo=l(),Y4=a("li"),sle=a("strong"),aNo=o("distilbert"),nNo=o(" \u2014 "),QI=a("a"),sNo=o("TFDistilBertForMaskedLM"),lNo=o(" (DistilBERT model)"),iNo=l(),K4=a("li"),lle=a("strong"),dNo=o("electra"),cNo=o(" \u2014 "),HI=a("a"),fNo=o("TFElectraForPreTraining"),mNo=o(" (ELECTRA model)"),gNo=l(),Z4=a("li"),ile=a("strong"),hNo=o("flaubert"),uNo=o(" \u2014 "),UI=a("a"),pNo=o("TFFlaubertWithLMHeadModel"),_No=o(" (FlauBERT model)"),vNo=l(),eb=a("li"),dle=a("strong"),bNo=o("funnel"),TNo=o(" \u2014 "),JI=a("a"),FNo=o("TFFunnelForPreTraining"),CNo=o(" (Funnel Transformer model)"),ENo=l(),ob=a("li"),cle=a("strong"),MNo=o("gpt2"),yNo=o(" \u2014 "),YI=a("a"),wNo=o("TFGPT2LMHeadModel"),ANo=o(" (OpenAI GPT-2 model)"),LNo=l(),rb=a("li"),fle=a("strong"),BNo=o("layoutlm"),kNo=o(" \u2014 "),KI=a("a"),xNo=o("TFLayoutLMForMaskedLM"),RNo=o(" (LayoutLM model)"),SNo=l(),tb=a("li"),mle=a("strong"),PNo=o("lxmert"),$No=o(" \u2014 "),ZI=a("a"),INo=o("TFLxmertForPreTraining"),jNo=o(" (LXMERT model)"),NNo=l(),ab=a("li"),gle=a("strong"),DNo=o("mobilebert"),qNo=o(" \u2014 "),ej=a("a"),ONo=o("TFMobileBertForPreTraining"),GNo=o(" (MobileBERT model)"),zNo=l(),nb=a("li"),hle=a("strong"),VNo=o("mpnet"),XNo=o(" \u2014 "),oj=a("a"),WNo=o("TFMPNetForMaskedLM"),QNo=o(" (MPNet model)"),HNo=l(),sb=a("li"),ule=a("strong"),UNo=o("openai-gpt"),JNo=o(" \u2014 "),rj=a("a"),YNo=o("TFOpenAIGPTLMHeadModel"),KNo=o(" (OpenAI GPT model)"),ZNo=l(),lb=a("li"),ple=a("strong"),eDo=o("roberta"),oDo=o(" \u2014 "),tj=a("a"),rDo=o("TFRobertaForMaskedLM"),tDo=o(" (RoBERTa model)"),aDo=l(),ib=a("li"),_le=a("strong"),nDo=o("t5"),sDo=o(" \u2014 "),aj=a("a"),lDo=o("TFT5ForConditionalGeneration"),iDo=o(" (T5 model)"),dDo=l(),db=a("li"),vle=a("strong"),cDo=o("tapas"),fDo=o(" \u2014 "),nj=a("a"),mDo=o("TFTapasForMaskedLM"),gDo=o(" (TAPAS model)"),hDo=l(),cb=a("li"),ble=a("strong"),uDo=o("transfo-xl"),pDo=o(" \u2014 "),sj=a("a"),_Do=o("TFTransfoXLLMHeadModel"),vDo=o(" (Transformer-XL model)"),bDo=l(),fb=a("li"),Tle=a("strong"),TDo=o("xlm"),FDo=o(" \u2014 "),lj=a("a"),CDo=o("TFXLMWithLMHeadModel"),EDo=o(" (XLM model)"),MDo=l(),mb=a("li"),Fle=a("strong"),yDo=o("xlm-roberta"),wDo=o(" \u2014 "),ij=a("a"),ADo=o("TFXLMRobertaForMaskedLM"),LDo=o(" (XLM-RoBERTa model)"),BDo=l(),gb=a("li"),Cle=a("strong"),kDo=o("xlnet"),xDo=o(" \u2014 "),dj=a("a"),RDo=o("TFXLNetLMHeadModel"),SDo=o(" (XLNet model)"),PDo=l(),Ele=a("p"),$Do=o("Examples:"),IDo=l(),f(ey.$$.fragment),aAe=l(),Bd=a("h2"),hb=a("a"),Mle=a("span"),f(oy.$$.fragment),jDo=l(),yle=a("span"),NDo=o("TFAutoModelForCausalLM"),nAe=l(),lr=a("div"),f(ry.$$.fragment),DDo=l(),kd=a("p"),qDo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wle=a("code"),ODo=o("from_pretrained()"),GDo=o("class method or the "),Ale=a("code"),zDo=o("from_config()"),VDo=o(`class
method.`),XDo=l(),ty=a("p"),WDo=o("This class cannot be instantiated directly using "),Lle=a("code"),QDo=o("__init__()"),HDo=o(" (throws an error)."),UDo=l(),Yr=a("div"),f(ay.$$.fragment),JDo=l(),Ble=a("p"),YDo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),KDo=l(),xd=a("p"),ZDo=o(`Note:
Loading a model from its configuration file does `),kle=a("strong"),eqo=o("not"),oqo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xle=a("code"),rqo=o("from_pretrained()"),tqo=o("to load the model weights."),aqo=l(),Rle=a("p"),nqo=o("Examples:"),sqo=l(),f(ny.$$.fragment),lqo=l(),mo=a("div"),f(sy.$$.fragment),iqo=l(),Sle=a("p"),dqo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),cqo=l(),Ua=a("p"),fqo=o("The model class to instantiate is selected based on the "),Ple=a("code"),mqo=o("model_type"),gqo=o(` property of the config object (either
passed as an argument or loaded from `),$le=a("code"),hqo=o("pretrained_model_name_or_path"),uqo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ile=a("code"),pqo=o("pretrained_model_name_or_path"),_qo=o(":"),vqo=l(),he=a("ul"),ub=a("li"),jle=a("strong"),bqo=o("bert"),Tqo=o(" \u2014 "),cj=a("a"),Fqo=o("TFBertLMHeadModel"),Cqo=o(" (BERT model)"),Eqo=l(),pb=a("li"),Nle=a("strong"),Mqo=o("ctrl"),yqo=o(" \u2014 "),fj=a("a"),wqo=o("TFCTRLLMHeadModel"),Aqo=o(" (CTRL model)"),Lqo=l(),_b=a("li"),Dle=a("strong"),Bqo=o("gpt2"),kqo=o(" \u2014 "),mj=a("a"),xqo=o("TFGPT2LMHeadModel"),Rqo=o(" (OpenAI GPT-2 model)"),Sqo=l(),vb=a("li"),qle=a("strong"),Pqo=o("openai-gpt"),$qo=o(" \u2014 "),gj=a("a"),Iqo=o("TFOpenAIGPTLMHeadModel"),jqo=o(" (OpenAI GPT model)"),Nqo=l(),bb=a("li"),Ole=a("strong"),Dqo=o("rembert"),qqo=o(" \u2014 "),hj=a("a"),Oqo=o("TFRemBertForCausalLM"),Gqo=o(" (RemBERT model)"),zqo=l(),Tb=a("li"),Gle=a("strong"),Vqo=o("roberta"),Xqo=o(" \u2014 "),uj=a("a"),Wqo=o("TFRobertaForCausalLM"),Qqo=o(" (RoBERTa model)"),Hqo=l(),Fb=a("li"),zle=a("strong"),Uqo=o("roformer"),Jqo=o(" \u2014 "),pj=a("a"),Yqo=o("TFRoFormerForCausalLM"),Kqo=o(" (RoFormer model)"),Zqo=l(),Cb=a("li"),Vle=a("strong"),eOo=o("transfo-xl"),oOo=o(" \u2014 "),_j=a("a"),rOo=o("TFTransfoXLLMHeadModel"),tOo=o(" (Transformer-XL model)"),aOo=l(),Eb=a("li"),Xle=a("strong"),nOo=o("xlm"),sOo=o(" \u2014 "),vj=a("a"),lOo=o("TFXLMWithLMHeadModel"),iOo=o(" (XLM model)"),dOo=l(),Mb=a("li"),Wle=a("strong"),cOo=o("xlnet"),fOo=o(" \u2014 "),bj=a("a"),mOo=o("TFXLNetLMHeadModel"),gOo=o(" (XLNet model)"),hOo=l(),Qle=a("p"),uOo=o("Examples:"),pOo=l(),f(ly.$$.fragment),sAe=l(),Rd=a("h2"),yb=a("a"),Hle=a("span"),f(iy.$$.fragment),_Oo=l(),Ule=a("span"),vOo=o("TFAutoModelForImageClassification"),lAe=l(),ir=a("div"),f(dy.$$.fragment),bOo=l(),Sd=a("p"),TOo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Jle=a("code"),FOo=o("from_pretrained()"),COo=o("class method or the "),Yle=a("code"),EOo=o("from_config()"),MOo=o(`class
method.`),yOo=l(),cy=a("p"),wOo=o("This class cannot be instantiated directly using "),Kle=a("code"),AOo=o("__init__()"),LOo=o(" (throws an error)."),BOo=l(),Kr=a("div"),f(fy.$$.fragment),kOo=l(),Zle=a("p"),xOo=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),ROo=l(),Pd=a("p"),SOo=o(`Note:
Loading a model from its configuration file does `),eie=a("strong"),POo=o("not"),$Oo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oie=a("code"),IOo=o("from_pretrained()"),jOo=o("to load the model weights."),NOo=l(),rie=a("p"),DOo=o("Examples:"),qOo=l(),f(my.$$.fragment),OOo=l(),go=a("div"),f(gy.$$.fragment),GOo=l(),tie=a("p"),zOo=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),VOo=l(),Ja=a("p"),XOo=o("The model class to instantiate is selected based on the "),aie=a("code"),WOo=o("model_type"),QOo=o(` property of the config object (either
passed as an argument or loaded from `),nie=a("code"),HOo=o("pretrained_model_name_or_path"),UOo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sie=a("code"),JOo=o("pretrained_model_name_or_path"),YOo=o(":"),KOo=l(),lie=a("ul"),wb=a("li"),iie=a("strong"),ZOo=o("vit"),eGo=o(" \u2014 "),Tj=a("a"),oGo=o("TFViTForImageClassification"),rGo=o(" (ViT model)"),tGo=l(),die=a("p"),aGo=o("Examples:"),nGo=l(),f(hy.$$.fragment),iAe=l(),$d=a("h2"),Ab=a("a"),cie=a("span"),f(uy.$$.fragment),sGo=l(),fie=a("span"),lGo=o("TFAutoModelForMaskedLM"),dAe=l(),dr=a("div"),f(py.$$.fragment),iGo=l(),Id=a("p"),dGo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),mie=a("code"),cGo=o("from_pretrained()"),fGo=o("class method or the "),gie=a("code"),mGo=o("from_config()"),gGo=o(`class
method.`),hGo=l(),_y=a("p"),uGo=o("This class cannot be instantiated directly using "),hie=a("code"),pGo=o("__init__()"),_Go=o(" (throws an error)."),vGo=l(),Zr=a("div"),f(vy.$$.fragment),bGo=l(),uie=a("p"),TGo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),FGo=l(),jd=a("p"),CGo=o(`Note:
Loading a model from its configuration file does `),pie=a("strong"),EGo=o("not"),MGo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_ie=a("code"),yGo=o("from_pretrained()"),wGo=o("to load the model weights."),AGo=l(),vie=a("p"),LGo=o("Examples:"),BGo=l(),f(by.$$.fragment),kGo=l(),ho=a("div"),f(Ty.$$.fragment),xGo=l(),bie=a("p"),RGo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),SGo=l(),Ya=a("p"),PGo=o("The model class to instantiate is selected based on the "),Tie=a("code"),$Go=o("model_type"),IGo=o(` property of the config object (either
passed as an argument or loaded from `),Fie=a("code"),jGo=o("pretrained_model_name_or_path"),NGo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cie=a("code"),DGo=o("pretrained_model_name_or_path"),qGo=o(":"),OGo=l(),Y=a("ul"),Lb=a("li"),Eie=a("strong"),GGo=o("albert"),zGo=o(" \u2014 "),Fj=a("a"),VGo=o("TFAlbertForMaskedLM"),XGo=o(" (ALBERT model)"),WGo=l(),Bb=a("li"),Mie=a("strong"),QGo=o("bert"),HGo=o(" \u2014 "),Cj=a("a"),UGo=o("TFBertForMaskedLM"),JGo=o(" (BERT model)"),YGo=l(),kb=a("li"),yie=a("strong"),KGo=o("camembert"),ZGo=o(" \u2014 "),Ej=a("a"),ezo=o("TFCamembertForMaskedLM"),ozo=o(" (CamemBERT model)"),rzo=l(),xb=a("li"),wie=a("strong"),tzo=o("convbert"),azo=o(" \u2014 "),Mj=a("a"),nzo=o("TFConvBertForMaskedLM"),szo=o(" (ConvBERT model)"),lzo=l(),Rb=a("li"),Aie=a("strong"),izo=o("deberta"),dzo=o(" \u2014 "),yj=a("a"),czo=o("TFDebertaForMaskedLM"),fzo=o(" (DeBERTa model)"),mzo=l(),Sb=a("li"),Lie=a("strong"),gzo=o("deberta-v2"),hzo=o(" \u2014 "),wj=a("a"),uzo=o("TFDebertaV2ForMaskedLM"),pzo=o(" (DeBERTa-v2 model)"),_zo=l(),Pb=a("li"),Bie=a("strong"),vzo=o("distilbert"),bzo=o(" \u2014 "),Aj=a("a"),Tzo=o("TFDistilBertForMaskedLM"),Fzo=o(" (DistilBERT model)"),Czo=l(),$b=a("li"),kie=a("strong"),Ezo=o("electra"),Mzo=o(" \u2014 "),Lj=a("a"),yzo=o("TFElectraForMaskedLM"),wzo=o(" (ELECTRA model)"),Azo=l(),Ib=a("li"),xie=a("strong"),Lzo=o("flaubert"),Bzo=o(" \u2014 "),Bj=a("a"),kzo=o("TFFlaubertWithLMHeadModel"),xzo=o(" (FlauBERT model)"),Rzo=l(),jb=a("li"),Rie=a("strong"),Szo=o("funnel"),Pzo=o(" \u2014 "),kj=a("a"),$zo=o("TFFunnelForMaskedLM"),Izo=o(" (Funnel Transformer model)"),jzo=l(),Nb=a("li"),Sie=a("strong"),Nzo=o("layoutlm"),Dzo=o(" \u2014 "),xj=a("a"),qzo=o("TFLayoutLMForMaskedLM"),Ozo=o(" (LayoutLM model)"),Gzo=l(),Db=a("li"),Pie=a("strong"),zzo=o("longformer"),Vzo=o(" \u2014 "),Rj=a("a"),Xzo=o("TFLongformerForMaskedLM"),Wzo=o(" (Longformer model)"),Qzo=l(),qb=a("li"),$ie=a("strong"),Hzo=o("mobilebert"),Uzo=o(" \u2014 "),Sj=a("a"),Jzo=o("TFMobileBertForMaskedLM"),Yzo=o(" (MobileBERT model)"),Kzo=l(),Ob=a("li"),Iie=a("strong"),Zzo=o("mpnet"),eVo=o(" \u2014 "),Pj=a("a"),oVo=o("TFMPNetForMaskedLM"),rVo=o(" (MPNet model)"),tVo=l(),Gb=a("li"),jie=a("strong"),aVo=o("rembert"),nVo=o(" \u2014 "),$j=a("a"),sVo=o("TFRemBertForMaskedLM"),lVo=o(" (RemBERT model)"),iVo=l(),zb=a("li"),Nie=a("strong"),dVo=o("roberta"),cVo=o(" \u2014 "),Ij=a("a"),fVo=o("TFRobertaForMaskedLM"),mVo=o(" (RoBERTa model)"),gVo=l(),Vb=a("li"),Die=a("strong"),hVo=o("roformer"),uVo=o(" \u2014 "),jj=a("a"),pVo=o("TFRoFormerForMaskedLM"),_Vo=o(" (RoFormer model)"),vVo=l(),Xb=a("li"),qie=a("strong"),bVo=o("tapas"),TVo=o(" \u2014 "),Nj=a("a"),FVo=o("TFTapasForMaskedLM"),CVo=o(" (TAPAS model)"),EVo=l(),Wb=a("li"),Oie=a("strong"),MVo=o("xlm"),yVo=o(" \u2014 "),Dj=a("a"),wVo=o("TFXLMWithLMHeadModel"),AVo=o(" (XLM model)"),LVo=l(),Qb=a("li"),Gie=a("strong"),BVo=o("xlm-roberta"),kVo=o(" \u2014 "),qj=a("a"),xVo=o("TFXLMRobertaForMaskedLM"),RVo=o(" (XLM-RoBERTa model)"),SVo=l(),zie=a("p"),PVo=o("Examples:"),$Vo=l(),f(Fy.$$.fragment),cAe=l(),Nd=a("h2"),Hb=a("a"),Vie=a("span"),f(Cy.$$.fragment),IVo=l(),Xie=a("span"),jVo=o("TFAutoModelForSeq2SeqLM"),fAe=l(),cr=a("div"),f(Ey.$$.fragment),NVo=l(),Dd=a("p"),DVo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Wie=a("code"),qVo=o("from_pretrained()"),OVo=o("class method or the "),Qie=a("code"),GVo=o("from_config()"),zVo=o(`class
method.`),VVo=l(),My=a("p"),XVo=o("This class cannot be instantiated directly using "),Hie=a("code"),WVo=o("__init__()"),QVo=o(" (throws an error)."),HVo=l(),et=a("div"),f(yy.$$.fragment),UVo=l(),Uie=a("p"),JVo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),YVo=l(),qd=a("p"),KVo=o(`Note:
Loading a model from its configuration file does `),Jie=a("strong"),ZVo=o("not"),eXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yie=a("code"),oXo=o("from_pretrained()"),rXo=o("to load the model weights."),tXo=l(),Kie=a("p"),aXo=o("Examples:"),nXo=l(),f(wy.$$.fragment),sXo=l(),uo=a("div"),f(Ay.$$.fragment),lXo=l(),Zie=a("p"),iXo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),dXo=l(),Ka=a("p"),cXo=o("The model class to instantiate is selected based on the "),ede=a("code"),fXo=o("model_type"),mXo=o(` property of the config object (either
passed as an argument or loaded from `),ode=a("code"),gXo=o("pretrained_model_name_or_path"),hXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rde=a("code"),uXo=o("pretrained_model_name_or_path"),pXo=o(":"),_Xo=l(),ue=a("ul"),Ub=a("li"),tde=a("strong"),vXo=o("bart"),bXo=o(" \u2014 "),Oj=a("a"),TXo=o("TFBartForConditionalGeneration"),FXo=o(" (BART model)"),CXo=l(),Jb=a("li"),ade=a("strong"),EXo=o("blenderbot"),MXo=o(" \u2014 "),Gj=a("a"),yXo=o("TFBlenderbotForConditionalGeneration"),wXo=o(" (Blenderbot model)"),AXo=l(),Yb=a("li"),nde=a("strong"),LXo=o("blenderbot-small"),BXo=o(" \u2014 "),zj=a("a"),kXo=o("TFBlenderbotSmallForConditionalGeneration"),xXo=o(" (BlenderbotSmall model)"),RXo=l(),Kb=a("li"),sde=a("strong"),SXo=o("encoder-decoder"),PXo=o(" \u2014 "),Vj=a("a"),$Xo=o("TFEncoderDecoderModel"),IXo=o(" (Encoder decoder model)"),jXo=l(),Zb=a("li"),lde=a("strong"),NXo=o("led"),DXo=o(" \u2014 "),Xj=a("a"),qXo=o("TFLEDForConditionalGeneration"),OXo=o(" (LED model)"),GXo=l(),eT=a("li"),ide=a("strong"),zXo=o("marian"),VXo=o(" \u2014 "),Wj=a("a"),XXo=o("TFMarianMTModel"),WXo=o(" (Marian model)"),QXo=l(),oT=a("li"),dde=a("strong"),HXo=o("mbart"),UXo=o(" \u2014 "),Qj=a("a"),JXo=o("TFMBartForConditionalGeneration"),YXo=o(" (mBART model)"),KXo=l(),rT=a("li"),cde=a("strong"),ZXo=o("mt5"),eWo=o(" \u2014 "),Hj=a("a"),oWo=o("TFMT5ForConditionalGeneration"),rWo=o(" (mT5 model)"),tWo=l(),tT=a("li"),fde=a("strong"),aWo=o("pegasus"),nWo=o(" \u2014 "),Uj=a("a"),sWo=o("TFPegasusForConditionalGeneration"),lWo=o(" (Pegasus model)"),iWo=l(),aT=a("li"),mde=a("strong"),dWo=o("t5"),cWo=o(" \u2014 "),Jj=a("a"),fWo=o("TFT5ForConditionalGeneration"),mWo=o(" (T5 model)"),gWo=l(),gde=a("p"),hWo=o("Examples:"),uWo=l(),f(Ly.$$.fragment),mAe=l(),Od=a("h2"),nT=a("a"),hde=a("span"),f(By.$$.fragment),pWo=l(),ude=a("span"),_Wo=o("TFAutoModelForSequenceClassification"),gAe=l(),fr=a("div"),f(ky.$$.fragment),vWo=l(),Gd=a("p"),bWo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),pde=a("code"),TWo=o("from_pretrained()"),FWo=o("class method or the "),_de=a("code"),CWo=o("from_config()"),EWo=o(`class
method.`),MWo=l(),xy=a("p"),yWo=o("This class cannot be instantiated directly using "),vde=a("code"),wWo=o("__init__()"),AWo=o(" (throws an error)."),LWo=l(),ot=a("div"),f(Ry.$$.fragment),BWo=l(),bde=a("p"),kWo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),xWo=l(),zd=a("p"),RWo=o(`Note:
Loading a model from its configuration file does `),Tde=a("strong"),SWo=o("not"),PWo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fde=a("code"),$Wo=o("from_pretrained()"),IWo=o("to load the model weights."),jWo=l(),Cde=a("p"),NWo=o("Examples:"),DWo=l(),f(Sy.$$.fragment),qWo=l(),po=a("div"),f(Py.$$.fragment),OWo=l(),Ede=a("p"),GWo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),zWo=l(),Za=a("p"),VWo=o("The model class to instantiate is selected based on the "),Mde=a("code"),XWo=o("model_type"),WWo=o(` property of the config object (either
passed as an argument or loaded from `),yde=a("code"),QWo=o("pretrained_model_name_or_path"),HWo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wde=a("code"),UWo=o("pretrained_model_name_or_path"),JWo=o(":"),YWo=l(),G=a("ul"),sT=a("li"),Ade=a("strong"),KWo=o("albert"),ZWo=o(" \u2014 "),Yj=a("a"),eQo=o("TFAlbertForSequenceClassification"),oQo=o(" (ALBERT model)"),rQo=l(),lT=a("li"),Lde=a("strong"),tQo=o("bert"),aQo=o(" \u2014 "),Kj=a("a"),nQo=o("TFBertForSequenceClassification"),sQo=o(" (BERT model)"),lQo=l(),iT=a("li"),Bde=a("strong"),iQo=o("camembert"),dQo=o(" \u2014 "),Zj=a("a"),cQo=o("TFCamembertForSequenceClassification"),fQo=o(" (CamemBERT model)"),mQo=l(),dT=a("li"),kde=a("strong"),gQo=o("convbert"),hQo=o(" \u2014 "),eN=a("a"),uQo=o("TFConvBertForSequenceClassification"),pQo=o(" (ConvBERT model)"),_Qo=l(),cT=a("li"),xde=a("strong"),vQo=o("ctrl"),bQo=o(" \u2014 "),oN=a("a"),TQo=o("TFCTRLForSequenceClassification"),FQo=o(" (CTRL model)"),CQo=l(),fT=a("li"),Rde=a("strong"),EQo=o("deberta"),MQo=o(" \u2014 "),rN=a("a"),yQo=o("TFDebertaForSequenceClassification"),wQo=o(" (DeBERTa model)"),AQo=l(),mT=a("li"),Sde=a("strong"),LQo=o("deberta-v2"),BQo=o(" \u2014 "),tN=a("a"),kQo=o("TFDebertaV2ForSequenceClassification"),xQo=o(" (DeBERTa-v2 model)"),RQo=l(),gT=a("li"),Pde=a("strong"),SQo=o("distilbert"),PQo=o(" \u2014 "),aN=a("a"),$Qo=o("TFDistilBertForSequenceClassification"),IQo=o(" (DistilBERT model)"),jQo=l(),hT=a("li"),$de=a("strong"),NQo=o("electra"),DQo=o(" \u2014 "),nN=a("a"),qQo=o("TFElectraForSequenceClassification"),OQo=o(" (ELECTRA model)"),GQo=l(),uT=a("li"),Ide=a("strong"),zQo=o("flaubert"),VQo=o(" \u2014 "),sN=a("a"),XQo=o("TFFlaubertForSequenceClassification"),WQo=o(" (FlauBERT model)"),QQo=l(),pT=a("li"),jde=a("strong"),HQo=o("funnel"),UQo=o(" \u2014 "),lN=a("a"),JQo=o("TFFunnelForSequenceClassification"),YQo=o(" (Funnel Transformer model)"),KQo=l(),_T=a("li"),Nde=a("strong"),ZQo=o("gpt2"),eHo=o(" \u2014 "),iN=a("a"),oHo=o("TFGPT2ForSequenceClassification"),rHo=o(" (OpenAI GPT-2 model)"),tHo=l(),vT=a("li"),Dde=a("strong"),aHo=o("layoutlm"),nHo=o(" \u2014 "),dN=a("a"),sHo=o("TFLayoutLMForSequenceClassification"),lHo=o(" (LayoutLM model)"),iHo=l(),bT=a("li"),qde=a("strong"),dHo=o("longformer"),cHo=o(" \u2014 "),cN=a("a"),fHo=o("TFLongformerForSequenceClassification"),mHo=o(" (Longformer model)"),gHo=l(),TT=a("li"),Ode=a("strong"),hHo=o("mobilebert"),uHo=o(" \u2014 "),fN=a("a"),pHo=o("TFMobileBertForSequenceClassification"),_Ho=o(" (MobileBERT model)"),vHo=l(),FT=a("li"),Gde=a("strong"),bHo=o("mpnet"),THo=o(" \u2014 "),mN=a("a"),FHo=o("TFMPNetForSequenceClassification"),CHo=o(" (MPNet model)"),EHo=l(),CT=a("li"),zde=a("strong"),MHo=o("openai-gpt"),yHo=o(" \u2014 "),gN=a("a"),wHo=o("TFOpenAIGPTForSequenceClassification"),AHo=o(" (OpenAI GPT model)"),LHo=l(),ET=a("li"),Vde=a("strong"),BHo=o("rembert"),kHo=o(" \u2014 "),hN=a("a"),xHo=o("TFRemBertForSequenceClassification"),RHo=o(" (RemBERT model)"),SHo=l(),MT=a("li"),Xde=a("strong"),PHo=o("roberta"),$Ho=o(" \u2014 "),uN=a("a"),IHo=o("TFRobertaForSequenceClassification"),jHo=o(" (RoBERTa model)"),NHo=l(),yT=a("li"),Wde=a("strong"),DHo=o("roformer"),qHo=o(" \u2014 "),pN=a("a"),OHo=o("TFRoFormerForSequenceClassification"),GHo=o(" (RoFormer model)"),zHo=l(),wT=a("li"),Qde=a("strong"),VHo=o("tapas"),XHo=o(" \u2014 "),_N=a("a"),WHo=o("TFTapasForSequenceClassification"),QHo=o(" (TAPAS model)"),HHo=l(),AT=a("li"),Hde=a("strong"),UHo=o("transfo-xl"),JHo=o(" \u2014 "),vN=a("a"),YHo=o("TFTransfoXLForSequenceClassification"),KHo=o(" (Transformer-XL model)"),ZHo=l(),LT=a("li"),Ude=a("strong"),eUo=o("xlm"),oUo=o(" \u2014 "),bN=a("a"),rUo=o("TFXLMForSequenceClassification"),tUo=o(" (XLM model)"),aUo=l(),BT=a("li"),Jde=a("strong"),nUo=o("xlm-roberta"),sUo=o(" \u2014 "),TN=a("a"),lUo=o("TFXLMRobertaForSequenceClassification"),iUo=o(" (XLM-RoBERTa model)"),dUo=l(),kT=a("li"),Yde=a("strong"),cUo=o("xlnet"),fUo=o(" \u2014 "),FN=a("a"),mUo=o("TFXLNetForSequenceClassification"),gUo=o(" (XLNet model)"),hUo=l(),Kde=a("p"),uUo=o("Examples:"),pUo=l(),f($y.$$.fragment),hAe=l(),Vd=a("h2"),xT=a("a"),Zde=a("span"),f(Iy.$$.fragment),_Uo=l(),ece=a("span"),vUo=o("TFAutoModelForMultipleChoice"),uAe=l(),mr=a("div"),f(jy.$$.fragment),bUo=l(),Xd=a("p"),TUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),oce=a("code"),FUo=o("from_pretrained()"),CUo=o("class method or the "),rce=a("code"),EUo=o("from_config()"),MUo=o(`class
method.`),yUo=l(),Ny=a("p"),wUo=o("This class cannot be instantiated directly using "),tce=a("code"),AUo=o("__init__()"),LUo=o(" (throws an error)."),BUo=l(),rt=a("div"),f(Dy.$$.fragment),kUo=l(),ace=a("p"),xUo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),RUo=l(),Wd=a("p"),SUo=o(`Note:
Loading a model from its configuration file does `),nce=a("strong"),PUo=o("not"),$Uo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sce=a("code"),IUo=o("from_pretrained()"),jUo=o("to load the model weights."),NUo=l(),lce=a("p"),DUo=o("Examples:"),qUo=l(),f(qy.$$.fragment),OUo=l(),_o=a("div"),f(Oy.$$.fragment),GUo=l(),ice=a("p"),zUo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),VUo=l(),en=a("p"),XUo=o("The model class to instantiate is selected based on the "),dce=a("code"),WUo=o("model_type"),QUo=o(` property of the config object (either
passed as an argument or loaded from `),cce=a("code"),HUo=o("pretrained_model_name_or_path"),UUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fce=a("code"),JUo=o("pretrained_model_name_or_path"),YUo=o(":"),KUo=l(),te=a("ul"),RT=a("li"),mce=a("strong"),ZUo=o("albert"),eJo=o(" \u2014 "),CN=a("a"),oJo=o("TFAlbertForMultipleChoice"),rJo=o(" (ALBERT model)"),tJo=l(),ST=a("li"),gce=a("strong"),aJo=o("bert"),nJo=o(" \u2014 "),EN=a("a"),sJo=o("TFBertForMultipleChoice"),lJo=o(" (BERT model)"),iJo=l(),PT=a("li"),hce=a("strong"),dJo=o("camembert"),cJo=o(" \u2014 "),MN=a("a"),fJo=o("TFCamembertForMultipleChoice"),mJo=o(" (CamemBERT model)"),gJo=l(),$T=a("li"),uce=a("strong"),hJo=o("convbert"),uJo=o(" \u2014 "),yN=a("a"),pJo=o("TFConvBertForMultipleChoice"),_Jo=o(" (ConvBERT model)"),vJo=l(),IT=a("li"),pce=a("strong"),bJo=o("distilbert"),TJo=o(" \u2014 "),wN=a("a"),FJo=o("TFDistilBertForMultipleChoice"),CJo=o(" (DistilBERT model)"),EJo=l(),jT=a("li"),_ce=a("strong"),MJo=o("electra"),yJo=o(" \u2014 "),AN=a("a"),wJo=o("TFElectraForMultipleChoice"),AJo=o(" (ELECTRA model)"),LJo=l(),NT=a("li"),vce=a("strong"),BJo=o("flaubert"),kJo=o(" \u2014 "),LN=a("a"),xJo=o("TFFlaubertForMultipleChoice"),RJo=o(" (FlauBERT model)"),SJo=l(),DT=a("li"),bce=a("strong"),PJo=o("funnel"),$Jo=o(" \u2014 "),BN=a("a"),IJo=o("TFFunnelForMultipleChoice"),jJo=o(" (Funnel Transformer model)"),NJo=l(),qT=a("li"),Tce=a("strong"),DJo=o("longformer"),qJo=o(" \u2014 "),kN=a("a"),OJo=o("TFLongformerForMultipleChoice"),GJo=o(" (Longformer model)"),zJo=l(),OT=a("li"),Fce=a("strong"),VJo=o("mobilebert"),XJo=o(" \u2014 "),xN=a("a"),WJo=o("TFMobileBertForMultipleChoice"),QJo=o(" (MobileBERT model)"),HJo=l(),GT=a("li"),Cce=a("strong"),UJo=o("mpnet"),JJo=o(" \u2014 "),RN=a("a"),YJo=o("TFMPNetForMultipleChoice"),KJo=o(" (MPNet model)"),ZJo=l(),zT=a("li"),Ece=a("strong"),eYo=o("rembert"),oYo=o(" \u2014 "),SN=a("a"),rYo=o("TFRemBertForMultipleChoice"),tYo=o(" (RemBERT model)"),aYo=l(),VT=a("li"),Mce=a("strong"),nYo=o("roberta"),sYo=o(" \u2014 "),PN=a("a"),lYo=o("TFRobertaForMultipleChoice"),iYo=o(" (RoBERTa model)"),dYo=l(),XT=a("li"),yce=a("strong"),cYo=o("roformer"),fYo=o(" \u2014 "),$N=a("a"),mYo=o("TFRoFormerForMultipleChoice"),gYo=o(" (RoFormer model)"),hYo=l(),WT=a("li"),wce=a("strong"),uYo=o("xlm"),pYo=o(" \u2014 "),IN=a("a"),_Yo=o("TFXLMForMultipleChoice"),vYo=o(" (XLM model)"),bYo=l(),QT=a("li"),Ace=a("strong"),TYo=o("xlm-roberta"),FYo=o(" \u2014 "),jN=a("a"),CYo=o("TFXLMRobertaForMultipleChoice"),EYo=o(" (XLM-RoBERTa model)"),MYo=l(),HT=a("li"),Lce=a("strong"),yYo=o("xlnet"),wYo=o(" \u2014 "),NN=a("a"),AYo=o("TFXLNetForMultipleChoice"),LYo=o(" (XLNet model)"),BYo=l(),Bce=a("p"),kYo=o("Examples:"),xYo=l(),f(Gy.$$.fragment),pAe=l(),Qd=a("h2"),UT=a("a"),kce=a("span"),f(zy.$$.fragment),RYo=l(),xce=a("span"),SYo=o("TFAutoModelForTableQuestionAnswering"),_Ae=l(),gr=a("div"),f(Vy.$$.fragment),PYo=l(),Hd=a("p"),$Yo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Rce=a("code"),IYo=o("from_pretrained()"),jYo=o("class method or the "),Sce=a("code"),NYo=o("from_config()"),DYo=o(`class
method.`),qYo=l(),Xy=a("p"),OYo=o("This class cannot be instantiated directly using "),Pce=a("code"),GYo=o("__init__()"),zYo=o(" (throws an error)."),VYo=l(),tt=a("div"),f(Wy.$$.fragment),XYo=l(),$ce=a("p"),WYo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),QYo=l(),Ud=a("p"),HYo=o(`Note:
Loading a model from its configuration file does `),Ice=a("strong"),UYo=o("not"),JYo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jce=a("code"),YYo=o("from_pretrained()"),KYo=o("to load the model weights."),ZYo=l(),Nce=a("p"),eKo=o("Examples:"),oKo=l(),f(Qy.$$.fragment),rKo=l(),vo=a("div"),f(Hy.$$.fragment),tKo=l(),Dce=a("p"),aKo=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),nKo=l(),on=a("p"),sKo=o("The model class to instantiate is selected based on the "),qce=a("code"),lKo=o("model_type"),iKo=o(` property of the config object (either
passed as an argument or loaded from `),Oce=a("code"),dKo=o("pretrained_model_name_or_path"),cKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gce=a("code"),fKo=o("pretrained_model_name_or_path"),mKo=o(":"),gKo=l(),zce=a("ul"),JT=a("li"),Vce=a("strong"),hKo=o("tapas"),uKo=o(" \u2014 "),DN=a("a"),pKo=o("TFTapasForQuestionAnswering"),_Ko=o(" (TAPAS model)"),vKo=l(),Xce=a("p"),bKo=o("Examples:"),TKo=l(),f(Uy.$$.fragment),vAe=l(),Jd=a("h2"),YT=a("a"),Wce=a("span"),f(Jy.$$.fragment),FKo=l(),Qce=a("span"),CKo=o("TFAutoModelForTokenClassification"),bAe=l(),hr=a("div"),f(Yy.$$.fragment),EKo=l(),Yd=a("p"),MKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Hce=a("code"),yKo=o("from_pretrained()"),wKo=o("class method or the "),Uce=a("code"),AKo=o("from_config()"),LKo=o(`class
method.`),BKo=l(),Ky=a("p"),kKo=o("This class cannot be instantiated directly using "),Jce=a("code"),xKo=o("__init__()"),RKo=o(" (throws an error)."),SKo=l(),at=a("div"),f(Zy.$$.fragment),PKo=l(),Yce=a("p"),$Ko=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),IKo=l(),Kd=a("p"),jKo=o(`Note:
Loading a model from its configuration file does `),Kce=a("strong"),NKo=o("not"),DKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zce=a("code"),qKo=o("from_pretrained()"),OKo=o("to load the model weights."),GKo=l(),efe=a("p"),zKo=o("Examples:"),VKo=l(),f(ew.$$.fragment),XKo=l(),bo=a("div"),f(ow.$$.fragment),WKo=l(),ofe=a("p"),QKo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),HKo=l(),rn=a("p"),UKo=o("The model class to instantiate is selected based on the "),rfe=a("code"),JKo=o("model_type"),YKo=o(` property of the config object (either
passed as an argument or loaded from `),tfe=a("code"),KKo=o("pretrained_model_name_or_path"),ZKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),afe=a("code"),eZo=o("pretrained_model_name_or_path"),oZo=o(":"),rZo=l(),K=a("ul"),KT=a("li"),nfe=a("strong"),tZo=o("albert"),aZo=o(" \u2014 "),qN=a("a"),nZo=o("TFAlbertForTokenClassification"),sZo=o(" (ALBERT model)"),lZo=l(),ZT=a("li"),sfe=a("strong"),iZo=o("bert"),dZo=o(" \u2014 "),ON=a("a"),cZo=o("TFBertForTokenClassification"),fZo=o(" (BERT model)"),mZo=l(),e6=a("li"),lfe=a("strong"),gZo=o("camembert"),hZo=o(" \u2014 "),GN=a("a"),uZo=o("TFCamembertForTokenClassification"),pZo=o(" (CamemBERT model)"),_Zo=l(),o6=a("li"),ife=a("strong"),vZo=o("convbert"),bZo=o(" \u2014 "),zN=a("a"),TZo=o("TFConvBertForTokenClassification"),FZo=o(" (ConvBERT model)"),CZo=l(),r6=a("li"),dfe=a("strong"),EZo=o("deberta"),MZo=o(" \u2014 "),VN=a("a"),yZo=o("TFDebertaForTokenClassification"),wZo=o(" (DeBERTa model)"),AZo=l(),t6=a("li"),cfe=a("strong"),LZo=o("deberta-v2"),BZo=o(" \u2014 "),XN=a("a"),kZo=o("TFDebertaV2ForTokenClassification"),xZo=o(" (DeBERTa-v2 model)"),RZo=l(),a6=a("li"),ffe=a("strong"),SZo=o("distilbert"),PZo=o(" \u2014 "),WN=a("a"),$Zo=o("TFDistilBertForTokenClassification"),IZo=o(" (DistilBERT model)"),jZo=l(),n6=a("li"),mfe=a("strong"),NZo=o("electra"),DZo=o(" \u2014 "),QN=a("a"),qZo=o("TFElectraForTokenClassification"),OZo=o(" (ELECTRA model)"),GZo=l(),s6=a("li"),gfe=a("strong"),zZo=o("flaubert"),VZo=o(" \u2014 "),HN=a("a"),XZo=o("TFFlaubertForTokenClassification"),WZo=o(" (FlauBERT model)"),QZo=l(),l6=a("li"),hfe=a("strong"),HZo=o("funnel"),UZo=o(" \u2014 "),UN=a("a"),JZo=o("TFFunnelForTokenClassification"),YZo=o(" (Funnel Transformer model)"),KZo=l(),i6=a("li"),ufe=a("strong"),ZZo=o("layoutlm"),eer=o(" \u2014 "),JN=a("a"),oer=o("TFLayoutLMForTokenClassification"),rer=o(" (LayoutLM model)"),ter=l(),d6=a("li"),pfe=a("strong"),aer=o("longformer"),ner=o(" \u2014 "),YN=a("a"),ser=o("TFLongformerForTokenClassification"),ler=o(" (Longformer model)"),ier=l(),c6=a("li"),_fe=a("strong"),der=o("mobilebert"),cer=o(" \u2014 "),KN=a("a"),fer=o("TFMobileBertForTokenClassification"),mer=o(" (MobileBERT model)"),ger=l(),f6=a("li"),vfe=a("strong"),her=o("mpnet"),uer=o(" \u2014 "),ZN=a("a"),per=o("TFMPNetForTokenClassification"),_er=o(" (MPNet model)"),ver=l(),m6=a("li"),bfe=a("strong"),ber=o("rembert"),Ter=o(" \u2014 "),eD=a("a"),Fer=o("TFRemBertForTokenClassification"),Cer=o(" (RemBERT model)"),Eer=l(),g6=a("li"),Tfe=a("strong"),Mer=o("roberta"),yer=o(" \u2014 "),oD=a("a"),wer=o("TFRobertaForTokenClassification"),Aer=o(" (RoBERTa model)"),Ler=l(),h6=a("li"),Ffe=a("strong"),Ber=o("roformer"),ker=o(" \u2014 "),rD=a("a"),xer=o("TFRoFormerForTokenClassification"),Rer=o(" (RoFormer model)"),Ser=l(),u6=a("li"),Cfe=a("strong"),Per=o("xlm"),$er=o(" \u2014 "),tD=a("a"),Ier=o("TFXLMForTokenClassification"),jer=o(" (XLM model)"),Ner=l(),p6=a("li"),Efe=a("strong"),Der=o("xlm-roberta"),qer=o(" \u2014 "),aD=a("a"),Oer=o("TFXLMRobertaForTokenClassification"),Ger=o(" (XLM-RoBERTa model)"),zer=l(),_6=a("li"),Mfe=a("strong"),Ver=o("xlnet"),Xer=o(" \u2014 "),nD=a("a"),Wer=o("TFXLNetForTokenClassification"),Qer=o(" (XLNet model)"),Her=l(),yfe=a("p"),Uer=o("Examples:"),Jer=l(),f(rw.$$.fragment),TAe=l(),Zd=a("h2"),v6=a("a"),wfe=a("span"),f(tw.$$.fragment),Yer=l(),Afe=a("span"),Ker=o("TFAutoModelForQuestionAnswering"),FAe=l(),ur=a("div"),f(aw.$$.fragment),Zer=l(),ec=a("p"),eor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Lfe=a("code"),oor=o("from_pretrained()"),ror=o("class method or the "),Bfe=a("code"),tor=o("from_config()"),aor=o(`class
method.`),nor=l(),nw=a("p"),sor=o("This class cannot be instantiated directly using "),kfe=a("code"),lor=o("__init__()"),ior=o(" (throws an error)."),dor=l(),nt=a("div"),f(sw.$$.fragment),cor=l(),xfe=a("p"),mor=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),gor=l(),oc=a("p"),hor=o(`Note:
Loading a model from its configuration file does `),Rfe=a("strong"),uor=o("not"),por=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Sfe=a("code"),_or=o("from_pretrained()"),vor=o("to load the model weights."),bor=l(),Pfe=a("p"),Tor=o("Examples:"),For=l(),f(lw.$$.fragment),Cor=l(),To=a("div"),f(iw.$$.fragment),Eor=l(),$fe=a("p"),Mor=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),yor=l(),tn=a("p"),wor=o("The model class to instantiate is selected based on the "),Ife=a("code"),Aor=o("model_type"),Lor=o(` property of the config object (either
passed as an argument or loaded from `),jfe=a("code"),Bor=o("pretrained_model_name_or_path"),kor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nfe=a("code"),xor=o("pretrained_model_name_or_path"),Ror=o(":"),Sor=l(),Z=a("ul"),b6=a("li"),Dfe=a("strong"),Por=o("albert"),$or=o(" \u2014 "),sD=a("a"),Ior=o("TFAlbertForQuestionAnswering"),jor=o(" (ALBERT model)"),Nor=l(),T6=a("li"),qfe=a("strong"),Dor=o("bert"),qor=o(" \u2014 "),lD=a("a"),Oor=o("TFBertForQuestionAnswering"),Gor=o(" (BERT model)"),zor=l(),F6=a("li"),Ofe=a("strong"),Vor=o("camembert"),Xor=o(" \u2014 "),iD=a("a"),Wor=o("TFCamembertForQuestionAnswering"),Qor=o(" (CamemBERT model)"),Hor=l(),C6=a("li"),Gfe=a("strong"),Uor=o("convbert"),Jor=o(" \u2014 "),dD=a("a"),Yor=o("TFConvBertForQuestionAnswering"),Kor=o(" (ConvBERT model)"),Zor=l(),E6=a("li"),zfe=a("strong"),err=o("deberta"),orr=o(" \u2014 "),cD=a("a"),rrr=o("TFDebertaForQuestionAnswering"),trr=o(" (DeBERTa model)"),arr=l(),M6=a("li"),Vfe=a("strong"),nrr=o("deberta-v2"),srr=o(" \u2014 "),fD=a("a"),lrr=o("TFDebertaV2ForQuestionAnswering"),irr=o(" (DeBERTa-v2 model)"),drr=l(),y6=a("li"),Xfe=a("strong"),crr=o("distilbert"),frr=o(" \u2014 "),mD=a("a"),mrr=o("TFDistilBertForQuestionAnswering"),grr=o(" (DistilBERT model)"),hrr=l(),w6=a("li"),Wfe=a("strong"),urr=o("electra"),prr=o(" \u2014 "),gD=a("a"),_rr=o("TFElectraForQuestionAnswering"),vrr=o(" (ELECTRA model)"),brr=l(),A6=a("li"),Qfe=a("strong"),Trr=o("flaubert"),Frr=o(" \u2014 "),hD=a("a"),Crr=o("TFFlaubertForQuestionAnsweringSimple"),Err=o(" (FlauBERT model)"),Mrr=l(),L6=a("li"),Hfe=a("strong"),yrr=o("funnel"),wrr=o(" \u2014 "),uD=a("a"),Arr=o("TFFunnelForQuestionAnswering"),Lrr=o(" (Funnel Transformer model)"),Brr=l(),B6=a("li"),Ufe=a("strong"),krr=o("longformer"),xrr=o(" \u2014 "),pD=a("a"),Rrr=o("TFLongformerForQuestionAnswering"),Srr=o(" (Longformer model)"),Prr=l(),k6=a("li"),Jfe=a("strong"),$rr=o("mobilebert"),Irr=o(" \u2014 "),_D=a("a"),jrr=o("TFMobileBertForQuestionAnswering"),Nrr=o(" (MobileBERT model)"),Drr=l(),x6=a("li"),Yfe=a("strong"),qrr=o("mpnet"),Orr=o(" \u2014 "),vD=a("a"),Grr=o("TFMPNetForQuestionAnswering"),zrr=o(" (MPNet model)"),Vrr=l(),R6=a("li"),Kfe=a("strong"),Xrr=o("rembert"),Wrr=o(" \u2014 "),bD=a("a"),Qrr=o("TFRemBertForQuestionAnswering"),Hrr=o(" (RemBERT model)"),Urr=l(),S6=a("li"),Zfe=a("strong"),Jrr=o("roberta"),Yrr=o(" \u2014 "),TD=a("a"),Krr=o("TFRobertaForQuestionAnswering"),Zrr=o(" (RoBERTa model)"),etr=l(),P6=a("li"),eme=a("strong"),otr=o("roformer"),rtr=o(" \u2014 "),FD=a("a"),ttr=o("TFRoFormerForQuestionAnswering"),atr=o(" (RoFormer model)"),ntr=l(),$6=a("li"),ome=a("strong"),str=o("xlm"),ltr=o(" \u2014 "),CD=a("a"),itr=o("TFXLMForQuestionAnsweringSimple"),dtr=o(" (XLM model)"),ctr=l(),I6=a("li"),rme=a("strong"),ftr=o("xlm-roberta"),mtr=o(" \u2014 "),ED=a("a"),gtr=o("TFXLMRobertaForQuestionAnswering"),htr=o(" (XLM-RoBERTa model)"),utr=l(),j6=a("li"),tme=a("strong"),ptr=o("xlnet"),_tr=o(" \u2014 "),MD=a("a"),vtr=o("TFXLNetForQuestionAnsweringSimple"),btr=o(" (XLNet model)"),Ttr=l(),ame=a("p"),Ftr=o("Examples:"),Ctr=l(),f(dw.$$.fragment),CAe=l(),rc=a("h2"),N6=a("a"),nme=a("span"),f(cw.$$.fragment),Etr=l(),sme=a("span"),Mtr=o("TFAutoModelForVision2Seq"),EAe=l(),pr=a("div"),f(fw.$$.fragment),ytr=l(),tc=a("p"),wtr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),lme=a("code"),Atr=o("from_pretrained()"),Ltr=o("class method or the "),ime=a("code"),Btr=o("from_config()"),ktr=o(`class
method.`),xtr=l(),mw=a("p"),Rtr=o("This class cannot be instantiated directly using "),dme=a("code"),Str=o("__init__()"),Ptr=o(" (throws an error)."),$tr=l(),st=a("div"),f(gw.$$.fragment),Itr=l(),cme=a("p"),jtr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Ntr=l(),ac=a("p"),Dtr=o(`Note:
Loading a model from its configuration file does `),fme=a("strong"),qtr=o("not"),Otr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mme=a("code"),Gtr=o("from_pretrained()"),ztr=o("to load the model weights."),Vtr=l(),gme=a("p"),Xtr=o("Examples:"),Wtr=l(),f(hw.$$.fragment),Qtr=l(),Fo=a("div"),f(uw.$$.fragment),Htr=l(),hme=a("p"),Utr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Jtr=l(),an=a("p"),Ytr=o("The model class to instantiate is selected based on the "),ume=a("code"),Ktr=o("model_type"),Ztr=o(` property of the config object (either
passed as an argument or loaded from `),pme=a("code"),ear=o("pretrained_model_name_or_path"),oar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_me=a("code"),rar=o("pretrained_model_name_or_path"),tar=o(":"),aar=l(),vme=a("ul"),D6=a("li"),bme=a("strong"),nar=o("vision-encoder-decoder"),sar=o(" \u2014 "),yD=a("a"),lar=o("TFVisionEncoderDecoderModel"),iar=o(" (Vision Encoder decoder model)"),dar=l(),Tme=a("p"),car=o("Examples:"),far=l(),f(pw.$$.fragment),MAe=l(),nc=a("h2"),q6=a("a"),Fme=a("span"),f(_w.$$.fragment),mar=l(),Cme=a("span"),gar=o("FlaxAutoModel"),yAe=l(),_r=a("div"),f(vw.$$.fragment),har=l(),sc=a("p"),uar=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Eme=a("code"),par=o("from_pretrained()"),_ar=o("class method or the "),Mme=a("code"),bar=o("from_config()"),Tar=o(`class
method.`),Far=l(),bw=a("p"),Car=o("This class cannot be instantiated directly using "),yme=a("code"),Ear=o("__init__()"),Mar=o(" (throws an error)."),yar=l(),lt=a("div"),f(Tw.$$.fragment),war=l(),wme=a("p"),Aar=o("Instantiates one of the base model classes of the library from a configuration."),Lar=l(),lc=a("p"),Bar=o(`Note:
Loading a model from its configuration file does `),Ame=a("strong"),kar=o("not"),xar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lme=a("code"),Rar=o("from_pretrained()"),Sar=o("to load the model weights."),Par=l(),Bme=a("p"),$ar=o("Examples:"),Iar=l(),f(Fw.$$.fragment),jar=l(),Co=a("div"),f(Cw.$$.fragment),Nar=l(),kme=a("p"),Dar=o("Instantiate one of the base model classes of the library from a pretrained model."),qar=l(),nn=a("p"),Oar=o("The model class to instantiate is selected based on the "),xme=a("code"),Gar=o("model_type"),zar=o(` property of the config object (either
passed as an argument or loaded from `),Rme=a("code"),Var=o("pretrained_model_name_or_path"),Xar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sme=a("code"),War=o("pretrained_model_name_or_path"),Qar=o(":"),Har=l(),W=a("ul"),O6=a("li"),Pme=a("strong"),Uar=o("albert"),Jar=o(" \u2014 "),wD=a("a"),Yar=o("FlaxAlbertModel"),Kar=o(" (ALBERT model)"),Zar=l(),G6=a("li"),$me=a("strong"),enr=o("bart"),onr=o(" \u2014 "),AD=a("a"),rnr=o("FlaxBartModel"),tnr=o(" (BART model)"),anr=l(),z6=a("li"),Ime=a("strong"),nnr=o("beit"),snr=o(" \u2014 "),LD=a("a"),lnr=o("FlaxBeitModel"),inr=o(" (BEiT model)"),dnr=l(),V6=a("li"),jme=a("strong"),cnr=o("bert"),fnr=o(" \u2014 "),BD=a("a"),mnr=o("FlaxBertModel"),gnr=o(" (BERT model)"),hnr=l(),X6=a("li"),Nme=a("strong"),unr=o("big_bird"),pnr=o(" \u2014 "),kD=a("a"),_nr=o("FlaxBigBirdModel"),vnr=o(" (BigBird model)"),bnr=l(),W6=a("li"),Dme=a("strong"),Tnr=o("blenderbot"),Fnr=o(" \u2014 "),xD=a("a"),Cnr=o("FlaxBlenderbotModel"),Enr=o(" (Blenderbot model)"),Mnr=l(),Q6=a("li"),qme=a("strong"),ynr=o("blenderbot-small"),wnr=o(" \u2014 "),RD=a("a"),Anr=o("FlaxBlenderbotSmallModel"),Lnr=o(" (BlenderbotSmall model)"),Bnr=l(),H6=a("li"),Ome=a("strong"),knr=o("clip"),xnr=o(" \u2014 "),SD=a("a"),Rnr=o("FlaxCLIPModel"),Snr=o(" (CLIP model)"),Pnr=l(),U6=a("li"),Gme=a("strong"),$nr=o("distilbert"),Inr=o(" \u2014 "),PD=a("a"),jnr=o("FlaxDistilBertModel"),Nnr=o(" (DistilBERT model)"),Dnr=l(),J6=a("li"),zme=a("strong"),qnr=o("electra"),Onr=o(" \u2014 "),$D=a("a"),Gnr=o("FlaxElectraModel"),znr=o(" (ELECTRA model)"),Vnr=l(),Y6=a("li"),Vme=a("strong"),Xnr=o("gpt2"),Wnr=o(" \u2014 "),ID=a("a"),Qnr=o("FlaxGPT2Model"),Hnr=o(" (OpenAI GPT-2 model)"),Unr=l(),K6=a("li"),Xme=a("strong"),Jnr=o("gpt_neo"),Ynr=o(" \u2014 "),jD=a("a"),Knr=o("FlaxGPTNeoModel"),Znr=o(" (GPT Neo model)"),esr=l(),Z6=a("li"),Wme=a("strong"),osr=o("gptj"),rsr=o(" \u2014 "),ND=a("a"),tsr=o("FlaxGPTJModel"),asr=o(" (GPT-J model)"),nsr=l(),eF=a("li"),Qme=a("strong"),ssr=o("marian"),lsr=o(" \u2014 "),DD=a("a"),isr=o("FlaxMarianModel"),dsr=o(" (Marian model)"),csr=l(),oF=a("li"),Hme=a("strong"),fsr=o("mbart"),msr=o(" \u2014 "),qD=a("a"),gsr=o("FlaxMBartModel"),hsr=o(" (mBART model)"),usr=l(),rF=a("li"),Ume=a("strong"),psr=o("mt5"),_sr=o(" \u2014 "),OD=a("a"),vsr=o("FlaxMT5Model"),bsr=o(" (mT5 model)"),Tsr=l(),tF=a("li"),Jme=a("strong"),Fsr=o("pegasus"),Csr=o(" \u2014 "),GD=a("a"),Esr=o("FlaxPegasusModel"),Msr=o(" (Pegasus model)"),ysr=l(),aF=a("li"),Yme=a("strong"),wsr=o("roberta"),Asr=o(" \u2014 "),zD=a("a"),Lsr=o("FlaxRobertaModel"),Bsr=o(" (RoBERTa model)"),ksr=l(),nF=a("li"),Kme=a("strong"),xsr=o("roformer"),Rsr=o(" \u2014 "),VD=a("a"),Ssr=o("FlaxRoFormerModel"),Psr=o(" (RoFormer model)"),$sr=l(),sF=a("li"),Zme=a("strong"),Isr=o("t5"),jsr=o(" \u2014 "),XD=a("a"),Nsr=o("FlaxT5Model"),Dsr=o(" (T5 model)"),qsr=l(),lF=a("li"),ege=a("strong"),Osr=o("vision-text-dual-encoder"),Gsr=o(" \u2014 "),WD=a("a"),zsr=o("FlaxVisionTextDualEncoderModel"),Vsr=o(" (VisionTextDualEncoder model)"),Xsr=l(),iF=a("li"),oge=a("strong"),Wsr=o("vit"),Qsr=o(" \u2014 "),QD=a("a"),Hsr=o("FlaxViTModel"),Usr=o(" (ViT model)"),Jsr=l(),dF=a("li"),rge=a("strong"),Ysr=o("wav2vec2"),Ksr=o(" \u2014 "),HD=a("a"),Zsr=o("FlaxWav2Vec2Model"),elr=o(" (Wav2Vec2 model)"),olr=l(),tge=a("p"),rlr=o("Examples:"),tlr=l(),f(Ew.$$.fragment),wAe=l(),ic=a("h2"),cF=a("a"),age=a("span"),f(Mw.$$.fragment),alr=l(),nge=a("span"),nlr=o("FlaxAutoModelForCausalLM"),AAe=l(),vr=a("div"),f(yw.$$.fragment),slr=l(),dc=a("p"),llr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),sge=a("code"),ilr=o("from_pretrained()"),dlr=o("class method or the "),lge=a("code"),clr=o("from_config()"),flr=o(`class
method.`),mlr=l(),ww=a("p"),glr=o("This class cannot be instantiated directly using "),ige=a("code"),hlr=o("__init__()"),ulr=o(" (throws an error)."),plr=l(),it=a("div"),f(Aw.$$.fragment),_lr=l(),dge=a("p"),vlr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),blr=l(),cc=a("p"),Tlr=o(`Note:
Loading a model from its configuration file does `),cge=a("strong"),Flr=o("not"),Clr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fge=a("code"),Elr=o("from_pretrained()"),Mlr=o("to load the model weights."),ylr=l(),mge=a("p"),wlr=o("Examples:"),Alr=l(),f(Lw.$$.fragment),Llr=l(),Eo=a("div"),f(Bw.$$.fragment),Blr=l(),gge=a("p"),klr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),xlr=l(),sn=a("p"),Rlr=o("The model class to instantiate is selected based on the "),hge=a("code"),Slr=o("model_type"),Plr=o(` property of the config object (either
passed as an argument or loaded from `),uge=a("code"),$lr=o("pretrained_model_name_or_path"),Ilr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pge=a("code"),jlr=o("pretrained_model_name_or_path"),Nlr=o(":"),Dlr=l(),fc=a("ul"),fF=a("li"),_ge=a("strong"),qlr=o("gpt2"),Olr=o(" \u2014 "),UD=a("a"),Glr=o("FlaxGPT2LMHeadModel"),zlr=o(" (OpenAI GPT-2 model)"),Vlr=l(),mF=a("li"),vge=a("strong"),Xlr=o("gpt_neo"),Wlr=o(" \u2014 "),JD=a("a"),Qlr=o("FlaxGPTNeoForCausalLM"),Hlr=o(" (GPT Neo model)"),Ulr=l(),gF=a("li"),bge=a("strong"),Jlr=o("gptj"),Ylr=o(" \u2014 "),YD=a("a"),Klr=o("FlaxGPTJForCausalLM"),Zlr=o(" (GPT-J model)"),eir=l(),Tge=a("p"),oir=o("Examples:"),rir=l(),f(kw.$$.fragment),LAe=l(),mc=a("h2"),hF=a("a"),Fge=a("span"),f(xw.$$.fragment),tir=l(),Cge=a("span"),air=o("FlaxAutoModelForPreTraining"),BAe=l(),br=a("div"),f(Rw.$$.fragment),nir=l(),gc=a("p"),sir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Ege=a("code"),lir=o("from_pretrained()"),iir=o("class method or the "),Mge=a("code"),dir=o("from_config()"),cir=o(`class
method.`),fir=l(),Sw=a("p"),mir=o("This class cannot be instantiated directly using "),yge=a("code"),gir=o("__init__()"),hir=o(" (throws an error)."),uir=l(),dt=a("div"),f(Pw.$$.fragment),pir=l(),wge=a("p"),_ir=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),vir=l(),hc=a("p"),bir=o(`Note:
Loading a model from its configuration file does `),Age=a("strong"),Tir=o("not"),Fir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lge=a("code"),Cir=o("from_pretrained()"),Eir=o("to load the model weights."),Mir=l(),Bge=a("p"),yir=o("Examples:"),wir=l(),f($w.$$.fragment),Air=l(),Mo=a("div"),f(Iw.$$.fragment),Lir=l(),kge=a("p"),Bir=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),kir=l(),ln=a("p"),xir=o("The model class to instantiate is selected based on the "),xge=a("code"),Rir=o("model_type"),Sir=o(` property of the config object (either
passed as an argument or loaded from `),Rge=a("code"),Pir=o("pretrained_model_name_or_path"),$ir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sge=a("code"),Iir=o("pretrained_model_name_or_path"),jir=o(":"),Nir=l(),ce=a("ul"),uF=a("li"),Pge=a("strong"),Dir=o("albert"),qir=o(" \u2014 "),KD=a("a"),Oir=o("FlaxAlbertForPreTraining"),Gir=o(" (ALBERT model)"),zir=l(),pF=a("li"),$ge=a("strong"),Vir=o("bart"),Xir=o(" \u2014 "),ZD=a("a"),Wir=o("FlaxBartForConditionalGeneration"),Qir=o(" (BART model)"),Hir=l(),_F=a("li"),Ige=a("strong"),Uir=o("bert"),Jir=o(" \u2014 "),eq=a("a"),Yir=o("FlaxBertForPreTraining"),Kir=o(" (BERT model)"),Zir=l(),vF=a("li"),jge=a("strong"),edr=o("big_bird"),odr=o(" \u2014 "),oq=a("a"),rdr=o("FlaxBigBirdForPreTraining"),tdr=o(" (BigBird model)"),adr=l(),bF=a("li"),Nge=a("strong"),ndr=o("electra"),sdr=o(" \u2014 "),rq=a("a"),ldr=o("FlaxElectraForPreTraining"),idr=o(" (ELECTRA model)"),ddr=l(),TF=a("li"),Dge=a("strong"),cdr=o("mbart"),fdr=o(" \u2014 "),tq=a("a"),mdr=o("FlaxMBartForConditionalGeneration"),gdr=o(" (mBART model)"),hdr=l(),FF=a("li"),qge=a("strong"),udr=o("mt5"),pdr=o(" \u2014 "),aq=a("a"),_dr=o("FlaxMT5ForConditionalGeneration"),vdr=o(" (mT5 model)"),bdr=l(),CF=a("li"),Oge=a("strong"),Tdr=o("roberta"),Fdr=o(" \u2014 "),nq=a("a"),Cdr=o("FlaxRobertaForMaskedLM"),Edr=o(" (RoBERTa model)"),Mdr=l(),EF=a("li"),Gge=a("strong"),ydr=o("roformer"),wdr=o(" \u2014 "),sq=a("a"),Adr=o("FlaxRoFormerForMaskedLM"),Ldr=o(" (RoFormer model)"),Bdr=l(),MF=a("li"),zge=a("strong"),kdr=o("t5"),xdr=o(" \u2014 "),lq=a("a"),Rdr=o("FlaxT5ForConditionalGeneration"),Sdr=o(" (T5 model)"),Pdr=l(),yF=a("li"),Vge=a("strong"),$dr=o("wav2vec2"),Idr=o(" \u2014 "),iq=a("a"),jdr=o("FlaxWav2Vec2ForPreTraining"),Ndr=o(" (Wav2Vec2 model)"),Ddr=l(),Xge=a("p"),qdr=o("Examples:"),Odr=l(),f(jw.$$.fragment),kAe=l(),uc=a("h2"),wF=a("a"),Wge=a("span"),f(Nw.$$.fragment),Gdr=l(),Qge=a("span"),zdr=o("FlaxAutoModelForMaskedLM"),xAe=l(),Tr=a("div"),f(Dw.$$.fragment),Vdr=l(),pc=a("p"),Xdr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Hge=a("code"),Wdr=o("from_pretrained()"),Qdr=o("class method or the "),Uge=a("code"),Hdr=o("from_config()"),Udr=o(`class
method.`),Jdr=l(),qw=a("p"),Ydr=o("This class cannot be instantiated directly using "),Jge=a("code"),Kdr=o("__init__()"),Zdr=o(" (throws an error)."),ecr=l(),ct=a("div"),f(Ow.$$.fragment),ocr=l(),Yge=a("p"),rcr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),tcr=l(),_c=a("p"),acr=o(`Note:
Loading a model from its configuration file does `),Kge=a("strong"),ncr=o("not"),scr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zge=a("code"),lcr=o("from_pretrained()"),icr=o("to load the model weights."),dcr=l(),ehe=a("p"),ccr=o("Examples:"),fcr=l(),f(Gw.$$.fragment),mcr=l(),yo=a("div"),f(zw.$$.fragment),gcr=l(),ohe=a("p"),hcr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),ucr=l(),dn=a("p"),pcr=o("The model class to instantiate is selected based on the "),rhe=a("code"),_cr=o("model_type"),vcr=o(` property of the config object (either
passed as an argument or loaded from `),the=a("code"),bcr=o("pretrained_model_name_or_path"),Tcr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ahe=a("code"),Fcr=o("pretrained_model_name_or_path"),Ccr=o(":"),Ecr=l(),ve=a("ul"),AF=a("li"),nhe=a("strong"),Mcr=o("albert"),ycr=o(" \u2014 "),dq=a("a"),wcr=o("FlaxAlbertForMaskedLM"),Acr=o(" (ALBERT model)"),Lcr=l(),LF=a("li"),she=a("strong"),Bcr=o("bart"),kcr=o(" \u2014 "),cq=a("a"),xcr=o("FlaxBartForConditionalGeneration"),Rcr=o(" (BART model)"),Scr=l(),BF=a("li"),lhe=a("strong"),Pcr=o("bert"),$cr=o(" \u2014 "),fq=a("a"),Icr=o("FlaxBertForMaskedLM"),jcr=o(" (BERT model)"),Ncr=l(),kF=a("li"),ihe=a("strong"),Dcr=o("big_bird"),qcr=o(" \u2014 "),mq=a("a"),Ocr=o("FlaxBigBirdForMaskedLM"),Gcr=o(" (BigBird model)"),zcr=l(),xF=a("li"),dhe=a("strong"),Vcr=o("distilbert"),Xcr=o(" \u2014 "),gq=a("a"),Wcr=o("FlaxDistilBertForMaskedLM"),Qcr=o(" (DistilBERT model)"),Hcr=l(),RF=a("li"),che=a("strong"),Ucr=o("electra"),Jcr=o(" \u2014 "),hq=a("a"),Ycr=o("FlaxElectraForMaskedLM"),Kcr=o(" (ELECTRA model)"),Zcr=l(),SF=a("li"),fhe=a("strong"),efr=o("mbart"),ofr=o(" \u2014 "),uq=a("a"),rfr=o("FlaxMBartForConditionalGeneration"),tfr=o(" (mBART model)"),afr=l(),PF=a("li"),mhe=a("strong"),nfr=o("roberta"),sfr=o(" \u2014 "),pq=a("a"),lfr=o("FlaxRobertaForMaskedLM"),ifr=o(" (RoBERTa model)"),dfr=l(),$F=a("li"),ghe=a("strong"),cfr=o("roformer"),ffr=o(" \u2014 "),_q=a("a"),mfr=o("FlaxRoFormerForMaskedLM"),gfr=o(" (RoFormer model)"),hfr=l(),hhe=a("p"),ufr=o("Examples:"),pfr=l(),f(Vw.$$.fragment),RAe=l(),vc=a("h2"),IF=a("a"),uhe=a("span"),f(Xw.$$.fragment),_fr=l(),phe=a("span"),vfr=o("FlaxAutoModelForSeq2SeqLM"),SAe=l(),Fr=a("div"),f(Ww.$$.fragment),bfr=l(),bc=a("p"),Tfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),_he=a("code"),Ffr=o("from_pretrained()"),Cfr=o("class method or the "),vhe=a("code"),Efr=o("from_config()"),Mfr=o(`class
method.`),yfr=l(),Qw=a("p"),wfr=o("This class cannot be instantiated directly using "),bhe=a("code"),Afr=o("__init__()"),Lfr=o(" (throws an error)."),Bfr=l(),ft=a("div"),f(Hw.$$.fragment),kfr=l(),The=a("p"),xfr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Rfr=l(),Tc=a("p"),Sfr=o(`Note:
Loading a model from its configuration file does `),Fhe=a("strong"),Pfr=o("not"),$fr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Che=a("code"),Ifr=o("from_pretrained()"),jfr=o("to load the model weights."),Nfr=l(),Ehe=a("p"),Dfr=o("Examples:"),qfr=l(),f(Uw.$$.fragment),Ofr=l(),wo=a("div"),f(Jw.$$.fragment),Gfr=l(),Mhe=a("p"),zfr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Vfr=l(),cn=a("p"),Xfr=o("The model class to instantiate is selected based on the "),yhe=a("code"),Wfr=o("model_type"),Qfr=o(` property of the config object (either
passed as an argument or loaded from `),whe=a("code"),Hfr=o("pretrained_model_name_or_path"),Ufr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ahe=a("code"),Jfr=o("pretrained_model_name_or_path"),Yfr=o(":"),Kfr=l(),be=a("ul"),jF=a("li"),Lhe=a("strong"),Zfr=o("bart"),emr=o(" \u2014 "),vq=a("a"),omr=o("FlaxBartForConditionalGeneration"),rmr=o(" (BART model)"),tmr=l(),NF=a("li"),Bhe=a("strong"),amr=o("blenderbot"),nmr=o(" \u2014 "),bq=a("a"),smr=o("FlaxBlenderbotForConditionalGeneration"),lmr=o(" (Blenderbot model)"),imr=l(),DF=a("li"),khe=a("strong"),dmr=o("blenderbot-small"),cmr=o(" \u2014 "),Tq=a("a"),fmr=o("FlaxBlenderbotSmallForConditionalGeneration"),mmr=o(" (BlenderbotSmall model)"),gmr=l(),qF=a("li"),xhe=a("strong"),hmr=o("encoder-decoder"),umr=o(" \u2014 "),Fq=a("a"),pmr=o("FlaxEncoderDecoderModel"),_mr=o(" (Encoder decoder model)"),vmr=l(),OF=a("li"),Rhe=a("strong"),bmr=o("marian"),Tmr=o(" \u2014 "),Cq=a("a"),Fmr=o("FlaxMarianMTModel"),Cmr=o(" (Marian model)"),Emr=l(),GF=a("li"),She=a("strong"),Mmr=o("mbart"),ymr=o(" \u2014 "),Eq=a("a"),wmr=o("FlaxMBartForConditionalGeneration"),Amr=o(" (mBART model)"),Lmr=l(),zF=a("li"),Phe=a("strong"),Bmr=o("mt5"),kmr=o(" \u2014 "),Mq=a("a"),xmr=o("FlaxMT5ForConditionalGeneration"),Rmr=o(" (mT5 model)"),Smr=l(),VF=a("li"),$he=a("strong"),Pmr=o("pegasus"),$mr=o(" \u2014 "),yq=a("a"),Imr=o("FlaxPegasusForConditionalGeneration"),jmr=o(" (Pegasus model)"),Nmr=l(),XF=a("li"),Ihe=a("strong"),Dmr=o("t5"),qmr=o(" \u2014 "),wq=a("a"),Omr=o("FlaxT5ForConditionalGeneration"),Gmr=o(" (T5 model)"),zmr=l(),jhe=a("p"),Vmr=o("Examples:"),Xmr=l(),f(Yw.$$.fragment),PAe=l(),Fc=a("h2"),WF=a("a"),Nhe=a("span"),f(Kw.$$.fragment),Wmr=l(),Dhe=a("span"),Qmr=o("FlaxAutoModelForSequenceClassification"),$Ae=l(),Cr=a("div"),f(Zw.$$.fragment),Hmr=l(),Cc=a("p"),Umr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),qhe=a("code"),Jmr=o("from_pretrained()"),Ymr=o("class method or the "),Ohe=a("code"),Kmr=o("from_config()"),Zmr=o(`class
method.`),egr=l(),eA=a("p"),ogr=o("This class cannot be instantiated directly using "),Ghe=a("code"),rgr=o("__init__()"),tgr=o(" (throws an error)."),agr=l(),mt=a("div"),f(oA.$$.fragment),ngr=l(),zhe=a("p"),sgr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),lgr=l(),Ec=a("p"),igr=o(`Note:
Loading a model from its configuration file does `),Vhe=a("strong"),dgr=o("not"),cgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xhe=a("code"),fgr=o("from_pretrained()"),mgr=o("to load the model weights."),ggr=l(),Whe=a("p"),hgr=o("Examples:"),ugr=l(),f(rA.$$.fragment),pgr=l(),Ao=a("div"),f(tA.$$.fragment),_gr=l(),Qhe=a("p"),vgr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),bgr=l(),fn=a("p"),Tgr=o("The model class to instantiate is selected based on the "),Hhe=a("code"),Fgr=o("model_type"),Cgr=o(` property of the config object (either
passed as an argument or loaded from `),Uhe=a("code"),Egr=o("pretrained_model_name_or_path"),Mgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jhe=a("code"),ygr=o("pretrained_model_name_or_path"),wgr=o(":"),Agr=l(),Te=a("ul"),QF=a("li"),Yhe=a("strong"),Lgr=o("albert"),Bgr=o(" \u2014 "),Aq=a("a"),kgr=o("FlaxAlbertForSequenceClassification"),xgr=o(" (ALBERT model)"),Rgr=l(),HF=a("li"),Khe=a("strong"),Sgr=o("bart"),Pgr=o(" \u2014 "),Lq=a("a"),$gr=o("FlaxBartForSequenceClassification"),Igr=o(" (BART model)"),jgr=l(),UF=a("li"),Zhe=a("strong"),Ngr=o("bert"),Dgr=o(" \u2014 "),Bq=a("a"),qgr=o("FlaxBertForSequenceClassification"),Ogr=o(" (BERT model)"),Ggr=l(),JF=a("li"),eue=a("strong"),zgr=o("big_bird"),Vgr=o(" \u2014 "),kq=a("a"),Xgr=o("FlaxBigBirdForSequenceClassification"),Wgr=o(" (BigBird model)"),Qgr=l(),YF=a("li"),oue=a("strong"),Hgr=o("distilbert"),Ugr=o(" \u2014 "),xq=a("a"),Jgr=o("FlaxDistilBertForSequenceClassification"),Ygr=o(" (DistilBERT model)"),Kgr=l(),KF=a("li"),rue=a("strong"),Zgr=o("electra"),ehr=o(" \u2014 "),Rq=a("a"),ohr=o("FlaxElectraForSequenceClassification"),rhr=o(" (ELECTRA model)"),thr=l(),ZF=a("li"),tue=a("strong"),ahr=o("mbart"),nhr=o(" \u2014 "),Sq=a("a"),shr=o("FlaxMBartForSequenceClassification"),lhr=o(" (mBART model)"),ihr=l(),eC=a("li"),aue=a("strong"),dhr=o("roberta"),chr=o(" \u2014 "),Pq=a("a"),fhr=o("FlaxRobertaForSequenceClassification"),mhr=o(" (RoBERTa model)"),ghr=l(),oC=a("li"),nue=a("strong"),hhr=o("roformer"),uhr=o(" \u2014 "),$q=a("a"),phr=o("FlaxRoFormerForSequenceClassification"),_hr=o(" (RoFormer model)"),vhr=l(),sue=a("p"),bhr=o("Examples:"),Thr=l(),f(aA.$$.fragment),IAe=l(),Mc=a("h2"),rC=a("a"),lue=a("span"),f(nA.$$.fragment),Fhr=l(),iue=a("span"),Chr=o("FlaxAutoModelForQuestionAnswering"),jAe=l(),Er=a("div"),f(sA.$$.fragment),Ehr=l(),yc=a("p"),Mhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),due=a("code"),yhr=o("from_pretrained()"),whr=o("class method or the "),cue=a("code"),Ahr=o("from_config()"),Lhr=o(`class
method.`),Bhr=l(),lA=a("p"),khr=o("This class cannot be instantiated directly using "),fue=a("code"),xhr=o("__init__()"),Rhr=o(" (throws an error)."),Shr=l(),gt=a("div"),f(iA.$$.fragment),Phr=l(),mue=a("p"),$hr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Ihr=l(),wc=a("p"),jhr=o(`Note:
Loading a model from its configuration file does `),gue=a("strong"),Nhr=o("not"),Dhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hue=a("code"),qhr=o("from_pretrained()"),Ohr=o("to load the model weights."),Ghr=l(),uue=a("p"),zhr=o("Examples:"),Vhr=l(),f(dA.$$.fragment),Xhr=l(),Lo=a("div"),f(cA.$$.fragment),Whr=l(),pue=a("p"),Qhr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Hhr=l(),mn=a("p"),Uhr=o("The model class to instantiate is selected based on the "),_ue=a("code"),Jhr=o("model_type"),Yhr=o(` property of the config object (either
passed as an argument or loaded from `),vue=a("code"),Khr=o("pretrained_model_name_or_path"),Zhr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bue=a("code"),eur=o("pretrained_model_name_or_path"),our=o(":"),rur=l(),Fe=a("ul"),tC=a("li"),Tue=a("strong"),tur=o("albert"),aur=o(" \u2014 "),Iq=a("a"),nur=o("FlaxAlbertForQuestionAnswering"),sur=o(" (ALBERT model)"),lur=l(),aC=a("li"),Fue=a("strong"),iur=o("bart"),dur=o(" \u2014 "),jq=a("a"),cur=o("FlaxBartForQuestionAnswering"),fur=o(" (BART model)"),mur=l(),nC=a("li"),Cue=a("strong"),gur=o("bert"),hur=o(" \u2014 "),Nq=a("a"),uur=o("FlaxBertForQuestionAnswering"),pur=o(" (BERT model)"),_ur=l(),sC=a("li"),Eue=a("strong"),vur=o("big_bird"),bur=o(" \u2014 "),Dq=a("a"),Tur=o("FlaxBigBirdForQuestionAnswering"),Fur=o(" (BigBird model)"),Cur=l(),lC=a("li"),Mue=a("strong"),Eur=o("distilbert"),Mur=o(" \u2014 "),qq=a("a"),yur=o("FlaxDistilBertForQuestionAnswering"),wur=o(" (DistilBERT model)"),Aur=l(),iC=a("li"),yue=a("strong"),Lur=o("electra"),Bur=o(" \u2014 "),Oq=a("a"),kur=o("FlaxElectraForQuestionAnswering"),xur=o(" (ELECTRA model)"),Rur=l(),dC=a("li"),wue=a("strong"),Sur=o("mbart"),Pur=o(" \u2014 "),Gq=a("a"),$ur=o("FlaxMBartForQuestionAnswering"),Iur=o(" (mBART model)"),jur=l(),cC=a("li"),Aue=a("strong"),Nur=o("roberta"),Dur=o(" \u2014 "),zq=a("a"),qur=o("FlaxRobertaForQuestionAnswering"),Our=o(" (RoBERTa model)"),Gur=l(),fC=a("li"),Lue=a("strong"),zur=o("roformer"),Vur=o(" \u2014 "),Vq=a("a"),Xur=o("FlaxRoFormerForQuestionAnswering"),Wur=o(" (RoFormer model)"),Qur=l(),Bue=a("p"),Hur=o("Examples:"),Uur=l(),f(fA.$$.fragment),NAe=l(),Ac=a("h2"),mC=a("a"),kue=a("span"),f(mA.$$.fragment),Jur=l(),xue=a("span"),Yur=o("FlaxAutoModelForTokenClassification"),DAe=l(),Mr=a("div"),f(gA.$$.fragment),Kur=l(),Lc=a("p"),Zur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Rue=a("code"),epr=o("from_pretrained()"),opr=o("class method or the "),Sue=a("code"),rpr=o("from_config()"),tpr=o(`class
method.`),apr=l(),hA=a("p"),npr=o("This class cannot be instantiated directly using "),Pue=a("code"),spr=o("__init__()"),lpr=o(" (throws an error)."),ipr=l(),ht=a("div"),f(uA.$$.fragment),dpr=l(),$ue=a("p"),cpr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),fpr=l(),Bc=a("p"),mpr=o(`Note:
Loading a model from its configuration file does `),Iue=a("strong"),gpr=o("not"),hpr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jue=a("code"),upr=o("from_pretrained()"),ppr=o("to load the model weights."),_pr=l(),Nue=a("p"),vpr=o("Examples:"),bpr=l(),f(pA.$$.fragment),Tpr=l(),Bo=a("div"),f(_A.$$.fragment),Fpr=l(),Due=a("p"),Cpr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Epr=l(),gn=a("p"),Mpr=o("The model class to instantiate is selected based on the "),que=a("code"),ypr=o("model_type"),wpr=o(` property of the config object (either
passed as an argument or loaded from `),Oue=a("code"),Apr=o("pretrained_model_name_or_path"),Lpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gue=a("code"),Bpr=o("pretrained_model_name_or_path"),kpr=o(":"),xpr=l(),to=a("ul"),gC=a("li"),zue=a("strong"),Rpr=o("albert"),Spr=o(" \u2014 "),Xq=a("a"),Ppr=o("FlaxAlbertForTokenClassification"),$pr=o(" (ALBERT model)"),Ipr=l(),hC=a("li"),Vue=a("strong"),jpr=o("bert"),Npr=o(" \u2014 "),Wq=a("a"),Dpr=o("FlaxBertForTokenClassification"),qpr=o(" (BERT model)"),Opr=l(),uC=a("li"),Xue=a("strong"),Gpr=o("big_bird"),zpr=o(" \u2014 "),Qq=a("a"),Vpr=o("FlaxBigBirdForTokenClassification"),Xpr=o(" (BigBird model)"),Wpr=l(),pC=a("li"),Wue=a("strong"),Qpr=o("distilbert"),Hpr=o(" \u2014 "),Hq=a("a"),Upr=o("FlaxDistilBertForTokenClassification"),Jpr=o(" (DistilBERT model)"),Ypr=l(),_C=a("li"),Que=a("strong"),Kpr=o("electra"),Zpr=o(" \u2014 "),Uq=a("a"),e_r=o("FlaxElectraForTokenClassification"),o_r=o(" (ELECTRA model)"),r_r=l(),vC=a("li"),Hue=a("strong"),t_r=o("roberta"),a_r=o(" \u2014 "),Jq=a("a"),n_r=o("FlaxRobertaForTokenClassification"),s_r=o(" (RoBERTa model)"),l_r=l(),bC=a("li"),Uue=a("strong"),i_r=o("roformer"),d_r=o(" \u2014 "),Yq=a("a"),c_r=o("FlaxRoFormerForTokenClassification"),f_r=o(" (RoFormer model)"),m_r=l(),Jue=a("p"),g_r=o("Examples:"),h_r=l(),f(vA.$$.fragment),qAe=l(),kc=a("h2"),TC=a("a"),Yue=a("span"),f(bA.$$.fragment),u_r=l(),Kue=a("span"),p_r=o("FlaxAutoModelForMultipleChoice"),OAe=l(),yr=a("div"),f(TA.$$.fragment),__r=l(),xc=a("p"),v_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Zue=a("code"),b_r=o("from_pretrained()"),T_r=o("class method or the "),epe=a("code"),F_r=o("from_config()"),C_r=o(`class
method.`),E_r=l(),FA=a("p"),M_r=o("This class cannot be instantiated directly using "),ope=a("code"),y_r=o("__init__()"),w_r=o(" (throws an error)."),A_r=l(),ut=a("div"),f(CA.$$.fragment),L_r=l(),rpe=a("p"),B_r=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),k_r=l(),Rc=a("p"),x_r=o(`Note:
Loading a model from its configuration file does `),tpe=a("strong"),R_r=o("not"),S_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ape=a("code"),P_r=o("from_pretrained()"),$_r=o("to load the model weights."),I_r=l(),npe=a("p"),j_r=o("Examples:"),N_r=l(),f(EA.$$.fragment),D_r=l(),ko=a("div"),f(MA.$$.fragment),q_r=l(),spe=a("p"),O_r=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),G_r=l(),hn=a("p"),z_r=o("The model class to instantiate is selected based on the "),lpe=a("code"),V_r=o("model_type"),X_r=o(` property of the config object (either
passed as an argument or loaded from `),ipe=a("code"),W_r=o("pretrained_model_name_or_path"),Q_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dpe=a("code"),H_r=o("pretrained_model_name_or_path"),U_r=o(":"),J_r=l(),ao=a("ul"),FC=a("li"),cpe=a("strong"),Y_r=o("albert"),K_r=o(" \u2014 "),Kq=a("a"),Z_r=o("FlaxAlbertForMultipleChoice"),e2r=o(" (ALBERT model)"),o2r=l(),CC=a("li"),fpe=a("strong"),r2r=o("bert"),t2r=o(" \u2014 "),Zq=a("a"),a2r=o("FlaxBertForMultipleChoice"),n2r=o(" (BERT model)"),s2r=l(),EC=a("li"),mpe=a("strong"),l2r=o("big_bird"),i2r=o(" \u2014 "),eO=a("a"),d2r=o("FlaxBigBirdForMultipleChoice"),c2r=o(" (BigBird model)"),f2r=l(),MC=a("li"),gpe=a("strong"),m2r=o("distilbert"),g2r=o(" \u2014 "),oO=a("a"),h2r=o("FlaxDistilBertForMultipleChoice"),u2r=o(" (DistilBERT model)"),p2r=l(),yC=a("li"),hpe=a("strong"),_2r=o("electra"),v2r=o(" \u2014 "),rO=a("a"),b2r=o("FlaxElectraForMultipleChoice"),T2r=o(" (ELECTRA model)"),F2r=l(),wC=a("li"),upe=a("strong"),C2r=o("roberta"),E2r=o(" \u2014 "),tO=a("a"),M2r=o("FlaxRobertaForMultipleChoice"),y2r=o(" (RoBERTa model)"),w2r=l(),AC=a("li"),ppe=a("strong"),A2r=o("roformer"),L2r=o(" \u2014 "),aO=a("a"),B2r=o("FlaxRoFormerForMultipleChoice"),k2r=o(" (RoFormer model)"),x2r=l(),_pe=a("p"),R2r=o("Examples:"),S2r=l(),f(yA.$$.fragment),GAe=l(),Sc=a("h2"),LC=a("a"),vpe=a("span"),f(wA.$$.fragment),P2r=l(),bpe=a("span"),$2r=o("FlaxAutoModelForNextSentencePrediction"),zAe=l(),wr=a("div"),f(AA.$$.fragment),I2r=l(),Pc=a("p"),j2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Tpe=a("code"),N2r=o("from_pretrained()"),D2r=o("class method or the "),Fpe=a("code"),q2r=o("from_config()"),O2r=o(`class
method.`),G2r=l(),LA=a("p"),z2r=o("This class cannot be instantiated directly using "),Cpe=a("code"),V2r=o("__init__()"),X2r=o(" (throws an error)."),W2r=l(),pt=a("div"),f(BA.$$.fragment),Q2r=l(),Epe=a("p"),H2r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),U2r=l(),$c=a("p"),J2r=o(`Note:
Loading a model from its configuration file does `),Mpe=a("strong"),Y2r=o("not"),K2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ype=a("code"),Z2r=o("from_pretrained()"),evr=o("to load the model weights."),ovr=l(),wpe=a("p"),rvr=o("Examples:"),tvr=l(),f(kA.$$.fragment),avr=l(),xo=a("div"),f(xA.$$.fragment),nvr=l(),Ape=a("p"),svr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),lvr=l(),un=a("p"),ivr=o("The model class to instantiate is selected based on the "),Lpe=a("code"),dvr=o("model_type"),cvr=o(` property of the config object (either
passed as an argument or loaded from `),Bpe=a("code"),fvr=o("pretrained_model_name_or_path"),mvr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kpe=a("code"),gvr=o("pretrained_model_name_or_path"),hvr=o(":"),uvr=l(),xpe=a("ul"),BC=a("li"),Rpe=a("strong"),pvr=o("bert"),_vr=o(" \u2014 "),nO=a("a"),vvr=o("FlaxBertForNextSentencePrediction"),bvr=o(" (BERT model)"),Tvr=l(),Spe=a("p"),Fvr=o("Examples:"),Cvr=l(),f(RA.$$.fragment),VAe=l(),Ic=a("h2"),kC=a("a"),Ppe=a("span"),f(SA.$$.fragment),Evr=l(),$pe=a("span"),Mvr=o("FlaxAutoModelForImageClassification"),XAe=l(),Ar=a("div"),f(PA.$$.fragment),yvr=l(),jc=a("p"),wvr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Ipe=a("code"),Avr=o("from_pretrained()"),Lvr=o("class method or the "),jpe=a("code"),Bvr=o("from_config()"),kvr=o(`class
method.`),xvr=l(),$A=a("p"),Rvr=o("This class cannot be instantiated directly using "),Npe=a("code"),Svr=o("__init__()"),Pvr=o(" (throws an error)."),$vr=l(),_t=a("div"),f(IA.$$.fragment),Ivr=l(),Dpe=a("p"),jvr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Nvr=l(),Nc=a("p"),Dvr=o(`Note:
Loading a model from its configuration file does `),qpe=a("strong"),qvr=o("not"),Ovr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ope=a("code"),Gvr=o("from_pretrained()"),zvr=o("to load the model weights."),Vvr=l(),Gpe=a("p"),Xvr=o("Examples:"),Wvr=l(),f(jA.$$.fragment),Qvr=l(),Ro=a("div"),f(NA.$$.fragment),Hvr=l(),zpe=a("p"),Uvr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Jvr=l(),pn=a("p"),Yvr=o("The model class to instantiate is selected based on the "),Vpe=a("code"),Kvr=o("model_type"),Zvr=o(` property of the config object (either
passed as an argument or loaded from `),Xpe=a("code"),e1r=o("pretrained_model_name_or_path"),o1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wpe=a("code"),r1r=o("pretrained_model_name_or_path"),t1r=o(":"),a1r=l(),DA=a("ul"),xC=a("li"),Qpe=a("strong"),n1r=o("beit"),s1r=o(" \u2014 "),sO=a("a"),l1r=o("FlaxBeitForImageClassification"),i1r=o(" (BEiT model)"),d1r=l(),RC=a("li"),Hpe=a("strong"),c1r=o("vit"),f1r=o(" \u2014 "),lO=a("a"),m1r=o("FlaxViTForImageClassification"),g1r=o(" (ViT model)"),h1r=l(),Upe=a("p"),u1r=o("Examples:"),p1r=l(),f(qA.$$.fragment),WAe=l(),Dc=a("h2"),SC=a("a"),Jpe=a("span"),f(OA.$$.fragment),_1r=l(),Ype=a("span"),v1r=o("FlaxAutoModelForVision2Seq"),QAe=l(),Lr=a("div"),f(GA.$$.fragment),b1r=l(),qc=a("p"),T1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Kpe=a("code"),F1r=o("from_pretrained()"),C1r=o("class method or the "),Zpe=a("code"),E1r=o("from_config()"),M1r=o(`class
method.`),y1r=l(),zA=a("p"),w1r=o("This class cannot be instantiated directly using "),e_e=a("code"),A1r=o("__init__()"),L1r=o(" (throws an error)."),B1r=l(),vt=a("div"),f(VA.$$.fragment),k1r=l(),o_e=a("p"),x1r=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),R1r=l(),Oc=a("p"),S1r=o(`Note:
Loading a model from its configuration file does `),r_e=a("strong"),P1r=o("not"),$1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),t_e=a("code"),I1r=o("from_pretrained()"),j1r=o("to load the model weights."),N1r=l(),a_e=a("p"),D1r=o("Examples:"),q1r=l(),f(XA.$$.fragment),O1r=l(),So=a("div"),f(WA.$$.fragment),G1r=l(),n_e=a("p"),z1r=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),V1r=l(),_n=a("p"),X1r=o("The model class to instantiate is selected based on the "),s_e=a("code"),W1r=o("model_type"),Q1r=o(` property of the config object (either
passed as an argument or loaded from `),l_e=a("code"),H1r=o("pretrained_model_name_or_path"),U1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i_e=a("code"),J1r=o("pretrained_model_name_or_path"),Y1r=o(":"),K1r=l(),d_e=a("ul"),PC=a("li"),c_e=a("strong"),Z1r=o("vision-encoder-decoder"),e4r=o(" \u2014 "),iO=a("a"),o4r=o("FlaxVisionEncoderDecoderModel"),r4r=o(" (Vision Encoder decoder model)"),t4r=l(),f_e=a("p"),a4r=o("Examples:"),n4r=l(),f(QA.$$.fragment),this.h()},l(d){const _=Xrt('[data-svelte="svelte-1phssyn"]',document.head);J=n(_,"META",{name:!0,content:!0}),_.forEach(t),we=i(d),se=n(d,"H1",{class:!0});var HA=s(se);me=n(HA,"A",{id:!0,class:!0,href:!0});var m_e=s(me);Ze=n(m_e,"SPAN",{});var g_e=s(Ze);m(de.$$.fragment,g_e),g_e.forEach(t),m_e.forEach(t),_e=i(HA),$o=n(HA,"SPAN",{});var l4r=s($o);oi=r(l4r,"Auto Classes"),l4r.forEach(t),HA.forEach(t),zc=i(d),Ut=n(d,"P",{});var UAe=s(Ut);ri=r(UAe,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ti=n(UAe,"CODE",{});var i4r=s(ti);kE=r(i4r,"from_pretrained()"),i4r.forEach(t),Vc=r(UAe,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),UAe.forEach(t),Me=i(d),no=n(d,"P",{});var $C=s(no);ai=r($C,"Instantiating one of "),vn=n($C,"A",{href:!0});var d4r=s(vn);xE=r(d4r,"AutoConfig"),d4r.forEach(t),bn=r($C,", "),Tn=n($C,"A",{href:!0});var c4r=s(Tn);RE=r(c4r,"AutoModel"),c4r.forEach(t),ni=r($C,`, and
`),Fn=n($C,"A",{href:!0});var f4r=s(Fn);SE=r(f4r,"AutoTokenizer"),f4r.forEach(t),si=r($C," will directly create a class of the relevant architecture. For instance"),$C.forEach(t),Xc=i(d),m(Ea.$$.fragment,d),so=i(d),ge=n(d,"P",{});var JAe=s(ge);z0=r(JAe,"will create a model that is an instance of "),li=n(JAe,"A",{href:!0});var m4r=s(li);V0=r(m4r,"BertModel"),m4r.forEach(t),X0=r(JAe,"."),JAe.forEach(t),Io=i(d),Ma=n(d,"P",{});var YAe=s(Ma);W0=r(YAe,"There is one class of "),Wc=n(YAe,"CODE",{});var g4r=s(Wc);Q0=r(g4r,"AutoModel"),g4r.forEach(t),U7e=r(YAe," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),YAe.forEach(t),owe=i(d),ii=n(d,"H2",{class:!0});var KAe=s(ii);Qc=n(KAe,"A",{id:!0,class:!0,href:!0});var h4r=s(Qc);UG=n(h4r,"SPAN",{});var u4r=s(UG);m(PE.$$.fragment,u4r),u4r.forEach(t),h4r.forEach(t),J7e=i(KAe),JG=n(KAe,"SPAN",{});var p4r=s(JG);Y7e=r(p4r,"Extending the Auto Classes"),p4r.forEach(t),KAe.forEach(t),rwe=i(d),Cn=n(d,"P",{});var dO=s(Cn);K7e=r(dO,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),YG=n(dO,"CODE",{});var _4r=s(YG);Z7e=r(_4r,"NewModel"),_4r.forEach(t),eLe=r(dO,", make sure you have a "),KG=n(dO,"CODE",{});var v4r=s(KG);oLe=r(v4r,"NewModelConfig"),v4r.forEach(t),rLe=r(dO,` then you can add those to the auto
classes like this:`),dO.forEach(t),twe=i(d),m($E.$$.fragment,d),awe=i(d),H0=n(d,"P",{});var b4r=s(H0);tLe=r(b4r,"You will then be able to use the auto classes like you would usually do!"),b4r.forEach(t),nwe=i(d),m(Hc.$$.fragment,d),swe=i(d),di=n(d,"H2",{class:!0});var ZAe=s(di);Uc=n(ZAe,"A",{id:!0,class:!0,href:!0});var T4r=s(Uc);ZG=n(T4r,"SPAN",{});var F4r=s(ZG);m(IE.$$.fragment,F4r),F4r.forEach(t),T4r.forEach(t),aLe=i(ZAe),ez=n(ZAe,"SPAN",{});var C4r=s(ez);nLe=r(C4r,"AutoConfig"),C4r.forEach(t),ZAe.forEach(t),lwe=i(d),jo=n(d,"DIV",{class:!0});var _s=s(jo);m(jE.$$.fragment,_s),sLe=i(_s),NE=n(_s,"P",{});var e0e=s(NE);lLe=r(e0e,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),U0=n(e0e,"A",{href:!0});var E4r=s(U0);iLe=r(E4r,"from_pretrained()"),E4r.forEach(t),dLe=r(e0e," class method."),e0e.forEach(t),cLe=i(_s),DE=n(_s,"P",{});var o0e=s(DE);fLe=r(o0e,"This class cannot be instantiated directly using "),oz=n(o0e,"CODE",{});var M4r=s(oz);mLe=r(M4r,"__init__()"),M4r.forEach(t),gLe=r(o0e," (throws an error)."),o0e.forEach(t),hLe=i(_s),lo=n(_s,"DIV",{class:!0});var Yt=s(lo);m(qE.$$.fragment,Yt),uLe=i(Yt),rz=n(Yt,"P",{});var y4r=s(rz);pLe=r(y4r,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),y4r.forEach(t),_Le=i(Yt),ci=n(Yt,"P",{});var cO=s(ci);vLe=r(cO,"The configuration class to instantiate is selected based on the "),tz=n(cO,"CODE",{});var w4r=s(tz);bLe=r(w4r,"model_type"),w4r.forEach(t),TLe=r(cO,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),az=n(cO,"CODE",{});var A4r=s(az);FLe=r(A4r,"pretrained_model_name_or_path"),A4r.forEach(t),CLe=r(cO,":"),cO.forEach(t),ELe=i(Yt),b=n(Yt,"UL",{});var T=s(b);Jc=n(T,"LI",{});var h_e=s(Jc);nz=n(h_e,"STRONG",{});var L4r=s(nz);MLe=r(L4r,"albert"),L4r.forEach(t),yLe=r(h_e," \u2014 "),J0=n(h_e,"A",{href:!0});var B4r=s(J0);wLe=r(B4r,"AlbertConfig"),B4r.forEach(t),ALe=r(h_e," (ALBERT model)"),h_e.forEach(t),LLe=i(T),Yc=n(T,"LI",{});var u_e=s(Yc);sz=n(u_e,"STRONG",{});var k4r=s(sz);BLe=r(k4r,"bart"),k4r.forEach(t),kLe=r(u_e," \u2014 "),Y0=n(u_e,"A",{href:!0});var x4r=s(Y0);xLe=r(x4r,"BartConfig"),x4r.forEach(t),RLe=r(u_e," (BART model)"),u_e.forEach(t),SLe=i(T),Kc=n(T,"LI",{});var p_e=s(Kc);lz=n(p_e,"STRONG",{});var R4r=s(lz);PLe=r(R4r,"beit"),R4r.forEach(t),$Le=r(p_e," \u2014 "),K0=n(p_e,"A",{href:!0});var S4r=s(K0);ILe=r(S4r,"BeitConfig"),S4r.forEach(t),jLe=r(p_e," (BEiT model)"),p_e.forEach(t),NLe=i(T),Zc=n(T,"LI",{});var __e=s(Zc);iz=n(__e,"STRONG",{});var P4r=s(iz);DLe=r(P4r,"bert"),P4r.forEach(t),qLe=r(__e," \u2014 "),Z0=n(__e,"A",{href:!0});var $4r=s(Z0);OLe=r($4r,"BertConfig"),$4r.forEach(t),GLe=r(__e," (BERT model)"),__e.forEach(t),zLe=i(T),ef=n(T,"LI",{});var v_e=s(ef);dz=n(v_e,"STRONG",{});var I4r=s(dz);VLe=r(I4r,"bert-generation"),I4r.forEach(t),XLe=r(v_e," \u2014 "),e7=n(v_e,"A",{href:!0});var j4r=s(e7);WLe=r(j4r,"BertGenerationConfig"),j4r.forEach(t),QLe=r(v_e," (Bert Generation model)"),v_e.forEach(t),HLe=i(T),of=n(T,"LI",{});var b_e=s(of);cz=n(b_e,"STRONG",{});var N4r=s(cz);ULe=r(N4r,"big_bird"),N4r.forEach(t),JLe=r(b_e," \u2014 "),o7=n(b_e,"A",{href:!0});var D4r=s(o7);YLe=r(D4r,"BigBirdConfig"),D4r.forEach(t),KLe=r(b_e," (BigBird model)"),b_e.forEach(t),ZLe=i(T),rf=n(T,"LI",{});var T_e=s(rf);fz=n(T_e,"STRONG",{});var q4r=s(fz);e8e=r(q4r,"bigbird_pegasus"),q4r.forEach(t),o8e=r(T_e," \u2014 "),r7=n(T_e,"A",{href:!0});var O4r=s(r7);r8e=r(O4r,"BigBirdPegasusConfig"),O4r.forEach(t),t8e=r(T_e," (BigBirdPegasus model)"),T_e.forEach(t),a8e=i(T),tf=n(T,"LI",{});var F_e=s(tf);mz=n(F_e,"STRONG",{});var G4r=s(mz);n8e=r(G4r,"blenderbot"),G4r.forEach(t),s8e=r(F_e," \u2014 "),t7=n(F_e,"A",{href:!0});var z4r=s(t7);l8e=r(z4r,"BlenderbotConfig"),z4r.forEach(t),i8e=r(F_e," (Blenderbot model)"),F_e.forEach(t),d8e=i(T),af=n(T,"LI",{});var C_e=s(af);gz=n(C_e,"STRONG",{});var V4r=s(gz);c8e=r(V4r,"blenderbot-small"),V4r.forEach(t),f8e=r(C_e," \u2014 "),a7=n(C_e,"A",{href:!0});var X4r=s(a7);m8e=r(X4r,"BlenderbotSmallConfig"),X4r.forEach(t),g8e=r(C_e," (BlenderbotSmall model)"),C_e.forEach(t),h8e=i(T),nf=n(T,"LI",{});var E_e=s(nf);hz=n(E_e,"STRONG",{});var W4r=s(hz);u8e=r(W4r,"camembert"),W4r.forEach(t),p8e=r(E_e," \u2014 "),n7=n(E_e,"A",{href:!0});var Q4r=s(n7);_8e=r(Q4r,"CamembertConfig"),Q4r.forEach(t),v8e=r(E_e," (CamemBERT model)"),E_e.forEach(t),b8e=i(T),sf=n(T,"LI",{});var M_e=s(sf);uz=n(M_e,"STRONG",{});var H4r=s(uz);T8e=r(H4r,"canine"),H4r.forEach(t),F8e=r(M_e," \u2014 "),s7=n(M_e,"A",{href:!0});var U4r=s(s7);C8e=r(U4r,"CanineConfig"),U4r.forEach(t),E8e=r(M_e," (Canine model)"),M_e.forEach(t),M8e=i(T),lf=n(T,"LI",{});var y_e=s(lf);pz=n(y_e,"STRONG",{});var J4r=s(pz);y8e=r(J4r,"clip"),J4r.forEach(t),w8e=r(y_e," \u2014 "),l7=n(y_e,"A",{href:!0});var Y4r=s(l7);A8e=r(Y4r,"CLIPConfig"),Y4r.forEach(t),L8e=r(y_e," (CLIP model)"),y_e.forEach(t),B8e=i(T),df=n(T,"LI",{});var w_e=s(df);_z=n(w_e,"STRONG",{});var K4r=s(_z);k8e=r(K4r,"convbert"),K4r.forEach(t),x8e=r(w_e," \u2014 "),i7=n(w_e,"A",{href:!0});var Z4r=s(i7);R8e=r(Z4r,"ConvBertConfig"),Z4r.forEach(t),S8e=r(w_e," (ConvBERT model)"),w_e.forEach(t),P8e=i(T),cf=n(T,"LI",{});var A_e=s(cf);vz=n(A_e,"STRONG",{});var ebr=s(vz);$8e=r(ebr,"ctrl"),ebr.forEach(t),I8e=r(A_e," \u2014 "),d7=n(A_e,"A",{href:!0});var obr=s(d7);j8e=r(obr,"CTRLConfig"),obr.forEach(t),N8e=r(A_e," (CTRL model)"),A_e.forEach(t),D8e=i(T),ff=n(T,"LI",{});var L_e=s(ff);bz=n(L_e,"STRONG",{});var rbr=s(bz);q8e=r(rbr,"deberta"),rbr.forEach(t),O8e=r(L_e," \u2014 "),c7=n(L_e,"A",{href:!0});var tbr=s(c7);G8e=r(tbr,"DebertaConfig"),tbr.forEach(t),z8e=r(L_e," (DeBERTa model)"),L_e.forEach(t),V8e=i(T),mf=n(T,"LI",{});var B_e=s(mf);Tz=n(B_e,"STRONG",{});var abr=s(Tz);X8e=r(abr,"deberta-v2"),abr.forEach(t),W8e=r(B_e," \u2014 "),f7=n(B_e,"A",{href:!0});var nbr=s(f7);Q8e=r(nbr,"DebertaV2Config"),nbr.forEach(t),H8e=r(B_e," (DeBERTa-v2 model)"),B_e.forEach(t),U8e=i(T),gf=n(T,"LI",{});var k_e=s(gf);Fz=n(k_e,"STRONG",{});var sbr=s(Fz);J8e=r(sbr,"deit"),sbr.forEach(t),Y8e=r(k_e," \u2014 "),m7=n(k_e,"A",{href:!0});var lbr=s(m7);K8e=r(lbr,"DeiTConfig"),lbr.forEach(t),Z8e=r(k_e," (DeiT model)"),k_e.forEach(t),eBe=i(T),hf=n(T,"LI",{});var x_e=s(hf);Cz=n(x_e,"STRONG",{});var ibr=s(Cz);oBe=r(ibr,"detr"),ibr.forEach(t),rBe=r(x_e," \u2014 "),g7=n(x_e,"A",{href:!0});var dbr=s(g7);tBe=r(dbr,"DetrConfig"),dbr.forEach(t),aBe=r(x_e," (DETR model)"),x_e.forEach(t),nBe=i(T),uf=n(T,"LI",{});var R_e=s(uf);Ez=n(R_e,"STRONG",{});var cbr=s(Ez);sBe=r(cbr,"distilbert"),cbr.forEach(t),lBe=r(R_e," \u2014 "),h7=n(R_e,"A",{href:!0});var fbr=s(h7);iBe=r(fbr,"DistilBertConfig"),fbr.forEach(t),dBe=r(R_e," (DistilBERT model)"),R_e.forEach(t),cBe=i(T),pf=n(T,"LI",{});var S_e=s(pf);Mz=n(S_e,"STRONG",{});var mbr=s(Mz);fBe=r(mbr,"dpr"),mbr.forEach(t),mBe=r(S_e," \u2014 "),u7=n(S_e,"A",{href:!0});var gbr=s(u7);gBe=r(gbr,"DPRConfig"),gbr.forEach(t),hBe=r(S_e," (DPR model)"),S_e.forEach(t),uBe=i(T),_f=n(T,"LI",{});var P_e=s(_f);yz=n(P_e,"STRONG",{});var hbr=s(yz);pBe=r(hbr,"electra"),hbr.forEach(t),_Be=r(P_e," \u2014 "),p7=n(P_e,"A",{href:!0});var ubr=s(p7);vBe=r(ubr,"ElectraConfig"),ubr.forEach(t),bBe=r(P_e," (ELECTRA model)"),P_e.forEach(t),TBe=i(T),vf=n(T,"LI",{});var $_e=s(vf);wz=n($_e,"STRONG",{});var pbr=s(wz);FBe=r(pbr,"encoder-decoder"),pbr.forEach(t),CBe=r($_e," \u2014 "),_7=n($_e,"A",{href:!0});var _br=s(_7);EBe=r(_br,"EncoderDecoderConfig"),_br.forEach(t),MBe=r($_e," (Encoder decoder model)"),$_e.forEach(t),yBe=i(T),bf=n(T,"LI",{});var I_e=s(bf);Az=n(I_e,"STRONG",{});var vbr=s(Az);wBe=r(vbr,"flaubert"),vbr.forEach(t),ABe=r(I_e," \u2014 "),v7=n(I_e,"A",{href:!0});var bbr=s(v7);LBe=r(bbr,"FlaubertConfig"),bbr.forEach(t),BBe=r(I_e," (FlauBERT model)"),I_e.forEach(t),kBe=i(T),Tf=n(T,"LI",{});var j_e=s(Tf);Lz=n(j_e,"STRONG",{});var Tbr=s(Lz);xBe=r(Tbr,"fnet"),Tbr.forEach(t),RBe=r(j_e," \u2014 "),b7=n(j_e,"A",{href:!0});var Fbr=s(b7);SBe=r(Fbr,"FNetConfig"),Fbr.forEach(t),PBe=r(j_e," (FNet model)"),j_e.forEach(t),$Be=i(T),Ff=n(T,"LI",{});var N_e=s(Ff);Bz=n(N_e,"STRONG",{});var Cbr=s(Bz);IBe=r(Cbr,"fsmt"),Cbr.forEach(t),jBe=r(N_e," \u2014 "),T7=n(N_e,"A",{href:!0});var Ebr=s(T7);NBe=r(Ebr,"FSMTConfig"),Ebr.forEach(t),DBe=r(N_e," (FairSeq Machine-Translation model)"),N_e.forEach(t),qBe=i(T),Cf=n(T,"LI",{});var D_e=s(Cf);kz=n(D_e,"STRONG",{});var Mbr=s(kz);OBe=r(Mbr,"funnel"),Mbr.forEach(t),GBe=r(D_e," \u2014 "),F7=n(D_e,"A",{href:!0});var ybr=s(F7);zBe=r(ybr,"FunnelConfig"),ybr.forEach(t),VBe=r(D_e," (Funnel Transformer model)"),D_e.forEach(t),XBe=i(T),Ef=n(T,"LI",{});var q_e=s(Ef);xz=n(q_e,"STRONG",{});var wbr=s(xz);WBe=r(wbr,"gpt2"),wbr.forEach(t),QBe=r(q_e," \u2014 "),C7=n(q_e,"A",{href:!0});var Abr=s(C7);HBe=r(Abr,"GPT2Config"),Abr.forEach(t),UBe=r(q_e," (OpenAI GPT-2 model)"),q_e.forEach(t),JBe=i(T),Mf=n(T,"LI",{});var O_e=s(Mf);Rz=n(O_e,"STRONG",{});var Lbr=s(Rz);YBe=r(Lbr,"gpt_neo"),Lbr.forEach(t),KBe=r(O_e," \u2014 "),E7=n(O_e,"A",{href:!0});var Bbr=s(E7);ZBe=r(Bbr,"GPTNeoConfig"),Bbr.forEach(t),e9e=r(O_e," (GPT Neo model)"),O_e.forEach(t),o9e=i(T),yf=n(T,"LI",{});var G_e=s(yf);Sz=n(G_e,"STRONG",{});var kbr=s(Sz);r9e=r(kbr,"gptj"),kbr.forEach(t),t9e=r(G_e," \u2014 "),M7=n(G_e,"A",{href:!0});var xbr=s(M7);a9e=r(xbr,"GPTJConfig"),xbr.forEach(t),n9e=r(G_e," (GPT-J model)"),G_e.forEach(t),s9e=i(T),wf=n(T,"LI",{});var z_e=s(wf);Pz=n(z_e,"STRONG",{});var Rbr=s(Pz);l9e=r(Rbr,"hubert"),Rbr.forEach(t),i9e=r(z_e," \u2014 "),y7=n(z_e,"A",{href:!0});var Sbr=s(y7);d9e=r(Sbr,"HubertConfig"),Sbr.forEach(t),c9e=r(z_e," (Hubert model)"),z_e.forEach(t),f9e=i(T),Af=n(T,"LI",{});var V_e=s(Af);$z=n(V_e,"STRONG",{});var Pbr=s($z);m9e=r(Pbr,"ibert"),Pbr.forEach(t),g9e=r(V_e," \u2014 "),w7=n(V_e,"A",{href:!0});var $br=s(w7);h9e=r($br,"IBertConfig"),$br.forEach(t),u9e=r(V_e," (I-BERT model)"),V_e.forEach(t),p9e=i(T),Lf=n(T,"LI",{});var X_e=s(Lf);Iz=n(X_e,"STRONG",{});var Ibr=s(Iz);_9e=r(Ibr,"imagegpt"),Ibr.forEach(t),v9e=r(X_e," \u2014 "),A7=n(X_e,"A",{href:!0});var jbr=s(A7);b9e=r(jbr,"ImageGPTConfig"),jbr.forEach(t),T9e=r(X_e," (ImageGPT model)"),X_e.forEach(t),F9e=i(T),Bf=n(T,"LI",{});var W_e=s(Bf);jz=n(W_e,"STRONG",{});var Nbr=s(jz);C9e=r(Nbr,"layoutlm"),Nbr.forEach(t),E9e=r(W_e," \u2014 "),L7=n(W_e,"A",{href:!0});var Dbr=s(L7);M9e=r(Dbr,"LayoutLMConfig"),Dbr.forEach(t),y9e=r(W_e," (LayoutLM model)"),W_e.forEach(t),w9e=i(T),kf=n(T,"LI",{});var Q_e=s(kf);Nz=n(Q_e,"STRONG",{});var qbr=s(Nz);A9e=r(qbr,"layoutlmv2"),qbr.forEach(t),L9e=r(Q_e," \u2014 "),B7=n(Q_e,"A",{href:!0});var Obr=s(B7);B9e=r(Obr,"LayoutLMv2Config"),Obr.forEach(t),k9e=r(Q_e," (LayoutLMv2 model)"),Q_e.forEach(t),x9e=i(T),xf=n(T,"LI",{});var H_e=s(xf);Dz=n(H_e,"STRONG",{});var Gbr=s(Dz);R9e=r(Gbr,"led"),Gbr.forEach(t),S9e=r(H_e," \u2014 "),k7=n(H_e,"A",{href:!0});var zbr=s(k7);P9e=r(zbr,"LEDConfig"),zbr.forEach(t),$9e=r(H_e," (LED model)"),H_e.forEach(t),I9e=i(T),Rf=n(T,"LI",{});var U_e=s(Rf);qz=n(U_e,"STRONG",{});var Vbr=s(qz);j9e=r(Vbr,"longformer"),Vbr.forEach(t),N9e=r(U_e," \u2014 "),x7=n(U_e,"A",{href:!0});var Xbr=s(x7);D9e=r(Xbr,"LongformerConfig"),Xbr.forEach(t),q9e=r(U_e," (Longformer model)"),U_e.forEach(t),O9e=i(T),Sf=n(T,"LI",{});var J_e=s(Sf);Oz=n(J_e,"STRONG",{});var Wbr=s(Oz);G9e=r(Wbr,"luke"),Wbr.forEach(t),z9e=r(J_e," \u2014 "),R7=n(J_e,"A",{href:!0});var Qbr=s(R7);V9e=r(Qbr,"LukeConfig"),Qbr.forEach(t),X9e=r(J_e," (LUKE model)"),J_e.forEach(t),W9e=i(T),Pf=n(T,"LI",{});var Y_e=s(Pf);Gz=n(Y_e,"STRONG",{});var Hbr=s(Gz);Q9e=r(Hbr,"lxmert"),Hbr.forEach(t),H9e=r(Y_e," \u2014 "),S7=n(Y_e,"A",{href:!0});var Ubr=s(S7);U9e=r(Ubr,"LxmertConfig"),Ubr.forEach(t),J9e=r(Y_e," (LXMERT model)"),Y_e.forEach(t),Y9e=i(T),$f=n(T,"LI",{});var K_e=s($f);zz=n(K_e,"STRONG",{});var Jbr=s(zz);K9e=r(Jbr,"m2m_100"),Jbr.forEach(t),Z9e=r(K_e," \u2014 "),P7=n(K_e,"A",{href:!0});var Ybr=s(P7);eke=r(Ybr,"M2M100Config"),Ybr.forEach(t),oke=r(K_e," (M2M100 model)"),K_e.forEach(t),rke=i(T),If=n(T,"LI",{});var Z_e=s(If);Vz=n(Z_e,"STRONG",{});var Kbr=s(Vz);tke=r(Kbr,"marian"),Kbr.forEach(t),ake=r(Z_e," \u2014 "),$7=n(Z_e,"A",{href:!0});var Zbr=s($7);nke=r(Zbr,"MarianConfig"),Zbr.forEach(t),ske=r(Z_e," (Marian model)"),Z_e.forEach(t),lke=i(T),jf=n(T,"LI",{});var e2e=s(jf);Xz=n(e2e,"STRONG",{});var eTr=s(Xz);ike=r(eTr,"mbart"),eTr.forEach(t),dke=r(e2e," \u2014 "),I7=n(e2e,"A",{href:!0});var oTr=s(I7);cke=r(oTr,"MBartConfig"),oTr.forEach(t),fke=r(e2e," (mBART model)"),e2e.forEach(t),mke=i(T),Nf=n(T,"LI",{});var o2e=s(Nf);Wz=n(o2e,"STRONG",{});var rTr=s(Wz);gke=r(rTr,"megatron-bert"),rTr.forEach(t),hke=r(o2e," \u2014 "),j7=n(o2e,"A",{href:!0});var tTr=s(j7);uke=r(tTr,"MegatronBertConfig"),tTr.forEach(t),pke=r(o2e," (MegatronBert model)"),o2e.forEach(t),_ke=i(T),Df=n(T,"LI",{});var r2e=s(Df);Qz=n(r2e,"STRONG",{});var aTr=s(Qz);vke=r(aTr,"mobilebert"),aTr.forEach(t),bke=r(r2e," \u2014 "),N7=n(r2e,"A",{href:!0});var nTr=s(N7);Tke=r(nTr,"MobileBertConfig"),nTr.forEach(t),Fke=r(r2e," (MobileBERT model)"),r2e.forEach(t),Cke=i(T),qf=n(T,"LI",{});var t2e=s(qf);Hz=n(t2e,"STRONG",{});var sTr=s(Hz);Eke=r(sTr,"mpnet"),sTr.forEach(t),Mke=r(t2e," \u2014 "),D7=n(t2e,"A",{href:!0});var lTr=s(D7);yke=r(lTr,"MPNetConfig"),lTr.forEach(t),wke=r(t2e," (MPNet model)"),t2e.forEach(t),Ake=i(T),Of=n(T,"LI",{});var a2e=s(Of);Uz=n(a2e,"STRONG",{});var iTr=s(Uz);Lke=r(iTr,"mt5"),iTr.forEach(t),Bke=r(a2e," \u2014 "),q7=n(a2e,"A",{href:!0});var dTr=s(q7);kke=r(dTr,"MT5Config"),dTr.forEach(t),xke=r(a2e," (mT5 model)"),a2e.forEach(t),Rke=i(T),Gf=n(T,"LI",{});var n2e=s(Gf);Jz=n(n2e,"STRONG",{});var cTr=s(Jz);Ske=r(cTr,"nystromformer"),cTr.forEach(t),Pke=r(n2e," \u2014 "),O7=n(n2e,"A",{href:!0});var fTr=s(O7);$ke=r(fTr,"NystromformerConfig"),fTr.forEach(t),Ike=r(n2e," (Nystromformer model)"),n2e.forEach(t),jke=i(T),zf=n(T,"LI",{});var s2e=s(zf);Yz=n(s2e,"STRONG",{});var mTr=s(Yz);Nke=r(mTr,"openai-gpt"),mTr.forEach(t),Dke=r(s2e," \u2014 "),G7=n(s2e,"A",{href:!0});var gTr=s(G7);qke=r(gTr,"OpenAIGPTConfig"),gTr.forEach(t),Oke=r(s2e," (OpenAI GPT model)"),s2e.forEach(t),Gke=i(T),Vf=n(T,"LI",{});var l2e=s(Vf);Kz=n(l2e,"STRONG",{});var hTr=s(Kz);zke=r(hTr,"pegasus"),hTr.forEach(t),Vke=r(l2e," \u2014 "),z7=n(l2e,"A",{href:!0});var uTr=s(z7);Xke=r(uTr,"PegasusConfig"),uTr.forEach(t),Wke=r(l2e," (Pegasus model)"),l2e.forEach(t),Qke=i(T),Xf=n(T,"LI",{});var i2e=s(Xf);Zz=n(i2e,"STRONG",{});var pTr=s(Zz);Hke=r(pTr,"perceiver"),pTr.forEach(t),Uke=r(i2e," \u2014 "),V7=n(i2e,"A",{href:!0});var _Tr=s(V7);Jke=r(_Tr,"PerceiverConfig"),_Tr.forEach(t),Yke=r(i2e," (Perceiver model)"),i2e.forEach(t),Kke=i(T),Wf=n(T,"LI",{});var d2e=s(Wf);eV=n(d2e,"STRONG",{});var vTr=s(eV);Zke=r(vTr,"prophetnet"),vTr.forEach(t),exe=r(d2e," \u2014 "),X7=n(d2e,"A",{href:!0});var bTr=s(X7);oxe=r(bTr,"ProphetNetConfig"),bTr.forEach(t),rxe=r(d2e," (ProphetNet model)"),d2e.forEach(t),txe=i(T),Qf=n(T,"LI",{});var c2e=s(Qf);oV=n(c2e,"STRONG",{});var TTr=s(oV);axe=r(TTr,"qdqbert"),TTr.forEach(t),nxe=r(c2e," \u2014 "),W7=n(c2e,"A",{href:!0});var FTr=s(W7);sxe=r(FTr,"QDQBertConfig"),FTr.forEach(t),lxe=r(c2e," (QDQBert model)"),c2e.forEach(t),ixe=i(T),Hf=n(T,"LI",{});var f2e=s(Hf);rV=n(f2e,"STRONG",{});var CTr=s(rV);dxe=r(CTr,"rag"),CTr.forEach(t),cxe=r(f2e," \u2014 "),Q7=n(f2e,"A",{href:!0});var ETr=s(Q7);fxe=r(ETr,"RagConfig"),ETr.forEach(t),mxe=r(f2e," (RAG model)"),f2e.forEach(t),gxe=i(T),Uf=n(T,"LI",{});var m2e=s(Uf);tV=n(m2e,"STRONG",{});var MTr=s(tV);hxe=r(MTr,"realm"),MTr.forEach(t),uxe=r(m2e," \u2014 "),H7=n(m2e,"A",{href:!0});var yTr=s(H7);pxe=r(yTr,"RealmConfig"),yTr.forEach(t),_xe=r(m2e," (Realm model)"),m2e.forEach(t),vxe=i(T),Jf=n(T,"LI",{});var g2e=s(Jf);aV=n(g2e,"STRONG",{});var wTr=s(aV);bxe=r(wTr,"reformer"),wTr.forEach(t),Txe=r(g2e," \u2014 "),U7=n(g2e,"A",{href:!0});var ATr=s(U7);Fxe=r(ATr,"ReformerConfig"),ATr.forEach(t),Cxe=r(g2e," (Reformer model)"),g2e.forEach(t),Exe=i(T),Yf=n(T,"LI",{});var h2e=s(Yf);nV=n(h2e,"STRONG",{});var LTr=s(nV);Mxe=r(LTr,"rembert"),LTr.forEach(t),yxe=r(h2e," \u2014 "),J7=n(h2e,"A",{href:!0});var BTr=s(J7);wxe=r(BTr,"RemBertConfig"),BTr.forEach(t),Axe=r(h2e," (RemBERT model)"),h2e.forEach(t),Lxe=i(T),Kf=n(T,"LI",{});var u2e=s(Kf);sV=n(u2e,"STRONG",{});var kTr=s(sV);Bxe=r(kTr,"retribert"),kTr.forEach(t),kxe=r(u2e," \u2014 "),Y7=n(u2e,"A",{href:!0});var xTr=s(Y7);xxe=r(xTr,"RetriBertConfig"),xTr.forEach(t),Rxe=r(u2e," (RetriBERT model)"),u2e.forEach(t),Sxe=i(T),Zf=n(T,"LI",{});var p2e=s(Zf);lV=n(p2e,"STRONG",{});var RTr=s(lV);Pxe=r(RTr,"roberta"),RTr.forEach(t),$xe=r(p2e," \u2014 "),K7=n(p2e,"A",{href:!0});var STr=s(K7);Ixe=r(STr,"RobertaConfig"),STr.forEach(t),jxe=r(p2e," (RoBERTa model)"),p2e.forEach(t),Nxe=i(T),em=n(T,"LI",{});var _2e=s(em);iV=n(_2e,"STRONG",{});var PTr=s(iV);Dxe=r(PTr,"roformer"),PTr.forEach(t),qxe=r(_2e," \u2014 "),Z7=n(_2e,"A",{href:!0});var $Tr=s(Z7);Oxe=r($Tr,"RoFormerConfig"),$Tr.forEach(t),Gxe=r(_2e," (RoFormer model)"),_2e.forEach(t),zxe=i(T),om=n(T,"LI",{});var v2e=s(om);dV=n(v2e,"STRONG",{});var ITr=s(dV);Vxe=r(ITr,"segformer"),ITr.forEach(t),Xxe=r(v2e," \u2014 "),eL=n(v2e,"A",{href:!0});var jTr=s(eL);Wxe=r(jTr,"SegformerConfig"),jTr.forEach(t),Qxe=r(v2e," (SegFormer model)"),v2e.forEach(t),Hxe=i(T),rm=n(T,"LI",{});var b2e=s(rm);cV=n(b2e,"STRONG",{});var NTr=s(cV);Uxe=r(NTr,"sew"),NTr.forEach(t),Jxe=r(b2e," \u2014 "),oL=n(b2e,"A",{href:!0});var DTr=s(oL);Yxe=r(DTr,"SEWConfig"),DTr.forEach(t),Kxe=r(b2e," (SEW model)"),b2e.forEach(t),Zxe=i(T),tm=n(T,"LI",{});var T2e=s(tm);fV=n(T2e,"STRONG",{});var qTr=s(fV);eRe=r(qTr,"sew-d"),qTr.forEach(t),oRe=r(T2e," \u2014 "),rL=n(T2e,"A",{href:!0});var OTr=s(rL);rRe=r(OTr,"SEWDConfig"),OTr.forEach(t),tRe=r(T2e," (SEW-D model)"),T2e.forEach(t),aRe=i(T),am=n(T,"LI",{});var F2e=s(am);mV=n(F2e,"STRONG",{});var GTr=s(mV);nRe=r(GTr,"speech-encoder-decoder"),GTr.forEach(t),sRe=r(F2e," \u2014 "),tL=n(F2e,"A",{href:!0});var zTr=s(tL);lRe=r(zTr,"SpeechEncoderDecoderConfig"),zTr.forEach(t),iRe=r(F2e," (Speech Encoder decoder model)"),F2e.forEach(t),dRe=i(T),nm=n(T,"LI",{});var C2e=s(nm);gV=n(C2e,"STRONG",{});var VTr=s(gV);cRe=r(VTr,"speech_to_text"),VTr.forEach(t),fRe=r(C2e," \u2014 "),aL=n(C2e,"A",{href:!0});var XTr=s(aL);mRe=r(XTr,"Speech2TextConfig"),XTr.forEach(t),gRe=r(C2e," (Speech2Text model)"),C2e.forEach(t),hRe=i(T),sm=n(T,"LI",{});var E2e=s(sm);hV=n(E2e,"STRONG",{});var WTr=s(hV);uRe=r(WTr,"speech_to_text_2"),WTr.forEach(t),pRe=r(E2e," \u2014 "),nL=n(E2e,"A",{href:!0});var QTr=s(nL);_Re=r(QTr,"Speech2Text2Config"),QTr.forEach(t),vRe=r(E2e," (Speech2Text2 model)"),E2e.forEach(t),bRe=i(T),lm=n(T,"LI",{});var M2e=s(lm);uV=n(M2e,"STRONG",{});var HTr=s(uV);TRe=r(HTr,"splinter"),HTr.forEach(t),FRe=r(M2e," \u2014 "),sL=n(M2e,"A",{href:!0});var UTr=s(sL);CRe=r(UTr,"SplinterConfig"),UTr.forEach(t),ERe=r(M2e," (Splinter model)"),M2e.forEach(t),MRe=i(T),im=n(T,"LI",{});var y2e=s(im);pV=n(y2e,"STRONG",{});var JTr=s(pV);yRe=r(JTr,"squeezebert"),JTr.forEach(t),wRe=r(y2e," \u2014 "),lL=n(y2e,"A",{href:!0});var YTr=s(lL);ARe=r(YTr,"SqueezeBertConfig"),YTr.forEach(t),LRe=r(y2e," (SqueezeBERT model)"),y2e.forEach(t),BRe=i(T),dm=n(T,"LI",{});var w2e=s(dm);_V=n(w2e,"STRONG",{});var KTr=s(_V);kRe=r(KTr,"swin"),KTr.forEach(t),xRe=r(w2e," \u2014 "),iL=n(w2e,"A",{href:!0});var ZTr=s(iL);RRe=r(ZTr,"SwinConfig"),ZTr.forEach(t),SRe=r(w2e," (Swin model)"),w2e.forEach(t),PRe=i(T),cm=n(T,"LI",{});var A2e=s(cm);vV=n(A2e,"STRONG",{});var e6r=s(vV);$Re=r(e6r,"t5"),e6r.forEach(t),IRe=r(A2e," \u2014 "),dL=n(A2e,"A",{href:!0});var o6r=s(dL);jRe=r(o6r,"T5Config"),o6r.forEach(t),NRe=r(A2e," (T5 model)"),A2e.forEach(t),DRe=i(T),fm=n(T,"LI",{});var L2e=s(fm);bV=n(L2e,"STRONG",{});var r6r=s(bV);qRe=r(r6r,"tapas"),r6r.forEach(t),ORe=r(L2e," \u2014 "),cL=n(L2e,"A",{href:!0});var t6r=s(cL);GRe=r(t6r,"TapasConfig"),t6r.forEach(t),zRe=r(L2e," (TAPAS model)"),L2e.forEach(t),VRe=i(T),mm=n(T,"LI",{});var B2e=s(mm);TV=n(B2e,"STRONG",{});var a6r=s(TV);XRe=r(a6r,"transfo-xl"),a6r.forEach(t),WRe=r(B2e," \u2014 "),fL=n(B2e,"A",{href:!0});var n6r=s(fL);QRe=r(n6r,"TransfoXLConfig"),n6r.forEach(t),HRe=r(B2e," (Transformer-XL model)"),B2e.forEach(t),URe=i(T),gm=n(T,"LI",{});var k2e=s(gm);FV=n(k2e,"STRONG",{});var s6r=s(FV);JRe=r(s6r,"trocr"),s6r.forEach(t),YRe=r(k2e," \u2014 "),mL=n(k2e,"A",{href:!0});var l6r=s(mL);KRe=r(l6r,"TrOCRConfig"),l6r.forEach(t),ZRe=r(k2e," (TrOCR model)"),k2e.forEach(t),eSe=i(T),hm=n(T,"LI",{});var x2e=s(hm);CV=n(x2e,"STRONG",{});var i6r=s(CV);oSe=r(i6r,"unispeech"),i6r.forEach(t),rSe=r(x2e," \u2014 "),gL=n(x2e,"A",{href:!0});var d6r=s(gL);tSe=r(d6r,"UniSpeechConfig"),d6r.forEach(t),aSe=r(x2e," (UniSpeech model)"),x2e.forEach(t),nSe=i(T),um=n(T,"LI",{});var R2e=s(um);EV=n(R2e,"STRONG",{});var c6r=s(EV);sSe=r(c6r,"unispeech-sat"),c6r.forEach(t),lSe=r(R2e," \u2014 "),hL=n(R2e,"A",{href:!0});var f6r=s(hL);iSe=r(f6r,"UniSpeechSatConfig"),f6r.forEach(t),dSe=r(R2e," (UniSpeechSat model)"),R2e.forEach(t),cSe=i(T),pm=n(T,"LI",{});var S2e=s(pm);MV=n(S2e,"STRONG",{});var m6r=s(MV);fSe=r(m6r,"vilt"),m6r.forEach(t),mSe=r(S2e," \u2014 "),uL=n(S2e,"A",{href:!0});var g6r=s(uL);gSe=r(g6r,"ViltConfig"),g6r.forEach(t),hSe=r(S2e," (ViLT model)"),S2e.forEach(t),uSe=i(T),_m=n(T,"LI",{});var P2e=s(_m);yV=n(P2e,"STRONG",{});var h6r=s(yV);pSe=r(h6r,"vision-encoder-decoder"),h6r.forEach(t),_Se=r(P2e," \u2014 "),pL=n(P2e,"A",{href:!0});var u6r=s(pL);vSe=r(u6r,"VisionEncoderDecoderConfig"),u6r.forEach(t),bSe=r(P2e," (Vision Encoder decoder model)"),P2e.forEach(t),TSe=i(T),vm=n(T,"LI",{});var $2e=s(vm);wV=n($2e,"STRONG",{});var p6r=s(wV);FSe=r(p6r,"vision-text-dual-encoder"),p6r.forEach(t),CSe=r($2e," \u2014 "),_L=n($2e,"A",{href:!0});var _6r=s(_L);ESe=r(_6r,"VisionTextDualEncoderConfig"),_6r.forEach(t),MSe=r($2e," (VisionTextDualEncoder model)"),$2e.forEach(t),ySe=i(T),bm=n(T,"LI",{});var I2e=s(bm);AV=n(I2e,"STRONG",{});var v6r=s(AV);wSe=r(v6r,"visual_bert"),v6r.forEach(t),ASe=r(I2e," \u2014 "),vL=n(I2e,"A",{href:!0});var b6r=s(vL);LSe=r(b6r,"VisualBertConfig"),b6r.forEach(t),BSe=r(I2e," (VisualBert model)"),I2e.forEach(t),kSe=i(T),Tm=n(T,"LI",{});var j2e=s(Tm);LV=n(j2e,"STRONG",{});var T6r=s(LV);xSe=r(T6r,"vit"),T6r.forEach(t),RSe=r(j2e," \u2014 "),bL=n(j2e,"A",{href:!0});var F6r=s(bL);SSe=r(F6r,"ViTConfig"),F6r.forEach(t),PSe=r(j2e," (ViT model)"),j2e.forEach(t),$Se=i(T),Fm=n(T,"LI",{});var N2e=s(Fm);BV=n(N2e,"STRONG",{});var C6r=s(BV);ISe=r(C6r,"vit_mae"),C6r.forEach(t),jSe=r(N2e," \u2014 "),TL=n(N2e,"A",{href:!0});var E6r=s(TL);NSe=r(E6r,"ViTMAEConfig"),E6r.forEach(t),DSe=r(N2e," (ViTMAE model)"),N2e.forEach(t),qSe=i(T),Cm=n(T,"LI",{});var D2e=s(Cm);kV=n(D2e,"STRONG",{});var M6r=s(kV);OSe=r(M6r,"wav2vec2"),M6r.forEach(t),GSe=r(D2e," \u2014 "),FL=n(D2e,"A",{href:!0});var y6r=s(FL);zSe=r(y6r,"Wav2Vec2Config"),y6r.forEach(t),VSe=r(D2e," (Wav2Vec2 model)"),D2e.forEach(t),XSe=i(T),Em=n(T,"LI",{});var q2e=s(Em);xV=n(q2e,"STRONG",{});var w6r=s(xV);WSe=r(w6r,"wavlm"),w6r.forEach(t),QSe=r(q2e," \u2014 "),CL=n(q2e,"A",{href:!0});var A6r=s(CL);HSe=r(A6r,"WavLMConfig"),A6r.forEach(t),USe=r(q2e," (WavLM model)"),q2e.forEach(t),JSe=i(T),Mm=n(T,"LI",{});var O2e=s(Mm);RV=n(O2e,"STRONG",{});var L6r=s(RV);YSe=r(L6r,"xlm"),L6r.forEach(t),KSe=r(O2e," \u2014 "),EL=n(O2e,"A",{href:!0});var B6r=s(EL);ZSe=r(B6r,"XLMConfig"),B6r.forEach(t),ePe=r(O2e," (XLM model)"),O2e.forEach(t),oPe=i(T),ym=n(T,"LI",{});var G2e=s(ym);SV=n(G2e,"STRONG",{});var k6r=s(SV);rPe=r(k6r,"xlm-prophetnet"),k6r.forEach(t),tPe=r(G2e," \u2014 "),ML=n(G2e,"A",{href:!0});var x6r=s(ML);aPe=r(x6r,"XLMProphetNetConfig"),x6r.forEach(t),nPe=r(G2e," (XLMProphetNet model)"),G2e.forEach(t),sPe=i(T),wm=n(T,"LI",{});var z2e=s(wm);PV=n(z2e,"STRONG",{});var R6r=s(PV);lPe=r(R6r,"xlm-roberta"),R6r.forEach(t),iPe=r(z2e," \u2014 "),yL=n(z2e,"A",{href:!0});var S6r=s(yL);dPe=r(S6r,"XLMRobertaConfig"),S6r.forEach(t),cPe=r(z2e," (XLM-RoBERTa model)"),z2e.forEach(t),fPe=i(T),Am=n(T,"LI",{});var V2e=s(Am);$V=n(V2e,"STRONG",{});var P6r=s($V);mPe=r(P6r,"xlnet"),P6r.forEach(t),gPe=r(V2e," \u2014 "),wL=n(V2e,"A",{href:!0});var $6r=s(wL);hPe=r($6r,"XLNetConfig"),$6r.forEach(t),uPe=r(V2e," (XLNet model)"),V2e.forEach(t),pPe=i(T),Lm=n(T,"LI",{});var X2e=s(Lm);IV=n(X2e,"STRONG",{});var I6r=s(IV);_Pe=r(I6r,"yoso"),I6r.forEach(t),vPe=r(X2e," \u2014 "),AL=n(X2e,"A",{href:!0});var j6r=s(AL);bPe=r(j6r,"YosoConfig"),j6r.forEach(t),TPe=r(X2e," (YOSO model)"),X2e.forEach(t),T.forEach(t),FPe=i(Yt),jV=n(Yt,"P",{});var N6r=s(jV);CPe=r(N6r,"Examples:"),N6r.forEach(t),EPe=i(Yt),m(OE.$$.fragment,Yt),Yt.forEach(t),MPe=i(_s),Bm=n(_s,"DIV",{class:!0});var r0e=s(Bm);m(GE.$$.fragment,r0e),yPe=i(r0e),NV=n(r0e,"P",{});var D6r=s(NV);wPe=r(D6r,"Register a new configuration for this class."),D6r.forEach(t),r0e.forEach(t),_s.forEach(t),iwe=i(d),fi=n(d,"H2",{class:!0});var t0e=s(fi);km=n(t0e,"A",{id:!0,class:!0,href:!0});var q6r=s(km);DV=n(q6r,"SPAN",{});var O6r=s(DV);m(zE.$$.fragment,O6r),O6r.forEach(t),q6r.forEach(t),APe=i(t0e),qV=n(t0e,"SPAN",{});var G6r=s(qV);LPe=r(G6r,"AutoTokenizer"),G6r.forEach(t),t0e.forEach(t),dwe=i(d),No=n(d,"DIV",{class:!0});var vs=s(No);m(VE.$$.fragment,vs),BPe=i(vs),XE=n(vs,"P",{});var a0e=s(XE);kPe=r(a0e,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),LL=n(a0e,"A",{href:!0});var z6r=s(LL);xPe=r(z6r,"AutoTokenizer.from_pretrained()"),z6r.forEach(t),RPe=r(a0e," class method."),a0e.forEach(t),SPe=i(vs),WE=n(vs,"P",{});var n0e=s(WE);PPe=r(n0e,"This class cannot be instantiated directly using "),OV=n(n0e,"CODE",{});var V6r=s(OV);$Pe=r(V6r,"__init__()"),V6r.forEach(t),IPe=r(n0e," (throws an error)."),n0e.forEach(t),jPe=i(vs),io=n(vs,"DIV",{class:!0});var Kt=s(io);m(QE.$$.fragment,Kt),NPe=i(Kt),GV=n(Kt,"P",{});var X6r=s(GV);DPe=r(X6r,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),X6r.forEach(t),qPe=i(Kt),ya=n(Kt,"P",{});var IC=s(ya);OPe=r(IC,"The tokenizer class to instantiate is selected based on the "),zV=n(IC,"CODE",{});var W6r=s(zV);GPe=r(W6r,"model_type"),W6r.forEach(t),zPe=r(IC,` property of the config object (either
passed as an argument or loaded from `),VV=n(IC,"CODE",{});var Q6r=s(VV);VPe=r(Q6r,"pretrained_model_name_or_path"),Q6r.forEach(t),XPe=r(IC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),XV=n(IC,"CODE",{});var H6r=s(XV);WPe=r(H6r,"pretrained_model_name_or_path"),H6r.forEach(t),QPe=r(IC,":"),IC.forEach(t),HPe=i(Kt),E=n(Kt,"UL",{});var M=s(E);En=n(M,"LI",{});var UA=s(En);WV=n(UA,"STRONG",{});var U6r=s(WV);UPe=r(U6r,"albert"),U6r.forEach(t),JPe=r(UA," \u2014 "),BL=n(UA,"A",{href:!0});var J6r=s(BL);YPe=r(J6r,"AlbertTokenizer"),J6r.forEach(t),KPe=r(UA," or "),kL=n(UA,"A",{href:!0});var Y6r=s(kL);ZPe=r(Y6r,"AlbertTokenizerFast"),Y6r.forEach(t),e$e=r(UA," (ALBERT model)"),UA.forEach(t),o$e=i(M),Mn=n(M,"LI",{});var JA=s(Mn);QV=n(JA,"STRONG",{});var K6r=s(QV);r$e=r(K6r,"bart"),K6r.forEach(t),t$e=r(JA," \u2014 "),xL=n(JA,"A",{href:!0});var Z6r=s(xL);a$e=r(Z6r,"BartTokenizer"),Z6r.forEach(t),n$e=r(JA," or "),RL=n(JA,"A",{href:!0});var eFr=s(RL);s$e=r(eFr,"BartTokenizerFast"),eFr.forEach(t),l$e=r(JA," (BART model)"),JA.forEach(t),i$e=i(M),yn=n(M,"LI",{});var YA=s(yn);HV=n(YA,"STRONG",{});var oFr=s(HV);d$e=r(oFr,"barthez"),oFr.forEach(t),c$e=r(YA," \u2014 "),SL=n(YA,"A",{href:!0});var rFr=s(SL);f$e=r(rFr,"BarthezTokenizer"),rFr.forEach(t),m$e=r(YA," or "),PL=n(YA,"A",{href:!0});var tFr=s(PL);g$e=r(tFr,"BarthezTokenizerFast"),tFr.forEach(t),h$e=r(YA," (BARThez model)"),YA.forEach(t),u$e=i(M),xm=n(M,"LI",{});var W2e=s(xm);UV=n(W2e,"STRONG",{});var aFr=s(UV);p$e=r(aFr,"bartpho"),aFr.forEach(t),_$e=r(W2e," \u2014 "),$L=n(W2e,"A",{href:!0});var nFr=s($L);v$e=r(nFr,"BartphoTokenizer"),nFr.forEach(t),b$e=r(W2e," (BARTpho model)"),W2e.forEach(t),T$e=i(M),wn=n(M,"LI",{});var KA=s(wn);JV=n(KA,"STRONG",{});var sFr=s(JV);F$e=r(sFr,"bert"),sFr.forEach(t),C$e=r(KA," \u2014 "),IL=n(KA,"A",{href:!0});var lFr=s(IL);E$e=r(lFr,"BertTokenizer"),lFr.forEach(t),M$e=r(KA," or "),jL=n(KA,"A",{href:!0});var iFr=s(jL);y$e=r(iFr,"BertTokenizerFast"),iFr.forEach(t),w$e=r(KA," (BERT model)"),KA.forEach(t),A$e=i(M),Rm=n(M,"LI",{});var Q2e=s(Rm);YV=n(Q2e,"STRONG",{});var dFr=s(YV);L$e=r(dFr,"bert-generation"),dFr.forEach(t),B$e=r(Q2e," \u2014 "),NL=n(Q2e,"A",{href:!0});var cFr=s(NL);k$e=r(cFr,"BertGenerationTokenizer"),cFr.forEach(t),x$e=r(Q2e," (Bert Generation model)"),Q2e.forEach(t),R$e=i(M),Sm=n(M,"LI",{});var H2e=s(Sm);KV=n(H2e,"STRONG",{});var fFr=s(KV);S$e=r(fFr,"bert-japanese"),fFr.forEach(t),P$e=r(H2e," \u2014 "),DL=n(H2e,"A",{href:!0});var mFr=s(DL);$$e=r(mFr,"BertJapaneseTokenizer"),mFr.forEach(t),I$e=r(H2e," (BertJapanese model)"),H2e.forEach(t),j$e=i(M),Pm=n(M,"LI",{});var U2e=s(Pm);ZV=n(U2e,"STRONG",{});var gFr=s(ZV);N$e=r(gFr,"bertweet"),gFr.forEach(t),D$e=r(U2e," \u2014 "),qL=n(U2e,"A",{href:!0});var hFr=s(qL);q$e=r(hFr,"BertweetTokenizer"),hFr.forEach(t),O$e=r(U2e," (Bertweet model)"),U2e.forEach(t),G$e=i(M),An=n(M,"LI",{});var ZA=s(An);eX=n(ZA,"STRONG",{});var uFr=s(eX);z$e=r(uFr,"big_bird"),uFr.forEach(t),V$e=r(ZA," \u2014 "),OL=n(ZA,"A",{href:!0});var pFr=s(OL);X$e=r(pFr,"BigBirdTokenizer"),pFr.forEach(t),W$e=r(ZA," or "),GL=n(ZA,"A",{href:!0});var _Fr=s(GL);Q$e=r(_Fr,"BigBirdTokenizerFast"),_Fr.forEach(t),H$e=r(ZA," (BigBird model)"),ZA.forEach(t),U$e=i(M),Ln=n(M,"LI",{});var e0=s(Ln);oX=n(e0,"STRONG",{});var vFr=s(oX);J$e=r(vFr,"bigbird_pegasus"),vFr.forEach(t),Y$e=r(e0," \u2014 "),zL=n(e0,"A",{href:!0});var bFr=s(zL);K$e=r(bFr,"PegasusTokenizer"),bFr.forEach(t),Z$e=r(e0," or "),VL=n(e0,"A",{href:!0});var TFr=s(VL);eIe=r(TFr,"PegasusTokenizerFast"),TFr.forEach(t),oIe=r(e0," (BigBirdPegasus model)"),e0.forEach(t),rIe=i(M),Bn=n(M,"LI",{});var o0=s(Bn);rX=n(o0,"STRONG",{});var FFr=s(rX);tIe=r(FFr,"blenderbot"),FFr.forEach(t),aIe=r(o0," \u2014 "),XL=n(o0,"A",{href:!0});var CFr=s(XL);nIe=r(CFr,"BlenderbotTokenizer"),CFr.forEach(t),sIe=r(o0," or "),WL=n(o0,"A",{href:!0});var EFr=s(WL);lIe=r(EFr,"BlenderbotTokenizerFast"),EFr.forEach(t),iIe=r(o0," (Blenderbot model)"),o0.forEach(t),dIe=i(M),$m=n(M,"LI",{});var J2e=s($m);tX=n(J2e,"STRONG",{});var MFr=s(tX);cIe=r(MFr,"blenderbot-small"),MFr.forEach(t),fIe=r(J2e," \u2014 "),QL=n(J2e,"A",{href:!0});var yFr=s(QL);mIe=r(yFr,"BlenderbotSmallTokenizer"),yFr.forEach(t),gIe=r(J2e," (BlenderbotSmall model)"),J2e.forEach(t),hIe=i(M),Im=n(M,"LI",{});var Y2e=s(Im);aX=n(Y2e,"STRONG",{});var wFr=s(aX);uIe=r(wFr,"byt5"),wFr.forEach(t),pIe=r(Y2e," \u2014 "),HL=n(Y2e,"A",{href:!0});var AFr=s(HL);_Ie=r(AFr,"ByT5Tokenizer"),AFr.forEach(t),vIe=r(Y2e," (ByT5 model)"),Y2e.forEach(t),bIe=i(M),kn=n(M,"LI",{});var r0=s(kn);nX=n(r0,"STRONG",{});var LFr=s(nX);TIe=r(LFr,"camembert"),LFr.forEach(t),FIe=r(r0," \u2014 "),UL=n(r0,"A",{href:!0});var BFr=s(UL);CIe=r(BFr,"CamembertTokenizer"),BFr.forEach(t),EIe=r(r0," or "),JL=n(r0,"A",{href:!0});var kFr=s(JL);MIe=r(kFr,"CamembertTokenizerFast"),kFr.forEach(t),yIe=r(r0," (CamemBERT model)"),r0.forEach(t),wIe=i(M),jm=n(M,"LI",{});var K2e=s(jm);sX=n(K2e,"STRONG",{});var xFr=s(sX);AIe=r(xFr,"canine"),xFr.forEach(t),LIe=r(K2e," \u2014 "),YL=n(K2e,"A",{href:!0});var RFr=s(YL);BIe=r(RFr,"CanineTokenizer"),RFr.forEach(t),kIe=r(K2e," (Canine model)"),K2e.forEach(t),xIe=i(M),xn=n(M,"LI",{});var t0=s(xn);lX=n(t0,"STRONG",{});var SFr=s(lX);RIe=r(SFr,"clip"),SFr.forEach(t),SIe=r(t0," \u2014 "),KL=n(t0,"A",{href:!0});var PFr=s(KL);PIe=r(PFr,"CLIPTokenizer"),PFr.forEach(t),$Ie=r(t0," or "),ZL=n(t0,"A",{href:!0});var $Fr=s(ZL);IIe=r($Fr,"CLIPTokenizerFast"),$Fr.forEach(t),jIe=r(t0," (CLIP model)"),t0.forEach(t),NIe=i(M),Rn=n(M,"LI",{});var a0=s(Rn);iX=n(a0,"STRONG",{});var IFr=s(iX);DIe=r(IFr,"convbert"),IFr.forEach(t),qIe=r(a0," \u2014 "),e8=n(a0,"A",{href:!0});var jFr=s(e8);OIe=r(jFr,"ConvBertTokenizer"),jFr.forEach(t),GIe=r(a0," or "),o8=n(a0,"A",{href:!0});var NFr=s(o8);zIe=r(NFr,"ConvBertTokenizerFast"),NFr.forEach(t),VIe=r(a0," (ConvBERT model)"),a0.forEach(t),XIe=i(M),Sn=n(M,"LI",{});var n0=s(Sn);dX=n(n0,"STRONG",{});var DFr=s(dX);WIe=r(DFr,"cpm"),DFr.forEach(t),QIe=r(n0," \u2014 "),r8=n(n0,"A",{href:!0});var qFr=s(r8);HIe=r(qFr,"CpmTokenizer"),qFr.forEach(t),UIe=r(n0," or "),cX=n(n0,"CODE",{});var OFr=s(cX);JIe=r(OFr,"CpmTokenizerFast"),OFr.forEach(t),YIe=r(n0," (CPM model)"),n0.forEach(t),KIe=i(M),Nm=n(M,"LI",{});var Z2e=s(Nm);fX=n(Z2e,"STRONG",{});var GFr=s(fX);ZIe=r(GFr,"ctrl"),GFr.forEach(t),eje=r(Z2e," \u2014 "),t8=n(Z2e,"A",{href:!0});var zFr=s(t8);oje=r(zFr,"CTRLTokenizer"),zFr.forEach(t),rje=r(Z2e," (CTRL model)"),Z2e.forEach(t),tje=i(M),Pn=n(M,"LI",{});var s0=s(Pn);mX=n(s0,"STRONG",{});var VFr=s(mX);aje=r(VFr,"deberta"),VFr.forEach(t),nje=r(s0," \u2014 "),a8=n(s0,"A",{href:!0});var XFr=s(a8);sje=r(XFr,"DebertaTokenizer"),XFr.forEach(t),lje=r(s0," or "),n8=n(s0,"A",{href:!0});var WFr=s(n8);ije=r(WFr,"DebertaTokenizerFast"),WFr.forEach(t),dje=r(s0," (DeBERTa model)"),s0.forEach(t),cje=i(M),Dm=n(M,"LI",{});var eve=s(Dm);gX=n(eve,"STRONG",{});var QFr=s(gX);fje=r(QFr,"deberta-v2"),QFr.forEach(t),mje=r(eve," \u2014 "),s8=n(eve,"A",{href:!0});var HFr=s(s8);gje=r(HFr,"DebertaV2Tokenizer"),HFr.forEach(t),hje=r(eve," (DeBERTa-v2 model)"),eve.forEach(t),uje=i(M),$n=n(M,"LI",{});var l0=s($n);hX=n(l0,"STRONG",{});var UFr=s(hX);pje=r(UFr,"distilbert"),UFr.forEach(t),_je=r(l0," \u2014 "),l8=n(l0,"A",{href:!0});var JFr=s(l8);vje=r(JFr,"DistilBertTokenizer"),JFr.forEach(t),bje=r(l0," or "),i8=n(l0,"A",{href:!0});var YFr=s(i8);Tje=r(YFr,"DistilBertTokenizerFast"),YFr.forEach(t),Fje=r(l0," (DistilBERT model)"),l0.forEach(t),Cje=i(M),In=n(M,"LI",{});var i0=s(In);uX=n(i0,"STRONG",{});var KFr=s(uX);Eje=r(KFr,"dpr"),KFr.forEach(t),Mje=r(i0," \u2014 "),d8=n(i0,"A",{href:!0});var ZFr=s(d8);yje=r(ZFr,"DPRQuestionEncoderTokenizer"),ZFr.forEach(t),wje=r(i0," or "),c8=n(i0,"A",{href:!0});var eCr=s(c8);Aje=r(eCr,"DPRQuestionEncoderTokenizerFast"),eCr.forEach(t),Lje=r(i0," (DPR model)"),i0.forEach(t),Bje=i(M),jn=n(M,"LI",{});var d0=s(jn);pX=n(d0,"STRONG",{});var oCr=s(pX);kje=r(oCr,"electra"),oCr.forEach(t),xje=r(d0," \u2014 "),f8=n(d0,"A",{href:!0});var rCr=s(f8);Rje=r(rCr,"ElectraTokenizer"),rCr.forEach(t),Sje=r(d0," or "),m8=n(d0,"A",{href:!0});var tCr=s(m8);Pje=r(tCr,"ElectraTokenizerFast"),tCr.forEach(t),$je=r(d0," (ELECTRA model)"),d0.forEach(t),Ije=i(M),qm=n(M,"LI",{});var ove=s(qm);_X=n(ove,"STRONG",{});var aCr=s(_X);jje=r(aCr,"flaubert"),aCr.forEach(t),Nje=r(ove," \u2014 "),g8=n(ove,"A",{href:!0});var nCr=s(g8);Dje=r(nCr,"FlaubertTokenizer"),nCr.forEach(t),qje=r(ove," (FlauBERT model)"),ove.forEach(t),Oje=i(M),Nn=n(M,"LI",{});var c0=s(Nn);vX=n(c0,"STRONG",{});var sCr=s(vX);Gje=r(sCr,"fnet"),sCr.forEach(t),zje=r(c0," \u2014 "),h8=n(c0,"A",{href:!0});var lCr=s(h8);Vje=r(lCr,"FNetTokenizer"),lCr.forEach(t),Xje=r(c0," or "),u8=n(c0,"A",{href:!0});var iCr=s(u8);Wje=r(iCr,"FNetTokenizerFast"),iCr.forEach(t),Qje=r(c0," (FNet model)"),c0.forEach(t),Hje=i(M),Om=n(M,"LI",{});var rve=s(Om);bX=n(rve,"STRONG",{});var dCr=s(bX);Uje=r(dCr,"fsmt"),dCr.forEach(t),Jje=r(rve," \u2014 "),p8=n(rve,"A",{href:!0});var cCr=s(p8);Yje=r(cCr,"FSMTTokenizer"),cCr.forEach(t),Kje=r(rve," (FairSeq Machine-Translation model)"),rve.forEach(t),Zje=i(M),Dn=n(M,"LI",{});var f0=s(Dn);TX=n(f0,"STRONG",{});var fCr=s(TX);eNe=r(fCr,"funnel"),fCr.forEach(t),oNe=r(f0," \u2014 "),_8=n(f0,"A",{href:!0});var mCr=s(_8);rNe=r(mCr,"FunnelTokenizer"),mCr.forEach(t),tNe=r(f0," or "),v8=n(f0,"A",{href:!0});var gCr=s(v8);aNe=r(gCr,"FunnelTokenizerFast"),gCr.forEach(t),nNe=r(f0," (Funnel Transformer model)"),f0.forEach(t),sNe=i(M),qn=n(M,"LI",{});var m0=s(qn);FX=n(m0,"STRONG",{});var hCr=s(FX);lNe=r(hCr,"gpt2"),hCr.forEach(t),iNe=r(m0," \u2014 "),b8=n(m0,"A",{href:!0});var uCr=s(b8);dNe=r(uCr,"GPT2Tokenizer"),uCr.forEach(t),cNe=r(m0," or "),T8=n(m0,"A",{href:!0});var pCr=s(T8);fNe=r(pCr,"GPT2TokenizerFast"),pCr.forEach(t),mNe=r(m0," (OpenAI GPT-2 model)"),m0.forEach(t),gNe=i(M),On=n(M,"LI",{});var g0=s(On);CX=n(g0,"STRONG",{});var _Cr=s(CX);hNe=r(_Cr,"gpt_neo"),_Cr.forEach(t),uNe=r(g0," \u2014 "),F8=n(g0,"A",{href:!0});var vCr=s(F8);pNe=r(vCr,"GPT2Tokenizer"),vCr.forEach(t),_Ne=r(g0," or "),C8=n(g0,"A",{href:!0});var bCr=s(C8);vNe=r(bCr,"GPT2TokenizerFast"),bCr.forEach(t),bNe=r(g0," (GPT Neo model)"),g0.forEach(t),TNe=i(M),Gn=n(M,"LI",{});var h0=s(Gn);EX=n(h0,"STRONG",{});var TCr=s(EX);FNe=r(TCr,"herbert"),TCr.forEach(t),CNe=r(h0," \u2014 "),E8=n(h0,"A",{href:!0});var FCr=s(E8);ENe=r(FCr,"HerbertTokenizer"),FCr.forEach(t),MNe=r(h0," or "),M8=n(h0,"A",{href:!0});var CCr=s(M8);yNe=r(CCr,"HerbertTokenizerFast"),CCr.forEach(t),wNe=r(h0," (HerBERT model)"),h0.forEach(t),ANe=i(M),Gm=n(M,"LI",{});var tve=s(Gm);MX=n(tve,"STRONG",{});var ECr=s(MX);LNe=r(ECr,"hubert"),ECr.forEach(t),BNe=r(tve," \u2014 "),y8=n(tve,"A",{href:!0});var MCr=s(y8);kNe=r(MCr,"Wav2Vec2CTCTokenizer"),MCr.forEach(t),xNe=r(tve," (Hubert model)"),tve.forEach(t),RNe=i(M),zn=n(M,"LI",{});var u0=s(zn);yX=n(u0,"STRONG",{});var yCr=s(yX);SNe=r(yCr,"ibert"),yCr.forEach(t),PNe=r(u0," \u2014 "),w8=n(u0,"A",{href:!0});var wCr=s(w8);$Ne=r(wCr,"RobertaTokenizer"),wCr.forEach(t),INe=r(u0," or "),A8=n(u0,"A",{href:!0});var ACr=s(A8);jNe=r(ACr,"RobertaTokenizerFast"),ACr.forEach(t),NNe=r(u0," (I-BERT model)"),u0.forEach(t),DNe=i(M),Vn=n(M,"LI",{});var p0=s(Vn);wX=n(p0,"STRONG",{});var LCr=s(wX);qNe=r(LCr,"layoutlm"),LCr.forEach(t),ONe=r(p0," \u2014 "),L8=n(p0,"A",{href:!0});var BCr=s(L8);GNe=r(BCr,"LayoutLMTokenizer"),BCr.forEach(t),zNe=r(p0," or "),B8=n(p0,"A",{href:!0});var kCr=s(B8);VNe=r(kCr,"LayoutLMTokenizerFast"),kCr.forEach(t),XNe=r(p0," (LayoutLM model)"),p0.forEach(t),WNe=i(M),Xn=n(M,"LI",{});var _0=s(Xn);AX=n(_0,"STRONG",{});var xCr=s(AX);QNe=r(xCr,"layoutlmv2"),xCr.forEach(t),HNe=r(_0," \u2014 "),k8=n(_0,"A",{href:!0});var RCr=s(k8);UNe=r(RCr,"LayoutLMv2Tokenizer"),RCr.forEach(t),JNe=r(_0," or "),x8=n(_0,"A",{href:!0});var SCr=s(x8);YNe=r(SCr,"LayoutLMv2TokenizerFast"),SCr.forEach(t),KNe=r(_0," (LayoutLMv2 model)"),_0.forEach(t),ZNe=i(M),Wn=n(M,"LI",{});var v0=s(Wn);LX=n(v0,"STRONG",{});var PCr=s(LX);eDe=r(PCr,"layoutxlm"),PCr.forEach(t),oDe=r(v0," \u2014 "),R8=n(v0,"A",{href:!0});var $Cr=s(R8);rDe=r($Cr,"LayoutXLMTokenizer"),$Cr.forEach(t),tDe=r(v0," or "),S8=n(v0,"A",{href:!0});var ICr=s(S8);aDe=r(ICr,"LayoutXLMTokenizerFast"),ICr.forEach(t),nDe=r(v0," (LayoutXLM model)"),v0.forEach(t),sDe=i(M),Qn=n(M,"LI",{});var b0=s(Qn);BX=n(b0,"STRONG",{});var jCr=s(BX);lDe=r(jCr,"led"),jCr.forEach(t),iDe=r(b0," \u2014 "),P8=n(b0,"A",{href:!0});var NCr=s(P8);dDe=r(NCr,"LEDTokenizer"),NCr.forEach(t),cDe=r(b0," or "),$8=n(b0,"A",{href:!0});var DCr=s($8);fDe=r(DCr,"LEDTokenizerFast"),DCr.forEach(t),mDe=r(b0," (LED model)"),b0.forEach(t),gDe=i(M),Hn=n(M,"LI",{});var T0=s(Hn);kX=n(T0,"STRONG",{});var qCr=s(kX);hDe=r(qCr,"longformer"),qCr.forEach(t),uDe=r(T0," \u2014 "),I8=n(T0,"A",{href:!0});var OCr=s(I8);pDe=r(OCr,"LongformerTokenizer"),OCr.forEach(t),_De=r(T0," or "),j8=n(T0,"A",{href:!0});var GCr=s(j8);vDe=r(GCr,"LongformerTokenizerFast"),GCr.forEach(t),bDe=r(T0," (Longformer model)"),T0.forEach(t),TDe=i(M),zm=n(M,"LI",{});var ave=s(zm);xX=n(ave,"STRONG",{});var zCr=s(xX);FDe=r(zCr,"luke"),zCr.forEach(t),CDe=r(ave," \u2014 "),N8=n(ave,"A",{href:!0});var VCr=s(N8);EDe=r(VCr,"LukeTokenizer"),VCr.forEach(t),MDe=r(ave," (LUKE model)"),ave.forEach(t),yDe=i(M),Un=n(M,"LI",{});var F0=s(Un);RX=n(F0,"STRONG",{});var XCr=s(RX);wDe=r(XCr,"lxmert"),XCr.forEach(t),ADe=r(F0," \u2014 "),D8=n(F0,"A",{href:!0});var WCr=s(D8);LDe=r(WCr,"LxmertTokenizer"),WCr.forEach(t),BDe=r(F0," or "),q8=n(F0,"A",{href:!0});var QCr=s(q8);kDe=r(QCr,"LxmertTokenizerFast"),QCr.forEach(t),xDe=r(F0," (LXMERT model)"),F0.forEach(t),RDe=i(M),Vm=n(M,"LI",{});var nve=s(Vm);SX=n(nve,"STRONG",{});var HCr=s(SX);SDe=r(HCr,"m2m_100"),HCr.forEach(t),PDe=r(nve," \u2014 "),O8=n(nve,"A",{href:!0});var UCr=s(O8);$De=r(UCr,"M2M100Tokenizer"),UCr.forEach(t),IDe=r(nve," (M2M100 model)"),nve.forEach(t),jDe=i(M),Xm=n(M,"LI",{});var sve=s(Xm);PX=n(sve,"STRONG",{});var JCr=s(PX);NDe=r(JCr,"marian"),JCr.forEach(t),DDe=r(sve," \u2014 "),G8=n(sve,"A",{href:!0});var YCr=s(G8);qDe=r(YCr,"MarianTokenizer"),YCr.forEach(t),ODe=r(sve," (Marian model)"),sve.forEach(t),GDe=i(M),Jn=n(M,"LI",{});var C0=s(Jn);$X=n(C0,"STRONG",{});var KCr=s($X);zDe=r(KCr,"mbart"),KCr.forEach(t),VDe=r(C0," \u2014 "),z8=n(C0,"A",{href:!0});var ZCr=s(z8);XDe=r(ZCr,"MBartTokenizer"),ZCr.forEach(t),WDe=r(C0," or "),V8=n(C0,"A",{href:!0});var eEr=s(V8);QDe=r(eEr,"MBartTokenizerFast"),eEr.forEach(t),HDe=r(C0," (mBART model)"),C0.forEach(t),UDe=i(M),Yn=n(M,"LI",{});var E0=s(Yn);IX=n(E0,"STRONG",{});var oEr=s(IX);JDe=r(oEr,"mbart50"),oEr.forEach(t),YDe=r(E0," \u2014 "),X8=n(E0,"A",{href:!0});var rEr=s(X8);KDe=r(rEr,"MBart50Tokenizer"),rEr.forEach(t),ZDe=r(E0," or "),W8=n(E0,"A",{href:!0});var tEr=s(W8);eqe=r(tEr,"MBart50TokenizerFast"),tEr.forEach(t),oqe=r(E0," (mBART-50 model)"),E0.forEach(t),rqe=i(M),Wm=n(M,"LI",{});var lve=s(Wm);jX=n(lve,"STRONG",{});var aEr=s(jX);tqe=r(aEr,"mluke"),aEr.forEach(t),aqe=r(lve," \u2014 "),Q8=n(lve,"A",{href:!0});var nEr=s(Q8);nqe=r(nEr,"MLukeTokenizer"),nEr.forEach(t),sqe=r(lve," (mLUKE model)"),lve.forEach(t),lqe=i(M),Kn=n(M,"LI",{});var M0=s(Kn);NX=n(M0,"STRONG",{});var sEr=s(NX);iqe=r(sEr,"mobilebert"),sEr.forEach(t),dqe=r(M0," \u2014 "),H8=n(M0,"A",{href:!0});var lEr=s(H8);cqe=r(lEr,"MobileBertTokenizer"),lEr.forEach(t),fqe=r(M0," or "),U8=n(M0,"A",{href:!0});var iEr=s(U8);mqe=r(iEr,"MobileBertTokenizerFast"),iEr.forEach(t),gqe=r(M0," (MobileBERT model)"),M0.forEach(t),hqe=i(M),Zn=n(M,"LI",{});var y0=s(Zn);DX=n(y0,"STRONG",{});var dEr=s(DX);uqe=r(dEr,"mpnet"),dEr.forEach(t),pqe=r(y0," \u2014 "),J8=n(y0,"A",{href:!0});var cEr=s(J8);_qe=r(cEr,"MPNetTokenizer"),cEr.forEach(t),vqe=r(y0," or "),Y8=n(y0,"A",{href:!0});var fEr=s(Y8);bqe=r(fEr,"MPNetTokenizerFast"),fEr.forEach(t),Tqe=r(y0," (MPNet model)"),y0.forEach(t),Fqe=i(M),es=n(M,"LI",{});var w0=s(es);qX=n(w0,"STRONG",{});var mEr=s(qX);Cqe=r(mEr,"mt5"),mEr.forEach(t),Eqe=r(w0," \u2014 "),K8=n(w0,"A",{href:!0});var gEr=s(K8);Mqe=r(gEr,"MT5Tokenizer"),gEr.forEach(t),yqe=r(w0," or "),Z8=n(w0,"A",{href:!0});var hEr=s(Z8);wqe=r(hEr,"MT5TokenizerFast"),hEr.forEach(t),Aqe=r(w0," (mT5 model)"),w0.forEach(t),Lqe=i(M),os=n(M,"LI",{});var A0=s(os);OX=n(A0,"STRONG",{});var uEr=s(OX);Bqe=r(uEr,"openai-gpt"),uEr.forEach(t),kqe=r(A0," \u2014 "),eB=n(A0,"A",{href:!0});var pEr=s(eB);xqe=r(pEr,"OpenAIGPTTokenizer"),pEr.forEach(t),Rqe=r(A0," or "),oB=n(A0,"A",{href:!0});var _Er=s(oB);Sqe=r(_Er,"OpenAIGPTTokenizerFast"),_Er.forEach(t),Pqe=r(A0," (OpenAI GPT model)"),A0.forEach(t),$qe=i(M),rs=n(M,"LI",{});var L0=s(rs);GX=n(L0,"STRONG",{});var vEr=s(GX);Iqe=r(vEr,"pegasus"),vEr.forEach(t),jqe=r(L0," \u2014 "),rB=n(L0,"A",{href:!0});var bEr=s(rB);Nqe=r(bEr,"PegasusTokenizer"),bEr.forEach(t),Dqe=r(L0," or "),tB=n(L0,"A",{href:!0});var TEr=s(tB);qqe=r(TEr,"PegasusTokenizerFast"),TEr.forEach(t),Oqe=r(L0," (Pegasus model)"),L0.forEach(t),Gqe=i(M),Qm=n(M,"LI",{});var ive=s(Qm);zX=n(ive,"STRONG",{});var FEr=s(zX);zqe=r(FEr,"perceiver"),FEr.forEach(t),Vqe=r(ive," \u2014 "),aB=n(ive,"A",{href:!0});var CEr=s(aB);Xqe=r(CEr,"PerceiverTokenizer"),CEr.forEach(t),Wqe=r(ive," (Perceiver model)"),ive.forEach(t),Qqe=i(M),Hm=n(M,"LI",{});var dve=s(Hm);VX=n(dve,"STRONG",{});var EEr=s(VX);Hqe=r(EEr,"phobert"),EEr.forEach(t),Uqe=r(dve," \u2014 "),nB=n(dve,"A",{href:!0});var MEr=s(nB);Jqe=r(MEr,"PhobertTokenizer"),MEr.forEach(t),Yqe=r(dve," (PhoBERT model)"),dve.forEach(t),Kqe=i(M),Um=n(M,"LI",{});var cve=s(Um);XX=n(cve,"STRONG",{});var yEr=s(XX);Zqe=r(yEr,"prophetnet"),yEr.forEach(t),eOe=r(cve," \u2014 "),sB=n(cve,"A",{href:!0});var wEr=s(sB);oOe=r(wEr,"ProphetNetTokenizer"),wEr.forEach(t),rOe=r(cve," (ProphetNet model)"),cve.forEach(t),tOe=i(M),ts=n(M,"LI",{});var B0=s(ts);WX=n(B0,"STRONG",{});var AEr=s(WX);aOe=r(AEr,"qdqbert"),AEr.forEach(t),nOe=r(B0," \u2014 "),lB=n(B0,"A",{href:!0});var LEr=s(lB);sOe=r(LEr,"BertTokenizer"),LEr.forEach(t),lOe=r(B0," or "),iB=n(B0,"A",{href:!0});var BEr=s(iB);iOe=r(BEr,"BertTokenizerFast"),BEr.forEach(t),dOe=r(B0," (QDQBert model)"),B0.forEach(t),cOe=i(M),Jm=n(M,"LI",{});var fve=s(Jm);QX=n(fve,"STRONG",{});var kEr=s(QX);fOe=r(kEr,"rag"),kEr.forEach(t),mOe=r(fve," \u2014 "),dB=n(fve,"A",{href:!0});var xEr=s(dB);gOe=r(xEr,"RagTokenizer"),xEr.forEach(t),hOe=r(fve," (RAG model)"),fve.forEach(t),uOe=i(M),as=n(M,"LI",{});var k0=s(as);HX=n(k0,"STRONG",{});var REr=s(HX);pOe=r(REr,"reformer"),REr.forEach(t),_Oe=r(k0," \u2014 "),cB=n(k0,"A",{href:!0});var SEr=s(cB);vOe=r(SEr,"ReformerTokenizer"),SEr.forEach(t),bOe=r(k0," or "),fB=n(k0,"A",{href:!0});var PEr=s(fB);TOe=r(PEr,"ReformerTokenizerFast"),PEr.forEach(t),FOe=r(k0," (Reformer model)"),k0.forEach(t),COe=i(M),ns=n(M,"LI",{});var x0=s(ns);UX=n(x0,"STRONG",{});var $Er=s(UX);EOe=r($Er,"rembert"),$Er.forEach(t),MOe=r(x0," \u2014 "),mB=n(x0,"A",{href:!0});var IEr=s(mB);yOe=r(IEr,"RemBertTokenizer"),IEr.forEach(t),wOe=r(x0," or "),gB=n(x0,"A",{href:!0});var jEr=s(gB);AOe=r(jEr,"RemBertTokenizerFast"),jEr.forEach(t),LOe=r(x0," (RemBERT model)"),x0.forEach(t),BOe=i(M),ss=n(M,"LI",{});var R0=s(ss);JX=n(R0,"STRONG",{});var NEr=s(JX);kOe=r(NEr,"retribert"),NEr.forEach(t),xOe=r(R0," \u2014 "),hB=n(R0,"A",{href:!0});var DEr=s(hB);ROe=r(DEr,"RetriBertTokenizer"),DEr.forEach(t),SOe=r(R0," or "),uB=n(R0,"A",{href:!0});var qEr=s(uB);POe=r(qEr,"RetriBertTokenizerFast"),qEr.forEach(t),$Oe=r(R0," (RetriBERT model)"),R0.forEach(t),IOe=i(M),ls=n(M,"LI",{});var S0=s(ls);YX=n(S0,"STRONG",{});var OEr=s(YX);jOe=r(OEr,"roberta"),OEr.forEach(t),NOe=r(S0," \u2014 "),pB=n(S0,"A",{href:!0});var GEr=s(pB);DOe=r(GEr,"RobertaTokenizer"),GEr.forEach(t),qOe=r(S0," or "),_B=n(S0,"A",{href:!0});var zEr=s(_B);OOe=r(zEr,"RobertaTokenizerFast"),zEr.forEach(t),GOe=r(S0," (RoBERTa model)"),S0.forEach(t),zOe=i(M),is=n(M,"LI",{});var P0=s(is);KX=n(P0,"STRONG",{});var VEr=s(KX);VOe=r(VEr,"roformer"),VEr.forEach(t),XOe=r(P0," \u2014 "),vB=n(P0,"A",{href:!0});var XEr=s(vB);WOe=r(XEr,"RoFormerTokenizer"),XEr.forEach(t),QOe=r(P0," or "),bB=n(P0,"A",{href:!0});var WEr=s(bB);HOe=r(WEr,"RoFormerTokenizerFast"),WEr.forEach(t),UOe=r(P0," (RoFormer model)"),P0.forEach(t),JOe=i(M),Ym=n(M,"LI",{});var mve=s(Ym);ZX=n(mve,"STRONG",{});var QEr=s(ZX);YOe=r(QEr,"speech_to_text"),QEr.forEach(t),KOe=r(mve," \u2014 "),TB=n(mve,"A",{href:!0});var HEr=s(TB);ZOe=r(HEr,"Speech2TextTokenizer"),HEr.forEach(t),eGe=r(mve," (Speech2Text model)"),mve.forEach(t),oGe=i(M),Km=n(M,"LI",{});var gve=s(Km);eW=n(gve,"STRONG",{});var UEr=s(eW);rGe=r(UEr,"speech_to_text_2"),UEr.forEach(t),tGe=r(gve," \u2014 "),FB=n(gve,"A",{href:!0});var JEr=s(FB);aGe=r(JEr,"Speech2Text2Tokenizer"),JEr.forEach(t),nGe=r(gve," (Speech2Text2 model)"),gve.forEach(t),sGe=i(M),ds=n(M,"LI",{});var $0=s(ds);oW=n($0,"STRONG",{});var YEr=s(oW);lGe=r(YEr,"splinter"),YEr.forEach(t),iGe=r($0," \u2014 "),CB=n($0,"A",{href:!0});var KEr=s(CB);dGe=r(KEr,"SplinterTokenizer"),KEr.forEach(t),cGe=r($0," or "),EB=n($0,"A",{href:!0});var ZEr=s(EB);fGe=r(ZEr,"SplinterTokenizerFast"),ZEr.forEach(t),mGe=r($0," (Splinter model)"),$0.forEach(t),gGe=i(M),cs=n(M,"LI",{});var I0=s(cs);rW=n(I0,"STRONG",{});var eMr=s(rW);hGe=r(eMr,"squeezebert"),eMr.forEach(t),uGe=r(I0," \u2014 "),MB=n(I0,"A",{href:!0});var oMr=s(MB);pGe=r(oMr,"SqueezeBertTokenizer"),oMr.forEach(t),_Ge=r(I0," or "),yB=n(I0,"A",{href:!0});var rMr=s(yB);vGe=r(rMr,"SqueezeBertTokenizerFast"),rMr.forEach(t),bGe=r(I0," (SqueezeBERT model)"),I0.forEach(t),TGe=i(M),fs=n(M,"LI",{});var j0=s(fs);tW=n(j0,"STRONG",{});var tMr=s(tW);FGe=r(tMr,"t5"),tMr.forEach(t),CGe=r(j0," \u2014 "),wB=n(j0,"A",{href:!0});var aMr=s(wB);EGe=r(aMr,"T5Tokenizer"),aMr.forEach(t),MGe=r(j0," or "),AB=n(j0,"A",{href:!0});var nMr=s(AB);yGe=r(nMr,"T5TokenizerFast"),nMr.forEach(t),wGe=r(j0," (T5 model)"),j0.forEach(t),AGe=i(M),Zm=n(M,"LI",{});var hve=s(Zm);aW=n(hve,"STRONG",{});var sMr=s(aW);LGe=r(sMr,"tapas"),sMr.forEach(t),BGe=r(hve," \u2014 "),LB=n(hve,"A",{href:!0});var lMr=s(LB);kGe=r(lMr,"TapasTokenizer"),lMr.forEach(t),xGe=r(hve," (TAPAS model)"),hve.forEach(t),RGe=i(M),eg=n(M,"LI",{});var uve=s(eg);nW=n(uve,"STRONG",{});var iMr=s(nW);SGe=r(iMr,"transfo-xl"),iMr.forEach(t),PGe=r(uve," \u2014 "),BB=n(uve,"A",{href:!0});var dMr=s(BB);$Ge=r(dMr,"TransfoXLTokenizer"),dMr.forEach(t),IGe=r(uve," (Transformer-XL model)"),uve.forEach(t),jGe=i(M),og=n(M,"LI",{});var pve=s(og);sW=n(pve,"STRONG",{});var cMr=s(sW);NGe=r(cMr,"wav2vec2"),cMr.forEach(t),DGe=r(pve," \u2014 "),kB=n(pve,"A",{href:!0});var fMr=s(kB);qGe=r(fMr,"Wav2Vec2CTCTokenizer"),fMr.forEach(t),OGe=r(pve," (Wav2Vec2 model)"),pve.forEach(t),GGe=i(M),rg=n(M,"LI",{});var _ve=s(rg);lW=n(_ve,"STRONG",{});var mMr=s(lW);zGe=r(mMr,"wav2vec2_phoneme"),mMr.forEach(t),VGe=r(_ve," \u2014 "),xB=n(_ve,"A",{href:!0});var gMr=s(xB);XGe=r(gMr,"Wav2Vec2PhonemeCTCTokenizer"),gMr.forEach(t),WGe=r(_ve," (Wav2Vec2Phoneme model)"),_ve.forEach(t),QGe=i(M),tg=n(M,"LI",{});var vve=s(tg);iW=n(vve,"STRONG",{});var hMr=s(iW);HGe=r(hMr,"xlm"),hMr.forEach(t),UGe=r(vve," \u2014 "),RB=n(vve,"A",{href:!0});var uMr=s(RB);JGe=r(uMr,"XLMTokenizer"),uMr.forEach(t),YGe=r(vve," (XLM model)"),vve.forEach(t),KGe=i(M),ag=n(M,"LI",{});var bve=s(ag);dW=n(bve,"STRONG",{});var pMr=s(dW);ZGe=r(pMr,"xlm-prophetnet"),pMr.forEach(t),eze=r(bve," \u2014 "),SB=n(bve,"A",{href:!0});var _Mr=s(SB);oze=r(_Mr,"XLMProphetNetTokenizer"),_Mr.forEach(t),rze=r(bve," (XLMProphetNet model)"),bve.forEach(t),tze=i(M),ms=n(M,"LI",{});var N0=s(ms);cW=n(N0,"STRONG",{});var vMr=s(cW);aze=r(vMr,"xlm-roberta"),vMr.forEach(t),nze=r(N0," \u2014 "),PB=n(N0,"A",{href:!0});var bMr=s(PB);sze=r(bMr,"XLMRobertaTokenizer"),bMr.forEach(t),lze=r(N0," or "),$B=n(N0,"A",{href:!0});var TMr=s($B);ize=r(TMr,"XLMRobertaTokenizerFast"),TMr.forEach(t),dze=r(N0," (XLM-RoBERTa model)"),N0.forEach(t),cze=i(M),gs=n(M,"LI",{});var D0=s(gs);fW=n(D0,"STRONG",{});var FMr=s(fW);fze=r(FMr,"xlnet"),FMr.forEach(t),mze=r(D0," \u2014 "),IB=n(D0,"A",{href:!0});var CMr=s(IB);gze=r(CMr,"XLNetTokenizer"),CMr.forEach(t),hze=r(D0," or "),jB=n(D0,"A",{href:!0});var EMr=s(jB);uze=r(EMr,"XLNetTokenizerFast"),EMr.forEach(t),pze=r(D0," (XLNet model)"),D0.forEach(t),M.forEach(t),_ze=i(Kt),mW=n(Kt,"P",{});var MMr=s(mW);vze=r(MMr,"Examples:"),MMr.forEach(t),bze=i(Kt),m(HE.$$.fragment,Kt),Kt.forEach(t),Tze=i(vs),ng=n(vs,"DIV",{class:!0});var s0e=s(ng);m(UE.$$.fragment,s0e),Fze=i(s0e),gW=n(s0e,"P",{});var yMr=s(gW);Cze=r(yMr,"Register a new tokenizer in this mapping."),yMr.forEach(t),s0e.forEach(t),vs.forEach(t),cwe=i(d),mi=n(d,"H2",{class:!0});var l0e=s(mi);sg=n(l0e,"A",{id:!0,class:!0,href:!0});var wMr=s(sg);hW=n(wMr,"SPAN",{});var AMr=s(hW);m(JE.$$.fragment,AMr),AMr.forEach(t),wMr.forEach(t),Eze=i(l0e),uW=n(l0e,"SPAN",{});var LMr=s(uW);Mze=r(LMr,"AutoFeatureExtractor"),LMr.forEach(t),l0e.forEach(t),fwe=i(d),Wt=n(d,"DIV",{class:!0});var jC=s(Wt);m(YE.$$.fragment,jC),yze=i(jC),KE=n(jC,"P",{});var i0e=s(KE);wze=r(i0e,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),NB=n(i0e,"A",{href:!0});var BMr=s(NB);Aze=r(BMr,"AutoFeatureExtractor.from_pretrained()"),BMr.forEach(t),Lze=r(i0e," class method."),i0e.forEach(t),Bze=i(jC),ZE=n(jC,"P",{});var d0e=s(ZE);kze=r(d0e,"This class cannot be instantiated directly using "),pW=n(d0e,"CODE",{});var kMr=s(pW);xze=r(kMr,"__init__()"),kMr.forEach(t),Rze=r(d0e," (throws an error)."),d0e.forEach(t),Sze=i(jC),Ae=n(jC,"DIV",{class:!0});var bt=s(Ae);m(eM.$$.fragment,bt),Pze=i(bt),_W=n(bt,"P",{});var xMr=s(_W);$ze=r(xMr,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),xMr.forEach(t),Ize=i(bt),wa=n(bt,"P",{});var NC=s(wa);jze=r(NC,"The feature extractor class to instantiate is selected based on the "),vW=n(NC,"CODE",{});var RMr=s(vW);Nze=r(RMr,"model_type"),RMr.forEach(t),Dze=r(NC,` property of the config object
(either passed as an argument or loaded from `),bW=n(NC,"CODE",{});var SMr=s(bW);qze=r(SMr,"pretrained_model_name_or_path"),SMr.forEach(t),Oze=r(NC,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),TW=n(NC,"CODE",{});var PMr=s(TW);Gze=r(PMr,"pretrained_model_name_or_path"),PMr.forEach(t),zze=r(NC,":"),NC.forEach(t),Vze=i(bt),ie=n(bt,"UL",{});var fe=s(ie);lg=n(fe,"LI",{});var Tve=s(lg);FW=n(Tve,"STRONG",{});var $Mr=s(FW);Xze=r($Mr,"beit"),$Mr.forEach(t),Wze=r(Tve," \u2014 "),DB=n(Tve,"A",{href:!0});var IMr=s(DB);Qze=r(IMr,"BeitFeatureExtractor"),IMr.forEach(t),Hze=r(Tve," (BEiT model)"),Tve.forEach(t),Uze=i(fe),ig=n(fe,"LI",{});var Fve=s(ig);CW=n(Fve,"STRONG",{});var jMr=s(CW);Jze=r(jMr,"clip"),jMr.forEach(t),Yze=r(Fve," \u2014 "),qB=n(Fve,"A",{href:!0});var NMr=s(qB);Kze=r(NMr,"CLIPFeatureExtractor"),NMr.forEach(t),Zze=r(Fve," (CLIP model)"),Fve.forEach(t),eVe=i(fe),dg=n(fe,"LI",{});var Cve=s(dg);EW=n(Cve,"STRONG",{});var DMr=s(EW);oVe=r(DMr,"deit"),DMr.forEach(t),rVe=r(Cve," \u2014 "),OB=n(Cve,"A",{href:!0});var qMr=s(OB);tVe=r(qMr,"DeiTFeatureExtractor"),qMr.forEach(t),aVe=r(Cve," (DeiT model)"),Cve.forEach(t),nVe=i(fe),cg=n(fe,"LI",{});var Eve=s(cg);MW=n(Eve,"STRONG",{});var OMr=s(MW);sVe=r(OMr,"detr"),OMr.forEach(t),lVe=r(Eve," \u2014 "),GB=n(Eve,"A",{href:!0});var GMr=s(GB);iVe=r(GMr,"DetrFeatureExtractor"),GMr.forEach(t),dVe=r(Eve," (DETR model)"),Eve.forEach(t),cVe=i(fe),fg=n(fe,"LI",{});var Mve=s(fg);yW=n(Mve,"STRONG",{});var zMr=s(yW);fVe=r(zMr,"hubert"),zMr.forEach(t),mVe=r(Mve," \u2014 "),zB=n(Mve,"A",{href:!0});var VMr=s(zB);gVe=r(VMr,"Wav2Vec2FeatureExtractor"),VMr.forEach(t),hVe=r(Mve," (Hubert model)"),Mve.forEach(t),uVe=i(fe),mg=n(fe,"LI",{});var yve=s(mg);wW=n(yve,"STRONG",{});var XMr=s(wW);pVe=r(XMr,"layoutlmv2"),XMr.forEach(t),_Ve=r(yve," \u2014 "),VB=n(yve,"A",{href:!0});var WMr=s(VB);vVe=r(WMr,"LayoutLMv2FeatureExtractor"),WMr.forEach(t),bVe=r(yve," (LayoutLMv2 model)"),yve.forEach(t),TVe=i(fe),gg=n(fe,"LI",{});var wve=s(gg);AW=n(wve,"STRONG",{});var QMr=s(AW);FVe=r(QMr,"perceiver"),QMr.forEach(t),CVe=r(wve," \u2014 "),XB=n(wve,"A",{href:!0});var HMr=s(XB);EVe=r(HMr,"PerceiverFeatureExtractor"),HMr.forEach(t),MVe=r(wve," (Perceiver model)"),wve.forEach(t),yVe=i(fe),hg=n(fe,"LI",{});var Ave=s(hg);LW=n(Ave,"STRONG",{});var UMr=s(LW);wVe=r(UMr,"speech_to_text"),UMr.forEach(t),AVe=r(Ave," \u2014 "),WB=n(Ave,"A",{href:!0});var JMr=s(WB);LVe=r(JMr,"Speech2TextFeatureExtractor"),JMr.forEach(t),BVe=r(Ave," (Speech2Text model)"),Ave.forEach(t),kVe=i(fe),ug=n(fe,"LI",{});var Lve=s(ug);BW=n(Lve,"STRONG",{});var YMr=s(BW);xVe=r(YMr,"swin"),YMr.forEach(t),RVe=r(Lve," \u2014 "),QB=n(Lve,"A",{href:!0});var KMr=s(QB);SVe=r(KMr,"ViTFeatureExtractor"),KMr.forEach(t),PVe=r(Lve," (Swin model)"),Lve.forEach(t),$Ve=i(fe),pg=n(fe,"LI",{});var Bve=s(pg);kW=n(Bve,"STRONG",{});var ZMr=s(kW);IVe=r(ZMr,"vit"),ZMr.forEach(t),jVe=r(Bve," \u2014 "),HB=n(Bve,"A",{href:!0});var e3r=s(HB);NVe=r(e3r,"ViTFeatureExtractor"),e3r.forEach(t),DVe=r(Bve," (ViT model)"),Bve.forEach(t),qVe=i(fe),_g=n(fe,"LI",{});var kve=s(_g);xW=n(kve,"STRONG",{});var o3r=s(xW);OVe=r(o3r,"vit_mae"),o3r.forEach(t),GVe=r(kve," \u2014 "),UB=n(kve,"A",{href:!0});var r3r=s(UB);zVe=r(r3r,"ViTFeatureExtractor"),r3r.forEach(t),VVe=r(kve," (ViTMAE model)"),kve.forEach(t),XVe=i(fe),vg=n(fe,"LI",{});var xve=s(vg);RW=n(xve,"STRONG",{});var t3r=s(RW);WVe=r(t3r,"wav2vec2"),t3r.forEach(t),QVe=r(xve," \u2014 "),JB=n(xve,"A",{href:!0});var a3r=s(JB);HVe=r(a3r,"Wav2Vec2FeatureExtractor"),a3r.forEach(t),UVe=r(xve," (Wav2Vec2 model)"),xve.forEach(t),fe.forEach(t),JVe=i(bt),m(bg.$$.fragment,bt),YVe=i(bt),SW=n(bt,"P",{});var n3r=s(SW);KVe=r(n3r,"Examples:"),n3r.forEach(t),ZVe=i(bt),m(oM.$$.fragment,bt),bt.forEach(t),jC.forEach(t),mwe=i(d),gi=n(d,"H2",{class:!0});var c0e=s(gi);Tg=n(c0e,"A",{id:!0,class:!0,href:!0});var s3r=s(Tg);PW=n(s3r,"SPAN",{});var l3r=s(PW);m(rM.$$.fragment,l3r),l3r.forEach(t),s3r.forEach(t),eXe=i(c0e),$W=n(c0e,"SPAN",{});var i3r=s($W);oXe=r(i3r,"AutoProcessor"),i3r.forEach(t),c0e.forEach(t),gwe=i(d),Qt=n(d,"DIV",{class:!0});var DC=s(Qt);m(tM.$$.fragment,DC),rXe=i(DC),aM=n(DC,"P",{});var f0e=s(aM);tXe=r(f0e,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),YB=n(f0e,"A",{href:!0});var d3r=s(YB);aXe=r(d3r,"AutoProcessor.from_pretrained()"),d3r.forEach(t),nXe=r(f0e," class method."),f0e.forEach(t),sXe=i(DC),nM=n(DC,"P",{});var m0e=s(nM);lXe=r(m0e,"This class cannot be instantiated directly using "),IW=n(m0e,"CODE",{});var c3r=s(IW);iXe=r(c3r,"__init__()"),c3r.forEach(t),dXe=r(m0e," (throws an error)."),m0e.forEach(t),cXe=i(DC),Le=n(DC,"DIV",{class:!0});var Tt=s(Le);m(sM.$$.fragment,Tt),fXe=i(Tt),jW=n(Tt,"P",{});var f3r=s(jW);mXe=r(f3r,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),f3r.forEach(t),gXe=i(Tt),hi=n(Tt,"P",{});var fO=s(hi);hXe=r(fO,"The processor class to instantiate is selected based on the "),NW=n(fO,"CODE",{});var m3r=s(NW);uXe=r(m3r,"model_type"),m3r.forEach(t),pXe=r(fO,` property of the config object (either
passed as an argument or loaded from `),DW=n(fO,"CODE",{});var g3r=s(DW);_Xe=r(g3r,"pretrained_model_name_or_path"),g3r.forEach(t),vXe=r(fO," if possible):"),fO.forEach(t),bXe=i(Tt),ye=n(Tt,"UL",{});var Po=s(ye);Fg=n(Po,"LI",{});var Rve=s(Fg);qW=n(Rve,"STRONG",{});var h3r=s(qW);TXe=r(h3r,"clip"),h3r.forEach(t),FXe=r(Rve," \u2014 "),KB=n(Rve,"A",{href:!0});var u3r=s(KB);CXe=r(u3r,"CLIPProcessor"),u3r.forEach(t),EXe=r(Rve," (CLIP model)"),Rve.forEach(t),MXe=i(Po),Cg=n(Po,"LI",{});var Sve=s(Cg);OW=n(Sve,"STRONG",{});var p3r=s(OW);yXe=r(p3r,"layoutlmv2"),p3r.forEach(t),wXe=r(Sve," \u2014 "),ZB=n(Sve,"A",{href:!0});var _3r=s(ZB);AXe=r(_3r,"LayoutLMv2Processor"),_3r.forEach(t),LXe=r(Sve," (LayoutLMv2 model)"),Sve.forEach(t),BXe=i(Po),Eg=n(Po,"LI",{});var Pve=s(Eg);GW=n(Pve,"STRONG",{});var v3r=s(GW);kXe=r(v3r,"layoutxlm"),v3r.forEach(t),xXe=r(Pve," \u2014 "),e9=n(Pve,"A",{href:!0});var b3r=s(e9);RXe=r(b3r,"LayoutXLMProcessor"),b3r.forEach(t),SXe=r(Pve," (LayoutXLM model)"),Pve.forEach(t),PXe=i(Po),Mg=n(Po,"LI",{});var $ve=s(Mg);zW=n($ve,"STRONG",{});var T3r=s(zW);$Xe=r(T3r,"speech_to_text"),T3r.forEach(t),IXe=r($ve," \u2014 "),o9=n($ve,"A",{href:!0});var F3r=s(o9);jXe=r(F3r,"Speech2TextProcessor"),F3r.forEach(t),NXe=r($ve," (Speech2Text model)"),$ve.forEach(t),DXe=i(Po),yg=n(Po,"LI",{});var Ive=s(yg);VW=n(Ive,"STRONG",{});var C3r=s(VW);qXe=r(C3r,"speech_to_text_2"),C3r.forEach(t),OXe=r(Ive," \u2014 "),r9=n(Ive,"A",{href:!0});var E3r=s(r9);GXe=r(E3r,"Speech2Text2Processor"),E3r.forEach(t),zXe=r(Ive," (Speech2Text2 model)"),Ive.forEach(t),VXe=i(Po),wg=n(Po,"LI",{});var jve=s(wg);XW=n(jve,"STRONG",{});var M3r=s(XW);XXe=r(M3r,"trocr"),M3r.forEach(t),WXe=r(jve," \u2014 "),t9=n(jve,"A",{href:!0});var y3r=s(t9);QXe=r(y3r,"TrOCRProcessor"),y3r.forEach(t),HXe=r(jve," (TrOCR model)"),jve.forEach(t),UXe=i(Po),Ag=n(Po,"LI",{});var Nve=s(Ag);WW=n(Nve,"STRONG",{});var w3r=s(WW);JXe=r(w3r,"vision-text-dual-encoder"),w3r.forEach(t),YXe=r(Nve," \u2014 "),a9=n(Nve,"A",{href:!0});var A3r=s(a9);KXe=r(A3r,"VisionTextDualEncoderProcessor"),A3r.forEach(t),ZXe=r(Nve," (VisionTextDualEncoder model)"),Nve.forEach(t),eWe=i(Po),Lg=n(Po,"LI",{});var Dve=s(Lg);QW=n(Dve,"STRONG",{});var L3r=s(QW);oWe=r(L3r,"wav2vec2"),L3r.forEach(t),rWe=r(Dve," \u2014 "),n9=n(Dve,"A",{href:!0});var B3r=s(n9);tWe=r(B3r,"Wav2Vec2Processor"),B3r.forEach(t),aWe=r(Dve," (Wav2Vec2 model)"),Dve.forEach(t),Po.forEach(t),nWe=i(Tt),m(Bg.$$.fragment,Tt),sWe=i(Tt),HW=n(Tt,"P",{});var k3r=s(HW);lWe=r(k3r,"Examples:"),k3r.forEach(t),iWe=i(Tt),m(lM.$$.fragment,Tt),Tt.forEach(t),DC.forEach(t),hwe=i(d),ui=n(d,"H2",{class:!0});var g0e=s(ui);kg=n(g0e,"A",{id:!0,class:!0,href:!0});var x3r=s(kg);UW=n(x3r,"SPAN",{});var R3r=s(UW);m(iM.$$.fragment,R3r),R3r.forEach(t),x3r.forEach(t),dWe=i(g0e),JW=n(g0e,"SPAN",{});var S3r=s(JW);cWe=r(S3r,"AutoModel"),S3r.forEach(t),g0e.forEach(t),uwe=i(d),Do=n(d,"DIV",{class:!0});var bs=s(Do);m(dM.$$.fragment,bs),fWe=i(bs),pi=n(bs,"P",{});var mO=s(pi);mWe=r(mO,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),YW=n(mO,"CODE",{});var P3r=s(YW);gWe=r(P3r,"from_pretrained()"),P3r.forEach(t),hWe=r(mO,"class method or the "),KW=n(mO,"CODE",{});var $3r=s(KW);uWe=r($3r,"from_config()"),$3r.forEach(t),pWe=r(mO,`class
method.`),mO.forEach(t),_We=i(bs),cM=n(bs,"P",{});var h0e=s(cM);vWe=r(h0e,"This class cannot be instantiated directly using "),ZW=n(h0e,"CODE",{});var I3r=s(ZW);bWe=r(I3r,"__init__()"),I3r.forEach(t),TWe=r(h0e," (throws an error)."),h0e.forEach(t),FWe=i(bs),Br=n(bs,"DIV",{class:!0});var Ts=s(Br);m(fM.$$.fragment,Ts),CWe=i(Ts),eQ=n(Ts,"P",{});var j3r=s(eQ);EWe=r(j3r,"Instantiates one of the base model classes of the library from a configuration."),j3r.forEach(t),MWe=i(Ts),_i=n(Ts,"P",{});var gO=s(_i);yWe=r(gO,`Note:
Loading a model from its configuration file does `),oQ=n(gO,"STRONG",{});var N3r=s(oQ);wWe=r(N3r,"not"),N3r.forEach(t),AWe=r(gO,` load the model weights. It only affects the
model\u2019s configuration. Use `),rQ=n(gO,"CODE",{});var D3r=s(rQ);LWe=r(D3r,"from_pretrained()"),D3r.forEach(t),BWe=r(gO,"to load the model weights."),gO.forEach(t),kWe=i(Ts),tQ=n(Ts,"P",{});var q3r=s(tQ);xWe=r(q3r,"Examples:"),q3r.forEach(t),RWe=i(Ts),m(mM.$$.fragment,Ts),Ts.forEach(t),SWe=i(bs),Be=n(bs,"DIV",{class:!0});var Ft=s(Be);m(gM.$$.fragment,Ft),PWe=i(Ft),aQ=n(Ft,"P",{});var O3r=s(aQ);$We=r(O3r,"Instantiate one of the base model classes of the library from a pretrained model."),O3r.forEach(t),IWe=i(Ft),Aa=n(Ft,"P",{});var qC=s(Aa);jWe=r(qC,"The model class to instantiate is selected based on the "),nQ=n(qC,"CODE",{});var G3r=s(nQ);NWe=r(G3r,"model_type"),G3r.forEach(t),DWe=r(qC,` property of the config object (either
passed as an argument or loaded from `),sQ=n(qC,"CODE",{});var z3r=s(sQ);qWe=r(z3r,"pretrained_model_name_or_path"),z3r.forEach(t),OWe=r(qC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lQ=n(qC,"CODE",{});var V3r=s(lQ);GWe=r(V3r,"pretrained_model_name_or_path"),V3r.forEach(t),zWe=r(qC,":"),qC.forEach(t),VWe=i(Ft),F=n(Ft,"UL",{});var C=s(F);xg=n(C,"LI",{});var qve=s(xg);iQ=n(qve,"STRONG",{});var X3r=s(iQ);XWe=r(X3r,"albert"),X3r.forEach(t),WWe=r(qve," \u2014 "),s9=n(qve,"A",{href:!0});var W3r=s(s9);QWe=r(W3r,"AlbertModel"),W3r.forEach(t),HWe=r(qve," (ALBERT model)"),qve.forEach(t),UWe=i(C),Rg=n(C,"LI",{});var Ove=s(Rg);dQ=n(Ove,"STRONG",{});var Q3r=s(dQ);JWe=r(Q3r,"bart"),Q3r.forEach(t),YWe=r(Ove," \u2014 "),l9=n(Ove,"A",{href:!0});var H3r=s(l9);KWe=r(H3r,"BartModel"),H3r.forEach(t),ZWe=r(Ove," (BART model)"),Ove.forEach(t),eQe=i(C),Sg=n(C,"LI",{});var Gve=s(Sg);cQ=n(Gve,"STRONG",{});var U3r=s(cQ);oQe=r(U3r,"beit"),U3r.forEach(t),rQe=r(Gve," \u2014 "),i9=n(Gve,"A",{href:!0});var J3r=s(i9);tQe=r(J3r,"BeitModel"),J3r.forEach(t),aQe=r(Gve," (BEiT model)"),Gve.forEach(t),nQe=i(C),Pg=n(C,"LI",{});var zve=s(Pg);fQ=n(zve,"STRONG",{});var Y3r=s(fQ);sQe=r(Y3r,"bert"),Y3r.forEach(t),lQe=r(zve," \u2014 "),d9=n(zve,"A",{href:!0});var K3r=s(d9);iQe=r(K3r,"BertModel"),K3r.forEach(t),dQe=r(zve," (BERT model)"),zve.forEach(t),cQe=i(C),$g=n(C,"LI",{});var Vve=s($g);mQ=n(Vve,"STRONG",{});var Z3r=s(mQ);fQe=r(Z3r,"bert-generation"),Z3r.forEach(t),mQe=r(Vve," \u2014 "),c9=n(Vve,"A",{href:!0});var e5r=s(c9);gQe=r(e5r,"BertGenerationEncoder"),e5r.forEach(t),hQe=r(Vve," (Bert Generation model)"),Vve.forEach(t),uQe=i(C),Ig=n(C,"LI",{});var Xve=s(Ig);gQ=n(Xve,"STRONG",{});var o5r=s(gQ);pQe=r(o5r,"big_bird"),o5r.forEach(t),_Qe=r(Xve," \u2014 "),f9=n(Xve,"A",{href:!0});var r5r=s(f9);vQe=r(r5r,"BigBirdModel"),r5r.forEach(t),bQe=r(Xve," (BigBird model)"),Xve.forEach(t),TQe=i(C),jg=n(C,"LI",{});var Wve=s(jg);hQ=n(Wve,"STRONG",{});var t5r=s(hQ);FQe=r(t5r,"bigbird_pegasus"),t5r.forEach(t),CQe=r(Wve," \u2014 "),m9=n(Wve,"A",{href:!0});var a5r=s(m9);EQe=r(a5r,"BigBirdPegasusModel"),a5r.forEach(t),MQe=r(Wve," (BigBirdPegasus model)"),Wve.forEach(t),yQe=i(C),Ng=n(C,"LI",{});var Qve=s(Ng);uQ=n(Qve,"STRONG",{});var n5r=s(uQ);wQe=r(n5r,"blenderbot"),n5r.forEach(t),AQe=r(Qve," \u2014 "),g9=n(Qve,"A",{href:!0});var s5r=s(g9);LQe=r(s5r,"BlenderbotModel"),s5r.forEach(t),BQe=r(Qve," (Blenderbot model)"),Qve.forEach(t),kQe=i(C),Dg=n(C,"LI",{});var Hve=s(Dg);pQ=n(Hve,"STRONG",{});var l5r=s(pQ);xQe=r(l5r,"blenderbot-small"),l5r.forEach(t),RQe=r(Hve," \u2014 "),h9=n(Hve,"A",{href:!0});var i5r=s(h9);SQe=r(i5r,"BlenderbotSmallModel"),i5r.forEach(t),PQe=r(Hve," (BlenderbotSmall model)"),Hve.forEach(t),$Qe=i(C),qg=n(C,"LI",{});var Uve=s(qg);_Q=n(Uve,"STRONG",{});var d5r=s(_Q);IQe=r(d5r,"camembert"),d5r.forEach(t),jQe=r(Uve," \u2014 "),u9=n(Uve,"A",{href:!0});var c5r=s(u9);NQe=r(c5r,"CamembertModel"),c5r.forEach(t),DQe=r(Uve," (CamemBERT model)"),Uve.forEach(t),qQe=i(C),Og=n(C,"LI",{});var Jve=s(Og);vQ=n(Jve,"STRONG",{});var f5r=s(vQ);OQe=r(f5r,"canine"),f5r.forEach(t),GQe=r(Jve," \u2014 "),p9=n(Jve,"A",{href:!0});var m5r=s(p9);zQe=r(m5r,"CanineModel"),m5r.forEach(t),VQe=r(Jve," (Canine model)"),Jve.forEach(t),XQe=i(C),Gg=n(C,"LI",{});var Yve=s(Gg);bQ=n(Yve,"STRONG",{});var g5r=s(bQ);WQe=r(g5r,"clip"),g5r.forEach(t),QQe=r(Yve," \u2014 "),_9=n(Yve,"A",{href:!0});var h5r=s(_9);HQe=r(h5r,"CLIPModel"),h5r.forEach(t),UQe=r(Yve," (CLIP model)"),Yve.forEach(t),JQe=i(C),zg=n(C,"LI",{});var Kve=s(zg);TQ=n(Kve,"STRONG",{});var u5r=s(TQ);YQe=r(u5r,"convbert"),u5r.forEach(t),KQe=r(Kve," \u2014 "),v9=n(Kve,"A",{href:!0});var p5r=s(v9);ZQe=r(p5r,"ConvBertModel"),p5r.forEach(t),eHe=r(Kve," (ConvBERT model)"),Kve.forEach(t),oHe=i(C),Vg=n(C,"LI",{});var Zve=s(Vg);FQ=n(Zve,"STRONG",{});var _5r=s(FQ);rHe=r(_5r,"ctrl"),_5r.forEach(t),tHe=r(Zve," \u2014 "),b9=n(Zve,"A",{href:!0});var v5r=s(b9);aHe=r(v5r,"CTRLModel"),v5r.forEach(t),nHe=r(Zve," (CTRL model)"),Zve.forEach(t),sHe=i(C),Xg=n(C,"LI",{});var e1e=s(Xg);CQ=n(e1e,"STRONG",{});var b5r=s(CQ);lHe=r(b5r,"deberta"),b5r.forEach(t),iHe=r(e1e," \u2014 "),T9=n(e1e,"A",{href:!0});var T5r=s(T9);dHe=r(T5r,"DebertaModel"),T5r.forEach(t),cHe=r(e1e," (DeBERTa model)"),e1e.forEach(t),fHe=i(C),Wg=n(C,"LI",{});var o1e=s(Wg);EQ=n(o1e,"STRONG",{});var F5r=s(EQ);mHe=r(F5r,"deberta-v2"),F5r.forEach(t),gHe=r(o1e," \u2014 "),F9=n(o1e,"A",{href:!0});var C5r=s(F9);hHe=r(C5r,"DebertaV2Model"),C5r.forEach(t),uHe=r(o1e," (DeBERTa-v2 model)"),o1e.forEach(t),pHe=i(C),Qg=n(C,"LI",{});var r1e=s(Qg);MQ=n(r1e,"STRONG",{});var E5r=s(MQ);_He=r(E5r,"deit"),E5r.forEach(t),vHe=r(r1e," \u2014 "),C9=n(r1e,"A",{href:!0});var M5r=s(C9);bHe=r(M5r,"DeiTModel"),M5r.forEach(t),THe=r(r1e," (DeiT model)"),r1e.forEach(t),FHe=i(C),Hg=n(C,"LI",{});var t1e=s(Hg);yQ=n(t1e,"STRONG",{});var y5r=s(yQ);CHe=r(y5r,"detr"),y5r.forEach(t),EHe=r(t1e," \u2014 "),E9=n(t1e,"A",{href:!0});var w5r=s(E9);MHe=r(w5r,"DetrModel"),w5r.forEach(t),yHe=r(t1e," (DETR model)"),t1e.forEach(t),wHe=i(C),Ug=n(C,"LI",{});var a1e=s(Ug);wQ=n(a1e,"STRONG",{});var A5r=s(wQ);AHe=r(A5r,"distilbert"),A5r.forEach(t),LHe=r(a1e," \u2014 "),M9=n(a1e,"A",{href:!0});var L5r=s(M9);BHe=r(L5r,"DistilBertModel"),L5r.forEach(t),kHe=r(a1e," (DistilBERT model)"),a1e.forEach(t),xHe=i(C),Jg=n(C,"LI",{});var n1e=s(Jg);AQ=n(n1e,"STRONG",{});var B5r=s(AQ);RHe=r(B5r,"dpr"),B5r.forEach(t),SHe=r(n1e," \u2014 "),y9=n(n1e,"A",{href:!0});var k5r=s(y9);PHe=r(k5r,"DPRQuestionEncoder"),k5r.forEach(t),$He=r(n1e," (DPR model)"),n1e.forEach(t),IHe=i(C),Yg=n(C,"LI",{});var s1e=s(Yg);LQ=n(s1e,"STRONG",{});var x5r=s(LQ);jHe=r(x5r,"electra"),x5r.forEach(t),NHe=r(s1e," \u2014 "),w9=n(s1e,"A",{href:!0});var R5r=s(w9);DHe=r(R5r,"ElectraModel"),R5r.forEach(t),qHe=r(s1e," (ELECTRA model)"),s1e.forEach(t),OHe=i(C),Kg=n(C,"LI",{});var l1e=s(Kg);BQ=n(l1e,"STRONG",{});var S5r=s(BQ);GHe=r(S5r,"flaubert"),S5r.forEach(t),zHe=r(l1e," \u2014 "),A9=n(l1e,"A",{href:!0});var P5r=s(A9);VHe=r(P5r,"FlaubertModel"),P5r.forEach(t),XHe=r(l1e," (FlauBERT model)"),l1e.forEach(t),WHe=i(C),Zg=n(C,"LI",{});var i1e=s(Zg);kQ=n(i1e,"STRONG",{});var $5r=s(kQ);QHe=r($5r,"fnet"),$5r.forEach(t),HHe=r(i1e," \u2014 "),L9=n(i1e,"A",{href:!0});var I5r=s(L9);UHe=r(I5r,"FNetModel"),I5r.forEach(t),JHe=r(i1e," (FNet model)"),i1e.forEach(t),YHe=i(C),eh=n(C,"LI",{});var d1e=s(eh);xQ=n(d1e,"STRONG",{});var j5r=s(xQ);KHe=r(j5r,"fsmt"),j5r.forEach(t),ZHe=r(d1e," \u2014 "),B9=n(d1e,"A",{href:!0});var N5r=s(B9);eUe=r(N5r,"FSMTModel"),N5r.forEach(t),oUe=r(d1e," (FairSeq Machine-Translation model)"),d1e.forEach(t),rUe=i(C),hs=n(C,"LI",{});var q0=s(hs);RQ=n(q0,"STRONG",{});var D5r=s(RQ);tUe=r(D5r,"funnel"),D5r.forEach(t),aUe=r(q0," \u2014 "),k9=n(q0,"A",{href:!0});var q5r=s(k9);nUe=r(q5r,"FunnelModel"),q5r.forEach(t),sUe=r(q0," or "),x9=n(q0,"A",{href:!0});var O5r=s(x9);lUe=r(O5r,"FunnelBaseModel"),O5r.forEach(t),iUe=r(q0," (Funnel Transformer model)"),q0.forEach(t),dUe=i(C),oh=n(C,"LI",{});var c1e=s(oh);SQ=n(c1e,"STRONG",{});var G5r=s(SQ);cUe=r(G5r,"gpt2"),G5r.forEach(t),fUe=r(c1e," \u2014 "),R9=n(c1e,"A",{href:!0});var z5r=s(R9);mUe=r(z5r,"GPT2Model"),z5r.forEach(t),gUe=r(c1e," (OpenAI GPT-2 model)"),c1e.forEach(t),hUe=i(C),rh=n(C,"LI",{});var f1e=s(rh);PQ=n(f1e,"STRONG",{});var V5r=s(PQ);uUe=r(V5r,"gpt_neo"),V5r.forEach(t),pUe=r(f1e," \u2014 "),S9=n(f1e,"A",{href:!0});var X5r=s(S9);_Ue=r(X5r,"GPTNeoModel"),X5r.forEach(t),vUe=r(f1e," (GPT Neo model)"),f1e.forEach(t),bUe=i(C),th=n(C,"LI",{});var m1e=s(th);$Q=n(m1e,"STRONG",{});var W5r=s($Q);TUe=r(W5r,"gptj"),W5r.forEach(t),FUe=r(m1e," \u2014 "),P9=n(m1e,"A",{href:!0});var Q5r=s(P9);CUe=r(Q5r,"GPTJModel"),Q5r.forEach(t),EUe=r(m1e," (GPT-J model)"),m1e.forEach(t),MUe=i(C),ah=n(C,"LI",{});var g1e=s(ah);IQ=n(g1e,"STRONG",{});var H5r=s(IQ);yUe=r(H5r,"hubert"),H5r.forEach(t),wUe=r(g1e," \u2014 "),$9=n(g1e,"A",{href:!0});var U5r=s($9);AUe=r(U5r,"HubertModel"),U5r.forEach(t),LUe=r(g1e," (Hubert model)"),g1e.forEach(t),BUe=i(C),nh=n(C,"LI",{});var h1e=s(nh);jQ=n(h1e,"STRONG",{});var J5r=s(jQ);kUe=r(J5r,"ibert"),J5r.forEach(t),xUe=r(h1e," \u2014 "),I9=n(h1e,"A",{href:!0});var Y5r=s(I9);RUe=r(Y5r,"IBertModel"),Y5r.forEach(t),SUe=r(h1e," (I-BERT model)"),h1e.forEach(t),PUe=i(C),sh=n(C,"LI",{});var u1e=s(sh);NQ=n(u1e,"STRONG",{});var K5r=s(NQ);$Ue=r(K5r,"imagegpt"),K5r.forEach(t),IUe=r(u1e," \u2014 "),j9=n(u1e,"A",{href:!0});var Z5r=s(j9);jUe=r(Z5r,"ImageGPTModel"),Z5r.forEach(t),NUe=r(u1e," (ImageGPT model)"),u1e.forEach(t),DUe=i(C),lh=n(C,"LI",{});var p1e=s(lh);DQ=n(p1e,"STRONG",{});var eyr=s(DQ);qUe=r(eyr,"layoutlm"),eyr.forEach(t),OUe=r(p1e," \u2014 "),N9=n(p1e,"A",{href:!0});var oyr=s(N9);GUe=r(oyr,"LayoutLMModel"),oyr.forEach(t),zUe=r(p1e," (LayoutLM model)"),p1e.forEach(t),VUe=i(C),ih=n(C,"LI",{});var _1e=s(ih);qQ=n(_1e,"STRONG",{});var ryr=s(qQ);XUe=r(ryr,"layoutlmv2"),ryr.forEach(t),WUe=r(_1e," \u2014 "),D9=n(_1e,"A",{href:!0});var tyr=s(D9);QUe=r(tyr,"LayoutLMv2Model"),tyr.forEach(t),HUe=r(_1e," (LayoutLMv2 model)"),_1e.forEach(t),UUe=i(C),dh=n(C,"LI",{});var v1e=s(dh);OQ=n(v1e,"STRONG",{});var ayr=s(OQ);JUe=r(ayr,"led"),ayr.forEach(t),YUe=r(v1e," \u2014 "),q9=n(v1e,"A",{href:!0});var nyr=s(q9);KUe=r(nyr,"LEDModel"),nyr.forEach(t),ZUe=r(v1e," (LED model)"),v1e.forEach(t),eJe=i(C),ch=n(C,"LI",{});var b1e=s(ch);GQ=n(b1e,"STRONG",{});var syr=s(GQ);oJe=r(syr,"longformer"),syr.forEach(t),rJe=r(b1e," \u2014 "),O9=n(b1e,"A",{href:!0});var lyr=s(O9);tJe=r(lyr,"LongformerModel"),lyr.forEach(t),aJe=r(b1e," (Longformer model)"),b1e.forEach(t),nJe=i(C),fh=n(C,"LI",{});var T1e=s(fh);zQ=n(T1e,"STRONG",{});var iyr=s(zQ);sJe=r(iyr,"luke"),iyr.forEach(t),lJe=r(T1e," \u2014 "),G9=n(T1e,"A",{href:!0});var dyr=s(G9);iJe=r(dyr,"LukeModel"),dyr.forEach(t),dJe=r(T1e," (LUKE model)"),T1e.forEach(t),cJe=i(C),mh=n(C,"LI",{});var F1e=s(mh);VQ=n(F1e,"STRONG",{});var cyr=s(VQ);fJe=r(cyr,"lxmert"),cyr.forEach(t),mJe=r(F1e," \u2014 "),z9=n(F1e,"A",{href:!0});var fyr=s(z9);gJe=r(fyr,"LxmertModel"),fyr.forEach(t),hJe=r(F1e," (LXMERT model)"),F1e.forEach(t),uJe=i(C),gh=n(C,"LI",{});var C1e=s(gh);XQ=n(C1e,"STRONG",{});var myr=s(XQ);pJe=r(myr,"m2m_100"),myr.forEach(t),_Je=r(C1e," \u2014 "),V9=n(C1e,"A",{href:!0});var gyr=s(V9);vJe=r(gyr,"M2M100Model"),gyr.forEach(t),bJe=r(C1e," (M2M100 model)"),C1e.forEach(t),TJe=i(C),hh=n(C,"LI",{});var E1e=s(hh);WQ=n(E1e,"STRONG",{});var hyr=s(WQ);FJe=r(hyr,"marian"),hyr.forEach(t),CJe=r(E1e," \u2014 "),X9=n(E1e,"A",{href:!0});var uyr=s(X9);EJe=r(uyr,"MarianModel"),uyr.forEach(t),MJe=r(E1e," (Marian model)"),E1e.forEach(t),yJe=i(C),uh=n(C,"LI",{});var M1e=s(uh);QQ=n(M1e,"STRONG",{});var pyr=s(QQ);wJe=r(pyr,"mbart"),pyr.forEach(t),AJe=r(M1e," \u2014 "),W9=n(M1e,"A",{href:!0});var _yr=s(W9);LJe=r(_yr,"MBartModel"),_yr.forEach(t),BJe=r(M1e," (mBART model)"),M1e.forEach(t),kJe=i(C),ph=n(C,"LI",{});var y1e=s(ph);HQ=n(y1e,"STRONG",{});var vyr=s(HQ);xJe=r(vyr,"megatron-bert"),vyr.forEach(t),RJe=r(y1e," \u2014 "),Q9=n(y1e,"A",{href:!0});var byr=s(Q9);SJe=r(byr,"MegatronBertModel"),byr.forEach(t),PJe=r(y1e," (MegatronBert model)"),y1e.forEach(t),$Je=i(C),_h=n(C,"LI",{});var w1e=s(_h);UQ=n(w1e,"STRONG",{});var Tyr=s(UQ);IJe=r(Tyr,"mobilebert"),Tyr.forEach(t),jJe=r(w1e," \u2014 "),H9=n(w1e,"A",{href:!0});var Fyr=s(H9);NJe=r(Fyr,"MobileBertModel"),Fyr.forEach(t),DJe=r(w1e," (MobileBERT model)"),w1e.forEach(t),qJe=i(C),vh=n(C,"LI",{});var A1e=s(vh);JQ=n(A1e,"STRONG",{});var Cyr=s(JQ);OJe=r(Cyr,"mpnet"),Cyr.forEach(t),GJe=r(A1e," \u2014 "),U9=n(A1e,"A",{href:!0});var Eyr=s(U9);zJe=r(Eyr,"MPNetModel"),Eyr.forEach(t),VJe=r(A1e," (MPNet model)"),A1e.forEach(t),XJe=i(C),bh=n(C,"LI",{});var L1e=s(bh);YQ=n(L1e,"STRONG",{});var Myr=s(YQ);WJe=r(Myr,"mt5"),Myr.forEach(t),QJe=r(L1e," \u2014 "),J9=n(L1e,"A",{href:!0});var yyr=s(J9);HJe=r(yyr,"MT5Model"),yyr.forEach(t),UJe=r(L1e," (mT5 model)"),L1e.forEach(t),JJe=i(C),Th=n(C,"LI",{});var B1e=s(Th);KQ=n(B1e,"STRONG",{});var wyr=s(KQ);YJe=r(wyr,"nystromformer"),wyr.forEach(t),KJe=r(B1e," \u2014 "),Y9=n(B1e,"A",{href:!0});var Ayr=s(Y9);ZJe=r(Ayr,"NystromformerModel"),Ayr.forEach(t),eYe=r(B1e," (Nystromformer model)"),B1e.forEach(t),oYe=i(C),Fh=n(C,"LI",{});var k1e=s(Fh);ZQ=n(k1e,"STRONG",{});var Lyr=s(ZQ);rYe=r(Lyr,"openai-gpt"),Lyr.forEach(t),tYe=r(k1e," \u2014 "),K9=n(k1e,"A",{href:!0});var Byr=s(K9);aYe=r(Byr,"OpenAIGPTModel"),Byr.forEach(t),nYe=r(k1e," (OpenAI GPT model)"),k1e.forEach(t),sYe=i(C),Ch=n(C,"LI",{});var x1e=s(Ch);eH=n(x1e,"STRONG",{});var kyr=s(eH);lYe=r(kyr,"pegasus"),kyr.forEach(t),iYe=r(x1e," \u2014 "),Z9=n(x1e,"A",{href:!0});var xyr=s(Z9);dYe=r(xyr,"PegasusModel"),xyr.forEach(t),cYe=r(x1e," (Pegasus model)"),x1e.forEach(t),fYe=i(C),Eh=n(C,"LI",{});var R1e=s(Eh);oH=n(R1e,"STRONG",{});var Ryr=s(oH);mYe=r(Ryr,"perceiver"),Ryr.forEach(t),gYe=r(R1e," \u2014 "),ek=n(R1e,"A",{href:!0});var Syr=s(ek);hYe=r(Syr,"PerceiverModel"),Syr.forEach(t),uYe=r(R1e," (Perceiver model)"),R1e.forEach(t),pYe=i(C),Mh=n(C,"LI",{});var S1e=s(Mh);rH=n(S1e,"STRONG",{});var Pyr=s(rH);_Ye=r(Pyr,"prophetnet"),Pyr.forEach(t),vYe=r(S1e," \u2014 "),ok=n(S1e,"A",{href:!0});var $yr=s(ok);bYe=r($yr,"ProphetNetModel"),$yr.forEach(t),TYe=r(S1e," (ProphetNet model)"),S1e.forEach(t),FYe=i(C),yh=n(C,"LI",{});var P1e=s(yh);tH=n(P1e,"STRONG",{});var Iyr=s(tH);CYe=r(Iyr,"qdqbert"),Iyr.forEach(t),EYe=r(P1e," \u2014 "),rk=n(P1e,"A",{href:!0});var jyr=s(rk);MYe=r(jyr,"QDQBertModel"),jyr.forEach(t),yYe=r(P1e," (QDQBert model)"),P1e.forEach(t),wYe=i(C),wh=n(C,"LI",{});var $1e=s(wh);aH=n($1e,"STRONG",{});var Nyr=s(aH);AYe=r(Nyr,"reformer"),Nyr.forEach(t),LYe=r($1e," \u2014 "),tk=n($1e,"A",{href:!0});var Dyr=s(tk);BYe=r(Dyr,"ReformerModel"),Dyr.forEach(t),kYe=r($1e," (Reformer model)"),$1e.forEach(t),xYe=i(C),Ah=n(C,"LI",{});var I1e=s(Ah);nH=n(I1e,"STRONG",{});var qyr=s(nH);RYe=r(qyr,"rembert"),qyr.forEach(t),SYe=r(I1e," \u2014 "),ak=n(I1e,"A",{href:!0});var Oyr=s(ak);PYe=r(Oyr,"RemBertModel"),Oyr.forEach(t),$Ye=r(I1e," (RemBERT model)"),I1e.forEach(t),IYe=i(C),Lh=n(C,"LI",{});var j1e=s(Lh);sH=n(j1e,"STRONG",{});var Gyr=s(sH);jYe=r(Gyr,"retribert"),Gyr.forEach(t),NYe=r(j1e," \u2014 "),nk=n(j1e,"A",{href:!0});var zyr=s(nk);DYe=r(zyr,"RetriBertModel"),zyr.forEach(t),qYe=r(j1e," (RetriBERT model)"),j1e.forEach(t),OYe=i(C),Bh=n(C,"LI",{});var N1e=s(Bh);lH=n(N1e,"STRONG",{});var Vyr=s(lH);GYe=r(Vyr,"roberta"),Vyr.forEach(t),zYe=r(N1e," \u2014 "),sk=n(N1e,"A",{href:!0});var Xyr=s(sk);VYe=r(Xyr,"RobertaModel"),Xyr.forEach(t),XYe=r(N1e," (RoBERTa model)"),N1e.forEach(t),WYe=i(C),kh=n(C,"LI",{});var D1e=s(kh);iH=n(D1e,"STRONG",{});var Wyr=s(iH);QYe=r(Wyr,"roformer"),Wyr.forEach(t),HYe=r(D1e," \u2014 "),lk=n(D1e,"A",{href:!0});var Qyr=s(lk);UYe=r(Qyr,"RoFormerModel"),Qyr.forEach(t),JYe=r(D1e," (RoFormer model)"),D1e.forEach(t),YYe=i(C),xh=n(C,"LI",{});var q1e=s(xh);dH=n(q1e,"STRONG",{});var Hyr=s(dH);KYe=r(Hyr,"segformer"),Hyr.forEach(t),ZYe=r(q1e," \u2014 "),ik=n(q1e,"A",{href:!0});var Uyr=s(ik);eKe=r(Uyr,"SegformerModel"),Uyr.forEach(t),oKe=r(q1e," (SegFormer model)"),q1e.forEach(t),rKe=i(C),Rh=n(C,"LI",{});var O1e=s(Rh);cH=n(O1e,"STRONG",{});var Jyr=s(cH);tKe=r(Jyr,"sew"),Jyr.forEach(t),aKe=r(O1e," \u2014 "),dk=n(O1e,"A",{href:!0});var Yyr=s(dk);nKe=r(Yyr,"SEWModel"),Yyr.forEach(t),sKe=r(O1e," (SEW model)"),O1e.forEach(t),lKe=i(C),Sh=n(C,"LI",{});var G1e=s(Sh);fH=n(G1e,"STRONG",{});var Kyr=s(fH);iKe=r(Kyr,"sew-d"),Kyr.forEach(t),dKe=r(G1e," \u2014 "),ck=n(G1e,"A",{href:!0});var Zyr=s(ck);cKe=r(Zyr,"SEWDModel"),Zyr.forEach(t),fKe=r(G1e," (SEW-D model)"),G1e.forEach(t),mKe=i(C),Ph=n(C,"LI",{});var z1e=s(Ph);mH=n(z1e,"STRONG",{});var ewr=s(mH);gKe=r(ewr,"speech_to_text"),ewr.forEach(t),hKe=r(z1e," \u2014 "),fk=n(z1e,"A",{href:!0});var owr=s(fk);uKe=r(owr,"Speech2TextModel"),owr.forEach(t),pKe=r(z1e," (Speech2Text model)"),z1e.forEach(t),_Ke=i(C),$h=n(C,"LI",{});var V1e=s($h);gH=n(V1e,"STRONG",{});var rwr=s(gH);vKe=r(rwr,"splinter"),rwr.forEach(t),bKe=r(V1e," \u2014 "),mk=n(V1e,"A",{href:!0});var twr=s(mk);TKe=r(twr,"SplinterModel"),twr.forEach(t),FKe=r(V1e," (Splinter model)"),V1e.forEach(t),CKe=i(C),Ih=n(C,"LI",{});var X1e=s(Ih);hH=n(X1e,"STRONG",{});var awr=s(hH);EKe=r(awr,"squeezebert"),awr.forEach(t),MKe=r(X1e," \u2014 "),gk=n(X1e,"A",{href:!0});var nwr=s(gk);yKe=r(nwr,"SqueezeBertModel"),nwr.forEach(t),wKe=r(X1e," (SqueezeBERT model)"),X1e.forEach(t),AKe=i(C),jh=n(C,"LI",{});var W1e=s(jh);uH=n(W1e,"STRONG",{});var swr=s(uH);LKe=r(swr,"swin"),swr.forEach(t),BKe=r(W1e," \u2014 "),hk=n(W1e,"A",{href:!0});var lwr=s(hk);kKe=r(lwr,"SwinModel"),lwr.forEach(t),xKe=r(W1e," (Swin model)"),W1e.forEach(t),RKe=i(C),Nh=n(C,"LI",{});var Q1e=s(Nh);pH=n(Q1e,"STRONG",{});var iwr=s(pH);SKe=r(iwr,"t5"),iwr.forEach(t),PKe=r(Q1e," \u2014 "),uk=n(Q1e,"A",{href:!0});var dwr=s(uk);$Ke=r(dwr,"T5Model"),dwr.forEach(t),IKe=r(Q1e," (T5 model)"),Q1e.forEach(t),jKe=i(C),Dh=n(C,"LI",{});var H1e=s(Dh);_H=n(H1e,"STRONG",{});var cwr=s(_H);NKe=r(cwr,"tapas"),cwr.forEach(t),DKe=r(H1e," \u2014 "),pk=n(H1e,"A",{href:!0});var fwr=s(pk);qKe=r(fwr,"TapasModel"),fwr.forEach(t),OKe=r(H1e," (TAPAS model)"),H1e.forEach(t),GKe=i(C),qh=n(C,"LI",{});var U1e=s(qh);vH=n(U1e,"STRONG",{});var mwr=s(vH);zKe=r(mwr,"transfo-xl"),mwr.forEach(t),VKe=r(U1e," \u2014 "),_k=n(U1e,"A",{href:!0});var gwr=s(_k);XKe=r(gwr,"TransfoXLModel"),gwr.forEach(t),WKe=r(U1e," (Transformer-XL model)"),U1e.forEach(t),QKe=i(C),Oh=n(C,"LI",{});var J1e=s(Oh);bH=n(J1e,"STRONG",{});var hwr=s(bH);HKe=r(hwr,"unispeech"),hwr.forEach(t),UKe=r(J1e," \u2014 "),vk=n(J1e,"A",{href:!0});var uwr=s(vk);JKe=r(uwr,"UniSpeechModel"),uwr.forEach(t),YKe=r(J1e," (UniSpeech model)"),J1e.forEach(t),KKe=i(C),Gh=n(C,"LI",{});var Y1e=s(Gh);TH=n(Y1e,"STRONG",{});var pwr=s(TH);ZKe=r(pwr,"unispeech-sat"),pwr.forEach(t),eZe=r(Y1e," \u2014 "),bk=n(Y1e,"A",{href:!0});var _wr=s(bk);oZe=r(_wr,"UniSpeechSatModel"),_wr.forEach(t),rZe=r(Y1e," (UniSpeechSat model)"),Y1e.forEach(t),tZe=i(C),zh=n(C,"LI",{});var K1e=s(zh);FH=n(K1e,"STRONG",{});var vwr=s(FH);aZe=r(vwr,"vilt"),vwr.forEach(t),nZe=r(K1e," \u2014 "),Tk=n(K1e,"A",{href:!0});var bwr=s(Tk);sZe=r(bwr,"ViltModel"),bwr.forEach(t),lZe=r(K1e," (ViLT model)"),K1e.forEach(t),iZe=i(C),Vh=n(C,"LI",{});var Z1e=s(Vh);CH=n(Z1e,"STRONG",{});var Twr=s(CH);dZe=r(Twr,"vision-text-dual-encoder"),Twr.forEach(t),cZe=r(Z1e," \u2014 "),Fk=n(Z1e,"A",{href:!0});var Fwr=s(Fk);fZe=r(Fwr,"VisionTextDualEncoderModel"),Fwr.forEach(t),mZe=r(Z1e," (VisionTextDualEncoder model)"),Z1e.forEach(t),gZe=i(C),Xh=n(C,"LI",{});var e4e=s(Xh);EH=n(e4e,"STRONG",{});var Cwr=s(EH);hZe=r(Cwr,"visual_bert"),Cwr.forEach(t),uZe=r(e4e," \u2014 "),Ck=n(e4e,"A",{href:!0});var Ewr=s(Ck);pZe=r(Ewr,"VisualBertModel"),Ewr.forEach(t),_Ze=r(e4e," (VisualBert model)"),e4e.forEach(t),vZe=i(C),Wh=n(C,"LI",{});var o4e=s(Wh);MH=n(o4e,"STRONG",{});var Mwr=s(MH);bZe=r(Mwr,"vit"),Mwr.forEach(t),TZe=r(o4e," \u2014 "),Ek=n(o4e,"A",{href:!0});var ywr=s(Ek);FZe=r(ywr,"ViTModel"),ywr.forEach(t),CZe=r(o4e," (ViT model)"),o4e.forEach(t),EZe=i(C),Qh=n(C,"LI",{});var r4e=s(Qh);yH=n(r4e,"STRONG",{});var wwr=s(yH);MZe=r(wwr,"vit_mae"),wwr.forEach(t),yZe=r(r4e," \u2014 "),Mk=n(r4e,"A",{href:!0});var Awr=s(Mk);wZe=r(Awr,"ViTMAEModel"),Awr.forEach(t),AZe=r(r4e," (ViTMAE model)"),r4e.forEach(t),LZe=i(C),Hh=n(C,"LI",{});var t4e=s(Hh);wH=n(t4e,"STRONG",{});var Lwr=s(wH);BZe=r(Lwr,"wav2vec2"),Lwr.forEach(t),kZe=r(t4e," \u2014 "),yk=n(t4e,"A",{href:!0});var Bwr=s(yk);xZe=r(Bwr,"Wav2Vec2Model"),Bwr.forEach(t),RZe=r(t4e," (Wav2Vec2 model)"),t4e.forEach(t),SZe=i(C),Uh=n(C,"LI",{});var a4e=s(Uh);AH=n(a4e,"STRONG",{});var kwr=s(AH);PZe=r(kwr,"wavlm"),kwr.forEach(t),$Ze=r(a4e," \u2014 "),wk=n(a4e,"A",{href:!0});var xwr=s(wk);IZe=r(xwr,"WavLMModel"),xwr.forEach(t),jZe=r(a4e," (WavLM model)"),a4e.forEach(t),NZe=i(C),Jh=n(C,"LI",{});var n4e=s(Jh);LH=n(n4e,"STRONG",{});var Rwr=s(LH);DZe=r(Rwr,"xlm"),Rwr.forEach(t),qZe=r(n4e," \u2014 "),Ak=n(n4e,"A",{href:!0});var Swr=s(Ak);OZe=r(Swr,"XLMModel"),Swr.forEach(t),GZe=r(n4e," (XLM model)"),n4e.forEach(t),zZe=i(C),Yh=n(C,"LI",{});var s4e=s(Yh);BH=n(s4e,"STRONG",{});var Pwr=s(BH);VZe=r(Pwr,"xlm-prophetnet"),Pwr.forEach(t),XZe=r(s4e," \u2014 "),Lk=n(s4e,"A",{href:!0});var $wr=s(Lk);WZe=r($wr,"XLMProphetNetModel"),$wr.forEach(t),QZe=r(s4e," (XLMProphetNet model)"),s4e.forEach(t),HZe=i(C),Kh=n(C,"LI",{});var l4e=s(Kh);kH=n(l4e,"STRONG",{});var Iwr=s(kH);UZe=r(Iwr,"xlm-roberta"),Iwr.forEach(t),JZe=r(l4e," \u2014 "),Bk=n(l4e,"A",{href:!0});var jwr=s(Bk);YZe=r(jwr,"XLMRobertaModel"),jwr.forEach(t),KZe=r(l4e," (XLM-RoBERTa model)"),l4e.forEach(t),ZZe=i(C),Zh=n(C,"LI",{});var i4e=s(Zh);xH=n(i4e,"STRONG",{});var Nwr=s(xH);eeo=r(Nwr,"xlnet"),Nwr.forEach(t),oeo=r(i4e," \u2014 "),kk=n(i4e,"A",{href:!0});var Dwr=s(kk);reo=r(Dwr,"XLNetModel"),Dwr.forEach(t),teo=r(i4e," (XLNet model)"),i4e.forEach(t),aeo=i(C),eu=n(C,"LI",{});var d4e=s(eu);RH=n(d4e,"STRONG",{});var qwr=s(RH);neo=r(qwr,"yoso"),qwr.forEach(t),seo=r(d4e," \u2014 "),xk=n(d4e,"A",{href:!0});var Owr=s(xk);leo=r(Owr,"YosoModel"),Owr.forEach(t),ieo=r(d4e," (YOSO model)"),d4e.forEach(t),C.forEach(t),deo=i(Ft),ou=n(Ft,"P",{});var c4e=s(ou);ceo=r(c4e,"The model is set in evaluation mode by default using "),SH=n(c4e,"CODE",{});var Gwr=s(SH);feo=r(Gwr,"model.eval()"),Gwr.forEach(t),meo=r(c4e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),PH=n(c4e,"CODE",{});var zwr=s(PH);geo=r(zwr,"model.train()"),zwr.forEach(t),c4e.forEach(t),heo=i(Ft),$H=n(Ft,"P",{});var Vwr=s($H);ueo=r(Vwr,"Examples:"),Vwr.forEach(t),peo=i(Ft),m(hM.$$.fragment,Ft),Ft.forEach(t),bs.forEach(t),pwe=i(d),vi=n(d,"H2",{class:!0});var u0e=s(vi);ru=n(u0e,"A",{id:!0,class:!0,href:!0});var Xwr=s(ru);IH=n(Xwr,"SPAN",{});var Wwr=s(IH);m(uM.$$.fragment,Wwr),Wwr.forEach(t),Xwr.forEach(t),_eo=i(u0e),jH=n(u0e,"SPAN",{});var Qwr=s(jH);veo=r(Qwr,"AutoModelForPreTraining"),Qwr.forEach(t),u0e.forEach(t),_we=i(d),qo=n(d,"DIV",{class:!0});var Fs=s(qo);m(pM.$$.fragment,Fs),beo=i(Fs),bi=n(Fs,"P",{});var hO=s(bi);Teo=r(hO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),NH=n(hO,"CODE",{});var Hwr=s(NH);Feo=r(Hwr,"from_pretrained()"),Hwr.forEach(t),Ceo=r(hO,"class method or the "),DH=n(hO,"CODE",{});var Uwr=s(DH);Eeo=r(Uwr,"from_config()"),Uwr.forEach(t),Meo=r(hO,`class
method.`),hO.forEach(t),yeo=i(Fs),_M=n(Fs,"P",{});var p0e=s(_M);weo=r(p0e,"This class cannot be instantiated directly using "),qH=n(p0e,"CODE",{});var Jwr=s(qH);Aeo=r(Jwr,"__init__()"),Jwr.forEach(t),Leo=r(p0e," (throws an error)."),p0e.forEach(t),Beo=i(Fs),kr=n(Fs,"DIV",{class:!0});var Cs=s(kr);m(vM.$$.fragment,Cs),keo=i(Cs),OH=n(Cs,"P",{});var Ywr=s(OH);xeo=r(Ywr,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Ywr.forEach(t),Reo=i(Cs),Ti=n(Cs,"P",{});var uO=s(Ti);Seo=r(uO,`Note:
Loading a model from its configuration file does `),GH=n(uO,"STRONG",{});var Kwr=s(GH);Peo=r(Kwr,"not"),Kwr.forEach(t),$eo=r(uO,` load the model weights. It only affects the
model\u2019s configuration. Use `),zH=n(uO,"CODE",{});var Zwr=s(zH);Ieo=r(Zwr,"from_pretrained()"),Zwr.forEach(t),jeo=r(uO,"to load the model weights."),uO.forEach(t),Neo=i(Cs),VH=n(Cs,"P",{});var eAr=s(VH);Deo=r(eAr,"Examples:"),eAr.forEach(t),qeo=i(Cs),m(bM.$$.fragment,Cs),Cs.forEach(t),Oeo=i(Fs),ke=n(Fs,"DIV",{class:!0});var Ct=s(ke);m(TM.$$.fragment,Ct),Geo=i(Ct),XH=n(Ct,"P",{});var oAr=s(XH);zeo=r(oAr,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),oAr.forEach(t),Veo=i(Ct),La=n(Ct,"P",{});var OC=s(La);Xeo=r(OC,"The model class to instantiate is selected based on the "),WH=n(OC,"CODE",{});var rAr=s(WH);Weo=r(rAr,"model_type"),rAr.forEach(t),Qeo=r(OC,` property of the config object (either
passed as an argument or loaded from `),QH=n(OC,"CODE",{});var tAr=s(QH);Heo=r(tAr,"pretrained_model_name_or_path"),tAr.forEach(t),Ueo=r(OC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HH=n(OC,"CODE",{});var aAr=s(HH);Jeo=r(aAr,"pretrained_model_name_or_path"),aAr.forEach(t),Yeo=r(OC,":"),OC.forEach(t),Keo=i(Ct),x=n(Ct,"UL",{});var S=s(x);tu=n(S,"LI",{});var f4e=s(tu);UH=n(f4e,"STRONG",{});var nAr=s(UH);Zeo=r(nAr,"albert"),nAr.forEach(t),eoo=r(f4e," \u2014 "),Rk=n(f4e,"A",{href:!0});var sAr=s(Rk);ooo=r(sAr,"AlbertForPreTraining"),sAr.forEach(t),roo=r(f4e," (ALBERT model)"),f4e.forEach(t),too=i(S),au=n(S,"LI",{});var m4e=s(au);JH=n(m4e,"STRONG",{});var lAr=s(JH);aoo=r(lAr,"bart"),lAr.forEach(t),noo=r(m4e," \u2014 "),Sk=n(m4e,"A",{href:!0});var iAr=s(Sk);soo=r(iAr,"BartForConditionalGeneration"),iAr.forEach(t),loo=r(m4e," (BART model)"),m4e.forEach(t),ioo=i(S),nu=n(S,"LI",{});var g4e=s(nu);YH=n(g4e,"STRONG",{});var dAr=s(YH);doo=r(dAr,"bert"),dAr.forEach(t),coo=r(g4e," \u2014 "),Pk=n(g4e,"A",{href:!0});var cAr=s(Pk);foo=r(cAr,"BertForPreTraining"),cAr.forEach(t),moo=r(g4e," (BERT model)"),g4e.forEach(t),goo=i(S),su=n(S,"LI",{});var h4e=s(su);KH=n(h4e,"STRONG",{});var fAr=s(KH);hoo=r(fAr,"big_bird"),fAr.forEach(t),uoo=r(h4e," \u2014 "),$k=n(h4e,"A",{href:!0});var mAr=s($k);poo=r(mAr,"BigBirdForPreTraining"),mAr.forEach(t),_oo=r(h4e," (BigBird model)"),h4e.forEach(t),voo=i(S),lu=n(S,"LI",{});var u4e=s(lu);ZH=n(u4e,"STRONG",{});var gAr=s(ZH);boo=r(gAr,"camembert"),gAr.forEach(t),Too=r(u4e," \u2014 "),Ik=n(u4e,"A",{href:!0});var hAr=s(Ik);Foo=r(hAr,"CamembertForMaskedLM"),hAr.forEach(t),Coo=r(u4e," (CamemBERT model)"),u4e.forEach(t),Eoo=i(S),iu=n(S,"LI",{});var p4e=s(iu);eU=n(p4e,"STRONG",{});var uAr=s(eU);Moo=r(uAr,"ctrl"),uAr.forEach(t),yoo=r(p4e," \u2014 "),jk=n(p4e,"A",{href:!0});var pAr=s(jk);woo=r(pAr,"CTRLLMHeadModel"),pAr.forEach(t),Aoo=r(p4e," (CTRL model)"),p4e.forEach(t),Loo=i(S),du=n(S,"LI",{});var _4e=s(du);oU=n(_4e,"STRONG",{});var _Ar=s(oU);Boo=r(_Ar,"deberta"),_Ar.forEach(t),koo=r(_4e," \u2014 "),Nk=n(_4e,"A",{href:!0});var vAr=s(Nk);xoo=r(vAr,"DebertaForMaskedLM"),vAr.forEach(t),Roo=r(_4e," (DeBERTa model)"),_4e.forEach(t),Soo=i(S),cu=n(S,"LI",{});var v4e=s(cu);rU=n(v4e,"STRONG",{});var bAr=s(rU);Poo=r(bAr,"deberta-v2"),bAr.forEach(t),$oo=r(v4e," \u2014 "),Dk=n(v4e,"A",{href:!0});var TAr=s(Dk);Ioo=r(TAr,"DebertaV2ForMaskedLM"),TAr.forEach(t),joo=r(v4e," (DeBERTa-v2 model)"),v4e.forEach(t),Noo=i(S),fu=n(S,"LI",{});var b4e=s(fu);tU=n(b4e,"STRONG",{});var FAr=s(tU);Doo=r(FAr,"distilbert"),FAr.forEach(t),qoo=r(b4e," \u2014 "),qk=n(b4e,"A",{href:!0});var CAr=s(qk);Ooo=r(CAr,"DistilBertForMaskedLM"),CAr.forEach(t),Goo=r(b4e," (DistilBERT model)"),b4e.forEach(t),zoo=i(S),mu=n(S,"LI",{});var T4e=s(mu);aU=n(T4e,"STRONG",{});var EAr=s(aU);Voo=r(EAr,"electra"),EAr.forEach(t),Xoo=r(T4e," \u2014 "),Ok=n(T4e,"A",{href:!0});var MAr=s(Ok);Woo=r(MAr,"ElectraForPreTraining"),MAr.forEach(t),Qoo=r(T4e," (ELECTRA model)"),T4e.forEach(t),Hoo=i(S),gu=n(S,"LI",{});var F4e=s(gu);nU=n(F4e,"STRONG",{});var yAr=s(nU);Uoo=r(yAr,"flaubert"),yAr.forEach(t),Joo=r(F4e," \u2014 "),Gk=n(F4e,"A",{href:!0});var wAr=s(Gk);Yoo=r(wAr,"FlaubertWithLMHeadModel"),wAr.forEach(t),Koo=r(F4e," (FlauBERT model)"),F4e.forEach(t),Zoo=i(S),hu=n(S,"LI",{});var C4e=s(hu);sU=n(C4e,"STRONG",{});var AAr=s(sU);ero=r(AAr,"fnet"),AAr.forEach(t),oro=r(C4e," \u2014 "),zk=n(C4e,"A",{href:!0});var LAr=s(zk);rro=r(LAr,"FNetForPreTraining"),LAr.forEach(t),tro=r(C4e," (FNet model)"),C4e.forEach(t),aro=i(S),uu=n(S,"LI",{});var E4e=s(uu);lU=n(E4e,"STRONG",{});var BAr=s(lU);nro=r(BAr,"fsmt"),BAr.forEach(t),sro=r(E4e," \u2014 "),Vk=n(E4e,"A",{href:!0});var kAr=s(Vk);lro=r(kAr,"FSMTForConditionalGeneration"),kAr.forEach(t),iro=r(E4e," (FairSeq Machine-Translation model)"),E4e.forEach(t),dro=i(S),pu=n(S,"LI",{});var M4e=s(pu);iU=n(M4e,"STRONG",{});var xAr=s(iU);cro=r(xAr,"funnel"),xAr.forEach(t),fro=r(M4e," \u2014 "),Xk=n(M4e,"A",{href:!0});var RAr=s(Xk);mro=r(RAr,"FunnelForPreTraining"),RAr.forEach(t),gro=r(M4e," (Funnel Transformer model)"),M4e.forEach(t),hro=i(S),_u=n(S,"LI",{});var y4e=s(_u);dU=n(y4e,"STRONG",{});var SAr=s(dU);uro=r(SAr,"gpt2"),SAr.forEach(t),pro=r(y4e," \u2014 "),Wk=n(y4e,"A",{href:!0});var PAr=s(Wk);_ro=r(PAr,"GPT2LMHeadModel"),PAr.forEach(t),vro=r(y4e," (OpenAI GPT-2 model)"),y4e.forEach(t),bro=i(S),vu=n(S,"LI",{});var w4e=s(vu);cU=n(w4e,"STRONG",{});var $Ar=s(cU);Tro=r($Ar,"ibert"),$Ar.forEach(t),Fro=r(w4e," \u2014 "),Qk=n(w4e,"A",{href:!0});var IAr=s(Qk);Cro=r(IAr,"IBertForMaskedLM"),IAr.forEach(t),Ero=r(w4e," (I-BERT model)"),w4e.forEach(t),Mro=i(S),bu=n(S,"LI",{});var A4e=s(bu);fU=n(A4e,"STRONG",{});var jAr=s(fU);yro=r(jAr,"layoutlm"),jAr.forEach(t),wro=r(A4e," \u2014 "),Hk=n(A4e,"A",{href:!0});var NAr=s(Hk);Aro=r(NAr,"LayoutLMForMaskedLM"),NAr.forEach(t),Lro=r(A4e," (LayoutLM model)"),A4e.forEach(t),Bro=i(S),Tu=n(S,"LI",{});var L4e=s(Tu);mU=n(L4e,"STRONG",{});var DAr=s(mU);kro=r(DAr,"longformer"),DAr.forEach(t),xro=r(L4e," \u2014 "),Uk=n(L4e,"A",{href:!0});var qAr=s(Uk);Rro=r(qAr,"LongformerForMaskedLM"),qAr.forEach(t),Sro=r(L4e," (Longformer model)"),L4e.forEach(t),Pro=i(S),Fu=n(S,"LI",{});var B4e=s(Fu);gU=n(B4e,"STRONG",{});var OAr=s(gU);$ro=r(OAr,"lxmert"),OAr.forEach(t),Iro=r(B4e," \u2014 "),Jk=n(B4e,"A",{href:!0});var GAr=s(Jk);jro=r(GAr,"LxmertForPreTraining"),GAr.forEach(t),Nro=r(B4e," (LXMERT model)"),B4e.forEach(t),Dro=i(S),Cu=n(S,"LI",{});var k4e=s(Cu);hU=n(k4e,"STRONG",{});var zAr=s(hU);qro=r(zAr,"megatron-bert"),zAr.forEach(t),Oro=r(k4e," \u2014 "),Yk=n(k4e,"A",{href:!0});var VAr=s(Yk);Gro=r(VAr,"MegatronBertForPreTraining"),VAr.forEach(t),zro=r(k4e," (MegatronBert model)"),k4e.forEach(t),Vro=i(S),Eu=n(S,"LI",{});var x4e=s(Eu);uU=n(x4e,"STRONG",{});var XAr=s(uU);Xro=r(XAr,"mobilebert"),XAr.forEach(t),Wro=r(x4e," \u2014 "),Kk=n(x4e,"A",{href:!0});var WAr=s(Kk);Qro=r(WAr,"MobileBertForPreTraining"),WAr.forEach(t),Hro=r(x4e," (MobileBERT model)"),x4e.forEach(t),Uro=i(S),Mu=n(S,"LI",{});var R4e=s(Mu);pU=n(R4e,"STRONG",{});var QAr=s(pU);Jro=r(QAr,"mpnet"),QAr.forEach(t),Yro=r(R4e," \u2014 "),Zk=n(R4e,"A",{href:!0});var HAr=s(Zk);Kro=r(HAr,"MPNetForMaskedLM"),HAr.forEach(t),Zro=r(R4e," (MPNet model)"),R4e.forEach(t),eto=i(S),yu=n(S,"LI",{});var S4e=s(yu);_U=n(S4e,"STRONG",{});var UAr=s(_U);oto=r(UAr,"openai-gpt"),UAr.forEach(t),rto=r(S4e," \u2014 "),ex=n(S4e,"A",{href:!0});var JAr=s(ex);tto=r(JAr,"OpenAIGPTLMHeadModel"),JAr.forEach(t),ato=r(S4e," (OpenAI GPT model)"),S4e.forEach(t),nto=i(S),wu=n(S,"LI",{});var P4e=s(wu);vU=n(P4e,"STRONG",{});var YAr=s(vU);sto=r(YAr,"retribert"),YAr.forEach(t),lto=r(P4e," \u2014 "),ox=n(P4e,"A",{href:!0});var KAr=s(ox);ito=r(KAr,"RetriBertModel"),KAr.forEach(t),dto=r(P4e," (RetriBERT model)"),P4e.forEach(t),cto=i(S),Au=n(S,"LI",{});var $4e=s(Au);bU=n($4e,"STRONG",{});var ZAr=s(bU);fto=r(ZAr,"roberta"),ZAr.forEach(t),mto=r($4e," \u2014 "),rx=n($4e,"A",{href:!0});var e0r=s(rx);gto=r(e0r,"RobertaForMaskedLM"),e0r.forEach(t),hto=r($4e," (RoBERTa model)"),$4e.forEach(t),uto=i(S),Lu=n(S,"LI",{});var I4e=s(Lu);TU=n(I4e,"STRONG",{});var o0r=s(TU);pto=r(o0r,"squeezebert"),o0r.forEach(t),_to=r(I4e," \u2014 "),tx=n(I4e,"A",{href:!0});var r0r=s(tx);vto=r(r0r,"SqueezeBertForMaskedLM"),r0r.forEach(t),bto=r(I4e," (SqueezeBERT model)"),I4e.forEach(t),Tto=i(S),Bu=n(S,"LI",{});var j4e=s(Bu);FU=n(j4e,"STRONG",{});var t0r=s(FU);Fto=r(t0r,"t5"),t0r.forEach(t),Cto=r(j4e," \u2014 "),ax=n(j4e,"A",{href:!0});var a0r=s(ax);Eto=r(a0r,"T5ForConditionalGeneration"),a0r.forEach(t),Mto=r(j4e," (T5 model)"),j4e.forEach(t),yto=i(S),ku=n(S,"LI",{});var N4e=s(ku);CU=n(N4e,"STRONG",{});var n0r=s(CU);wto=r(n0r,"tapas"),n0r.forEach(t),Ato=r(N4e," \u2014 "),nx=n(N4e,"A",{href:!0});var s0r=s(nx);Lto=r(s0r,"TapasForMaskedLM"),s0r.forEach(t),Bto=r(N4e," (TAPAS model)"),N4e.forEach(t),kto=i(S),xu=n(S,"LI",{});var D4e=s(xu);EU=n(D4e,"STRONG",{});var l0r=s(EU);xto=r(l0r,"transfo-xl"),l0r.forEach(t),Rto=r(D4e," \u2014 "),sx=n(D4e,"A",{href:!0});var i0r=s(sx);Sto=r(i0r,"TransfoXLLMHeadModel"),i0r.forEach(t),Pto=r(D4e," (Transformer-XL model)"),D4e.forEach(t),$to=i(S),Ru=n(S,"LI",{});var q4e=s(Ru);MU=n(q4e,"STRONG",{});var d0r=s(MU);Ito=r(d0r,"unispeech"),d0r.forEach(t),jto=r(q4e," \u2014 "),lx=n(q4e,"A",{href:!0});var c0r=s(lx);Nto=r(c0r,"UniSpeechForPreTraining"),c0r.forEach(t),Dto=r(q4e," (UniSpeech model)"),q4e.forEach(t),qto=i(S),Su=n(S,"LI",{});var O4e=s(Su);yU=n(O4e,"STRONG",{});var f0r=s(yU);Oto=r(f0r,"unispeech-sat"),f0r.forEach(t),Gto=r(O4e," \u2014 "),ix=n(O4e,"A",{href:!0});var m0r=s(ix);zto=r(m0r,"UniSpeechSatForPreTraining"),m0r.forEach(t),Vto=r(O4e," (UniSpeechSat model)"),O4e.forEach(t),Xto=i(S),Pu=n(S,"LI",{});var G4e=s(Pu);wU=n(G4e,"STRONG",{});var g0r=s(wU);Wto=r(g0r,"visual_bert"),g0r.forEach(t),Qto=r(G4e," \u2014 "),dx=n(G4e,"A",{href:!0});var h0r=s(dx);Hto=r(h0r,"VisualBertForPreTraining"),h0r.forEach(t),Uto=r(G4e," (VisualBert model)"),G4e.forEach(t),Jto=i(S),$u=n(S,"LI",{});var z4e=s($u);AU=n(z4e,"STRONG",{});var u0r=s(AU);Yto=r(u0r,"vit_mae"),u0r.forEach(t),Kto=r(z4e," \u2014 "),cx=n(z4e,"A",{href:!0});var p0r=s(cx);Zto=r(p0r,"ViTMAEForPreTraining"),p0r.forEach(t),eao=r(z4e," (ViTMAE model)"),z4e.forEach(t),oao=i(S),Iu=n(S,"LI",{});var V4e=s(Iu);LU=n(V4e,"STRONG",{});var _0r=s(LU);rao=r(_0r,"wav2vec2"),_0r.forEach(t),tao=r(V4e," \u2014 "),fx=n(V4e,"A",{href:!0});var v0r=s(fx);aao=r(v0r,"Wav2Vec2ForPreTraining"),v0r.forEach(t),nao=r(V4e," (Wav2Vec2 model)"),V4e.forEach(t),sao=i(S),ju=n(S,"LI",{});var X4e=s(ju);BU=n(X4e,"STRONG",{});var b0r=s(BU);lao=r(b0r,"xlm"),b0r.forEach(t),iao=r(X4e," \u2014 "),mx=n(X4e,"A",{href:!0});var T0r=s(mx);dao=r(T0r,"XLMWithLMHeadModel"),T0r.forEach(t),cao=r(X4e," (XLM model)"),X4e.forEach(t),fao=i(S),Nu=n(S,"LI",{});var W4e=s(Nu);kU=n(W4e,"STRONG",{});var F0r=s(kU);mao=r(F0r,"xlm-roberta"),F0r.forEach(t),gao=r(W4e," \u2014 "),gx=n(W4e,"A",{href:!0});var C0r=s(gx);hao=r(C0r,"XLMRobertaForMaskedLM"),C0r.forEach(t),uao=r(W4e," (XLM-RoBERTa model)"),W4e.forEach(t),pao=i(S),Du=n(S,"LI",{});var Q4e=s(Du);xU=n(Q4e,"STRONG",{});var E0r=s(xU);_ao=r(E0r,"xlnet"),E0r.forEach(t),vao=r(Q4e," \u2014 "),hx=n(Q4e,"A",{href:!0});var M0r=s(hx);bao=r(M0r,"XLNetLMHeadModel"),M0r.forEach(t),Tao=r(Q4e," (XLNet model)"),Q4e.forEach(t),S.forEach(t),Fao=i(Ct),qu=n(Ct,"P",{});var H4e=s(qu);Cao=r(H4e,"The model is set in evaluation mode by default using "),RU=n(H4e,"CODE",{});var y0r=s(RU);Eao=r(y0r,"model.eval()"),y0r.forEach(t),Mao=r(H4e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),SU=n(H4e,"CODE",{});var w0r=s(SU);yao=r(w0r,"model.train()"),w0r.forEach(t),H4e.forEach(t),wao=i(Ct),PU=n(Ct,"P",{});var A0r=s(PU);Aao=r(A0r,"Examples:"),A0r.forEach(t),Lao=i(Ct),m(FM.$$.fragment,Ct),Ct.forEach(t),Fs.forEach(t),vwe=i(d),Fi=n(d,"H2",{class:!0});var _0e=s(Fi);Ou=n(_0e,"A",{id:!0,class:!0,href:!0});var L0r=s(Ou);$U=n(L0r,"SPAN",{});var B0r=s($U);m(CM.$$.fragment,B0r),B0r.forEach(t),L0r.forEach(t),Bao=i(_0e),IU=n(_0e,"SPAN",{});var k0r=s(IU);kao=r(k0r,"AutoModelForCausalLM"),k0r.forEach(t),_0e.forEach(t),bwe=i(d),Oo=n(d,"DIV",{class:!0});var Es=s(Oo);m(EM.$$.fragment,Es),xao=i(Es),Ci=n(Es,"P",{});var pO=s(Ci);Rao=r(pO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),jU=n(pO,"CODE",{});var x0r=s(jU);Sao=r(x0r,"from_pretrained()"),x0r.forEach(t),Pao=r(pO,"class method or the "),NU=n(pO,"CODE",{});var R0r=s(NU);$ao=r(R0r,"from_config()"),R0r.forEach(t),Iao=r(pO,`class
method.`),pO.forEach(t),jao=i(Es),MM=n(Es,"P",{});var v0e=s(MM);Nao=r(v0e,"This class cannot be instantiated directly using "),DU=n(v0e,"CODE",{});var S0r=s(DU);Dao=r(S0r,"__init__()"),S0r.forEach(t),qao=r(v0e," (throws an error)."),v0e.forEach(t),Oao=i(Es),xr=n(Es,"DIV",{class:!0});var Ms=s(xr);m(yM.$$.fragment,Ms),Gao=i(Ms),qU=n(Ms,"P",{});var P0r=s(qU);zao=r(P0r,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),P0r.forEach(t),Vao=i(Ms),Ei=n(Ms,"P",{});var _O=s(Ei);Xao=r(_O,`Note:
Loading a model from its configuration file does `),OU=n(_O,"STRONG",{});var $0r=s(OU);Wao=r($0r,"not"),$0r.forEach(t),Qao=r(_O,` load the model weights. It only affects the
model\u2019s configuration. Use `),GU=n(_O,"CODE",{});var I0r=s(GU);Hao=r(I0r,"from_pretrained()"),I0r.forEach(t),Uao=r(_O,"to load the model weights."),_O.forEach(t),Jao=i(Ms),zU=n(Ms,"P",{});var j0r=s(zU);Yao=r(j0r,"Examples:"),j0r.forEach(t),Kao=i(Ms),m(wM.$$.fragment,Ms),Ms.forEach(t),Zao=i(Es),xe=n(Es,"DIV",{class:!0});var Et=s(xe);m(AM.$$.fragment,Et),eno=i(Et),VU=n(Et,"P",{});var N0r=s(VU);ono=r(N0r,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),N0r.forEach(t),rno=i(Et),Ba=n(Et,"P",{});var GC=s(Ba);tno=r(GC,"The model class to instantiate is selected based on the "),XU=n(GC,"CODE",{});var D0r=s(XU);ano=r(D0r,"model_type"),D0r.forEach(t),nno=r(GC,` property of the config object (either
passed as an argument or loaded from `),WU=n(GC,"CODE",{});var q0r=s(WU);sno=r(q0r,"pretrained_model_name_or_path"),q0r.forEach(t),lno=r(GC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QU=n(GC,"CODE",{});var O0r=s(QU);ino=r(O0r,"pretrained_model_name_or_path"),O0r.forEach(t),dno=r(GC,":"),GC.forEach(t),cno=i(Et),j=n(Et,"UL",{});var D=s(j);Gu=n(D,"LI",{});var U4e=s(Gu);HU=n(U4e,"STRONG",{});var G0r=s(HU);fno=r(G0r,"bart"),G0r.forEach(t),mno=r(U4e," \u2014 "),ux=n(U4e,"A",{href:!0});var z0r=s(ux);gno=r(z0r,"BartForCausalLM"),z0r.forEach(t),hno=r(U4e," (BART model)"),U4e.forEach(t),uno=i(D),zu=n(D,"LI",{});var J4e=s(zu);UU=n(J4e,"STRONG",{});var V0r=s(UU);pno=r(V0r,"bert"),V0r.forEach(t),_no=r(J4e," \u2014 "),px=n(J4e,"A",{href:!0});var X0r=s(px);vno=r(X0r,"BertLMHeadModel"),X0r.forEach(t),bno=r(J4e," (BERT model)"),J4e.forEach(t),Tno=i(D),Vu=n(D,"LI",{});var Y4e=s(Vu);JU=n(Y4e,"STRONG",{});var W0r=s(JU);Fno=r(W0r,"bert-generation"),W0r.forEach(t),Cno=r(Y4e," \u2014 "),_x=n(Y4e,"A",{href:!0});var Q0r=s(_x);Eno=r(Q0r,"BertGenerationDecoder"),Q0r.forEach(t),Mno=r(Y4e," (Bert Generation model)"),Y4e.forEach(t),yno=i(D),Xu=n(D,"LI",{});var K4e=s(Xu);YU=n(K4e,"STRONG",{});var H0r=s(YU);wno=r(H0r,"big_bird"),H0r.forEach(t),Ano=r(K4e," \u2014 "),vx=n(K4e,"A",{href:!0});var U0r=s(vx);Lno=r(U0r,"BigBirdForCausalLM"),U0r.forEach(t),Bno=r(K4e," (BigBird model)"),K4e.forEach(t),kno=i(D),Wu=n(D,"LI",{});var Z4e=s(Wu);KU=n(Z4e,"STRONG",{});var J0r=s(KU);xno=r(J0r,"bigbird_pegasus"),J0r.forEach(t),Rno=r(Z4e," \u2014 "),bx=n(Z4e,"A",{href:!0});var Y0r=s(bx);Sno=r(Y0r,"BigBirdPegasusForCausalLM"),Y0r.forEach(t),Pno=r(Z4e," (BigBirdPegasus model)"),Z4e.forEach(t),$no=i(D),Qu=n(D,"LI",{});var ebe=s(Qu);ZU=n(ebe,"STRONG",{});var K0r=s(ZU);Ino=r(K0r,"blenderbot"),K0r.forEach(t),jno=r(ebe," \u2014 "),Tx=n(ebe,"A",{href:!0});var Z0r=s(Tx);Nno=r(Z0r,"BlenderbotForCausalLM"),Z0r.forEach(t),Dno=r(ebe," (Blenderbot model)"),ebe.forEach(t),qno=i(D),Hu=n(D,"LI",{});var obe=s(Hu);eJ=n(obe,"STRONG",{});var e7r=s(eJ);Ono=r(e7r,"blenderbot-small"),e7r.forEach(t),Gno=r(obe," \u2014 "),Fx=n(obe,"A",{href:!0});var o7r=s(Fx);zno=r(o7r,"BlenderbotSmallForCausalLM"),o7r.forEach(t),Vno=r(obe," (BlenderbotSmall model)"),obe.forEach(t),Xno=i(D),Uu=n(D,"LI",{});var rbe=s(Uu);oJ=n(rbe,"STRONG",{});var r7r=s(oJ);Wno=r(r7r,"camembert"),r7r.forEach(t),Qno=r(rbe," \u2014 "),Cx=n(rbe,"A",{href:!0});var t7r=s(Cx);Hno=r(t7r,"CamembertForCausalLM"),t7r.forEach(t),Uno=r(rbe," (CamemBERT model)"),rbe.forEach(t),Jno=i(D),Ju=n(D,"LI",{});var tbe=s(Ju);rJ=n(tbe,"STRONG",{});var a7r=s(rJ);Yno=r(a7r,"ctrl"),a7r.forEach(t),Kno=r(tbe," \u2014 "),Ex=n(tbe,"A",{href:!0});var n7r=s(Ex);Zno=r(n7r,"CTRLLMHeadModel"),n7r.forEach(t),eso=r(tbe," (CTRL model)"),tbe.forEach(t),oso=i(D),Yu=n(D,"LI",{});var abe=s(Yu);tJ=n(abe,"STRONG",{});var s7r=s(tJ);rso=r(s7r,"electra"),s7r.forEach(t),tso=r(abe," \u2014 "),Mx=n(abe,"A",{href:!0});var l7r=s(Mx);aso=r(l7r,"ElectraForCausalLM"),l7r.forEach(t),nso=r(abe," (ELECTRA model)"),abe.forEach(t),sso=i(D),Ku=n(D,"LI",{});var nbe=s(Ku);aJ=n(nbe,"STRONG",{});var i7r=s(aJ);lso=r(i7r,"gpt2"),i7r.forEach(t),iso=r(nbe," \u2014 "),yx=n(nbe,"A",{href:!0});var d7r=s(yx);dso=r(d7r,"GPT2LMHeadModel"),d7r.forEach(t),cso=r(nbe," (OpenAI GPT-2 model)"),nbe.forEach(t),fso=i(D),Zu=n(D,"LI",{});var sbe=s(Zu);nJ=n(sbe,"STRONG",{});var c7r=s(nJ);mso=r(c7r,"gpt_neo"),c7r.forEach(t),gso=r(sbe," \u2014 "),wx=n(sbe,"A",{href:!0});var f7r=s(wx);hso=r(f7r,"GPTNeoForCausalLM"),f7r.forEach(t),uso=r(sbe," (GPT Neo model)"),sbe.forEach(t),pso=i(D),ep=n(D,"LI",{});var lbe=s(ep);sJ=n(lbe,"STRONG",{});var m7r=s(sJ);_so=r(m7r,"gptj"),m7r.forEach(t),vso=r(lbe," \u2014 "),Ax=n(lbe,"A",{href:!0});var g7r=s(Ax);bso=r(g7r,"GPTJForCausalLM"),g7r.forEach(t),Tso=r(lbe," (GPT-J model)"),lbe.forEach(t),Fso=i(D),op=n(D,"LI",{});var ibe=s(op);lJ=n(ibe,"STRONG",{});var h7r=s(lJ);Cso=r(h7r,"marian"),h7r.forEach(t),Eso=r(ibe," \u2014 "),Lx=n(ibe,"A",{href:!0});var u7r=s(Lx);Mso=r(u7r,"MarianForCausalLM"),u7r.forEach(t),yso=r(ibe," (Marian model)"),ibe.forEach(t),wso=i(D),rp=n(D,"LI",{});var dbe=s(rp);iJ=n(dbe,"STRONG",{});var p7r=s(iJ);Aso=r(p7r,"mbart"),p7r.forEach(t),Lso=r(dbe," \u2014 "),Bx=n(dbe,"A",{href:!0});var _7r=s(Bx);Bso=r(_7r,"MBartForCausalLM"),_7r.forEach(t),kso=r(dbe," (mBART model)"),dbe.forEach(t),xso=i(D),tp=n(D,"LI",{});var cbe=s(tp);dJ=n(cbe,"STRONG",{});var v7r=s(dJ);Rso=r(v7r,"megatron-bert"),v7r.forEach(t),Sso=r(cbe," \u2014 "),kx=n(cbe,"A",{href:!0});var b7r=s(kx);Pso=r(b7r,"MegatronBertForCausalLM"),b7r.forEach(t),$so=r(cbe," (MegatronBert model)"),cbe.forEach(t),Iso=i(D),ap=n(D,"LI",{});var fbe=s(ap);cJ=n(fbe,"STRONG",{});var T7r=s(cJ);jso=r(T7r,"openai-gpt"),T7r.forEach(t),Nso=r(fbe," \u2014 "),xx=n(fbe,"A",{href:!0});var F7r=s(xx);Dso=r(F7r,"OpenAIGPTLMHeadModel"),F7r.forEach(t),qso=r(fbe," (OpenAI GPT model)"),fbe.forEach(t),Oso=i(D),np=n(D,"LI",{});var mbe=s(np);fJ=n(mbe,"STRONG",{});var C7r=s(fJ);Gso=r(C7r,"pegasus"),C7r.forEach(t),zso=r(mbe," \u2014 "),Rx=n(mbe,"A",{href:!0});var E7r=s(Rx);Vso=r(E7r,"PegasusForCausalLM"),E7r.forEach(t),Xso=r(mbe," (Pegasus model)"),mbe.forEach(t),Wso=i(D),sp=n(D,"LI",{});var gbe=s(sp);mJ=n(gbe,"STRONG",{});var M7r=s(mJ);Qso=r(M7r,"prophetnet"),M7r.forEach(t),Hso=r(gbe," \u2014 "),Sx=n(gbe,"A",{href:!0});var y7r=s(Sx);Uso=r(y7r,"ProphetNetForCausalLM"),y7r.forEach(t),Jso=r(gbe," (ProphetNet model)"),gbe.forEach(t),Yso=i(D),lp=n(D,"LI",{});var hbe=s(lp);gJ=n(hbe,"STRONG",{});var w7r=s(gJ);Kso=r(w7r,"qdqbert"),w7r.forEach(t),Zso=r(hbe," \u2014 "),Px=n(hbe,"A",{href:!0});var A7r=s(Px);elo=r(A7r,"QDQBertLMHeadModel"),A7r.forEach(t),olo=r(hbe," (QDQBert model)"),hbe.forEach(t),rlo=i(D),ip=n(D,"LI",{});var ube=s(ip);hJ=n(ube,"STRONG",{});var L7r=s(hJ);tlo=r(L7r,"reformer"),L7r.forEach(t),alo=r(ube," \u2014 "),$x=n(ube,"A",{href:!0});var B7r=s($x);nlo=r(B7r,"ReformerModelWithLMHead"),B7r.forEach(t),slo=r(ube," (Reformer model)"),ube.forEach(t),llo=i(D),dp=n(D,"LI",{});var pbe=s(dp);uJ=n(pbe,"STRONG",{});var k7r=s(uJ);ilo=r(k7r,"rembert"),k7r.forEach(t),dlo=r(pbe," \u2014 "),Ix=n(pbe,"A",{href:!0});var x7r=s(Ix);clo=r(x7r,"RemBertForCausalLM"),x7r.forEach(t),flo=r(pbe," (RemBERT model)"),pbe.forEach(t),mlo=i(D),cp=n(D,"LI",{});var _be=s(cp);pJ=n(_be,"STRONG",{});var R7r=s(pJ);glo=r(R7r,"roberta"),R7r.forEach(t),hlo=r(_be," \u2014 "),jx=n(_be,"A",{href:!0});var S7r=s(jx);ulo=r(S7r,"RobertaForCausalLM"),S7r.forEach(t),plo=r(_be," (RoBERTa model)"),_be.forEach(t),_lo=i(D),fp=n(D,"LI",{});var vbe=s(fp);_J=n(vbe,"STRONG",{});var P7r=s(_J);vlo=r(P7r,"roformer"),P7r.forEach(t),blo=r(vbe," \u2014 "),Nx=n(vbe,"A",{href:!0});var $7r=s(Nx);Tlo=r($7r,"RoFormerForCausalLM"),$7r.forEach(t),Flo=r(vbe," (RoFormer model)"),vbe.forEach(t),Clo=i(D),mp=n(D,"LI",{});var bbe=s(mp);vJ=n(bbe,"STRONG",{});var I7r=s(vJ);Elo=r(I7r,"speech_to_text_2"),I7r.forEach(t),Mlo=r(bbe," \u2014 "),Dx=n(bbe,"A",{href:!0});var j7r=s(Dx);ylo=r(j7r,"Speech2Text2ForCausalLM"),j7r.forEach(t),wlo=r(bbe," (Speech2Text2 model)"),bbe.forEach(t),Alo=i(D),gp=n(D,"LI",{});var Tbe=s(gp);bJ=n(Tbe,"STRONG",{});var N7r=s(bJ);Llo=r(N7r,"transfo-xl"),N7r.forEach(t),Blo=r(Tbe," \u2014 "),qx=n(Tbe,"A",{href:!0});var D7r=s(qx);klo=r(D7r,"TransfoXLLMHeadModel"),D7r.forEach(t),xlo=r(Tbe," (Transformer-XL model)"),Tbe.forEach(t),Rlo=i(D),hp=n(D,"LI",{});var Fbe=s(hp);TJ=n(Fbe,"STRONG",{});var q7r=s(TJ);Slo=r(q7r,"trocr"),q7r.forEach(t),Plo=r(Fbe," \u2014 "),Ox=n(Fbe,"A",{href:!0});var O7r=s(Ox);$lo=r(O7r,"TrOCRForCausalLM"),O7r.forEach(t),Ilo=r(Fbe," (TrOCR model)"),Fbe.forEach(t),jlo=i(D),up=n(D,"LI",{});var Cbe=s(up);FJ=n(Cbe,"STRONG",{});var G7r=s(FJ);Nlo=r(G7r,"xlm"),G7r.forEach(t),Dlo=r(Cbe," \u2014 "),Gx=n(Cbe,"A",{href:!0});var z7r=s(Gx);qlo=r(z7r,"XLMWithLMHeadModel"),z7r.forEach(t),Olo=r(Cbe," (XLM model)"),Cbe.forEach(t),Glo=i(D),pp=n(D,"LI",{});var Ebe=s(pp);CJ=n(Ebe,"STRONG",{});var V7r=s(CJ);zlo=r(V7r,"xlm-prophetnet"),V7r.forEach(t),Vlo=r(Ebe," \u2014 "),zx=n(Ebe,"A",{href:!0});var X7r=s(zx);Xlo=r(X7r,"XLMProphetNetForCausalLM"),X7r.forEach(t),Wlo=r(Ebe," (XLMProphetNet model)"),Ebe.forEach(t),Qlo=i(D),_p=n(D,"LI",{});var Mbe=s(_p);EJ=n(Mbe,"STRONG",{});var W7r=s(EJ);Hlo=r(W7r,"xlm-roberta"),W7r.forEach(t),Ulo=r(Mbe," \u2014 "),Vx=n(Mbe,"A",{href:!0});var Q7r=s(Vx);Jlo=r(Q7r,"XLMRobertaForCausalLM"),Q7r.forEach(t),Ylo=r(Mbe," (XLM-RoBERTa model)"),Mbe.forEach(t),Klo=i(D),vp=n(D,"LI",{});var ybe=s(vp);MJ=n(ybe,"STRONG",{});var H7r=s(MJ);Zlo=r(H7r,"xlnet"),H7r.forEach(t),eio=r(ybe," \u2014 "),Xx=n(ybe,"A",{href:!0});var U7r=s(Xx);oio=r(U7r,"XLNetLMHeadModel"),U7r.forEach(t),rio=r(ybe," (XLNet model)"),ybe.forEach(t),D.forEach(t),tio=i(Et),bp=n(Et,"P",{});var wbe=s(bp);aio=r(wbe,"The model is set in evaluation mode by default using "),yJ=n(wbe,"CODE",{});var J7r=s(yJ);nio=r(J7r,"model.eval()"),J7r.forEach(t),sio=r(wbe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wJ=n(wbe,"CODE",{});var Y7r=s(wJ);lio=r(Y7r,"model.train()"),Y7r.forEach(t),wbe.forEach(t),iio=i(Et),AJ=n(Et,"P",{});var K7r=s(AJ);dio=r(K7r,"Examples:"),K7r.forEach(t),cio=i(Et),m(LM.$$.fragment,Et),Et.forEach(t),Es.forEach(t),Twe=i(d),Mi=n(d,"H2",{class:!0});var b0e=s(Mi);Tp=n(b0e,"A",{id:!0,class:!0,href:!0});var Z7r=s(Tp);LJ=n(Z7r,"SPAN",{});var eLr=s(LJ);m(BM.$$.fragment,eLr),eLr.forEach(t),Z7r.forEach(t),fio=i(b0e),BJ=n(b0e,"SPAN",{});var oLr=s(BJ);mio=r(oLr,"AutoModelForMaskedLM"),oLr.forEach(t),b0e.forEach(t),Fwe=i(d),Go=n(d,"DIV",{class:!0});var ys=s(Go);m(kM.$$.fragment,ys),gio=i(ys),yi=n(ys,"P",{});var vO=s(yi);hio=r(vO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),kJ=n(vO,"CODE",{});var rLr=s(kJ);uio=r(rLr,"from_pretrained()"),rLr.forEach(t),pio=r(vO,"class method or the "),xJ=n(vO,"CODE",{});var tLr=s(xJ);_io=r(tLr,"from_config()"),tLr.forEach(t),vio=r(vO,`class
method.`),vO.forEach(t),bio=i(ys),xM=n(ys,"P",{});var T0e=s(xM);Tio=r(T0e,"This class cannot be instantiated directly using "),RJ=n(T0e,"CODE",{});var aLr=s(RJ);Fio=r(aLr,"__init__()"),aLr.forEach(t),Cio=r(T0e," (throws an error)."),T0e.forEach(t),Eio=i(ys),Rr=n(ys,"DIV",{class:!0});var ws=s(Rr);m(RM.$$.fragment,ws),Mio=i(ws),SJ=n(ws,"P",{});var nLr=s(SJ);yio=r(nLr,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),nLr.forEach(t),wio=i(ws),wi=n(ws,"P",{});var bO=s(wi);Aio=r(bO,`Note:
Loading a model from its configuration file does `),PJ=n(bO,"STRONG",{});var sLr=s(PJ);Lio=r(sLr,"not"),sLr.forEach(t),Bio=r(bO,` load the model weights. It only affects the
model\u2019s configuration. Use `),$J=n(bO,"CODE",{});var lLr=s($J);kio=r(lLr,"from_pretrained()"),lLr.forEach(t),xio=r(bO,"to load the model weights."),bO.forEach(t),Rio=i(ws),IJ=n(ws,"P",{});var iLr=s(IJ);Sio=r(iLr,"Examples:"),iLr.forEach(t),Pio=i(ws),m(SM.$$.fragment,ws),ws.forEach(t),$io=i(ys),Re=n(ys,"DIV",{class:!0});var Mt=s(Re);m(PM.$$.fragment,Mt),Iio=i(Mt),jJ=n(Mt,"P",{});var dLr=s(jJ);jio=r(dLr,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),dLr.forEach(t),Nio=i(Mt),ka=n(Mt,"P",{});var zC=s(ka);Dio=r(zC,"The model class to instantiate is selected based on the "),NJ=n(zC,"CODE",{});var cLr=s(NJ);qio=r(cLr,"model_type"),cLr.forEach(t),Oio=r(zC,` property of the config object (either
passed as an argument or loaded from `),DJ=n(zC,"CODE",{});var fLr=s(DJ);Gio=r(fLr,"pretrained_model_name_or_path"),fLr.forEach(t),zio=r(zC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qJ=n(zC,"CODE",{});var mLr=s(qJ);Vio=r(mLr,"pretrained_model_name_or_path"),mLr.forEach(t),Xio=r(zC,":"),zC.forEach(t),Wio=i(Mt),$=n(Mt,"UL",{});var I=s($);Fp=n(I,"LI",{});var Abe=s(Fp);OJ=n(Abe,"STRONG",{});var gLr=s(OJ);Qio=r(gLr,"albert"),gLr.forEach(t),Hio=r(Abe," \u2014 "),Wx=n(Abe,"A",{href:!0});var hLr=s(Wx);Uio=r(hLr,"AlbertForMaskedLM"),hLr.forEach(t),Jio=r(Abe," (ALBERT model)"),Abe.forEach(t),Yio=i(I),Cp=n(I,"LI",{});var Lbe=s(Cp);GJ=n(Lbe,"STRONG",{});var uLr=s(GJ);Kio=r(uLr,"bart"),uLr.forEach(t),Zio=r(Lbe," \u2014 "),Qx=n(Lbe,"A",{href:!0});var pLr=s(Qx);edo=r(pLr,"BartForConditionalGeneration"),pLr.forEach(t),odo=r(Lbe," (BART model)"),Lbe.forEach(t),rdo=i(I),Ep=n(I,"LI",{});var Bbe=s(Ep);zJ=n(Bbe,"STRONG",{});var _Lr=s(zJ);tdo=r(_Lr,"bert"),_Lr.forEach(t),ado=r(Bbe," \u2014 "),Hx=n(Bbe,"A",{href:!0});var vLr=s(Hx);ndo=r(vLr,"BertForMaskedLM"),vLr.forEach(t),sdo=r(Bbe," (BERT model)"),Bbe.forEach(t),ldo=i(I),Mp=n(I,"LI",{});var kbe=s(Mp);VJ=n(kbe,"STRONG",{});var bLr=s(VJ);ido=r(bLr,"big_bird"),bLr.forEach(t),ddo=r(kbe," \u2014 "),Ux=n(kbe,"A",{href:!0});var TLr=s(Ux);cdo=r(TLr,"BigBirdForMaskedLM"),TLr.forEach(t),fdo=r(kbe," (BigBird model)"),kbe.forEach(t),mdo=i(I),yp=n(I,"LI",{});var xbe=s(yp);XJ=n(xbe,"STRONG",{});var FLr=s(XJ);gdo=r(FLr,"camembert"),FLr.forEach(t),hdo=r(xbe," \u2014 "),Jx=n(xbe,"A",{href:!0});var CLr=s(Jx);udo=r(CLr,"CamembertForMaskedLM"),CLr.forEach(t),pdo=r(xbe," (CamemBERT model)"),xbe.forEach(t),_do=i(I),wp=n(I,"LI",{});var Rbe=s(wp);WJ=n(Rbe,"STRONG",{});var ELr=s(WJ);vdo=r(ELr,"convbert"),ELr.forEach(t),bdo=r(Rbe," \u2014 "),Yx=n(Rbe,"A",{href:!0});var MLr=s(Yx);Tdo=r(MLr,"ConvBertForMaskedLM"),MLr.forEach(t),Fdo=r(Rbe," (ConvBERT model)"),Rbe.forEach(t),Cdo=i(I),Ap=n(I,"LI",{});var Sbe=s(Ap);QJ=n(Sbe,"STRONG",{});var yLr=s(QJ);Edo=r(yLr,"deberta"),yLr.forEach(t),Mdo=r(Sbe," \u2014 "),Kx=n(Sbe,"A",{href:!0});var wLr=s(Kx);ydo=r(wLr,"DebertaForMaskedLM"),wLr.forEach(t),wdo=r(Sbe," (DeBERTa model)"),Sbe.forEach(t),Ado=i(I),Lp=n(I,"LI",{});var Pbe=s(Lp);HJ=n(Pbe,"STRONG",{});var ALr=s(HJ);Ldo=r(ALr,"deberta-v2"),ALr.forEach(t),Bdo=r(Pbe," \u2014 "),Zx=n(Pbe,"A",{href:!0});var LLr=s(Zx);kdo=r(LLr,"DebertaV2ForMaskedLM"),LLr.forEach(t),xdo=r(Pbe," (DeBERTa-v2 model)"),Pbe.forEach(t),Rdo=i(I),Bp=n(I,"LI",{});var $be=s(Bp);UJ=n($be,"STRONG",{});var BLr=s(UJ);Sdo=r(BLr,"distilbert"),BLr.forEach(t),Pdo=r($be," \u2014 "),eR=n($be,"A",{href:!0});var kLr=s(eR);$do=r(kLr,"DistilBertForMaskedLM"),kLr.forEach(t),Ido=r($be," (DistilBERT model)"),$be.forEach(t),jdo=i(I),kp=n(I,"LI",{});var Ibe=s(kp);JJ=n(Ibe,"STRONG",{});var xLr=s(JJ);Ndo=r(xLr,"electra"),xLr.forEach(t),Ddo=r(Ibe," \u2014 "),oR=n(Ibe,"A",{href:!0});var RLr=s(oR);qdo=r(RLr,"ElectraForMaskedLM"),RLr.forEach(t),Odo=r(Ibe," (ELECTRA model)"),Ibe.forEach(t),Gdo=i(I),xp=n(I,"LI",{});var jbe=s(xp);YJ=n(jbe,"STRONG",{});var SLr=s(YJ);zdo=r(SLr,"flaubert"),SLr.forEach(t),Vdo=r(jbe," \u2014 "),rR=n(jbe,"A",{href:!0});var PLr=s(rR);Xdo=r(PLr,"FlaubertWithLMHeadModel"),PLr.forEach(t),Wdo=r(jbe," (FlauBERT model)"),jbe.forEach(t),Qdo=i(I),Rp=n(I,"LI",{});var Nbe=s(Rp);KJ=n(Nbe,"STRONG",{});var $Lr=s(KJ);Hdo=r($Lr,"fnet"),$Lr.forEach(t),Udo=r(Nbe," \u2014 "),tR=n(Nbe,"A",{href:!0});var ILr=s(tR);Jdo=r(ILr,"FNetForMaskedLM"),ILr.forEach(t),Ydo=r(Nbe," (FNet model)"),Nbe.forEach(t),Kdo=i(I),Sp=n(I,"LI",{});var Dbe=s(Sp);ZJ=n(Dbe,"STRONG",{});var jLr=s(ZJ);Zdo=r(jLr,"funnel"),jLr.forEach(t),eco=r(Dbe," \u2014 "),aR=n(Dbe,"A",{href:!0});var NLr=s(aR);oco=r(NLr,"FunnelForMaskedLM"),NLr.forEach(t),rco=r(Dbe," (Funnel Transformer model)"),Dbe.forEach(t),tco=i(I),Pp=n(I,"LI",{});var qbe=s(Pp);eY=n(qbe,"STRONG",{});var DLr=s(eY);aco=r(DLr,"ibert"),DLr.forEach(t),nco=r(qbe," \u2014 "),nR=n(qbe,"A",{href:!0});var qLr=s(nR);sco=r(qLr,"IBertForMaskedLM"),qLr.forEach(t),lco=r(qbe," (I-BERT model)"),qbe.forEach(t),ico=i(I),$p=n(I,"LI",{});var Obe=s($p);oY=n(Obe,"STRONG",{});var OLr=s(oY);dco=r(OLr,"layoutlm"),OLr.forEach(t),cco=r(Obe," \u2014 "),sR=n(Obe,"A",{href:!0});var GLr=s(sR);fco=r(GLr,"LayoutLMForMaskedLM"),GLr.forEach(t),mco=r(Obe," (LayoutLM model)"),Obe.forEach(t),gco=i(I),Ip=n(I,"LI",{});var Gbe=s(Ip);rY=n(Gbe,"STRONG",{});var zLr=s(rY);hco=r(zLr,"longformer"),zLr.forEach(t),uco=r(Gbe," \u2014 "),lR=n(Gbe,"A",{href:!0});var VLr=s(lR);pco=r(VLr,"LongformerForMaskedLM"),VLr.forEach(t),_co=r(Gbe," (Longformer model)"),Gbe.forEach(t),vco=i(I),jp=n(I,"LI",{});var zbe=s(jp);tY=n(zbe,"STRONG",{});var XLr=s(tY);bco=r(XLr,"mbart"),XLr.forEach(t),Tco=r(zbe," \u2014 "),iR=n(zbe,"A",{href:!0});var WLr=s(iR);Fco=r(WLr,"MBartForConditionalGeneration"),WLr.forEach(t),Cco=r(zbe," (mBART model)"),zbe.forEach(t),Eco=i(I),Np=n(I,"LI",{});var Vbe=s(Np);aY=n(Vbe,"STRONG",{});var QLr=s(aY);Mco=r(QLr,"megatron-bert"),QLr.forEach(t),yco=r(Vbe," \u2014 "),dR=n(Vbe,"A",{href:!0});var HLr=s(dR);wco=r(HLr,"MegatronBertForMaskedLM"),HLr.forEach(t),Aco=r(Vbe," (MegatronBert model)"),Vbe.forEach(t),Lco=i(I),Dp=n(I,"LI",{});var Xbe=s(Dp);nY=n(Xbe,"STRONG",{});var ULr=s(nY);Bco=r(ULr,"mobilebert"),ULr.forEach(t),kco=r(Xbe," \u2014 "),cR=n(Xbe,"A",{href:!0});var JLr=s(cR);xco=r(JLr,"MobileBertForMaskedLM"),JLr.forEach(t),Rco=r(Xbe," (MobileBERT model)"),Xbe.forEach(t),Sco=i(I),qp=n(I,"LI",{});var Wbe=s(qp);sY=n(Wbe,"STRONG",{});var YLr=s(sY);Pco=r(YLr,"mpnet"),YLr.forEach(t),$co=r(Wbe," \u2014 "),fR=n(Wbe,"A",{href:!0});var KLr=s(fR);Ico=r(KLr,"MPNetForMaskedLM"),KLr.forEach(t),jco=r(Wbe," (MPNet model)"),Wbe.forEach(t),Nco=i(I),Op=n(I,"LI",{});var Qbe=s(Op);lY=n(Qbe,"STRONG",{});var ZLr=s(lY);Dco=r(ZLr,"nystromformer"),ZLr.forEach(t),qco=r(Qbe," \u2014 "),mR=n(Qbe,"A",{href:!0});var e8r=s(mR);Oco=r(e8r,"NystromformerForMaskedLM"),e8r.forEach(t),Gco=r(Qbe," (Nystromformer model)"),Qbe.forEach(t),zco=i(I),Gp=n(I,"LI",{});var Hbe=s(Gp);iY=n(Hbe,"STRONG",{});var o8r=s(iY);Vco=r(o8r,"perceiver"),o8r.forEach(t),Xco=r(Hbe," \u2014 "),gR=n(Hbe,"A",{href:!0});var r8r=s(gR);Wco=r(r8r,"PerceiverForMaskedLM"),r8r.forEach(t),Qco=r(Hbe," (Perceiver model)"),Hbe.forEach(t),Hco=i(I),zp=n(I,"LI",{});var Ube=s(zp);dY=n(Ube,"STRONG",{});var t8r=s(dY);Uco=r(t8r,"qdqbert"),t8r.forEach(t),Jco=r(Ube," \u2014 "),hR=n(Ube,"A",{href:!0});var a8r=s(hR);Yco=r(a8r,"QDQBertForMaskedLM"),a8r.forEach(t),Kco=r(Ube," (QDQBert model)"),Ube.forEach(t),Zco=i(I),Vp=n(I,"LI",{});var Jbe=s(Vp);cY=n(Jbe,"STRONG",{});var n8r=s(cY);efo=r(n8r,"reformer"),n8r.forEach(t),ofo=r(Jbe," \u2014 "),uR=n(Jbe,"A",{href:!0});var s8r=s(uR);rfo=r(s8r,"ReformerForMaskedLM"),s8r.forEach(t),tfo=r(Jbe," (Reformer model)"),Jbe.forEach(t),afo=i(I),Xp=n(I,"LI",{});var Ybe=s(Xp);fY=n(Ybe,"STRONG",{});var l8r=s(fY);nfo=r(l8r,"rembert"),l8r.forEach(t),sfo=r(Ybe," \u2014 "),pR=n(Ybe,"A",{href:!0});var i8r=s(pR);lfo=r(i8r,"RemBertForMaskedLM"),i8r.forEach(t),ifo=r(Ybe," (RemBERT model)"),Ybe.forEach(t),dfo=i(I),Wp=n(I,"LI",{});var Kbe=s(Wp);mY=n(Kbe,"STRONG",{});var d8r=s(mY);cfo=r(d8r,"roberta"),d8r.forEach(t),ffo=r(Kbe," \u2014 "),_R=n(Kbe,"A",{href:!0});var c8r=s(_R);mfo=r(c8r,"RobertaForMaskedLM"),c8r.forEach(t),gfo=r(Kbe," (RoBERTa model)"),Kbe.forEach(t),hfo=i(I),Qp=n(I,"LI",{});var Zbe=s(Qp);gY=n(Zbe,"STRONG",{});var f8r=s(gY);ufo=r(f8r,"roformer"),f8r.forEach(t),pfo=r(Zbe," \u2014 "),vR=n(Zbe,"A",{href:!0});var m8r=s(vR);_fo=r(m8r,"RoFormerForMaskedLM"),m8r.forEach(t),vfo=r(Zbe," (RoFormer model)"),Zbe.forEach(t),bfo=i(I),Hp=n(I,"LI",{});var eTe=s(Hp);hY=n(eTe,"STRONG",{});var g8r=s(hY);Tfo=r(g8r,"squeezebert"),g8r.forEach(t),Ffo=r(eTe," \u2014 "),bR=n(eTe,"A",{href:!0});var h8r=s(bR);Cfo=r(h8r,"SqueezeBertForMaskedLM"),h8r.forEach(t),Efo=r(eTe," (SqueezeBERT model)"),eTe.forEach(t),Mfo=i(I),Up=n(I,"LI",{});var oTe=s(Up);uY=n(oTe,"STRONG",{});var u8r=s(uY);yfo=r(u8r,"tapas"),u8r.forEach(t),wfo=r(oTe," \u2014 "),TR=n(oTe,"A",{href:!0});var p8r=s(TR);Afo=r(p8r,"TapasForMaskedLM"),p8r.forEach(t),Lfo=r(oTe," (TAPAS model)"),oTe.forEach(t),Bfo=i(I),Jp=n(I,"LI",{});var rTe=s(Jp);pY=n(rTe,"STRONG",{});var _8r=s(pY);kfo=r(_8r,"wav2vec2"),_8r.forEach(t),xfo=r(rTe," \u2014 "),_Y=n(rTe,"CODE",{});var v8r=s(_Y);Rfo=r(v8r,"Wav2Vec2ForMaskedLM"),v8r.forEach(t),Sfo=r(rTe,"(Wav2Vec2 model)"),rTe.forEach(t),Pfo=i(I),Yp=n(I,"LI",{});var tTe=s(Yp);vY=n(tTe,"STRONG",{});var b8r=s(vY);$fo=r(b8r,"xlm"),b8r.forEach(t),Ifo=r(tTe," \u2014 "),FR=n(tTe,"A",{href:!0});var T8r=s(FR);jfo=r(T8r,"XLMWithLMHeadModel"),T8r.forEach(t),Nfo=r(tTe," (XLM model)"),tTe.forEach(t),Dfo=i(I),Kp=n(I,"LI",{});var aTe=s(Kp);bY=n(aTe,"STRONG",{});var F8r=s(bY);qfo=r(F8r,"xlm-roberta"),F8r.forEach(t),Ofo=r(aTe," \u2014 "),CR=n(aTe,"A",{href:!0});var C8r=s(CR);Gfo=r(C8r,"XLMRobertaForMaskedLM"),C8r.forEach(t),zfo=r(aTe," (XLM-RoBERTa model)"),aTe.forEach(t),Vfo=i(I),Zp=n(I,"LI",{});var nTe=s(Zp);TY=n(nTe,"STRONG",{});var E8r=s(TY);Xfo=r(E8r,"yoso"),E8r.forEach(t),Wfo=r(nTe," \u2014 "),ER=n(nTe,"A",{href:!0});var M8r=s(ER);Qfo=r(M8r,"YosoForMaskedLM"),M8r.forEach(t),Hfo=r(nTe," (YOSO model)"),nTe.forEach(t),I.forEach(t),Ufo=i(Mt),e_=n(Mt,"P",{});var sTe=s(e_);Jfo=r(sTe,"The model is set in evaluation mode by default using "),FY=n(sTe,"CODE",{});var y8r=s(FY);Yfo=r(y8r,"model.eval()"),y8r.forEach(t),Kfo=r(sTe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CY=n(sTe,"CODE",{});var w8r=s(CY);Zfo=r(w8r,"model.train()"),w8r.forEach(t),sTe.forEach(t),emo=i(Mt),EY=n(Mt,"P",{});var A8r=s(EY);omo=r(A8r,"Examples:"),A8r.forEach(t),rmo=i(Mt),m($M.$$.fragment,Mt),Mt.forEach(t),ys.forEach(t),Cwe=i(d),Ai=n(d,"H2",{class:!0});var F0e=s(Ai);o_=n(F0e,"A",{id:!0,class:!0,href:!0});var L8r=s(o_);MY=n(L8r,"SPAN",{});var B8r=s(MY);m(IM.$$.fragment,B8r),B8r.forEach(t),L8r.forEach(t),tmo=i(F0e),yY=n(F0e,"SPAN",{});var k8r=s(yY);amo=r(k8r,"AutoModelForSeq2SeqLM"),k8r.forEach(t),F0e.forEach(t),Ewe=i(d),zo=n(d,"DIV",{class:!0});var As=s(zo);m(jM.$$.fragment,As),nmo=i(As),Li=n(As,"P",{});var TO=s(Li);smo=r(TO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),wY=n(TO,"CODE",{});var x8r=s(wY);lmo=r(x8r,"from_pretrained()"),x8r.forEach(t),imo=r(TO,"class method or the "),AY=n(TO,"CODE",{});var R8r=s(AY);dmo=r(R8r,"from_config()"),R8r.forEach(t),cmo=r(TO,`class
method.`),TO.forEach(t),fmo=i(As),NM=n(As,"P",{});var C0e=s(NM);mmo=r(C0e,"This class cannot be instantiated directly using "),LY=n(C0e,"CODE",{});var S8r=s(LY);gmo=r(S8r,"__init__()"),S8r.forEach(t),hmo=r(C0e," (throws an error)."),C0e.forEach(t),umo=i(As),Sr=n(As,"DIV",{class:!0});var Ls=s(Sr);m(DM.$$.fragment,Ls),pmo=i(Ls),BY=n(Ls,"P",{});var P8r=s(BY);_mo=r(P8r,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),P8r.forEach(t),vmo=i(Ls),Bi=n(Ls,"P",{});var FO=s(Bi);bmo=r(FO,`Note:
Loading a model from its configuration file does `),kY=n(FO,"STRONG",{});var $8r=s(kY);Tmo=r($8r,"not"),$8r.forEach(t),Fmo=r(FO,` load the model weights. It only affects the
model\u2019s configuration. Use `),xY=n(FO,"CODE",{});var I8r=s(xY);Cmo=r(I8r,"from_pretrained()"),I8r.forEach(t),Emo=r(FO,"to load the model weights."),FO.forEach(t),Mmo=i(Ls),RY=n(Ls,"P",{});var j8r=s(RY);ymo=r(j8r,"Examples:"),j8r.forEach(t),wmo=i(Ls),m(qM.$$.fragment,Ls),Ls.forEach(t),Amo=i(As),Se=n(As,"DIV",{class:!0});var yt=s(Se);m(OM.$$.fragment,yt),Lmo=i(yt),SY=n(yt,"P",{});var N8r=s(SY);Bmo=r(N8r,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),N8r.forEach(t),kmo=i(yt),xa=n(yt,"P",{});var VC=s(xa);xmo=r(VC,"The model class to instantiate is selected based on the "),PY=n(VC,"CODE",{});var D8r=s(PY);Rmo=r(D8r,"model_type"),D8r.forEach(t),Smo=r(VC,` property of the config object (either
passed as an argument or loaded from `),$Y=n(VC,"CODE",{});var q8r=s($Y);Pmo=r(q8r,"pretrained_model_name_or_path"),q8r.forEach(t),$mo=r(VC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IY=n(VC,"CODE",{});var O8r=s(IY);Imo=r(O8r,"pretrained_model_name_or_path"),O8r.forEach(t),jmo=r(VC,":"),VC.forEach(t),Nmo=i(yt),ne=n(yt,"UL",{});var le=s(ne);r_=n(le,"LI",{});var lTe=s(r_);jY=n(lTe,"STRONG",{});var G8r=s(jY);Dmo=r(G8r,"bart"),G8r.forEach(t),qmo=r(lTe," \u2014 "),MR=n(lTe,"A",{href:!0});var z8r=s(MR);Omo=r(z8r,"BartForConditionalGeneration"),z8r.forEach(t),Gmo=r(lTe," (BART model)"),lTe.forEach(t),zmo=i(le),t_=n(le,"LI",{});var iTe=s(t_);NY=n(iTe,"STRONG",{});var V8r=s(NY);Vmo=r(V8r,"bigbird_pegasus"),V8r.forEach(t),Xmo=r(iTe," \u2014 "),yR=n(iTe,"A",{href:!0});var X8r=s(yR);Wmo=r(X8r,"BigBirdPegasusForConditionalGeneration"),X8r.forEach(t),Qmo=r(iTe," (BigBirdPegasus model)"),iTe.forEach(t),Hmo=i(le),a_=n(le,"LI",{});var dTe=s(a_);DY=n(dTe,"STRONG",{});var W8r=s(DY);Umo=r(W8r,"blenderbot"),W8r.forEach(t),Jmo=r(dTe," \u2014 "),wR=n(dTe,"A",{href:!0});var Q8r=s(wR);Ymo=r(Q8r,"BlenderbotForConditionalGeneration"),Q8r.forEach(t),Kmo=r(dTe," (Blenderbot model)"),dTe.forEach(t),Zmo=i(le),n_=n(le,"LI",{});var cTe=s(n_);qY=n(cTe,"STRONG",{});var H8r=s(qY);ego=r(H8r,"blenderbot-small"),H8r.forEach(t),ogo=r(cTe," \u2014 "),AR=n(cTe,"A",{href:!0});var U8r=s(AR);rgo=r(U8r,"BlenderbotSmallForConditionalGeneration"),U8r.forEach(t),tgo=r(cTe," (BlenderbotSmall model)"),cTe.forEach(t),ago=i(le),s_=n(le,"LI",{});var fTe=s(s_);OY=n(fTe,"STRONG",{});var J8r=s(OY);ngo=r(J8r,"encoder-decoder"),J8r.forEach(t),sgo=r(fTe," \u2014 "),LR=n(fTe,"A",{href:!0});var Y8r=s(LR);lgo=r(Y8r,"EncoderDecoderModel"),Y8r.forEach(t),igo=r(fTe," (Encoder decoder model)"),fTe.forEach(t),dgo=i(le),l_=n(le,"LI",{});var mTe=s(l_);GY=n(mTe,"STRONG",{});var K8r=s(GY);cgo=r(K8r,"fsmt"),K8r.forEach(t),fgo=r(mTe," \u2014 "),BR=n(mTe,"A",{href:!0});var Z8r=s(BR);mgo=r(Z8r,"FSMTForConditionalGeneration"),Z8r.forEach(t),ggo=r(mTe," (FairSeq Machine-Translation model)"),mTe.forEach(t),hgo=i(le),i_=n(le,"LI",{});var gTe=s(i_);zY=n(gTe,"STRONG",{});var eBr=s(zY);ugo=r(eBr,"led"),eBr.forEach(t),pgo=r(gTe," \u2014 "),kR=n(gTe,"A",{href:!0});var oBr=s(kR);_go=r(oBr,"LEDForConditionalGeneration"),oBr.forEach(t),vgo=r(gTe," (LED model)"),gTe.forEach(t),bgo=i(le),d_=n(le,"LI",{});var hTe=s(d_);VY=n(hTe,"STRONG",{});var rBr=s(VY);Tgo=r(rBr,"m2m_100"),rBr.forEach(t),Fgo=r(hTe," \u2014 "),xR=n(hTe,"A",{href:!0});var tBr=s(xR);Cgo=r(tBr,"M2M100ForConditionalGeneration"),tBr.forEach(t),Ego=r(hTe," (M2M100 model)"),hTe.forEach(t),Mgo=i(le),c_=n(le,"LI",{});var uTe=s(c_);XY=n(uTe,"STRONG",{});var aBr=s(XY);ygo=r(aBr,"marian"),aBr.forEach(t),wgo=r(uTe," \u2014 "),RR=n(uTe,"A",{href:!0});var nBr=s(RR);Ago=r(nBr,"MarianMTModel"),nBr.forEach(t),Lgo=r(uTe," (Marian model)"),uTe.forEach(t),Bgo=i(le),f_=n(le,"LI",{});var pTe=s(f_);WY=n(pTe,"STRONG",{});var sBr=s(WY);kgo=r(sBr,"mbart"),sBr.forEach(t),xgo=r(pTe," \u2014 "),SR=n(pTe,"A",{href:!0});var lBr=s(SR);Rgo=r(lBr,"MBartForConditionalGeneration"),lBr.forEach(t),Sgo=r(pTe," (mBART model)"),pTe.forEach(t),Pgo=i(le),m_=n(le,"LI",{});var _Te=s(m_);QY=n(_Te,"STRONG",{});var iBr=s(QY);$go=r(iBr,"mt5"),iBr.forEach(t),Igo=r(_Te," \u2014 "),PR=n(_Te,"A",{href:!0});var dBr=s(PR);jgo=r(dBr,"MT5ForConditionalGeneration"),dBr.forEach(t),Ngo=r(_Te," (mT5 model)"),_Te.forEach(t),Dgo=i(le),g_=n(le,"LI",{});var vTe=s(g_);HY=n(vTe,"STRONG",{});var cBr=s(HY);qgo=r(cBr,"pegasus"),cBr.forEach(t),Ogo=r(vTe," \u2014 "),$R=n(vTe,"A",{href:!0});var fBr=s($R);Ggo=r(fBr,"PegasusForConditionalGeneration"),fBr.forEach(t),zgo=r(vTe," (Pegasus model)"),vTe.forEach(t),Vgo=i(le),h_=n(le,"LI",{});var bTe=s(h_);UY=n(bTe,"STRONG",{});var mBr=s(UY);Xgo=r(mBr,"prophetnet"),mBr.forEach(t),Wgo=r(bTe," \u2014 "),IR=n(bTe,"A",{href:!0});var gBr=s(IR);Qgo=r(gBr,"ProphetNetForConditionalGeneration"),gBr.forEach(t),Hgo=r(bTe," (ProphetNet model)"),bTe.forEach(t),Ugo=i(le),u_=n(le,"LI",{});var TTe=s(u_);JY=n(TTe,"STRONG",{});var hBr=s(JY);Jgo=r(hBr,"t5"),hBr.forEach(t),Ygo=r(TTe," \u2014 "),jR=n(TTe,"A",{href:!0});var uBr=s(jR);Kgo=r(uBr,"T5ForConditionalGeneration"),uBr.forEach(t),Zgo=r(TTe," (T5 model)"),TTe.forEach(t),eho=i(le),p_=n(le,"LI",{});var FTe=s(p_);YY=n(FTe,"STRONG",{});var pBr=s(YY);oho=r(pBr,"xlm-prophetnet"),pBr.forEach(t),rho=r(FTe," \u2014 "),NR=n(FTe,"A",{href:!0});var _Br=s(NR);tho=r(_Br,"XLMProphetNetForConditionalGeneration"),_Br.forEach(t),aho=r(FTe," (XLMProphetNet model)"),FTe.forEach(t),le.forEach(t),nho=i(yt),__=n(yt,"P",{});var CTe=s(__);sho=r(CTe,"The model is set in evaluation mode by default using "),KY=n(CTe,"CODE",{});var vBr=s(KY);lho=r(vBr,"model.eval()"),vBr.forEach(t),iho=r(CTe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ZY=n(CTe,"CODE",{});var bBr=s(ZY);dho=r(bBr,"model.train()"),bBr.forEach(t),CTe.forEach(t),cho=i(yt),eK=n(yt,"P",{});var TBr=s(eK);fho=r(TBr,"Examples:"),TBr.forEach(t),mho=i(yt),m(GM.$$.fragment,yt),yt.forEach(t),As.forEach(t),Mwe=i(d),ki=n(d,"H2",{class:!0});var E0e=s(ki);v_=n(E0e,"A",{id:!0,class:!0,href:!0});var FBr=s(v_);oK=n(FBr,"SPAN",{});var CBr=s(oK);m(zM.$$.fragment,CBr),CBr.forEach(t),FBr.forEach(t),gho=i(E0e),rK=n(E0e,"SPAN",{});var EBr=s(rK);hho=r(EBr,"AutoModelForSequenceClassification"),EBr.forEach(t),E0e.forEach(t),ywe=i(d),Vo=n(d,"DIV",{class:!0});var Bs=s(Vo);m(VM.$$.fragment,Bs),uho=i(Bs),xi=n(Bs,"P",{});var CO=s(xi);pho=r(CO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),tK=n(CO,"CODE",{});var MBr=s(tK);_ho=r(MBr,"from_pretrained()"),MBr.forEach(t),vho=r(CO,"class method or the "),aK=n(CO,"CODE",{});var yBr=s(aK);bho=r(yBr,"from_config()"),yBr.forEach(t),Tho=r(CO,`class
method.`),CO.forEach(t),Fho=i(Bs),XM=n(Bs,"P",{});var M0e=s(XM);Cho=r(M0e,"This class cannot be instantiated directly using "),nK=n(M0e,"CODE",{});var wBr=s(nK);Eho=r(wBr,"__init__()"),wBr.forEach(t),Mho=r(M0e," (throws an error)."),M0e.forEach(t),yho=i(Bs),Pr=n(Bs,"DIV",{class:!0});var ks=s(Pr);m(WM.$$.fragment,ks),who=i(ks),sK=n(ks,"P",{});var ABr=s(sK);Aho=r(ABr,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),ABr.forEach(t),Lho=i(ks),Ri=n(ks,"P",{});var EO=s(Ri);Bho=r(EO,`Note:
Loading a model from its configuration file does `),lK=n(EO,"STRONG",{});var LBr=s(lK);kho=r(LBr,"not"),LBr.forEach(t),xho=r(EO,` load the model weights. It only affects the
model\u2019s configuration. Use `),iK=n(EO,"CODE",{});var BBr=s(iK);Rho=r(BBr,"from_pretrained()"),BBr.forEach(t),Sho=r(EO,"to load the model weights."),EO.forEach(t),Pho=i(ks),dK=n(ks,"P",{});var kBr=s(dK);$ho=r(kBr,"Examples:"),kBr.forEach(t),Iho=i(ks),m(QM.$$.fragment,ks),ks.forEach(t),jho=i(Bs),Pe=n(Bs,"DIV",{class:!0});var wt=s(Pe);m(HM.$$.fragment,wt),Nho=i(wt),cK=n(wt,"P",{});var xBr=s(cK);Dho=r(xBr,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),xBr.forEach(t),qho=i(wt),Ra=n(wt,"P",{});var XC=s(Ra);Oho=r(XC,"The model class to instantiate is selected based on the "),fK=n(XC,"CODE",{});var RBr=s(fK);Gho=r(RBr,"model_type"),RBr.forEach(t),zho=r(XC,` property of the config object (either
passed as an argument or loaded from `),mK=n(XC,"CODE",{});var SBr=s(mK);Vho=r(SBr,"pretrained_model_name_or_path"),SBr.forEach(t),Xho=r(XC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gK=n(XC,"CODE",{});var PBr=s(gK);Who=r(PBr,"pretrained_model_name_or_path"),PBr.forEach(t),Qho=r(XC,":"),XC.forEach(t),Hho=i(wt),A=n(wt,"UL",{});var L=s(A);b_=n(L,"LI",{});var ETe=s(b_);hK=n(ETe,"STRONG",{});var $Br=s(hK);Uho=r($Br,"albert"),$Br.forEach(t),Jho=r(ETe," \u2014 "),DR=n(ETe,"A",{href:!0});var IBr=s(DR);Yho=r(IBr,"AlbertForSequenceClassification"),IBr.forEach(t),Kho=r(ETe," (ALBERT model)"),ETe.forEach(t),Zho=i(L),T_=n(L,"LI",{});var MTe=s(T_);uK=n(MTe,"STRONG",{});var jBr=s(uK);euo=r(jBr,"bart"),jBr.forEach(t),ouo=r(MTe," \u2014 "),qR=n(MTe,"A",{href:!0});var NBr=s(qR);ruo=r(NBr,"BartForSequenceClassification"),NBr.forEach(t),tuo=r(MTe," (BART model)"),MTe.forEach(t),auo=i(L),F_=n(L,"LI",{});var yTe=s(F_);pK=n(yTe,"STRONG",{});var DBr=s(pK);nuo=r(DBr,"bert"),DBr.forEach(t),suo=r(yTe," \u2014 "),OR=n(yTe,"A",{href:!0});var qBr=s(OR);luo=r(qBr,"BertForSequenceClassification"),qBr.forEach(t),iuo=r(yTe," (BERT model)"),yTe.forEach(t),duo=i(L),C_=n(L,"LI",{});var wTe=s(C_);_K=n(wTe,"STRONG",{});var OBr=s(_K);cuo=r(OBr,"big_bird"),OBr.forEach(t),fuo=r(wTe," \u2014 "),GR=n(wTe,"A",{href:!0});var GBr=s(GR);muo=r(GBr,"BigBirdForSequenceClassification"),GBr.forEach(t),guo=r(wTe," (BigBird model)"),wTe.forEach(t),huo=i(L),E_=n(L,"LI",{});var ATe=s(E_);vK=n(ATe,"STRONG",{});var zBr=s(vK);uuo=r(zBr,"bigbird_pegasus"),zBr.forEach(t),puo=r(ATe," \u2014 "),zR=n(ATe,"A",{href:!0});var VBr=s(zR);_uo=r(VBr,"BigBirdPegasusForSequenceClassification"),VBr.forEach(t),vuo=r(ATe," (BigBirdPegasus model)"),ATe.forEach(t),buo=i(L),M_=n(L,"LI",{});var LTe=s(M_);bK=n(LTe,"STRONG",{});var XBr=s(bK);Tuo=r(XBr,"camembert"),XBr.forEach(t),Fuo=r(LTe," \u2014 "),VR=n(LTe,"A",{href:!0});var WBr=s(VR);Cuo=r(WBr,"CamembertForSequenceClassification"),WBr.forEach(t),Euo=r(LTe," (CamemBERT model)"),LTe.forEach(t),Muo=i(L),y_=n(L,"LI",{});var BTe=s(y_);TK=n(BTe,"STRONG",{});var QBr=s(TK);yuo=r(QBr,"canine"),QBr.forEach(t),wuo=r(BTe," \u2014 "),XR=n(BTe,"A",{href:!0});var HBr=s(XR);Auo=r(HBr,"CanineForSequenceClassification"),HBr.forEach(t),Luo=r(BTe," (Canine model)"),BTe.forEach(t),Buo=i(L),w_=n(L,"LI",{});var kTe=s(w_);FK=n(kTe,"STRONG",{});var UBr=s(FK);kuo=r(UBr,"convbert"),UBr.forEach(t),xuo=r(kTe," \u2014 "),WR=n(kTe,"A",{href:!0});var JBr=s(WR);Ruo=r(JBr,"ConvBertForSequenceClassification"),JBr.forEach(t),Suo=r(kTe," (ConvBERT model)"),kTe.forEach(t),Puo=i(L),A_=n(L,"LI",{});var xTe=s(A_);CK=n(xTe,"STRONG",{});var YBr=s(CK);$uo=r(YBr,"ctrl"),YBr.forEach(t),Iuo=r(xTe," \u2014 "),QR=n(xTe,"A",{href:!0});var KBr=s(QR);juo=r(KBr,"CTRLForSequenceClassification"),KBr.forEach(t),Nuo=r(xTe," (CTRL model)"),xTe.forEach(t),Duo=i(L),L_=n(L,"LI",{});var RTe=s(L_);EK=n(RTe,"STRONG",{});var ZBr=s(EK);quo=r(ZBr,"deberta"),ZBr.forEach(t),Ouo=r(RTe," \u2014 "),HR=n(RTe,"A",{href:!0});var e9r=s(HR);Guo=r(e9r,"DebertaForSequenceClassification"),e9r.forEach(t),zuo=r(RTe," (DeBERTa model)"),RTe.forEach(t),Vuo=i(L),B_=n(L,"LI",{});var STe=s(B_);MK=n(STe,"STRONG",{});var o9r=s(MK);Xuo=r(o9r,"deberta-v2"),o9r.forEach(t),Wuo=r(STe," \u2014 "),UR=n(STe,"A",{href:!0});var r9r=s(UR);Quo=r(r9r,"DebertaV2ForSequenceClassification"),r9r.forEach(t),Huo=r(STe," (DeBERTa-v2 model)"),STe.forEach(t),Uuo=i(L),k_=n(L,"LI",{});var PTe=s(k_);yK=n(PTe,"STRONG",{});var t9r=s(yK);Juo=r(t9r,"distilbert"),t9r.forEach(t),Yuo=r(PTe," \u2014 "),JR=n(PTe,"A",{href:!0});var a9r=s(JR);Kuo=r(a9r,"DistilBertForSequenceClassification"),a9r.forEach(t),Zuo=r(PTe," (DistilBERT model)"),PTe.forEach(t),epo=i(L),x_=n(L,"LI",{});var $Te=s(x_);wK=n($Te,"STRONG",{});var n9r=s(wK);opo=r(n9r,"electra"),n9r.forEach(t),rpo=r($Te," \u2014 "),YR=n($Te,"A",{href:!0});var s9r=s(YR);tpo=r(s9r,"ElectraForSequenceClassification"),s9r.forEach(t),apo=r($Te," (ELECTRA model)"),$Te.forEach(t),npo=i(L),R_=n(L,"LI",{});var ITe=s(R_);AK=n(ITe,"STRONG",{});var l9r=s(AK);spo=r(l9r,"flaubert"),l9r.forEach(t),lpo=r(ITe," \u2014 "),KR=n(ITe,"A",{href:!0});var i9r=s(KR);ipo=r(i9r,"FlaubertForSequenceClassification"),i9r.forEach(t),dpo=r(ITe," (FlauBERT model)"),ITe.forEach(t),cpo=i(L),S_=n(L,"LI",{});var jTe=s(S_);LK=n(jTe,"STRONG",{});var d9r=s(LK);fpo=r(d9r,"fnet"),d9r.forEach(t),mpo=r(jTe," \u2014 "),ZR=n(jTe,"A",{href:!0});var c9r=s(ZR);gpo=r(c9r,"FNetForSequenceClassification"),c9r.forEach(t),hpo=r(jTe," (FNet model)"),jTe.forEach(t),upo=i(L),P_=n(L,"LI",{});var NTe=s(P_);BK=n(NTe,"STRONG",{});var f9r=s(BK);ppo=r(f9r,"funnel"),f9r.forEach(t),_po=r(NTe," \u2014 "),eS=n(NTe,"A",{href:!0});var m9r=s(eS);vpo=r(m9r,"FunnelForSequenceClassification"),m9r.forEach(t),bpo=r(NTe," (Funnel Transformer model)"),NTe.forEach(t),Tpo=i(L),$_=n(L,"LI",{});var DTe=s($_);kK=n(DTe,"STRONG",{});var g9r=s(kK);Fpo=r(g9r,"gpt2"),g9r.forEach(t),Cpo=r(DTe," \u2014 "),oS=n(DTe,"A",{href:!0});var h9r=s(oS);Epo=r(h9r,"GPT2ForSequenceClassification"),h9r.forEach(t),Mpo=r(DTe," (OpenAI GPT-2 model)"),DTe.forEach(t),ypo=i(L),I_=n(L,"LI",{});var qTe=s(I_);xK=n(qTe,"STRONG",{});var u9r=s(xK);wpo=r(u9r,"gpt_neo"),u9r.forEach(t),Apo=r(qTe," \u2014 "),rS=n(qTe,"A",{href:!0});var p9r=s(rS);Lpo=r(p9r,"GPTNeoForSequenceClassification"),p9r.forEach(t),Bpo=r(qTe," (GPT Neo model)"),qTe.forEach(t),kpo=i(L),j_=n(L,"LI",{});var OTe=s(j_);RK=n(OTe,"STRONG",{});var _9r=s(RK);xpo=r(_9r,"gptj"),_9r.forEach(t),Rpo=r(OTe," \u2014 "),tS=n(OTe,"A",{href:!0});var v9r=s(tS);Spo=r(v9r,"GPTJForSequenceClassification"),v9r.forEach(t),Ppo=r(OTe," (GPT-J model)"),OTe.forEach(t),$po=i(L),N_=n(L,"LI",{});var GTe=s(N_);SK=n(GTe,"STRONG",{});var b9r=s(SK);Ipo=r(b9r,"ibert"),b9r.forEach(t),jpo=r(GTe," \u2014 "),aS=n(GTe,"A",{href:!0});var T9r=s(aS);Npo=r(T9r,"IBertForSequenceClassification"),T9r.forEach(t),Dpo=r(GTe," (I-BERT model)"),GTe.forEach(t),qpo=i(L),D_=n(L,"LI",{});var zTe=s(D_);PK=n(zTe,"STRONG",{});var F9r=s(PK);Opo=r(F9r,"layoutlm"),F9r.forEach(t),Gpo=r(zTe," \u2014 "),nS=n(zTe,"A",{href:!0});var C9r=s(nS);zpo=r(C9r,"LayoutLMForSequenceClassification"),C9r.forEach(t),Vpo=r(zTe," (LayoutLM model)"),zTe.forEach(t),Xpo=i(L),q_=n(L,"LI",{});var VTe=s(q_);$K=n(VTe,"STRONG",{});var E9r=s($K);Wpo=r(E9r,"layoutlmv2"),E9r.forEach(t),Qpo=r(VTe," \u2014 "),sS=n(VTe,"A",{href:!0});var M9r=s(sS);Hpo=r(M9r,"LayoutLMv2ForSequenceClassification"),M9r.forEach(t),Upo=r(VTe," (LayoutLMv2 model)"),VTe.forEach(t),Jpo=i(L),O_=n(L,"LI",{});var XTe=s(O_);IK=n(XTe,"STRONG",{});var y9r=s(IK);Ypo=r(y9r,"led"),y9r.forEach(t),Kpo=r(XTe," \u2014 "),lS=n(XTe,"A",{href:!0});var w9r=s(lS);Zpo=r(w9r,"LEDForSequenceClassification"),w9r.forEach(t),e_o=r(XTe," (LED model)"),XTe.forEach(t),o_o=i(L),G_=n(L,"LI",{});var WTe=s(G_);jK=n(WTe,"STRONG",{});var A9r=s(jK);r_o=r(A9r,"longformer"),A9r.forEach(t),t_o=r(WTe," \u2014 "),iS=n(WTe,"A",{href:!0});var L9r=s(iS);a_o=r(L9r,"LongformerForSequenceClassification"),L9r.forEach(t),n_o=r(WTe," (Longformer model)"),WTe.forEach(t),s_o=i(L),z_=n(L,"LI",{});var QTe=s(z_);NK=n(QTe,"STRONG",{});var B9r=s(NK);l_o=r(B9r,"mbart"),B9r.forEach(t),i_o=r(QTe," \u2014 "),dS=n(QTe,"A",{href:!0});var k9r=s(dS);d_o=r(k9r,"MBartForSequenceClassification"),k9r.forEach(t),c_o=r(QTe," (mBART model)"),QTe.forEach(t),f_o=i(L),V_=n(L,"LI",{});var HTe=s(V_);DK=n(HTe,"STRONG",{});var x9r=s(DK);m_o=r(x9r,"megatron-bert"),x9r.forEach(t),g_o=r(HTe," \u2014 "),cS=n(HTe,"A",{href:!0});var R9r=s(cS);h_o=r(R9r,"MegatronBertForSequenceClassification"),R9r.forEach(t),u_o=r(HTe," (MegatronBert model)"),HTe.forEach(t),p_o=i(L),X_=n(L,"LI",{});var UTe=s(X_);qK=n(UTe,"STRONG",{});var S9r=s(qK);__o=r(S9r,"mobilebert"),S9r.forEach(t),v_o=r(UTe," \u2014 "),fS=n(UTe,"A",{href:!0});var P9r=s(fS);b_o=r(P9r,"MobileBertForSequenceClassification"),P9r.forEach(t),T_o=r(UTe," (MobileBERT model)"),UTe.forEach(t),F_o=i(L),W_=n(L,"LI",{});var JTe=s(W_);OK=n(JTe,"STRONG",{});var $9r=s(OK);C_o=r($9r,"mpnet"),$9r.forEach(t),E_o=r(JTe," \u2014 "),mS=n(JTe,"A",{href:!0});var I9r=s(mS);M_o=r(I9r,"MPNetForSequenceClassification"),I9r.forEach(t),y_o=r(JTe," (MPNet model)"),JTe.forEach(t),w_o=i(L),Q_=n(L,"LI",{});var YTe=s(Q_);GK=n(YTe,"STRONG",{});var j9r=s(GK);A_o=r(j9r,"nystromformer"),j9r.forEach(t),L_o=r(YTe," \u2014 "),gS=n(YTe,"A",{href:!0});var N9r=s(gS);B_o=r(N9r,"NystromformerForSequenceClassification"),N9r.forEach(t),k_o=r(YTe," (Nystromformer model)"),YTe.forEach(t),x_o=i(L),H_=n(L,"LI",{});var KTe=s(H_);zK=n(KTe,"STRONG",{});var D9r=s(zK);R_o=r(D9r,"openai-gpt"),D9r.forEach(t),S_o=r(KTe," \u2014 "),hS=n(KTe,"A",{href:!0});var q9r=s(hS);P_o=r(q9r,"OpenAIGPTForSequenceClassification"),q9r.forEach(t),$_o=r(KTe," (OpenAI GPT model)"),KTe.forEach(t),I_o=i(L),U_=n(L,"LI",{});var ZTe=s(U_);VK=n(ZTe,"STRONG",{});var O9r=s(VK);j_o=r(O9r,"perceiver"),O9r.forEach(t),N_o=r(ZTe," \u2014 "),uS=n(ZTe,"A",{href:!0});var G9r=s(uS);D_o=r(G9r,"PerceiverForSequenceClassification"),G9r.forEach(t),q_o=r(ZTe," (Perceiver model)"),ZTe.forEach(t),O_o=i(L),J_=n(L,"LI",{});var e6e=s(J_);XK=n(e6e,"STRONG",{});var z9r=s(XK);G_o=r(z9r,"qdqbert"),z9r.forEach(t),z_o=r(e6e," \u2014 "),pS=n(e6e,"A",{href:!0});var V9r=s(pS);V_o=r(V9r,"QDQBertForSequenceClassification"),V9r.forEach(t),X_o=r(e6e," (QDQBert model)"),e6e.forEach(t),W_o=i(L),Y_=n(L,"LI",{});var o6e=s(Y_);WK=n(o6e,"STRONG",{});var X9r=s(WK);Q_o=r(X9r,"reformer"),X9r.forEach(t),H_o=r(o6e," \u2014 "),_S=n(o6e,"A",{href:!0});var W9r=s(_S);U_o=r(W9r,"ReformerForSequenceClassification"),W9r.forEach(t),J_o=r(o6e," (Reformer model)"),o6e.forEach(t),Y_o=i(L),K_=n(L,"LI",{});var r6e=s(K_);QK=n(r6e,"STRONG",{});var Q9r=s(QK);K_o=r(Q9r,"rembert"),Q9r.forEach(t),Z_o=r(r6e," \u2014 "),vS=n(r6e,"A",{href:!0});var H9r=s(vS);e2o=r(H9r,"RemBertForSequenceClassification"),H9r.forEach(t),o2o=r(r6e," (RemBERT model)"),r6e.forEach(t),r2o=i(L),Z_=n(L,"LI",{});var t6e=s(Z_);HK=n(t6e,"STRONG",{});var U9r=s(HK);t2o=r(U9r,"roberta"),U9r.forEach(t),a2o=r(t6e," \u2014 "),bS=n(t6e,"A",{href:!0});var J9r=s(bS);n2o=r(J9r,"RobertaForSequenceClassification"),J9r.forEach(t),s2o=r(t6e," (RoBERTa model)"),t6e.forEach(t),l2o=i(L),e2=n(L,"LI",{});var a6e=s(e2);UK=n(a6e,"STRONG",{});var Y9r=s(UK);i2o=r(Y9r,"roformer"),Y9r.forEach(t),d2o=r(a6e," \u2014 "),TS=n(a6e,"A",{href:!0});var K9r=s(TS);c2o=r(K9r,"RoFormerForSequenceClassification"),K9r.forEach(t),f2o=r(a6e," (RoFormer model)"),a6e.forEach(t),m2o=i(L),o2=n(L,"LI",{});var n6e=s(o2);JK=n(n6e,"STRONG",{});var Z9r=s(JK);g2o=r(Z9r,"squeezebert"),Z9r.forEach(t),h2o=r(n6e," \u2014 "),FS=n(n6e,"A",{href:!0});var ekr=s(FS);u2o=r(ekr,"SqueezeBertForSequenceClassification"),ekr.forEach(t),p2o=r(n6e," (SqueezeBERT model)"),n6e.forEach(t),_2o=i(L),r2=n(L,"LI",{});var s6e=s(r2);YK=n(s6e,"STRONG",{});var okr=s(YK);v2o=r(okr,"tapas"),okr.forEach(t),b2o=r(s6e," \u2014 "),CS=n(s6e,"A",{href:!0});var rkr=s(CS);T2o=r(rkr,"TapasForSequenceClassification"),rkr.forEach(t),F2o=r(s6e," (TAPAS model)"),s6e.forEach(t),C2o=i(L),t2=n(L,"LI",{});var l6e=s(t2);KK=n(l6e,"STRONG",{});var tkr=s(KK);E2o=r(tkr,"transfo-xl"),tkr.forEach(t),M2o=r(l6e," \u2014 "),ES=n(l6e,"A",{href:!0});var akr=s(ES);y2o=r(akr,"TransfoXLForSequenceClassification"),akr.forEach(t),w2o=r(l6e," (Transformer-XL model)"),l6e.forEach(t),A2o=i(L),a2=n(L,"LI",{});var i6e=s(a2);ZK=n(i6e,"STRONG",{});var nkr=s(ZK);L2o=r(nkr,"xlm"),nkr.forEach(t),B2o=r(i6e," \u2014 "),MS=n(i6e,"A",{href:!0});var skr=s(MS);k2o=r(skr,"XLMForSequenceClassification"),skr.forEach(t),x2o=r(i6e," (XLM model)"),i6e.forEach(t),R2o=i(L),n2=n(L,"LI",{});var d6e=s(n2);eZ=n(d6e,"STRONG",{});var lkr=s(eZ);S2o=r(lkr,"xlm-roberta"),lkr.forEach(t),P2o=r(d6e," \u2014 "),yS=n(d6e,"A",{href:!0});var ikr=s(yS);$2o=r(ikr,"XLMRobertaForSequenceClassification"),ikr.forEach(t),I2o=r(d6e," (XLM-RoBERTa model)"),d6e.forEach(t),j2o=i(L),s2=n(L,"LI",{});var c6e=s(s2);oZ=n(c6e,"STRONG",{});var dkr=s(oZ);N2o=r(dkr,"xlnet"),dkr.forEach(t),D2o=r(c6e," \u2014 "),wS=n(c6e,"A",{href:!0});var ckr=s(wS);q2o=r(ckr,"XLNetForSequenceClassification"),ckr.forEach(t),O2o=r(c6e," (XLNet model)"),c6e.forEach(t),G2o=i(L),l2=n(L,"LI",{});var f6e=s(l2);rZ=n(f6e,"STRONG",{});var fkr=s(rZ);z2o=r(fkr,"yoso"),fkr.forEach(t),V2o=r(f6e," \u2014 "),AS=n(f6e,"A",{href:!0});var mkr=s(AS);X2o=r(mkr,"YosoForSequenceClassification"),mkr.forEach(t),W2o=r(f6e," (YOSO model)"),f6e.forEach(t),L.forEach(t),Q2o=i(wt),i2=n(wt,"P",{});var m6e=s(i2);H2o=r(m6e,"The model is set in evaluation mode by default using "),tZ=n(m6e,"CODE",{});var gkr=s(tZ);U2o=r(gkr,"model.eval()"),gkr.forEach(t),J2o=r(m6e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),aZ=n(m6e,"CODE",{});var hkr=s(aZ);Y2o=r(hkr,"model.train()"),hkr.forEach(t),m6e.forEach(t),K2o=i(wt),nZ=n(wt,"P",{});var ukr=s(nZ);Z2o=r(ukr,"Examples:"),ukr.forEach(t),evo=i(wt),m(UM.$$.fragment,wt),wt.forEach(t),Bs.forEach(t),wwe=i(d),Si=n(d,"H2",{class:!0});var y0e=s(Si);d2=n(y0e,"A",{id:!0,class:!0,href:!0});var pkr=s(d2);sZ=n(pkr,"SPAN",{});var _kr=s(sZ);m(JM.$$.fragment,_kr),_kr.forEach(t),pkr.forEach(t),ovo=i(y0e),lZ=n(y0e,"SPAN",{});var vkr=s(lZ);rvo=r(vkr,"AutoModelForMultipleChoice"),vkr.forEach(t),y0e.forEach(t),Awe=i(d),Xo=n(d,"DIV",{class:!0});var xs=s(Xo);m(YM.$$.fragment,xs),tvo=i(xs),Pi=n(xs,"P",{});var MO=s(Pi);avo=r(MO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),iZ=n(MO,"CODE",{});var bkr=s(iZ);nvo=r(bkr,"from_pretrained()"),bkr.forEach(t),svo=r(MO,"class method or the "),dZ=n(MO,"CODE",{});var Tkr=s(dZ);lvo=r(Tkr,"from_config()"),Tkr.forEach(t),ivo=r(MO,`class
method.`),MO.forEach(t),dvo=i(xs),KM=n(xs,"P",{});var w0e=s(KM);cvo=r(w0e,"This class cannot be instantiated directly using "),cZ=n(w0e,"CODE",{});var Fkr=s(cZ);fvo=r(Fkr,"__init__()"),Fkr.forEach(t),mvo=r(w0e," (throws an error)."),w0e.forEach(t),gvo=i(xs),$r=n(xs,"DIV",{class:!0});var Rs=s($r);m(ZM.$$.fragment,Rs),hvo=i(Rs),fZ=n(Rs,"P",{});var Ckr=s(fZ);uvo=r(Ckr,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Ckr.forEach(t),pvo=i(Rs),$i=n(Rs,"P",{});var yO=s($i);_vo=r(yO,`Note:
Loading a model from its configuration file does `),mZ=n(yO,"STRONG",{});var Ekr=s(mZ);vvo=r(Ekr,"not"),Ekr.forEach(t),bvo=r(yO,` load the model weights. It only affects the
model\u2019s configuration. Use `),gZ=n(yO,"CODE",{});var Mkr=s(gZ);Tvo=r(Mkr,"from_pretrained()"),Mkr.forEach(t),Fvo=r(yO,"to load the model weights."),yO.forEach(t),Cvo=i(Rs),hZ=n(Rs,"P",{});var ykr=s(hZ);Evo=r(ykr,"Examples:"),ykr.forEach(t),Mvo=i(Rs),m(e3.$$.fragment,Rs),Rs.forEach(t),yvo=i(xs),$e=n(xs,"DIV",{class:!0});var At=s($e);m(o3.$$.fragment,At),wvo=i(At),uZ=n(At,"P",{});var wkr=s(uZ);Avo=r(wkr,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),wkr.forEach(t),Lvo=i(At),Sa=n(At,"P",{});var WC=s(Sa);Bvo=r(WC,"The model class to instantiate is selected based on the "),pZ=n(WC,"CODE",{});var Akr=s(pZ);kvo=r(Akr,"model_type"),Akr.forEach(t),xvo=r(WC,` property of the config object (either
passed as an argument or loaded from `),_Z=n(WC,"CODE",{});var Lkr=s(_Z);Rvo=r(Lkr,"pretrained_model_name_or_path"),Lkr.forEach(t),Svo=r(WC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vZ=n(WC,"CODE",{});var Bkr=s(vZ);Pvo=r(Bkr,"pretrained_model_name_or_path"),Bkr.forEach(t),$vo=r(WC,":"),WC.forEach(t),Ivo=i(At),O=n(At,"UL",{});var z=s(O);c2=n(z,"LI",{});var g6e=s(c2);bZ=n(g6e,"STRONG",{});var kkr=s(bZ);jvo=r(kkr,"albert"),kkr.forEach(t),Nvo=r(g6e," \u2014 "),LS=n(g6e,"A",{href:!0});var xkr=s(LS);Dvo=r(xkr,"AlbertForMultipleChoice"),xkr.forEach(t),qvo=r(g6e," (ALBERT model)"),g6e.forEach(t),Ovo=i(z),f2=n(z,"LI",{});var h6e=s(f2);TZ=n(h6e,"STRONG",{});var Rkr=s(TZ);Gvo=r(Rkr,"bert"),Rkr.forEach(t),zvo=r(h6e," \u2014 "),BS=n(h6e,"A",{href:!0});var Skr=s(BS);Vvo=r(Skr,"BertForMultipleChoice"),Skr.forEach(t),Xvo=r(h6e," (BERT model)"),h6e.forEach(t),Wvo=i(z),m2=n(z,"LI",{});var u6e=s(m2);FZ=n(u6e,"STRONG",{});var Pkr=s(FZ);Qvo=r(Pkr,"big_bird"),Pkr.forEach(t),Hvo=r(u6e," \u2014 "),kS=n(u6e,"A",{href:!0});var $kr=s(kS);Uvo=r($kr,"BigBirdForMultipleChoice"),$kr.forEach(t),Jvo=r(u6e," (BigBird model)"),u6e.forEach(t),Yvo=i(z),g2=n(z,"LI",{});var p6e=s(g2);CZ=n(p6e,"STRONG",{});var Ikr=s(CZ);Kvo=r(Ikr,"camembert"),Ikr.forEach(t),Zvo=r(p6e," \u2014 "),xS=n(p6e,"A",{href:!0});var jkr=s(xS);e1o=r(jkr,"CamembertForMultipleChoice"),jkr.forEach(t),o1o=r(p6e," (CamemBERT model)"),p6e.forEach(t),r1o=i(z),h2=n(z,"LI",{});var _6e=s(h2);EZ=n(_6e,"STRONG",{});var Nkr=s(EZ);t1o=r(Nkr,"canine"),Nkr.forEach(t),a1o=r(_6e," \u2014 "),RS=n(_6e,"A",{href:!0});var Dkr=s(RS);n1o=r(Dkr,"CanineForMultipleChoice"),Dkr.forEach(t),s1o=r(_6e," (Canine model)"),_6e.forEach(t),l1o=i(z),u2=n(z,"LI",{});var v6e=s(u2);MZ=n(v6e,"STRONG",{});var qkr=s(MZ);i1o=r(qkr,"convbert"),qkr.forEach(t),d1o=r(v6e," \u2014 "),SS=n(v6e,"A",{href:!0});var Okr=s(SS);c1o=r(Okr,"ConvBertForMultipleChoice"),Okr.forEach(t),f1o=r(v6e," (ConvBERT model)"),v6e.forEach(t),m1o=i(z),p2=n(z,"LI",{});var b6e=s(p2);yZ=n(b6e,"STRONG",{});var Gkr=s(yZ);g1o=r(Gkr,"distilbert"),Gkr.forEach(t),h1o=r(b6e," \u2014 "),PS=n(b6e,"A",{href:!0});var zkr=s(PS);u1o=r(zkr,"DistilBertForMultipleChoice"),zkr.forEach(t),p1o=r(b6e," (DistilBERT model)"),b6e.forEach(t),_1o=i(z),_2=n(z,"LI",{});var T6e=s(_2);wZ=n(T6e,"STRONG",{});var Vkr=s(wZ);v1o=r(Vkr,"electra"),Vkr.forEach(t),b1o=r(T6e," \u2014 "),$S=n(T6e,"A",{href:!0});var Xkr=s($S);T1o=r(Xkr,"ElectraForMultipleChoice"),Xkr.forEach(t),F1o=r(T6e," (ELECTRA model)"),T6e.forEach(t),C1o=i(z),v2=n(z,"LI",{});var F6e=s(v2);AZ=n(F6e,"STRONG",{});var Wkr=s(AZ);E1o=r(Wkr,"flaubert"),Wkr.forEach(t),M1o=r(F6e," \u2014 "),IS=n(F6e,"A",{href:!0});var Qkr=s(IS);y1o=r(Qkr,"FlaubertForMultipleChoice"),Qkr.forEach(t),w1o=r(F6e," (FlauBERT model)"),F6e.forEach(t),A1o=i(z),b2=n(z,"LI",{});var C6e=s(b2);LZ=n(C6e,"STRONG",{});var Hkr=s(LZ);L1o=r(Hkr,"fnet"),Hkr.forEach(t),B1o=r(C6e," \u2014 "),jS=n(C6e,"A",{href:!0});var Ukr=s(jS);k1o=r(Ukr,"FNetForMultipleChoice"),Ukr.forEach(t),x1o=r(C6e," (FNet model)"),C6e.forEach(t),R1o=i(z),T2=n(z,"LI",{});var E6e=s(T2);BZ=n(E6e,"STRONG",{});var Jkr=s(BZ);S1o=r(Jkr,"funnel"),Jkr.forEach(t),P1o=r(E6e," \u2014 "),NS=n(E6e,"A",{href:!0});var Ykr=s(NS);$1o=r(Ykr,"FunnelForMultipleChoice"),Ykr.forEach(t),I1o=r(E6e," (Funnel Transformer model)"),E6e.forEach(t),j1o=i(z),F2=n(z,"LI",{});var M6e=s(F2);kZ=n(M6e,"STRONG",{});var Kkr=s(kZ);N1o=r(Kkr,"ibert"),Kkr.forEach(t),D1o=r(M6e," \u2014 "),DS=n(M6e,"A",{href:!0});var Zkr=s(DS);q1o=r(Zkr,"IBertForMultipleChoice"),Zkr.forEach(t),O1o=r(M6e," (I-BERT model)"),M6e.forEach(t),G1o=i(z),C2=n(z,"LI",{});var y6e=s(C2);xZ=n(y6e,"STRONG",{});var exr=s(xZ);z1o=r(exr,"longformer"),exr.forEach(t),V1o=r(y6e," \u2014 "),qS=n(y6e,"A",{href:!0});var oxr=s(qS);X1o=r(oxr,"LongformerForMultipleChoice"),oxr.forEach(t),W1o=r(y6e," (Longformer model)"),y6e.forEach(t),Q1o=i(z),E2=n(z,"LI",{});var w6e=s(E2);RZ=n(w6e,"STRONG",{});var rxr=s(RZ);H1o=r(rxr,"megatron-bert"),rxr.forEach(t),U1o=r(w6e," \u2014 "),OS=n(w6e,"A",{href:!0});var txr=s(OS);J1o=r(txr,"MegatronBertForMultipleChoice"),txr.forEach(t),Y1o=r(w6e," (MegatronBert model)"),w6e.forEach(t),K1o=i(z),M2=n(z,"LI",{});var A6e=s(M2);SZ=n(A6e,"STRONG",{});var axr=s(SZ);Z1o=r(axr,"mobilebert"),axr.forEach(t),e4o=r(A6e," \u2014 "),GS=n(A6e,"A",{href:!0});var nxr=s(GS);o4o=r(nxr,"MobileBertForMultipleChoice"),nxr.forEach(t),r4o=r(A6e," (MobileBERT model)"),A6e.forEach(t),t4o=i(z),y2=n(z,"LI",{});var L6e=s(y2);PZ=n(L6e,"STRONG",{});var sxr=s(PZ);a4o=r(sxr,"mpnet"),sxr.forEach(t),n4o=r(L6e," \u2014 "),zS=n(L6e,"A",{href:!0});var lxr=s(zS);s4o=r(lxr,"MPNetForMultipleChoice"),lxr.forEach(t),l4o=r(L6e," (MPNet model)"),L6e.forEach(t),i4o=i(z),w2=n(z,"LI",{});var B6e=s(w2);$Z=n(B6e,"STRONG",{});var ixr=s($Z);d4o=r(ixr,"nystromformer"),ixr.forEach(t),c4o=r(B6e," \u2014 "),VS=n(B6e,"A",{href:!0});var dxr=s(VS);f4o=r(dxr,"NystromformerForMultipleChoice"),dxr.forEach(t),m4o=r(B6e," (Nystromformer model)"),B6e.forEach(t),g4o=i(z),A2=n(z,"LI",{});var k6e=s(A2);IZ=n(k6e,"STRONG",{});var cxr=s(IZ);h4o=r(cxr,"qdqbert"),cxr.forEach(t),u4o=r(k6e," \u2014 "),XS=n(k6e,"A",{href:!0});var fxr=s(XS);p4o=r(fxr,"QDQBertForMultipleChoice"),fxr.forEach(t),_4o=r(k6e," (QDQBert model)"),k6e.forEach(t),v4o=i(z),L2=n(z,"LI",{});var x6e=s(L2);jZ=n(x6e,"STRONG",{});var mxr=s(jZ);b4o=r(mxr,"rembert"),mxr.forEach(t),T4o=r(x6e," \u2014 "),WS=n(x6e,"A",{href:!0});var gxr=s(WS);F4o=r(gxr,"RemBertForMultipleChoice"),gxr.forEach(t),C4o=r(x6e," (RemBERT model)"),x6e.forEach(t),E4o=i(z),B2=n(z,"LI",{});var R6e=s(B2);NZ=n(R6e,"STRONG",{});var hxr=s(NZ);M4o=r(hxr,"roberta"),hxr.forEach(t),y4o=r(R6e," \u2014 "),QS=n(R6e,"A",{href:!0});var uxr=s(QS);w4o=r(uxr,"RobertaForMultipleChoice"),uxr.forEach(t),A4o=r(R6e," (RoBERTa model)"),R6e.forEach(t),L4o=i(z),k2=n(z,"LI",{});var S6e=s(k2);DZ=n(S6e,"STRONG",{});var pxr=s(DZ);B4o=r(pxr,"roformer"),pxr.forEach(t),k4o=r(S6e," \u2014 "),HS=n(S6e,"A",{href:!0});var _xr=s(HS);x4o=r(_xr,"RoFormerForMultipleChoice"),_xr.forEach(t),R4o=r(S6e," (RoFormer model)"),S6e.forEach(t),S4o=i(z),x2=n(z,"LI",{});var P6e=s(x2);qZ=n(P6e,"STRONG",{});var vxr=s(qZ);P4o=r(vxr,"squeezebert"),vxr.forEach(t),$4o=r(P6e," \u2014 "),US=n(P6e,"A",{href:!0});var bxr=s(US);I4o=r(bxr,"SqueezeBertForMultipleChoice"),bxr.forEach(t),j4o=r(P6e," (SqueezeBERT model)"),P6e.forEach(t),N4o=i(z),R2=n(z,"LI",{});var $6e=s(R2);OZ=n($6e,"STRONG",{});var Txr=s(OZ);D4o=r(Txr,"xlm"),Txr.forEach(t),q4o=r($6e," \u2014 "),JS=n($6e,"A",{href:!0});var Fxr=s(JS);O4o=r(Fxr,"XLMForMultipleChoice"),Fxr.forEach(t),G4o=r($6e," (XLM model)"),$6e.forEach(t),z4o=i(z),S2=n(z,"LI",{});var I6e=s(S2);GZ=n(I6e,"STRONG",{});var Cxr=s(GZ);V4o=r(Cxr,"xlm-roberta"),Cxr.forEach(t),X4o=r(I6e," \u2014 "),YS=n(I6e,"A",{href:!0});var Exr=s(YS);W4o=r(Exr,"XLMRobertaForMultipleChoice"),Exr.forEach(t),Q4o=r(I6e," (XLM-RoBERTa model)"),I6e.forEach(t),H4o=i(z),P2=n(z,"LI",{});var j6e=s(P2);zZ=n(j6e,"STRONG",{});var Mxr=s(zZ);U4o=r(Mxr,"xlnet"),Mxr.forEach(t),J4o=r(j6e," \u2014 "),KS=n(j6e,"A",{href:!0});var yxr=s(KS);Y4o=r(yxr,"XLNetForMultipleChoice"),yxr.forEach(t),K4o=r(j6e," (XLNet model)"),j6e.forEach(t),Z4o=i(z),$2=n(z,"LI",{});var N6e=s($2);VZ=n(N6e,"STRONG",{});var wxr=s(VZ);ebo=r(wxr,"yoso"),wxr.forEach(t),obo=r(N6e," \u2014 "),ZS=n(N6e,"A",{href:!0});var Axr=s(ZS);rbo=r(Axr,"YosoForMultipleChoice"),Axr.forEach(t),tbo=r(N6e," (YOSO model)"),N6e.forEach(t),z.forEach(t),abo=i(At),I2=n(At,"P",{});var D6e=s(I2);nbo=r(D6e,"The model is set in evaluation mode by default using "),XZ=n(D6e,"CODE",{});var Lxr=s(XZ);sbo=r(Lxr,"model.eval()"),Lxr.forEach(t),lbo=r(D6e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),WZ=n(D6e,"CODE",{});var Bxr=s(WZ);ibo=r(Bxr,"model.train()"),Bxr.forEach(t),D6e.forEach(t),dbo=i(At),QZ=n(At,"P",{});var kxr=s(QZ);cbo=r(kxr,"Examples:"),kxr.forEach(t),fbo=i(At),m(r3.$$.fragment,At),At.forEach(t),xs.forEach(t),Lwe=i(d),Ii=n(d,"H2",{class:!0});var A0e=s(Ii);j2=n(A0e,"A",{id:!0,class:!0,href:!0});var xxr=s(j2);HZ=n(xxr,"SPAN",{});var Rxr=s(HZ);m(t3.$$.fragment,Rxr),Rxr.forEach(t),xxr.forEach(t),mbo=i(A0e),UZ=n(A0e,"SPAN",{});var Sxr=s(UZ);gbo=r(Sxr,"AutoModelForNextSentencePrediction"),Sxr.forEach(t),A0e.forEach(t),Bwe=i(d),Wo=n(d,"DIV",{class:!0});var Ss=s(Wo);m(a3.$$.fragment,Ss),hbo=i(Ss),ji=n(Ss,"P",{});var wO=s(ji);ubo=r(wO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),JZ=n(wO,"CODE",{});var Pxr=s(JZ);pbo=r(Pxr,"from_pretrained()"),Pxr.forEach(t),_bo=r(wO,"class method or the "),YZ=n(wO,"CODE",{});var $xr=s(YZ);vbo=r($xr,"from_config()"),$xr.forEach(t),bbo=r(wO,`class
method.`),wO.forEach(t),Tbo=i(Ss),n3=n(Ss,"P",{});var L0e=s(n3);Fbo=r(L0e,"This class cannot be instantiated directly using "),KZ=n(L0e,"CODE",{});var Ixr=s(KZ);Cbo=r(Ixr,"__init__()"),Ixr.forEach(t),Ebo=r(L0e," (throws an error)."),L0e.forEach(t),Mbo=i(Ss),Ir=n(Ss,"DIV",{class:!0});var Ps=s(Ir);m(s3.$$.fragment,Ps),ybo=i(Ps),ZZ=n(Ps,"P",{});var jxr=s(ZZ);wbo=r(jxr,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),jxr.forEach(t),Abo=i(Ps),Ni=n(Ps,"P",{});var AO=s(Ni);Lbo=r(AO,`Note:
Loading a model from its configuration file does `),eee=n(AO,"STRONG",{});var Nxr=s(eee);Bbo=r(Nxr,"not"),Nxr.forEach(t),kbo=r(AO,` load the model weights. It only affects the
model\u2019s configuration. Use `),oee=n(AO,"CODE",{});var Dxr=s(oee);xbo=r(Dxr,"from_pretrained()"),Dxr.forEach(t),Rbo=r(AO,"to load the model weights."),AO.forEach(t),Sbo=i(Ps),ree=n(Ps,"P",{});var qxr=s(ree);Pbo=r(qxr,"Examples:"),qxr.forEach(t),$bo=i(Ps),m(l3.$$.fragment,Ps),Ps.forEach(t),Ibo=i(Ss),Ie=n(Ss,"DIV",{class:!0});var Lt=s(Ie);m(i3.$$.fragment,Lt),jbo=i(Lt),tee=n(Lt,"P",{});var Oxr=s(tee);Nbo=r(Oxr,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Oxr.forEach(t),Dbo=i(Lt),Pa=n(Lt,"P",{});var QC=s(Pa);qbo=r(QC,"The model class to instantiate is selected based on the "),aee=n(QC,"CODE",{});var Gxr=s(aee);Obo=r(Gxr,"model_type"),Gxr.forEach(t),Gbo=r(QC,` property of the config object (either
passed as an argument or loaded from `),nee=n(QC,"CODE",{});var zxr=s(nee);zbo=r(zxr,"pretrained_model_name_or_path"),zxr.forEach(t),Vbo=r(QC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),see=n(QC,"CODE",{});var Vxr=s(see);Xbo=r(Vxr,"pretrained_model_name_or_path"),Vxr.forEach(t),Wbo=r(QC,":"),QC.forEach(t),Qbo=i(Lt),Ht=n(Lt,"UL",{});var $s=s(Ht);N2=n($s,"LI",{});var q6e=s(N2);lee=n(q6e,"STRONG",{});var Xxr=s(lee);Hbo=r(Xxr,"bert"),Xxr.forEach(t),Ubo=r(q6e," \u2014 "),eP=n(q6e,"A",{href:!0});var Wxr=s(eP);Jbo=r(Wxr,"BertForNextSentencePrediction"),Wxr.forEach(t),Ybo=r(q6e," (BERT model)"),q6e.forEach(t),Kbo=i($s),D2=n($s,"LI",{});var O6e=s(D2);iee=n(O6e,"STRONG",{});var Qxr=s(iee);Zbo=r(Qxr,"fnet"),Qxr.forEach(t),eTo=r(O6e," \u2014 "),oP=n(O6e,"A",{href:!0});var Hxr=s(oP);oTo=r(Hxr,"FNetForNextSentencePrediction"),Hxr.forEach(t),rTo=r(O6e," (FNet model)"),O6e.forEach(t),tTo=i($s),q2=n($s,"LI",{});var G6e=s(q2);dee=n(G6e,"STRONG",{});var Uxr=s(dee);aTo=r(Uxr,"megatron-bert"),Uxr.forEach(t),nTo=r(G6e," \u2014 "),rP=n(G6e,"A",{href:!0});var Jxr=s(rP);sTo=r(Jxr,"MegatronBertForNextSentencePrediction"),Jxr.forEach(t),lTo=r(G6e," (MegatronBert model)"),G6e.forEach(t),iTo=i($s),O2=n($s,"LI",{});var z6e=s(O2);cee=n(z6e,"STRONG",{});var Yxr=s(cee);dTo=r(Yxr,"mobilebert"),Yxr.forEach(t),cTo=r(z6e," \u2014 "),tP=n(z6e,"A",{href:!0});var Kxr=s(tP);fTo=r(Kxr,"MobileBertForNextSentencePrediction"),Kxr.forEach(t),mTo=r(z6e," (MobileBERT model)"),z6e.forEach(t),gTo=i($s),G2=n($s,"LI",{});var V6e=s(G2);fee=n(V6e,"STRONG",{});var Zxr=s(fee);hTo=r(Zxr,"qdqbert"),Zxr.forEach(t),uTo=r(V6e," \u2014 "),aP=n(V6e,"A",{href:!0});var eRr=s(aP);pTo=r(eRr,"QDQBertForNextSentencePrediction"),eRr.forEach(t),_To=r(V6e," (QDQBert model)"),V6e.forEach(t),$s.forEach(t),vTo=i(Lt),z2=n(Lt,"P",{});var X6e=s(z2);bTo=r(X6e,"The model is set in evaluation mode by default using "),mee=n(X6e,"CODE",{});var oRr=s(mee);TTo=r(oRr,"model.eval()"),oRr.forEach(t),FTo=r(X6e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gee=n(X6e,"CODE",{});var rRr=s(gee);CTo=r(rRr,"model.train()"),rRr.forEach(t),X6e.forEach(t),ETo=i(Lt),hee=n(Lt,"P",{});var tRr=s(hee);MTo=r(tRr,"Examples:"),tRr.forEach(t),yTo=i(Lt),m(d3.$$.fragment,Lt),Lt.forEach(t),Ss.forEach(t),kwe=i(d),Di=n(d,"H2",{class:!0});var B0e=s(Di);V2=n(B0e,"A",{id:!0,class:!0,href:!0});var aRr=s(V2);uee=n(aRr,"SPAN",{});var nRr=s(uee);m(c3.$$.fragment,nRr),nRr.forEach(t),aRr.forEach(t),wTo=i(B0e),pee=n(B0e,"SPAN",{});var sRr=s(pee);ATo=r(sRr,"AutoModelForTokenClassification"),sRr.forEach(t),B0e.forEach(t),xwe=i(d),Qo=n(d,"DIV",{class:!0});var Is=s(Qo);m(f3.$$.fragment,Is),LTo=i(Is),qi=n(Is,"P",{});var LO=s(qi);BTo=r(LO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),_ee=n(LO,"CODE",{});var lRr=s(_ee);kTo=r(lRr,"from_pretrained()"),lRr.forEach(t),xTo=r(LO,"class method or the "),vee=n(LO,"CODE",{});var iRr=s(vee);RTo=r(iRr,"from_config()"),iRr.forEach(t),STo=r(LO,`class
method.`),LO.forEach(t),PTo=i(Is),m3=n(Is,"P",{});var k0e=s(m3);$To=r(k0e,"This class cannot be instantiated directly using "),bee=n(k0e,"CODE",{});var dRr=s(bee);ITo=r(dRr,"__init__()"),dRr.forEach(t),jTo=r(k0e," (throws an error)."),k0e.forEach(t),NTo=i(Is),jr=n(Is,"DIV",{class:!0});var js=s(jr);m(g3.$$.fragment,js),DTo=i(js),Tee=n(js,"P",{});var cRr=s(Tee);qTo=r(cRr,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),cRr.forEach(t),OTo=i(js),Oi=n(js,"P",{});var BO=s(Oi);GTo=r(BO,`Note:
Loading a model from its configuration file does `),Fee=n(BO,"STRONG",{});var fRr=s(Fee);zTo=r(fRr,"not"),fRr.forEach(t),VTo=r(BO,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cee=n(BO,"CODE",{});var mRr=s(Cee);XTo=r(mRr,"from_pretrained()"),mRr.forEach(t),WTo=r(BO,"to load the model weights."),BO.forEach(t),QTo=i(js),Eee=n(js,"P",{});var gRr=s(Eee);HTo=r(gRr,"Examples:"),gRr.forEach(t),UTo=i(js),m(h3.$$.fragment,js),js.forEach(t),JTo=i(Is),je=n(Is,"DIV",{class:!0});var Bt=s(je);m(u3.$$.fragment,Bt),YTo=i(Bt),Mee=n(Bt,"P",{});var hRr=s(Mee);KTo=r(hRr,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),hRr.forEach(t),ZTo=i(Bt),$a=n(Bt,"P",{});var HC=s($a);e6o=r(HC,"The model class to instantiate is selected based on the "),yee=n(HC,"CODE",{});var uRr=s(yee);o6o=r(uRr,"model_type"),uRr.forEach(t),r6o=r(HC,` property of the config object (either
passed as an argument or loaded from `),wee=n(HC,"CODE",{});var pRr=s(wee);t6o=r(pRr,"pretrained_model_name_or_path"),pRr.forEach(t),a6o=r(HC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Aee=n(HC,"CODE",{});var _Rr=s(Aee);n6o=r(_Rr,"pretrained_model_name_or_path"),_Rr.forEach(t),s6o=r(HC,":"),HC.forEach(t),l6o=i(Bt),N=n(Bt,"UL",{});var q=s(N);X2=n(q,"LI",{});var W6e=s(X2);Lee=n(W6e,"STRONG",{});var vRr=s(Lee);i6o=r(vRr,"albert"),vRr.forEach(t),d6o=r(W6e," \u2014 "),nP=n(W6e,"A",{href:!0});var bRr=s(nP);c6o=r(bRr,"AlbertForTokenClassification"),bRr.forEach(t),f6o=r(W6e," (ALBERT model)"),W6e.forEach(t),m6o=i(q),W2=n(q,"LI",{});var Q6e=s(W2);Bee=n(Q6e,"STRONG",{});var TRr=s(Bee);g6o=r(TRr,"bert"),TRr.forEach(t),h6o=r(Q6e," \u2014 "),sP=n(Q6e,"A",{href:!0});var FRr=s(sP);u6o=r(FRr,"BertForTokenClassification"),FRr.forEach(t),p6o=r(Q6e," (BERT model)"),Q6e.forEach(t),_6o=i(q),Q2=n(q,"LI",{});var H6e=s(Q2);kee=n(H6e,"STRONG",{});var CRr=s(kee);v6o=r(CRr,"big_bird"),CRr.forEach(t),b6o=r(H6e," \u2014 "),lP=n(H6e,"A",{href:!0});var ERr=s(lP);T6o=r(ERr,"BigBirdForTokenClassification"),ERr.forEach(t),F6o=r(H6e," (BigBird model)"),H6e.forEach(t),C6o=i(q),H2=n(q,"LI",{});var U6e=s(H2);xee=n(U6e,"STRONG",{});var MRr=s(xee);E6o=r(MRr,"camembert"),MRr.forEach(t),M6o=r(U6e," \u2014 "),iP=n(U6e,"A",{href:!0});var yRr=s(iP);y6o=r(yRr,"CamembertForTokenClassification"),yRr.forEach(t),w6o=r(U6e," (CamemBERT model)"),U6e.forEach(t),A6o=i(q),U2=n(q,"LI",{});var J6e=s(U2);Ree=n(J6e,"STRONG",{});var wRr=s(Ree);L6o=r(wRr,"canine"),wRr.forEach(t),B6o=r(J6e," \u2014 "),dP=n(J6e,"A",{href:!0});var ARr=s(dP);k6o=r(ARr,"CanineForTokenClassification"),ARr.forEach(t),x6o=r(J6e," (Canine model)"),J6e.forEach(t),R6o=i(q),J2=n(q,"LI",{});var Y6e=s(J2);See=n(Y6e,"STRONG",{});var LRr=s(See);S6o=r(LRr,"convbert"),LRr.forEach(t),P6o=r(Y6e," \u2014 "),cP=n(Y6e,"A",{href:!0});var BRr=s(cP);$6o=r(BRr,"ConvBertForTokenClassification"),BRr.forEach(t),I6o=r(Y6e," (ConvBERT model)"),Y6e.forEach(t),j6o=i(q),Y2=n(q,"LI",{});var K6e=s(Y2);Pee=n(K6e,"STRONG",{});var kRr=s(Pee);N6o=r(kRr,"deberta"),kRr.forEach(t),D6o=r(K6e," \u2014 "),fP=n(K6e,"A",{href:!0});var xRr=s(fP);q6o=r(xRr,"DebertaForTokenClassification"),xRr.forEach(t),O6o=r(K6e," (DeBERTa model)"),K6e.forEach(t),G6o=i(q),K2=n(q,"LI",{});var Z6e=s(K2);$ee=n(Z6e,"STRONG",{});var RRr=s($ee);z6o=r(RRr,"deberta-v2"),RRr.forEach(t),V6o=r(Z6e," \u2014 "),mP=n(Z6e,"A",{href:!0});var SRr=s(mP);X6o=r(SRr,"DebertaV2ForTokenClassification"),SRr.forEach(t),W6o=r(Z6e," (DeBERTa-v2 model)"),Z6e.forEach(t),Q6o=i(q),Z2=n(q,"LI",{});var eFe=s(Z2);Iee=n(eFe,"STRONG",{});var PRr=s(Iee);H6o=r(PRr,"distilbert"),PRr.forEach(t),U6o=r(eFe," \u2014 "),gP=n(eFe,"A",{href:!0});var $Rr=s(gP);J6o=r($Rr,"DistilBertForTokenClassification"),$Rr.forEach(t),Y6o=r(eFe," (DistilBERT model)"),eFe.forEach(t),K6o=i(q),ev=n(q,"LI",{});var oFe=s(ev);jee=n(oFe,"STRONG",{});var IRr=s(jee);Z6o=r(IRr,"electra"),IRr.forEach(t),eFo=r(oFe," \u2014 "),hP=n(oFe,"A",{href:!0});var jRr=s(hP);oFo=r(jRr,"ElectraForTokenClassification"),jRr.forEach(t),rFo=r(oFe," (ELECTRA model)"),oFe.forEach(t),tFo=i(q),ov=n(q,"LI",{});var rFe=s(ov);Nee=n(rFe,"STRONG",{});var NRr=s(Nee);aFo=r(NRr,"flaubert"),NRr.forEach(t),nFo=r(rFe," \u2014 "),uP=n(rFe,"A",{href:!0});var DRr=s(uP);sFo=r(DRr,"FlaubertForTokenClassification"),DRr.forEach(t),lFo=r(rFe," (FlauBERT model)"),rFe.forEach(t),iFo=i(q),rv=n(q,"LI",{});var tFe=s(rv);Dee=n(tFe,"STRONG",{});var qRr=s(Dee);dFo=r(qRr,"fnet"),qRr.forEach(t),cFo=r(tFe," \u2014 "),pP=n(tFe,"A",{href:!0});var ORr=s(pP);fFo=r(ORr,"FNetForTokenClassification"),ORr.forEach(t),mFo=r(tFe," (FNet model)"),tFe.forEach(t),gFo=i(q),tv=n(q,"LI",{});var aFe=s(tv);qee=n(aFe,"STRONG",{});var GRr=s(qee);hFo=r(GRr,"funnel"),GRr.forEach(t),uFo=r(aFe," \u2014 "),_P=n(aFe,"A",{href:!0});var zRr=s(_P);pFo=r(zRr,"FunnelForTokenClassification"),zRr.forEach(t),_Fo=r(aFe," (Funnel Transformer model)"),aFe.forEach(t),vFo=i(q),av=n(q,"LI",{});var nFe=s(av);Oee=n(nFe,"STRONG",{});var VRr=s(Oee);bFo=r(VRr,"gpt2"),VRr.forEach(t),TFo=r(nFe," \u2014 "),vP=n(nFe,"A",{href:!0});var XRr=s(vP);FFo=r(XRr,"GPT2ForTokenClassification"),XRr.forEach(t),CFo=r(nFe," (OpenAI GPT-2 model)"),nFe.forEach(t),EFo=i(q),nv=n(q,"LI",{});var sFe=s(nv);Gee=n(sFe,"STRONG",{});var WRr=s(Gee);MFo=r(WRr,"ibert"),WRr.forEach(t),yFo=r(sFe," \u2014 "),bP=n(sFe,"A",{href:!0});var QRr=s(bP);wFo=r(QRr,"IBertForTokenClassification"),QRr.forEach(t),AFo=r(sFe," (I-BERT model)"),sFe.forEach(t),LFo=i(q),sv=n(q,"LI",{});var lFe=s(sv);zee=n(lFe,"STRONG",{});var HRr=s(zee);BFo=r(HRr,"layoutlm"),HRr.forEach(t),kFo=r(lFe," \u2014 "),TP=n(lFe,"A",{href:!0});var URr=s(TP);xFo=r(URr,"LayoutLMForTokenClassification"),URr.forEach(t),RFo=r(lFe," (LayoutLM model)"),lFe.forEach(t),SFo=i(q),lv=n(q,"LI",{});var iFe=s(lv);Vee=n(iFe,"STRONG",{});var JRr=s(Vee);PFo=r(JRr,"layoutlmv2"),JRr.forEach(t),$Fo=r(iFe," \u2014 "),FP=n(iFe,"A",{href:!0});var YRr=s(FP);IFo=r(YRr,"LayoutLMv2ForTokenClassification"),YRr.forEach(t),jFo=r(iFe," (LayoutLMv2 model)"),iFe.forEach(t),NFo=i(q),iv=n(q,"LI",{});var dFe=s(iv);Xee=n(dFe,"STRONG",{});var KRr=s(Xee);DFo=r(KRr,"longformer"),KRr.forEach(t),qFo=r(dFe," \u2014 "),CP=n(dFe,"A",{href:!0});var ZRr=s(CP);OFo=r(ZRr,"LongformerForTokenClassification"),ZRr.forEach(t),GFo=r(dFe," (Longformer model)"),dFe.forEach(t),zFo=i(q),dv=n(q,"LI",{});var cFe=s(dv);Wee=n(cFe,"STRONG",{});var eSr=s(Wee);VFo=r(eSr,"megatron-bert"),eSr.forEach(t),XFo=r(cFe," \u2014 "),EP=n(cFe,"A",{href:!0});var oSr=s(EP);WFo=r(oSr,"MegatronBertForTokenClassification"),oSr.forEach(t),QFo=r(cFe," (MegatronBert model)"),cFe.forEach(t),HFo=i(q),cv=n(q,"LI",{});var fFe=s(cv);Qee=n(fFe,"STRONG",{});var rSr=s(Qee);UFo=r(rSr,"mobilebert"),rSr.forEach(t),JFo=r(fFe," \u2014 "),MP=n(fFe,"A",{href:!0});var tSr=s(MP);YFo=r(tSr,"MobileBertForTokenClassification"),tSr.forEach(t),KFo=r(fFe," (MobileBERT model)"),fFe.forEach(t),ZFo=i(q),fv=n(q,"LI",{});var mFe=s(fv);Hee=n(mFe,"STRONG",{});var aSr=s(Hee);eCo=r(aSr,"mpnet"),aSr.forEach(t),oCo=r(mFe," \u2014 "),yP=n(mFe,"A",{href:!0});var nSr=s(yP);rCo=r(nSr,"MPNetForTokenClassification"),nSr.forEach(t),tCo=r(mFe," (MPNet model)"),mFe.forEach(t),aCo=i(q),mv=n(q,"LI",{});var gFe=s(mv);Uee=n(gFe,"STRONG",{});var sSr=s(Uee);nCo=r(sSr,"nystromformer"),sSr.forEach(t),sCo=r(gFe," \u2014 "),wP=n(gFe,"A",{href:!0});var lSr=s(wP);lCo=r(lSr,"NystromformerForTokenClassification"),lSr.forEach(t),iCo=r(gFe," (Nystromformer model)"),gFe.forEach(t),dCo=i(q),gv=n(q,"LI",{});var hFe=s(gv);Jee=n(hFe,"STRONG",{});var iSr=s(Jee);cCo=r(iSr,"qdqbert"),iSr.forEach(t),fCo=r(hFe," \u2014 "),AP=n(hFe,"A",{href:!0});var dSr=s(AP);mCo=r(dSr,"QDQBertForTokenClassification"),dSr.forEach(t),gCo=r(hFe," (QDQBert model)"),hFe.forEach(t),hCo=i(q),hv=n(q,"LI",{});var uFe=s(hv);Yee=n(uFe,"STRONG",{});var cSr=s(Yee);uCo=r(cSr,"rembert"),cSr.forEach(t),pCo=r(uFe," \u2014 "),LP=n(uFe,"A",{href:!0});var fSr=s(LP);_Co=r(fSr,"RemBertForTokenClassification"),fSr.forEach(t),vCo=r(uFe," (RemBERT model)"),uFe.forEach(t),bCo=i(q),uv=n(q,"LI",{});var pFe=s(uv);Kee=n(pFe,"STRONG",{});var mSr=s(Kee);TCo=r(mSr,"roberta"),mSr.forEach(t),FCo=r(pFe," \u2014 "),BP=n(pFe,"A",{href:!0});var gSr=s(BP);CCo=r(gSr,"RobertaForTokenClassification"),gSr.forEach(t),ECo=r(pFe," (RoBERTa model)"),pFe.forEach(t),MCo=i(q),pv=n(q,"LI",{});var _Fe=s(pv);Zee=n(_Fe,"STRONG",{});var hSr=s(Zee);yCo=r(hSr,"roformer"),hSr.forEach(t),wCo=r(_Fe," \u2014 "),kP=n(_Fe,"A",{href:!0});var uSr=s(kP);ACo=r(uSr,"RoFormerForTokenClassification"),uSr.forEach(t),LCo=r(_Fe," (RoFormer model)"),_Fe.forEach(t),BCo=i(q),_v=n(q,"LI",{});var vFe=s(_v);eoe=n(vFe,"STRONG",{});var pSr=s(eoe);kCo=r(pSr,"squeezebert"),pSr.forEach(t),xCo=r(vFe," \u2014 "),xP=n(vFe,"A",{href:!0});var _Sr=s(xP);RCo=r(_Sr,"SqueezeBertForTokenClassification"),_Sr.forEach(t),SCo=r(vFe," (SqueezeBERT model)"),vFe.forEach(t),PCo=i(q),vv=n(q,"LI",{});var bFe=s(vv);ooe=n(bFe,"STRONG",{});var vSr=s(ooe);$Co=r(vSr,"xlm"),vSr.forEach(t),ICo=r(bFe," \u2014 "),RP=n(bFe,"A",{href:!0});var bSr=s(RP);jCo=r(bSr,"XLMForTokenClassification"),bSr.forEach(t),NCo=r(bFe," (XLM model)"),bFe.forEach(t),DCo=i(q),bv=n(q,"LI",{});var TFe=s(bv);roe=n(TFe,"STRONG",{});var TSr=s(roe);qCo=r(TSr,"xlm-roberta"),TSr.forEach(t),OCo=r(TFe," \u2014 "),SP=n(TFe,"A",{href:!0});var FSr=s(SP);GCo=r(FSr,"XLMRobertaForTokenClassification"),FSr.forEach(t),zCo=r(TFe," (XLM-RoBERTa model)"),TFe.forEach(t),VCo=i(q),Tv=n(q,"LI",{});var FFe=s(Tv);toe=n(FFe,"STRONG",{});var CSr=s(toe);XCo=r(CSr,"xlnet"),CSr.forEach(t),WCo=r(FFe," \u2014 "),PP=n(FFe,"A",{href:!0});var ESr=s(PP);QCo=r(ESr,"XLNetForTokenClassification"),ESr.forEach(t),HCo=r(FFe," (XLNet model)"),FFe.forEach(t),UCo=i(q),Fv=n(q,"LI",{});var CFe=s(Fv);aoe=n(CFe,"STRONG",{});var MSr=s(aoe);JCo=r(MSr,"yoso"),MSr.forEach(t),YCo=r(CFe," \u2014 "),$P=n(CFe,"A",{href:!0});var ySr=s($P);KCo=r(ySr,"YosoForTokenClassification"),ySr.forEach(t),ZCo=r(CFe," (YOSO model)"),CFe.forEach(t),q.forEach(t),eEo=i(Bt),Cv=n(Bt,"P",{});var EFe=s(Cv);oEo=r(EFe,"The model is set in evaluation mode by default using "),noe=n(EFe,"CODE",{});var wSr=s(noe);rEo=r(wSr,"model.eval()"),wSr.forEach(t),tEo=r(EFe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),soe=n(EFe,"CODE",{});var ASr=s(soe);aEo=r(ASr,"model.train()"),ASr.forEach(t),EFe.forEach(t),nEo=i(Bt),loe=n(Bt,"P",{});var LSr=s(loe);sEo=r(LSr,"Examples:"),LSr.forEach(t),lEo=i(Bt),m(p3.$$.fragment,Bt),Bt.forEach(t),Is.forEach(t),Rwe=i(d),Gi=n(d,"H2",{class:!0});var x0e=s(Gi);Ev=n(x0e,"A",{id:!0,class:!0,href:!0});var BSr=s(Ev);ioe=n(BSr,"SPAN",{});var kSr=s(ioe);m(_3.$$.fragment,kSr),kSr.forEach(t),BSr.forEach(t),iEo=i(x0e),doe=n(x0e,"SPAN",{});var xSr=s(doe);dEo=r(xSr,"AutoModelForQuestionAnswering"),xSr.forEach(t),x0e.forEach(t),Swe=i(d),Ho=n(d,"DIV",{class:!0});var Ns=s(Ho);m(v3.$$.fragment,Ns),cEo=i(Ns),zi=n(Ns,"P",{});var kO=s(zi);fEo=r(kO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),coe=n(kO,"CODE",{});var RSr=s(coe);mEo=r(RSr,"from_pretrained()"),RSr.forEach(t),gEo=r(kO,"class method or the "),foe=n(kO,"CODE",{});var SSr=s(foe);hEo=r(SSr,"from_config()"),SSr.forEach(t),uEo=r(kO,`class
method.`),kO.forEach(t),pEo=i(Ns),b3=n(Ns,"P",{});var R0e=s(b3);_Eo=r(R0e,"This class cannot be instantiated directly using "),moe=n(R0e,"CODE",{});var PSr=s(moe);vEo=r(PSr,"__init__()"),PSr.forEach(t),bEo=r(R0e," (throws an error)."),R0e.forEach(t),TEo=i(Ns),Nr=n(Ns,"DIV",{class:!0});var Ds=s(Nr);m(T3.$$.fragment,Ds),FEo=i(Ds),goe=n(Ds,"P",{});var $Sr=s(goe);CEo=r($Sr,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),$Sr.forEach(t),EEo=i(Ds),Vi=n(Ds,"P",{});var xO=s(Vi);MEo=r(xO,`Note:
Loading a model from its configuration file does `),hoe=n(xO,"STRONG",{});var ISr=s(hoe);yEo=r(ISr,"not"),ISr.forEach(t),wEo=r(xO,` load the model weights. It only affects the
model\u2019s configuration. Use `),uoe=n(xO,"CODE",{});var jSr=s(uoe);AEo=r(jSr,"from_pretrained()"),jSr.forEach(t),LEo=r(xO,"to load the model weights."),xO.forEach(t),BEo=i(Ds),poe=n(Ds,"P",{});var NSr=s(poe);kEo=r(NSr,"Examples:"),NSr.forEach(t),xEo=i(Ds),m(F3.$$.fragment,Ds),Ds.forEach(t),REo=i(Ns),Ne=n(Ns,"DIV",{class:!0});var kt=s(Ne);m(C3.$$.fragment,kt),SEo=i(kt),_oe=n(kt,"P",{});var DSr=s(_oe);PEo=r(DSr,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),DSr.forEach(t),$Eo=i(kt),Ia=n(kt,"P",{});var UC=s(Ia);IEo=r(UC,"The model class to instantiate is selected based on the "),voe=n(UC,"CODE",{});var qSr=s(voe);jEo=r(qSr,"model_type"),qSr.forEach(t),NEo=r(UC,` property of the config object (either
passed as an argument or loaded from `),boe=n(UC,"CODE",{});var OSr=s(boe);DEo=r(OSr,"pretrained_model_name_or_path"),OSr.forEach(t),qEo=r(UC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Toe=n(UC,"CODE",{});var GSr=s(Toe);OEo=r(GSr,"pretrained_model_name_or_path"),GSr.forEach(t),GEo=r(UC,":"),UC.forEach(t),zEo=i(kt),R=n(kt,"UL",{});var P=s(R);Mv=n(P,"LI",{});var MFe=s(Mv);Foe=n(MFe,"STRONG",{});var zSr=s(Foe);VEo=r(zSr,"albert"),zSr.forEach(t),XEo=r(MFe," \u2014 "),IP=n(MFe,"A",{href:!0});var VSr=s(IP);WEo=r(VSr,"AlbertForQuestionAnswering"),VSr.forEach(t),QEo=r(MFe," (ALBERT model)"),MFe.forEach(t),HEo=i(P),yv=n(P,"LI",{});var yFe=s(yv);Coe=n(yFe,"STRONG",{});var XSr=s(Coe);UEo=r(XSr,"bart"),XSr.forEach(t),JEo=r(yFe," \u2014 "),jP=n(yFe,"A",{href:!0});var WSr=s(jP);YEo=r(WSr,"BartForQuestionAnswering"),WSr.forEach(t),KEo=r(yFe," (BART model)"),yFe.forEach(t),ZEo=i(P),wv=n(P,"LI",{});var wFe=s(wv);Eoe=n(wFe,"STRONG",{});var QSr=s(Eoe);eMo=r(QSr,"bert"),QSr.forEach(t),oMo=r(wFe," \u2014 "),NP=n(wFe,"A",{href:!0});var HSr=s(NP);rMo=r(HSr,"BertForQuestionAnswering"),HSr.forEach(t),tMo=r(wFe," (BERT model)"),wFe.forEach(t),aMo=i(P),Av=n(P,"LI",{});var AFe=s(Av);Moe=n(AFe,"STRONG",{});var USr=s(Moe);nMo=r(USr,"big_bird"),USr.forEach(t),sMo=r(AFe," \u2014 "),DP=n(AFe,"A",{href:!0});var JSr=s(DP);lMo=r(JSr,"BigBirdForQuestionAnswering"),JSr.forEach(t),iMo=r(AFe," (BigBird model)"),AFe.forEach(t),dMo=i(P),Lv=n(P,"LI",{});var LFe=s(Lv);yoe=n(LFe,"STRONG",{});var YSr=s(yoe);cMo=r(YSr,"bigbird_pegasus"),YSr.forEach(t),fMo=r(LFe," \u2014 "),qP=n(LFe,"A",{href:!0});var KSr=s(qP);mMo=r(KSr,"BigBirdPegasusForQuestionAnswering"),KSr.forEach(t),gMo=r(LFe," (BigBirdPegasus model)"),LFe.forEach(t),hMo=i(P),Bv=n(P,"LI",{});var BFe=s(Bv);woe=n(BFe,"STRONG",{});var ZSr=s(woe);uMo=r(ZSr,"camembert"),ZSr.forEach(t),pMo=r(BFe," \u2014 "),OP=n(BFe,"A",{href:!0});var ePr=s(OP);_Mo=r(ePr,"CamembertForQuestionAnswering"),ePr.forEach(t),vMo=r(BFe," (CamemBERT model)"),BFe.forEach(t),bMo=i(P),kv=n(P,"LI",{});var kFe=s(kv);Aoe=n(kFe,"STRONG",{});var oPr=s(Aoe);TMo=r(oPr,"canine"),oPr.forEach(t),FMo=r(kFe," \u2014 "),GP=n(kFe,"A",{href:!0});var rPr=s(GP);CMo=r(rPr,"CanineForQuestionAnswering"),rPr.forEach(t),EMo=r(kFe," (Canine model)"),kFe.forEach(t),MMo=i(P),xv=n(P,"LI",{});var xFe=s(xv);Loe=n(xFe,"STRONG",{});var tPr=s(Loe);yMo=r(tPr,"convbert"),tPr.forEach(t),wMo=r(xFe," \u2014 "),zP=n(xFe,"A",{href:!0});var aPr=s(zP);AMo=r(aPr,"ConvBertForQuestionAnswering"),aPr.forEach(t),LMo=r(xFe," (ConvBERT model)"),xFe.forEach(t),BMo=i(P),Rv=n(P,"LI",{});var RFe=s(Rv);Boe=n(RFe,"STRONG",{});var nPr=s(Boe);kMo=r(nPr,"deberta"),nPr.forEach(t),xMo=r(RFe," \u2014 "),VP=n(RFe,"A",{href:!0});var sPr=s(VP);RMo=r(sPr,"DebertaForQuestionAnswering"),sPr.forEach(t),SMo=r(RFe," (DeBERTa model)"),RFe.forEach(t),PMo=i(P),Sv=n(P,"LI",{});var SFe=s(Sv);koe=n(SFe,"STRONG",{});var lPr=s(koe);$Mo=r(lPr,"deberta-v2"),lPr.forEach(t),IMo=r(SFe," \u2014 "),XP=n(SFe,"A",{href:!0});var iPr=s(XP);jMo=r(iPr,"DebertaV2ForQuestionAnswering"),iPr.forEach(t),NMo=r(SFe," (DeBERTa-v2 model)"),SFe.forEach(t),DMo=i(P),Pv=n(P,"LI",{});var PFe=s(Pv);xoe=n(PFe,"STRONG",{});var dPr=s(xoe);qMo=r(dPr,"distilbert"),dPr.forEach(t),OMo=r(PFe," \u2014 "),WP=n(PFe,"A",{href:!0});var cPr=s(WP);GMo=r(cPr,"DistilBertForQuestionAnswering"),cPr.forEach(t),zMo=r(PFe," (DistilBERT model)"),PFe.forEach(t),VMo=i(P),$v=n(P,"LI",{});var $Fe=s($v);Roe=n($Fe,"STRONG",{});var fPr=s(Roe);XMo=r(fPr,"electra"),fPr.forEach(t),WMo=r($Fe," \u2014 "),QP=n($Fe,"A",{href:!0});var mPr=s(QP);QMo=r(mPr,"ElectraForQuestionAnswering"),mPr.forEach(t),HMo=r($Fe," (ELECTRA model)"),$Fe.forEach(t),UMo=i(P),Iv=n(P,"LI",{});var IFe=s(Iv);Soe=n(IFe,"STRONG",{});var gPr=s(Soe);JMo=r(gPr,"flaubert"),gPr.forEach(t),YMo=r(IFe," \u2014 "),HP=n(IFe,"A",{href:!0});var hPr=s(HP);KMo=r(hPr,"FlaubertForQuestionAnsweringSimple"),hPr.forEach(t),ZMo=r(IFe," (FlauBERT model)"),IFe.forEach(t),e3o=i(P),jv=n(P,"LI",{});var jFe=s(jv);Poe=n(jFe,"STRONG",{});var uPr=s(Poe);o3o=r(uPr,"fnet"),uPr.forEach(t),r3o=r(jFe," \u2014 "),UP=n(jFe,"A",{href:!0});var pPr=s(UP);t3o=r(pPr,"FNetForQuestionAnswering"),pPr.forEach(t),a3o=r(jFe," (FNet model)"),jFe.forEach(t),n3o=i(P),Nv=n(P,"LI",{});var NFe=s(Nv);$oe=n(NFe,"STRONG",{});var _Pr=s($oe);s3o=r(_Pr,"funnel"),_Pr.forEach(t),l3o=r(NFe," \u2014 "),JP=n(NFe,"A",{href:!0});var vPr=s(JP);i3o=r(vPr,"FunnelForQuestionAnswering"),vPr.forEach(t),d3o=r(NFe," (Funnel Transformer model)"),NFe.forEach(t),c3o=i(P),Dv=n(P,"LI",{});var DFe=s(Dv);Ioe=n(DFe,"STRONG",{});var bPr=s(Ioe);f3o=r(bPr,"gptj"),bPr.forEach(t),m3o=r(DFe," \u2014 "),YP=n(DFe,"A",{href:!0});var TPr=s(YP);g3o=r(TPr,"GPTJForQuestionAnswering"),TPr.forEach(t),h3o=r(DFe," (GPT-J model)"),DFe.forEach(t),u3o=i(P),qv=n(P,"LI",{});var qFe=s(qv);joe=n(qFe,"STRONG",{});var FPr=s(joe);p3o=r(FPr,"ibert"),FPr.forEach(t),_3o=r(qFe," \u2014 "),KP=n(qFe,"A",{href:!0});var CPr=s(KP);v3o=r(CPr,"IBertForQuestionAnswering"),CPr.forEach(t),b3o=r(qFe," (I-BERT model)"),qFe.forEach(t),T3o=i(P),Ov=n(P,"LI",{});var OFe=s(Ov);Noe=n(OFe,"STRONG",{});var EPr=s(Noe);F3o=r(EPr,"layoutlmv2"),EPr.forEach(t),C3o=r(OFe," \u2014 "),ZP=n(OFe,"A",{href:!0});var MPr=s(ZP);E3o=r(MPr,"LayoutLMv2ForQuestionAnswering"),MPr.forEach(t),M3o=r(OFe," (LayoutLMv2 model)"),OFe.forEach(t),y3o=i(P),Gv=n(P,"LI",{});var GFe=s(Gv);Doe=n(GFe,"STRONG",{});var yPr=s(Doe);w3o=r(yPr,"led"),yPr.forEach(t),A3o=r(GFe," \u2014 "),e$=n(GFe,"A",{href:!0});var wPr=s(e$);L3o=r(wPr,"LEDForQuestionAnswering"),wPr.forEach(t),B3o=r(GFe," (LED model)"),GFe.forEach(t),k3o=i(P),zv=n(P,"LI",{});var zFe=s(zv);qoe=n(zFe,"STRONG",{});var APr=s(qoe);x3o=r(APr,"longformer"),APr.forEach(t),R3o=r(zFe," \u2014 "),o$=n(zFe,"A",{href:!0});var LPr=s(o$);S3o=r(LPr,"LongformerForQuestionAnswering"),LPr.forEach(t),P3o=r(zFe," (Longformer model)"),zFe.forEach(t),$3o=i(P),Vv=n(P,"LI",{});var VFe=s(Vv);Ooe=n(VFe,"STRONG",{});var BPr=s(Ooe);I3o=r(BPr,"lxmert"),BPr.forEach(t),j3o=r(VFe," \u2014 "),r$=n(VFe,"A",{href:!0});var kPr=s(r$);N3o=r(kPr,"LxmertForQuestionAnswering"),kPr.forEach(t),D3o=r(VFe," (LXMERT model)"),VFe.forEach(t),q3o=i(P),Xv=n(P,"LI",{});var XFe=s(Xv);Goe=n(XFe,"STRONG",{});var xPr=s(Goe);O3o=r(xPr,"mbart"),xPr.forEach(t),G3o=r(XFe," \u2014 "),t$=n(XFe,"A",{href:!0});var RPr=s(t$);z3o=r(RPr,"MBartForQuestionAnswering"),RPr.forEach(t),V3o=r(XFe," (mBART model)"),XFe.forEach(t),X3o=i(P),Wv=n(P,"LI",{});var WFe=s(Wv);zoe=n(WFe,"STRONG",{});var SPr=s(zoe);W3o=r(SPr,"megatron-bert"),SPr.forEach(t),Q3o=r(WFe," \u2014 "),a$=n(WFe,"A",{href:!0});var PPr=s(a$);H3o=r(PPr,"MegatronBertForQuestionAnswering"),PPr.forEach(t),U3o=r(WFe," (MegatronBert model)"),WFe.forEach(t),J3o=i(P),Qv=n(P,"LI",{});var QFe=s(Qv);Voe=n(QFe,"STRONG",{});var $Pr=s(Voe);Y3o=r($Pr,"mobilebert"),$Pr.forEach(t),K3o=r(QFe," \u2014 "),n$=n(QFe,"A",{href:!0});var IPr=s(n$);Z3o=r(IPr,"MobileBertForQuestionAnswering"),IPr.forEach(t),e5o=r(QFe," (MobileBERT model)"),QFe.forEach(t),o5o=i(P),Hv=n(P,"LI",{});var HFe=s(Hv);Xoe=n(HFe,"STRONG",{});var jPr=s(Xoe);r5o=r(jPr,"mpnet"),jPr.forEach(t),t5o=r(HFe," \u2014 "),s$=n(HFe,"A",{href:!0});var NPr=s(s$);a5o=r(NPr,"MPNetForQuestionAnswering"),NPr.forEach(t),n5o=r(HFe," (MPNet model)"),HFe.forEach(t),s5o=i(P),Uv=n(P,"LI",{});var UFe=s(Uv);Woe=n(UFe,"STRONG",{});var DPr=s(Woe);l5o=r(DPr,"nystromformer"),DPr.forEach(t),i5o=r(UFe," \u2014 "),l$=n(UFe,"A",{href:!0});var qPr=s(l$);d5o=r(qPr,"NystromformerForQuestionAnswering"),qPr.forEach(t),c5o=r(UFe," (Nystromformer model)"),UFe.forEach(t),f5o=i(P),Jv=n(P,"LI",{});var JFe=s(Jv);Qoe=n(JFe,"STRONG",{});var OPr=s(Qoe);m5o=r(OPr,"qdqbert"),OPr.forEach(t),g5o=r(JFe," \u2014 "),i$=n(JFe,"A",{href:!0});var GPr=s(i$);h5o=r(GPr,"QDQBertForQuestionAnswering"),GPr.forEach(t),u5o=r(JFe," (QDQBert model)"),JFe.forEach(t),p5o=i(P),Yv=n(P,"LI",{});var YFe=s(Yv);Hoe=n(YFe,"STRONG",{});var zPr=s(Hoe);_5o=r(zPr,"reformer"),zPr.forEach(t),v5o=r(YFe," \u2014 "),d$=n(YFe,"A",{href:!0});var VPr=s(d$);b5o=r(VPr,"ReformerForQuestionAnswering"),VPr.forEach(t),T5o=r(YFe," (Reformer model)"),YFe.forEach(t),F5o=i(P),Kv=n(P,"LI",{});var KFe=s(Kv);Uoe=n(KFe,"STRONG",{});var XPr=s(Uoe);C5o=r(XPr,"rembert"),XPr.forEach(t),E5o=r(KFe," \u2014 "),c$=n(KFe,"A",{href:!0});var WPr=s(c$);M5o=r(WPr,"RemBertForQuestionAnswering"),WPr.forEach(t),y5o=r(KFe," (RemBERT model)"),KFe.forEach(t),w5o=i(P),Zv=n(P,"LI",{});var ZFe=s(Zv);Joe=n(ZFe,"STRONG",{});var QPr=s(Joe);A5o=r(QPr,"roberta"),QPr.forEach(t),L5o=r(ZFe," \u2014 "),f$=n(ZFe,"A",{href:!0});var HPr=s(f$);B5o=r(HPr,"RobertaForQuestionAnswering"),HPr.forEach(t),k5o=r(ZFe," (RoBERTa model)"),ZFe.forEach(t),x5o=i(P),e1=n(P,"LI",{});var eCe=s(e1);Yoe=n(eCe,"STRONG",{});var UPr=s(Yoe);R5o=r(UPr,"roformer"),UPr.forEach(t),S5o=r(eCe," \u2014 "),m$=n(eCe,"A",{href:!0});var JPr=s(m$);P5o=r(JPr,"RoFormerForQuestionAnswering"),JPr.forEach(t),$5o=r(eCe," (RoFormer model)"),eCe.forEach(t),I5o=i(P),o1=n(P,"LI",{});var oCe=s(o1);Koe=n(oCe,"STRONG",{});var YPr=s(Koe);j5o=r(YPr,"splinter"),YPr.forEach(t),N5o=r(oCe," \u2014 "),g$=n(oCe,"A",{href:!0});var KPr=s(g$);D5o=r(KPr,"SplinterForQuestionAnswering"),KPr.forEach(t),q5o=r(oCe," (Splinter model)"),oCe.forEach(t),O5o=i(P),r1=n(P,"LI",{});var rCe=s(r1);Zoe=n(rCe,"STRONG",{});var ZPr=s(Zoe);G5o=r(ZPr,"squeezebert"),ZPr.forEach(t),z5o=r(rCe," \u2014 "),h$=n(rCe,"A",{href:!0});var e$r=s(h$);V5o=r(e$r,"SqueezeBertForQuestionAnswering"),e$r.forEach(t),X5o=r(rCe," (SqueezeBERT model)"),rCe.forEach(t),W5o=i(P),t1=n(P,"LI",{});var tCe=s(t1);ere=n(tCe,"STRONG",{});var o$r=s(ere);Q5o=r(o$r,"xlm"),o$r.forEach(t),H5o=r(tCe," \u2014 "),u$=n(tCe,"A",{href:!0});var r$r=s(u$);U5o=r(r$r,"XLMForQuestionAnsweringSimple"),r$r.forEach(t),J5o=r(tCe," (XLM model)"),tCe.forEach(t),Y5o=i(P),a1=n(P,"LI",{});var aCe=s(a1);ore=n(aCe,"STRONG",{});var t$r=s(ore);K5o=r(t$r,"xlm-roberta"),t$r.forEach(t),Z5o=r(aCe," \u2014 "),p$=n(aCe,"A",{href:!0});var a$r=s(p$);eyo=r(a$r,"XLMRobertaForQuestionAnswering"),a$r.forEach(t),oyo=r(aCe," (XLM-RoBERTa model)"),aCe.forEach(t),ryo=i(P),n1=n(P,"LI",{});var nCe=s(n1);rre=n(nCe,"STRONG",{});var n$r=s(rre);tyo=r(n$r,"xlnet"),n$r.forEach(t),ayo=r(nCe," \u2014 "),_$=n(nCe,"A",{href:!0});var s$r=s(_$);nyo=r(s$r,"XLNetForQuestionAnsweringSimple"),s$r.forEach(t),syo=r(nCe," (XLNet model)"),nCe.forEach(t),lyo=i(P),s1=n(P,"LI",{});var sCe=s(s1);tre=n(sCe,"STRONG",{});var l$r=s(tre);iyo=r(l$r,"yoso"),l$r.forEach(t),dyo=r(sCe," \u2014 "),v$=n(sCe,"A",{href:!0});var i$r=s(v$);cyo=r(i$r,"YosoForQuestionAnswering"),i$r.forEach(t),fyo=r(sCe," (YOSO model)"),sCe.forEach(t),P.forEach(t),myo=i(kt),l1=n(kt,"P",{});var lCe=s(l1);gyo=r(lCe,"The model is set in evaluation mode by default using "),are=n(lCe,"CODE",{});var d$r=s(are);hyo=r(d$r,"model.eval()"),d$r.forEach(t),uyo=r(lCe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nre=n(lCe,"CODE",{});var c$r=s(nre);pyo=r(c$r,"model.train()"),c$r.forEach(t),lCe.forEach(t),_yo=i(kt),sre=n(kt,"P",{});var f$r=s(sre);vyo=r(f$r,"Examples:"),f$r.forEach(t),byo=i(kt),m(E3.$$.fragment,kt),kt.forEach(t),Ns.forEach(t),Pwe=i(d),Xi=n(d,"H2",{class:!0});var S0e=s(Xi);i1=n(S0e,"A",{id:!0,class:!0,href:!0});var m$r=s(i1);lre=n(m$r,"SPAN",{});var g$r=s(lre);m(M3.$$.fragment,g$r),g$r.forEach(t),m$r.forEach(t),Tyo=i(S0e),ire=n(S0e,"SPAN",{});var h$r=s(ire);Fyo=r(h$r,"AutoModelForTableQuestionAnswering"),h$r.forEach(t),S0e.forEach(t),$we=i(d),Uo=n(d,"DIV",{class:!0});var qs=s(Uo);m(y3.$$.fragment,qs),Cyo=i(qs),Wi=n(qs,"P",{});var RO=s(Wi);Eyo=r(RO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),dre=n(RO,"CODE",{});var u$r=s(dre);Myo=r(u$r,"from_pretrained()"),u$r.forEach(t),yyo=r(RO,"class method or the "),cre=n(RO,"CODE",{});var p$r=s(cre);wyo=r(p$r,"from_config()"),p$r.forEach(t),Ayo=r(RO,`class
method.`),RO.forEach(t),Lyo=i(qs),w3=n(qs,"P",{});var P0e=s(w3);Byo=r(P0e,"This class cannot be instantiated directly using "),fre=n(P0e,"CODE",{});var _$r=s(fre);kyo=r(_$r,"__init__()"),_$r.forEach(t),xyo=r(P0e," (throws an error)."),P0e.forEach(t),Ryo=i(qs),Dr=n(qs,"DIV",{class:!0});var Os=s(Dr);m(A3.$$.fragment,Os),Syo=i(Os),mre=n(Os,"P",{});var v$r=s(mre);Pyo=r(v$r,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),v$r.forEach(t),$yo=i(Os),Qi=n(Os,"P",{});var SO=s(Qi);Iyo=r(SO,`Note:
Loading a model from its configuration file does `),gre=n(SO,"STRONG",{});var b$r=s(gre);jyo=r(b$r,"not"),b$r.forEach(t),Nyo=r(SO,` load the model weights. It only affects the
model\u2019s configuration. Use `),hre=n(SO,"CODE",{});var T$r=s(hre);Dyo=r(T$r,"from_pretrained()"),T$r.forEach(t),qyo=r(SO,"to load the model weights."),SO.forEach(t),Oyo=i(Os),ure=n(Os,"P",{});var F$r=s(ure);Gyo=r(F$r,"Examples:"),F$r.forEach(t),zyo=i(Os),m(L3.$$.fragment,Os),Os.forEach(t),Vyo=i(qs),De=n(qs,"DIV",{class:!0});var xt=s(De);m(B3.$$.fragment,xt),Xyo=i(xt),pre=n(xt,"P",{});var C$r=s(pre);Wyo=r(C$r,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),C$r.forEach(t),Qyo=i(xt),ja=n(xt,"P",{});var JC=s(ja);Hyo=r(JC,"The model class to instantiate is selected based on the "),_re=n(JC,"CODE",{});var E$r=s(_re);Uyo=r(E$r,"model_type"),E$r.forEach(t),Jyo=r(JC,` property of the config object (either
passed as an argument or loaded from `),vre=n(JC,"CODE",{});var M$r=s(vre);Yyo=r(M$r,"pretrained_model_name_or_path"),M$r.forEach(t),Kyo=r(JC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bre=n(JC,"CODE",{});var y$r=s(bre);Zyo=r(y$r,"pretrained_model_name_or_path"),y$r.forEach(t),ewo=r(JC,":"),JC.forEach(t),owo=i(xt),Tre=n(xt,"UL",{});var w$r=s(Tre);d1=n(w$r,"LI",{});var iCe=s(d1);Fre=n(iCe,"STRONG",{});var A$r=s(Fre);rwo=r(A$r,"tapas"),A$r.forEach(t),two=r(iCe," \u2014 "),b$=n(iCe,"A",{href:!0});var L$r=s(b$);awo=r(L$r,"TapasForQuestionAnswering"),L$r.forEach(t),nwo=r(iCe," (TAPAS model)"),iCe.forEach(t),w$r.forEach(t),swo=i(xt),c1=n(xt,"P",{});var dCe=s(c1);lwo=r(dCe,"The model is set in evaluation mode by default using "),Cre=n(dCe,"CODE",{});var B$r=s(Cre);iwo=r(B$r,"model.eval()"),B$r.forEach(t),dwo=r(dCe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ere=n(dCe,"CODE",{});var k$r=s(Ere);cwo=r(k$r,"model.train()"),k$r.forEach(t),dCe.forEach(t),fwo=i(xt),Mre=n(xt,"P",{});var x$r=s(Mre);mwo=r(x$r,"Examples:"),x$r.forEach(t),gwo=i(xt),m(k3.$$.fragment,xt),xt.forEach(t),qs.forEach(t),Iwe=i(d),Hi=n(d,"H2",{class:!0});var $0e=s(Hi);f1=n($0e,"A",{id:!0,class:!0,href:!0});var R$r=s(f1);yre=n(R$r,"SPAN",{});var S$r=s(yre);m(x3.$$.fragment,S$r),S$r.forEach(t),R$r.forEach(t),hwo=i($0e),wre=n($0e,"SPAN",{});var P$r=s(wre);uwo=r(P$r,"AutoModelForImageClassification"),P$r.forEach(t),$0e.forEach(t),jwe=i(d),Jo=n(d,"DIV",{class:!0});var Gs=s(Jo);m(R3.$$.fragment,Gs),pwo=i(Gs),Ui=n(Gs,"P",{});var PO=s(Ui);_wo=r(PO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Are=n(PO,"CODE",{});var $$r=s(Are);vwo=r($$r,"from_pretrained()"),$$r.forEach(t),bwo=r(PO,"class method or the "),Lre=n(PO,"CODE",{});var I$r=s(Lre);Two=r(I$r,"from_config()"),I$r.forEach(t),Fwo=r(PO,`class
method.`),PO.forEach(t),Cwo=i(Gs),S3=n(Gs,"P",{});var I0e=s(S3);Ewo=r(I0e,"This class cannot be instantiated directly using "),Bre=n(I0e,"CODE",{});var j$r=s(Bre);Mwo=r(j$r,"__init__()"),j$r.forEach(t),ywo=r(I0e," (throws an error)."),I0e.forEach(t),wwo=i(Gs),qr=n(Gs,"DIV",{class:!0});var zs=s(qr);m(P3.$$.fragment,zs),Awo=i(zs),kre=n(zs,"P",{});var N$r=s(kre);Lwo=r(N$r,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),N$r.forEach(t),Bwo=i(zs),Ji=n(zs,"P",{});var $O=s(Ji);kwo=r($O,`Note:
Loading a model from its configuration file does `),xre=n($O,"STRONG",{});var D$r=s(xre);xwo=r(D$r,"not"),D$r.forEach(t),Rwo=r($O,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rre=n($O,"CODE",{});var q$r=s(Rre);Swo=r(q$r,"from_pretrained()"),q$r.forEach(t),Pwo=r($O,"to load the model weights."),$O.forEach(t),$wo=i(zs),Sre=n(zs,"P",{});var O$r=s(Sre);Iwo=r(O$r,"Examples:"),O$r.forEach(t),jwo=i(zs),m($3.$$.fragment,zs),zs.forEach(t),Nwo=i(Gs),qe=n(Gs,"DIV",{class:!0});var Rt=s(qe);m(I3.$$.fragment,Rt),Dwo=i(Rt),Pre=n(Rt,"P",{});var G$r=s(Pre);qwo=r(G$r,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),G$r.forEach(t),Owo=i(Rt),Na=n(Rt,"P",{});var YC=s(Na);Gwo=r(YC,"The model class to instantiate is selected based on the "),$re=n(YC,"CODE",{});var z$r=s($re);zwo=r(z$r,"model_type"),z$r.forEach(t),Vwo=r(YC,` property of the config object (either
passed as an argument or loaded from `),Ire=n(YC,"CODE",{});var V$r=s(Ire);Xwo=r(V$r,"pretrained_model_name_or_path"),V$r.forEach(t),Wwo=r(YC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jre=n(YC,"CODE",{});var X$r=s(jre);Qwo=r(X$r,"pretrained_model_name_or_path"),X$r.forEach(t),Hwo=r(YC,":"),YC.forEach(t),Uwo=i(Rt),eo=n(Rt,"UL",{});var St=s(eo);m1=n(St,"LI",{});var cCe=s(m1);Nre=n(cCe,"STRONG",{});var W$r=s(Nre);Jwo=r(W$r,"beit"),W$r.forEach(t),Ywo=r(cCe," \u2014 "),T$=n(cCe,"A",{href:!0});var Q$r=s(T$);Kwo=r(Q$r,"BeitForImageClassification"),Q$r.forEach(t),Zwo=r(cCe," (BEiT model)"),cCe.forEach(t),eAo=i(St),us=n(St,"LI",{});var O0=s(us);Dre=n(O0,"STRONG",{});var H$r=s(Dre);oAo=r(H$r,"deit"),H$r.forEach(t),rAo=r(O0," \u2014 "),F$=n(O0,"A",{href:!0});var U$r=s(F$);tAo=r(U$r,"DeiTForImageClassification"),U$r.forEach(t),aAo=r(O0," or "),C$=n(O0,"A",{href:!0});var J$r=s(C$);nAo=r(J$r,"DeiTForImageClassificationWithTeacher"),J$r.forEach(t),sAo=r(O0," (DeiT model)"),O0.forEach(t),lAo=i(St),g1=n(St,"LI",{});var fCe=s(g1);qre=n(fCe,"STRONG",{});var Y$r=s(qre);iAo=r(Y$r,"imagegpt"),Y$r.forEach(t),dAo=r(fCe," \u2014 "),E$=n(fCe,"A",{href:!0});var K$r=s(E$);cAo=r(K$r,"ImageGPTForImageClassification"),K$r.forEach(t),fAo=r(fCe," (ImageGPT model)"),fCe.forEach(t),mAo=i(St),Jt=n(St,"LI",{});var Gc=s(Jt);Ore=n(Gc,"STRONG",{});var Z$r=s(Ore);gAo=r(Z$r,"perceiver"),Z$r.forEach(t),hAo=r(Gc," \u2014 "),M$=n(Gc,"A",{href:!0});var eIr=s(M$);uAo=r(eIr,"PerceiverForImageClassificationLearned"),eIr.forEach(t),pAo=r(Gc," or "),y$=n(Gc,"A",{href:!0});var oIr=s(y$);_Ao=r(oIr,"PerceiverForImageClassificationFourier"),oIr.forEach(t),vAo=r(Gc," or "),w$=n(Gc,"A",{href:!0});var rIr=s(w$);bAo=r(rIr,"PerceiverForImageClassificationConvProcessing"),rIr.forEach(t),TAo=r(Gc," (Perceiver model)"),Gc.forEach(t),FAo=i(St),h1=n(St,"LI",{});var mCe=s(h1);Gre=n(mCe,"STRONG",{});var tIr=s(Gre);CAo=r(tIr,"segformer"),tIr.forEach(t),EAo=r(mCe," \u2014 "),A$=n(mCe,"A",{href:!0});var aIr=s(A$);MAo=r(aIr,"SegformerForImageClassification"),aIr.forEach(t),yAo=r(mCe," (SegFormer model)"),mCe.forEach(t),wAo=i(St),u1=n(St,"LI",{});var gCe=s(u1);zre=n(gCe,"STRONG",{});var nIr=s(zre);AAo=r(nIr,"swin"),nIr.forEach(t),LAo=r(gCe," \u2014 "),L$=n(gCe,"A",{href:!0});var sIr=s(L$);BAo=r(sIr,"SwinForImageClassification"),sIr.forEach(t),kAo=r(gCe," (Swin model)"),gCe.forEach(t),xAo=i(St),p1=n(St,"LI",{});var hCe=s(p1);Vre=n(hCe,"STRONG",{});var lIr=s(Vre);RAo=r(lIr,"vit"),lIr.forEach(t),SAo=r(hCe," \u2014 "),B$=n(hCe,"A",{href:!0});var iIr=s(B$);PAo=r(iIr,"ViTForImageClassification"),iIr.forEach(t),$Ao=r(hCe," (ViT model)"),hCe.forEach(t),St.forEach(t),IAo=i(Rt),_1=n(Rt,"P",{});var uCe=s(_1);jAo=r(uCe,"The model is set in evaluation mode by default using "),Xre=n(uCe,"CODE",{});var dIr=s(Xre);NAo=r(dIr,"model.eval()"),dIr.forEach(t),DAo=r(uCe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Wre=n(uCe,"CODE",{});var cIr=s(Wre);qAo=r(cIr,"model.train()"),cIr.forEach(t),uCe.forEach(t),OAo=i(Rt),Qre=n(Rt,"P",{});var fIr=s(Qre);GAo=r(fIr,"Examples:"),fIr.forEach(t),zAo=i(Rt),m(j3.$$.fragment,Rt),Rt.forEach(t),Gs.forEach(t),Nwe=i(d),Yi=n(d,"H2",{class:!0});var j0e=s(Yi);v1=n(j0e,"A",{id:!0,class:!0,href:!0});var mIr=s(v1);Hre=n(mIr,"SPAN",{});var gIr=s(Hre);m(N3.$$.fragment,gIr),gIr.forEach(t),mIr.forEach(t),VAo=i(j0e),Ure=n(j0e,"SPAN",{});var hIr=s(Ure);XAo=r(hIr,"AutoModelForVision2Seq"),hIr.forEach(t),j0e.forEach(t),Dwe=i(d),Yo=n(d,"DIV",{class:!0});var Vs=s(Yo);m(D3.$$.fragment,Vs),WAo=i(Vs),Ki=n(Vs,"P",{});var IO=s(Ki);QAo=r(IO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Jre=n(IO,"CODE",{});var uIr=s(Jre);HAo=r(uIr,"from_pretrained()"),uIr.forEach(t),UAo=r(IO,"class method or the "),Yre=n(IO,"CODE",{});var pIr=s(Yre);JAo=r(pIr,"from_config()"),pIr.forEach(t),YAo=r(IO,`class
method.`),IO.forEach(t),KAo=i(Vs),q3=n(Vs,"P",{});var N0e=s(q3);ZAo=r(N0e,"This class cannot be instantiated directly using "),Kre=n(N0e,"CODE",{});var _Ir=s(Kre);e0o=r(_Ir,"__init__()"),_Ir.forEach(t),o0o=r(N0e," (throws an error)."),N0e.forEach(t),r0o=i(Vs),Or=n(Vs,"DIV",{class:!0});var Xs=s(Or);m(O3.$$.fragment,Xs),t0o=i(Xs),Zre=n(Xs,"P",{});var vIr=s(Zre);a0o=r(vIr,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),vIr.forEach(t),n0o=i(Xs),Zi=n(Xs,"P",{});var jO=s(Zi);s0o=r(jO,`Note:
Loading a model from its configuration file does `),ete=n(jO,"STRONG",{});var bIr=s(ete);l0o=r(bIr,"not"),bIr.forEach(t),i0o=r(jO,` load the model weights. It only affects the
model\u2019s configuration. Use `),ote=n(jO,"CODE",{});var TIr=s(ote);d0o=r(TIr,"from_pretrained()"),TIr.forEach(t),c0o=r(jO,"to load the model weights."),jO.forEach(t),f0o=i(Xs),rte=n(Xs,"P",{});var FIr=s(rte);m0o=r(FIr,"Examples:"),FIr.forEach(t),g0o=i(Xs),m(G3.$$.fragment,Xs),Xs.forEach(t),h0o=i(Vs),Oe=n(Vs,"DIV",{class:!0});var Pt=s(Oe);m(z3.$$.fragment,Pt),u0o=i(Pt),tte=n(Pt,"P",{});var CIr=s(tte);p0o=r(CIr,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),CIr.forEach(t),_0o=i(Pt),Da=n(Pt,"P",{});var KC=s(Da);v0o=r(KC,"The model class to instantiate is selected based on the "),ate=n(KC,"CODE",{});var EIr=s(ate);b0o=r(EIr,"model_type"),EIr.forEach(t),T0o=r(KC,` property of the config object (either
passed as an argument or loaded from `),nte=n(KC,"CODE",{});var MIr=s(nte);F0o=r(MIr,"pretrained_model_name_or_path"),MIr.forEach(t),C0o=r(KC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ste=n(KC,"CODE",{});var yIr=s(ste);E0o=r(yIr,"pretrained_model_name_or_path"),yIr.forEach(t),M0o=r(KC,":"),KC.forEach(t),y0o=i(Pt),lte=n(Pt,"UL",{});var wIr=s(lte);b1=n(wIr,"LI",{});var pCe=s(b1);ite=n(pCe,"STRONG",{});var AIr=s(ite);w0o=r(AIr,"vision-encoder-decoder"),AIr.forEach(t),A0o=r(pCe," \u2014 "),k$=n(pCe,"A",{href:!0});var LIr=s(k$);L0o=r(LIr,"VisionEncoderDecoderModel"),LIr.forEach(t),B0o=r(pCe," (Vision Encoder decoder model)"),pCe.forEach(t),wIr.forEach(t),k0o=i(Pt),T1=n(Pt,"P",{});var _Ce=s(T1);x0o=r(_Ce,"The model is set in evaluation mode by default using "),dte=n(_Ce,"CODE",{});var BIr=s(dte);R0o=r(BIr,"model.eval()"),BIr.forEach(t),S0o=r(_Ce,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cte=n(_Ce,"CODE",{});var kIr=s(cte);P0o=r(kIr,"model.train()"),kIr.forEach(t),_Ce.forEach(t),$0o=i(Pt),fte=n(Pt,"P",{});var xIr=s(fte);I0o=r(xIr,"Examples:"),xIr.forEach(t),j0o=i(Pt),m(V3.$$.fragment,Pt),Pt.forEach(t),Vs.forEach(t),qwe=i(d),ed=n(d,"H2",{class:!0});var D0e=s(ed);F1=n(D0e,"A",{id:!0,class:!0,href:!0});var RIr=s(F1);mte=n(RIr,"SPAN",{});var SIr=s(mte);m(X3.$$.fragment,SIr),SIr.forEach(t),RIr.forEach(t),N0o=i(D0e),gte=n(D0e,"SPAN",{});var PIr=s(gte);D0o=r(PIr,"AutoModelForAudioClassification"),PIr.forEach(t),D0e.forEach(t),Owe=i(d),Ko=n(d,"DIV",{class:!0});var Ws=s(Ko);m(W3.$$.fragment,Ws),q0o=i(Ws),od=n(Ws,"P",{});var NO=s(od);O0o=r(NO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),hte=n(NO,"CODE",{});var $Ir=s(hte);G0o=r($Ir,"from_pretrained()"),$Ir.forEach(t),z0o=r(NO,"class method or the "),ute=n(NO,"CODE",{});var IIr=s(ute);V0o=r(IIr,"from_config()"),IIr.forEach(t),X0o=r(NO,`class
method.`),NO.forEach(t),W0o=i(Ws),Q3=n(Ws,"P",{});var q0e=s(Q3);Q0o=r(q0e,"This class cannot be instantiated directly using "),pte=n(q0e,"CODE",{});var jIr=s(pte);H0o=r(jIr,"__init__()"),jIr.forEach(t),U0o=r(q0e," (throws an error)."),q0e.forEach(t),J0o=i(Ws),Gr=n(Ws,"DIV",{class:!0});var Qs=s(Gr);m(H3.$$.fragment,Qs),Y0o=i(Qs),_te=n(Qs,"P",{});var NIr=s(_te);K0o=r(NIr,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),NIr.forEach(t),Z0o=i(Qs),rd=n(Qs,"P",{});var DO=s(rd);e7o=r(DO,`Note:
Loading a model from its configuration file does `),vte=n(DO,"STRONG",{});var DIr=s(vte);o7o=r(DIr,"not"),DIr.forEach(t),r7o=r(DO,` load the model weights. It only affects the
model\u2019s configuration. Use `),bte=n(DO,"CODE",{});var qIr=s(bte);t7o=r(qIr,"from_pretrained()"),qIr.forEach(t),a7o=r(DO,"to load the model weights."),DO.forEach(t),n7o=i(Qs),Tte=n(Qs,"P",{});var OIr=s(Tte);s7o=r(OIr,"Examples:"),OIr.forEach(t),l7o=i(Qs),m(U3.$$.fragment,Qs),Qs.forEach(t),i7o=i(Ws),Ge=n(Ws,"DIV",{class:!0});var $t=s(Ge);m(J3.$$.fragment,$t),d7o=i($t),Fte=n($t,"P",{});var GIr=s(Fte);c7o=r(GIr,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),GIr.forEach(t),f7o=i($t),qa=n($t,"P",{});var ZC=s(qa);m7o=r(ZC,"The model class to instantiate is selected based on the "),Cte=n(ZC,"CODE",{});var zIr=s(Cte);g7o=r(zIr,"model_type"),zIr.forEach(t),h7o=r(ZC,` property of the config object (either
passed as an argument or loaded from `),Ete=n(ZC,"CODE",{});var VIr=s(Ete);u7o=r(VIr,"pretrained_model_name_or_path"),VIr.forEach(t),p7o=r(ZC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mte=n(ZC,"CODE",{});var XIr=s(Mte);_7o=r(XIr,"pretrained_model_name_or_path"),XIr.forEach(t),v7o=r(ZC,":"),ZC.forEach(t),b7o=i($t),oo=n($t,"UL",{});var It=s(oo);C1=n(It,"LI",{});var vCe=s(C1);yte=n(vCe,"STRONG",{});var WIr=s(yte);T7o=r(WIr,"hubert"),WIr.forEach(t),F7o=r(vCe," \u2014 "),x$=n(vCe,"A",{href:!0});var QIr=s(x$);C7o=r(QIr,"HubertForSequenceClassification"),QIr.forEach(t),E7o=r(vCe," (Hubert model)"),vCe.forEach(t),M7o=i(It),E1=n(It,"LI",{});var bCe=s(E1);wte=n(bCe,"STRONG",{});var HIr=s(wte);y7o=r(HIr,"sew"),HIr.forEach(t),w7o=r(bCe," \u2014 "),R$=n(bCe,"A",{href:!0});var UIr=s(R$);A7o=r(UIr,"SEWForSequenceClassification"),UIr.forEach(t),L7o=r(bCe," (SEW model)"),bCe.forEach(t),B7o=i(It),M1=n(It,"LI",{});var TCe=s(M1);Ate=n(TCe,"STRONG",{});var JIr=s(Ate);k7o=r(JIr,"sew-d"),JIr.forEach(t),x7o=r(TCe," \u2014 "),S$=n(TCe,"A",{href:!0});var YIr=s(S$);R7o=r(YIr,"SEWDForSequenceClassification"),YIr.forEach(t),S7o=r(TCe," (SEW-D model)"),TCe.forEach(t),P7o=i(It),y1=n(It,"LI",{});var FCe=s(y1);Lte=n(FCe,"STRONG",{});var KIr=s(Lte);$7o=r(KIr,"unispeech"),KIr.forEach(t),I7o=r(FCe," \u2014 "),P$=n(FCe,"A",{href:!0});var ZIr=s(P$);j7o=r(ZIr,"UniSpeechForSequenceClassification"),ZIr.forEach(t),N7o=r(FCe," (UniSpeech model)"),FCe.forEach(t),D7o=i(It),w1=n(It,"LI",{});var CCe=s(w1);Bte=n(CCe,"STRONG",{});var ejr=s(Bte);q7o=r(ejr,"unispeech-sat"),ejr.forEach(t),O7o=r(CCe," \u2014 "),$$=n(CCe,"A",{href:!0});var ojr=s($$);G7o=r(ojr,"UniSpeechSatForSequenceClassification"),ojr.forEach(t),z7o=r(CCe," (UniSpeechSat model)"),CCe.forEach(t),V7o=i(It),A1=n(It,"LI",{});var ECe=s(A1);kte=n(ECe,"STRONG",{});var rjr=s(kte);X7o=r(rjr,"wav2vec2"),rjr.forEach(t),W7o=r(ECe," \u2014 "),I$=n(ECe,"A",{href:!0});var tjr=s(I$);Q7o=r(tjr,"Wav2Vec2ForSequenceClassification"),tjr.forEach(t),H7o=r(ECe," (Wav2Vec2 model)"),ECe.forEach(t),U7o=i(It),L1=n(It,"LI",{});var MCe=s(L1);xte=n(MCe,"STRONG",{});var ajr=s(xte);J7o=r(ajr,"wavlm"),ajr.forEach(t),Y7o=r(MCe," \u2014 "),j$=n(MCe,"A",{href:!0});var njr=s(j$);K7o=r(njr,"WavLMForSequenceClassification"),njr.forEach(t),Z7o=r(MCe," (WavLM model)"),MCe.forEach(t),It.forEach(t),eLo=i($t),B1=n($t,"P",{});var yCe=s(B1);oLo=r(yCe,"The model is set in evaluation mode by default using "),Rte=n(yCe,"CODE",{});var sjr=s(Rte);rLo=r(sjr,"model.eval()"),sjr.forEach(t),tLo=r(yCe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ste=n(yCe,"CODE",{});var ljr=s(Ste);aLo=r(ljr,"model.train()"),ljr.forEach(t),yCe.forEach(t),nLo=i($t),Pte=n($t,"P",{});var ijr=s(Pte);sLo=r(ijr,"Examples:"),ijr.forEach(t),lLo=i($t),m(Y3.$$.fragment,$t),$t.forEach(t),Ws.forEach(t),Gwe=i(d),td=n(d,"H2",{class:!0});var O0e=s(td);k1=n(O0e,"A",{id:!0,class:!0,href:!0});var djr=s(k1);$te=n(djr,"SPAN",{});var cjr=s($te);m(K3.$$.fragment,cjr),cjr.forEach(t),djr.forEach(t),iLo=i(O0e),Ite=n(O0e,"SPAN",{});var fjr=s(Ite);dLo=r(fjr,"AutoModelForAudioFrameClassification"),fjr.forEach(t),O0e.forEach(t),zwe=i(d),Zo=n(d,"DIV",{class:!0});var Hs=s(Zo);m(Z3.$$.fragment,Hs),cLo=i(Hs),ad=n(Hs,"P",{});var qO=s(ad);fLo=r(qO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),jte=n(qO,"CODE",{});var mjr=s(jte);mLo=r(mjr,"from_pretrained()"),mjr.forEach(t),gLo=r(qO,"class method or the "),Nte=n(qO,"CODE",{});var gjr=s(Nte);hLo=r(gjr,"from_config()"),gjr.forEach(t),uLo=r(qO,`class
method.`),qO.forEach(t),pLo=i(Hs),e5=n(Hs,"P",{});var G0e=s(e5);_Lo=r(G0e,"This class cannot be instantiated directly using "),Dte=n(G0e,"CODE",{});var hjr=s(Dte);vLo=r(hjr,"__init__()"),hjr.forEach(t),bLo=r(G0e," (throws an error)."),G0e.forEach(t),TLo=i(Hs),zr=n(Hs,"DIV",{class:!0});var Us=s(zr);m(o5.$$.fragment,Us),FLo=i(Us),qte=n(Us,"P",{});var ujr=s(qte);CLo=r(ujr,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),ujr.forEach(t),ELo=i(Us),nd=n(Us,"P",{});var OO=s(nd);MLo=r(OO,`Note:
Loading a model from its configuration file does `),Ote=n(OO,"STRONG",{});var pjr=s(Ote);yLo=r(pjr,"not"),pjr.forEach(t),wLo=r(OO,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gte=n(OO,"CODE",{});var _jr=s(Gte);ALo=r(_jr,"from_pretrained()"),_jr.forEach(t),LLo=r(OO,"to load the model weights."),OO.forEach(t),BLo=i(Us),zte=n(Us,"P",{});var vjr=s(zte);kLo=r(vjr,"Examples:"),vjr.forEach(t),xLo=i(Us),m(r5.$$.fragment,Us),Us.forEach(t),RLo=i(Hs),ze=n(Hs,"DIV",{class:!0});var jt=s(ze);m(t5.$$.fragment,jt),SLo=i(jt),Vte=n(jt,"P",{});var bjr=s(Vte);PLo=r(bjr,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),bjr.forEach(t),$Lo=i(jt),Oa=n(jt,"P",{});var eE=s(Oa);ILo=r(eE,"The model class to instantiate is selected based on the "),Xte=n(eE,"CODE",{});var Tjr=s(Xte);jLo=r(Tjr,"model_type"),Tjr.forEach(t),NLo=r(eE,` property of the config object (either
passed as an argument or loaded from `),Wte=n(eE,"CODE",{});var Fjr=s(Wte);DLo=r(Fjr,"pretrained_model_name_or_path"),Fjr.forEach(t),qLo=r(eE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qte=n(eE,"CODE",{});var Cjr=s(Qte);OLo=r(Cjr,"pretrained_model_name_or_path"),Cjr.forEach(t),GLo=r(eE,":"),eE.forEach(t),zLo=i(jt),sd=n(jt,"UL",{});var GO=s(sd);x1=n(GO,"LI",{});var wCe=s(x1);Hte=n(wCe,"STRONG",{});var Ejr=s(Hte);VLo=r(Ejr,"unispeech-sat"),Ejr.forEach(t),XLo=r(wCe," \u2014 "),N$=n(wCe,"A",{href:!0});var Mjr=s(N$);WLo=r(Mjr,"UniSpeechSatForAudioFrameClassification"),Mjr.forEach(t),QLo=r(wCe," (UniSpeechSat model)"),wCe.forEach(t),HLo=i(GO),R1=n(GO,"LI",{});var ACe=s(R1);Ute=n(ACe,"STRONG",{});var yjr=s(Ute);ULo=r(yjr,"wav2vec2"),yjr.forEach(t),JLo=r(ACe," \u2014 "),D$=n(ACe,"A",{href:!0});var wjr=s(D$);YLo=r(wjr,"Wav2Vec2ForAudioFrameClassification"),wjr.forEach(t),KLo=r(ACe," (Wav2Vec2 model)"),ACe.forEach(t),ZLo=i(GO),S1=n(GO,"LI",{});var LCe=s(S1);Jte=n(LCe,"STRONG",{});var Ajr=s(Jte);e8o=r(Ajr,"wavlm"),Ajr.forEach(t),o8o=r(LCe," \u2014 "),q$=n(LCe,"A",{href:!0});var Ljr=s(q$);r8o=r(Ljr,"WavLMForAudioFrameClassification"),Ljr.forEach(t),t8o=r(LCe," (WavLM model)"),LCe.forEach(t),GO.forEach(t),a8o=i(jt),P1=n(jt,"P",{});var BCe=s(P1);n8o=r(BCe,"The model is set in evaluation mode by default using "),Yte=n(BCe,"CODE",{});var Bjr=s(Yte);s8o=r(Bjr,"model.eval()"),Bjr.forEach(t),l8o=r(BCe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Kte=n(BCe,"CODE",{});var kjr=s(Kte);i8o=r(kjr,"model.train()"),kjr.forEach(t),BCe.forEach(t),d8o=i(jt),Zte=n(jt,"P",{});var xjr=s(Zte);c8o=r(xjr,"Examples:"),xjr.forEach(t),f8o=i(jt),m(a5.$$.fragment,jt),jt.forEach(t),Hs.forEach(t),Vwe=i(d),ld=n(d,"H2",{class:!0});var z0e=s(ld);$1=n(z0e,"A",{id:!0,class:!0,href:!0});var Rjr=s($1);eae=n(Rjr,"SPAN",{});var Sjr=s(eae);m(n5.$$.fragment,Sjr),Sjr.forEach(t),Rjr.forEach(t),m8o=i(z0e),oae=n(z0e,"SPAN",{});var Pjr=s(oae);g8o=r(Pjr,"AutoModelForCTC"),Pjr.forEach(t),z0e.forEach(t),Xwe=i(d),er=n(d,"DIV",{class:!0});var Js=s(er);m(s5.$$.fragment,Js),h8o=i(Js),id=n(Js,"P",{});var zO=s(id);u8o=r(zO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),rae=n(zO,"CODE",{});var $jr=s(rae);p8o=r($jr,"from_pretrained()"),$jr.forEach(t),_8o=r(zO,"class method or the "),tae=n(zO,"CODE",{});var Ijr=s(tae);v8o=r(Ijr,"from_config()"),Ijr.forEach(t),b8o=r(zO,`class
method.`),zO.forEach(t),T8o=i(Js),l5=n(Js,"P",{});var V0e=s(l5);F8o=r(V0e,"This class cannot be instantiated directly using "),aae=n(V0e,"CODE",{});var jjr=s(aae);C8o=r(jjr,"__init__()"),jjr.forEach(t),E8o=r(V0e," (throws an error)."),V0e.forEach(t),M8o=i(Js),Vr=n(Js,"DIV",{class:!0});var Ys=s(Vr);m(i5.$$.fragment,Ys),y8o=i(Ys),nae=n(Ys,"P",{});var Njr=s(nae);w8o=r(Njr,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),Njr.forEach(t),A8o=i(Ys),dd=n(Ys,"P",{});var VO=s(dd);L8o=r(VO,`Note:
Loading a model from its configuration file does `),sae=n(VO,"STRONG",{});var Djr=s(sae);B8o=r(Djr,"not"),Djr.forEach(t),k8o=r(VO,` load the model weights. It only affects the
model\u2019s configuration. Use `),lae=n(VO,"CODE",{});var qjr=s(lae);x8o=r(qjr,"from_pretrained()"),qjr.forEach(t),R8o=r(VO,"to load the model weights."),VO.forEach(t),S8o=i(Ys),iae=n(Ys,"P",{});var Ojr=s(iae);P8o=r(Ojr,"Examples:"),Ojr.forEach(t),$8o=i(Ys),m(d5.$$.fragment,Ys),Ys.forEach(t),I8o=i(Js),Ve=n(Js,"DIV",{class:!0});var Nt=s(Ve);m(c5.$$.fragment,Nt),j8o=i(Nt),dae=n(Nt,"P",{});var Gjr=s(dae);N8o=r(Gjr,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Gjr.forEach(t),D8o=i(Nt),Ga=n(Nt,"P",{});var oE=s(Ga);q8o=r(oE,"The model class to instantiate is selected based on the "),cae=n(oE,"CODE",{});var zjr=s(cae);O8o=r(zjr,"model_type"),zjr.forEach(t),G8o=r(oE,` property of the config object (either
passed as an argument or loaded from `),fae=n(oE,"CODE",{});var Vjr=s(fae);z8o=r(Vjr,"pretrained_model_name_or_path"),Vjr.forEach(t),V8o=r(oE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mae=n(oE,"CODE",{});var Xjr=s(mae);X8o=r(Xjr,"pretrained_model_name_or_path"),Xjr.forEach(t),W8o=r(oE,":"),oE.forEach(t),Q8o=i(Nt),ro=n(Nt,"UL",{});var Dt=s(ro);I1=n(Dt,"LI",{});var kCe=s(I1);gae=n(kCe,"STRONG",{});var Wjr=s(gae);H8o=r(Wjr,"hubert"),Wjr.forEach(t),U8o=r(kCe," \u2014 "),O$=n(kCe,"A",{href:!0});var Qjr=s(O$);J8o=r(Qjr,"HubertForCTC"),Qjr.forEach(t),Y8o=r(kCe," (Hubert model)"),kCe.forEach(t),K8o=i(Dt),j1=n(Dt,"LI",{});var xCe=s(j1);hae=n(xCe,"STRONG",{});var Hjr=s(hae);Z8o=r(Hjr,"sew"),Hjr.forEach(t),eBo=r(xCe," \u2014 "),G$=n(xCe,"A",{href:!0});var Ujr=s(G$);oBo=r(Ujr,"SEWForCTC"),Ujr.forEach(t),rBo=r(xCe," (SEW model)"),xCe.forEach(t),tBo=i(Dt),N1=n(Dt,"LI",{});var RCe=s(N1);uae=n(RCe,"STRONG",{});var Jjr=s(uae);aBo=r(Jjr,"sew-d"),Jjr.forEach(t),nBo=r(RCe," \u2014 "),z$=n(RCe,"A",{href:!0});var Yjr=s(z$);sBo=r(Yjr,"SEWDForCTC"),Yjr.forEach(t),lBo=r(RCe," (SEW-D model)"),RCe.forEach(t),iBo=i(Dt),D1=n(Dt,"LI",{});var SCe=s(D1);pae=n(SCe,"STRONG",{});var Kjr=s(pae);dBo=r(Kjr,"unispeech"),Kjr.forEach(t),cBo=r(SCe," \u2014 "),V$=n(SCe,"A",{href:!0});var Zjr=s(V$);fBo=r(Zjr,"UniSpeechForCTC"),Zjr.forEach(t),mBo=r(SCe," (UniSpeech model)"),SCe.forEach(t),gBo=i(Dt),q1=n(Dt,"LI",{});var PCe=s(q1);_ae=n(PCe,"STRONG",{});var eNr=s(_ae);hBo=r(eNr,"unispeech-sat"),eNr.forEach(t),uBo=r(PCe," \u2014 "),X$=n(PCe,"A",{href:!0});var oNr=s(X$);pBo=r(oNr,"UniSpeechSatForCTC"),oNr.forEach(t),_Bo=r(PCe," (UniSpeechSat model)"),PCe.forEach(t),vBo=i(Dt),O1=n(Dt,"LI",{});var $Ce=s(O1);vae=n($Ce,"STRONG",{});var rNr=s(vae);bBo=r(rNr,"wav2vec2"),rNr.forEach(t),TBo=r($Ce," \u2014 "),W$=n($Ce,"A",{href:!0});var tNr=s(W$);FBo=r(tNr,"Wav2Vec2ForCTC"),tNr.forEach(t),CBo=r($Ce," (Wav2Vec2 model)"),$Ce.forEach(t),EBo=i(Dt),G1=n(Dt,"LI",{});var ICe=s(G1);bae=n(ICe,"STRONG",{});var aNr=s(bae);MBo=r(aNr,"wavlm"),aNr.forEach(t),yBo=r(ICe," \u2014 "),Q$=n(ICe,"A",{href:!0});var nNr=s(Q$);wBo=r(nNr,"WavLMForCTC"),nNr.forEach(t),ABo=r(ICe," (WavLM model)"),ICe.forEach(t),Dt.forEach(t),LBo=i(Nt),z1=n(Nt,"P",{});var jCe=s(z1);BBo=r(jCe,"The model is set in evaluation mode by default using "),Tae=n(jCe,"CODE",{});var sNr=s(Tae);kBo=r(sNr,"model.eval()"),sNr.forEach(t),xBo=r(jCe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fae=n(jCe,"CODE",{});var lNr=s(Fae);RBo=r(lNr,"model.train()"),lNr.forEach(t),jCe.forEach(t),SBo=i(Nt),Cae=n(Nt,"P",{});var iNr=s(Cae);PBo=r(iNr,"Examples:"),iNr.forEach(t),$Bo=i(Nt),m(f5.$$.fragment,Nt),Nt.forEach(t),Js.forEach(t),Wwe=i(d),cd=n(d,"H2",{class:!0});var X0e=s(cd);V1=n(X0e,"A",{id:!0,class:!0,href:!0});var dNr=s(V1);Eae=n(dNr,"SPAN",{});var cNr=s(Eae);m(m5.$$.fragment,cNr),cNr.forEach(t),dNr.forEach(t),IBo=i(X0e),Mae=n(X0e,"SPAN",{});var fNr=s(Mae);jBo=r(fNr,"AutoModelForSpeechSeq2Seq"),fNr.forEach(t),X0e.forEach(t),Qwe=i(d),or=n(d,"DIV",{class:!0});var Ks=s(or);m(g5.$$.fragment,Ks),NBo=i(Ks),fd=n(Ks,"P",{});var XO=s(fd);DBo=r(XO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeing head) when created
with the `),yae=n(XO,"CODE",{});var mNr=s(yae);qBo=r(mNr,"from_pretrained()"),mNr.forEach(t),OBo=r(XO,"class method or the "),wae=n(XO,"CODE",{});var gNr=s(wae);GBo=r(gNr,"from_config()"),gNr.forEach(t),zBo=r(XO,`class
method.`),XO.forEach(t),VBo=i(Ks),h5=n(Ks,"P",{});var W0e=s(h5);XBo=r(W0e,"This class cannot be instantiated directly using "),Aae=n(W0e,"CODE",{});var hNr=s(Aae);WBo=r(hNr,"__init__()"),hNr.forEach(t),QBo=r(W0e," (throws an error)."),W0e.forEach(t),HBo=i(Ks),Xr=n(Ks,"DIV",{class:!0});var Zs=s(Xr);m(u5.$$.fragment,Zs),UBo=i(Zs),Lae=n(Zs,"P",{});var uNr=s(Lae);JBo=r(uNr,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeing head) from a configuration."),uNr.forEach(t),YBo=i(Zs),md=n(Zs,"P",{});var WO=s(md);KBo=r(WO,`Note:
Loading a model from its configuration file does `),Bae=n(WO,"STRONG",{});var pNr=s(Bae);ZBo=r(pNr,"not"),pNr.forEach(t),e9o=r(WO,` load the model weights. It only affects the
model\u2019s configuration. Use `),kae=n(WO,"CODE",{});var _Nr=s(kae);o9o=r(_Nr,"from_pretrained()"),_Nr.forEach(t),r9o=r(WO,"to load the model weights."),WO.forEach(t),t9o=i(Zs),xae=n(Zs,"P",{});var vNr=s(xae);a9o=r(vNr,"Examples:"),vNr.forEach(t),n9o=i(Zs),m(p5.$$.fragment,Zs),Zs.forEach(t),s9o=i(Ks),Xe=n(Ks,"DIV",{class:!0});var qt=s(Xe);m(_5.$$.fragment,qt),l9o=i(qt),Rae=n(qt,"P",{});var bNr=s(Rae);i9o=r(bNr,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeing head) from a pretrained model."),bNr.forEach(t),d9o=i(qt),za=n(qt,"P",{});var rE=s(za);c9o=r(rE,"The model class to instantiate is selected based on the "),Sae=n(rE,"CODE",{});var TNr=s(Sae);f9o=r(TNr,"model_type"),TNr.forEach(t),m9o=r(rE,` property of the config object (either
passed as an argument or loaded from `),Pae=n(rE,"CODE",{});var FNr=s(Pae);g9o=r(FNr,"pretrained_model_name_or_path"),FNr.forEach(t),h9o=r(rE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ae=n(rE,"CODE",{});var CNr=s($ae);u9o=r(CNr,"pretrained_model_name_or_path"),CNr.forEach(t),p9o=r(rE,":"),rE.forEach(t),_9o=i(qt),v5=n(qt,"UL",{});var Q0e=s(v5);X1=n(Q0e,"LI",{});var NCe=s(X1);Iae=n(NCe,"STRONG",{});var ENr=s(Iae);v9o=r(ENr,"speech-encoder-decoder"),ENr.forEach(t),b9o=r(NCe," \u2014 "),H$=n(NCe,"A",{href:!0});var MNr=s(H$);T9o=r(MNr,"SpeechEncoderDecoderModel"),MNr.forEach(t),F9o=r(NCe," (Speech Encoder decoder model)"),NCe.forEach(t),C9o=i(Q0e),W1=n(Q0e,"LI",{});var DCe=s(W1);jae=n(DCe,"STRONG",{});var yNr=s(jae);E9o=r(yNr,"speech_to_text"),yNr.forEach(t),M9o=r(DCe," \u2014 "),U$=n(DCe,"A",{href:!0});var wNr=s(U$);y9o=r(wNr,"Speech2TextForConditionalGeneration"),wNr.forEach(t),w9o=r(DCe," (Speech2Text model)"),DCe.forEach(t),Q0e.forEach(t),A9o=i(qt),Q1=n(qt,"P",{});var qCe=s(Q1);L9o=r(qCe,"The model is set in evaluation mode by default using "),Nae=n(qCe,"CODE",{});var ANr=s(Nae);B9o=r(ANr,"model.eval()"),ANr.forEach(t),k9o=r(qCe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dae=n(qCe,"CODE",{});var LNr=s(Dae);x9o=r(LNr,"model.train()"),LNr.forEach(t),qCe.forEach(t),R9o=i(qt),qae=n(qt,"P",{});var BNr=s(qae);S9o=r(BNr,"Examples:"),BNr.forEach(t),P9o=i(qt),m(b5.$$.fragment,qt),qt.forEach(t),Ks.forEach(t),Hwe=i(d),gd=n(d,"H2",{class:!0});var H0e=s(gd);H1=n(H0e,"A",{id:!0,class:!0,href:!0});var kNr=s(H1);Oae=n(kNr,"SPAN",{});var xNr=s(Oae);m(T5.$$.fragment,xNr),xNr.forEach(t),kNr.forEach(t),$9o=i(H0e),Gae=n(H0e,"SPAN",{});var RNr=s(Gae);I9o=r(RNr,"AutoModelForAudioXVector"),RNr.forEach(t),H0e.forEach(t),Uwe=i(d),rr=n(d,"DIV",{class:!0});var el=s(rr);m(F5.$$.fragment,el),j9o=i(el),hd=n(el,"P",{});var QO=s(hd);N9o=r(QO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),zae=n(QO,"CODE",{});var SNr=s(zae);D9o=r(SNr,"from_pretrained()"),SNr.forEach(t),q9o=r(QO,"class method or the "),Vae=n(QO,"CODE",{});var PNr=s(Vae);O9o=r(PNr,"from_config()"),PNr.forEach(t),G9o=r(QO,`class
method.`),QO.forEach(t),z9o=i(el),C5=n(el,"P",{});var U0e=s(C5);V9o=r(U0e,"This class cannot be instantiated directly using "),Xae=n(U0e,"CODE",{});var $Nr=s(Xae);X9o=r($Nr,"__init__()"),$Nr.forEach(t),W9o=r(U0e," (throws an error)."),U0e.forEach(t),Q9o=i(el),Wr=n(el,"DIV",{class:!0});var ol=s(Wr);m(E5.$$.fragment,ol),H9o=i(ol),Wae=n(ol,"P",{});var INr=s(Wae);U9o=r(INr,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),INr.forEach(t),J9o=i(ol),ud=n(ol,"P",{});var HO=s(ud);Y9o=r(HO,`Note:
Loading a model from its configuration file does `),Qae=n(HO,"STRONG",{});var jNr=s(Qae);K9o=r(jNr,"not"),jNr.forEach(t),Z9o=r(HO,` load the model weights. It only affects the
model\u2019s configuration. Use `),Hae=n(HO,"CODE",{});var NNr=s(Hae);eko=r(NNr,"from_pretrained()"),NNr.forEach(t),oko=r(HO,"to load the model weights."),HO.forEach(t),rko=i(ol),Uae=n(ol,"P",{});var DNr=s(Uae);tko=r(DNr,"Examples:"),DNr.forEach(t),ako=i(ol),m(M5.$$.fragment,ol),ol.forEach(t),nko=i(el),We=n(el,"DIV",{class:!0});var Ot=s(We);m(y5.$$.fragment,Ot),sko=i(Ot),Jae=n(Ot,"P",{});var qNr=s(Jae);lko=r(qNr,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),qNr.forEach(t),iko=i(Ot),Va=n(Ot,"P",{});var tE=s(Va);dko=r(tE,"The model class to instantiate is selected based on the "),Yae=n(tE,"CODE",{});var ONr=s(Yae);cko=r(ONr,"model_type"),ONr.forEach(t),fko=r(tE,` property of the config object (either
passed as an argument or loaded from `),Kae=n(tE,"CODE",{});var GNr=s(Kae);mko=r(GNr,"pretrained_model_name_or_path"),GNr.forEach(t),gko=r(tE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zae=n(tE,"CODE",{});var zNr=s(Zae);hko=r(zNr,"pretrained_model_name_or_path"),zNr.forEach(t),uko=r(tE,":"),tE.forEach(t),pko=i(Ot),pd=n(Ot,"UL",{});var UO=s(pd);U1=n(UO,"LI",{});var OCe=s(U1);ene=n(OCe,"STRONG",{});var VNr=s(ene);_ko=r(VNr,"unispeech-sat"),VNr.forEach(t),vko=r(OCe," \u2014 "),J$=n(OCe,"A",{href:!0});var XNr=s(J$);bko=r(XNr,"UniSpeechSatForXVector"),XNr.forEach(t),Tko=r(OCe," (UniSpeechSat model)"),OCe.forEach(t),Fko=i(UO),J1=n(UO,"LI",{});var GCe=s(J1);one=n(GCe,"STRONG",{});var WNr=s(one);Cko=r(WNr,"wav2vec2"),WNr.forEach(t),Eko=r(GCe," \u2014 "),Y$=n(GCe,"A",{href:!0});var QNr=s(Y$);Mko=r(QNr,"Wav2Vec2ForXVector"),QNr.forEach(t),yko=r(GCe," (Wav2Vec2 model)"),GCe.forEach(t),wko=i(UO),Y1=n(UO,"LI",{});var zCe=s(Y1);rne=n(zCe,"STRONG",{});var HNr=s(rne);Ako=r(HNr,"wavlm"),HNr.forEach(t),Lko=r(zCe," \u2014 "),K$=n(zCe,"A",{href:!0});var UNr=s(K$);Bko=r(UNr,"WavLMForXVector"),UNr.forEach(t),kko=r(zCe," (WavLM model)"),zCe.forEach(t),UO.forEach(t),xko=i(Ot),K1=n(Ot,"P",{});var VCe=s(K1);Rko=r(VCe,"The model is set in evaluation mode by default using "),tne=n(VCe,"CODE",{});var JNr=s(tne);Sko=r(JNr,"model.eval()"),JNr.forEach(t),Pko=r(VCe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ane=n(VCe,"CODE",{});var YNr=s(ane);$ko=r(YNr,"model.train()"),YNr.forEach(t),VCe.forEach(t),Iko=i(Ot),nne=n(Ot,"P",{});var KNr=s(nne);jko=r(KNr,"Examples:"),KNr.forEach(t),Nko=i(Ot),m(w5.$$.fragment,Ot),Ot.forEach(t),el.forEach(t),Jwe=i(d),_d=n(d,"H2",{class:!0});var J0e=s(_d);Z1=n(J0e,"A",{id:!0,class:!0,href:!0});var ZNr=s(Z1);sne=n(ZNr,"SPAN",{});var eDr=s(sne);m(A5.$$.fragment,eDr),eDr.forEach(t),ZNr.forEach(t),Dko=i(J0e),lne=n(J0e,"SPAN",{});var oDr=s(lne);qko=r(oDr,"AutoModelForObjectDetection"),oDr.forEach(t),J0e.forEach(t),Ywe=i(d),tr=n(d,"DIV",{class:!0});var rl=s(tr);m(L5.$$.fragment,rl),Oko=i(rl),vd=n(rl,"P",{});var JO=s(vd);Gko=r(JO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),ine=n(JO,"CODE",{});var rDr=s(ine);zko=r(rDr,"from_pretrained()"),rDr.forEach(t),Vko=r(JO,"class method or the "),dne=n(JO,"CODE",{});var tDr=s(dne);Xko=r(tDr,"from_config()"),tDr.forEach(t),Wko=r(JO,`class
method.`),JO.forEach(t),Qko=i(rl),B5=n(rl,"P",{});var Y0e=s(B5);Hko=r(Y0e,"This class cannot be instantiated directly using "),cne=n(Y0e,"CODE",{});var aDr=s(cne);Uko=r(aDr,"__init__()"),aDr.forEach(t),Jko=r(Y0e," (throws an error)."),Y0e.forEach(t),Yko=i(rl),Qr=n(rl,"DIV",{class:!0});var tl=s(Qr);m(k5.$$.fragment,tl),Kko=i(tl),fne=n(tl,"P",{});var nDr=s(fne);Zko=r(nDr,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),nDr.forEach(t),exo=i(tl),bd=n(tl,"P",{});var YO=s(bd);oxo=r(YO,`Note:
Loading a model from its configuration file does `),mne=n(YO,"STRONG",{});var sDr=s(mne);rxo=r(sDr,"not"),sDr.forEach(t),txo=r(YO,` load the model weights. It only affects the
model\u2019s configuration. Use `),gne=n(YO,"CODE",{});var lDr=s(gne);axo=r(lDr,"from_pretrained()"),lDr.forEach(t),nxo=r(YO,"to load the model weights."),YO.forEach(t),sxo=i(tl),hne=n(tl,"P",{});var iDr=s(hne);lxo=r(iDr,"Examples:"),iDr.forEach(t),ixo=i(tl),m(x5.$$.fragment,tl),tl.forEach(t),dxo=i(rl),Qe=n(rl,"DIV",{class:!0});var Gt=s(Qe);m(R5.$$.fragment,Gt),cxo=i(Gt),une=n(Gt,"P",{});var dDr=s(une);fxo=r(dDr,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),dDr.forEach(t),mxo=i(Gt),Xa=n(Gt,"P",{});var aE=s(Xa);gxo=r(aE,"The model class to instantiate is selected based on the "),pne=n(aE,"CODE",{});var cDr=s(pne);hxo=r(cDr,"model_type"),cDr.forEach(t),uxo=r(aE,` property of the config object (either
passed as an argument or loaded from `),_ne=n(aE,"CODE",{});var fDr=s(_ne);pxo=r(fDr,"pretrained_model_name_or_path"),fDr.forEach(t),_xo=r(aE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vne=n(aE,"CODE",{});var mDr=s(vne);vxo=r(mDr,"pretrained_model_name_or_path"),mDr.forEach(t),bxo=r(aE,":"),aE.forEach(t),Txo=i(Gt),bne=n(Gt,"UL",{});var gDr=s(bne);e4=n(gDr,"LI",{});var XCe=s(e4);Tne=n(XCe,"STRONG",{});var hDr=s(Tne);Fxo=r(hDr,"detr"),hDr.forEach(t),Cxo=r(XCe," \u2014 "),Z$=n(XCe,"A",{href:!0});var uDr=s(Z$);Exo=r(uDr,"DetrForObjectDetection"),uDr.forEach(t),Mxo=r(XCe," (DETR model)"),XCe.forEach(t),gDr.forEach(t),yxo=i(Gt),o4=n(Gt,"P",{});var WCe=s(o4);wxo=r(WCe,"The model is set in evaluation mode by default using "),Fne=n(WCe,"CODE",{});var pDr=s(Fne);Axo=r(pDr,"model.eval()"),pDr.forEach(t),Lxo=r(WCe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cne=n(WCe,"CODE",{});var _Dr=s(Cne);Bxo=r(_Dr,"model.train()"),_Dr.forEach(t),WCe.forEach(t),kxo=i(Gt),Ene=n(Gt,"P",{});var vDr=s(Ene);xxo=r(vDr,"Examples:"),vDr.forEach(t),Rxo=i(Gt),m(S5.$$.fragment,Gt),Gt.forEach(t),rl.forEach(t),Kwe=i(d),Td=n(d,"H2",{class:!0});var K0e=s(Td);r4=n(K0e,"A",{id:!0,class:!0,href:!0});var bDr=s(r4);Mne=n(bDr,"SPAN",{});var TDr=s(Mne);m(P5.$$.fragment,TDr),TDr.forEach(t),bDr.forEach(t),Sxo=i(K0e),yne=n(K0e,"SPAN",{});var FDr=s(yne);Pxo=r(FDr,"AutoModelForImageSegmentation"),FDr.forEach(t),K0e.forEach(t),Zwe=i(d),ar=n(d,"DIV",{class:!0});var al=s(ar);m($5.$$.fragment,al),$xo=i(al),Fd=n(al,"P",{});var KO=s(Fd);Ixo=r(KO,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),wne=n(KO,"CODE",{});var CDr=s(wne);jxo=r(CDr,"from_pretrained()"),CDr.forEach(t),Nxo=r(KO,"class method or the "),Ane=n(KO,"CODE",{});var EDr=s(Ane);Dxo=r(EDr,"from_config()"),EDr.forEach(t),qxo=r(KO,`class
method.`),KO.forEach(t),Oxo=i(al),I5=n(al,"P",{});var Z0e=s(I5);Gxo=r(Z0e,"This class cannot be instantiated directly using "),Lne=n(Z0e,"CODE",{});var MDr=s(Lne);zxo=r(MDr,"__init__()"),MDr.forEach(t),Vxo=r(Z0e," (throws an error)."),Z0e.forEach(t),Xxo=i(al),Hr=n(al,"DIV",{class:!0});var nl=s(Hr);m(j5.$$.fragment,nl),Wxo=i(nl),Bne=n(nl,"P",{});var yDr=s(Bne);Qxo=r(yDr,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),yDr.forEach(t),Hxo=i(nl),Cd=n(nl,"P",{});var ZO=s(Cd);Uxo=r(ZO,`Note:
Loading a model from its configuration file does `),kne=n(ZO,"STRONG",{});var wDr=s(kne);Jxo=r(wDr,"not"),wDr.forEach(t),Yxo=r(ZO,` load the model weights. It only affects the
model\u2019s configuration. Use `),xne=n(ZO,"CODE",{});var ADr=s(xne);Kxo=r(ADr,"from_pretrained()"),ADr.forEach(t),Zxo=r(ZO,"to load the model weights."),ZO.forEach(t),eRo=i(nl),Rne=n(nl,"P",{});var LDr=s(Rne);oRo=r(LDr,"Examples:"),LDr.forEach(t),rRo=i(nl),m(N5.$$.fragment,nl),nl.forEach(t),tRo=i(al),He=n(al,"DIV",{class:!0});var zt=s(He);m(D5.$$.fragment,zt),aRo=i(zt),Sne=n(zt,"P",{});var BDr=s(Sne);nRo=r(BDr,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),BDr.forEach(t),sRo=i(zt),Wa=n(zt,"P",{});var nE=s(Wa);lRo=r(nE,"The model class to instantiate is selected based on the "),Pne=n(nE,"CODE",{});var kDr=s(Pne);iRo=r(kDr,"model_type"),kDr.forEach(t),dRo=r(nE,` property of the config object (either
passed as an argument or loaded from `),$ne=n(nE,"CODE",{});var xDr=s($ne);cRo=r(xDr,"pretrained_model_name_or_path"),xDr.forEach(t),fRo=r(nE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ine=n(nE,"CODE",{});var RDr=s(Ine);mRo=r(RDr,"pretrained_model_name_or_path"),RDr.forEach(t),gRo=r(nE,":"),nE.forEach(t),hRo=i(zt),jne=n(zt,"UL",{});var SDr=s(jne);t4=n(SDr,"LI",{});var QCe=s(t4);Nne=n(QCe,"STRONG",{});var PDr=s(Nne);uRo=r(PDr,"detr"),PDr.forEach(t),pRo=r(QCe," \u2014 "),eI=n(QCe,"A",{href:!0});var $Dr=s(eI);_Ro=r($Dr,"DetrForSegmentation"),$Dr.forEach(t),vRo=r(QCe," (DETR model)"),QCe.forEach(t),SDr.forEach(t),bRo=i(zt),a4=n(zt,"P",{});var HCe=s(a4);TRo=r(HCe,"The model is set in evaluation mode by default using "),Dne=n(HCe,"CODE",{});var IDr=s(Dne);FRo=r(IDr,"model.eval()"),IDr.forEach(t),CRo=r(HCe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qne=n(HCe,"CODE",{});var jDr=s(qne);ERo=r(jDr,"model.train()"),jDr.forEach(t),HCe.forEach(t),MRo=i(zt),One=n(zt,"P",{});var NDr=s(One);yRo=r(NDr,"Examples:"),NDr.forEach(t),wRo=i(zt),m(q5.$$.fragment,zt),zt.forEach(t),al.forEach(t),eAe=i(d),Ed=n(d,"H2",{class:!0});var e7e=s(Ed);n4=n(e7e,"A",{id:!0,class:!0,href:!0});var DDr=s(n4);Gne=n(DDr,"SPAN",{});var qDr=s(Gne);m(O5.$$.fragment,qDr),qDr.forEach(t),DDr.forEach(t),ARo=i(e7e),zne=n(e7e,"SPAN",{});var ODr=s(zne);LRo=r(ODr,"TFAutoModel"),ODr.forEach(t),e7e.forEach(t),oAe=i(d),nr=n(d,"DIV",{class:!0});var sl=s(nr);m(G5.$$.fragment,sl),BRo=i(sl),Md=n(sl,"P",{});var eG=s(Md);kRo=r(eG,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Vne=n(eG,"CODE",{});var GDr=s(Vne);xRo=r(GDr,"from_pretrained()"),GDr.forEach(t),RRo=r(eG,"class method or the "),Xne=n(eG,"CODE",{});var zDr=s(Xne);SRo=r(zDr,"from_config()"),zDr.forEach(t),PRo=r(eG,`class
method.`),eG.forEach(t),$Ro=i(sl),z5=n(sl,"P",{});var o7e=s(z5);IRo=r(o7e,"This class cannot be instantiated directly using "),Wne=n(o7e,"CODE",{});var VDr=s(Wne);jRo=r(VDr,"__init__()"),VDr.forEach(t),NRo=r(o7e," (throws an error)."),o7e.forEach(t),DRo=i(sl),Ur=n(sl,"DIV",{class:!0});var ll=s(Ur);m(V5.$$.fragment,ll),qRo=i(ll),Qne=n(ll,"P",{});var XDr=s(Qne);ORo=r(XDr,"Instantiates one of the base model classes of the library from a configuration."),XDr.forEach(t),GRo=i(ll),yd=n(ll,"P",{});var oG=s(yd);zRo=r(oG,`Note:
Loading a model from its configuration file does `),Hne=n(oG,"STRONG",{});var WDr=s(Hne);VRo=r(WDr,"not"),WDr.forEach(t),XRo=r(oG,` load the model weights. It only affects the
model\u2019s configuration. Use `),Une=n(oG,"CODE",{});var QDr=s(Une);WRo=r(QDr,"from_pretrained()"),QDr.forEach(t),QRo=r(oG,"to load the model weights."),oG.forEach(t),HRo=i(ll),Jne=n(ll,"P",{});var HDr=s(Jne);URo=r(HDr,"Examples:"),HDr.forEach(t),JRo=i(ll),m(X5.$$.fragment,ll),ll.forEach(t),YRo=i(sl),co=n(sl,"DIV",{class:!0});var Zt=s(co);m(W5.$$.fragment,Zt),KRo=i(Zt),Yne=n(Zt,"P",{});var UDr=s(Yne);ZRo=r(UDr,"Instantiate one of the base model classes of the library from a pretrained model."),UDr.forEach(t),eSo=i(Zt),Qa=n(Zt,"P",{});var sE=s(Qa);oSo=r(sE,"The model class to instantiate is selected based on the "),Kne=n(sE,"CODE",{});var JDr=s(Kne);rSo=r(JDr,"model_type"),JDr.forEach(t),tSo=r(sE,` property of the config object (either
passed as an argument or loaded from `),Zne=n(sE,"CODE",{});var YDr=s(Zne);aSo=r(YDr,"pretrained_model_name_or_path"),YDr.forEach(t),nSo=r(sE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ese=n(sE,"CODE",{});var KDr=s(ese);sSo=r(KDr,"pretrained_model_name_or_path"),KDr.forEach(t),lSo=r(sE,":"),sE.forEach(t),iSo=i(Zt),B=n(Zt,"UL",{});var k=s(B);s4=n(k,"LI",{});var UCe=s(s4);ose=n(UCe,"STRONG",{});var ZDr=s(ose);dSo=r(ZDr,"albert"),ZDr.forEach(t),cSo=r(UCe," \u2014 "),oI=n(UCe,"A",{href:!0});var eqr=s(oI);fSo=r(eqr,"TFAlbertModel"),eqr.forEach(t),mSo=r(UCe," (ALBERT model)"),UCe.forEach(t),gSo=i(k),l4=n(k,"LI",{});var JCe=s(l4);rse=n(JCe,"STRONG",{});var oqr=s(rse);hSo=r(oqr,"bart"),oqr.forEach(t),uSo=r(JCe," \u2014 "),rI=n(JCe,"A",{href:!0});var rqr=s(rI);pSo=r(rqr,"TFBartModel"),rqr.forEach(t),_So=r(JCe," (BART model)"),JCe.forEach(t),vSo=i(k),i4=n(k,"LI",{});var YCe=s(i4);tse=n(YCe,"STRONG",{});var tqr=s(tse);bSo=r(tqr,"bert"),tqr.forEach(t),TSo=r(YCe," \u2014 "),tI=n(YCe,"A",{href:!0});var aqr=s(tI);FSo=r(aqr,"TFBertModel"),aqr.forEach(t),CSo=r(YCe," (BERT model)"),YCe.forEach(t),ESo=i(k),d4=n(k,"LI",{});var KCe=s(d4);ase=n(KCe,"STRONG",{});var nqr=s(ase);MSo=r(nqr,"blenderbot"),nqr.forEach(t),ySo=r(KCe," \u2014 "),aI=n(KCe,"A",{href:!0});var sqr=s(aI);wSo=r(sqr,"TFBlenderbotModel"),sqr.forEach(t),ASo=r(KCe," (Blenderbot model)"),KCe.forEach(t),LSo=i(k),c4=n(k,"LI",{});var ZCe=s(c4);nse=n(ZCe,"STRONG",{});var lqr=s(nse);BSo=r(lqr,"blenderbot-small"),lqr.forEach(t),kSo=r(ZCe," \u2014 "),nI=n(ZCe,"A",{href:!0});var iqr=s(nI);xSo=r(iqr,"TFBlenderbotSmallModel"),iqr.forEach(t),RSo=r(ZCe," (BlenderbotSmall model)"),ZCe.forEach(t),SSo=i(k),f4=n(k,"LI",{});var eEe=s(f4);sse=n(eEe,"STRONG",{});var dqr=s(sse);PSo=r(dqr,"camembert"),dqr.forEach(t),$So=r(eEe," \u2014 "),sI=n(eEe,"A",{href:!0});var cqr=s(sI);ISo=r(cqr,"TFCamembertModel"),cqr.forEach(t),jSo=r(eEe," (CamemBERT model)"),eEe.forEach(t),NSo=i(k),m4=n(k,"LI",{});var oEe=s(m4);lse=n(oEe,"STRONG",{});var fqr=s(lse);DSo=r(fqr,"clip"),fqr.forEach(t),qSo=r(oEe," \u2014 "),lI=n(oEe,"A",{href:!0});var mqr=s(lI);OSo=r(mqr,"TFCLIPModel"),mqr.forEach(t),GSo=r(oEe," (CLIP model)"),oEe.forEach(t),zSo=i(k),g4=n(k,"LI",{});var rEe=s(g4);ise=n(rEe,"STRONG",{});var gqr=s(ise);VSo=r(gqr,"convbert"),gqr.forEach(t),XSo=r(rEe," \u2014 "),iI=n(rEe,"A",{href:!0});var hqr=s(iI);WSo=r(hqr,"TFConvBertModel"),hqr.forEach(t),QSo=r(rEe," (ConvBERT model)"),rEe.forEach(t),HSo=i(k),h4=n(k,"LI",{});var tEe=s(h4);dse=n(tEe,"STRONG",{});var uqr=s(dse);USo=r(uqr,"ctrl"),uqr.forEach(t),JSo=r(tEe," \u2014 "),dI=n(tEe,"A",{href:!0});var pqr=s(dI);YSo=r(pqr,"TFCTRLModel"),pqr.forEach(t),KSo=r(tEe," (CTRL model)"),tEe.forEach(t),ZSo=i(k),u4=n(k,"LI",{});var aEe=s(u4);cse=n(aEe,"STRONG",{});var _qr=s(cse);ePo=r(_qr,"deberta"),_qr.forEach(t),oPo=r(aEe," \u2014 "),cI=n(aEe,"A",{href:!0});var vqr=s(cI);rPo=r(vqr,"TFDebertaModel"),vqr.forEach(t),tPo=r(aEe," (DeBERTa model)"),aEe.forEach(t),aPo=i(k),p4=n(k,"LI",{});var nEe=s(p4);fse=n(nEe,"STRONG",{});var bqr=s(fse);nPo=r(bqr,"deberta-v2"),bqr.forEach(t),sPo=r(nEe," \u2014 "),fI=n(nEe,"A",{href:!0});var Tqr=s(fI);lPo=r(Tqr,"TFDebertaV2Model"),Tqr.forEach(t),iPo=r(nEe," (DeBERTa-v2 model)"),nEe.forEach(t),dPo=i(k),_4=n(k,"LI",{});var sEe=s(_4);mse=n(sEe,"STRONG",{});var Fqr=s(mse);cPo=r(Fqr,"distilbert"),Fqr.forEach(t),fPo=r(sEe," \u2014 "),mI=n(sEe,"A",{href:!0});var Cqr=s(mI);mPo=r(Cqr,"TFDistilBertModel"),Cqr.forEach(t),gPo=r(sEe," (DistilBERT model)"),sEe.forEach(t),hPo=i(k),v4=n(k,"LI",{});var lEe=s(v4);gse=n(lEe,"STRONG",{});var Eqr=s(gse);uPo=r(Eqr,"dpr"),Eqr.forEach(t),pPo=r(lEe," \u2014 "),gI=n(lEe,"A",{href:!0});var Mqr=s(gI);_Po=r(Mqr,"TFDPRQuestionEncoder"),Mqr.forEach(t),vPo=r(lEe," (DPR model)"),lEe.forEach(t),bPo=i(k),b4=n(k,"LI",{});var iEe=s(b4);hse=n(iEe,"STRONG",{});var yqr=s(hse);TPo=r(yqr,"electra"),yqr.forEach(t),FPo=r(iEe," \u2014 "),hI=n(iEe,"A",{href:!0});var wqr=s(hI);CPo=r(wqr,"TFElectraModel"),wqr.forEach(t),EPo=r(iEe," (ELECTRA model)"),iEe.forEach(t),MPo=i(k),T4=n(k,"LI",{});var dEe=s(T4);use=n(dEe,"STRONG",{});var Aqr=s(use);yPo=r(Aqr,"flaubert"),Aqr.forEach(t),wPo=r(dEe," \u2014 "),uI=n(dEe,"A",{href:!0});var Lqr=s(uI);APo=r(Lqr,"TFFlaubertModel"),Lqr.forEach(t),LPo=r(dEe," (FlauBERT model)"),dEe.forEach(t),BPo=i(k),ps=n(k,"LI",{});var G0=s(ps);pse=n(G0,"STRONG",{});var Bqr=s(pse);kPo=r(Bqr,"funnel"),Bqr.forEach(t),xPo=r(G0," \u2014 "),pI=n(G0,"A",{href:!0});var kqr=s(pI);RPo=r(kqr,"TFFunnelModel"),kqr.forEach(t),SPo=r(G0," or "),_I=n(G0,"A",{href:!0});var xqr=s(_I);PPo=r(xqr,"TFFunnelBaseModel"),xqr.forEach(t),$Po=r(G0," (Funnel Transformer model)"),G0.forEach(t),IPo=i(k),F4=n(k,"LI",{});var cEe=s(F4);_se=n(cEe,"STRONG",{});var Rqr=s(_se);jPo=r(Rqr,"gpt2"),Rqr.forEach(t),NPo=r(cEe," \u2014 "),vI=n(cEe,"A",{href:!0});var Sqr=s(vI);DPo=r(Sqr,"TFGPT2Model"),Sqr.forEach(t),qPo=r(cEe," (OpenAI GPT-2 model)"),cEe.forEach(t),OPo=i(k),C4=n(k,"LI",{});var fEe=s(C4);vse=n(fEe,"STRONG",{});var Pqr=s(vse);GPo=r(Pqr,"hubert"),Pqr.forEach(t),zPo=r(fEe," \u2014 "),bI=n(fEe,"A",{href:!0});var $qr=s(bI);VPo=r($qr,"TFHubertModel"),$qr.forEach(t),XPo=r(fEe," (Hubert model)"),fEe.forEach(t),WPo=i(k),E4=n(k,"LI",{});var mEe=s(E4);bse=n(mEe,"STRONG",{});var Iqr=s(bse);QPo=r(Iqr,"layoutlm"),Iqr.forEach(t),HPo=r(mEe," \u2014 "),TI=n(mEe,"A",{href:!0});var jqr=s(TI);UPo=r(jqr,"TFLayoutLMModel"),jqr.forEach(t),JPo=r(mEe," (LayoutLM model)"),mEe.forEach(t),YPo=i(k),M4=n(k,"LI",{});var gEe=s(M4);Tse=n(gEe,"STRONG",{});var Nqr=s(Tse);KPo=r(Nqr,"led"),Nqr.forEach(t),ZPo=r(gEe," \u2014 "),FI=n(gEe,"A",{href:!0});var Dqr=s(FI);e$o=r(Dqr,"TFLEDModel"),Dqr.forEach(t),o$o=r(gEe," (LED model)"),gEe.forEach(t),r$o=i(k),y4=n(k,"LI",{});var hEe=s(y4);Fse=n(hEe,"STRONG",{});var qqr=s(Fse);t$o=r(qqr,"longformer"),qqr.forEach(t),a$o=r(hEe," \u2014 "),CI=n(hEe,"A",{href:!0});var Oqr=s(CI);n$o=r(Oqr,"TFLongformerModel"),Oqr.forEach(t),s$o=r(hEe," (Longformer model)"),hEe.forEach(t),l$o=i(k),w4=n(k,"LI",{});var uEe=s(w4);Cse=n(uEe,"STRONG",{});var Gqr=s(Cse);i$o=r(Gqr,"lxmert"),Gqr.forEach(t),d$o=r(uEe," \u2014 "),EI=n(uEe,"A",{href:!0});var zqr=s(EI);c$o=r(zqr,"TFLxmertModel"),zqr.forEach(t),f$o=r(uEe," (LXMERT model)"),uEe.forEach(t),m$o=i(k),A4=n(k,"LI",{});var pEe=s(A4);Ese=n(pEe,"STRONG",{});var Vqr=s(Ese);g$o=r(Vqr,"marian"),Vqr.forEach(t),h$o=r(pEe," \u2014 "),MI=n(pEe,"A",{href:!0});var Xqr=s(MI);u$o=r(Xqr,"TFMarianModel"),Xqr.forEach(t),p$o=r(pEe," (Marian model)"),pEe.forEach(t),_$o=i(k),L4=n(k,"LI",{});var _Ee=s(L4);Mse=n(_Ee,"STRONG",{});var Wqr=s(Mse);v$o=r(Wqr,"mbart"),Wqr.forEach(t),b$o=r(_Ee," \u2014 "),yI=n(_Ee,"A",{href:!0});var Qqr=s(yI);T$o=r(Qqr,"TFMBartModel"),Qqr.forEach(t),F$o=r(_Ee," (mBART model)"),_Ee.forEach(t),C$o=i(k),B4=n(k,"LI",{});var vEe=s(B4);yse=n(vEe,"STRONG",{});var Hqr=s(yse);E$o=r(Hqr,"mobilebert"),Hqr.forEach(t),M$o=r(vEe," \u2014 "),wI=n(vEe,"A",{href:!0});var Uqr=s(wI);y$o=r(Uqr,"TFMobileBertModel"),Uqr.forEach(t),w$o=r(vEe," (MobileBERT model)"),vEe.forEach(t),A$o=i(k),k4=n(k,"LI",{});var bEe=s(k4);wse=n(bEe,"STRONG",{});var Jqr=s(wse);L$o=r(Jqr,"mpnet"),Jqr.forEach(t),B$o=r(bEe," \u2014 "),AI=n(bEe,"A",{href:!0});var Yqr=s(AI);k$o=r(Yqr,"TFMPNetModel"),Yqr.forEach(t),x$o=r(bEe," (MPNet model)"),bEe.forEach(t),R$o=i(k),x4=n(k,"LI",{});var TEe=s(x4);Ase=n(TEe,"STRONG",{});var Kqr=s(Ase);S$o=r(Kqr,"mt5"),Kqr.forEach(t),P$o=r(TEe," \u2014 "),LI=n(TEe,"A",{href:!0});var Zqr=s(LI);$$o=r(Zqr,"TFMT5Model"),Zqr.forEach(t),I$o=r(TEe," (mT5 model)"),TEe.forEach(t),j$o=i(k),R4=n(k,"LI",{});var FEe=s(R4);Lse=n(FEe,"STRONG",{});var eOr=s(Lse);N$o=r(eOr,"openai-gpt"),eOr.forEach(t),D$o=r(FEe," \u2014 "),BI=n(FEe,"A",{href:!0});var oOr=s(BI);q$o=r(oOr,"TFOpenAIGPTModel"),oOr.forEach(t),O$o=r(FEe," (OpenAI GPT model)"),FEe.forEach(t),G$o=i(k),S4=n(k,"LI",{});var CEe=s(S4);Bse=n(CEe,"STRONG",{});var rOr=s(Bse);z$o=r(rOr,"pegasus"),rOr.forEach(t),V$o=r(CEe," \u2014 "),kI=n(CEe,"A",{href:!0});var tOr=s(kI);X$o=r(tOr,"TFPegasusModel"),tOr.forEach(t),W$o=r(CEe," (Pegasus model)"),CEe.forEach(t),Q$o=i(k),P4=n(k,"LI",{});var EEe=s(P4);kse=n(EEe,"STRONG",{});var aOr=s(kse);H$o=r(aOr,"rembert"),aOr.forEach(t),U$o=r(EEe," \u2014 "),xI=n(EEe,"A",{href:!0});var nOr=s(xI);J$o=r(nOr,"TFRemBertModel"),nOr.forEach(t),Y$o=r(EEe," (RemBERT model)"),EEe.forEach(t),K$o=i(k),$4=n(k,"LI",{});var MEe=s($4);xse=n(MEe,"STRONG",{});var sOr=s(xse);Z$o=r(sOr,"roberta"),sOr.forEach(t),eIo=r(MEe," \u2014 "),RI=n(MEe,"A",{href:!0});var lOr=s(RI);oIo=r(lOr,"TFRobertaModel"),lOr.forEach(t),rIo=r(MEe," (RoBERTa model)"),MEe.forEach(t),tIo=i(k),I4=n(k,"LI",{});var yEe=s(I4);Rse=n(yEe,"STRONG",{});var iOr=s(Rse);aIo=r(iOr,"roformer"),iOr.forEach(t),nIo=r(yEe," \u2014 "),SI=n(yEe,"A",{href:!0});var dOr=s(SI);sIo=r(dOr,"TFRoFormerModel"),dOr.forEach(t),lIo=r(yEe," (RoFormer model)"),yEe.forEach(t),iIo=i(k),j4=n(k,"LI",{});var wEe=s(j4);Sse=n(wEe,"STRONG",{});var cOr=s(Sse);dIo=r(cOr,"t5"),cOr.forEach(t),cIo=r(wEe," \u2014 "),PI=n(wEe,"A",{href:!0});var fOr=s(PI);fIo=r(fOr,"TFT5Model"),fOr.forEach(t),mIo=r(wEe," (T5 model)"),wEe.forEach(t),gIo=i(k),N4=n(k,"LI",{});var AEe=s(N4);Pse=n(AEe,"STRONG",{});var mOr=s(Pse);hIo=r(mOr,"tapas"),mOr.forEach(t),uIo=r(AEe," \u2014 "),$I=n(AEe,"A",{href:!0});var gOr=s($I);pIo=r(gOr,"TFTapasModel"),gOr.forEach(t),_Io=r(AEe," (TAPAS model)"),AEe.forEach(t),vIo=i(k),D4=n(k,"LI",{});var LEe=s(D4);$se=n(LEe,"STRONG",{});var hOr=s($se);bIo=r(hOr,"transfo-xl"),hOr.forEach(t),TIo=r(LEe," \u2014 "),II=n(LEe,"A",{href:!0});var uOr=s(II);FIo=r(uOr,"TFTransfoXLModel"),uOr.forEach(t),CIo=r(LEe," (Transformer-XL model)"),LEe.forEach(t),EIo=i(k),q4=n(k,"LI",{});var BEe=s(q4);Ise=n(BEe,"STRONG",{});var pOr=s(Ise);MIo=r(pOr,"vit"),pOr.forEach(t),yIo=r(BEe," \u2014 "),jI=n(BEe,"A",{href:!0});var _Or=s(jI);wIo=r(_Or,"TFViTModel"),_Or.forEach(t),AIo=r(BEe," (ViT model)"),BEe.forEach(t),LIo=i(k),O4=n(k,"LI",{});var kEe=s(O4);jse=n(kEe,"STRONG",{});var vOr=s(jse);BIo=r(vOr,"wav2vec2"),vOr.forEach(t),kIo=r(kEe," \u2014 "),NI=n(kEe,"A",{href:!0});var bOr=s(NI);xIo=r(bOr,"TFWav2Vec2Model"),bOr.forEach(t),RIo=r(kEe," (Wav2Vec2 model)"),kEe.forEach(t),SIo=i(k),G4=n(k,"LI",{});var xEe=s(G4);Nse=n(xEe,"STRONG",{});var TOr=s(Nse);PIo=r(TOr,"xlm"),TOr.forEach(t),$Io=r(xEe," \u2014 "),DI=n(xEe,"A",{href:!0});var FOr=s(DI);IIo=r(FOr,"TFXLMModel"),FOr.forEach(t),jIo=r(xEe," (XLM model)"),xEe.forEach(t),NIo=i(k),z4=n(k,"LI",{});var REe=s(z4);Dse=n(REe,"STRONG",{});var COr=s(Dse);DIo=r(COr,"xlm-roberta"),COr.forEach(t),qIo=r(REe," \u2014 "),qI=n(REe,"A",{href:!0});var EOr=s(qI);OIo=r(EOr,"TFXLMRobertaModel"),EOr.forEach(t),GIo=r(REe," (XLM-RoBERTa model)"),REe.forEach(t),zIo=i(k),V4=n(k,"LI",{});var SEe=s(V4);qse=n(SEe,"STRONG",{});var MOr=s(qse);VIo=r(MOr,"xlnet"),MOr.forEach(t),XIo=r(SEe," \u2014 "),OI=n(SEe,"A",{href:!0});var yOr=s(OI);WIo=r(yOr,"TFXLNetModel"),yOr.forEach(t),QIo=r(SEe," (XLNet model)"),SEe.forEach(t),k.forEach(t),HIo=i(Zt),Ose=n(Zt,"P",{});var wOr=s(Ose);UIo=r(wOr,"Examples:"),wOr.forEach(t),JIo=i(Zt),m(Q5.$$.fragment,Zt),Zt.forEach(t),sl.forEach(t),rAe=i(d),wd=n(d,"H2",{class:!0});var r7e=s(wd);X4=n(r7e,"A",{id:!0,class:!0,href:!0});var AOr=s(X4);Gse=n(AOr,"SPAN",{});var LOr=s(Gse);m(H5.$$.fragment,LOr),LOr.forEach(t),AOr.forEach(t),YIo=i(r7e),zse=n(r7e,"SPAN",{});var BOr=s(zse);KIo=r(BOr,"TFAutoModelForPreTraining"),BOr.forEach(t),r7e.forEach(t),tAe=i(d),sr=n(d,"DIV",{class:!0});var il=s(sr);m(U5.$$.fragment,il),ZIo=i(il),Ad=n(il,"P",{});var rG=s(Ad);ejo=r(rG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Vse=n(rG,"CODE",{});var kOr=s(Vse);ojo=r(kOr,"from_pretrained()"),kOr.forEach(t),rjo=r(rG,"class method or the "),Xse=n(rG,"CODE",{});var xOr=s(Xse);tjo=r(xOr,"from_config()"),xOr.forEach(t),ajo=r(rG,`class
method.`),rG.forEach(t),njo=i(il),J5=n(il,"P",{});var t7e=s(J5);sjo=r(t7e,"This class cannot be instantiated directly using "),Wse=n(t7e,"CODE",{});var ROr=s(Wse);ljo=r(ROr,"__init__()"),ROr.forEach(t),ijo=r(t7e," (throws an error)."),t7e.forEach(t),djo=i(il),Jr=n(il,"DIV",{class:!0});var dl=s(Jr);m(Y5.$$.fragment,dl),cjo=i(dl),Qse=n(dl,"P",{});var SOr=s(Qse);fjo=r(SOr,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),SOr.forEach(t),mjo=i(dl),Ld=n(dl,"P",{});var tG=s(Ld);gjo=r(tG,`Note:
Loading a model from its configuration file does `),Hse=n(tG,"STRONG",{});var POr=s(Hse);hjo=r(POr,"not"),POr.forEach(t),ujo=r(tG,` load the model weights. It only affects the
model\u2019s configuration. Use `),Use=n(tG,"CODE",{});var $Or=s(Use);pjo=r($Or,"from_pretrained()"),$Or.forEach(t),_jo=r(tG,"to load the model weights."),tG.forEach(t),vjo=i(dl),Jse=n(dl,"P",{});var IOr=s(Jse);bjo=r(IOr,"Examples:"),IOr.forEach(t),Tjo=i(dl),m(K5.$$.fragment,dl),dl.forEach(t),Fjo=i(il),fo=n(il,"DIV",{class:!0});var ea=s(fo);m(Z5.$$.fragment,ea),Cjo=i(ea),Yse=n(ea,"P",{});var jOr=s(Yse);Ejo=r(jOr,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),jOr.forEach(t),Mjo=i(ea),Ha=n(ea,"P",{});var lE=s(Ha);yjo=r(lE,"The model class to instantiate is selected based on the "),Kse=n(lE,"CODE",{});var NOr=s(Kse);wjo=r(NOr,"model_type"),NOr.forEach(t),Ajo=r(lE,` property of the config object (either
passed as an argument or loaded from `),Zse=n(lE,"CODE",{});var DOr=s(Zse);Ljo=r(DOr,"pretrained_model_name_or_path"),DOr.forEach(t),Bjo=r(lE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ele=n(lE,"CODE",{});var qOr=s(ele);kjo=r(qOr,"pretrained_model_name_or_path"),qOr.forEach(t),xjo=r(lE,":"),lE.forEach(t),Rjo=i(ea),Q=n(ea,"UL",{});var U=s(Q);W4=n(U,"LI",{});var PEe=s(W4);ole=n(PEe,"STRONG",{});var OOr=s(ole);Sjo=r(OOr,"albert"),OOr.forEach(t),Pjo=r(PEe," \u2014 "),GI=n(PEe,"A",{href:!0});var GOr=s(GI);$jo=r(GOr,"TFAlbertForPreTraining"),GOr.forEach(t),Ijo=r(PEe," (ALBERT model)"),PEe.forEach(t),jjo=i(U),Q4=n(U,"LI",{});var $Ee=s(Q4);rle=n($Ee,"STRONG",{});var zOr=s(rle);Njo=r(zOr,"bart"),zOr.forEach(t),Djo=r($Ee," \u2014 "),zI=n($Ee,"A",{href:!0});var VOr=s(zI);qjo=r(VOr,"TFBartForConditionalGeneration"),VOr.forEach(t),Ojo=r($Ee," (BART model)"),$Ee.forEach(t),Gjo=i(U),H4=n(U,"LI",{});var IEe=s(H4);tle=n(IEe,"STRONG",{});var XOr=s(tle);zjo=r(XOr,"bert"),XOr.forEach(t),Vjo=r(IEe," \u2014 "),VI=n(IEe,"A",{href:!0});var WOr=s(VI);Xjo=r(WOr,"TFBertForPreTraining"),WOr.forEach(t),Wjo=r(IEe," (BERT model)"),IEe.forEach(t),Qjo=i(U),U4=n(U,"LI",{});var jEe=s(U4);ale=n(jEe,"STRONG",{});var QOr=s(ale);Hjo=r(QOr,"camembert"),QOr.forEach(t),Ujo=r(jEe," \u2014 "),XI=n(jEe,"A",{href:!0});var HOr=s(XI);Jjo=r(HOr,"TFCamembertForMaskedLM"),HOr.forEach(t),Yjo=r(jEe," (CamemBERT model)"),jEe.forEach(t),Kjo=i(U),J4=n(U,"LI",{});var NEe=s(J4);nle=n(NEe,"STRONG",{});var UOr=s(nle);Zjo=r(UOr,"ctrl"),UOr.forEach(t),eNo=r(NEe," \u2014 "),WI=n(NEe,"A",{href:!0});var JOr=s(WI);oNo=r(JOr,"TFCTRLLMHeadModel"),JOr.forEach(t),rNo=r(NEe," (CTRL model)"),NEe.forEach(t),tNo=i(U),Y4=n(U,"LI",{});var DEe=s(Y4);sle=n(DEe,"STRONG",{});var YOr=s(sle);aNo=r(YOr,"distilbert"),YOr.forEach(t),nNo=r(DEe," \u2014 "),QI=n(DEe,"A",{href:!0});var KOr=s(QI);sNo=r(KOr,"TFDistilBertForMaskedLM"),KOr.forEach(t),lNo=r(DEe," (DistilBERT model)"),DEe.forEach(t),iNo=i(U),K4=n(U,"LI",{});var qEe=s(K4);lle=n(qEe,"STRONG",{});var ZOr=s(lle);dNo=r(ZOr,"electra"),ZOr.forEach(t),cNo=r(qEe," \u2014 "),HI=n(qEe,"A",{href:!0});var eGr=s(HI);fNo=r(eGr,"TFElectraForPreTraining"),eGr.forEach(t),mNo=r(qEe," (ELECTRA model)"),qEe.forEach(t),gNo=i(U),Z4=n(U,"LI",{});var OEe=s(Z4);ile=n(OEe,"STRONG",{});var oGr=s(ile);hNo=r(oGr,"flaubert"),oGr.forEach(t),uNo=r(OEe," \u2014 "),UI=n(OEe,"A",{href:!0});var rGr=s(UI);pNo=r(rGr,"TFFlaubertWithLMHeadModel"),rGr.forEach(t),_No=r(OEe," (FlauBERT model)"),OEe.forEach(t),vNo=i(U),eb=n(U,"LI",{});var GEe=s(eb);dle=n(GEe,"STRONG",{});var tGr=s(dle);bNo=r(tGr,"funnel"),tGr.forEach(t),TNo=r(GEe," \u2014 "),JI=n(GEe,"A",{href:!0});var aGr=s(JI);FNo=r(aGr,"TFFunnelForPreTraining"),aGr.forEach(t),CNo=r(GEe," (Funnel Transformer model)"),GEe.forEach(t),ENo=i(U),ob=n(U,"LI",{});var zEe=s(ob);cle=n(zEe,"STRONG",{});var nGr=s(cle);MNo=r(nGr,"gpt2"),nGr.forEach(t),yNo=r(zEe," \u2014 "),YI=n(zEe,"A",{href:!0});var sGr=s(YI);wNo=r(sGr,"TFGPT2LMHeadModel"),sGr.forEach(t),ANo=r(zEe," (OpenAI GPT-2 model)"),zEe.forEach(t),LNo=i(U),rb=n(U,"LI",{});var VEe=s(rb);fle=n(VEe,"STRONG",{});var lGr=s(fle);BNo=r(lGr,"layoutlm"),lGr.forEach(t),kNo=r(VEe," \u2014 "),KI=n(VEe,"A",{href:!0});var iGr=s(KI);xNo=r(iGr,"TFLayoutLMForMaskedLM"),iGr.forEach(t),RNo=r(VEe," (LayoutLM model)"),VEe.forEach(t),SNo=i(U),tb=n(U,"LI",{});var XEe=s(tb);mle=n(XEe,"STRONG",{});var dGr=s(mle);PNo=r(dGr,"lxmert"),dGr.forEach(t),$No=r(XEe," \u2014 "),ZI=n(XEe,"A",{href:!0});var cGr=s(ZI);INo=r(cGr,"TFLxmertForPreTraining"),cGr.forEach(t),jNo=r(XEe," (LXMERT model)"),XEe.forEach(t),NNo=i(U),ab=n(U,"LI",{});var WEe=s(ab);gle=n(WEe,"STRONG",{});var fGr=s(gle);DNo=r(fGr,"mobilebert"),fGr.forEach(t),qNo=r(WEe," \u2014 "),ej=n(WEe,"A",{href:!0});var mGr=s(ej);ONo=r(mGr,"TFMobileBertForPreTraining"),mGr.forEach(t),GNo=r(WEe," (MobileBERT model)"),WEe.forEach(t),zNo=i(U),nb=n(U,"LI",{});var QEe=s(nb);hle=n(QEe,"STRONG",{});var gGr=s(hle);VNo=r(gGr,"mpnet"),gGr.forEach(t),XNo=r(QEe," \u2014 "),oj=n(QEe,"A",{href:!0});var hGr=s(oj);WNo=r(hGr,"TFMPNetForMaskedLM"),hGr.forEach(t),QNo=r(QEe," (MPNet model)"),QEe.forEach(t),HNo=i(U),sb=n(U,"LI",{});var HEe=s(sb);ule=n(HEe,"STRONG",{});var uGr=s(ule);UNo=r(uGr,"openai-gpt"),uGr.forEach(t),JNo=r(HEe," \u2014 "),rj=n(HEe,"A",{href:!0});var pGr=s(rj);YNo=r(pGr,"TFOpenAIGPTLMHeadModel"),pGr.forEach(t),KNo=r(HEe," (OpenAI GPT model)"),HEe.forEach(t),ZNo=i(U),lb=n(U,"LI",{});var UEe=s(lb);ple=n(UEe,"STRONG",{});var _Gr=s(ple);eDo=r(_Gr,"roberta"),_Gr.forEach(t),oDo=r(UEe," \u2014 "),tj=n(UEe,"A",{href:!0});var vGr=s(tj);rDo=r(vGr,"TFRobertaForMaskedLM"),vGr.forEach(t),tDo=r(UEe," (RoBERTa model)"),UEe.forEach(t),aDo=i(U),ib=n(U,"LI",{});var JEe=s(ib);_le=n(JEe,"STRONG",{});var bGr=s(_le);nDo=r(bGr,"t5"),bGr.forEach(t),sDo=r(JEe," \u2014 "),aj=n(JEe,"A",{href:!0});var TGr=s(aj);lDo=r(TGr,"TFT5ForConditionalGeneration"),TGr.forEach(t),iDo=r(JEe," (T5 model)"),JEe.forEach(t),dDo=i(U),db=n(U,"LI",{});var YEe=s(db);vle=n(YEe,"STRONG",{});var FGr=s(vle);cDo=r(FGr,"tapas"),FGr.forEach(t),fDo=r(YEe," \u2014 "),nj=n(YEe,"A",{href:!0});var CGr=s(nj);mDo=r(CGr,"TFTapasForMaskedLM"),CGr.forEach(t),gDo=r(YEe," (TAPAS model)"),YEe.forEach(t),hDo=i(U),cb=n(U,"LI",{});var KEe=s(cb);ble=n(KEe,"STRONG",{});var EGr=s(ble);uDo=r(EGr,"transfo-xl"),EGr.forEach(t),pDo=r(KEe," \u2014 "),sj=n(KEe,"A",{href:!0});var MGr=s(sj);_Do=r(MGr,"TFTransfoXLLMHeadModel"),MGr.forEach(t),vDo=r(KEe," (Transformer-XL model)"),KEe.forEach(t),bDo=i(U),fb=n(U,"LI",{});var ZEe=s(fb);Tle=n(ZEe,"STRONG",{});var yGr=s(Tle);TDo=r(yGr,"xlm"),yGr.forEach(t),FDo=r(ZEe," \u2014 "),lj=n(ZEe,"A",{href:!0});var wGr=s(lj);CDo=r(wGr,"TFXLMWithLMHeadModel"),wGr.forEach(t),EDo=r(ZEe," (XLM model)"),ZEe.forEach(t),MDo=i(U),mb=n(U,"LI",{});var eMe=s(mb);Fle=n(eMe,"STRONG",{});var AGr=s(Fle);yDo=r(AGr,"xlm-roberta"),AGr.forEach(t),wDo=r(eMe," \u2014 "),ij=n(eMe,"A",{href:!0});var LGr=s(ij);ADo=r(LGr,"TFXLMRobertaForMaskedLM"),LGr.forEach(t),LDo=r(eMe," (XLM-RoBERTa model)"),eMe.forEach(t),BDo=i(U),gb=n(U,"LI",{});var oMe=s(gb);Cle=n(oMe,"STRONG",{});var BGr=s(Cle);kDo=r(BGr,"xlnet"),BGr.forEach(t),xDo=r(oMe," \u2014 "),dj=n(oMe,"A",{href:!0});var kGr=s(dj);RDo=r(kGr,"TFXLNetLMHeadModel"),kGr.forEach(t),SDo=r(oMe," (XLNet model)"),oMe.forEach(t),U.forEach(t),PDo=i(ea),Ele=n(ea,"P",{});var xGr=s(Ele);$Do=r(xGr,"Examples:"),xGr.forEach(t),IDo=i(ea),m(ey.$$.fragment,ea),ea.forEach(t),il.forEach(t),aAe=i(d),Bd=n(d,"H2",{class:!0});var a7e=s(Bd);hb=n(a7e,"A",{id:!0,class:!0,href:!0});var RGr=s(hb);Mle=n(RGr,"SPAN",{});var SGr=s(Mle);m(oy.$$.fragment,SGr),SGr.forEach(t),RGr.forEach(t),jDo=i(a7e),yle=n(a7e,"SPAN",{});var PGr=s(yle);NDo=r(PGr,"TFAutoModelForCausalLM"),PGr.forEach(t),a7e.forEach(t),nAe=i(d),lr=n(d,"DIV",{class:!0});var cl=s(lr);m(ry.$$.fragment,cl),DDo=i(cl),kd=n(cl,"P",{});var aG=s(kd);qDo=r(aG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wle=n(aG,"CODE",{});var $Gr=s(wle);ODo=r($Gr,"from_pretrained()"),$Gr.forEach(t),GDo=r(aG,"class method or the "),Ale=n(aG,"CODE",{});var IGr=s(Ale);zDo=r(IGr,"from_config()"),IGr.forEach(t),VDo=r(aG,`class
method.`),aG.forEach(t),XDo=i(cl),ty=n(cl,"P",{});var n7e=s(ty);WDo=r(n7e,"This class cannot be instantiated directly using "),Lle=n(n7e,"CODE",{});var jGr=s(Lle);QDo=r(jGr,"__init__()"),jGr.forEach(t),HDo=r(n7e," (throws an error)."),n7e.forEach(t),UDo=i(cl),Yr=n(cl,"DIV",{class:!0});var fl=s(Yr);m(ay.$$.fragment,fl),JDo=i(fl),Ble=n(fl,"P",{});var NGr=s(Ble);YDo=r(NGr,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),NGr.forEach(t),KDo=i(fl),xd=n(fl,"P",{});var nG=s(xd);ZDo=r(nG,`Note:
Loading a model from its configuration file does `),kle=n(nG,"STRONG",{});var DGr=s(kle);eqo=r(DGr,"not"),DGr.forEach(t),oqo=r(nG,` load the model weights. It only affects the
model\u2019s configuration. Use `),xle=n(nG,"CODE",{});var qGr=s(xle);rqo=r(qGr,"from_pretrained()"),qGr.forEach(t),tqo=r(nG,"to load the model weights."),nG.forEach(t),aqo=i(fl),Rle=n(fl,"P",{});var OGr=s(Rle);nqo=r(OGr,"Examples:"),OGr.forEach(t),sqo=i(fl),m(ny.$$.fragment,fl),fl.forEach(t),lqo=i(cl),mo=n(cl,"DIV",{class:!0});var oa=s(mo);m(sy.$$.fragment,oa),iqo=i(oa),Sle=n(oa,"P",{});var GGr=s(Sle);dqo=r(GGr,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),GGr.forEach(t),cqo=i(oa),Ua=n(oa,"P",{});var iE=s(Ua);fqo=r(iE,"The model class to instantiate is selected based on the "),Ple=n(iE,"CODE",{});var zGr=s(Ple);mqo=r(zGr,"model_type"),zGr.forEach(t),gqo=r(iE,` property of the config object (either
passed as an argument or loaded from `),$le=n(iE,"CODE",{});var VGr=s($le);hqo=r(VGr,"pretrained_model_name_or_path"),VGr.forEach(t),uqo=r(iE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ile=n(iE,"CODE",{});var XGr=s(Ile);pqo=r(XGr,"pretrained_model_name_or_path"),XGr.forEach(t),_qo=r(iE,":"),iE.forEach(t),vqo=i(oa),he=n(oa,"UL",{});var Ce=s(he);ub=n(Ce,"LI",{});var rMe=s(ub);jle=n(rMe,"STRONG",{});var WGr=s(jle);bqo=r(WGr,"bert"),WGr.forEach(t),Tqo=r(rMe," \u2014 "),cj=n(rMe,"A",{href:!0});var QGr=s(cj);Fqo=r(QGr,"TFBertLMHeadModel"),QGr.forEach(t),Cqo=r(rMe," (BERT model)"),rMe.forEach(t),Eqo=i(Ce),pb=n(Ce,"LI",{});var tMe=s(pb);Nle=n(tMe,"STRONG",{});var HGr=s(Nle);Mqo=r(HGr,"ctrl"),HGr.forEach(t),yqo=r(tMe," \u2014 "),fj=n(tMe,"A",{href:!0});var UGr=s(fj);wqo=r(UGr,"TFCTRLLMHeadModel"),UGr.forEach(t),Aqo=r(tMe," (CTRL model)"),tMe.forEach(t),Lqo=i(Ce),_b=n(Ce,"LI",{});var aMe=s(_b);Dle=n(aMe,"STRONG",{});var JGr=s(Dle);Bqo=r(JGr,"gpt2"),JGr.forEach(t),kqo=r(aMe," \u2014 "),mj=n(aMe,"A",{href:!0});var YGr=s(mj);xqo=r(YGr,"TFGPT2LMHeadModel"),YGr.forEach(t),Rqo=r(aMe," (OpenAI GPT-2 model)"),aMe.forEach(t),Sqo=i(Ce),vb=n(Ce,"LI",{});var nMe=s(vb);qle=n(nMe,"STRONG",{});var KGr=s(qle);Pqo=r(KGr,"openai-gpt"),KGr.forEach(t),$qo=r(nMe," \u2014 "),gj=n(nMe,"A",{href:!0});var ZGr=s(gj);Iqo=r(ZGr,"TFOpenAIGPTLMHeadModel"),ZGr.forEach(t),jqo=r(nMe," (OpenAI GPT model)"),nMe.forEach(t),Nqo=i(Ce),bb=n(Ce,"LI",{});var sMe=s(bb);Ole=n(sMe,"STRONG",{});var ezr=s(Ole);Dqo=r(ezr,"rembert"),ezr.forEach(t),qqo=r(sMe," \u2014 "),hj=n(sMe,"A",{href:!0});var ozr=s(hj);Oqo=r(ozr,"TFRemBertForCausalLM"),ozr.forEach(t),Gqo=r(sMe," (RemBERT model)"),sMe.forEach(t),zqo=i(Ce),Tb=n(Ce,"LI",{});var lMe=s(Tb);Gle=n(lMe,"STRONG",{});var rzr=s(Gle);Vqo=r(rzr,"roberta"),rzr.forEach(t),Xqo=r(lMe," \u2014 "),uj=n(lMe,"A",{href:!0});var tzr=s(uj);Wqo=r(tzr,"TFRobertaForCausalLM"),tzr.forEach(t),Qqo=r(lMe," (RoBERTa model)"),lMe.forEach(t),Hqo=i(Ce),Fb=n(Ce,"LI",{});var iMe=s(Fb);zle=n(iMe,"STRONG",{});var azr=s(zle);Uqo=r(azr,"roformer"),azr.forEach(t),Jqo=r(iMe," \u2014 "),pj=n(iMe,"A",{href:!0});var nzr=s(pj);Yqo=r(nzr,"TFRoFormerForCausalLM"),nzr.forEach(t),Kqo=r(iMe," (RoFormer model)"),iMe.forEach(t),Zqo=i(Ce),Cb=n(Ce,"LI",{});var dMe=s(Cb);Vle=n(dMe,"STRONG",{});var szr=s(Vle);eOo=r(szr,"transfo-xl"),szr.forEach(t),oOo=r(dMe," \u2014 "),_j=n(dMe,"A",{href:!0});var lzr=s(_j);rOo=r(lzr,"TFTransfoXLLMHeadModel"),lzr.forEach(t),tOo=r(dMe," (Transformer-XL model)"),dMe.forEach(t),aOo=i(Ce),Eb=n(Ce,"LI",{});var cMe=s(Eb);Xle=n(cMe,"STRONG",{});var izr=s(Xle);nOo=r(izr,"xlm"),izr.forEach(t),sOo=r(cMe," \u2014 "),vj=n(cMe,"A",{href:!0});var dzr=s(vj);lOo=r(dzr,"TFXLMWithLMHeadModel"),dzr.forEach(t),iOo=r(cMe," (XLM model)"),cMe.forEach(t),dOo=i(Ce),Mb=n(Ce,"LI",{});var fMe=s(Mb);Wle=n(fMe,"STRONG",{});var czr=s(Wle);cOo=r(czr,"xlnet"),czr.forEach(t),fOo=r(fMe," \u2014 "),bj=n(fMe,"A",{href:!0});var fzr=s(bj);mOo=r(fzr,"TFXLNetLMHeadModel"),fzr.forEach(t),gOo=r(fMe," (XLNet model)"),fMe.forEach(t),Ce.forEach(t),hOo=i(oa),Qle=n(oa,"P",{});var mzr=s(Qle);uOo=r(mzr,"Examples:"),mzr.forEach(t),pOo=i(oa),m(ly.$$.fragment,oa),oa.forEach(t),cl.forEach(t),sAe=i(d),Rd=n(d,"H2",{class:!0});var s7e=s(Rd);yb=n(s7e,"A",{id:!0,class:!0,href:!0});var gzr=s(yb);Hle=n(gzr,"SPAN",{});var hzr=s(Hle);m(iy.$$.fragment,hzr),hzr.forEach(t),gzr.forEach(t),_Oo=i(s7e),Ule=n(s7e,"SPAN",{});var uzr=s(Ule);vOo=r(uzr,"TFAutoModelForImageClassification"),uzr.forEach(t),s7e.forEach(t),lAe=i(d),ir=n(d,"DIV",{class:!0});var ml=s(ir);m(dy.$$.fragment,ml),bOo=i(ml),Sd=n(ml,"P",{});var sG=s(Sd);TOo=r(sG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Jle=n(sG,"CODE",{});var pzr=s(Jle);FOo=r(pzr,"from_pretrained()"),pzr.forEach(t),COo=r(sG,"class method or the "),Yle=n(sG,"CODE",{});var _zr=s(Yle);EOo=r(_zr,"from_config()"),_zr.forEach(t),MOo=r(sG,`class
method.`),sG.forEach(t),yOo=i(ml),cy=n(ml,"P",{});var l7e=s(cy);wOo=r(l7e,"This class cannot be instantiated directly using "),Kle=n(l7e,"CODE",{});var vzr=s(Kle);AOo=r(vzr,"__init__()"),vzr.forEach(t),LOo=r(l7e," (throws an error)."),l7e.forEach(t),BOo=i(ml),Kr=n(ml,"DIV",{class:!0});var gl=s(Kr);m(fy.$$.fragment,gl),kOo=i(gl),Zle=n(gl,"P",{});var bzr=s(Zle);xOo=r(bzr,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),bzr.forEach(t),ROo=i(gl),Pd=n(gl,"P",{});var lG=s(Pd);SOo=r(lG,`Note:
Loading a model from its configuration file does `),eie=n(lG,"STRONG",{});var Tzr=s(eie);POo=r(Tzr,"not"),Tzr.forEach(t),$Oo=r(lG,` load the model weights. It only affects the
model\u2019s configuration. Use `),oie=n(lG,"CODE",{});var Fzr=s(oie);IOo=r(Fzr,"from_pretrained()"),Fzr.forEach(t),jOo=r(lG,"to load the model weights."),lG.forEach(t),NOo=i(gl),rie=n(gl,"P",{});var Czr=s(rie);DOo=r(Czr,"Examples:"),Czr.forEach(t),qOo=i(gl),m(my.$$.fragment,gl),gl.forEach(t),OOo=i(ml),go=n(ml,"DIV",{class:!0});var ra=s(go);m(gy.$$.fragment,ra),GOo=i(ra),tie=n(ra,"P",{});var Ezr=s(tie);zOo=r(Ezr,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Ezr.forEach(t),VOo=i(ra),Ja=n(ra,"P",{});var dE=s(Ja);XOo=r(dE,"The model class to instantiate is selected based on the "),aie=n(dE,"CODE",{});var Mzr=s(aie);WOo=r(Mzr,"model_type"),Mzr.forEach(t),QOo=r(dE,` property of the config object (either
passed as an argument or loaded from `),nie=n(dE,"CODE",{});var yzr=s(nie);HOo=r(yzr,"pretrained_model_name_or_path"),yzr.forEach(t),UOo=r(dE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sie=n(dE,"CODE",{});var wzr=s(sie);JOo=r(wzr,"pretrained_model_name_or_path"),wzr.forEach(t),YOo=r(dE,":"),dE.forEach(t),KOo=i(ra),lie=n(ra,"UL",{});var Azr=s(lie);wb=n(Azr,"LI",{});var mMe=s(wb);iie=n(mMe,"STRONG",{});var Lzr=s(iie);ZOo=r(Lzr,"vit"),Lzr.forEach(t),eGo=r(mMe," \u2014 "),Tj=n(mMe,"A",{href:!0});var Bzr=s(Tj);oGo=r(Bzr,"TFViTForImageClassification"),Bzr.forEach(t),rGo=r(mMe," (ViT model)"),mMe.forEach(t),Azr.forEach(t),tGo=i(ra),die=n(ra,"P",{});var kzr=s(die);aGo=r(kzr,"Examples:"),kzr.forEach(t),nGo=i(ra),m(hy.$$.fragment,ra),ra.forEach(t),ml.forEach(t),iAe=i(d),$d=n(d,"H2",{class:!0});var i7e=s($d);Ab=n(i7e,"A",{id:!0,class:!0,href:!0});var xzr=s(Ab);cie=n(xzr,"SPAN",{});var Rzr=s(cie);m(uy.$$.fragment,Rzr),Rzr.forEach(t),xzr.forEach(t),sGo=i(i7e),fie=n(i7e,"SPAN",{});var Szr=s(fie);lGo=r(Szr,"TFAutoModelForMaskedLM"),Szr.forEach(t),i7e.forEach(t),dAe=i(d),dr=n(d,"DIV",{class:!0});var hl=s(dr);m(py.$$.fragment,hl),iGo=i(hl),Id=n(hl,"P",{});var iG=s(Id);dGo=r(iG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),mie=n(iG,"CODE",{});var Pzr=s(mie);cGo=r(Pzr,"from_pretrained()"),Pzr.forEach(t),fGo=r(iG,"class method or the "),gie=n(iG,"CODE",{});var $zr=s(gie);mGo=r($zr,"from_config()"),$zr.forEach(t),gGo=r(iG,`class
method.`),iG.forEach(t),hGo=i(hl),_y=n(hl,"P",{});var d7e=s(_y);uGo=r(d7e,"This class cannot be instantiated directly using "),hie=n(d7e,"CODE",{});var Izr=s(hie);pGo=r(Izr,"__init__()"),Izr.forEach(t),_Go=r(d7e," (throws an error)."),d7e.forEach(t),vGo=i(hl),Zr=n(hl,"DIV",{class:!0});var ul=s(Zr);m(vy.$$.fragment,ul),bGo=i(ul),uie=n(ul,"P",{});var jzr=s(uie);TGo=r(jzr,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),jzr.forEach(t),FGo=i(ul),jd=n(ul,"P",{});var dG=s(jd);CGo=r(dG,`Note:
Loading a model from its configuration file does `),pie=n(dG,"STRONG",{});var Nzr=s(pie);EGo=r(Nzr,"not"),Nzr.forEach(t),MGo=r(dG,` load the model weights. It only affects the
model\u2019s configuration. Use `),_ie=n(dG,"CODE",{});var Dzr=s(_ie);yGo=r(Dzr,"from_pretrained()"),Dzr.forEach(t),wGo=r(dG,"to load the model weights."),dG.forEach(t),AGo=i(ul),vie=n(ul,"P",{});var qzr=s(vie);LGo=r(qzr,"Examples:"),qzr.forEach(t),BGo=i(ul),m(by.$$.fragment,ul),ul.forEach(t),kGo=i(hl),ho=n(hl,"DIV",{class:!0});var ta=s(ho);m(Ty.$$.fragment,ta),xGo=i(ta),bie=n(ta,"P",{});var Ozr=s(bie);RGo=r(Ozr,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Ozr.forEach(t),SGo=i(ta),Ya=n(ta,"P",{});var cE=s(Ya);PGo=r(cE,"The model class to instantiate is selected based on the "),Tie=n(cE,"CODE",{});var Gzr=s(Tie);$Go=r(Gzr,"model_type"),Gzr.forEach(t),IGo=r(cE,` property of the config object (either
passed as an argument or loaded from `),Fie=n(cE,"CODE",{});var zzr=s(Fie);jGo=r(zzr,"pretrained_model_name_or_path"),zzr.forEach(t),NGo=r(cE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cie=n(cE,"CODE",{});var Vzr=s(Cie);DGo=r(Vzr,"pretrained_model_name_or_path"),Vzr.forEach(t),qGo=r(cE,":"),cE.forEach(t),OGo=i(ta),Y=n(ta,"UL",{});var ee=s(Y);Lb=n(ee,"LI",{});var gMe=s(Lb);Eie=n(gMe,"STRONG",{});var Xzr=s(Eie);GGo=r(Xzr,"albert"),Xzr.forEach(t),zGo=r(gMe," \u2014 "),Fj=n(gMe,"A",{href:!0});var Wzr=s(Fj);VGo=r(Wzr,"TFAlbertForMaskedLM"),Wzr.forEach(t),XGo=r(gMe," (ALBERT model)"),gMe.forEach(t),WGo=i(ee),Bb=n(ee,"LI",{});var hMe=s(Bb);Mie=n(hMe,"STRONG",{});var Qzr=s(Mie);QGo=r(Qzr,"bert"),Qzr.forEach(t),HGo=r(hMe," \u2014 "),Cj=n(hMe,"A",{href:!0});var Hzr=s(Cj);UGo=r(Hzr,"TFBertForMaskedLM"),Hzr.forEach(t),JGo=r(hMe," (BERT model)"),hMe.forEach(t),YGo=i(ee),kb=n(ee,"LI",{});var uMe=s(kb);yie=n(uMe,"STRONG",{});var Uzr=s(yie);KGo=r(Uzr,"camembert"),Uzr.forEach(t),ZGo=r(uMe," \u2014 "),Ej=n(uMe,"A",{href:!0});var Jzr=s(Ej);ezo=r(Jzr,"TFCamembertForMaskedLM"),Jzr.forEach(t),ozo=r(uMe," (CamemBERT model)"),uMe.forEach(t),rzo=i(ee),xb=n(ee,"LI",{});var pMe=s(xb);wie=n(pMe,"STRONG",{});var Yzr=s(wie);tzo=r(Yzr,"convbert"),Yzr.forEach(t),azo=r(pMe," \u2014 "),Mj=n(pMe,"A",{href:!0});var Kzr=s(Mj);nzo=r(Kzr,"TFConvBertForMaskedLM"),Kzr.forEach(t),szo=r(pMe," (ConvBERT model)"),pMe.forEach(t),lzo=i(ee),Rb=n(ee,"LI",{});var _Me=s(Rb);Aie=n(_Me,"STRONG",{});var Zzr=s(Aie);izo=r(Zzr,"deberta"),Zzr.forEach(t),dzo=r(_Me," \u2014 "),yj=n(_Me,"A",{href:!0});var eVr=s(yj);czo=r(eVr,"TFDebertaForMaskedLM"),eVr.forEach(t),fzo=r(_Me," (DeBERTa model)"),_Me.forEach(t),mzo=i(ee),Sb=n(ee,"LI",{});var vMe=s(Sb);Lie=n(vMe,"STRONG",{});var oVr=s(Lie);gzo=r(oVr,"deberta-v2"),oVr.forEach(t),hzo=r(vMe," \u2014 "),wj=n(vMe,"A",{href:!0});var rVr=s(wj);uzo=r(rVr,"TFDebertaV2ForMaskedLM"),rVr.forEach(t),pzo=r(vMe," (DeBERTa-v2 model)"),vMe.forEach(t),_zo=i(ee),Pb=n(ee,"LI",{});var bMe=s(Pb);Bie=n(bMe,"STRONG",{});var tVr=s(Bie);vzo=r(tVr,"distilbert"),tVr.forEach(t),bzo=r(bMe," \u2014 "),Aj=n(bMe,"A",{href:!0});var aVr=s(Aj);Tzo=r(aVr,"TFDistilBertForMaskedLM"),aVr.forEach(t),Fzo=r(bMe," (DistilBERT model)"),bMe.forEach(t),Czo=i(ee),$b=n(ee,"LI",{});var TMe=s($b);kie=n(TMe,"STRONG",{});var nVr=s(kie);Ezo=r(nVr,"electra"),nVr.forEach(t),Mzo=r(TMe," \u2014 "),Lj=n(TMe,"A",{href:!0});var sVr=s(Lj);yzo=r(sVr,"TFElectraForMaskedLM"),sVr.forEach(t),wzo=r(TMe," (ELECTRA model)"),TMe.forEach(t),Azo=i(ee),Ib=n(ee,"LI",{});var FMe=s(Ib);xie=n(FMe,"STRONG",{});var lVr=s(xie);Lzo=r(lVr,"flaubert"),lVr.forEach(t),Bzo=r(FMe," \u2014 "),Bj=n(FMe,"A",{href:!0});var iVr=s(Bj);kzo=r(iVr,"TFFlaubertWithLMHeadModel"),iVr.forEach(t),xzo=r(FMe," (FlauBERT model)"),FMe.forEach(t),Rzo=i(ee),jb=n(ee,"LI",{});var CMe=s(jb);Rie=n(CMe,"STRONG",{});var dVr=s(Rie);Szo=r(dVr,"funnel"),dVr.forEach(t),Pzo=r(CMe," \u2014 "),kj=n(CMe,"A",{href:!0});var cVr=s(kj);$zo=r(cVr,"TFFunnelForMaskedLM"),cVr.forEach(t),Izo=r(CMe," (Funnel Transformer model)"),CMe.forEach(t),jzo=i(ee),Nb=n(ee,"LI",{});var EMe=s(Nb);Sie=n(EMe,"STRONG",{});var fVr=s(Sie);Nzo=r(fVr,"layoutlm"),fVr.forEach(t),Dzo=r(EMe," \u2014 "),xj=n(EMe,"A",{href:!0});var mVr=s(xj);qzo=r(mVr,"TFLayoutLMForMaskedLM"),mVr.forEach(t),Ozo=r(EMe," (LayoutLM model)"),EMe.forEach(t),Gzo=i(ee),Db=n(ee,"LI",{});var MMe=s(Db);Pie=n(MMe,"STRONG",{});var gVr=s(Pie);zzo=r(gVr,"longformer"),gVr.forEach(t),Vzo=r(MMe," \u2014 "),Rj=n(MMe,"A",{href:!0});var hVr=s(Rj);Xzo=r(hVr,"TFLongformerForMaskedLM"),hVr.forEach(t),Wzo=r(MMe," (Longformer model)"),MMe.forEach(t),Qzo=i(ee),qb=n(ee,"LI",{});var yMe=s(qb);$ie=n(yMe,"STRONG",{});var uVr=s($ie);Hzo=r(uVr,"mobilebert"),uVr.forEach(t),Uzo=r(yMe," \u2014 "),Sj=n(yMe,"A",{href:!0});var pVr=s(Sj);Jzo=r(pVr,"TFMobileBertForMaskedLM"),pVr.forEach(t),Yzo=r(yMe," (MobileBERT model)"),yMe.forEach(t),Kzo=i(ee),Ob=n(ee,"LI",{});var wMe=s(Ob);Iie=n(wMe,"STRONG",{});var _Vr=s(Iie);Zzo=r(_Vr,"mpnet"),_Vr.forEach(t),eVo=r(wMe," \u2014 "),Pj=n(wMe,"A",{href:!0});var vVr=s(Pj);oVo=r(vVr,"TFMPNetForMaskedLM"),vVr.forEach(t),rVo=r(wMe," (MPNet model)"),wMe.forEach(t),tVo=i(ee),Gb=n(ee,"LI",{});var AMe=s(Gb);jie=n(AMe,"STRONG",{});var bVr=s(jie);aVo=r(bVr,"rembert"),bVr.forEach(t),nVo=r(AMe," \u2014 "),$j=n(AMe,"A",{href:!0});var TVr=s($j);sVo=r(TVr,"TFRemBertForMaskedLM"),TVr.forEach(t),lVo=r(AMe," (RemBERT model)"),AMe.forEach(t),iVo=i(ee),zb=n(ee,"LI",{});var LMe=s(zb);Nie=n(LMe,"STRONG",{});var FVr=s(Nie);dVo=r(FVr,"roberta"),FVr.forEach(t),cVo=r(LMe," \u2014 "),Ij=n(LMe,"A",{href:!0});var CVr=s(Ij);fVo=r(CVr,"TFRobertaForMaskedLM"),CVr.forEach(t),mVo=r(LMe," (RoBERTa model)"),LMe.forEach(t),gVo=i(ee),Vb=n(ee,"LI",{});var BMe=s(Vb);Die=n(BMe,"STRONG",{});var EVr=s(Die);hVo=r(EVr,"roformer"),EVr.forEach(t),uVo=r(BMe," \u2014 "),jj=n(BMe,"A",{href:!0});var MVr=s(jj);pVo=r(MVr,"TFRoFormerForMaskedLM"),MVr.forEach(t),_Vo=r(BMe," (RoFormer model)"),BMe.forEach(t),vVo=i(ee),Xb=n(ee,"LI",{});var kMe=s(Xb);qie=n(kMe,"STRONG",{});var yVr=s(qie);bVo=r(yVr,"tapas"),yVr.forEach(t),TVo=r(kMe," \u2014 "),Nj=n(kMe,"A",{href:!0});var wVr=s(Nj);FVo=r(wVr,"TFTapasForMaskedLM"),wVr.forEach(t),CVo=r(kMe," (TAPAS model)"),kMe.forEach(t),EVo=i(ee),Wb=n(ee,"LI",{});var xMe=s(Wb);Oie=n(xMe,"STRONG",{});var AVr=s(Oie);MVo=r(AVr,"xlm"),AVr.forEach(t),yVo=r(xMe," \u2014 "),Dj=n(xMe,"A",{href:!0});var LVr=s(Dj);wVo=r(LVr,"TFXLMWithLMHeadModel"),LVr.forEach(t),AVo=r(xMe," (XLM model)"),xMe.forEach(t),LVo=i(ee),Qb=n(ee,"LI",{});var RMe=s(Qb);Gie=n(RMe,"STRONG",{});var BVr=s(Gie);BVo=r(BVr,"xlm-roberta"),BVr.forEach(t),kVo=r(RMe," \u2014 "),qj=n(RMe,"A",{href:!0});var kVr=s(qj);xVo=r(kVr,"TFXLMRobertaForMaskedLM"),kVr.forEach(t),RVo=r(RMe," (XLM-RoBERTa model)"),RMe.forEach(t),ee.forEach(t),SVo=i(ta),zie=n(ta,"P",{});var xVr=s(zie);PVo=r(xVr,"Examples:"),xVr.forEach(t),$Vo=i(ta),m(Fy.$$.fragment,ta),ta.forEach(t),hl.forEach(t),cAe=i(d),Nd=n(d,"H2",{class:!0});var c7e=s(Nd);Hb=n(c7e,"A",{id:!0,class:!0,href:!0});var RVr=s(Hb);Vie=n(RVr,"SPAN",{});var SVr=s(Vie);m(Cy.$$.fragment,SVr),SVr.forEach(t),RVr.forEach(t),IVo=i(c7e),Xie=n(c7e,"SPAN",{});var PVr=s(Xie);jVo=r(PVr,"TFAutoModelForSeq2SeqLM"),PVr.forEach(t),c7e.forEach(t),fAe=i(d),cr=n(d,"DIV",{class:!0});var pl=s(cr);m(Ey.$$.fragment,pl),NVo=i(pl),Dd=n(pl,"P",{});var cG=s(Dd);DVo=r(cG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Wie=n(cG,"CODE",{});var $Vr=s(Wie);qVo=r($Vr,"from_pretrained()"),$Vr.forEach(t),OVo=r(cG,"class method or the "),Qie=n(cG,"CODE",{});var IVr=s(Qie);GVo=r(IVr,"from_config()"),IVr.forEach(t),zVo=r(cG,`class
method.`),cG.forEach(t),VVo=i(pl),My=n(pl,"P",{});var f7e=s(My);XVo=r(f7e,"This class cannot be instantiated directly using "),Hie=n(f7e,"CODE",{});var jVr=s(Hie);WVo=r(jVr,"__init__()"),jVr.forEach(t),QVo=r(f7e," (throws an error)."),f7e.forEach(t),HVo=i(pl),et=n(pl,"DIV",{class:!0});var _l=s(et);m(yy.$$.fragment,_l),UVo=i(_l),Uie=n(_l,"P",{});var NVr=s(Uie);JVo=r(NVr,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),NVr.forEach(t),YVo=i(_l),qd=n(_l,"P",{});var fG=s(qd);KVo=r(fG,`Note:
Loading a model from its configuration file does `),Jie=n(fG,"STRONG",{});var DVr=s(Jie);ZVo=r(DVr,"not"),DVr.forEach(t),eXo=r(fG,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yie=n(fG,"CODE",{});var qVr=s(Yie);oXo=r(qVr,"from_pretrained()"),qVr.forEach(t),rXo=r(fG,"to load the model weights."),fG.forEach(t),tXo=i(_l),Kie=n(_l,"P",{});var OVr=s(Kie);aXo=r(OVr,"Examples:"),OVr.forEach(t),nXo=i(_l),m(wy.$$.fragment,_l),_l.forEach(t),sXo=i(pl),uo=n(pl,"DIV",{class:!0});var aa=s(uo);m(Ay.$$.fragment,aa),lXo=i(aa),Zie=n(aa,"P",{});var GVr=s(Zie);iXo=r(GVr,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),GVr.forEach(t),dXo=i(aa),Ka=n(aa,"P",{});var fE=s(Ka);cXo=r(fE,"The model class to instantiate is selected based on the "),ede=n(fE,"CODE",{});var zVr=s(ede);fXo=r(zVr,"model_type"),zVr.forEach(t),mXo=r(fE,` property of the config object (either
passed as an argument or loaded from `),ode=n(fE,"CODE",{});var VVr=s(ode);gXo=r(VVr,"pretrained_model_name_or_path"),VVr.forEach(t),hXo=r(fE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rde=n(fE,"CODE",{});var XVr=s(rde);uXo=r(XVr,"pretrained_model_name_or_path"),XVr.forEach(t),pXo=r(fE,":"),fE.forEach(t),_Xo=i(aa),ue=n(aa,"UL",{});var Ee=s(ue);Ub=n(Ee,"LI",{});var SMe=s(Ub);tde=n(SMe,"STRONG",{});var WVr=s(tde);vXo=r(WVr,"bart"),WVr.forEach(t),bXo=r(SMe," \u2014 "),Oj=n(SMe,"A",{href:!0});var QVr=s(Oj);TXo=r(QVr,"TFBartForConditionalGeneration"),QVr.forEach(t),FXo=r(SMe," (BART model)"),SMe.forEach(t),CXo=i(Ee),Jb=n(Ee,"LI",{});var PMe=s(Jb);ade=n(PMe,"STRONG",{});var HVr=s(ade);EXo=r(HVr,"blenderbot"),HVr.forEach(t),MXo=r(PMe," \u2014 "),Gj=n(PMe,"A",{href:!0});var UVr=s(Gj);yXo=r(UVr,"TFBlenderbotForConditionalGeneration"),UVr.forEach(t),wXo=r(PMe," (Blenderbot model)"),PMe.forEach(t),AXo=i(Ee),Yb=n(Ee,"LI",{});var $Me=s(Yb);nde=n($Me,"STRONG",{});var JVr=s(nde);LXo=r(JVr,"blenderbot-small"),JVr.forEach(t),BXo=r($Me," \u2014 "),zj=n($Me,"A",{href:!0});var YVr=s(zj);kXo=r(YVr,"TFBlenderbotSmallForConditionalGeneration"),YVr.forEach(t),xXo=r($Me," (BlenderbotSmall model)"),$Me.forEach(t),RXo=i(Ee),Kb=n(Ee,"LI",{});var IMe=s(Kb);sde=n(IMe,"STRONG",{});var KVr=s(sde);SXo=r(KVr,"encoder-decoder"),KVr.forEach(t),PXo=r(IMe," \u2014 "),Vj=n(IMe,"A",{href:!0});var ZVr=s(Vj);$Xo=r(ZVr,"TFEncoderDecoderModel"),ZVr.forEach(t),IXo=r(IMe," (Encoder decoder model)"),IMe.forEach(t),jXo=i(Ee),Zb=n(Ee,"LI",{});var jMe=s(Zb);lde=n(jMe,"STRONG",{});var eXr=s(lde);NXo=r(eXr,"led"),eXr.forEach(t),DXo=r(jMe," \u2014 "),Xj=n(jMe,"A",{href:!0});var oXr=s(Xj);qXo=r(oXr,"TFLEDForConditionalGeneration"),oXr.forEach(t),OXo=r(jMe," (LED model)"),jMe.forEach(t),GXo=i(Ee),eT=n(Ee,"LI",{});var NMe=s(eT);ide=n(NMe,"STRONG",{});var rXr=s(ide);zXo=r(rXr,"marian"),rXr.forEach(t),VXo=r(NMe," \u2014 "),Wj=n(NMe,"A",{href:!0});var tXr=s(Wj);XXo=r(tXr,"TFMarianMTModel"),tXr.forEach(t),WXo=r(NMe," (Marian model)"),NMe.forEach(t),QXo=i(Ee),oT=n(Ee,"LI",{});var DMe=s(oT);dde=n(DMe,"STRONG",{});var aXr=s(dde);HXo=r(aXr,"mbart"),aXr.forEach(t),UXo=r(DMe," \u2014 "),Qj=n(DMe,"A",{href:!0});var nXr=s(Qj);JXo=r(nXr,"TFMBartForConditionalGeneration"),nXr.forEach(t),YXo=r(DMe," (mBART model)"),DMe.forEach(t),KXo=i(Ee),rT=n(Ee,"LI",{});var qMe=s(rT);cde=n(qMe,"STRONG",{});var sXr=s(cde);ZXo=r(sXr,"mt5"),sXr.forEach(t),eWo=r(qMe," \u2014 "),Hj=n(qMe,"A",{href:!0});var lXr=s(Hj);oWo=r(lXr,"TFMT5ForConditionalGeneration"),lXr.forEach(t),rWo=r(qMe," (mT5 model)"),qMe.forEach(t),tWo=i(Ee),tT=n(Ee,"LI",{});var OMe=s(tT);fde=n(OMe,"STRONG",{});var iXr=s(fde);aWo=r(iXr,"pegasus"),iXr.forEach(t),nWo=r(OMe," \u2014 "),Uj=n(OMe,"A",{href:!0});var dXr=s(Uj);sWo=r(dXr,"TFPegasusForConditionalGeneration"),dXr.forEach(t),lWo=r(OMe," (Pegasus model)"),OMe.forEach(t),iWo=i(Ee),aT=n(Ee,"LI",{});var GMe=s(aT);mde=n(GMe,"STRONG",{});var cXr=s(mde);dWo=r(cXr,"t5"),cXr.forEach(t),cWo=r(GMe," \u2014 "),Jj=n(GMe,"A",{href:!0});var fXr=s(Jj);fWo=r(fXr,"TFT5ForConditionalGeneration"),fXr.forEach(t),mWo=r(GMe," (T5 model)"),GMe.forEach(t),Ee.forEach(t),gWo=i(aa),gde=n(aa,"P",{});var mXr=s(gde);hWo=r(mXr,"Examples:"),mXr.forEach(t),uWo=i(aa),m(Ly.$$.fragment,aa),aa.forEach(t),pl.forEach(t),mAe=i(d),Od=n(d,"H2",{class:!0});var m7e=s(Od);nT=n(m7e,"A",{id:!0,class:!0,href:!0});var gXr=s(nT);hde=n(gXr,"SPAN",{});var hXr=s(hde);m(By.$$.fragment,hXr),hXr.forEach(t),gXr.forEach(t),pWo=i(m7e),ude=n(m7e,"SPAN",{});var uXr=s(ude);_Wo=r(uXr,"TFAutoModelForSequenceClassification"),uXr.forEach(t),m7e.forEach(t),gAe=i(d),fr=n(d,"DIV",{class:!0});var vl=s(fr);m(ky.$$.fragment,vl),vWo=i(vl),Gd=n(vl,"P",{});var mG=s(Gd);bWo=r(mG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),pde=n(mG,"CODE",{});var pXr=s(pde);TWo=r(pXr,"from_pretrained()"),pXr.forEach(t),FWo=r(mG,"class method or the "),_de=n(mG,"CODE",{});var _Xr=s(_de);CWo=r(_Xr,"from_config()"),_Xr.forEach(t),EWo=r(mG,`class
method.`),mG.forEach(t),MWo=i(vl),xy=n(vl,"P",{});var g7e=s(xy);yWo=r(g7e,"This class cannot be instantiated directly using "),vde=n(g7e,"CODE",{});var vXr=s(vde);wWo=r(vXr,"__init__()"),vXr.forEach(t),AWo=r(g7e," (throws an error)."),g7e.forEach(t),LWo=i(vl),ot=n(vl,"DIV",{class:!0});var bl=s(ot);m(Ry.$$.fragment,bl),BWo=i(bl),bde=n(bl,"P",{});var bXr=s(bde);kWo=r(bXr,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),bXr.forEach(t),xWo=i(bl),zd=n(bl,"P",{});var gG=s(zd);RWo=r(gG,`Note:
Loading a model from its configuration file does `),Tde=n(gG,"STRONG",{});var TXr=s(Tde);SWo=r(TXr,"not"),TXr.forEach(t),PWo=r(gG,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fde=n(gG,"CODE",{});var FXr=s(Fde);$Wo=r(FXr,"from_pretrained()"),FXr.forEach(t),IWo=r(gG,"to load the model weights."),gG.forEach(t),jWo=i(bl),Cde=n(bl,"P",{});var CXr=s(Cde);NWo=r(CXr,"Examples:"),CXr.forEach(t),DWo=i(bl),m(Sy.$$.fragment,bl),bl.forEach(t),qWo=i(vl),po=n(vl,"DIV",{class:!0});var na=s(po);m(Py.$$.fragment,na),OWo=i(na),Ede=n(na,"P",{});var EXr=s(Ede);GWo=r(EXr,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),EXr.forEach(t),zWo=i(na),Za=n(na,"P",{});var mE=s(Za);VWo=r(mE,"The model class to instantiate is selected based on the "),Mde=n(mE,"CODE",{});var MXr=s(Mde);XWo=r(MXr,"model_type"),MXr.forEach(t),WWo=r(mE,` property of the config object (either
passed as an argument or loaded from `),yde=n(mE,"CODE",{});var yXr=s(yde);QWo=r(yXr,"pretrained_model_name_or_path"),yXr.forEach(t),HWo=r(mE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wde=n(mE,"CODE",{});var wXr=s(wde);UWo=r(wXr,"pretrained_model_name_or_path"),wXr.forEach(t),JWo=r(mE,":"),mE.forEach(t),YWo=i(na),G=n(na,"UL",{});var V=s(G);sT=n(V,"LI",{});var zMe=s(sT);Ade=n(zMe,"STRONG",{});var AXr=s(Ade);KWo=r(AXr,"albert"),AXr.forEach(t),ZWo=r(zMe," \u2014 "),Yj=n(zMe,"A",{href:!0});var LXr=s(Yj);eQo=r(LXr,"TFAlbertForSequenceClassification"),LXr.forEach(t),oQo=r(zMe," (ALBERT model)"),zMe.forEach(t),rQo=i(V),lT=n(V,"LI",{});var VMe=s(lT);Lde=n(VMe,"STRONG",{});var BXr=s(Lde);tQo=r(BXr,"bert"),BXr.forEach(t),aQo=r(VMe," \u2014 "),Kj=n(VMe,"A",{href:!0});var kXr=s(Kj);nQo=r(kXr,"TFBertForSequenceClassification"),kXr.forEach(t),sQo=r(VMe," (BERT model)"),VMe.forEach(t),lQo=i(V),iT=n(V,"LI",{});var XMe=s(iT);Bde=n(XMe,"STRONG",{});var xXr=s(Bde);iQo=r(xXr,"camembert"),xXr.forEach(t),dQo=r(XMe," \u2014 "),Zj=n(XMe,"A",{href:!0});var RXr=s(Zj);cQo=r(RXr,"TFCamembertForSequenceClassification"),RXr.forEach(t),fQo=r(XMe," (CamemBERT model)"),XMe.forEach(t),mQo=i(V),dT=n(V,"LI",{});var WMe=s(dT);kde=n(WMe,"STRONG",{});var SXr=s(kde);gQo=r(SXr,"convbert"),SXr.forEach(t),hQo=r(WMe," \u2014 "),eN=n(WMe,"A",{href:!0});var PXr=s(eN);uQo=r(PXr,"TFConvBertForSequenceClassification"),PXr.forEach(t),pQo=r(WMe," (ConvBERT model)"),WMe.forEach(t),_Qo=i(V),cT=n(V,"LI",{});var QMe=s(cT);xde=n(QMe,"STRONG",{});var $Xr=s(xde);vQo=r($Xr,"ctrl"),$Xr.forEach(t),bQo=r(QMe," \u2014 "),oN=n(QMe,"A",{href:!0});var IXr=s(oN);TQo=r(IXr,"TFCTRLForSequenceClassification"),IXr.forEach(t),FQo=r(QMe," (CTRL model)"),QMe.forEach(t),CQo=i(V),fT=n(V,"LI",{});var HMe=s(fT);Rde=n(HMe,"STRONG",{});var jXr=s(Rde);EQo=r(jXr,"deberta"),jXr.forEach(t),MQo=r(HMe," \u2014 "),rN=n(HMe,"A",{href:!0});var NXr=s(rN);yQo=r(NXr,"TFDebertaForSequenceClassification"),NXr.forEach(t),wQo=r(HMe," (DeBERTa model)"),HMe.forEach(t),AQo=i(V),mT=n(V,"LI",{});var UMe=s(mT);Sde=n(UMe,"STRONG",{});var DXr=s(Sde);LQo=r(DXr,"deberta-v2"),DXr.forEach(t),BQo=r(UMe," \u2014 "),tN=n(UMe,"A",{href:!0});var qXr=s(tN);kQo=r(qXr,"TFDebertaV2ForSequenceClassification"),qXr.forEach(t),xQo=r(UMe," (DeBERTa-v2 model)"),UMe.forEach(t),RQo=i(V),gT=n(V,"LI",{});var JMe=s(gT);Pde=n(JMe,"STRONG",{});var OXr=s(Pde);SQo=r(OXr,"distilbert"),OXr.forEach(t),PQo=r(JMe," \u2014 "),aN=n(JMe,"A",{href:!0});var GXr=s(aN);$Qo=r(GXr,"TFDistilBertForSequenceClassification"),GXr.forEach(t),IQo=r(JMe," (DistilBERT model)"),JMe.forEach(t),jQo=i(V),hT=n(V,"LI",{});var YMe=s(hT);$de=n(YMe,"STRONG",{});var zXr=s($de);NQo=r(zXr,"electra"),zXr.forEach(t),DQo=r(YMe," \u2014 "),nN=n(YMe,"A",{href:!0});var VXr=s(nN);qQo=r(VXr,"TFElectraForSequenceClassification"),VXr.forEach(t),OQo=r(YMe," (ELECTRA model)"),YMe.forEach(t),GQo=i(V),uT=n(V,"LI",{});var KMe=s(uT);Ide=n(KMe,"STRONG",{});var XXr=s(Ide);zQo=r(XXr,"flaubert"),XXr.forEach(t),VQo=r(KMe," \u2014 "),sN=n(KMe,"A",{href:!0});var WXr=s(sN);XQo=r(WXr,"TFFlaubertForSequenceClassification"),WXr.forEach(t),WQo=r(KMe," (FlauBERT model)"),KMe.forEach(t),QQo=i(V),pT=n(V,"LI",{});var ZMe=s(pT);jde=n(ZMe,"STRONG",{});var QXr=s(jde);HQo=r(QXr,"funnel"),QXr.forEach(t),UQo=r(ZMe," \u2014 "),lN=n(ZMe,"A",{href:!0});var HXr=s(lN);JQo=r(HXr,"TFFunnelForSequenceClassification"),HXr.forEach(t),YQo=r(ZMe," (Funnel Transformer model)"),ZMe.forEach(t),KQo=i(V),_T=n(V,"LI",{});var e3e=s(_T);Nde=n(e3e,"STRONG",{});var UXr=s(Nde);ZQo=r(UXr,"gpt2"),UXr.forEach(t),eHo=r(e3e," \u2014 "),iN=n(e3e,"A",{href:!0});var JXr=s(iN);oHo=r(JXr,"TFGPT2ForSequenceClassification"),JXr.forEach(t),rHo=r(e3e," (OpenAI GPT-2 model)"),e3e.forEach(t),tHo=i(V),vT=n(V,"LI",{});var o3e=s(vT);Dde=n(o3e,"STRONG",{});var YXr=s(Dde);aHo=r(YXr,"layoutlm"),YXr.forEach(t),nHo=r(o3e," \u2014 "),dN=n(o3e,"A",{href:!0});var KXr=s(dN);sHo=r(KXr,"TFLayoutLMForSequenceClassification"),KXr.forEach(t),lHo=r(o3e," (LayoutLM model)"),o3e.forEach(t),iHo=i(V),bT=n(V,"LI",{});var r3e=s(bT);qde=n(r3e,"STRONG",{});var ZXr=s(qde);dHo=r(ZXr,"longformer"),ZXr.forEach(t),cHo=r(r3e," \u2014 "),cN=n(r3e,"A",{href:!0});var eWr=s(cN);fHo=r(eWr,"TFLongformerForSequenceClassification"),eWr.forEach(t),mHo=r(r3e," (Longformer model)"),r3e.forEach(t),gHo=i(V),TT=n(V,"LI",{});var t3e=s(TT);Ode=n(t3e,"STRONG",{});var oWr=s(Ode);hHo=r(oWr,"mobilebert"),oWr.forEach(t),uHo=r(t3e," \u2014 "),fN=n(t3e,"A",{href:!0});var rWr=s(fN);pHo=r(rWr,"TFMobileBertForSequenceClassification"),rWr.forEach(t),_Ho=r(t3e," (MobileBERT model)"),t3e.forEach(t),vHo=i(V),FT=n(V,"LI",{});var a3e=s(FT);Gde=n(a3e,"STRONG",{});var tWr=s(Gde);bHo=r(tWr,"mpnet"),tWr.forEach(t),THo=r(a3e," \u2014 "),mN=n(a3e,"A",{href:!0});var aWr=s(mN);FHo=r(aWr,"TFMPNetForSequenceClassification"),aWr.forEach(t),CHo=r(a3e," (MPNet model)"),a3e.forEach(t),EHo=i(V),CT=n(V,"LI",{});var n3e=s(CT);zde=n(n3e,"STRONG",{});var nWr=s(zde);MHo=r(nWr,"openai-gpt"),nWr.forEach(t),yHo=r(n3e," \u2014 "),gN=n(n3e,"A",{href:!0});var sWr=s(gN);wHo=r(sWr,"TFOpenAIGPTForSequenceClassification"),sWr.forEach(t),AHo=r(n3e," (OpenAI GPT model)"),n3e.forEach(t),LHo=i(V),ET=n(V,"LI",{});var s3e=s(ET);Vde=n(s3e,"STRONG",{});var lWr=s(Vde);BHo=r(lWr,"rembert"),lWr.forEach(t),kHo=r(s3e," \u2014 "),hN=n(s3e,"A",{href:!0});var iWr=s(hN);xHo=r(iWr,"TFRemBertForSequenceClassification"),iWr.forEach(t),RHo=r(s3e," (RemBERT model)"),s3e.forEach(t),SHo=i(V),MT=n(V,"LI",{});var l3e=s(MT);Xde=n(l3e,"STRONG",{});var dWr=s(Xde);PHo=r(dWr,"roberta"),dWr.forEach(t),$Ho=r(l3e," \u2014 "),uN=n(l3e,"A",{href:!0});var cWr=s(uN);IHo=r(cWr,"TFRobertaForSequenceClassification"),cWr.forEach(t),jHo=r(l3e," (RoBERTa model)"),l3e.forEach(t),NHo=i(V),yT=n(V,"LI",{});var i3e=s(yT);Wde=n(i3e,"STRONG",{});var fWr=s(Wde);DHo=r(fWr,"roformer"),fWr.forEach(t),qHo=r(i3e," \u2014 "),pN=n(i3e,"A",{href:!0});var mWr=s(pN);OHo=r(mWr,"TFRoFormerForSequenceClassification"),mWr.forEach(t),GHo=r(i3e," (RoFormer model)"),i3e.forEach(t),zHo=i(V),wT=n(V,"LI",{});var d3e=s(wT);Qde=n(d3e,"STRONG",{});var gWr=s(Qde);VHo=r(gWr,"tapas"),gWr.forEach(t),XHo=r(d3e," \u2014 "),_N=n(d3e,"A",{href:!0});var hWr=s(_N);WHo=r(hWr,"TFTapasForSequenceClassification"),hWr.forEach(t),QHo=r(d3e," (TAPAS model)"),d3e.forEach(t),HHo=i(V),AT=n(V,"LI",{});var c3e=s(AT);Hde=n(c3e,"STRONG",{});var uWr=s(Hde);UHo=r(uWr,"transfo-xl"),uWr.forEach(t),JHo=r(c3e," \u2014 "),vN=n(c3e,"A",{href:!0});var pWr=s(vN);YHo=r(pWr,"TFTransfoXLForSequenceClassification"),pWr.forEach(t),KHo=r(c3e," (Transformer-XL model)"),c3e.forEach(t),ZHo=i(V),LT=n(V,"LI",{});var f3e=s(LT);Ude=n(f3e,"STRONG",{});var _Wr=s(Ude);eUo=r(_Wr,"xlm"),_Wr.forEach(t),oUo=r(f3e," \u2014 "),bN=n(f3e,"A",{href:!0});var vWr=s(bN);rUo=r(vWr,"TFXLMForSequenceClassification"),vWr.forEach(t),tUo=r(f3e," (XLM model)"),f3e.forEach(t),aUo=i(V),BT=n(V,"LI",{});var m3e=s(BT);Jde=n(m3e,"STRONG",{});var bWr=s(Jde);nUo=r(bWr,"xlm-roberta"),bWr.forEach(t),sUo=r(m3e," \u2014 "),TN=n(m3e,"A",{href:!0});var TWr=s(TN);lUo=r(TWr,"TFXLMRobertaForSequenceClassification"),TWr.forEach(t),iUo=r(m3e," (XLM-RoBERTa model)"),m3e.forEach(t),dUo=i(V),kT=n(V,"LI",{});var g3e=s(kT);Yde=n(g3e,"STRONG",{});var FWr=s(Yde);cUo=r(FWr,"xlnet"),FWr.forEach(t),fUo=r(g3e," \u2014 "),FN=n(g3e,"A",{href:!0});var CWr=s(FN);mUo=r(CWr,"TFXLNetForSequenceClassification"),CWr.forEach(t),gUo=r(g3e," (XLNet model)"),g3e.forEach(t),V.forEach(t),hUo=i(na),Kde=n(na,"P",{});var EWr=s(Kde);uUo=r(EWr,"Examples:"),EWr.forEach(t),pUo=i(na),m($y.$$.fragment,na),na.forEach(t),vl.forEach(t),hAe=i(d),Vd=n(d,"H2",{class:!0});var h7e=s(Vd);xT=n(h7e,"A",{id:!0,class:!0,href:!0});var MWr=s(xT);Zde=n(MWr,"SPAN",{});var yWr=s(Zde);m(Iy.$$.fragment,yWr),yWr.forEach(t),MWr.forEach(t),_Uo=i(h7e),ece=n(h7e,"SPAN",{});var wWr=s(ece);vUo=r(wWr,"TFAutoModelForMultipleChoice"),wWr.forEach(t),h7e.forEach(t),uAe=i(d),mr=n(d,"DIV",{class:!0});var Tl=s(mr);m(jy.$$.fragment,Tl),bUo=i(Tl),Xd=n(Tl,"P",{});var hG=s(Xd);TUo=r(hG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),oce=n(hG,"CODE",{});var AWr=s(oce);FUo=r(AWr,"from_pretrained()"),AWr.forEach(t),CUo=r(hG,"class method or the "),rce=n(hG,"CODE",{});var LWr=s(rce);EUo=r(LWr,"from_config()"),LWr.forEach(t),MUo=r(hG,`class
method.`),hG.forEach(t),yUo=i(Tl),Ny=n(Tl,"P",{});var u7e=s(Ny);wUo=r(u7e,"This class cannot be instantiated directly using "),tce=n(u7e,"CODE",{});var BWr=s(tce);AUo=r(BWr,"__init__()"),BWr.forEach(t),LUo=r(u7e," (throws an error)."),u7e.forEach(t),BUo=i(Tl),rt=n(Tl,"DIV",{class:!0});var Fl=s(rt);m(Dy.$$.fragment,Fl),kUo=i(Fl),ace=n(Fl,"P",{});var kWr=s(ace);xUo=r(kWr,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),kWr.forEach(t),RUo=i(Fl),Wd=n(Fl,"P",{});var uG=s(Wd);SUo=r(uG,`Note:
Loading a model from its configuration file does `),nce=n(uG,"STRONG",{});var xWr=s(nce);PUo=r(xWr,"not"),xWr.forEach(t),$Uo=r(uG,` load the model weights. It only affects the
model\u2019s configuration. Use `),sce=n(uG,"CODE",{});var RWr=s(sce);IUo=r(RWr,"from_pretrained()"),RWr.forEach(t),jUo=r(uG,"to load the model weights."),uG.forEach(t),NUo=i(Fl),lce=n(Fl,"P",{});var SWr=s(lce);DUo=r(SWr,"Examples:"),SWr.forEach(t),qUo=i(Fl),m(qy.$$.fragment,Fl),Fl.forEach(t),OUo=i(Tl),_o=n(Tl,"DIV",{class:!0});var sa=s(_o);m(Oy.$$.fragment,sa),GUo=i(sa),ice=n(sa,"P",{});var PWr=s(ice);zUo=r(PWr,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),PWr.forEach(t),VUo=i(sa),en=n(sa,"P",{});var gE=s(en);XUo=r(gE,"The model class to instantiate is selected based on the "),dce=n(gE,"CODE",{});var $Wr=s(dce);WUo=r($Wr,"model_type"),$Wr.forEach(t),QUo=r(gE,` property of the config object (either
passed as an argument or loaded from `),cce=n(gE,"CODE",{});var IWr=s(cce);HUo=r(IWr,"pretrained_model_name_or_path"),IWr.forEach(t),UUo=r(gE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fce=n(gE,"CODE",{});var jWr=s(fce);JUo=r(jWr,"pretrained_model_name_or_path"),jWr.forEach(t),YUo=r(gE,":"),gE.forEach(t),KUo=i(sa),te=n(sa,"UL",{});var ae=s(te);RT=n(ae,"LI",{});var h3e=s(RT);mce=n(h3e,"STRONG",{});var NWr=s(mce);ZUo=r(NWr,"albert"),NWr.forEach(t),eJo=r(h3e," \u2014 "),CN=n(h3e,"A",{href:!0});var DWr=s(CN);oJo=r(DWr,"TFAlbertForMultipleChoice"),DWr.forEach(t),rJo=r(h3e," (ALBERT model)"),h3e.forEach(t),tJo=i(ae),ST=n(ae,"LI",{});var u3e=s(ST);gce=n(u3e,"STRONG",{});var qWr=s(gce);aJo=r(qWr,"bert"),qWr.forEach(t),nJo=r(u3e," \u2014 "),EN=n(u3e,"A",{href:!0});var OWr=s(EN);sJo=r(OWr,"TFBertForMultipleChoice"),OWr.forEach(t),lJo=r(u3e," (BERT model)"),u3e.forEach(t),iJo=i(ae),PT=n(ae,"LI",{});var p3e=s(PT);hce=n(p3e,"STRONG",{});var GWr=s(hce);dJo=r(GWr,"camembert"),GWr.forEach(t),cJo=r(p3e," \u2014 "),MN=n(p3e,"A",{href:!0});var zWr=s(MN);fJo=r(zWr,"TFCamembertForMultipleChoice"),zWr.forEach(t),mJo=r(p3e," (CamemBERT model)"),p3e.forEach(t),gJo=i(ae),$T=n(ae,"LI",{});var _3e=s($T);uce=n(_3e,"STRONG",{});var VWr=s(uce);hJo=r(VWr,"convbert"),VWr.forEach(t),uJo=r(_3e," \u2014 "),yN=n(_3e,"A",{href:!0});var XWr=s(yN);pJo=r(XWr,"TFConvBertForMultipleChoice"),XWr.forEach(t),_Jo=r(_3e," (ConvBERT model)"),_3e.forEach(t),vJo=i(ae),IT=n(ae,"LI",{});var v3e=s(IT);pce=n(v3e,"STRONG",{});var WWr=s(pce);bJo=r(WWr,"distilbert"),WWr.forEach(t),TJo=r(v3e," \u2014 "),wN=n(v3e,"A",{href:!0});var QWr=s(wN);FJo=r(QWr,"TFDistilBertForMultipleChoice"),QWr.forEach(t),CJo=r(v3e," (DistilBERT model)"),v3e.forEach(t),EJo=i(ae),jT=n(ae,"LI",{});var b3e=s(jT);_ce=n(b3e,"STRONG",{});var HWr=s(_ce);MJo=r(HWr,"electra"),HWr.forEach(t),yJo=r(b3e," \u2014 "),AN=n(b3e,"A",{href:!0});var UWr=s(AN);wJo=r(UWr,"TFElectraForMultipleChoice"),UWr.forEach(t),AJo=r(b3e," (ELECTRA model)"),b3e.forEach(t),LJo=i(ae),NT=n(ae,"LI",{});var T3e=s(NT);vce=n(T3e,"STRONG",{});var JWr=s(vce);BJo=r(JWr,"flaubert"),JWr.forEach(t),kJo=r(T3e," \u2014 "),LN=n(T3e,"A",{href:!0});var YWr=s(LN);xJo=r(YWr,"TFFlaubertForMultipleChoice"),YWr.forEach(t),RJo=r(T3e," (FlauBERT model)"),T3e.forEach(t),SJo=i(ae),DT=n(ae,"LI",{});var F3e=s(DT);bce=n(F3e,"STRONG",{});var KWr=s(bce);PJo=r(KWr,"funnel"),KWr.forEach(t),$Jo=r(F3e," \u2014 "),BN=n(F3e,"A",{href:!0});var ZWr=s(BN);IJo=r(ZWr,"TFFunnelForMultipleChoice"),ZWr.forEach(t),jJo=r(F3e," (Funnel Transformer model)"),F3e.forEach(t),NJo=i(ae),qT=n(ae,"LI",{});var C3e=s(qT);Tce=n(C3e,"STRONG",{});var eQr=s(Tce);DJo=r(eQr,"longformer"),eQr.forEach(t),qJo=r(C3e," \u2014 "),kN=n(C3e,"A",{href:!0});var oQr=s(kN);OJo=r(oQr,"TFLongformerForMultipleChoice"),oQr.forEach(t),GJo=r(C3e," (Longformer model)"),C3e.forEach(t),zJo=i(ae),OT=n(ae,"LI",{});var E3e=s(OT);Fce=n(E3e,"STRONG",{});var rQr=s(Fce);VJo=r(rQr,"mobilebert"),rQr.forEach(t),XJo=r(E3e," \u2014 "),xN=n(E3e,"A",{href:!0});var tQr=s(xN);WJo=r(tQr,"TFMobileBertForMultipleChoice"),tQr.forEach(t),QJo=r(E3e," (MobileBERT model)"),E3e.forEach(t),HJo=i(ae),GT=n(ae,"LI",{});var M3e=s(GT);Cce=n(M3e,"STRONG",{});var aQr=s(Cce);UJo=r(aQr,"mpnet"),aQr.forEach(t),JJo=r(M3e," \u2014 "),RN=n(M3e,"A",{href:!0});var nQr=s(RN);YJo=r(nQr,"TFMPNetForMultipleChoice"),nQr.forEach(t),KJo=r(M3e," (MPNet model)"),M3e.forEach(t),ZJo=i(ae),zT=n(ae,"LI",{});var y3e=s(zT);Ece=n(y3e,"STRONG",{});var sQr=s(Ece);eYo=r(sQr,"rembert"),sQr.forEach(t),oYo=r(y3e," \u2014 "),SN=n(y3e,"A",{href:!0});var lQr=s(SN);rYo=r(lQr,"TFRemBertForMultipleChoice"),lQr.forEach(t),tYo=r(y3e," (RemBERT model)"),y3e.forEach(t),aYo=i(ae),VT=n(ae,"LI",{});var w3e=s(VT);Mce=n(w3e,"STRONG",{});var iQr=s(Mce);nYo=r(iQr,"roberta"),iQr.forEach(t),sYo=r(w3e," \u2014 "),PN=n(w3e,"A",{href:!0});var dQr=s(PN);lYo=r(dQr,"TFRobertaForMultipleChoice"),dQr.forEach(t),iYo=r(w3e," (RoBERTa model)"),w3e.forEach(t),dYo=i(ae),XT=n(ae,"LI",{});var A3e=s(XT);yce=n(A3e,"STRONG",{});var cQr=s(yce);cYo=r(cQr,"roformer"),cQr.forEach(t),fYo=r(A3e," \u2014 "),$N=n(A3e,"A",{href:!0});var fQr=s($N);mYo=r(fQr,"TFRoFormerForMultipleChoice"),fQr.forEach(t),gYo=r(A3e," (RoFormer model)"),A3e.forEach(t),hYo=i(ae),WT=n(ae,"LI",{});var L3e=s(WT);wce=n(L3e,"STRONG",{});var mQr=s(wce);uYo=r(mQr,"xlm"),mQr.forEach(t),pYo=r(L3e," \u2014 "),IN=n(L3e,"A",{href:!0});var gQr=s(IN);_Yo=r(gQr,"TFXLMForMultipleChoice"),gQr.forEach(t),vYo=r(L3e," (XLM model)"),L3e.forEach(t),bYo=i(ae),QT=n(ae,"LI",{});var B3e=s(QT);Ace=n(B3e,"STRONG",{});var hQr=s(Ace);TYo=r(hQr,"xlm-roberta"),hQr.forEach(t),FYo=r(B3e," \u2014 "),jN=n(B3e,"A",{href:!0});var uQr=s(jN);CYo=r(uQr,"TFXLMRobertaForMultipleChoice"),uQr.forEach(t),EYo=r(B3e," (XLM-RoBERTa model)"),B3e.forEach(t),MYo=i(ae),HT=n(ae,"LI",{});var k3e=s(HT);Lce=n(k3e,"STRONG",{});var pQr=s(Lce);yYo=r(pQr,"xlnet"),pQr.forEach(t),wYo=r(k3e," \u2014 "),NN=n(k3e,"A",{href:!0});var _Qr=s(NN);AYo=r(_Qr,"TFXLNetForMultipleChoice"),_Qr.forEach(t),LYo=r(k3e," (XLNet model)"),k3e.forEach(t),ae.forEach(t),BYo=i(sa),Bce=n(sa,"P",{});var vQr=s(Bce);kYo=r(vQr,"Examples:"),vQr.forEach(t),xYo=i(sa),m(Gy.$$.fragment,sa),sa.forEach(t),Tl.forEach(t),pAe=i(d),Qd=n(d,"H2",{class:!0});var p7e=s(Qd);UT=n(p7e,"A",{id:!0,class:!0,href:!0});var bQr=s(UT);kce=n(bQr,"SPAN",{});var TQr=s(kce);m(zy.$$.fragment,TQr),TQr.forEach(t),bQr.forEach(t),RYo=i(p7e),xce=n(p7e,"SPAN",{});var FQr=s(xce);SYo=r(FQr,"TFAutoModelForTableQuestionAnswering"),FQr.forEach(t),p7e.forEach(t),_Ae=i(d),gr=n(d,"DIV",{class:!0});var Cl=s(gr);m(Vy.$$.fragment,Cl),PYo=i(Cl),Hd=n(Cl,"P",{});var pG=s(Hd);$Yo=r(pG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Rce=n(pG,"CODE",{});var CQr=s(Rce);IYo=r(CQr,"from_pretrained()"),CQr.forEach(t),jYo=r(pG,"class method or the "),Sce=n(pG,"CODE",{});var EQr=s(Sce);NYo=r(EQr,"from_config()"),EQr.forEach(t),DYo=r(pG,`class
method.`),pG.forEach(t),qYo=i(Cl),Xy=n(Cl,"P",{});var _7e=s(Xy);OYo=r(_7e,"This class cannot be instantiated directly using "),Pce=n(_7e,"CODE",{});var MQr=s(Pce);GYo=r(MQr,"__init__()"),MQr.forEach(t),zYo=r(_7e," (throws an error)."),_7e.forEach(t),VYo=i(Cl),tt=n(Cl,"DIV",{class:!0});var El=s(tt);m(Wy.$$.fragment,El),XYo=i(El),$ce=n(El,"P",{});var yQr=s($ce);WYo=r(yQr,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),yQr.forEach(t),QYo=i(El),Ud=n(El,"P",{});var _G=s(Ud);HYo=r(_G,`Note:
Loading a model from its configuration file does `),Ice=n(_G,"STRONG",{});var wQr=s(Ice);UYo=r(wQr,"not"),wQr.forEach(t),JYo=r(_G,` load the model weights. It only affects the
model\u2019s configuration. Use `),jce=n(_G,"CODE",{});var AQr=s(jce);YYo=r(AQr,"from_pretrained()"),AQr.forEach(t),KYo=r(_G,"to load the model weights."),_G.forEach(t),ZYo=i(El),Nce=n(El,"P",{});var LQr=s(Nce);eKo=r(LQr,"Examples:"),LQr.forEach(t),oKo=i(El),m(Qy.$$.fragment,El),El.forEach(t),rKo=i(Cl),vo=n(Cl,"DIV",{class:!0});var la=s(vo);m(Hy.$$.fragment,la),tKo=i(la),Dce=n(la,"P",{});var BQr=s(Dce);aKo=r(BQr,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),BQr.forEach(t),nKo=i(la),on=n(la,"P",{});var hE=s(on);sKo=r(hE,"The model class to instantiate is selected based on the "),qce=n(hE,"CODE",{});var kQr=s(qce);lKo=r(kQr,"model_type"),kQr.forEach(t),iKo=r(hE,` property of the config object (either
passed as an argument or loaded from `),Oce=n(hE,"CODE",{});var xQr=s(Oce);dKo=r(xQr,"pretrained_model_name_or_path"),xQr.forEach(t),cKo=r(hE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gce=n(hE,"CODE",{});var RQr=s(Gce);fKo=r(RQr,"pretrained_model_name_or_path"),RQr.forEach(t),mKo=r(hE,":"),hE.forEach(t),gKo=i(la),zce=n(la,"UL",{});var SQr=s(zce);JT=n(SQr,"LI",{});var x3e=s(JT);Vce=n(x3e,"STRONG",{});var PQr=s(Vce);hKo=r(PQr,"tapas"),PQr.forEach(t),uKo=r(x3e," \u2014 "),DN=n(x3e,"A",{href:!0});var $Qr=s(DN);pKo=r($Qr,"TFTapasForQuestionAnswering"),$Qr.forEach(t),_Ko=r(x3e," (TAPAS model)"),x3e.forEach(t),SQr.forEach(t),vKo=i(la),Xce=n(la,"P",{});var IQr=s(Xce);bKo=r(IQr,"Examples:"),IQr.forEach(t),TKo=i(la),m(Uy.$$.fragment,la),la.forEach(t),Cl.forEach(t),vAe=i(d),Jd=n(d,"H2",{class:!0});var v7e=s(Jd);YT=n(v7e,"A",{id:!0,class:!0,href:!0});var jQr=s(YT);Wce=n(jQr,"SPAN",{});var NQr=s(Wce);m(Jy.$$.fragment,NQr),NQr.forEach(t),jQr.forEach(t),FKo=i(v7e),Qce=n(v7e,"SPAN",{});var DQr=s(Qce);CKo=r(DQr,"TFAutoModelForTokenClassification"),DQr.forEach(t),v7e.forEach(t),bAe=i(d),hr=n(d,"DIV",{class:!0});var Ml=s(hr);m(Yy.$$.fragment,Ml),EKo=i(Ml),Yd=n(Ml,"P",{});var vG=s(Yd);MKo=r(vG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Hce=n(vG,"CODE",{});var qQr=s(Hce);yKo=r(qQr,"from_pretrained()"),qQr.forEach(t),wKo=r(vG,"class method or the "),Uce=n(vG,"CODE",{});var OQr=s(Uce);AKo=r(OQr,"from_config()"),OQr.forEach(t),LKo=r(vG,`class
method.`),vG.forEach(t),BKo=i(Ml),Ky=n(Ml,"P",{});var b7e=s(Ky);kKo=r(b7e,"This class cannot be instantiated directly using "),Jce=n(b7e,"CODE",{});var GQr=s(Jce);xKo=r(GQr,"__init__()"),GQr.forEach(t),RKo=r(b7e," (throws an error)."),b7e.forEach(t),SKo=i(Ml),at=n(Ml,"DIV",{class:!0});var yl=s(at);m(Zy.$$.fragment,yl),PKo=i(yl),Yce=n(yl,"P",{});var zQr=s(Yce);$Ko=r(zQr,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),zQr.forEach(t),IKo=i(yl),Kd=n(yl,"P",{});var bG=s(Kd);jKo=r(bG,`Note:
Loading a model from its configuration file does `),Kce=n(bG,"STRONG",{});var VQr=s(Kce);NKo=r(VQr,"not"),VQr.forEach(t),DKo=r(bG,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zce=n(bG,"CODE",{});var XQr=s(Zce);qKo=r(XQr,"from_pretrained()"),XQr.forEach(t),OKo=r(bG,"to load the model weights."),bG.forEach(t),GKo=i(yl),efe=n(yl,"P",{});var WQr=s(efe);zKo=r(WQr,"Examples:"),WQr.forEach(t),VKo=i(yl),m(ew.$$.fragment,yl),yl.forEach(t),XKo=i(Ml),bo=n(Ml,"DIV",{class:!0});var ia=s(bo);m(ow.$$.fragment,ia),WKo=i(ia),ofe=n(ia,"P",{});var QQr=s(ofe);QKo=r(QQr,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),QQr.forEach(t),HKo=i(ia),rn=n(ia,"P",{});var uE=s(rn);UKo=r(uE,"The model class to instantiate is selected based on the "),rfe=n(uE,"CODE",{});var HQr=s(rfe);JKo=r(HQr,"model_type"),HQr.forEach(t),YKo=r(uE,` property of the config object (either
passed as an argument or loaded from `),tfe=n(uE,"CODE",{});var UQr=s(tfe);KKo=r(UQr,"pretrained_model_name_or_path"),UQr.forEach(t),ZKo=r(uE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),afe=n(uE,"CODE",{});var JQr=s(afe);eZo=r(JQr,"pretrained_model_name_or_path"),JQr.forEach(t),oZo=r(uE,":"),uE.forEach(t),rZo=i(ia),K=n(ia,"UL",{});var oe=s(K);KT=n(oe,"LI",{});var R3e=s(KT);nfe=n(R3e,"STRONG",{});var YQr=s(nfe);tZo=r(YQr,"albert"),YQr.forEach(t),aZo=r(R3e," \u2014 "),qN=n(R3e,"A",{href:!0});var KQr=s(qN);nZo=r(KQr,"TFAlbertForTokenClassification"),KQr.forEach(t),sZo=r(R3e," (ALBERT model)"),R3e.forEach(t),lZo=i(oe),ZT=n(oe,"LI",{});var S3e=s(ZT);sfe=n(S3e,"STRONG",{});var ZQr=s(sfe);iZo=r(ZQr,"bert"),ZQr.forEach(t),dZo=r(S3e," \u2014 "),ON=n(S3e,"A",{href:!0});var eHr=s(ON);cZo=r(eHr,"TFBertForTokenClassification"),eHr.forEach(t),fZo=r(S3e," (BERT model)"),S3e.forEach(t),mZo=i(oe),e6=n(oe,"LI",{});var P3e=s(e6);lfe=n(P3e,"STRONG",{});var oHr=s(lfe);gZo=r(oHr,"camembert"),oHr.forEach(t),hZo=r(P3e," \u2014 "),GN=n(P3e,"A",{href:!0});var rHr=s(GN);uZo=r(rHr,"TFCamembertForTokenClassification"),rHr.forEach(t),pZo=r(P3e," (CamemBERT model)"),P3e.forEach(t),_Zo=i(oe),o6=n(oe,"LI",{});var $3e=s(o6);ife=n($3e,"STRONG",{});var tHr=s(ife);vZo=r(tHr,"convbert"),tHr.forEach(t),bZo=r($3e," \u2014 "),zN=n($3e,"A",{href:!0});var aHr=s(zN);TZo=r(aHr,"TFConvBertForTokenClassification"),aHr.forEach(t),FZo=r($3e," (ConvBERT model)"),$3e.forEach(t),CZo=i(oe),r6=n(oe,"LI",{});var I3e=s(r6);dfe=n(I3e,"STRONG",{});var nHr=s(dfe);EZo=r(nHr,"deberta"),nHr.forEach(t),MZo=r(I3e," \u2014 "),VN=n(I3e,"A",{href:!0});var sHr=s(VN);yZo=r(sHr,"TFDebertaForTokenClassification"),sHr.forEach(t),wZo=r(I3e," (DeBERTa model)"),I3e.forEach(t),AZo=i(oe),t6=n(oe,"LI",{});var j3e=s(t6);cfe=n(j3e,"STRONG",{});var lHr=s(cfe);LZo=r(lHr,"deberta-v2"),lHr.forEach(t),BZo=r(j3e," \u2014 "),XN=n(j3e,"A",{href:!0});var iHr=s(XN);kZo=r(iHr,"TFDebertaV2ForTokenClassification"),iHr.forEach(t),xZo=r(j3e," (DeBERTa-v2 model)"),j3e.forEach(t),RZo=i(oe),a6=n(oe,"LI",{});var N3e=s(a6);ffe=n(N3e,"STRONG",{});var dHr=s(ffe);SZo=r(dHr,"distilbert"),dHr.forEach(t),PZo=r(N3e," \u2014 "),WN=n(N3e,"A",{href:!0});var cHr=s(WN);$Zo=r(cHr,"TFDistilBertForTokenClassification"),cHr.forEach(t),IZo=r(N3e," (DistilBERT model)"),N3e.forEach(t),jZo=i(oe),n6=n(oe,"LI",{});var D3e=s(n6);mfe=n(D3e,"STRONG",{});var fHr=s(mfe);NZo=r(fHr,"electra"),fHr.forEach(t),DZo=r(D3e," \u2014 "),QN=n(D3e,"A",{href:!0});var mHr=s(QN);qZo=r(mHr,"TFElectraForTokenClassification"),mHr.forEach(t),OZo=r(D3e," (ELECTRA model)"),D3e.forEach(t),GZo=i(oe),s6=n(oe,"LI",{});var q3e=s(s6);gfe=n(q3e,"STRONG",{});var gHr=s(gfe);zZo=r(gHr,"flaubert"),gHr.forEach(t),VZo=r(q3e," \u2014 "),HN=n(q3e,"A",{href:!0});var hHr=s(HN);XZo=r(hHr,"TFFlaubertForTokenClassification"),hHr.forEach(t),WZo=r(q3e," (FlauBERT model)"),q3e.forEach(t),QZo=i(oe),l6=n(oe,"LI",{});var O3e=s(l6);hfe=n(O3e,"STRONG",{});var uHr=s(hfe);HZo=r(uHr,"funnel"),uHr.forEach(t),UZo=r(O3e," \u2014 "),UN=n(O3e,"A",{href:!0});var pHr=s(UN);JZo=r(pHr,"TFFunnelForTokenClassification"),pHr.forEach(t),YZo=r(O3e," (Funnel Transformer model)"),O3e.forEach(t),KZo=i(oe),i6=n(oe,"LI",{});var G3e=s(i6);ufe=n(G3e,"STRONG",{});var _Hr=s(ufe);ZZo=r(_Hr,"layoutlm"),_Hr.forEach(t),eer=r(G3e," \u2014 "),JN=n(G3e,"A",{href:!0});var vHr=s(JN);oer=r(vHr,"TFLayoutLMForTokenClassification"),vHr.forEach(t),rer=r(G3e," (LayoutLM model)"),G3e.forEach(t),ter=i(oe),d6=n(oe,"LI",{});var z3e=s(d6);pfe=n(z3e,"STRONG",{});var bHr=s(pfe);aer=r(bHr,"longformer"),bHr.forEach(t),ner=r(z3e," \u2014 "),YN=n(z3e,"A",{href:!0});var THr=s(YN);ser=r(THr,"TFLongformerForTokenClassification"),THr.forEach(t),ler=r(z3e," (Longformer model)"),z3e.forEach(t),ier=i(oe),c6=n(oe,"LI",{});var V3e=s(c6);_fe=n(V3e,"STRONG",{});var FHr=s(_fe);der=r(FHr,"mobilebert"),FHr.forEach(t),cer=r(V3e," \u2014 "),KN=n(V3e,"A",{href:!0});var CHr=s(KN);fer=r(CHr,"TFMobileBertForTokenClassification"),CHr.forEach(t),mer=r(V3e," (MobileBERT model)"),V3e.forEach(t),ger=i(oe),f6=n(oe,"LI",{});var X3e=s(f6);vfe=n(X3e,"STRONG",{});var EHr=s(vfe);her=r(EHr,"mpnet"),EHr.forEach(t),uer=r(X3e," \u2014 "),ZN=n(X3e,"A",{href:!0});var MHr=s(ZN);per=r(MHr,"TFMPNetForTokenClassification"),MHr.forEach(t),_er=r(X3e," (MPNet model)"),X3e.forEach(t),ver=i(oe),m6=n(oe,"LI",{});var W3e=s(m6);bfe=n(W3e,"STRONG",{});var yHr=s(bfe);ber=r(yHr,"rembert"),yHr.forEach(t),Ter=r(W3e," \u2014 "),eD=n(W3e,"A",{href:!0});var wHr=s(eD);Fer=r(wHr,"TFRemBertForTokenClassification"),wHr.forEach(t),Cer=r(W3e," (RemBERT model)"),W3e.forEach(t),Eer=i(oe),g6=n(oe,"LI",{});var Q3e=s(g6);Tfe=n(Q3e,"STRONG",{});var AHr=s(Tfe);Mer=r(AHr,"roberta"),AHr.forEach(t),yer=r(Q3e," \u2014 "),oD=n(Q3e,"A",{href:!0});var LHr=s(oD);wer=r(LHr,"TFRobertaForTokenClassification"),LHr.forEach(t),Aer=r(Q3e," (RoBERTa model)"),Q3e.forEach(t),Ler=i(oe),h6=n(oe,"LI",{});var H3e=s(h6);Ffe=n(H3e,"STRONG",{});var BHr=s(Ffe);Ber=r(BHr,"roformer"),BHr.forEach(t),ker=r(H3e," \u2014 "),rD=n(H3e,"A",{href:!0});var kHr=s(rD);xer=r(kHr,"TFRoFormerForTokenClassification"),kHr.forEach(t),Rer=r(H3e," (RoFormer model)"),H3e.forEach(t),Ser=i(oe),u6=n(oe,"LI",{});var U3e=s(u6);Cfe=n(U3e,"STRONG",{});var xHr=s(Cfe);Per=r(xHr,"xlm"),xHr.forEach(t),$er=r(U3e," \u2014 "),tD=n(U3e,"A",{href:!0});var RHr=s(tD);Ier=r(RHr,"TFXLMForTokenClassification"),RHr.forEach(t),jer=r(U3e," (XLM model)"),U3e.forEach(t),Ner=i(oe),p6=n(oe,"LI",{});var J3e=s(p6);Efe=n(J3e,"STRONG",{});var SHr=s(Efe);Der=r(SHr,"xlm-roberta"),SHr.forEach(t),qer=r(J3e," \u2014 "),aD=n(J3e,"A",{href:!0});var PHr=s(aD);Oer=r(PHr,"TFXLMRobertaForTokenClassification"),PHr.forEach(t),Ger=r(J3e," (XLM-RoBERTa model)"),J3e.forEach(t),zer=i(oe),_6=n(oe,"LI",{});var Y3e=s(_6);Mfe=n(Y3e,"STRONG",{});var $Hr=s(Mfe);Ver=r($Hr,"xlnet"),$Hr.forEach(t),Xer=r(Y3e," \u2014 "),nD=n(Y3e,"A",{href:!0});var IHr=s(nD);Wer=r(IHr,"TFXLNetForTokenClassification"),IHr.forEach(t),Qer=r(Y3e," (XLNet model)"),Y3e.forEach(t),oe.forEach(t),Her=i(ia),yfe=n(ia,"P",{});var jHr=s(yfe);Uer=r(jHr,"Examples:"),jHr.forEach(t),Jer=i(ia),m(rw.$$.fragment,ia),ia.forEach(t),Ml.forEach(t),TAe=i(d),Zd=n(d,"H2",{class:!0});var T7e=s(Zd);v6=n(T7e,"A",{id:!0,class:!0,href:!0});var NHr=s(v6);wfe=n(NHr,"SPAN",{});var DHr=s(wfe);m(tw.$$.fragment,DHr),DHr.forEach(t),NHr.forEach(t),Yer=i(T7e),Afe=n(T7e,"SPAN",{});var qHr=s(Afe);Ker=r(qHr,"TFAutoModelForQuestionAnswering"),qHr.forEach(t),T7e.forEach(t),FAe=i(d),ur=n(d,"DIV",{class:!0});var wl=s(ur);m(aw.$$.fragment,wl),Zer=i(wl),ec=n(wl,"P",{});var TG=s(ec);eor=r(TG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Lfe=n(TG,"CODE",{});var OHr=s(Lfe);oor=r(OHr,"from_pretrained()"),OHr.forEach(t),ror=r(TG,"class method or the "),Bfe=n(TG,"CODE",{});var GHr=s(Bfe);tor=r(GHr,"from_config()"),GHr.forEach(t),aor=r(TG,`class
method.`),TG.forEach(t),nor=i(wl),nw=n(wl,"P",{});var F7e=s(nw);sor=r(F7e,"This class cannot be instantiated directly using "),kfe=n(F7e,"CODE",{});var zHr=s(kfe);lor=r(zHr,"__init__()"),zHr.forEach(t),ior=r(F7e," (throws an error)."),F7e.forEach(t),dor=i(wl),nt=n(wl,"DIV",{class:!0});var Al=s(nt);m(sw.$$.fragment,Al),cor=i(Al),xfe=n(Al,"P",{});var VHr=s(xfe);mor=r(VHr,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),VHr.forEach(t),gor=i(Al),oc=n(Al,"P",{});var FG=s(oc);hor=r(FG,`Note:
Loading a model from its configuration file does `),Rfe=n(FG,"STRONG",{});var XHr=s(Rfe);uor=r(XHr,"not"),XHr.forEach(t),por=r(FG,` load the model weights. It only affects the
model\u2019s configuration. Use `),Sfe=n(FG,"CODE",{});var WHr=s(Sfe);_or=r(WHr,"from_pretrained()"),WHr.forEach(t),vor=r(FG,"to load the model weights."),FG.forEach(t),bor=i(Al),Pfe=n(Al,"P",{});var QHr=s(Pfe);Tor=r(QHr,"Examples:"),QHr.forEach(t),For=i(Al),m(lw.$$.fragment,Al),Al.forEach(t),Cor=i(wl),To=n(wl,"DIV",{class:!0});var da=s(To);m(iw.$$.fragment,da),Eor=i(da),$fe=n(da,"P",{});var HHr=s($fe);Mor=r(HHr,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),HHr.forEach(t),yor=i(da),tn=n(da,"P",{});var pE=s(tn);wor=r(pE,"The model class to instantiate is selected based on the "),Ife=n(pE,"CODE",{});var UHr=s(Ife);Aor=r(UHr,"model_type"),UHr.forEach(t),Lor=r(pE,` property of the config object (either
passed as an argument or loaded from `),jfe=n(pE,"CODE",{});var JHr=s(jfe);Bor=r(JHr,"pretrained_model_name_or_path"),JHr.forEach(t),kor=r(pE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nfe=n(pE,"CODE",{});var YHr=s(Nfe);xor=r(YHr,"pretrained_model_name_or_path"),YHr.forEach(t),Ror=r(pE,":"),pE.forEach(t),Sor=i(da),Z=n(da,"UL",{});var re=s(Z);b6=n(re,"LI",{});var K3e=s(b6);Dfe=n(K3e,"STRONG",{});var KHr=s(Dfe);Por=r(KHr,"albert"),KHr.forEach(t),$or=r(K3e," \u2014 "),sD=n(K3e,"A",{href:!0});var ZHr=s(sD);Ior=r(ZHr,"TFAlbertForQuestionAnswering"),ZHr.forEach(t),jor=r(K3e," (ALBERT model)"),K3e.forEach(t),Nor=i(re),T6=n(re,"LI",{});var Z3e=s(T6);qfe=n(Z3e,"STRONG",{});var eUr=s(qfe);Dor=r(eUr,"bert"),eUr.forEach(t),qor=r(Z3e," \u2014 "),lD=n(Z3e,"A",{href:!0});var oUr=s(lD);Oor=r(oUr,"TFBertForQuestionAnswering"),oUr.forEach(t),Gor=r(Z3e," (BERT model)"),Z3e.forEach(t),zor=i(re),F6=n(re,"LI",{});var e5e=s(F6);Ofe=n(e5e,"STRONG",{});var rUr=s(Ofe);Vor=r(rUr,"camembert"),rUr.forEach(t),Xor=r(e5e," \u2014 "),iD=n(e5e,"A",{href:!0});var tUr=s(iD);Wor=r(tUr,"TFCamembertForQuestionAnswering"),tUr.forEach(t),Qor=r(e5e," (CamemBERT model)"),e5e.forEach(t),Hor=i(re),C6=n(re,"LI",{});var o5e=s(C6);Gfe=n(o5e,"STRONG",{});var aUr=s(Gfe);Uor=r(aUr,"convbert"),aUr.forEach(t),Jor=r(o5e," \u2014 "),dD=n(o5e,"A",{href:!0});var nUr=s(dD);Yor=r(nUr,"TFConvBertForQuestionAnswering"),nUr.forEach(t),Kor=r(o5e," (ConvBERT model)"),o5e.forEach(t),Zor=i(re),E6=n(re,"LI",{});var r5e=s(E6);zfe=n(r5e,"STRONG",{});var sUr=s(zfe);err=r(sUr,"deberta"),sUr.forEach(t),orr=r(r5e," \u2014 "),cD=n(r5e,"A",{href:!0});var lUr=s(cD);rrr=r(lUr,"TFDebertaForQuestionAnswering"),lUr.forEach(t),trr=r(r5e," (DeBERTa model)"),r5e.forEach(t),arr=i(re),M6=n(re,"LI",{});var t5e=s(M6);Vfe=n(t5e,"STRONG",{});var iUr=s(Vfe);nrr=r(iUr,"deberta-v2"),iUr.forEach(t),srr=r(t5e," \u2014 "),fD=n(t5e,"A",{href:!0});var dUr=s(fD);lrr=r(dUr,"TFDebertaV2ForQuestionAnswering"),dUr.forEach(t),irr=r(t5e," (DeBERTa-v2 model)"),t5e.forEach(t),drr=i(re),y6=n(re,"LI",{});var a5e=s(y6);Xfe=n(a5e,"STRONG",{});var cUr=s(Xfe);crr=r(cUr,"distilbert"),cUr.forEach(t),frr=r(a5e," \u2014 "),mD=n(a5e,"A",{href:!0});var fUr=s(mD);mrr=r(fUr,"TFDistilBertForQuestionAnswering"),fUr.forEach(t),grr=r(a5e," (DistilBERT model)"),a5e.forEach(t),hrr=i(re),w6=n(re,"LI",{});var n5e=s(w6);Wfe=n(n5e,"STRONG",{});var mUr=s(Wfe);urr=r(mUr,"electra"),mUr.forEach(t),prr=r(n5e," \u2014 "),gD=n(n5e,"A",{href:!0});var gUr=s(gD);_rr=r(gUr,"TFElectraForQuestionAnswering"),gUr.forEach(t),vrr=r(n5e," (ELECTRA model)"),n5e.forEach(t),brr=i(re),A6=n(re,"LI",{});var s5e=s(A6);Qfe=n(s5e,"STRONG",{});var hUr=s(Qfe);Trr=r(hUr,"flaubert"),hUr.forEach(t),Frr=r(s5e," \u2014 "),hD=n(s5e,"A",{href:!0});var uUr=s(hD);Crr=r(uUr,"TFFlaubertForQuestionAnsweringSimple"),uUr.forEach(t),Err=r(s5e," (FlauBERT model)"),s5e.forEach(t),Mrr=i(re),L6=n(re,"LI",{});var l5e=s(L6);Hfe=n(l5e,"STRONG",{});var pUr=s(Hfe);yrr=r(pUr,"funnel"),pUr.forEach(t),wrr=r(l5e," \u2014 "),uD=n(l5e,"A",{href:!0});var _Ur=s(uD);Arr=r(_Ur,"TFFunnelForQuestionAnswering"),_Ur.forEach(t),Lrr=r(l5e," (Funnel Transformer model)"),l5e.forEach(t),Brr=i(re),B6=n(re,"LI",{});var i5e=s(B6);Ufe=n(i5e,"STRONG",{});var vUr=s(Ufe);krr=r(vUr,"longformer"),vUr.forEach(t),xrr=r(i5e," \u2014 "),pD=n(i5e,"A",{href:!0});var bUr=s(pD);Rrr=r(bUr,"TFLongformerForQuestionAnswering"),bUr.forEach(t),Srr=r(i5e," (Longformer model)"),i5e.forEach(t),Prr=i(re),k6=n(re,"LI",{});var d5e=s(k6);Jfe=n(d5e,"STRONG",{});var TUr=s(Jfe);$rr=r(TUr,"mobilebert"),TUr.forEach(t),Irr=r(d5e," \u2014 "),_D=n(d5e,"A",{href:!0});var FUr=s(_D);jrr=r(FUr,"TFMobileBertForQuestionAnswering"),FUr.forEach(t),Nrr=r(d5e," (MobileBERT model)"),d5e.forEach(t),Drr=i(re),x6=n(re,"LI",{});var c5e=s(x6);Yfe=n(c5e,"STRONG",{});var CUr=s(Yfe);qrr=r(CUr,"mpnet"),CUr.forEach(t),Orr=r(c5e," \u2014 "),vD=n(c5e,"A",{href:!0});var EUr=s(vD);Grr=r(EUr,"TFMPNetForQuestionAnswering"),EUr.forEach(t),zrr=r(c5e," (MPNet model)"),c5e.forEach(t),Vrr=i(re),R6=n(re,"LI",{});var f5e=s(R6);Kfe=n(f5e,"STRONG",{});var MUr=s(Kfe);Xrr=r(MUr,"rembert"),MUr.forEach(t),Wrr=r(f5e," \u2014 "),bD=n(f5e,"A",{href:!0});var yUr=s(bD);Qrr=r(yUr,"TFRemBertForQuestionAnswering"),yUr.forEach(t),Hrr=r(f5e," (RemBERT model)"),f5e.forEach(t),Urr=i(re),S6=n(re,"LI",{});var m5e=s(S6);Zfe=n(m5e,"STRONG",{});var wUr=s(Zfe);Jrr=r(wUr,"roberta"),wUr.forEach(t),Yrr=r(m5e," \u2014 "),TD=n(m5e,"A",{href:!0});var AUr=s(TD);Krr=r(AUr,"TFRobertaForQuestionAnswering"),AUr.forEach(t),Zrr=r(m5e," (RoBERTa model)"),m5e.forEach(t),etr=i(re),P6=n(re,"LI",{});var g5e=s(P6);eme=n(g5e,"STRONG",{});var LUr=s(eme);otr=r(LUr,"roformer"),LUr.forEach(t),rtr=r(g5e," \u2014 "),FD=n(g5e,"A",{href:!0});var BUr=s(FD);ttr=r(BUr,"TFRoFormerForQuestionAnswering"),BUr.forEach(t),atr=r(g5e," (RoFormer model)"),g5e.forEach(t),ntr=i(re),$6=n(re,"LI",{});var h5e=s($6);ome=n(h5e,"STRONG",{});var kUr=s(ome);str=r(kUr,"xlm"),kUr.forEach(t),ltr=r(h5e," \u2014 "),CD=n(h5e,"A",{href:!0});var xUr=s(CD);itr=r(xUr,"TFXLMForQuestionAnsweringSimple"),xUr.forEach(t),dtr=r(h5e," (XLM model)"),h5e.forEach(t),ctr=i(re),I6=n(re,"LI",{});var u5e=s(I6);rme=n(u5e,"STRONG",{});var RUr=s(rme);ftr=r(RUr,"xlm-roberta"),RUr.forEach(t),mtr=r(u5e," \u2014 "),ED=n(u5e,"A",{href:!0});var SUr=s(ED);gtr=r(SUr,"TFXLMRobertaForQuestionAnswering"),SUr.forEach(t),htr=r(u5e," (XLM-RoBERTa model)"),u5e.forEach(t),utr=i(re),j6=n(re,"LI",{});var p5e=s(j6);tme=n(p5e,"STRONG",{});var PUr=s(tme);ptr=r(PUr,"xlnet"),PUr.forEach(t),_tr=r(p5e," \u2014 "),MD=n(p5e,"A",{href:!0});var $Ur=s(MD);vtr=r($Ur,"TFXLNetForQuestionAnsweringSimple"),$Ur.forEach(t),btr=r(p5e," (XLNet model)"),p5e.forEach(t),re.forEach(t),Ttr=i(da),ame=n(da,"P",{});var IUr=s(ame);Ftr=r(IUr,"Examples:"),IUr.forEach(t),Ctr=i(da),m(dw.$$.fragment,da),da.forEach(t),wl.forEach(t),CAe=i(d),rc=n(d,"H2",{class:!0});var C7e=s(rc);N6=n(C7e,"A",{id:!0,class:!0,href:!0});var jUr=s(N6);nme=n(jUr,"SPAN",{});var NUr=s(nme);m(cw.$$.fragment,NUr),NUr.forEach(t),jUr.forEach(t),Etr=i(C7e),sme=n(C7e,"SPAN",{});var DUr=s(sme);Mtr=r(DUr,"TFAutoModelForVision2Seq"),DUr.forEach(t),C7e.forEach(t),EAe=i(d),pr=n(d,"DIV",{class:!0});var Ll=s(pr);m(fw.$$.fragment,Ll),ytr=i(Ll),tc=n(Ll,"P",{});var CG=s(tc);wtr=r(CG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),lme=n(CG,"CODE",{});var qUr=s(lme);Atr=r(qUr,"from_pretrained()"),qUr.forEach(t),Ltr=r(CG,"class method or the "),ime=n(CG,"CODE",{});var OUr=s(ime);Btr=r(OUr,"from_config()"),OUr.forEach(t),ktr=r(CG,`class
method.`),CG.forEach(t),xtr=i(Ll),mw=n(Ll,"P",{});var E7e=s(mw);Rtr=r(E7e,"This class cannot be instantiated directly using "),dme=n(E7e,"CODE",{});var GUr=s(dme);Str=r(GUr,"__init__()"),GUr.forEach(t),Ptr=r(E7e," (throws an error)."),E7e.forEach(t),$tr=i(Ll),st=n(Ll,"DIV",{class:!0});var Bl=s(st);m(gw.$$.fragment,Bl),Itr=i(Bl),cme=n(Bl,"P",{});var zUr=s(cme);jtr=r(zUr,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),zUr.forEach(t),Ntr=i(Bl),ac=n(Bl,"P",{});var EG=s(ac);Dtr=r(EG,`Note:
Loading a model from its configuration file does `),fme=n(EG,"STRONG",{});var VUr=s(fme);qtr=r(VUr,"not"),VUr.forEach(t),Otr=r(EG,` load the model weights. It only affects the
model\u2019s configuration. Use `),mme=n(EG,"CODE",{});var XUr=s(mme);Gtr=r(XUr,"from_pretrained()"),XUr.forEach(t),ztr=r(EG,"to load the model weights."),EG.forEach(t),Vtr=i(Bl),gme=n(Bl,"P",{});var WUr=s(gme);Xtr=r(WUr,"Examples:"),WUr.forEach(t),Wtr=i(Bl),m(hw.$$.fragment,Bl),Bl.forEach(t),Qtr=i(Ll),Fo=n(Ll,"DIV",{class:!0});var ca=s(Fo);m(uw.$$.fragment,ca),Htr=i(ca),hme=n(ca,"P",{});var QUr=s(hme);Utr=r(QUr,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),QUr.forEach(t),Jtr=i(ca),an=n(ca,"P",{});var _E=s(an);Ytr=r(_E,"The model class to instantiate is selected based on the "),ume=n(_E,"CODE",{});var HUr=s(ume);Ktr=r(HUr,"model_type"),HUr.forEach(t),Ztr=r(_E,` property of the config object (either
passed as an argument or loaded from `),pme=n(_E,"CODE",{});var UUr=s(pme);ear=r(UUr,"pretrained_model_name_or_path"),UUr.forEach(t),oar=r(_E,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_me=n(_E,"CODE",{});var JUr=s(_me);rar=r(JUr,"pretrained_model_name_or_path"),JUr.forEach(t),tar=r(_E,":"),_E.forEach(t),aar=i(ca),vme=n(ca,"UL",{});var YUr=s(vme);D6=n(YUr,"LI",{});var _5e=s(D6);bme=n(_5e,"STRONG",{});var KUr=s(bme);nar=r(KUr,"vision-encoder-decoder"),KUr.forEach(t),sar=r(_5e," \u2014 "),yD=n(_5e,"A",{href:!0});var ZUr=s(yD);lar=r(ZUr,"TFVisionEncoderDecoderModel"),ZUr.forEach(t),iar=r(_5e," (Vision Encoder decoder model)"),_5e.forEach(t),YUr.forEach(t),dar=i(ca),Tme=n(ca,"P",{});var eJr=s(Tme);car=r(eJr,"Examples:"),eJr.forEach(t),far=i(ca),m(pw.$$.fragment,ca),ca.forEach(t),Ll.forEach(t),MAe=i(d),nc=n(d,"H2",{class:!0});var M7e=s(nc);q6=n(M7e,"A",{id:!0,class:!0,href:!0});var oJr=s(q6);Fme=n(oJr,"SPAN",{});var rJr=s(Fme);m(_w.$$.fragment,rJr),rJr.forEach(t),oJr.forEach(t),mar=i(M7e),Cme=n(M7e,"SPAN",{});var tJr=s(Cme);gar=r(tJr,"FlaxAutoModel"),tJr.forEach(t),M7e.forEach(t),yAe=i(d),_r=n(d,"DIV",{class:!0});var kl=s(_r);m(vw.$$.fragment,kl),har=i(kl),sc=n(kl,"P",{});var MG=s(sc);uar=r(MG,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Eme=n(MG,"CODE",{});var aJr=s(Eme);par=r(aJr,"from_pretrained()"),aJr.forEach(t),_ar=r(MG,"class method or the "),Mme=n(MG,"CODE",{});var nJr=s(Mme);bar=r(nJr,"from_config()"),nJr.forEach(t),Tar=r(MG,`class
method.`),MG.forEach(t),Far=i(kl),bw=n(kl,"P",{});var y7e=s(bw);Car=r(y7e,"This class cannot be instantiated directly using "),yme=n(y7e,"CODE",{});var sJr=s(yme);Ear=r(sJr,"__init__()"),sJr.forEach(t),Mar=r(y7e," (throws an error)."),y7e.forEach(t),yar=i(kl),lt=n(kl,"DIV",{class:!0});var xl=s(lt);m(Tw.$$.fragment,xl),war=i(xl),wme=n(xl,"P",{});var lJr=s(wme);Aar=r(lJr,"Instantiates one of the base model classes of the library from a configuration."),lJr.forEach(t),Lar=i(xl),lc=n(xl,"P",{});var yG=s(lc);Bar=r(yG,`Note:
Loading a model from its configuration file does `),Ame=n(yG,"STRONG",{});var iJr=s(Ame);kar=r(iJr,"not"),iJr.forEach(t),xar=r(yG,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lme=n(yG,"CODE",{});var dJr=s(Lme);Rar=r(dJr,"from_pretrained()"),dJr.forEach(t),Sar=r(yG,"to load the model weights."),yG.forEach(t),Par=i(xl),Bme=n(xl,"P",{});var cJr=s(Bme);$ar=r(cJr,"Examples:"),cJr.forEach(t),Iar=i(xl),m(Fw.$$.fragment,xl),xl.forEach(t),jar=i(kl),Co=n(kl,"DIV",{class:!0});var fa=s(Co);m(Cw.$$.fragment,fa),Nar=i(fa),kme=n(fa,"P",{});var fJr=s(kme);Dar=r(fJr,"Instantiate one of the base model classes of the library from a pretrained model."),fJr.forEach(t),qar=i(fa),nn=n(fa,"P",{});var vE=s(nn);Oar=r(vE,"The model class to instantiate is selected based on the "),xme=n(vE,"CODE",{});var mJr=s(xme);Gar=r(mJr,"model_type"),mJr.forEach(t),zar=r(vE,` property of the config object (either
passed as an argument or loaded from `),Rme=n(vE,"CODE",{});var gJr=s(Rme);Var=r(gJr,"pretrained_model_name_or_path"),gJr.forEach(t),Xar=r(vE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sme=n(vE,"CODE",{});var hJr=s(Sme);War=r(hJr,"pretrained_model_name_or_path"),hJr.forEach(t),Qar=r(vE,":"),vE.forEach(t),Har=i(fa),W=n(fa,"UL",{});var H=s(W);O6=n(H,"LI",{});var v5e=s(O6);Pme=n(v5e,"STRONG",{});var uJr=s(Pme);Uar=r(uJr,"albert"),uJr.forEach(t),Jar=r(v5e," \u2014 "),wD=n(v5e,"A",{href:!0});var pJr=s(wD);Yar=r(pJr,"FlaxAlbertModel"),pJr.forEach(t),Kar=r(v5e," (ALBERT model)"),v5e.forEach(t),Zar=i(H),G6=n(H,"LI",{});var b5e=s(G6);$me=n(b5e,"STRONG",{});var _Jr=s($me);enr=r(_Jr,"bart"),_Jr.forEach(t),onr=r(b5e," \u2014 "),AD=n(b5e,"A",{href:!0});var vJr=s(AD);rnr=r(vJr,"FlaxBartModel"),vJr.forEach(t),tnr=r(b5e," (BART model)"),b5e.forEach(t),anr=i(H),z6=n(H,"LI",{});var T5e=s(z6);Ime=n(T5e,"STRONG",{});var bJr=s(Ime);nnr=r(bJr,"beit"),bJr.forEach(t),snr=r(T5e," \u2014 "),LD=n(T5e,"A",{href:!0});var TJr=s(LD);lnr=r(TJr,"FlaxBeitModel"),TJr.forEach(t),inr=r(T5e," (BEiT model)"),T5e.forEach(t),dnr=i(H),V6=n(H,"LI",{});var F5e=s(V6);jme=n(F5e,"STRONG",{});var FJr=s(jme);cnr=r(FJr,"bert"),FJr.forEach(t),fnr=r(F5e," \u2014 "),BD=n(F5e,"A",{href:!0});var CJr=s(BD);mnr=r(CJr,"FlaxBertModel"),CJr.forEach(t),gnr=r(F5e," (BERT model)"),F5e.forEach(t),hnr=i(H),X6=n(H,"LI",{});var C5e=s(X6);Nme=n(C5e,"STRONG",{});var EJr=s(Nme);unr=r(EJr,"big_bird"),EJr.forEach(t),pnr=r(C5e," \u2014 "),kD=n(C5e,"A",{href:!0});var MJr=s(kD);_nr=r(MJr,"FlaxBigBirdModel"),MJr.forEach(t),vnr=r(C5e," (BigBird model)"),C5e.forEach(t),bnr=i(H),W6=n(H,"LI",{});var E5e=s(W6);Dme=n(E5e,"STRONG",{});var yJr=s(Dme);Tnr=r(yJr,"blenderbot"),yJr.forEach(t),Fnr=r(E5e," \u2014 "),xD=n(E5e,"A",{href:!0});var wJr=s(xD);Cnr=r(wJr,"FlaxBlenderbotModel"),wJr.forEach(t),Enr=r(E5e," (Blenderbot model)"),E5e.forEach(t),Mnr=i(H),Q6=n(H,"LI",{});var M5e=s(Q6);qme=n(M5e,"STRONG",{});var AJr=s(qme);ynr=r(AJr,"blenderbot-small"),AJr.forEach(t),wnr=r(M5e," \u2014 "),RD=n(M5e,"A",{href:!0});var LJr=s(RD);Anr=r(LJr,"FlaxBlenderbotSmallModel"),LJr.forEach(t),Lnr=r(M5e," (BlenderbotSmall model)"),M5e.forEach(t),Bnr=i(H),H6=n(H,"LI",{});var y5e=s(H6);Ome=n(y5e,"STRONG",{});var BJr=s(Ome);knr=r(BJr,"clip"),BJr.forEach(t),xnr=r(y5e," \u2014 "),SD=n(y5e,"A",{href:!0});var kJr=s(SD);Rnr=r(kJr,"FlaxCLIPModel"),kJr.forEach(t),Snr=r(y5e," (CLIP model)"),y5e.forEach(t),Pnr=i(H),U6=n(H,"LI",{});var w5e=s(U6);Gme=n(w5e,"STRONG",{});var xJr=s(Gme);$nr=r(xJr,"distilbert"),xJr.forEach(t),Inr=r(w5e," \u2014 "),PD=n(w5e,"A",{href:!0});var RJr=s(PD);jnr=r(RJr,"FlaxDistilBertModel"),RJr.forEach(t),Nnr=r(w5e," (DistilBERT model)"),w5e.forEach(t),Dnr=i(H),J6=n(H,"LI",{});var A5e=s(J6);zme=n(A5e,"STRONG",{});var SJr=s(zme);qnr=r(SJr,"electra"),SJr.forEach(t),Onr=r(A5e," \u2014 "),$D=n(A5e,"A",{href:!0});var PJr=s($D);Gnr=r(PJr,"FlaxElectraModel"),PJr.forEach(t),znr=r(A5e," (ELECTRA model)"),A5e.forEach(t),Vnr=i(H),Y6=n(H,"LI",{});var L5e=s(Y6);Vme=n(L5e,"STRONG",{});var $Jr=s(Vme);Xnr=r($Jr,"gpt2"),$Jr.forEach(t),Wnr=r(L5e," \u2014 "),ID=n(L5e,"A",{href:!0});var IJr=s(ID);Qnr=r(IJr,"FlaxGPT2Model"),IJr.forEach(t),Hnr=r(L5e," (OpenAI GPT-2 model)"),L5e.forEach(t),Unr=i(H),K6=n(H,"LI",{});var B5e=s(K6);Xme=n(B5e,"STRONG",{});var jJr=s(Xme);Jnr=r(jJr,"gpt_neo"),jJr.forEach(t),Ynr=r(B5e," \u2014 "),jD=n(B5e,"A",{href:!0});var NJr=s(jD);Knr=r(NJr,"FlaxGPTNeoModel"),NJr.forEach(t),Znr=r(B5e," (GPT Neo model)"),B5e.forEach(t),esr=i(H),Z6=n(H,"LI",{});var k5e=s(Z6);Wme=n(k5e,"STRONG",{});var DJr=s(Wme);osr=r(DJr,"gptj"),DJr.forEach(t),rsr=r(k5e," \u2014 "),ND=n(k5e,"A",{href:!0});var qJr=s(ND);tsr=r(qJr,"FlaxGPTJModel"),qJr.forEach(t),asr=r(k5e," (GPT-J model)"),k5e.forEach(t),nsr=i(H),eF=n(H,"LI",{});var x5e=s(eF);Qme=n(x5e,"STRONG",{});var OJr=s(Qme);ssr=r(OJr,"marian"),OJr.forEach(t),lsr=r(x5e," \u2014 "),DD=n(x5e,"A",{href:!0});var GJr=s(DD);isr=r(GJr,"FlaxMarianModel"),GJr.forEach(t),dsr=r(x5e," (Marian model)"),x5e.forEach(t),csr=i(H),oF=n(H,"LI",{});var R5e=s(oF);Hme=n(R5e,"STRONG",{});var zJr=s(Hme);fsr=r(zJr,"mbart"),zJr.forEach(t),msr=r(R5e," \u2014 "),qD=n(R5e,"A",{href:!0});var VJr=s(qD);gsr=r(VJr,"FlaxMBartModel"),VJr.forEach(t),hsr=r(R5e," (mBART model)"),R5e.forEach(t),usr=i(H),rF=n(H,"LI",{});var S5e=s(rF);Ume=n(S5e,"STRONG",{});var XJr=s(Ume);psr=r(XJr,"mt5"),XJr.forEach(t),_sr=r(S5e," \u2014 "),OD=n(S5e,"A",{href:!0});var WJr=s(OD);vsr=r(WJr,"FlaxMT5Model"),WJr.forEach(t),bsr=r(S5e," (mT5 model)"),S5e.forEach(t),Tsr=i(H),tF=n(H,"LI",{});var P5e=s(tF);Jme=n(P5e,"STRONG",{});var QJr=s(Jme);Fsr=r(QJr,"pegasus"),QJr.forEach(t),Csr=r(P5e," \u2014 "),GD=n(P5e,"A",{href:!0});var HJr=s(GD);Esr=r(HJr,"FlaxPegasusModel"),HJr.forEach(t),Msr=r(P5e," (Pegasus model)"),P5e.forEach(t),ysr=i(H),aF=n(H,"LI",{});var $5e=s(aF);Yme=n($5e,"STRONG",{});var UJr=s(Yme);wsr=r(UJr,"roberta"),UJr.forEach(t),Asr=r($5e," \u2014 "),zD=n($5e,"A",{href:!0});var JJr=s(zD);Lsr=r(JJr,"FlaxRobertaModel"),JJr.forEach(t),Bsr=r($5e," (RoBERTa model)"),$5e.forEach(t),ksr=i(H),nF=n(H,"LI",{});var I5e=s(nF);Kme=n(I5e,"STRONG",{});var YJr=s(Kme);xsr=r(YJr,"roformer"),YJr.forEach(t),Rsr=r(I5e," \u2014 "),VD=n(I5e,"A",{href:!0});var KJr=s(VD);Ssr=r(KJr,"FlaxRoFormerModel"),KJr.forEach(t),Psr=r(I5e," (RoFormer model)"),I5e.forEach(t),$sr=i(H),sF=n(H,"LI",{});var j5e=s(sF);Zme=n(j5e,"STRONG",{});var ZJr=s(Zme);Isr=r(ZJr,"t5"),ZJr.forEach(t),jsr=r(j5e," \u2014 "),XD=n(j5e,"A",{href:!0});var eYr=s(XD);Nsr=r(eYr,"FlaxT5Model"),eYr.forEach(t),Dsr=r(j5e," (T5 model)"),j5e.forEach(t),qsr=i(H),lF=n(H,"LI",{});var N5e=s(lF);ege=n(N5e,"STRONG",{});var oYr=s(ege);Osr=r(oYr,"vision-text-dual-encoder"),oYr.forEach(t),Gsr=r(N5e," \u2014 "),WD=n(N5e,"A",{href:!0});var rYr=s(WD);zsr=r(rYr,"FlaxVisionTextDualEncoderModel"),rYr.forEach(t),Vsr=r(N5e," (VisionTextDualEncoder model)"),N5e.forEach(t),Xsr=i(H),iF=n(H,"LI",{});var D5e=s(iF);oge=n(D5e,"STRONG",{});var tYr=s(oge);Wsr=r(tYr,"vit"),tYr.forEach(t),Qsr=r(D5e," \u2014 "),QD=n(D5e,"A",{href:!0});var aYr=s(QD);Hsr=r(aYr,"FlaxViTModel"),aYr.forEach(t),Usr=r(D5e," (ViT model)"),D5e.forEach(t),Jsr=i(H),dF=n(H,"LI",{});var q5e=s(dF);rge=n(q5e,"STRONG",{});var nYr=s(rge);Ysr=r(nYr,"wav2vec2"),nYr.forEach(t),Ksr=r(q5e," \u2014 "),HD=n(q5e,"A",{href:!0});var sYr=s(HD);Zsr=r(sYr,"FlaxWav2Vec2Model"),sYr.forEach(t),elr=r(q5e," (Wav2Vec2 model)"),q5e.forEach(t),H.forEach(t),olr=i(fa),tge=n(fa,"P",{});var lYr=s(tge);rlr=r(lYr,"Examples:"),lYr.forEach(t),tlr=i(fa),m(Ew.$$.fragment,fa),fa.forEach(t),kl.forEach(t),wAe=i(d),ic=n(d,"H2",{class:!0});var w7e=s(ic);cF=n(w7e,"A",{id:!0,class:!0,href:!0});var iYr=s(cF);age=n(iYr,"SPAN",{});var dYr=s(age);m(Mw.$$.fragment,dYr),dYr.forEach(t),iYr.forEach(t),alr=i(w7e),nge=n(w7e,"SPAN",{});var cYr=s(nge);nlr=r(cYr,"FlaxAutoModelForCausalLM"),cYr.forEach(t),w7e.forEach(t),AAe=i(d),vr=n(d,"DIV",{class:!0});var Rl=s(vr);m(yw.$$.fragment,Rl),slr=i(Rl),dc=n(Rl,"P",{});var wG=s(dc);llr=r(wG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),sge=n(wG,"CODE",{});var fYr=s(sge);ilr=r(fYr,"from_pretrained()"),fYr.forEach(t),dlr=r(wG,"class method or the "),lge=n(wG,"CODE",{});var mYr=s(lge);clr=r(mYr,"from_config()"),mYr.forEach(t),flr=r(wG,`class
method.`),wG.forEach(t),mlr=i(Rl),ww=n(Rl,"P",{});var A7e=s(ww);glr=r(A7e,"This class cannot be instantiated directly using "),ige=n(A7e,"CODE",{});var gYr=s(ige);hlr=r(gYr,"__init__()"),gYr.forEach(t),ulr=r(A7e," (throws an error)."),A7e.forEach(t),plr=i(Rl),it=n(Rl,"DIV",{class:!0});var Sl=s(it);m(Aw.$$.fragment,Sl),_lr=i(Sl),dge=n(Sl,"P",{});var hYr=s(dge);vlr=r(hYr,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),hYr.forEach(t),blr=i(Sl),cc=n(Sl,"P",{});var AG=s(cc);Tlr=r(AG,`Note:
Loading a model from its configuration file does `),cge=n(AG,"STRONG",{});var uYr=s(cge);Flr=r(uYr,"not"),uYr.forEach(t),Clr=r(AG,` load the model weights. It only affects the
model\u2019s configuration. Use `),fge=n(AG,"CODE",{});var pYr=s(fge);Elr=r(pYr,"from_pretrained()"),pYr.forEach(t),Mlr=r(AG,"to load the model weights."),AG.forEach(t),ylr=i(Sl),mge=n(Sl,"P",{});var _Yr=s(mge);wlr=r(_Yr,"Examples:"),_Yr.forEach(t),Alr=i(Sl),m(Lw.$$.fragment,Sl),Sl.forEach(t),Llr=i(Rl),Eo=n(Rl,"DIV",{class:!0});var ma=s(Eo);m(Bw.$$.fragment,ma),Blr=i(ma),gge=n(ma,"P",{});var vYr=s(gge);klr=r(vYr,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),vYr.forEach(t),xlr=i(ma),sn=n(ma,"P",{});var bE=s(sn);Rlr=r(bE,"The model class to instantiate is selected based on the "),hge=n(bE,"CODE",{});var bYr=s(hge);Slr=r(bYr,"model_type"),bYr.forEach(t),Plr=r(bE,` property of the config object (either
passed as an argument or loaded from `),uge=n(bE,"CODE",{});var TYr=s(uge);$lr=r(TYr,"pretrained_model_name_or_path"),TYr.forEach(t),Ilr=r(bE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pge=n(bE,"CODE",{});var FYr=s(pge);jlr=r(FYr,"pretrained_model_name_or_path"),FYr.forEach(t),Nlr=r(bE,":"),bE.forEach(t),Dlr=i(ma),fc=n(ma,"UL",{});var LG=s(fc);fF=n(LG,"LI",{});var O5e=s(fF);_ge=n(O5e,"STRONG",{});var CYr=s(_ge);qlr=r(CYr,"gpt2"),CYr.forEach(t),Olr=r(O5e," \u2014 "),UD=n(O5e,"A",{href:!0});var EYr=s(UD);Glr=r(EYr,"FlaxGPT2LMHeadModel"),EYr.forEach(t),zlr=r(O5e," (OpenAI GPT-2 model)"),O5e.forEach(t),Vlr=i(LG),mF=n(LG,"LI",{});var G5e=s(mF);vge=n(G5e,"STRONG",{});var MYr=s(vge);Xlr=r(MYr,"gpt_neo"),MYr.forEach(t),Wlr=r(G5e," \u2014 "),JD=n(G5e,"A",{href:!0});var yYr=s(JD);Qlr=r(yYr,"FlaxGPTNeoForCausalLM"),yYr.forEach(t),Hlr=r(G5e," (GPT Neo model)"),G5e.forEach(t),Ulr=i(LG),gF=n(LG,"LI",{});var z5e=s(gF);bge=n(z5e,"STRONG",{});var wYr=s(bge);Jlr=r(wYr,"gptj"),wYr.forEach(t),Ylr=r(z5e," \u2014 "),YD=n(z5e,"A",{href:!0});var AYr=s(YD);Klr=r(AYr,"FlaxGPTJForCausalLM"),AYr.forEach(t),Zlr=r(z5e," (GPT-J model)"),z5e.forEach(t),LG.forEach(t),eir=i(ma),Tge=n(ma,"P",{});var LYr=s(Tge);oir=r(LYr,"Examples:"),LYr.forEach(t),rir=i(ma),m(kw.$$.fragment,ma),ma.forEach(t),Rl.forEach(t),LAe=i(d),mc=n(d,"H2",{class:!0});var L7e=s(mc);hF=n(L7e,"A",{id:!0,class:!0,href:!0});var BYr=s(hF);Fge=n(BYr,"SPAN",{});var kYr=s(Fge);m(xw.$$.fragment,kYr),kYr.forEach(t),BYr.forEach(t),tir=i(L7e),Cge=n(L7e,"SPAN",{});var xYr=s(Cge);air=r(xYr,"FlaxAutoModelForPreTraining"),xYr.forEach(t),L7e.forEach(t),BAe=i(d),br=n(d,"DIV",{class:!0});var Pl=s(br);m(Rw.$$.fragment,Pl),nir=i(Pl),gc=n(Pl,"P",{});var BG=s(gc);sir=r(BG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Ege=n(BG,"CODE",{});var RYr=s(Ege);lir=r(RYr,"from_pretrained()"),RYr.forEach(t),iir=r(BG,"class method or the "),Mge=n(BG,"CODE",{});var SYr=s(Mge);dir=r(SYr,"from_config()"),SYr.forEach(t),cir=r(BG,`class
method.`),BG.forEach(t),fir=i(Pl),Sw=n(Pl,"P",{});var B7e=s(Sw);mir=r(B7e,"This class cannot be instantiated directly using "),yge=n(B7e,"CODE",{});var PYr=s(yge);gir=r(PYr,"__init__()"),PYr.forEach(t),hir=r(B7e," (throws an error)."),B7e.forEach(t),uir=i(Pl),dt=n(Pl,"DIV",{class:!0});var $l=s(dt);m(Pw.$$.fragment,$l),pir=i($l),wge=n($l,"P",{});var $Yr=s(wge);_ir=r($Yr,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),$Yr.forEach(t),vir=i($l),hc=n($l,"P",{});var kG=s(hc);bir=r(kG,`Note:
Loading a model from its configuration file does `),Age=n(kG,"STRONG",{});var IYr=s(Age);Tir=r(IYr,"not"),IYr.forEach(t),Fir=r(kG,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lge=n(kG,"CODE",{});var jYr=s(Lge);Cir=r(jYr,"from_pretrained()"),jYr.forEach(t),Eir=r(kG,"to load the model weights."),kG.forEach(t),Mir=i($l),Bge=n($l,"P",{});var NYr=s(Bge);yir=r(NYr,"Examples:"),NYr.forEach(t),wir=i($l),m($w.$$.fragment,$l),$l.forEach(t),Air=i(Pl),Mo=n(Pl,"DIV",{class:!0});var ga=s(Mo);m(Iw.$$.fragment,ga),Lir=i(ga),kge=n(ga,"P",{});var DYr=s(kge);Bir=r(DYr,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),DYr.forEach(t),kir=i(ga),ln=n(ga,"P",{});var TE=s(ln);xir=r(TE,"The model class to instantiate is selected based on the "),xge=n(TE,"CODE",{});var qYr=s(xge);Rir=r(qYr,"model_type"),qYr.forEach(t),Sir=r(TE,` property of the config object (either
passed as an argument or loaded from `),Rge=n(TE,"CODE",{});var OYr=s(Rge);Pir=r(OYr,"pretrained_model_name_or_path"),OYr.forEach(t),$ir=r(TE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sge=n(TE,"CODE",{});var GYr=s(Sge);Iir=r(GYr,"pretrained_model_name_or_path"),GYr.forEach(t),jir=r(TE,":"),TE.forEach(t),Nir=i(ga),ce=n(ga,"UL",{});var pe=s(ce);uF=n(pe,"LI",{});var V5e=s(uF);Pge=n(V5e,"STRONG",{});var zYr=s(Pge);Dir=r(zYr,"albert"),zYr.forEach(t),qir=r(V5e," \u2014 "),KD=n(V5e,"A",{href:!0});var VYr=s(KD);Oir=r(VYr,"FlaxAlbertForPreTraining"),VYr.forEach(t),Gir=r(V5e," (ALBERT model)"),V5e.forEach(t),zir=i(pe),pF=n(pe,"LI",{});var X5e=s(pF);$ge=n(X5e,"STRONG",{});var XYr=s($ge);Vir=r(XYr,"bart"),XYr.forEach(t),Xir=r(X5e," \u2014 "),ZD=n(X5e,"A",{href:!0});var WYr=s(ZD);Wir=r(WYr,"FlaxBartForConditionalGeneration"),WYr.forEach(t),Qir=r(X5e," (BART model)"),X5e.forEach(t),Hir=i(pe),_F=n(pe,"LI",{});var W5e=s(_F);Ige=n(W5e,"STRONG",{});var QYr=s(Ige);Uir=r(QYr,"bert"),QYr.forEach(t),Jir=r(W5e," \u2014 "),eq=n(W5e,"A",{href:!0});var HYr=s(eq);Yir=r(HYr,"FlaxBertForPreTraining"),HYr.forEach(t),Kir=r(W5e," (BERT model)"),W5e.forEach(t),Zir=i(pe),vF=n(pe,"LI",{});var Q5e=s(vF);jge=n(Q5e,"STRONG",{});var UYr=s(jge);edr=r(UYr,"big_bird"),UYr.forEach(t),odr=r(Q5e," \u2014 "),oq=n(Q5e,"A",{href:!0});var JYr=s(oq);rdr=r(JYr,"FlaxBigBirdForPreTraining"),JYr.forEach(t),tdr=r(Q5e," (BigBird model)"),Q5e.forEach(t),adr=i(pe),bF=n(pe,"LI",{});var H5e=s(bF);Nge=n(H5e,"STRONG",{});var YYr=s(Nge);ndr=r(YYr,"electra"),YYr.forEach(t),sdr=r(H5e," \u2014 "),rq=n(H5e,"A",{href:!0});var KYr=s(rq);ldr=r(KYr,"FlaxElectraForPreTraining"),KYr.forEach(t),idr=r(H5e," (ELECTRA model)"),H5e.forEach(t),ddr=i(pe),TF=n(pe,"LI",{});var U5e=s(TF);Dge=n(U5e,"STRONG",{});var ZYr=s(Dge);cdr=r(ZYr,"mbart"),ZYr.forEach(t),fdr=r(U5e," \u2014 "),tq=n(U5e,"A",{href:!0});var eKr=s(tq);mdr=r(eKr,"FlaxMBartForConditionalGeneration"),eKr.forEach(t),gdr=r(U5e," (mBART model)"),U5e.forEach(t),hdr=i(pe),FF=n(pe,"LI",{});var J5e=s(FF);qge=n(J5e,"STRONG",{});var oKr=s(qge);udr=r(oKr,"mt5"),oKr.forEach(t),pdr=r(J5e," \u2014 "),aq=n(J5e,"A",{href:!0});var rKr=s(aq);_dr=r(rKr,"FlaxMT5ForConditionalGeneration"),rKr.forEach(t),vdr=r(J5e," (mT5 model)"),J5e.forEach(t),bdr=i(pe),CF=n(pe,"LI",{});var Y5e=s(CF);Oge=n(Y5e,"STRONG",{});var tKr=s(Oge);Tdr=r(tKr,"roberta"),tKr.forEach(t),Fdr=r(Y5e," \u2014 "),nq=n(Y5e,"A",{href:!0});var aKr=s(nq);Cdr=r(aKr,"FlaxRobertaForMaskedLM"),aKr.forEach(t),Edr=r(Y5e," (RoBERTa model)"),Y5e.forEach(t),Mdr=i(pe),EF=n(pe,"LI",{});var K5e=s(EF);Gge=n(K5e,"STRONG",{});var nKr=s(Gge);ydr=r(nKr,"roformer"),nKr.forEach(t),wdr=r(K5e," \u2014 "),sq=n(K5e,"A",{href:!0});var sKr=s(sq);Adr=r(sKr,"FlaxRoFormerForMaskedLM"),sKr.forEach(t),Ldr=r(K5e," (RoFormer model)"),K5e.forEach(t),Bdr=i(pe),MF=n(pe,"LI",{});var Z5e=s(MF);zge=n(Z5e,"STRONG",{});var lKr=s(zge);kdr=r(lKr,"t5"),lKr.forEach(t),xdr=r(Z5e," \u2014 "),lq=n(Z5e,"A",{href:!0});var iKr=s(lq);Rdr=r(iKr,"FlaxT5ForConditionalGeneration"),iKr.forEach(t),Sdr=r(Z5e," (T5 model)"),Z5e.forEach(t),Pdr=i(pe),yF=n(pe,"LI",{});var eye=s(yF);Vge=n(eye,"STRONG",{});var dKr=s(Vge);$dr=r(dKr,"wav2vec2"),dKr.forEach(t),Idr=r(eye," \u2014 "),iq=n(eye,"A",{href:!0});var cKr=s(iq);jdr=r(cKr,"FlaxWav2Vec2ForPreTraining"),cKr.forEach(t),Ndr=r(eye," (Wav2Vec2 model)"),eye.forEach(t),pe.forEach(t),Ddr=i(ga),Xge=n(ga,"P",{});var fKr=s(Xge);qdr=r(fKr,"Examples:"),fKr.forEach(t),Odr=i(ga),m(jw.$$.fragment,ga),ga.forEach(t),Pl.forEach(t),kAe=i(d),uc=n(d,"H2",{class:!0});var k7e=s(uc);wF=n(k7e,"A",{id:!0,class:!0,href:!0});var mKr=s(wF);Wge=n(mKr,"SPAN",{});var gKr=s(Wge);m(Nw.$$.fragment,gKr),gKr.forEach(t),mKr.forEach(t),Gdr=i(k7e),Qge=n(k7e,"SPAN",{});var hKr=s(Qge);zdr=r(hKr,"FlaxAutoModelForMaskedLM"),hKr.forEach(t),k7e.forEach(t),xAe=i(d),Tr=n(d,"DIV",{class:!0});var Il=s(Tr);m(Dw.$$.fragment,Il),Vdr=i(Il),pc=n(Il,"P",{});var xG=s(pc);Xdr=r(xG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Hge=n(xG,"CODE",{});var uKr=s(Hge);Wdr=r(uKr,"from_pretrained()"),uKr.forEach(t),Qdr=r(xG,"class method or the "),Uge=n(xG,"CODE",{});var pKr=s(Uge);Hdr=r(pKr,"from_config()"),pKr.forEach(t),Udr=r(xG,`class
method.`),xG.forEach(t),Jdr=i(Il),qw=n(Il,"P",{});var x7e=s(qw);Ydr=r(x7e,"This class cannot be instantiated directly using "),Jge=n(x7e,"CODE",{});var _Kr=s(Jge);Kdr=r(_Kr,"__init__()"),_Kr.forEach(t),Zdr=r(x7e," (throws an error)."),x7e.forEach(t),ecr=i(Il),ct=n(Il,"DIV",{class:!0});var jl=s(ct);m(Ow.$$.fragment,jl),ocr=i(jl),Yge=n(jl,"P",{});var vKr=s(Yge);rcr=r(vKr,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),vKr.forEach(t),tcr=i(jl),_c=n(jl,"P",{});var RG=s(_c);acr=r(RG,`Note:
Loading a model from its configuration file does `),Kge=n(RG,"STRONG",{});var bKr=s(Kge);ncr=r(bKr,"not"),bKr.forEach(t),scr=r(RG,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zge=n(RG,"CODE",{});var TKr=s(Zge);lcr=r(TKr,"from_pretrained()"),TKr.forEach(t),icr=r(RG,"to load the model weights."),RG.forEach(t),dcr=i(jl),ehe=n(jl,"P",{});var FKr=s(ehe);ccr=r(FKr,"Examples:"),FKr.forEach(t),fcr=i(jl),m(Gw.$$.fragment,jl),jl.forEach(t),mcr=i(Il),yo=n(Il,"DIV",{class:!0});var ha=s(yo);m(zw.$$.fragment,ha),gcr=i(ha),ohe=n(ha,"P",{});var CKr=s(ohe);hcr=r(CKr,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),CKr.forEach(t),ucr=i(ha),dn=n(ha,"P",{});var FE=s(dn);pcr=r(FE,"The model class to instantiate is selected based on the "),rhe=n(FE,"CODE",{});var EKr=s(rhe);_cr=r(EKr,"model_type"),EKr.forEach(t),vcr=r(FE,` property of the config object (either
passed as an argument or loaded from `),the=n(FE,"CODE",{});var MKr=s(the);bcr=r(MKr,"pretrained_model_name_or_path"),MKr.forEach(t),Tcr=r(FE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ahe=n(FE,"CODE",{});var yKr=s(ahe);Fcr=r(yKr,"pretrained_model_name_or_path"),yKr.forEach(t),Ccr=r(FE,":"),FE.forEach(t),Ecr=i(ha),ve=n(ha,"UL",{});var Ue=s(ve);AF=n(Ue,"LI",{});var oye=s(AF);nhe=n(oye,"STRONG",{});var wKr=s(nhe);Mcr=r(wKr,"albert"),wKr.forEach(t),ycr=r(oye," \u2014 "),dq=n(oye,"A",{href:!0});var AKr=s(dq);wcr=r(AKr,"FlaxAlbertForMaskedLM"),AKr.forEach(t),Acr=r(oye," (ALBERT model)"),oye.forEach(t),Lcr=i(Ue),LF=n(Ue,"LI",{});var rye=s(LF);she=n(rye,"STRONG",{});var LKr=s(she);Bcr=r(LKr,"bart"),LKr.forEach(t),kcr=r(rye," \u2014 "),cq=n(rye,"A",{href:!0});var BKr=s(cq);xcr=r(BKr,"FlaxBartForConditionalGeneration"),BKr.forEach(t),Rcr=r(rye," (BART model)"),rye.forEach(t),Scr=i(Ue),BF=n(Ue,"LI",{});var tye=s(BF);lhe=n(tye,"STRONG",{});var kKr=s(lhe);Pcr=r(kKr,"bert"),kKr.forEach(t),$cr=r(tye," \u2014 "),fq=n(tye,"A",{href:!0});var xKr=s(fq);Icr=r(xKr,"FlaxBertForMaskedLM"),xKr.forEach(t),jcr=r(tye," (BERT model)"),tye.forEach(t),Ncr=i(Ue),kF=n(Ue,"LI",{});var aye=s(kF);ihe=n(aye,"STRONG",{});var RKr=s(ihe);Dcr=r(RKr,"big_bird"),RKr.forEach(t),qcr=r(aye," \u2014 "),mq=n(aye,"A",{href:!0});var SKr=s(mq);Ocr=r(SKr,"FlaxBigBirdForMaskedLM"),SKr.forEach(t),Gcr=r(aye," (BigBird model)"),aye.forEach(t),zcr=i(Ue),xF=n(Ue,"LI",{});var nye=s(xF);dhe=n(nye,"STRONG",{});var PKr=s(dhe);Vcr=r(PKr,"distilbert"),PKr.forEach(t),Xcr=r(nye," \u2014 "),gq=n(nye,"A",{href:!0});var $Kr=s(gq);Wcr=r($Kr,"FlaxDistilBertForMaskedLM"),$Kr.forEach(t),Qcr=r(nye," (DistilBERT model)"),nye.forEach(t),Hcr=i(Ue),RF=n(Ue,"LI",{});var sye=s(RF);che=n(sye,"STRONG",{});var IKr=s(che);Ucr=r(IKr,"electra"),IKr.forEach(t),Jcr=r(sye," \u2014 "),hq=n(sye,"A",{href:!0});var jKr=s(hq);Ycr=r(jKr,"FlaxElectraForMaskedLM"),jKr.forEach(t),Kcr=r(sye," (ELECTRA model)"),sye.forEach(t),Zcr=i(Ue),SF=n(Ue,"LI",{});var lye=s(SF);fhe=n(lye,"STRONG",{});var NKr=s(fhe);efr=r(NKr,"mbart"),NKr.forEach(t),ofr=r(lye," \u2014 "),uq=n(lye,"A",{href:!0});var DKr=s(uq);rfr=r(DKr,"FlaxMBartForConditionalGeneration"),DKr.forEach(t),tfr=r(lye," (mBART model)"),lye.forEach(t),afr=i(Ue),PF=n(Ue,"LI",{});var iye=s(PF);mhe=n(iye,"STRONG",{});var qKr=s(mhe);nfr=r(qKr,"roberta"),qKr.forEach(t),sfr=r(iye," \u2014 "),pq=n(iye,"A",{href:!0});var OKr=s(pq);lfr=r(OKr,"FlaxRobertaForMaskedLM"),OKr.forEach(t),ifr=r(iye," (RoBERTa model)"),iye.forEach(t),dfr=i(Ue),$F=n(Ue,"LI",{});var dye=s($F);ghe=n(dye,"STRONG",{});var GKr=s(ghe);cfr=r(GKr,"roformer"),GKr.forEach(t),ffr=r(dye," \u2014 "),_q=n(dye,"A",{href:!0});var zKr=s(_q);mfr=r(zKr,"FlaxRoFormerForMaskedLM"),zKr.forEach(t),gfr=r(dye," (RoFormer model)"),dye.forEach(t),Ue.forEach(t),hfr=i(ha),hhe=n(ha,"P",{});var VKr=s(hhe);ufr=r(VKr,"Examples:"),VKr.forEach(t),pfr=i(ha),m(Vw.$$.fragment,ha),ha.forEach(t),Il.forEach(t),RAe=i(d),vc=n(d,"H2",{class:!0});var R7e=s(vc);IF=n(R7e,"A",{id:!0,class:!0,href:!0});var XKr=s(IF);uhe=n(XKr,"SPAN",{});var WKr=s(uhe);m(Xw.$$.fragment,WKr),WKr.forEach(t),XKr.forEach(t),_fr=i(R7e),phe=n(R7e,"SPAN",{});var QKr=s(phe);vfr=r(QKr,"FlaxAutoModelForSeq2SeqLM"),QKr.forEach(t),R7e.forEach(t),SAe=i(d),Fr=n(d,"DIV",{class:!0});var Nl=s(Fr);m(Ww.$$.fragment,Nl),bfr=i(Nl),bc=n(Nl,"P",{});var SG=s(bc);Tfr=r(SG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),_he=n(SG,"CODE",{});var HKr=s(_he);Ffr=r(HKr,"from_pretrained()"),HKr.forEach(t),Cfr=r(SG,"class method or the "),vhe=n(SG,"CODE",{});var UKr=s(vhe);Efr=r(UKr,"from_config()"),UKr.forEach(t),Mfr=r(SG,`class
method.`),SG.forEach(t),yfr=i(Nl),Qw=n(Nl,"P",{});var S7e=s(Qw);wfr=r(S7e,"This class cannot be instantiated directly using "),bhe=n(S7e,"CODE",{});var JKr=s(bhe);Afr=r(JKr,"__init__()"),JKr.forEach(t),Lfr=r(S7e," (throws an error)."),S7e.forEach(t),Bfr=i(Nl),ft=n(Nl,"DIV",{class:!0});var Dl=s(ft);m(Hw.$$.fragment,Dl),kfr=i(Dl),The=n(Dl,"P",{});var YKr=s(The);xfr=r(YKr,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),YKr.forEach(t),Rfr=i(Dl),Tc=n(Dl,"P",{});var PG=s(Tc);Sfr=r(PG,`Note:
Loading a model from its configuration file does `),Fhe=n(PG,"STRONG",{});var KKr=s(Fhe);Pfr=r(KKr,"not"),KKr.forEach(t),$fr=r(PG,` load the model weights. It only affects the
model\u2019s configuration. Use `),Che=n(PG,"CODE",{});var ZKr=s(Che);Ifr=r(ZKr,"from_pretrained()"),ZKr.forEach(t),jfr=r(PG,"to load the model weights."),PG.forEach(t),Nfr=i(Dl),Ehe=n(Dl,"P",{});var eZr=s(Ehe);Dfr=r(eZr,"Examples:"),eZr.forEach(t),qfr=i(Dl),m(Uw.$$.fragment,Dl),Dl.forEach(t),Ofr=i(Nl),wo=n(Nl,"DIV",{class:!0});var ua=s(wo);m(Jw.$$.fragment,ua),Gfr=i(ua),Mhe=n(ua,"P",{});var oZr=s(Mhe);zfr=r(oZr,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),oZr.forEach(t),Vfr=i(ua),cn=n(ua,"P",{});var CE=s(cn);Xfr=r(CE,"The model class to instantiate is selected based on the "),yhe=n(CE,"CODE",{});var rZr=s(yhe);Wfr=r(rZr,"model_type"),rZr.forEach(t),Qfr=r(CE,` property of the config object (either
passed as an argument or loaded from `),whe=n(CE,"CODE",{});var tZr=s(whe);Hfr=r(tZr,"pretrained_model_name_or_path"),tZr.forEach(t),Ufr=r(CE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ahe=n(CE,"CODE",{});var aZr=s(Ahe);Jfr=r(aZr,"pretrained_model_name_or_path"),aZr.forEach(t),Yfr=r(CE,":"),CE.forEach(t),Kfr=i(ua),be=n(ua,"UL",{});var Je=s(be);jF=n(Je,"LI",{});var cye=s(jF);Lhe=n(cye,"STRONG",{});var nZr=s(Lhe);Zfr=r(nZr,"bart"),nZr.forEach(t),emr=r(cye," \u2014 "),vq=n(cye,"A",{href:!0});var sZr=s(vq);omr=r(sZr,"FlaxBartForConditionalGeneration"),sZr.forEach(t),rmr=r(cye," (BART model)"),cye.forEach(t),tmr=i(Je),NF=n(Je,"LI",{});var fye=s(NF);Bhe=n(fye,"STRONG",{});var lZr=s(Bhe);amr=r(lZr,"blenderbot"),lZr.forEach(t),nmr=r(fye," \u2014 "),bq=n(fye,"A",{href:!0});var iZr=s(bq);smr=r(iZr,"FlaxBlenderbotForConditionalGeneration"),iZr.forEach(t),lmr=r(fye," (Blenderbot model)"),fye.forEach(t),imr=i(Je),DF=n(Je,"LI",{});var mye=s(DF);khe=n(mye,"STRONG",{});var dZr=s(khe);dmr=r(dZr,"blenderbot-small"),dZr.forEach(t),cmr=r(mye," \u2014 "),Tq=n(mye,"A",{href:!0});var cZr=s(Tq);fmr=r(cZr,"FlaxBlenderbotSmallForConditionalGeneration"),cZr.forEach(t),mmr=r(mye," (BlenderbotSmall model)"),mye.forEach(t),gmr=i(Je),qF=n(Je,"LI",{});var gye=s(qF);xhe=n(gye,"STRONG",{});var fZr=s(xhe);hmr=r(fZr,"encoder-decoder"),fZr.forEach(t),umr=r(gye," \u2014 "),Fq=n(gye,"A",{href:!0});var mZr=s(Fq);pmr=r(mZr,"FlaxEncoderDecoderModel"),mZr.forEach(t),_mr=r(gye," (Encoder decoder model)"),gye.forEach(t),vmr=i(Je),OF=n(Je,"LI",{});var hye=s(OF);Rhe=n(hye,"STRONG",{});var gZr=s(Rhe);bmr=r(gZr,"marian"),gZr.forEach(t),Tmr=r(hye," \u2014 "),Cq=n(hye,"A",{href:!0});var hZr=s(Cq);Fmr=r(hZr,"FlaxMarianMTModel"),hZr.forEach(t),Cmr=r(hye," (Marian model)"),hye.forEach(t),Emr=i(Je),GF=n(Je,"LI",{});var uye=s(GF);She=n(uye,"STRONG",{});var uZr=s(She);Mmr=r(uZr,"mbart"),uZr.forEach(t),ymr=r(uye," \u2014 "),Eq=n(uye,"A",{href:!0});var pZr=s(Eq);wmr=r(pZr,"FlaxMBartForConditionalGeneration"),pZr.forEach(t),Amr=r(uye," (mBART model)"),uye.forEach(t),Lmr=i(Je),zF=n(Je,"LI",{});var pye=s(zF);Phe=n(pye,"STRONG",{});var _Zr=s(Phe);Bmr=r(_Zr,"mt5"),_Zr.forEach(t),kmr=r(pye," \u2014 "),Mq=n(pye,"A",{href:!0});var vZr=s(Mq);xmr=r(vZr,"FlaxMT5ForConditionalGeneration"),vZr.forEach(t),Rmr=r(pye," (mT5 model)"),pye.forEach(t),Smr=i(Je),VF=n(Je,"LI",{});var _ye=s(VF);$he=n(_ye,"STRONG",{});var bZr=s($he);Pmr=r(bZr,"pegasus"),bZr.forEach(t),$mr=r(_ye," \u2014 "),yq=n(_ye,"A",{href:!0});var TZr=s(yq);Imr=r(TZr,"FlaxPegasusForConditionalGeneration"),TZr.forEach(t),jmr=r(_ye," (Pegasus model)"),_ye.forEach(t),Nmr=i(Je),XF=n(Je,"LI",{});var vye=s(XF);Ihe=n(vye,"STRONG",{});var FZr=s(Ihe);Dmr=r(FZr,"t5"),FZr.forEach(t),qmr=r(vye," \u2014 "),wq=n(vye,"A",{href:!0});var CZr=s(wq);Omr=r(CZr,"FlaxT5ForConditionalGeneration"),CZr.forEach(t),Gmr=r(vye," (T5 model)"),vye.forEach(t),Je.forEach(t),zmr=i(ua),jhe=n(ua,"P",{});var EZr=s(jhe);Vmr=r(EZr,"Examples:"),EZr.forEach(t),Xmr=i(ua),m(Yw.$$.fragment,ua),ua.forEach(t),Nl.forEach(t),PAe=i(d),Fc=n(d,"H2",{class:!0});var P7e=s(Fc);WF=n(P7e,"A",{id:!0,class:!0,href:!0});var MZr=s(WF);Nhe=n(MZr,"SPAN",{});var yZr=s(Nhe);m(Kw.$$.fragment,yZr),yZr.forEach(t),MZr.forEach(t),Wmr=i(P7e),Dhe=n(P7e,"SPAN",{});var wZr=s(Dhe);Qmr=r(wZr,"FlaxAutoModelForSequenceClassification"),wZr.forEach(t),P7e.forEach(t),$Ae=i(d),Cr=n(d,"DIV",{class:!0});var ql=s(Cr);m(Zw.$$.fragment,ql),Hmr=i(ql),Cc=n(ql,"P",{});var $G=s(Cc);Umr=r($G,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),qhe=n($G,"CODE",{});var AZr=s(qhe);Jmr=r(AZr,"from_pretrained()"),AZr.forEach(t),Ymr=r($G,"class method or the "),Ohe=n($G,"CODE",{});var LZr=s(Ohe);Kmr=r(LZr,"from_config()"),LZr.forEach(t),Zmr=r($G,`class
method.`),$G.forEach(t),egr=i(ql),eA=n(ql,"P",{});var $7e=s(eA);ogr=r($7e,"This class cannot be instantiated directly using "),Ghe=n($7e,"CODE",{});var BZr=s(Ghe);rgr=r(BZr,"__init__()"),BZr.forEach(t),tgr=r($7e," (throws an error)."),$7e.forEach(t),agr=i(ql),mt=n(ql,"DIV",{class:!0});var Ol=s(mt);m(oA.$$.fragment,Ol),ngr=i(Ol),zhe=n(Ol,"P",{});var kZr=s(zhe);sgr=r(kZr,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),kZr.forEach(t),lgr=i(Ol),Ec=n(Ol,"P",{});var IG=s(Ec);igr=r(IG,`Note:
Loading a model from its configuration file does `),Vhe=n(IG,"STRONG",{});var xZr=s(Vhe);dgr=r(xZr,"not"),xZr.forEach(t),cgr=r(IG,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xhe=n(IG,"CODE",{});var RZr=s(Xhe);fgr=r(RZr,"from_pretrained()"),RZr.forEach(t),mgr=r(IG,"to load the model weights."),IG.forEach(t),ggr=i(Ol),Whe=n(Ol,"P",{});var SZr=s(Whe);hgr=r(SZr,"Examples:"),SZr.forEach(t),ugr=i(Ol),m(rA.$$.fragment,Ol),Ol.forEach(t),pgr=i(ql),Ao=n(ql,"DIV",{class:!0});var pa=s(Ao);m(tA.$$.fragment,pa),_gr=i(pa),Qhe=n(pa,"P",{});var PZr=s(Qhe);vgr=r(PZr,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),PZr.forEach(t),bgr=i(pa),fn=n(pa,"P",{});var EE=s(fn);Tgr=r(EE,"The model class to instantiate is selected based on the "),Hhe=n(EE,"CODE",{});var $Zr=s(Hhe);Fgr=r($Zr,"model_type"),$Zr.forEach(t),Cgr=r(EE,` property of the config object (either
passed as an argument or loaded from `),Uhe=n(EE,"CODE",{});var IZr=s(Uhe);Egr=r(IZr,"pretrained_model_name_or_path"),IZr.forEach(t),Mgr=r(EE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jhe=n(EE,"CODE",{});var jZr=s(Jhe);ygr=r(jZr,"pretrained_model_name_or_path"),jZr.forEach(t),wgr=r(EE,":"),EE.forEach(t),Agr=i(pa),Te=n(pa,"UL",{});var Ye=s(Te);QF=n(Ye,"LI",{});var bye=s(QF);Yhe=n(bye,"STRONG",{});var NZr=s(Yhe);Lgr=r(NZr,"albert"),NZr.forEach(t),Bgr=r(bye," \u2014 "),Aq=n(bye,"A",{href:!0});var DZr=s(Aq);kgr=r(DZr,"FlaxAlbertForSequenceClassification"),DZr.forEach(t),xgr=r(bye," (ALBERT model)"),bye.forEach(t),Rgr=i(Ye),HF=n(Ye,"LI",{});var Tye=s(HF);Khe=n(Tye,"STRONG",{});var qZr=s(Khe);Sgr=r(qZr,"bart"),qZr.forEach(t),Pgr=r(Tye," \u2014 "),Lq=n(Tye,"A",{href:!0});var OZr=s(Lq);$gr=r(OZr,"FlaxBartForSequenceClassification"),OZr.forEach(t),Igr=r(Tye," (BART model)"),Tye.forEach(t),jgr=i(Ye),UF=n(Ye,"LI",{});var Fye=s(UF);Zhe=n(Fye,"STRONG",{});var GZr=s(Zhe);Ngr=r(GZr,"bert"),GZr.forEach(t),Dgr=r(Fye," \u2014 "),Bq=n(Fye,"A",{href:!0});var zZr=s(Bq);qgr=r(zZr,"FlaxBertForSequenceClassification"),zZr.forEach(t),Ogr=r(Fye," (BERT model)"),Fye.forEach(t),Ggr=i(Ye),JF=n(Ye,"LI",{});var Cye=s(JF);eue=n(Cye,"STRONG",{});var VZr=s(eue);zgr=r(VZr,"big_bird"),VZr.forEach(t),Vgr=r(Cye," \u2014 "),kq=n(Cye,"A",{href:!0});var XZr=s(kq);Xgr=r(XZr,"FlaxBigBirdForSequenceClassification"),XZr.forEach(t),Wgr=r(Cye," (BigBird model)"),Cye.forEach(t),Qgr=i(Ye),YF=n(Ye,"LI",{});var Eye=s(YF);oue=n(Eye,"STRONG",{});var WZr=s(oue);Hgr=r(WZr,"distilbert"),WZr.forEach(t),Ugr=r(Eye," \u2014 "),xq=n(Eye,"A",{href:!0});var QZr=s(xq);Jgr=r(QZr,"FlaxDistilBertForSequenceClassification"),QZr.forEach(t),Ygr=r(Eye," (DistilBERT model)"),Eye.forEach(t),Kgr=i(Ye),KF=n(Ye,"LI",{});var Mye=s(KF);rue=n(Mye,"STRONG",{});var HZr=s(rue);Zgr=r(HZr,"electra"),HZr.forEach(t),ehr=r(Mye," \u2014 "),Rq=n(Mye,"A",{href:!0});var UZr=s(Rq);ohr=r(UZr,"FlaxElectraForSequenceClassification"),UZr.forEach(t),rhr=r(Mye," (ELECTRA model)"),Mye.forEach(t),thr=i(Ye),ZF=n(Ye,"LI",{});var yye=s(ZF);tue=n(yye,"STRONG",{});var JZr=s(tue);ahr=r(JZr,"mbart"),JZr.forEach(t),nhr=r(yye," \u2014 "),Sq=n(yye,"A",{href:!0});var YZr=s(Sq);shr=r(YZr,"FlaxMBartForSequenceClassification"),YZr.forEach(t),lhr=r(yye," (mBART model)"),yye.forEach(t),ihr=i(Ye),eC=n(Ye,"LI",{});var wye=s(eC);aue=n(wye,"STRONG",{});var KZr=s(aue);dhr=r(KZr,"roberta"),KZr.forEach(t),chr=r(wye," \u2014 "),Pq=n(wye,"A",{href:!0});var ZZr=s(Pq);fhr=r(ZZr,"FlaxRobertaForSequenceClassification"),ZZr.forEach(t),mhr=r(wye," (RoBERTa model)"),wye.forEach(t),ghr=i(Ye),oC=n(Ye,"LI",{});var Aye=s(oC);nue=n(Aye,"STRONG",{});var eet=s(nue);hhr=r(eet,"roformer"),eet.forEach(t),uhr=r(Aye," \u2014 "),$q=n(Aye,"A",{href:!0});var oet=s($q);phr=r(oet,"FlaxRoFormerForSequenceClassification"),oet.forEach(t),_hr=r(Aye," (RoFormer model)"),Aye.forEach(t),Ye.forEach(t),vhr=i(pa),sue=n(pa,"P",{});var ret=s(sue);bhr=r(ret,"Examples:"),ret.forEach(t),Thr=i(pa),m(aA.$$.fragment,pa),pa.forEach(t),ql.forEach(t),IAe=i(d),Mc=n(d,"H2",{class:!0});var I7e=s(Mc);rC=n(I7e,"A",{id:!0,class:!0,href:!0});var tet=s(rC);lue=n(tet,"SPAN",{});var aet=s(lue);m(nA.$$.fragment,aet),aet.forEach(t),tet.forEach(t),Fhr=i(I7e),iue=n(I7e,"SPAN",{});var net=s(iue);Chr=r(net,"FlaxAutoModelForQuestionAnswering"),net.forEach(t),I7e.forEach(t),jAe=i(d),Er=n(d,"DIV",{class:!0});var Gl=s(Er);m(sA.$$.fragment,Gl),Ehr=i(Gl),yc=n(Gl,"P",{});var jG=s(yc);Mhr=r(jG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),due=n(jG,"CODE",{});var set=s(due);yhr=r(set,"from_pretrained()"),set.forEach(t),whr=r(jG,"class method or the "),cue=n(jG,"CODE",{});var iet=s(cue);Ahr=r(iet,"from_config()"),iet.forEach(t),Lhr=r(jG,`class
method.`),jG.forEach(t),Bhr=i(Gl),lA=n(Gl,"P",{});var j7e=s(lA);khr=r(j7e,"This class cannot be instantiated directly using "),fue=n(j7e,"CODE",{});var det=s(fue);xhr=r(det,"__init__()"),det.forEach(t),Rhr=r(j7e," (throws an error)."),j7e.forEach(t),Shr=i(Gl),gt=n(Gl,"DIV",{class:!0});var zl=s(gt);m(iA.$$.fragment,zl),Phr=i(zl),mue=n(zl,"P",{});var cet=s(mue);$hr=r(cet,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),cet.forEach(t),Ihr=i(zl),wc=n(zl,"P",{});var NG=s(wc);jhr=r(NG,`Note:
Loading a model from its configuration file does `),gue=n(NG,"STRONG",{});var fet=s(gue);Nhr=r(fet,"not"),fet.forEach(t),Dhr=r(NG,` load the model weights. It only affects the
model\u2019s configuration. Use `),hue=n(NG,"CODE",{});var met=s(hue);qhr=r(met,"from_pretrained()"),met.forEach(t),Ohr=r(NG,"to load the model weights."),NG.forEach(t),Ghr=i(zl),uue=n(zl,"P",{});var get=s(uue);zhr=r(get,"Examples:"),get.forEach(t),Vhr=i(zl),m(dA.$$.fragment,zl),zl.forEach(t),Xhr=i(Gl),Lo=n(Gl,"DIV",{class:!0});var _a=s(Lo);m(cA.$$.fragment,_a),Whr=i(_a),pue=n(_a,"P",{});var het=s(pue);Qhr=r(het,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),het.forEach(t),Hhr=i(_a),mn=n(_a,"P",{});var ME=s(mn);Uhr=r(ME,"The model class to instantiate is selected based on the "),_ue=n(ME,"CODE",{});var uet=s(_ue);Jhr=r(uet,"model_type"),uet.forEach(t),Yhr=r(ME,` property of the config object (either
passed as an argument or loaded from `),vue=n(ME,"CODE",{});var pet=s(vue);Khr=r(pet,"pretrained_model_name_or_path"),pet.forEach(t),Zhr=r(ME,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bue=n(ME,"CODE",{});var _et=s(bue);eur=r(_et,"pretrained_model_name_or_path"),_et.forEach(t),our=r(ME,":"),ME.forEach(t),rur=i(_a),Fe=n(_a,"UL",{});var Ke=s(Fe);tC=n(Ke,"LI",{});var Lye=s(tC);Tue=n(Lye,"STRONG",{});var vet=s(Tue);tur=r(vet,"albert"),vet.forEach(t),aur=r(Lye," \u2014 "),Iq=n(Lye,"A",{href:!0});var bet=s(Iq);nur=r(bet,"FlaxAlbertForQuestionAnswering"),bet.forEach(t),sur=r(Lye," (ALBERT model)"),Lye.forEach(t),lur=i(Ke),aC=n(Ke,"LI",{});var Bye=s(aC);Fue=n(Bye,"STRONG",{});var Tet=s(Fue);iur=r(Tet,"bart"),Tet.forEach(t),dur=r(Bye," \u2014 "),jq=n(Bye,"A",{href:!0});var Fet=s(jq);cur=r(Fet,"FlaxBartForQuestionAnswering"),Fet.forEach(t),fur=r(Bye," (BART model)"),Bye.forEach(t),mur=i(Ke),nC=n(Ke,"LI",{});var kye=s(nC);Cue=n(kye,"STRONG",{});var Cet=s(Cue);gur=r(Cet,"bert"),Cet.forEach(t),hur=r(kye," \u2014 "),Nq=n(kye,"A",{href:!0});var Eet=s(Nq);uur=r(Eet,"FlaxBertForQuestionAnswering"),Eet.forEach(t),pur=r(kye," (BERT model)"),kye.forEach(t),_ur=i(Ke),sC=n(Ke,"LI",{});var xye=s(sC);Eue=n(xye,"STRONG",{});var Met=s(Eue);vur=r(Met,"big_bird"),Met.forEach(t),bur=r(xye," \u2014 "),Dq=n(xye,"A",{href:!0});var yet=s(Dq);Tur=r(yet,"FlaxBigBirdForQuestionAnswering"),yet.forEach(t),Fur=r(xye," (BigBird model)"),xye.forEach(t),Cur=i(Ke),lC=n(Ke,"LI",{});var Rye=s(lC);Mue=n(Rye,"STRONG",{});var wet=s(Mue);Eur=r(wet,"distilbert"),wet.forEach(t),Mur=r(Rye," \u2014 "),qq=n(Rye,"A",{href:!0});var Aet=s(qq);yur=r(Aet,"FlaxDistilBertForQuestionAnswering"),Aet.forEach(t),wur=r(Rye," (DistilBERT model)"),Rye.forEach(t),Aur=i(Ke),iC=n(Ke,"LI",{});var Sye=s(iC);yue=n(Sye,"STRONG",{});var Let=s(yue);Lur=r(Let,"electra"),Let.forEach(t),Bur=r(Sye," \u2014 "),Oq=n(Sye,"A",{href:!0});var Bet=s(Oq);kur=r(Bet,"FlaxElectraForQuestionAnswering"),Bet.forEach(t),xur=r(Sye," (ELECTRA model)"),Sye.forEach(t),Rur=i(Ke),dC=n(Ke,"LI",{});var Pye=s(dC);wue=n(Pye,"STRONG",{});var ket=s(wue);Sur=r(ket,"mbart"),ket.forEach(t),Pur=r(Pye," \u2014 "),Gq=n(Pye,"A",{href:!0});var xet=s(Gq);$ur=r(xet,"FlaxMBartForQuestionAnswering"),xet.forEach(t),Iur=r(Pye," (mBART model)"),Pye.forEach(t),jur=i(Ke),cC=n(Ke,"LI",{});var $ye=s(cC);Aue=n($ye,"STRONG",{});var Ret=s(Aue);Nur=r(Ret,"roberta"),Ret.forEach(t),Dur=r($ye," \u2014 "),zq=n($ye,"A",{href:!0});var Set=s(zq);qur=r(Set,"FlaxRobertaForQuestionAnswering"),Set.forEach(t),Our=r($ye," (RoBERTa model)"),$ye.forEach(t),Gur=i(Ke),fC=n(Ke,"LI",{});var Iye=s(fC);Lue=n(Iye,"STRONG",{});var Pet=s(Lue);zur=r(Pet,"roformer"),Pet.forEach(t),Vur=r(Iye," \u2014 "),Vq=n(Iye,"A",{href:!0});var $et=s(Vq);Xur=r($et,"FlaxRoFormerForQuestionAnswering"),$et.forEach(t),Wur=r(Iye," (RoFormer model)"),Iye.forEach(t),Ke.forEach(t),Qur=i(_a),Bue=n(_a,"P",{});var Iet=s(Bue);Hur=r(Iet,"Examples:"),Iet.forEach(t),Uur=i(_a),m(fA.$$.fragment,_a),_a.forEach(t),Gl.forEach(t),NAe=i(d),Ac=n(d,"H2",{class:!0});var N7e=s(Ac);mC=n(N7e,"A",{id:!0,class:!0,href:!0});var jet=s(mC);kue=n(jet,"SPAN",{});var Net=s(kue);m(mA.$$.fragment,Net),Net.forEach(t),jet.forEach(t),Jur=i(N7e),xue=n(N7e,"SPAN",{});var Det=s(xue);Yur=r(Det,"FlaxAutoModelForTokenClassification"),Det.forEach(t),N7e.forEach(t),DAe=i(d),Mr=n(d,"DIV",{class:!0});var Vl=s(Mr);m(gA.$$.fragment,Vl),Kur=i(Vl),Lc=n(Vl,"P",{});var DG=s(Lc);Zur=r(DG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Rue=n(DG,"CODE",{});var qet=s(Rue);epr=r(qet,"from_pretrained()"),qet.forEach(t),opr=r(DG,"class method or the "),Sue=n(DG,"CODE",{});var Oet=s(Sue);rpr=r(Oet,"from_config()"),Oet.forEach(t),tpr=r(DG,`class
method.`),DG.forEach(t),apr=i(Vl),hA=n(Vl,"P",{});var D7e=s(hA);npr=r(D7e,"This class cannot be instantiated directly using "),Pue=n(D7e,"CODE",{});var Get=s(Pue);spr=r(Get,"__init__()"),Get.forEach(t),lpr=r(D7e," (throws an error)."),D7e.forEach(t),ipr=i(Vl),ht=n(Vl,"DIV",{class:!0});var Xl=s(ht);m(uA.$$.fragment,Xl),dpr=i(Xl),$ue=n(Xl,"P",{});var zet=s($ue);cpr=r(zet,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),zet.forEach(t),fpr=i(Xl),Bc=n(Xl,"P",{});var qG=s(Bc);mpr=r(qG,`Note:
Loading a model from its configuration file does `),Iue=n(qG,"STRONG",{});var Vet=s(Iue);gpr=r(Vet,"not"),Vet.forEach(t),hpr=r(qG,` load the model weights. It only affects the
model\u2019s configuration. Use `),jue=n(qG,"CODE",{});var Xet=s(jue);upr=r(Xet,"from_pretrained()"),Xet.forEach(t),ppr=r(qG,"to load the model weights."),qG.forEach(t),_pr=i(Xl),Nue=n(Xl,"P",{});var Wet=s(Nue);vpr=r(Wet,"Examples:"),Wet.forEach(t),bpr=i(Xl),m(pA.$$.fragment,Xl),Xl.forEach(t),Tpr=i(Vl),Bo=n(Vl,"DIV",{class:!0});var va=s(Bo);m(_A.$$.fragment,va),Fpr=i(va),Due=n(va,"P",{});var Qet=s(Due);Cpr=r(Qet,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Qet.forEach(t),Epr=i(va),gn=n(va,"P",{});var yE=s(gn);Mpr=r(yE,"The model class to instantiate is selected based on the "),que=n(yE,"CODE",{});var Het=s(que);ypr=r(Het,"model_type"),Het.forEach(t),wpr=r(yE,` property of the config object (either
passed as an argument or loaded from `),Oue=n(yE,"CODE",{});var Uet=s(Oue);Apr=r(Uet,"pretrained_model_name_or_path"),Uet.forEach(t),Lpr=r(yE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gue=n(yE,"CODE",{});var Jet=s(Gue);Bpr=r(Jet,"pretrained_model_name_or_path"),Jet.forEach(t),kpr=r(yE,":"),yE.forEach(t),xpr=i(va),to=n(va,"UL",{});var Vt=s(to);gC=n(Vt,"LI",{});var jye=s(gC);zue=n(jye,"STRONG",{});var Yet=s(zue);Rpr=r(Yet,"albert"),Yet.forEach(t),Spr=r(jye," \u2014 "),Xq=n(jye,"A",{href:!0});var Ket=s(Xq);Ppr=r(Ket,"FlaxAlbertForTokenClassification"),Ket.forEach(t),$pr=r(jye," (ALBERT model)"),jye.forEach(t),Ipr=i(Vt),hC=n(Vt,"LI",{});var Nye=s(hC);Vue=n(Nye,"STRONG",{});var Zet=s(Vue);jpr=r(Zet,"bert"),Zet.forEach(t),Npr=r(Nye," \u2014 "),Wq=n(Nye,"A",{href:!0});var eot=s(Wq);Dpr=r(eot,"FlaxBertForTokenClassification"),eot.forEach(t),qpr=r(Nye," (BERT model)"),Nye.forEach(t),Opr=i(Vt),uC=n(Vt,"LI",{});var Dye=s(uC);Xue=n(Dye,"STRONG",{});var oot=s(Xue);Gpr=r(oot,"big_bird"),oot.forEach(t),zpr=r(Dye," \u2014 "),Qq=n(Dye,"A",{href:!0});var rot=s(Qq);Vpr=r(rot,"FlaxBigBirdForTokenClassification"),rot.forEach(t),Xpr=r(Dye," (BigBird model)"),Dye.forEach(t),Wpr=i(Vt),pC=n(Vt,"LI",{});var qye=s(pC);Wue=n(qye,"STRONG",{});var tot=s(Wue);Qpr=r(tot,"distilbert"),tot.forEach(t),Hpr=r(qye," \u2014 "),Hq=n(qye,"A",{href:!0});var aot=s(Hq);Upr=r(aot,"FlaxDistilBertForTokenClassification"),aot.forEach(t),Jpr=r(qye," (DistilBERT model)"),qye.forEach(t),Ypr=i(Vt),_C=n(Vt,"LI",{});var Oye=s(_C);Que=n(Oye,"STRONG",{});var not=s(Que);Kpr=r(not,"electra"),not.forEach(t),Zpr=r(Oye," \u2014 "),Uq=n(Oye,"A",{href:!0});var sot=s(Uq);e_r=r(sot,"FlaxElectraForTokenClassification"),sot.forEach(t),o_r=r(Oye," (ELECTRA model)"),Oye.forEach(t),r_r=i(Vt),vC=n(Vt,"LI",{});var Gye=s(vC);Hue=n(Gye,"STRONG",{});var lot=s(Hue);t_r=r(lot,"roberta"),lot.forEach(t),a_r=r(Gye," \u2014 "),Jq=n(Gye,"A",{href:!0});var iot=s(Jq);n_r=r(iot,"FlaxRobertaForTokenClassification"),iot.forEach(t),s_r=r(Gye," (RoBERTa model)"),Gye.forEach(t),l_r=i(Vt),bC=n(Vt,"LI",{});var zye=s(bC);Uue=n(zye,"STRONG",{});var dot=s(Uue);i_r=r(dot,"roformer"),dot.forEach(t),d_r=r(zye," \u2014 "),Yq=n(zye,"A",{href:!0});var cot=s(Yq);c_r=r(cot,"FlaxRoFormerForTokenClassification"),cot.forEach(t),f_r=r(zye," (RoFormer model)"),zye.forEach(t),Vt.forEach(t),m_r=i(va),Jue=n(va,"P",{});var fot=s(Jue);g_r=r(fot,"Examples:"),fot.forEach(t),h_r=i(va),m(vA.$$.fragment,va),va.forEach(t),Vl.forEach(t),qAe=i(d),kc=n(d,"H2",{class:!0});var q7e=s(kc);TC=n(q7e,"A",{id:!0,class:!0,href:!0});var mot=s(TC);Yue=n(mot,"SPAN",{});var got=s(Yue);m(bA.$$.fragment,got),got.forEach(t),mot.forEach(t),u_r=i(q7e),Kue=n(q7e,"SPAN",{});var hot=s(Kue);p_r=r(hot,"FlaxAutoModelForMultipleChoice"),hot.forEach(t),q7e.forEach(t),OAe=i(d),yr=n(d,"DIV",{class:!0});var Wl=s(yr);m(TA.$$.fragment,Wl),__r=i(Wl),xc=n(Wl,"P",{});var OG=s(xc);v_r=r(OG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Zue=n(OG,"CODE",{});var uot=s(Zue);b_r=r(uot,"from_pretrained()"),uot.forEach(t),T_r=r(OG,"class method or the "),epe=n(OG,"CODE",{});var pot=s(epe);F_r=r(pot,"from_config()"),pot.forEach(t),C_r=r(OG,`class
method.`),OG.forEach(t),E_r=i(Wl),FA=n(Wl,"P",{});var O7e=s(FA);M_r=r(O7e,"This class cannot be instantiated directly using "),ope=n(O7e,"CODE",{});var _ot=s(ope);y_r=r(_ot,"__init__()"),_ot.forEach(t),w_r=r(O7e," (throws an error)."),O7e.forEach(t),A_r=i(Wl),ut=n(Wl,"DIV",{class:!0});var Ql=s(ut);m(CA.$$.fragment,Ql),L_r=i(Ql),rpe=n(Ql,"P",{});var vot=s(rpe);B_r=r(vot,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),vot.forEach(t),k_r=i(Ql),Rc=n(Ql,"P",{});var GG=s(Rc);x_r=r(GG,`Note:
Loading a model from its configuration file does `),tpe=n(GG,"STRONG",{});var bot=s(tpe);R_r=r(bot,"not"),bot.forEach(t),S_r=r(GG,` load the model weights. It only affects the
model\u2019s configuration. Use `),ape=n(GG,"CODE",{});var Tot=s(ape);P_r=r(Tot,"from_pretrained()"),Tot.forEach(t),$_r=r(GG,"to load the model weights."),GG.forEach(t),I_r=i(Ql),npe=n(Ql,"P",{});var Fot=s(npe);j_r=r(Fot,"Examples:"),Fot.forEach(t),N_r=i(Ql),m(EA.$$.fragment,Ql),Ql.forEach(t),D_r=i(Wl),ko=n(Wl,"DIV",{class:!0});var ba=s(ko);m(MA.$$.fragment,ba),q_r=i(ba),spe=n(ba,"P",{});var Cot=s(spe);O_r=r(Cot,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Cot.forEach(t),G_r=i(ba),hn=n(ba,"P",{});var wE=s(hn);z_r=r(wE,"The model class to instantiate is selected based on the "),lpe=n(wE,"CODE",{});var Eot=s(lpe);V_r=r(Eot,"model_type"),Eot.forEach(t),X_r=r(wE,` property of the config object (either
passed as an argument or loaded from `),ipe=n(wE,"CODE",{});var Mot=s(ipe);W_r=r(Mot,"pretrained_model_name_or_path"),Mot.forEach(t),Q_r=r(wE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dpe=n(wE,"CODE",{});var yot=s(dpe);H_r=r(yot,"pretrained_model_name_or_path"),yot.forEach(t),U_r=r(wE,":"),wE.forEach(t),J_r=i(ba),ao=n(ba,"UL",{});var Xt=s(ao);FC=n(Xt,"LI",{});var Vye=s(FC);cpe=n(Vye,"STRONG",{});var wot=s(cpe);Y_r=r(wot,"albert"),wot.forEach(t),K_r=r(Vye," \u2014 "),Kq=n(Vye,"A",{href:!0});var Aot=s(Kq);Z_r=r(Aot,"FlaxAlbertForMultipleChoice"),Aot.forEach(t),e2r=r(Vye," (ALBERT model)"),Vye.forEach(t),o2r=i(Xt),CC=n(Xt,"LI",{});var Xye=s(CC);fpe=n(Xye,"STRONG",{});var Lot=s(fpe);r2r=r(Lot,"bert"),Lot.forEach(t),t2r=r(Xye," \u2014 "),Zq=n(Xye,"A",{href:!0});var Bot=s(Zq);a2r=r(Bot,"FlaxBertForMultipleChoice"),Bot.forEach(t),n2r=r(Xye," (BERT model)"),Xye.forEach(t),s2r=i(Xt),EC=n(Xt,"LI",{});var Wye=s(EC);mpe=n(Wye,"STRONG",{});var kot=s(mpe);l2r=r(kot,"big_bird"),kot.forEach(t),i2r=r(Wye," \u2014 "),eO=n(Wye,"A",{href:!0});var xot=s(eO);d2r=r(xot,"FlaxBigBirdForMultipleChoice"),xot.forEach(t),c2r=r(Wye," (BigBird model)"),Wye.forEach(t),f2r=i(Xt),MC=n(Xt,"LI",{});var Qye=s(MC);gpe=n(Qye,"STRONG",{});var Rot=s(gpe);m2r=r(Rot,"distilbert"),Rot.forEach(t),g2r=r(Qye," \u2014 "),oO=n(Qye,"A",{href:!0});var Sot=s(oO);h2r=r(Sot,"FlaxDistilBertForMultipleChoice"),Sot.forEach(t),u2r=r(Qye," (DistilBERT model)"),Qye.forEach(t),p2r=i(Xt),yC=n(Xt,"LI",{});var Hye=s(yC);hpe=n(Hye,"STRONG",{});var Pot=s(hpe);_2r=r(Pot,"electra"),Pot.forEach(t),v2r=r(Hye," \u2014 "),rO=n(Hye,"A",{href:!0});var $ot=s(rO);b2r=r($ot,"FlaxElectraForMultipleChoice"),$ot.forEach(t),T2r=r(Hye," (ELECTRA model)"),Hye.forEach(t),F2r=i(Xt),wC=n(Xt,"LI",{});var Uye=s(wC);upe=n(Uye,"STRONG",{});var Iot=s(upe);C2r=r(Iot,"roberta"),Iot.forEach(t),E2r=r(Uye," \u2014 "),tO=n(Uye,"A",{href:!0});var jot=s(tO);M2r=r(jot,"FlaxRobertaForMultipleChoice"),jot.forEach(t),y2r=r(Uye," (RoBERTa model)"),Uye.forEach(t),w2r=i(Xt),AC=n(Xt,"LI",{});var Jye=s(AC);ppe=n(Jye,"STRONG",{});var Not=s(ppe);A2r=r(Not,"roformer"),Not.forEach(t),L2r=r(Jye," \u2014 "),aO=n(Jye,"A",{href:!0});var Dot=s(aO);B2r=r(Dot,"FlaxRoFormerForMultipleChoice"),Dot.forEach(t),k2r=r(Jye," (RoFormer model)"),Jye.forEach(t),Xt.forEach(t),x2r=i(ba),_pe=n(ba,"P",{});var qot=s(_pe);R2r=r(qot,"Examples:"),qot.forEach(t),S2r=i(ba),m(yA.$$.fragment,ba),ba.forEach(t),Wl.forEach(t),GAe=i(d),Sc=n(d,"H2",{class:!0});var G7e=s(Sc);LC=n(G7e,"A",{id:!0,class:!0,href:!0});var Oot=s(LC);vpe=n(Oot,"SPAN",{});var Got=s(vpe);m(wA.$$.fragment,Got),Got.forEach(t),Oot.forEach(t),P2r=i(G7e),bpe=n(G7e,"SPAN",{});var zot=s(bpe);$2r=r(zot,"FlaxAutoModelForNextSentencePrediction"),zot.forEach(t),G7e.forEach(t),zAe=i(d),wr=n(d,"DIV",{class:!0});var Hl=s(wr);m(AA.$$.fragment,Hl),I2r=i(Hl),Pc=n(Hl,"P",{});var zG=s(Pc);j2r=r(zG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Tpe=n(zG,"CODE",{});var Vot=s(Tpe);N2r=r(Vot,"from_pretrained()"),Vot.forEach(t),D2r=r(zG,"class method or the "),Fpe=n(zG,"CODE",{});var Xot=s(Fpe);q2r=r(Xot,"from_config()"),Xot.forEach(t),O2r=r(zG,`class
method.`),zG.forEach(t),G2r=i(Hl),LA=n(Hl,"P",{});var z7e=s(LA);z2r=r(z7e,"This class cannot be instantiated directly using "),Cpe=n(z7e,"CODE",{});var Wot=s(Cpe);V2r=r(Wot,"__init__()"),Wot.forEach(t),X2r=r(z7e," (throws an error)."),z7e.forEach(t),W2r=i(Hl),pt=n(Hl,"DIV",{class:!0});var Ul=s(pt);m(BA.$$.fragment,Ul),Q2r=i(Ul),Epe=n(Ul,"P",{});var Qot=s(Epe);H2r=r(Qot,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Qot.forEach(t),U2r=i(Ul),$c=n(Ul,"P",{});var VG=s($c);J2r=r(VG,`Note:
Loading a model from its configuration file does `),Mpe=n(VG,"STRONG",{});var Hot=s(Mpe);Y2r=r(Hot,"not"),Hot.forEach(t),K2r=r(VG,` load the model weights. It only affects the
model\u2019s configuration. Use `),ype=n(VG,"CODE",{});var Uot=s(ype);Z2r=r(Uot,"from_pretrained()"),Uot.forEach(t),evr=r(VG,"to load the model weights."),VG.forEach(t),ovr=i(Ul),wpe=n(Ul,"P",{});var Jot=s(wpe);rvr=r(Jot,"Examples:"),Jot.forEach(t),tvr=i(Ul),m(kA.$$.fragment,Ul),Ul.forEach(t),avr=i(Hl),xo=n(Hl,"DIV",{class:!0});var Ta=s(xo);m(xA.$$.fragment,Ta),nvr=i(Ta),Ape=n(Ta,"P",{});var Yot=s(Ape);svr=r(Yot,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Yot.forEach(t),lvr=i(Ta),un=n(Ta,"P",{});var AE=s(un);ivr=r(AE,"The model class to instantiate is selected based on the "),Lpe=n(AE,"CODE",{});var Kot=s(Lpe);dvr=r(Kot,"model_type"),Kot.forEach(t),cvr=r(AE,` property of the config object (either
passed as an argument or loaded from `),Bpe=n(AE,"CODE",{});var Zot=s(Bpe);fvr=r(Zot,"pretrained_model_name_or_path"),Zot.forEach(t),mvr=r(AE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kpe=n(AE,"CODE",{});var ert=s(kpe);gvr=r(ert,"pretrained_model_name_or_path"),ert.forEach(t),hvr=r(AE,":"),AE.forEach(t),uvr=i(Ta),xpe=n(Ta,"UL",{});var ort=s(xpe);BC=n(ort,"LI",{});var Yye=s(BC);Rpe=n(Yye,"STRONG",{});var rrt=s(Rpe);pvr=r(rrt,"bert"),rrt.forEach(t),_vr=r(Yye," \u2014 "),nO=n(Yye,"A",{href:!0});var trt=s(nO);vvr=r(trt,"FlaxBertForNextSentencePrediction"),trt.forEach(t),bvr=r(Yye," (BERT model)"),Yye.forEach(t),ort.forEach(t),Tvr=i(Ta),Spe=n(Ta,"P",{});var art=s(Spe);Fvr=r(art,"Examples:"),art.forEach(t),Cvr=i(Ta),m(RA.$$.fragment,Ta),Ta.forEach(t),Hl.forEach(t),VAe=i(d),Ic=n(d,"H2",{class:!0});var V7e=s(Ic);kC=n(V7e,"A",{id:!0,class:!0,href:!0});var nrt=s(kC);Ppe=n(nrt,"SPAN",{});var srt=s(Ppe);m(SA.$$.fragment,srt),srt.forEach(t),nrt.forEach(t),Evr=i(V7e),$pe=n(V7e,"SPAN",{});var lrt=s($pe);Mvr=r(lrt,"FlaxAutoModelForImageClassification"),lrt.forEach(t),V7e.forEach(t),XAe=i(d),Ar=n(d,"DIV",{class:!0});var Jl=s(Ar);m(PA.$$.fragment,Jl),yvr=i(Jl),jc=n(Jl,"P",{});var XG=s(jc);wvr=r(XG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Ipe=n(XG,"CODE",{});var irt=s(Ipe);Avr=r(irt,"from_pretrained()"),irt.forEach(t),Lvr=r(XG,"class method or the "),jpe=n(XG,"CODE",{});var drt=s(jpe);Bvr=r(drt,"from_config()"),drt.forEach(t),kvr=r(XG,`class
method.`),XG.forEach(t),xvr=i(Jl),$A=n(Jl,"P",{});var X7e=s($A);Rvr=r(X7e,"This class cannot be instantiated directly using "),Npe=n(X7e,"CODE",{});var crt=s(Npe);Svr=r(crt,"__init__()"),crt.forEach(t),Pvr=r(X7e," (throws an error)."),X7e.forEach(t),$vr=i(Jl),_t=n(Jl,"DIV",{class:!0});var Yl=s(_t);m(IA.$$.fragment,Yl),Ivr=i(Yl),Dpe=n(Yl,"P",{});var frt=s(Dpe);jvr=r(frt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),frt.forEach(t),Nvr=i(Yl),Nc=n(Yl,"P",{});var WG=s(Nc);Dvr=r(WG,`Note:
Loading a model from its configuration file does `),qpe=n(WG,"STRONG",{});var mrt=s(qpe);qvr=r(mrt,"not"),mrt.forEach(t),Ovr=r(WG,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ope=n(WG,"CODE",{});var grt=s(Ope);Gvr=r(grt,"from_pretrained()"),grt.forEach(t),zvr=r(WG,"to load the model weights."),WG.forEach(t),Vvr=i(Yl),Gpe=n(Yl,"P",{});var hrt=s(Gpe);Xvr=r(hrt,"Examples:"),hrt.forEach(t),Wvr=i(Yl),m(jA.$$.fragment,Yl),Yl.forEach(t),Qvr=i(Jl),Ro=n(Jl,"DIV",{class:!0});var Fa=s(Ro);m(NA.$$.fragment,Fa),Hvr=i(Fa),zpe=n(Fa,"P",{});var urt=s(zpe);Uvr=r(urt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),urt.forEach(t),Jvr=i(Fa),pn=n(Fa,"P",{});var LE=s(pn);Yvr=r(LE,"The model class to instantiate is selected based on the "),Vpe=n(LE,"CODE",{});var prt=s(Vpe);Kvr=r(prt,"model_type"),prt.forEach(t),Zvr=r(LE,` property of the config object (either
passed as an argument or loaded from `),Xpe=n(LE,"CODE",{});var _rt=s(Xpe);e1r=r(_rt,"pretrained_model_name_or_path"),_rt.forEach(t),o1r=r(LE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wpe=n(LE,"CODE",{});var vrt=s(Wpe);r1r=r(vrt,"pretrained_model_name_or_path"),vrt.forEach(t),t1r=r(LE,":"),LE.forEach(t),a1r=i(Fa),DA=n(Fa,"UL",{});var W7e=s(DA);xC=n(W7e,"LI",{});var Kye=s(xC);Qpe=n(Kye,"STRONG",{});var brt=s(Qpe);n1r=r(brt,"beit"),brt.forEach(t),s1r=r(Kye," \u2014 "),sO=n(Kye,"A",{href:!0});var Trt=s(sO);l1r=r(Trt,"FlaxBeitForImageClassification"),Trt.forEach(t),i1r=r(Kye," (BEiT model)"),Kye.forEach(t),d1r=i(W7e),RC=n(W7e,"LI",{});var Zye=s(RC);Hpe=n(Zye,"STRONG",{});var Frt=s(Hpe);c1r=r(Frt,"vit"),Frt.forEach(t),f1r=r(Zye," \u2014 "),lO=n(Zye,"A",{href:!0});var Crt=s(lO);m1r=r(Crt,"FlaxViTForImageClassification"),Crt.forEach(t),g1r=r(Zye," (ViT model)"),Zye.forEach(t),W7e.forEach(t),h1r=i(Fa),Upe=n(Fa,"P",{});var Ert=s(Upe);u1r=r(Ert,"Examples:"),Ert.forEach(t),p1r=i(Fa),m(qA.$$.fragment,Fa),Fa.forEach(t),Jl.forEach(t),WAe=i(d),Dc=n(d,"H2",{class:!0});var Q7e=s(Dc);SC=n(Q7e,"A",{id:!0,class:!0,href:!0});var Mrt=s(SC);Jpe=n(Mrt,"SPAN",{});var yrt=s(Jpe);m(OA.$$.fragment,yrt),yrt.forEach(t),Mrt.forEach(t),_1r=i(Q7e),Ype=n(Q7e,"SPAN",{});var wrt=s(Ype);v1r=r(wrt,"FlaxAutoModelForVision2Seq"),wrt.forEach(t),Q7e.forEach(t),QAe=i(d),Lr=n(d,"DIV",{class:!0});var Kl=s(Lr);m(GA.$$.fragment,Kl),b1r=i(Kl),qc=n(Kl,"P",{});var QG=s(qc);T1r=r(QG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Kpe=n(QG,"CODE",{});var Art=s(Kpe);F1r=r(Art,"from_pretrained()"),Art.forEach(t),C1r=r(QG,"class method or the "),Zpe=n(QG,"CODE",{});var Lrt=s(Zpe);E1r=r(Lrt,"from_config()"),Lrt.forEach(t),M1r=r(QG,`class
method.`),QG.forEach(t),y1r=i(Kl),zA=n(Kl,"P",{});var H7e=s(zA);w1r=r(H7e,"This class cannot be instantiated directly using "),e_e=n(H7e,"CODE",{});var Brt=s(e_e);A1r=r(Brt,"__init__()"),Brt.forEach(t),L1r=r(H7e," (throws an error)."),H7e.forEach(t),B1r=i(Kl),vt=n(Kl,"DIV",{class:!0});var Zl=s(vt);m(VA.$$.fragment,Zl),k1r=i(Zl),o_e=n(Zl,"P",{});var krt=s(o_e);x1r=r(krt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),krt.forEach(t),R1r=i(Zl),Oc=n(Zl,"P",{});var HG=s(Oc);S1r=r(HG,`Note:
Loading a model from its configuration file does `),r_e=n(HG,"STRONG",{});var xrt=s(r_e);P1r=r(xrt,"not"),xrt.forEach(t),$1r=r(HG,` load the model weights. It only affects the
model\u2019s configuration. Use `),t_e=n(HG,"CODE",{});var Rrt=s(t_e);I1r=r(Rrt,"from_pretrained()"),Rrt.forEach(t),j1r=r(HG,"to load the model weights."),HG.forEach(t),N1r=i(Zl),a_e=n(Zl,"P",{});var Srt=s(a_e);D1r=r(Srt,"Examples:"),Srt.forEach(t),q1r=i(Zl),m(XA.$$.fragment,Zl),Zl.forEach(t),O1r=i(Kl),So=n(Kl,"DIV",{class:!0});var Ca=s(So);m(WA.$$.fragment,Ca),G1r=i(Ca),n_e=n(Ca,"P",{});var Prt=s(n_e);z1r=r(Prt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Prt.forEach(t),V1r=i(Ca),_n=n(Ca,"P",{});var BE=s(_n);X1r=r(BE,"The model class to instantiate is selected based on the "),s_e=n(BE,"CODE",{});var $rt=s(s_e);W1r=r($rt,"model_type"),$rt.forEach(t),Q1r=r(BE,` property of the config object (either
passed as an argument or loaded from `),l_e=n(BE,"CODE",{});var Irt=s(l_e);H1r=r(Irt,"pretrained_model_name_or_path"),Irt.forEach(t),U1r=r(BE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i_e=n(BE,"CODE",{});var jrt=s(i_e);J1r=r(jrt,"pretrained_model_name_or_path"),jrt.forEach(t),Y1r=r(BE,":"),BE.forEach(t),K1r=i(Ca),d_e=n(Ca,"UL",{});var Nrt=s(d_e);PC=n(Nrt,"LI",{});var ewe=s(PC);c_e=n(ewe,"STRONG",{});var Drt=s(c_e);Z1r=r(Drt,"vision-encoder-decoder"),Drt.forEach(t),e4r=r(ewe," \u2014 "),iO=n(ewe,"A",{href:!0});var qrt=s(iO);o4r=r(qrt,"FlaxVisionEncoderDecoderModel"),qrt.forEach(t),r4r=r(ewe," (Vision Encoder decoder model)"),ewe.forEach(t),Nrt.forEach(t),t4r=i(Ca),f_e=n(Ca,"P",{});var Ort=s(f_e);a4r=r(Ort,"Examples:"),Ort.forEach(t),n4r=i(Ca),m(QA.$$.fragment,Ca),Ca.forEach(t),Kl.forEach(t),this.h()},h(){c(J,"name","hf:doc:metadata"),c(J,"content",JSON.stringify(Jrt)),c(me,"id","auto-classes"),c(me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(me,"href","#auto-classes"),c(se,"class","relative group"),c(vn,"href","/docs/transformers/v4.16.2/en/model_doc/auto#transformers.AutoConfig"),c(Tn,"href","/docs/transformers/v4.16.2/en/model_doc/auto#transformers.AutoModel"),c(Fn,"href","/docs/transformers/v4.16.2/en/model_doc/auto#transformers.AutoTokenizer"),c(li,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertModel"),c(Qc,"id","extending-the-auto-classes"),c(Qc,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Qc,"href","#extending-the-auto-classes"),c(ii,"class","relative group"),c(Uc,"id","transformers.AutoConfig"),c(Uc,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Uc,"href","#transformers.AutoConfig"),c(di,"class","relative group"),c(U0,"href","/docs/transformers/v4.16.2/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(J0,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertConfig"),c(Y0,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartConfig"),c(K0,"href","/docs/transformers/v4.16.2/en/model_doc/beit#transformers.BeitConfig"),c(Z0,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertConfig"),c(e7,"href","/docs/transformers/v4.16.2/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(o7,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdConfig"),c(r7,"href","/docs/transformers/v4.16.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(t7,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(a7,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(n7,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertConfig"),c(s7,"href","/docs/transformers/v4.16.2/en/model_doc/canine#transformers.CanineConfig"),c(l7,"href","/docs/transformers/v4.16.2/en/model_doc/clip#transformers.CLIPConfig"),c(i7,"href","/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertConfig"),c(d7,"href","/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLConfig"),c(c7,"href","/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaConfig"),c(f7,"href","/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(m7,"href","/docs/transformers/v4.16.2/en/model_doc/deit#transformers.DeiTConfig"),c(g7,"href","/docs/transformers/v4.16.2/en/model_doc/detr#transformers.DetrConfig"),c(h7,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertConfig"),c(u7,"href","/docs/transformers/v4.16.2/en/model_doc/dpr#transformers.DPRConfig"),c(p7,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraConfig"),c(_7,"href","/docs/transformers/v4.16.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(v7,"href","/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertConfig"),c(b7,"href","/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetConfig"),c(T7,"href","/docs/transformers/v4.16.2/en/model_doc/fsmt#transformers.FSMTConfig"),c(F7,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelConfig"),c(C7,"href","/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2Config"),c(E7,"href","/docs/transformers/v4.16.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(M7,"href","/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.GPTJConfig"),c(y7,"href","/docs/transformers/v4.16.2/en/model_doc/hubert#transformers.HubertConfig"),c(w7,"href","/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertConfig"),c(A7,"href","/docs/transformers/v4.16.2/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(L7,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(B7,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(k7,"href","/docs/transformers/v4.16.2/en/model_doc/led#transformers.LEDConfig"),c(x7,"href","/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerConfig"),c(R7,"href","/docs/transformers/v4.16.2/en/model_doc/luke#transformers.LukeConfig"),c(S7,"href","/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.LxmertConfig"),c(P7,"href","/docs/transformers/v4.16.2/en/model_doc/m2m_100#transformers.M2M100Config"),c($7,"href","/docs/transformers/v4.16.2/en/model_doc/marian#transformers.MarianConfig"),c(I7,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartConfig"),c(j7,"href","/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(N7,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(D7,"href","/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetConfig"),c(q7,"href","/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.MT5Config"),c(O7,"href","/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(G7,"href","/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(z7,"href","/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusConfig"),c(V7,"href","/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverConfig"),c(X7,"href","/docs/transformers/v4.16.2/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(W7,"href","/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(Q7,"href","/docs/transformers/v4.16.2/en/model_doc/rag#transformers.RagConfig"),c(H7,"href","/docs/transformers/v4.16.2/en/model_doc/realm#transformers.RealmConfig"),c(U7,"href","/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerConfig"),c(J7,"href","/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertConfig"),c(Y7,"href","/docs/transformers/v4.16.2/en/model_doc/retribert#transformers.RetriBertConfig"),c(K7,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaConfig"),c(Z7,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerConfig"),c(eL,"href","/docs/transformers/v4.16.2/en/model_doc/segformer#transformers.SegformerConfig"),c(oL,"href","/docs/transformers/v4.16.2/en/model_doc/sew#transformers.SEWConfig"),c(rL,"href","/docs/transformers/v4.16.2/en/model_doc/sew-d#transformers.SEWDConfig"),c(tL,"href","/docs/transformers/v4.16.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(aL,"href","/docs/transformers/v4.16.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(nL,"href","/docs/transformers/v4.16.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(sL,"href","/docs/transformers/v4.16.2/en/model_doc/splinter#transformers.SplinterConfig"),c(lL,"href","/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(iL,"href","/docs/transformers/v4.16.2/en/model_doc/swin#transformers.SwinConfig"),c(dL,"href","/docs/transformers/v4.16.2/en/model_doc/t5#transformers.T5Config"),c(cL,"href","/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasConfig"),c(fL,"href","/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(mL,"href","/docs/transformers/v4.16.2/en/model_doc/trocr#transformers.TrOCRConfig"),c(gL,"href","/docs/transformers/v4.16.2/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(hL,"href","/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(uL,"href","/docs/transformers/v4.16.2/en/model_doc/vilt#transformers.ViltConfig"),c(pL,"href","/docs/transformers/v4.16.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(_L,"href","/docs/transformers/v4.16.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(vL,"href","/docs/transformers/v4.16.2/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(bL,"href","/docs/transformers/v4.16.2/en/model_doc/vit#transformers.ViTConfig"),c(TL,"href","/docs/transformers/v4.16.2/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(FL,"href","/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(CL,"href","/docs/transformers/v4.16.2/en/model_doc/wavlm#transformers.WavLMConfig"),c(EL,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMConfig"),c(ML,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(yL,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(wL,"href","/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetConfig"),c(AL,"href","/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoConfig"),c(lo,"class","docstring"),c(Bm,"class","docstring"),c(jo,"class","docstring"),c(km,"id","transformers.AutoTokenizer"),c(km,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(km,"href","#transformers.AutoTokenizer"),c(fi,"class","relative group"),c(LL,"href","/docs/transformers/v4.16.2/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(BL,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertTokenizer"),c(kL,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(xL,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartTokenizer"),c(RL,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartTokenizerFast"),c(SL,"href","/docs/transformers/v4.16.2/en/model_doc/barthez#transformers.BarthezTokenizer"),c(PL,"href","/docs/transformers/v4.16.2/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c($L,"href","/docs/transformers/v4.16.2/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(IL,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertTokenizer"),c(jL,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertTokenizerFast"),c(NL,"href","/docs/transformers/v4.16.2/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(DL,"href","/docs/transformers/v4.16.2/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(qL,"href","/docs/transformers/v4.16.2/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(OL,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(GL,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(zL,"href","/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(VL,"href","/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(XL,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(WL,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(QL,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(HL,"href","/docs/transformers/v4.16.2/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(UL,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertTokenizer"),c(JL,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(YL,"href","/docs/transformers/v4.16.2/en/model_doc/canine#transformers.CanineTokenizer"),c(KL,"href","/docs/transformers/v4.16.2/en/model_doc/clip#transformers.CLIPTokenizer"),c(ZL,"href","/docs/transformers/v4.16.2/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(e8,"href","/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(o8,"href","/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(r8,"href","/docs/transformers/v4.16.2/en/model_doc/cpm#transformers.CpmTokenizer"),c(t8,"href","/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(a8,"href","/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaTokenizer"),c(n8,"href","/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(s8,"href","/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(l8,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(i8,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(d8,"href","/docs/transformers/v4.16.2/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(c8,"href","/docs/transformers/v4.16.2/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(f8,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraTokenizer"),c(m8,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(g8,"href","/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(h8,"href","/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetTokenizer"),c(u8,"href","/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(p8,"href","/docs/transformers/v4.16.2/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(_8,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelTokenizer"),c(v8,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(b8,"href","/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(T8,"href","/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(F8,"href","/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(C8,"href","/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(E8,"href","/docs/transformers/v4.16.2/en/model_doc/herbert#transformers.HerbertTokenizer"),c(M8,"href","/docs/transformers/v4.16.2/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(y8,"href","/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(w8,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaTokenizer"),c(A8,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(L8,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(B8,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(k8,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(x8,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(R8,"href","/docs/transformers/v4.16.2/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(S8,"href","/docs/transformers/v4.16.2/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(P8,"href","/docs/transformers/v4.16.2/en/model_doc/led#transformers.LEDTokenizer"),c($8,"href","/docs/transformers/v4.16.2/en/model_doc/led#transformers.LEDTokenizerFast"),c(I8,"href","/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerTokenizer"),c(j8,"href","/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(N8,"href","/docs/transformers/v4.16.2/en/model_doc/luke#transformers.LukeTokenizer"),c(D8,"href","/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(q8,"href","/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(O8,"href","/docs/transformers/v4.16.2/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(G8,"href","/docs/transformers/v4.16.2/en/model_doc/marian#transformers.MarianTokenizer"),c(z8,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartTokenizer"),c(V8,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(X8,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(W8,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(Q8,"href","/docs/transformers/v4.16.2/en/model_doc/mluke#transformers.MLukeTokenizer"),c(H8,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(U8,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(J8,"href","/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(Y8,"href","/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(K8,"href","/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.T5Tokenizer"),c(Z8,"href","/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.T5TokenizerFast"),c(eB,"href","/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(oB,"href","/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(rB,"href","/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(tB,"href","/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(aB,"href","/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(nB,"href","/docs/transformers/v4.16.2/en/model_doc/phobert#transformers.PhobertTokenizer"),c(sB,"href","/docs/transformers/v4.16.2/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(lB,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertTokenizer"),c(iB,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertTokenizerFast"),c(dB,"href","/docs/transformers/v4.16.2/en/model_doc/rag#transformers.RagTokenizer"),c(cB,"href","/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerTokenizer"),c(fB,"href","/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(mB,"href","/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertTokenizer"),c(gB,"href","/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(hB,"href","/docs/transformers/v4.16.2/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(uB,"href","/docs/transformers/v4.16.2/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(pB,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaTokenizer"),c(_B,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(vB,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(bB,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(TB,"href","/docs/transformers/v4.16.2/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(FB,"href","/docs/transformers/v4.16.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(CB,"href","/docs/transformers/v4.16.2/en/model_doc/splinter#transformers.SplinterTokenizer"),c(EB,"href","/docs/transformers/v4.16.2/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(MB,"href","/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(yB,"href","/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(wB,"href","/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.T5Tokenizer"),c(AB,"href","/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.T5TokenizerFast"),c(LB,"href","/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasTokenizer"),c(BB,"href","/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(kB,"href","/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(xB,"href","/docs/transformers/v4.16.2/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(RB,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMTokenizer"),c(SB,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(PB,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c($B,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(IB,"href","/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(jB,"href","/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(io,"class","docstring"),c(ng,"class","docstring"),c(No,"class","docstring"),c(sg,"id","transformers.AutoFeatureExtractor"),c(sg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sg,"href","#transformers.AutoFeatureExtractor"),c(mi,"class","relative group"),c(NB,"href","/docs/transformers/v4.16.2/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(DB,"href","/docs/transformers/v4.16.2/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(qB,"href","/docs/transformers/v4.16.2/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(OB,"href","/docs/transformers/v4.16.2/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(GB,"href","/docs/transformers/v4.16.2/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(zB,"href","/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(VB,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(XB,"href","/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(WB,"href","/docs/transformers/v4.16.2/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(QB,"href","/docs/transformers/v4.16.2/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(HB,"href","/docs/transformers/v4.16.2/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(UB,"href","/docs/transformers/v4.16.2/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(JB,"href","/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(Ae,"class","docstring"),c(Wt,"class","docstring"),c(Tg,"id","transformers.AutoProcessor"),c(Tg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Tg,"href","#transformers.AutoProcessor"),c(gi,"class","relative group"),c(YB,"href","/docs/transformers/v4.16.2/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(KB,"href","/docs/transformers/v4.16.2/en/model_doc/clip#transformers.CLIPProcessor"),c(ZB,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(e9,"href","/docs/transformers/v4.16.2/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(o9,"href","/docs/transformers/v4.16.2/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(r9,"href","/docs/transformers/v4.16.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(t9,"href","/docs/transformers/v4.16.2/en/model_doc/trocr#transformers.TrOCRProcessor"),c(a9,"href","/docs/transformers/v4.16.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(n9,"href","/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Le,"class","docstring"),c(Qt,"class","docstring"),c(kg,"id","transformers.AutoModel"),c(kg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kg,"href","#transformers.AutoModel"),c(ui,"class","relative group"),c(Br,"class","docstring"),c(s9,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertModel"),c(l9,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartModel"),c(i9,"href","/docs/transformers/v4.16.2/en/model_doc/beit#transformers.BeitModel"),c(d9,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertModel"),c(c9,"href","/docs/transformers/v4.16.2/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(f9,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdModel"),c(m9,"href","/docs/transformers/v4.16.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(g9,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(h9,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(u9,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertModel"),c(p9,"href","/docs/transformers/v4.16.2/en/model_doc/canine#transformers.CanineModel"),c(_9,"href","/docs/transformers/v4.16.2/en/model_doc/clip#transformers.CLIPModel"),c(v9,"href","/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertModel"),c(b9,"href","/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLModel"),c(T9,"href","/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaModel"),c(F9,"href","/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(C9,"href","/docs/transformers/v4.16.2/en/model_doc/deit#transformers.DeiTModel"),c(E9,"href","/docs/transformers/v4.16.2/en/model_doc/detr#transformers.DetrModel"),c(M9,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertModel"),c(y9,"href","/docs/transformers/v4.16.2/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(w9,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraModel"),c(A9,"href","/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertModel"),c(L9,"href","/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetModel"),c(B9,"href","/docs/transformers/v4.16.2/en/model_doc/fsmt#transformers.FSMTModel"),c(k9,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelModel"),c(x9,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelBaseModel"),c(R9,"href","/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2Model"),c(S9,"href","/docs/transformers/v4.16.2/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(P9,"href","/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.GPTJModel"),c($9,"href","/docs/transformers/v4.16.2/en/model_doc/hubert#transformers.HubertModel"),c(I9,"href","/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertModel"),c(j9,"href","/docs/transformers/v4.16.2/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(N9,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(D9,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(q9,"href","/docs/transformers/v4.16.2/en/model_doc/led#transformers.LEDModel"),c(O9,"href","/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerModel"),c(G9,"href","/docs/transformers/v4.16.2/en/model_doc/luke#transformers.LukeModel"),c(z9,"href","/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.LxmertModel"),c(V9,"href","/docs/transformers/v4.16.2/en/model_doc/m2m_100#transformers.M2M100Model"),c(X9,"href","/docs/transformers/v4.16.2/en/model_doc/marian#transformers.MarianModel"),c(W9,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartModel"),c(Q9,"href","/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(H9,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertModel"),c(U9,"href","/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetModel"),c(J9,"href","/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.MT5Model"),c(Y9,"href","/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerModel"),c(K9,"href","/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(Z9,"href","/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusModel"),c(ek,"href","/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverModel"),c(ok,"href","/docs/transformers/v4.16.2/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(rk,"href","/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertModel"),c(tk,"href","/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerModel"),c(ak,"href","/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertModel"),c(nk,"href","/docs/transformers/v4.16.2/en/model_doc/retribert#transformers.RetriBertModel"),c(sk,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaModel"),c(lk,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerModel"),c(ik,"href","/docs/transformers/v4.16.2/en/model_doc/segformer#transformers.SegformerModel"),c(dk,"href","/docs/transformers/v4.16.2/en/model_doc/sew#transformers.SEWModel"),c(ck,"href","/docs/transformers/v4.16.2/en/model_doc/sew-d#transformers.SEWDModel"),c(fk,"href","/docs/transformers/v4.16.2/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(mk,"href","/docs/transformers/v4.16.2/en/model_doc/splinter#transformers.SplinterModel"),c(gk,"href","/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(hk,"href","/docs/transformers/v4.16.2/en/model_doc/swin#transformers.SwinModel"),c(uk,"href","/docs/transformers/v4.16.2/en/model_doc/t5#transformers.T5Model"),c(pk,"href","/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasModel"),c(_k,"href","/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(vk,"href","/docs/transformers/v4.16.2/en/model_doc/unispeech#transformers.UniSpeechModel"),c(bk,"href","/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(Tk,"href","/docs/transformers/v4.16.2/en/model_doc/vilt#transformers.ViltModel"),c(Fk,"href","/docs/transformers/v4.16.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(Ck,"href","/docs/transformers/v4.16.2/en/model_doc/visual_bert#transformers.VisualBertModel"),c(Ek,"href","/docs/transformers/v4.16.2/en/model_doc/vit#transformers.ViTModel"),c(Mk,"href","/docs/transformers/v4.16.2/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(yk,"href","/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(wk,"href","/docs/transformers/v4.16.2/en/model_doc/wavlm#transformers.WavLMModel"),c(Ak,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMModel"),c(Lk,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(Bk,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(kk,"href","/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetModel"),c(xk,"href","/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoModel"),c(Be,"class","docstring"),c(Do,"class","docstring"),c(ru,"id","transformers.AutoModelForPreTraining"),c(ru,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ru,"href","#transformers.AutoModelForPreTraining"),c(vi,"class","relative group"),c(kr,"class","docstring"),c(Rk,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertForPreTraining"),c(Sk,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(Pk,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertForPreTraining"),c($k,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(Ik,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(jk,"href","/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(Nk,"href","/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(Dk,"href","/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(qk,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(Ok,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraForPreTraining"),c(Gk,"href","/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(zk,"href","/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetForPreTraining"),c(Vk,"href","/docs/transformers/v4.16.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(Xk,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(Wk,"href","/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(Qk,"href","/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(Hk,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(Uk,"href","/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(Jk,"href","/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(Yk,"href","/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(Kk,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(Zk,"href","/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(ex,"href","/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(ox,"href","/docs/transformers/v4.16.2/en/model_doc/retribert#transformers.RetriBertModel"),c(rx,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(tx,"href","/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(ax,"href","/docs/transformers/v4.16.2/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(nx,"href","/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(sx,"href","/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(lx,"href","/docs/transformers/v4.16.2/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(ix,"href","/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(dx,"href","/docs/transformers/v4.16.2/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(cx,"href","/docs/transformers/v4.16.2/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(fx,"href","/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(mx,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(gx,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(hx,"href","/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(ke,"class","docstring"),c(qo,"class","docstring"),c(Ou,"id","transformers.AutoModelForCausalLM"),c(Ou,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ou,"href","#transformers.AutoModelForCausalLM"),c(Fi,"class","relative group"),c(xr,"class","docstring"),c(ux,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartForCausalLM"),c(px,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertLMHeadModel"),c(_x,"href","/docs/transformers/v4.16.2/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(vx,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(bx,"href","/docs/transformers/v4.16.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(Tx,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(Fx,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(Cx,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(Ex,"href","/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(Mx,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraForCausalLM"),c(yx,"href","/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(wx,"href","/docs/transformers/v4.16.2/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(Ax,"href","/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(Lx,"href","/docs/transformers/v4.16.2/en/model_doc/marian#transformers.MarianForCausalLM"),c(Bx,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartForCausalLM"),c(kx,"href","/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(xx,"href","/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(Rx,"href","/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(Sx,"href","/docs/transformers/v4.16.2/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(Px,"href","/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c($x,"href","/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(Ix,"href","/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(jx,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(Nx,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(Dx,"href","/docs/transformers/v4.16.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(qx,"href","/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(Ox,"href","/docs/transformers/v4.16.2/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(Gx,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(zx,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(Vx,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(Xx,"href","/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(xe,"class","docstring"),c(Oo,"class","docstring"),c(Tp,"id","transformers.AutoModelForMaskedLM"),c(Tp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Tp,"href","#transformers.AutoModelForMaskedLM"),c(Mi,"class","relative group"),c(Rr,"class","docstring"),c(Wx,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(Qx,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(Hx,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertForMaskedLM"),c(Ux,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(Jx,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(Yx,"href","/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(Kx,"href","/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(Zx,"href","/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(eR,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(oR,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(rR,"href","/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(tR,"href","/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(aR,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(nR,"href","/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(sR,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(lR,"href","/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(iR,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(dR,"href","/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(cR,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(fR,"href","/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(mR,"href","/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(gR,"href","/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(hR,"href","/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(uR,"href","/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(pR,"href","/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(_R,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(vR,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(bR,"href","/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(TR,"href","/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(FR,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(CR,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(ER,"href","/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Re,"class","docstring"),c(Go,"class","docstring"),c(o_,"id","transformers.AutoModelForSeq2SeqLM"),c(o_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(o_,"href","#transformers.AutoModelForSeq2SeqLM"),c(Ai,"class","relative group"),c(Sr,"class","docstring"),c(MR,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(yR,"href","/docs/transformers/v4.16.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(wR,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(AR,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(LR,"href","/docs/transformers/v4.16.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(BR,"href","/docs/transformers/v4.16.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(kR,"href","/docs/transformers/v4.16.2/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(xR,"href","/docs/transformers/v4.16.2/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(RR,"href","/docs/transformers/v4.16.2/en/model_doc/marian#transformers.MarianMTModel"),c(SR,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(PR,"href","/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c($R,"href","/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(IR,"href","/docs/transformers/v4.16.2/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(jR,"href","/docs/transformers/v4.16.2/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(NR,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(Se,"class","docstring"),c(zo,"class","docstring"),c(v_,"id","transformers.AutoModelForSequenceClassification"),c(v_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(v_,"href","#transformers.AutoModelForSequenceClassification"),c(ki,"class","relative group"),c(Pr,"class","docstring"),c(DR,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(qR,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartForSequenceClassification"),c(OR,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertForSequenceClassification"),c(GR,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(zR,"href","/docs/transformers/v4.16.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(VR,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(XR,"href","/docs/transformers/v4.16.2/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(WR,"href","/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(QR,"href","/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(HR,"href","/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(UR,"href","/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(JR,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(YR,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(KR,"href","/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(ZR,"href","/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(eS,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(oS,"href","/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(rS,"href","/docs/transformers/v4.16.2/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(tS,"href","/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(aS,"href","/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(nS,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(sS,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(lS,"href","/docs/transformers/v4.16.2/en/model_doc/led#transformers.LEDForSequenceClassification"),c(iS,"href","/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(dS,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(cS,"href","/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(fS,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(mS,"href","/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(gS,"href","/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(hS,"href","/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(uS,"href","/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(pS,"href","/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(_S,"href","/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(vS,"href","/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(bS,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(TS,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(FS,"href","/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(CS,"href","/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(ES,"href","/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(MS,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(yS,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(wS,"href","/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(AS,"href","/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(Pe,"class","docstring"),c(Vo,"class","docstring"),c(d2,"id","transformers.AutoModelForMultipleChoice"),c(d2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d2,"href","#transformers.AutoModelForMultipleChoice"),c(Si,"class","relative group"),c($r,"class","docstring"),c(LS,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(BS,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertForMultipleChoice"),c(kS,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(xS,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(RS,"href","/docs/transformers/v4.16.2/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(SS,"href","/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(PS,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c($S,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(IS,"href","/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(jS,"href","/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(NS,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(DS,"href","/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(qS,"href","/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(OS,"href","/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(GS,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(zS,"href","/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(VS,"href","/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(XS,"href","/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(WS,"href","/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(QS,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(HS,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(US,"href","/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(JS,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(YS,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(KS,"href","/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(ZS,"href","/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c($e,"class","docstring"),c(Xo,"class","docstring"),c(j2,"id","transformers.AutoModelForNextSentencePrediction"),c(j2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j2,"href","#transformers.AutoModelForNextSentencePrediction"),c(Ii,"class","relative group"),c(Ir,"class","docstring"),c(eP,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(oP,"href","/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(rP,"href","/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(tP,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(aP,"href","/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(Ie,"class","docstring"),c(Wo,"class","docstring"),c(V2,"id","transformers.AutoModelForTokenClassification"),c(V2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(V2,"href","#transformers.AutoModelForTokenClassification"),c(Di,"class","relative group"),c(jr,"class","docstring"),c(nP,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(sP,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertForTokenClassification"),c(lP,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(iP,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(dP,"href","/docs/transformers/v4.16.2/en/model_doc/canine#transformers.CanineForTokenClassification"),c(cP,"href","/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(fP,"href","/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(mP,"href","/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(gP,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(hP,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(uP,"href","/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(pP,"href","/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(_P,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(vP,"href","/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(bP,"href","/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(TP,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(FP,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(CP,"href","/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(EP,"href","/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(MP,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(yP,"href","/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(wP,"href","/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(AP,"href","/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(LP,"href","/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(BP,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(kP,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(xP,"href","/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(RP,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(SP,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(PP,"href","/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c($P,"href","/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(je,"class","docstring"),c(Qo,"class","docstring"),c(Ev,"id","transformers.AutoModelForQuestionAnswering"),c(Ev,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ev,"href","#transformers.AutoModelForQuestionAnswering"),c(Gi,"class","relative group"),c(Nr,"class","docstring"),c(IP,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(jP,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(NP,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(DP,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(qP,"href","/docs/transformers/v4.16.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(OP,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(GP,"href","/docs/transformers/v4.16.2/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(zP,"href","/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(VP,"href","/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(XP,"href","/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(WP,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(QP,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(HP,"href","/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(UP,"href","/docs/transformers/v4.16.2/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(JP,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(YP,"href","/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(KP,"href","/docs/transformers/v4.16.2/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(ZP,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(e$,"href","/docs/transformers/v4.16.2/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(o$,"href","/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(r$,"href","/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(t$,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(a$,"href","/docs/transformers/v4.16.2/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(n$,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(s$,"href","/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(l$,"href","/docs/transformers/v4.16.2/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(i$,"href","/docs/transformers/v4.16.2/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(d$,"href","/docs/transformers/v4.16.2/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(c$,"href","/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(f$,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(m$,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(g$,"href","/docs/transformers/v4.16.2/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(h$,"href","/docs/transformers/v4.16.2/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(u$,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(p$,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(_$,"href","/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(v$,"href","/docs/transformers/v4.16.2/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(Ne,"class","docstring"),c(Ho,"class","docstring"),c(i1,"id","transformers.AutoModelForTableQuestionAnswering"),c(i1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(i1,"href","#transformers.AutoModelForTableQuestionAnswering"),c(Xi,"class","relative group"),c(Dr,"class","docstring"),c(b$,"href","/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(De,"class","docstring"),c(Uo,"class","docstring"),c(f1,"id","transformers.AutoModelForImageClassification"),c(f1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f1,"href","#transformers.AutoModelForImageClassification"),c(Hi,"class","relative group"),c(qr,"class","docstring"),c(T$,"href","/docs/transformers/v4.16.2/en/model_doc/beit#transformers.BeitForImageClassification"),c(F$,"href","/docs/transformers/v4.16.2/en/model_doc/deit#transformers.DeiTForImageClassification"),c(C$,"href","/docs/transformers/v4.16.2/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(E$,"href","/docs/transformers/v4.16.2/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(M$,"href","/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(y$,"href","/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(w$,"href","/docs/transformers/v4.16.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(A$,"href","/docs/transformers/v4.16.2/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(L$,"href","/docs/transformers/v4.16.2/en/model_doc/swin#transformers.SwinForImageClassification"),c(B$,"href","/docs/transformers/v4.16.2/en/model_doc/vit#transformers.ViTForImageClassification"),c(qe,"class","docstring"),c(Jo,"class","docstring"),c(v1,"id","transformers.AutoModelForVision2Seq"),c(v1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(v1,"href","#transformers.AutoModelForVision2Seq"),c(Yi,"class","relative group"),c(Or,"class","docstring"),c(k$,"href","/docs/transformers/v4.16.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(Oe,"class","docstring"),c(Yo,"class","docstring"),c(F1,"id","transformers.AutoModelForAudioClassification"),c(F1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F1,"href","#transformers.AutoModelForAudioClassification"),c(ed,"class","relative group"),c(Gr,"class","docstring"),c(x$,"href","/docs/transformers/v4.16.2/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(R$,"href","/docs/transformers/v4.16.2/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(S$,"href","/docs/transformers/v4.16.2/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(P$,"href","/docs/transformers/v4.16.2/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c($$,"href","/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(I$,"href","/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(j$,"href","/docs/transformers/v4.16.2/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(Ge,"class","docstring"),c(Ko,"class","docstring"),c(k1,"id","transformers.AutoModelForAudioFrameClassification"),c(k1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(k1,"href","#transformers.AutoModelForAudioFrameClassification"),c(td,"class","relative group"),c(zr,"class","docstring"),c(N$,"href","/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(D$,"href","/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(q$,"href","/docs/transformers/v4.16.2/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(ze,"class","docstring"),c(Zo,"class","docstring"),c($1,"id","transformers.AutoModelForCTC"),c($1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($1,"href","#transformers.AutoModelForCTC"),c(ld,"class","relative group"),c(Vr,"class","docstring"),c(O$,"href","/docs/transformers/v4.16.2/en/model_doc/hubert#transformers.HubertForCTC"),c(G$,"href","/docs/transformers/v4.16.2/en/model_doc/sew#transformers.SEWForCTC"),c(z$,"href","/docs/transformers/v4.16.2/en/model_doc/sew-d#transformers.SEWDForCTC"),c(V$,"href","/docs/transformers/v4.16.2/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(X$,"href","/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(W$,"href","/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(Q$,"href","/docs/transformers/v4.16.2/en/model_doc/wavlm#transformers.WavLMForCTC"),c(Ve,"class","docstring"),c(er,"class","docstring"),c(V1,"id","transformers.AutoModelForSpeechSeq2Seq"),c(V1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(V1,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(cd,"class","relative group"),c(Xr,"class","docstring"),c(H$,"href","/docs/transformers/v4.16.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(U$,"href","/docs/transformers/v4.16.2/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(Xe,"class","docstring"),c(or,"class","docstring"),c(H1,"id","transformers.AutoModelForAudioXVector"),c(H1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(H1,"href","#transformers.AutoModelForAudioXVector"),c(gd,"class","relative group"),c(Wr,"class","docstring"),c(J$,"href","/docs/transformers/v4.16.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(Y$,"href","/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(K$,"href","/docs/transformers/v4.16.2/en/model_doc/wavlm#transformers.WavLMForXVector"),c(We,"class","docstring"),c(rr,"class","docstring"),c(Z1,"id","transformers.AutoModelForObjectDetection"),c(Z1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z1,"href","#transformers.AutoModelForObjectDetection"),c(_d,"class","relative group"),c(Qr,"class","docstring"),c(Z$,"href","/docs/transformers/v4.16.2/en/model_doc/detr#transformers.DetrForObjectDetection"),c(Qe,"class","docstring"),c(tr,"class","docstring"),c(r4,"id","transformers.AutoModelForImageSegmentation"),c(r4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(r4,"href","#transformers.AutoModelForImageSegmentation"),c(Td,"class","relative group"),c(Hr,"class","docstring"),c(eI,"href","/docs/transformers/v4.16.2/en/model_doc/detr#transformers.DetrForSegmentation"),c(He,"class","docstring"),c(ar,"class","docstring"),c(n4,"id","transformers.TFAutoModel"),c(n4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n4,"href","#transformers.TFAutoModel"),c(Ed,"class","relative group"),c(Ur,"class","docstring"),c(oI,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.TFAlbertModel"),c(rI,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.TFBartModel"),c(tI,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertModel"),c(aI,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(nI,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(sI,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.TFCamembertModel"),c(lI,"href","/docs/transformers/v4.16.2/en/model_doc/clip#transformers.TFCLIPModel"),c(iI,"href","/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.TFConvBertModel"),c(dI,"href","/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.TFCTRLModel"),c(cI,"href","/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.TFDebertaModel"),c(fI,"href","/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(mI,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(gI,"href","/docs/transformers/v4.16.2/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(hI,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.TFElectraModel"),c(uI,"href","/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(pI,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.TFFunnelModel"),c(_I,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(vI,"href","/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.TFGPT2Model"),c(bI,"href","/docs/transformers/v4.16.2/en/model_doc/hubert#transformers.TFHubertModel"),c(TI,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(FI,"href","/docs/transformers/v4.16.2/en/model_doc/led#transformers.TFLEDModel"),c(CI,"href","/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.TFLongformerModel"),c(EI,"href","/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.TFLxmertModel"),c(MI,"href","/docs/transformers/v4.16.2/en/model_doc/marian#transformers.TFMarianModel"),c(yI,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.TFMBartModel"),c(wI,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(AI,"href","/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.TFMPNetModel"),c(LI,"href","/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.TFMT5Model"),c(BI,"href","/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(kI,"href","/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.TFPegasusModel"),c(xI,"href","/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.TFRemBertModel"),c(RI,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.TFRobertaModel"),c(SI,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.TFRoFormerModel"),c(PI,"href","/docs/transformers/v4.16.2/en/model_doc/t5#transformers.TFT5Model"),c($I,"href","/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TFTapasModel"),c(II,"href","/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(jI,"href","/docs/transformers/v4.16.2/en/model_doc/vit#transformers.TFViTModel"),c(NI,"href","/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(DI,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.TFXLMModel"),c(qI,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(OI,"href","/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.TFXLNetModel"),c(co,"class","docstring"),c(nr,"class","docstring"),c(X4,"id","transformers.TFAutoModelForPreTraining"),c(X4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(X4,"href","#transformers.TFAutoModelForPreTraining"),c(wd,"class","relative group"),c(Jr,"class","docstring"),c(GI,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(zI,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(VI,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertForPreTraining"),c(XI,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(WI,"href","/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(QI,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(HI,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(UI,"href","/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(JI,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(YI,"href","/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(KI,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(ZI,"href","/docs/transformers/v4.16.2/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(ej,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(oj,"href","/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(rj,"href","/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(tj,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(aj,"href","/docs/transformers/v4.16.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(nj,"href","/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(sj,"href","/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(lj,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(ij,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(dj,"href","/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(fo,"class","docstring"),c(sr,"class","docstring"),c(hb,"id","transformers.TFAutoModelForCausalLM"),c(hb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hb,"href","#transformers.TFAutoModelForCausalLM"),c(Bd,"class","relative group"),c(Yr,"class","docstring"),c(cj,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(fj,"href","/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(mj,"href","/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(gj,"href","/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(hj,"href","/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(uj,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(pj,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(_j,"href","/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(vj,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(bj,"href","/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(mo,"class","docstring"),c(lr,"class","docstring"),c(yb,"id","transformers.TFAutoModelForImageClassification"),c(yb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yb,"href","#transformers.TFAutoModelForImageClassification"),c(Rd,"class","relative group"),c(Kr,"class","docstring"),c(Tj,"href","/docs/transformers/v4.16.2/en/model_doc/vit#transformers.TFViTForImageClassification"),c(go,"class","docstring"),c(ir,"class","docstring"),c(Ab,"id","transformers.TFAutoModelForMaskedLM"),c(Ab,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ab,"href","#transformers.TFAutoModelForMaskedLM"),c($d,"class","relative group"),c(Zr,"class","docstring"),c(Fj,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(Cj,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(Ej,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(Mj,"href","/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(yj,"href","/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(wj,"href","/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(Aj,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(Lj,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(Bj,"href","/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(kj,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(xj,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(Rj,"href","/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(Sj,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(Pj,"href","/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c($j,"href","/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(Ij,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(jj,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(Nj,"href","/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(Dj,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(qj,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(ho,"class","docstring"),c(dr,"class","docstring"),c(Hb,"id","transformers.TFAutoModelForSeq2SeqLM"),c(Hb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Hb,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(Nd,"class","relative group"),c(et,"class","docstring"),c(Oj,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(Gj,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(zj,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(Vj,"href","/docs/transformers/v4.16.2/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(Xj,"href","/docs/transformers/v4.16.2/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(Wj,"href","/docs/transformers/v4.16.2/en/model_doc/marian#transformers.TFMarianMTModel"),c(Qj,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(Hj,"href","/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(Uj,"href","/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(Jj,"href","/docs/transformers/v4.16.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(uo,"class","docstring"),c(cr,"class","docstring"),c(nT,"id","transformers.TFAutoModelForSequenceClassification"),c(nT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(nT,"href","#transformers.TFAutoModelForSequenceClassification"),c(Od,"class","relative group"),c(ot,"class","docstring"),c(Yj,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(Kj,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(Zj,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(eN,"href","/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(oN,"href","/docs/transformers/v4.16.2/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(rN,"href","/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(tN,"href","/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(aN,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(nN,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(sN,"href","/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(lN,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(iN,"href","/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(dN,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(cN,"href","/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(fN,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(mN,"href","/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(gN,"href","/docs/transformers/v4.16.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(hN,"href","/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(uN,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(pN,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(_N,"href","/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(vN,"href","/docs/transformers/v4.16.2/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(bN,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(TN,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(FN,"href","/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(po,"class","docstring"),c(fr,"class","docstring"),c(xT,"id","transformers.TFAutoModelForMultipleChoice"),c(xT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xT,"href","#transformers.TFAutoModelForMultipleChoice"),c(Vd,"class","relative group"),c(rt,"class","docstring"),c(CN,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(EN,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(MN,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(yN,"href","/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(wN,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(AN,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(LN,"href","/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(BN,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(kN,"href","/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(xN,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(RN,"href","/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(SN,"href","/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(PN,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c($N,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(IN,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(jN,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(NN,"href","/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(_o,"class","docstring"),c(mr,"class","docstring"),c(UT,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(UT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(UT,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(Qd,"class","relative group"),c(tt,"class","docstring"),c(DN,"href","/docs/transformers/v4.16.2/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(vo,"class","docstring"),c(gr,"class","docstring"),c(YT,"id","transformers.TFAutoModelForTokenClassification"),c(YT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(YT,"href","#transformers.TFAutoModelForTokenClassification"),c(Jd,"class","relative group"),c(at,"class","docstring"),c(qN,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(ON,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(GN,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(zN,"href","/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(VN,"href","/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(XN,"href","/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(WN,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(QN,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(HN,"href","/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(UN,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(JN,"href","/docs/transformers/v4.16.2/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(YN,"href","/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(KN,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(ZN,"href","/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(eD,"href","/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(oD,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(rD,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(tD,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(aD,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(nD,"href","/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(bo,"class","docstring"),c(hr,"class","docstring"),c(v6,"id","transformers.TFAutoModelForQuestionAnswering"),c(v6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(v6,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Zd,"class","relative group"),c(nt,"class","docstring"),c(sD,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(lD,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(iD,"href","/docs/transformers/v4.16.2/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(dD,"href","/docs/transformers/v4.16.2/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(cD,"href","/docs/transformers/v4.16.2/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(fD,"href","/docs/transformers/v4.16.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(mD,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(gD,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(hD,"href","/docs/transformers/v4.16.2/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(uD,"href","/docs/transformers/v4.16.2/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(pD,"href","/docs/transformers/v4.16.2/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(_D,"href","/docs/transformers/v4.16.2/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(vD,"href","/docs/transformers/v4.16.2/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(bD,"href","/docs/transformers/v4.16.2/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(TD,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(FD,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(CD,"href","/docs/transformers/v4.16.2/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(ED,"href","/docs/transformers/v4.16.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(MD,"href","/docs/transformers/v4.16.2/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(To,"class","docstring"),c(ur,"class","docstring"),c(N6,"id","transformers.TFAutoModelForVision2Seq"),c(N6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N6,"href","#transformers.TFAutoModelForVision2Seq"),c(rc,"class","relative group"),c(st,"class","docstring"),c(yD,"href","/docs/transformers/v4.16.2/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Fo,"class","docstring"),c(pr,"class","docstring"),c(q6,"id","transformers.FlaxAutoModel"),c(q6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q6,"href","#transformers.FlaxAutoModel"),c(nc,"class","relative group"),c(lt,"class","docstring"),c(wD,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.FlaxAlbertModel"),c(AD,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.FlaxBartModel"),c(LD,"href","/docs/transformers/v4.16.2/en/model_doc/beit#transformers.FlaxBeitModel"),c(BD,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.FlaxBertModel"),c(kD,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(xD,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(RD,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(SD,"href","/docs/transformers/v4.16.2/en/model_doc/clip#transformers.FlaxCLIPModel"),c(PD,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c($D,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.FlaxElectraModel"),c(ID,"href","/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(jD,"href","/docs/transformers/v4.16.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(ND,"href","/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(DD,"href","/docs/transformers/v4.16.2/en/model_doc/marian#transformers.FlaxMarianModel"),c(qD,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.FlaxMBartModel"),c(OD,"href","/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.FlaxMT5Model"),c(GD,"href","/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(zD,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(VD,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(XD,"href","/docs/transformers/v4.16.2/en/model_doc/t5#transformers.FlaxT5Model"),c(WD,"href","/docs/transformers/v4.16.2/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(QD,"href","/docs/transformers/v4.16.2/en/model_doc/vit#transformers.FlaxViTModel"),c(HD,"href","/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(Co,"class","docstring"),c(_r,"class","docstring"),c(cF,"id","transformers.FlaxAutoModelForCausalLM"),c(cF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cF,"href","#transformers.FlaxAutoModelForCausalLM"),c(ic,"class","relative group"),c(it,"class","docstring"),c(UD,"href","/docs/transformers/v4.16.2/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(JD,"href","/docs/transformers/v4.16.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(YD,"href","/docs/transformers/v4.16.2/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(Eo,"class","docstring"),c(vr,"class","docstring"),c(hF,"id","transformers.FlaxAutoModelForPreTraining"),c(hF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hF,"href","#transformers.FlaxAutoModelForPreTraining"),c(mc,"class","relative group"),c(dt,"class","docstring"),c(KD,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(ZD,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(eq,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(oq,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(rq,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(tq,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(aq,"href","/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(nq,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(sq,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(lq,"href","/docs/transformers/v4.16.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(iq,"href","/docs/transformers/v4.16.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(Mo,"class","docstring"),c(br,"class","docstring"),c(wF,"id","transformers.FlaxAutoModelForMaskedLM"),c(wF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(wF,"href","#transformers.FlaxAutoModelForMaskedLM"),c(uc,"class","relative group"),c(ct,"class","docstring"),c(dq,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(cq,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(fq,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(mq,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(gq,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(hq,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(uq,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(pq,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(_q,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(yo,"class","docstring"),c(Tr,"class","docstring"),c(IF,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(IF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(IF,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(vc,"class","relative group"),c(ft,"class","docstring"),c(vq,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(bq,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(Tq,"href","/docs/transformers/v4.16.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(Fq,"href","/docs/transformers/v4.16.2/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(Cq,"href","/docs/transformers/v4.16.2/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(Eq,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Mq,"href","/docs/transformers/v4.16.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(yq,"href","/docs/transformers/v4.16.2/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(wq,"href","/docs/transformers/v4.16.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(wo,"class","docstring"),c(Fr,"class","docstring"),c(WF,"id","transformers.FlaxAutoModelForSequenceClassification"),c(WF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(WF,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Fc,"class","relative group"),c(mt,"class","docstring"),c(Aq,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(Lq,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(Bq,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(kq,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(xq,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(Rq,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(Sq,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(Pq,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c($q,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(Ao,"class","docstring"),c(Cr,"class","docstring"),c(rC,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(rC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(rC,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(Mc,"class","relative group"),c(gt,"class","docstring"),c(Iq,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(jq,"href","/docs/transformers/v4.16.2/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(Nq,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(Dq,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(qq,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(Oq,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(Gq,"href","/docs/transformers/v4.16.2/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(zq,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(Vq,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(Lo,"class","docstring"),c(Er,"class","docstring"),c(mC,"id","transformers.FlaxAutoModelForTokenClassification"),c(mC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mC,"href","#transformers.FlaxAutoModelForTokenClassification"),c(Ac,"class","relative group"),c(ht,"class","docstring"),c(Xq,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(Wq,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(Qq,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(Hq,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(Uq,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(Jq,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Yq,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Bo,"class","docstring"),c(Mr,"class","docstring"),c(TC,"id","transformers.FlaxAutoModelForMultipleChoice"),c(TC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(TC,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(kc,"class","relative group"),c(ut,"class","docstring"),c(Kq,"href","/docs/transformers/v4.16.2/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(Zq,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(eO,"href","/docs/transformers/v4.16.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(oO,"href","/docs/transformers/v4.16.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(rO,"href","/docs/transformers/v4.16.2/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(tO,"href","/docs/transformers/v4.16.2/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(aO,"href","/docs/transformers/v4.16.2/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(ko,"class","docstring"),c(yr,"class","docstring"),c(LC,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(LC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(LC,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(Sc,"class","relative group"),c(pt,"class","docstring"),c(nO,"href","/docs/transformers/v4.16.2/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(xo,"class","docstring"),c(wr,"class","docstring"),c(kC,"id","transformers.FlaxAutoModelForImageClassification"),c(kC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kC,"href","#transformers.FlaxAutoModelForImageClassification"),c(Ic,"class","relative group"),c(_t,"class","docstring"),c(sO,"href","/docs/transformers/v4.16.2/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(lO,"href","/docs/transformers/v4.16.2/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Ro,"class","docstring"),c(Ar,"class","docstring"),c(SC,"id","transformers.FlaxAutoModelForVision2Seq"),c(SC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(SC,"href","#transformers.FlaxAutoModelForVision2Seq"),c(Dc,"class","relative group"),c(vt,"class","docstring"),c(iO,"href","/docs/transformers/v4.16.2/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(So,"class","docstring"),c(Lr,"class","docstring")},m(d,_){e(document.head,J),v(d,we,_),v(d,se,_),e(se,me),e(me,Ze),g(de,Ze,null),e(se,_e),e(se,$o),e($o,oi),v(d,zc,_),v(d,Ut,_),e(Ut,ri),e(Ut,ti),e(ti,kE),e(Ut,Vc),v(d,Me,_),v(d,no,_),e(no,ai),e(no,vn),e(vn,xE),e(no,bn),e(no,Tn),e(Tn,RE),e(no,ni),e(no,Fn),e(Fn,SE),e(no,si),v(d,Xc,_),g(Ea,d,_),v(d,so,_),v(d,ge,_),e(ge,z0),e(ge,li),e(li,V0),e(ge,X0),v(d,Io,_),v(d,Ma,_),e(Ma,W0),e(Ma,Wc),e(Wc,Q0),e(Ma,U7e),v(d,owe,_),v(d,ii,_),e(ii,Qc),e(Qc,UG),g(PE,UG,null),e(ii,J7e),e(ii,JG),e(JG,Y7e),v(d,rwe,_),v(d,Cn,_),e(Cn,K7e),e(Cn,YG),e(YG,Z7e),e(Cn,eLe),e(Cn,KG),e(KG,oLe),e(Cn,rLe),v(d,twe,_),g($E,d,_),v(d,awe,_),v(d,H0,_),e(H0,tLe),v(d,nwe,_),g(Hc,d,_),v(d,swe,_),v(d,di,_),e(di,Uc),e(Uc,ZG),g(IE,ZG,null),e(di,aLe),e(di,ez),e(ez,nLe),v(d,lwe,_),v(d,jo,_),g(jE,jo,null),e(jo,sLe),e(jo,NE),e(NE,lLe),e(NE,U0),e(U0,iLe),e(NE,dLe),e(jo,cLe),e(jo,DE),e(DE,fLe),e(DE,oz),e(oz,mLe),e(DE,gLe),e(jo,hLe),e(jo,lo),g(qE,lo,null),e(lo,uLe),e(lo,rz),e(rz,pLe),e(lo,_Le),e(lo,ci),e(ci,vLe),e(ci,tz),e(tz,bLe),e(ci,TLe),e(ci,az),e(az,FLe),e(ci,CLe),e(lo,ELe),e(lo,b),e(b,Jc),e(Jc,nz),e(nz,MLe),e(Jc,yLe),e(Jc,J0),e(J0,wLe),e(Jc,ALe),e(b,LLe),e(b,Yc),e(Yc,sz),e(sz,BLe),e(Yc,kLe),e(Yc,Y0),e(Y0,xLe),e(Yc,RLe),e(b,SLe),e(b,Kc),e(Kc,lz),e(lz,PLe),e(Kc,$Le),e(Kc,K0),e(K0,ILe),e(Kc,jLe),e(b,NLe),e(b,Zc),e(Zc,iz),e(iz,DLe),e(Zc,qLe),e(Zc,Z0),e(Z0,OLe),e(Zc,GLe),e(b,zLe),e(b,ef),e(ef,dz),e(dz,VLe),e(ef,XLe),e(ef,e7),e(e7,WLe),e(ef,QLe),e(b,HLe),e(b,of),e(of,cz),e(cz,ULe),e(of,JLe),e(of,o7),e(o7,YLe),e(of,KLe),e(b,ZLe),e(b,rf),e(rf,fz),e(fz,e8e),e(rf,o8e),e(rf,r7),e(r7,r8e),e(rf,t8e),e(b,a8e),e(b,tf),e(tf,mz),e(mz,n8e),e(tf,s8e),e(tf,t7),e(t7,l8e),e(tf,i8e),e(b,d8e),e(b,af),e(af,gz),e(gz,c8e),e(af,f8e),e(af,a7),e(a7,m8e),e(af,g8e),e(b,h8e),e(b,nf),e(nf,hz),e(hz,u8e),e(nf,p8e),e(nf,n7),e(n7,_8e),e(nf,v8e),e(b,b8e),e(b,sf),e(sf,uz),e(uz,T8e),e(sf,F8e),e(sf,s7),e(s7,C8e),e(sf,E8e),e(b,M8e),e(b,lf),e(lf,pz),e(pz,y8e),e(lf,w8e),e(lf,l7),e(l7,A8e),e(lf,L8e),e(b,B8e),e(b,df),e(df,_z),e(_z,k8e),e(df,x8e),e(df,i7),e(i7,R8e),e(df,S8e),e(b,P8e),e(b,cf),e(cf,vz),e(vz,$8e),e(cf,I8e),e(cf,d7),e(d7,j8e),e(cf,N8e),e(b,D8e),e(b,ff),e(ff,bz),e(bz,q8e),e(ff,O8e),e(ff,c7),e(c7,G8e),e(ff,z8e),e(b,V8e),e(b,mf),e(mf,Tz),e(Tz,X8e),e(mf,W8e),e(mf,f7),e(f7,Q8e),e(mf,H8e),e(b,U8e),e(b,gf),e(gf,Fz),e(Fz,J8e),e(gf,Y8e),e(gf,m7),e(m7,K8e),e(gf,Z8e),e(b,eBe),e(b,hf),e(hf,Cz),e(Cz,oBe),e(hf,rBe),e(hf,g7),e(g7,tBe),e(hf,aBe),e(b,nBe),e(b,uf),e(uf,Ez),e(Ez,sBe),e(uf,lBe),e(uf,h7),e(h7,iBe),e(uf,dBe),e(b,cBe),e(b,pf),e(pf,Mz),e(Mz,fBe),e(pf,mBe),e(pf,u7),e(u7,gBe),e(pf,hBe),e(b,uBe),e(b,_f),e(_f,yz),e(yz,pBe),e(_f,_Be),e(_f,p7),e(p7,vBe),e(_f,bBe),e(b,TBe),e(b,vf),e(vf,wz),e(wz,FBe),e(vf,CBe),e(vf,_7),e(_7,EBe),e(vf,MBe),e(b,yBe),e(b,bf),e(bf,Az),e(Az,wBe),e(bf,ABe),e(bf,v7),e(v7,LBe),e(bf,BBe),e(b,kBe),e(b,Tf),e(Tf,Lz),e(Lz,xBe),e(Tf,RBe),e(Tf,b7),e(b7,SBe),e(Tf,PBe),e(b,$Be),e(b,Ff),e(Ff,Bz),e(Bz,IBe),e(Ff,jBe),e(Ff,T7),e(T7,NBe),e(Ff,DBe),e(b,qBe),e(b,Cf),e(Cf,kz),e(kz,OBe),e(Cf,GBe),e(Cf,F7),e(F7,zBe),e(Cf,VBe),e(b,XBe),e(b,Ef),e(Ef,xz),e(xz,WBe),e(Ef,QBe),e(Ef,C7),e(C7,HBe),e(Ef,UBe),e(b,JBe),e(b,Mf),e(Mf,Rz),e(Rz,YBe),e(Mf,KBe),e(Mf,E7),e(E7,ZBe),e(Mf,e9e),e(b,o9e),e(b,yf),e(yf,Sz),e(Sz,r9e),e(yf,t9e),e(yf,M7),e(M7,a9e),e(yf,n9e),e(b,s9e),e(b,wf),e(wf,Pz),e(Pz,l9e),e(wf,i9e),e(wf,y7),e(y7,d9e),e(wf,c9e),e(b,f9e),e(b,Af),e(Af,$z),e($z,m9e),e(Af,g9e),e(Af,w7),e(w7,h9e),e(Af,u9e),e(b,p9e),e(b,Lf),e(Lf,Iz),e(Iz,_9e),e(Lf,v9e),e(Lf,A7),e(A7,b9e),e(Lf,T9e),e(b,F9e),e(b,Bf),e(Bf,jz),e(jz,C9e),e(Bf,E9e),e(Bf,L7),e(L7,M9e),e(Bf,y9e),e(b,w9e),e(b,kf),e(kf,Nz),e(Nz,A9e),e(kf,L9e),e(kf,B7),e(B7,B9e),e(kf,k9e),e(b,x9e),e(b,xf),e(xf,Dz),e(Dz,R9e),e(xf,S9e),e(xf,k7),e(k7,P9e),e(xf,$9e),e(b,I9e),e(b,Rf),e(Rf,qz),e(qz,j9e),e(Rf,N9e),e(Rf,x7),e(x7,D9e),e(Rf,q9e),e(b,O9e),e(b,Sf),e(Sf,Oz),e(Oz,G9e),e(Sf,z9e),e(Sf,R7),e(R7,V9e),e(Sf,X9e),e(b,W9e),e(b,Pf),e(Pf,Gz),e(Gz,Q9e),e(Pf,H9e),e(Pf,S7),e(S7,U9e),e(Pf,J9e),e(b,Y9e),e(b,$f),e($f,zz),e(zz,K9e),e($f,Z9e),e($f,P7),e(P7,eke),e($f,oke),e(b,rke),e(b,If),e(If,Vz),e(Vz,tke),e(If,ake),e(If,$7),e($7,nke),e(If,ske),e(b,lke),e(b,jf),e(jf,Xz),e(Xz,ike),e(jf,dke),e(jf,I7),e(I7,cke),e(jf,fke),e(b,mke),e(b,Nf),e(Nf,Wz),e(Wz,gke),e(Nf,hke),e(Nf,j7),e(j7,uke),e(Nf,pke),e(b,_ke),e(b,Df),e(Df,Qz),e(Qz,vke),e(Df,bke),e(Df,N7),e(N7,Tke),e(Df,Fke),e(b,Cke),e(b,qf),e(qf,Hz),e(Hz,Eke),e(qf,Mke),e(qf,D7),e(D7,yke),e(qf,wke),e(b,Ake),e(b,Of),e(Of,Uz),e(Uz,Lke),e(Of,Bke),e(Of,q7),e(q7,kke),e(Of,xke),e(b,Rke),e(b,Gf),e(Gf,Jz),e(Jz,Ske),e(Gf,Pke),e(Gf,O7),e(O7,$ke),e(Gf,Ike),e(b,jke),e(b,zf),e(zf,Yz),e(Yz,Nke),e(zf,Dke),e(zf,G7),e(G7,qke),e(zf,Oke),e(b,Gke),e(b,Vf),e(Vf,Kz),e(Kz,zke),e(Vf,Vke),e(Vf,z7),e(z7,Xke),e(Vf,Wke),e(b,Qke),e(b,Xf),e(Xf,Zz),e(Zz,Hke),e(Xf,Uke),e(Xf,V7),e(V7,Jke),e(Xf,Yke),e(b,Kke),e(b,Wf),e(Wf,eV),e(eV,Zke),e(Wf,exe),e(Wf,X7),e(X7,oxe),e(Wf,rxe),e(b,txe),e(b,Qf),e(Qf,oV),e(oV,axe),e(Qf,nxe),e(Qf,W7),e(W7,sxe),e(Qf,lxe),e(b,ixe),e(b,Hf),e(Hf,rV),e(rV,dxe),e(Hf,cxe),e(Hf,Q7),e(Q7,fxe),e(Hf,mxe),e(b,gxe),e(b,Uf),e(Uf,tV),e(tV,hxe),e(Uf,uxe),e(Uf,H7),e(H7,pxe),e(Uf,_xe),e(b,vxe),e(b,Jf),e(Jf,aV),e(aV,bxe),e(Jf,Txe),e(Jf,U7),e(U7,Fxe),e(Jf,Cxe),e(b,Exe),e(b,Yf),e(Yf,nV),e(nV,Mxe),e(Yf,yxe),e(Yf,J7),e(J7,wxe),e(Yf,Axe),e(b,Lxe),e(b,Kf),e(Kf,sV),e(sV,Bxe),e(Kf,kxe),e(Kf,Y7),e(Y7,xxe),e(Kf,Rxe),e(b,Sxe),e(b,Zf),e(Zf,lV),e(lV,Pxe),e(Zf,$xe),e(Zf,K7),e(K7,Ixe),e(Zf,jxe),e(b,Nxe),e(b,em),e(em,iV),e(iV,Dxe),e(em,qxe),e(em,Z7),e(Z7,Oxe),e(em,Gxe),e(b,zxe),e(b,om),e(om,dV),e(dV,Vxe),e(om,Xxe),e(om,eL),e(eL,Wxe),e(om,Qxe),e(b,Hxe),e(b,rm),e(rm,cV),e(cV,Uxe),e(rm,Jxe),e(rm,oL),e(oL,Yxe),e(rm,Kxe),e(b,Zxe),e(b,tm),e(tm,fV),e(fV,eRe),e(tm,oRe),e(tm,rL),e(rL,rRe),e(tm,tRe),e(b,aRe),e(b,am),e(am,mV),e(mV,nRe),e(am,sRe),e(am,tL),e(tL,lRe),e(am,iRe),e(b,dRe),e(b,nm),e(nm,gV),e(gV,cRe),e(nm,fRe),e(nm,aL),e(aL,mRe),e(nm,gRe),e(b,hRe),e(b,sm),e(sm,hV),e(hV,uRe),e(sm,pRe),e(sm,nL),e(nL,_Re),e(sm,vRe),e(b,bRe),e(b,lm),e(lm,uV),e(uV,TRe),e(lm,FRe),e(lm,sL),e(sL,CRe),e(lm,ERe),e(b,MRe),e(b,im),e(im,pV),e(pV,yRe),e(im,wRe),e(im,lL),e(lL,ARe),e(im,LRe),e(b,BRe),e(b,dm),e(dm,_V),e(_V,kRe),e(dm,xRe),e(dm,iL),e(iL,RRe),e(dm,SRe),e(b,PRe),e(b,cm),e(cm,vV),e(vV,$Re),e(cm,IRe),e(cm,dL),e(dL,jRe),e(cm,NRe),e(b,DRe),e(b,fm),e(fm,bV),e(bV,qRe),e(fm,ORe),e(fm,cL),e(cL,GRe),e(fm,zRe),e(b,VRe),e(b,mm),e(mm,TV),e(TV,XRe),e(mm,WRe),e(mm,fL),e(fL,QRe),e(mm,HRe),e(b,URe),e(b,gm),e(gm,FV),e(FV,JRe),e(gm,YRe),e(gm,mL),e(mL,KRe),e(gm,ZRe),e(b,eSe),e(b,hm),e(hm,CV),e(CV,oSe),e(hm,rSe),e(hm,gL),e(gL,tSe),e(hm,aSe),e(b,nSe),e(b,um),e(um,EV),e(EV,sSe),e(um,lSe),e(um,hL),e(hL,iSe),e(um,dSe),e(b,cSe),e(b,pm),e(pm,MV),e(MV,fSe),e(pm,mSe),e(pm,uL),e(uL,gSe),e(pm,hSe),e(b,uSe),e(b,_m),e(_m,yV),e(yV,pSe),e(_m,_Se),e(_m,pL),e(pL,vSe),e(_m,bSe),e(b,TSe),e(b,vm),e(vm,wV),e(wV,FSe),e(vm,CSe),e(vm,_L),e(_L,ESe),e(vm,MSe),e(b,ySe),e(b,bm),e(bm,AV),e(AV,wSe),e(bm,ASe),e(bm,vL),e(vL,LSe),e(bm,BSe),e(b,kSe),e(b,Tm),e(Tm,LV),e(LV,xSe),e(Tm,RSe),e(Tm,bL),e(bL,SSe),e(Tm,PSe),e(b,$Se),e(b,Fm),e(Fm,BV),e(BV,ISe),e(Fm,jSe),e(Fm,TL),e(TL,NSe),e(Fm,DSe),e(b,qSe),e(b,Cm),e(Cm,kV),e(kV,OSe),e(Cm,GSe),e(Cm,FL),e(FL,zSe),e(Cm,VSe),e(b,XSe),e(b,Em),e(Em,xV),e(xV,WSe),e(Em,QSe),e(Em,CL),e(CL,HSe),e(Em,USe),e(b,JSe),e(b,Mm),e(Mm,RV),e(RV,YSe),e(Mm,KSe),e(Mm,EL),e(EL,ZSe),e(Mm,ePe),e(b,oPe),e(b,ym),e(ym,SV),e(SV,rPe),e(ym,tPe),e(ym,ML),e(ML,aPe),e(ym,nPe),e(b,sPe),e(b,wm),e(wm,PV),e(PV,lPe),e(wm,iPe),e(wm,yL),e(yL,dPe),e(wm,cPe),e(b,fPe),e(b,Am),e(Am,$V),e($V,mPe),e(Am,gPe),e(Am,wL),e(wL,hPe),e(Am,uPe),e(b,pPe),e(b,Lm),e(Lm,IV),e(IV,_Pe),e(Lm,vPe),e(Lm,AL),e(AL,bPe),e(Lm,TPe),e(lo,FPe),e(lo,jV),e(jV,CPe),e(lo,EPe),g(OE,lo,null),e(jo,MPe),e(jo,Bm),g(GE,Bm,null),e(Bm,yPe),e(Bm,NV),e(NV,wPe),v(d,iwe,_),v(d,fi,_),e(fi,km),e(km,DV),g(zE,DV,null),e(fi,APe),e(fi,qV),e(qV,LPe),v(d,dwe,_),v(d,No,_),g(VE,No,null),e(No,BPe),e(No,XE),e(XE,kPe),e(XE,LL),e(LL,xPe),e(XE,RPe),e(No,SPe),e(No,WE),e(WE,PPe),e(WE,OV),e(OV,$Pe),e(WE,IPe),e(No,jPe),e(No,io),g(QE,io,null),e(io,NPe),e(io,GV),e(GV,DPe),e(io,qPe),e(io,ya),e(ya,OPe),e(ya,zV),e(zV,GPe),e(ya,zPe),e(ya,VV),e(VV,VPe),e(ya,XPe),e(ya,XV),e(XV,WPe),e(ya,QPe),e(io,HPe),e(io,E),e(E,En),e(En,WV),e(WV,UPe),e(En,JPe),e(En,BL),e(BL,YPe),e(En,KPe),e(En,kL),e(kL,ZPe),e(En,e$e),e(E,o$e),e(E,Mn),e(Mn,QV),e(QV,r$e),e(Mn,t$e),e(Mn,xL),e(xL,a$e),e(Mn,n$e),e(Mn,RL),e(RL,s$e),e(Mn,l$e),e(E,i$e),e(E,yn),e(yn,HV),e(HV,d$e),e(yn,c$e),e(yn,SL),e(SL,f$e),e(yn,m$e),e(yn,PL),e(PL,g$e),e(yn,h$e),e(E,u$e),e(E,xm),e(xm,UV),e(UV,p$e),e(xm,_$e),e(xm,$L),e($L,v$e),e(xm,b$e),e(E,T$e),e(E,wn),e(wn,JV),e(JV,F$e),e(wn,C$e),e(wn,IL),e(IL,E$e),e(wn,M$e),e(wn,jL),e(jL,y$e),e(wn,w$e),e(E,A$e),e(E,Rm),e(Rm,YV),e(YV,L$e),e(Rm,B$e),e(Rm,NL),e(NL,k$e),e(Rm,x$e),e(E,R$e),e(E,Sm),e(Sm,KV),e(KV,S$e),e(Sm,P$e),e(Sm,DL),e(DL,$$e),e(Sm,I$e),e(E,j$e),e(E,Pm),e(Pm,ZV),e(ZV,N$e),e(Pm,D$e),e(Pm,qL),e(qL,q$e),e(Pm,O$e),e(E,G$e),e(E,An),e(An,eX),e(eX,z$e),e(An,V$e),e(An,OL),e(OL,X$e),e(An,W$e),e(An,GL),e(GL,Q$e),e(An,H$e),e(E,U$e),e(E,Ln),e(Ln,oX),e(oX,J$e),e(Ln,Y$e),e(Ln,zL),e(zL,K$e),e(Ln,Z$e),e(Ln,VL),e(VL,eIe),e(Ln,oIe),e(E,rIe),e(E,Bn),e(Bn,rX),e(rX,tIe),e(Bn,aIe),e(Bn,XL),e(XL,nIe),e(Bn,sIe),e(Bn,WL),e(WL,lIe),e(Bn,iIe),e(E,dIe),e(E,$m),e($m,tX),e(tX,cIe),e($m,fIe),e($m,QL),e(QL,mIe),e($m,gIe),e(E,hIe),e(E,Im),e(Im,aX),e(aX,uIe),e(Im,pIe),e(Im,HL),e(HL,_Ie),e(Im,vIe),e(E,bIe),e(E,kn),e(kn,nX),e(nX,TIe),e(kn,FIe),e(kn,UL),e(UL,CIe),e(kn,EIe),e(kn,JL),e(JL,MIe),e(kn,yIe),e(E,wIe),e(E,jm),e(jm,sX),e(sX,AIe),e(jm,LIe),e(jm,YL),e(YL,BIe),e(jm,kIe),e(E,xIe),e(E,xn),e(xn,lX),e(lX,RIe),e(xn,SIe),e(xn,KL),e(KL,PIe),e(xn,$Ie),e(xn,ZL),e(ZL,IIe),e(xn,jIe),e(E,NIe),e(E,Rn),e(Rn,iX),e(iX,DIe),e(Rn,qIe),e(Rn,e8),e(e8,OIe),e(Rn,GIe),e(Rn,o8),e(o8,zIe),e(Rn,VIe),e(E,XIe),e(E,Sn),e(Sn,dX),e(dX,WIe),e(Sn,QIe),e(Sn,r8),e(r8,HIe),e(Sn,UIe),e(Sn,cX),e(cX,JIe),e(Sn,YIe),e(E,KIe),e(E,Nm),e(Nm,fX),e(fX,ZIe),e(Nm,eje),e(Nm,t8),e(t8,oje),e(Nm,rje),e(E,tje),e(E,Pn),e(Pn,mX),e(mX,aje),e(Pn,nje),e(Pn,a8),e(a8,sje),e(Pn,lje),e(Pn,n8),e(n8,ije),e(Pn,dje),e(E,cje),e(E,Dm),e(Dm,gX),e(gX,fje),e(Dm,mje),e(Dm,s8),e(s8,gje),e(Dm,hje),e(E,uje),e(E,$n),e($n,hX),e(hX,pje),e($n,_je),e($n,l8),e(l8,vje),e($n,bje),e($n,i8),e(i8,Tje),e($n,Fje),e(E,Cje),e(E,In),e(In,uX),e(uX,Eje),e(In,Mje),e(In,d8),e(d8,yje),e(In,wje),e(In,c8),e(c8,Aje),e(In,Lje),e(E,Bje),e(E,jn),e(jn,pX),e(pX,kje),e(jn,xje),e(jn,f8),e(f8,Rje),e(jn,Sje),e(jn,m8),e(m8,Pje),e(jn,$je),e(E,Ije),e(E,qm),e(qm,_X),e(_X,jje),e(qm,Nje),e(qm,g8),e(g8,Dje),e(qm,qje),e(E,Oje),e(E,Nn),e(Nn,vX),e(vX,Gje),e(Nn,zje),e(Nn,h8),e(h8,Vje),e(Nn,Xje),e(Nn,u8),e(u8,Wje),e(Nn,Qje),e(E,Hje),e(E,Om),e(Om,bX),e(bX,Uje),e(Om,Jje),e(Om,p8),e(p8,Yje),e(Om,Kje),e(E,Zje),e(E,Dn),e(Dn,TX),e(TX,eNe),e(Dn,oNe),e(Dn,_8),e(_8,rNe),e(Dn,tNe),e(Dn,v8),e(v8,aNe),e(Dn,nNe),e(E,sNe),e(E,qn),e(qn,FX),e(FX,lNe),e(qn,iNe),e(qn,b8),e(b8,dNe),e(qn,cNe),e(qn,T8),e(T8,fNe),e(qn,mNe),e(E,gNe),e(E,On),e(On,CX),e(CX,hNe),e(On,uNe),e(On,F8),e(F8,pNe),e(On,_Ne),e(On,C8),e(C8,vNe),e(On,bNe),e(E,TNe),e(E,Gn),e(Gn,EX),e(EX,FNe),e(Gn,CNe),e(Gn,E8),e(E8,ENe),e(Gn,MNe),e(Gn,M8),e(M8,yNe),e(Gn,wNe),e(E,ANe),e(E,Gm),e(Gm,MX),e(MX,LNe),e(Gm,BNe),e(Gm,y8),e(y8,kNe),e(Gm,xNe),e(E,RNe),e(E,zn),e(zn,yX),e(yX,SNe),e(zn,PNe),e(zn,w8),e(w8,$Ne),e(zn,INe),e(zn,A8),e(A8,jNe),e(zn,NNe),e(E,DNe),e(E,Vn),e(Vn,wX),e(wX,qNe),e(Vn,ONe),e(Vn,L8),e(L8,GNe),e(Vn,zNe),e(Vn,B8),e(B8,VNe),e(Vn,XNe),e(E,WNe),e(E,Xn),e(Xn,AX),e(AX,QNe),e(Xn,HNe),e(Xn,k8),e(k8,UNe),e(Xn,JNe),e(Xn,x8),e(x8,YNe),e(Xn,KNe),e(E,ZNe),e(E,Wn),e(Wn,LX),e(LX,eDe),e(Wn,oDe),e(Wn,R8),e(R8,rDe),e(Wn,tDe),e(Wn,S8),e(S8,aDe),e(Wn,nDe),e(E,sDe),e(E,Qn),e(Qn,BX),e(BX,lDe),e(Qn,iDe),e(Qn,P8),e(P8,dDe),e(Qn,cDe),e(Qn,$8),e($8,fDe),e(Qn,mDe),e(E,gDe),e(E,Hn),e(Hn,kX),e(kX,hDe),e(Hn,uDe),e(Hn,I8),e(I8,pDe),e(Hn,_De),e(Hn,j8),e(j8,vDe),e(Hn,bDe),e(E,TDe),e(E,zm),e(zm,xX),e(xX,FDe),e(zm,CDe),e(zm,N8),e(N8,EDe),e(zm,MDe),e(E,yDe),e(E,Un),e(Un,RX),e(RX,wDe),e(Un,ADe),e(Un,D8),e(D8,LDe),e(Un,BDe),e(Un,q8),e(q8,kDe),e(Un,xDe),e(E,RDe),e(E,Vm),e(Vm,SX),e(SX,SDe),e(Vm,PDe),e(Vm,O8),e(O8,$De),e(Vm,IDe),e(E,jDe),e(E,Xm),e(Xm,PX),e(PX,NDe),e(Xm,DDe),e(Xm,G8),e(G8,qDe),e(Xm,ODe),e(E,GDe),e(E,Jn),e(Jn,$X),e($X,zDe),e(Jn,VDe),e(Jn,z8),e(z8,XDe),e(Jn,WDe),e(Jn,V8),e(V8,QDe),e(Jn,HDe),e(E,UDe),e(E,Yn),e(Yn,IX),e(IX,JDe),e(Yn,YDe),e(Yn,X8),e(X8,KDe),e(Yn,ZDe),e(Yn,W8),e(W8,eqe),e(Yn,oqe),e(E,rqe),e(E,Wm),e(Wm,jX),e(jX,tqe),e(Wm,aqe),e(Wm,Q8),e(Q8,nqe),e(Wm,sqe),e(E,lqe),e(E,Kn),e(Kn,NX),e(NX,iqe),e(Kn,dqe),e(Kn,H8),e(H8,cqe),e(Kn,fqe),e(Kn,U8),e(U8,mqe),e(Kn,gqe),e(E,hqe),e(E,Zn),e(Zn,DX),e(DX,uqe),e(Zn,pqe),e(Zn,J8),e(J8,_qe),e(Zn,vqe),e(Zn,Y8),e(Y8,bqe),e(Zn,Tqe),e(E,Fqe),e(E,es),e(es,qX),e(qX,Cqe),e(es,Eqe),e(es,K8),e(K8,Mqe),e(es,yqe),e(es,Z8),e(Z8,wqe),e(es,Aqe),e(E,Lqe),e(E,os),e(os,OX),e(OX,Bqe),e(os,kqe),e(os,eB),e(eB,xqe),e(os,Rqe),e(os,oB),e(oB,Sqe),e(os,Pqe),e(E,$qe),e(E,rs),e(rs,GX),e(GX,Iqe),e(rs,jqe),e(rs,rB),e(rB,Nqe),e(rs,Dqe),e(rs,tB),e(tB,qqe),e(rs,Oqe),e(E,Gqe),e(E,Qm),e(Qm,zX),e(zX,zqe),e(Qm,Vqe),e(Qm,aB),e(aB,Xqe),e(Qm,Wqe),e(E,Qqe),e(E,Hm),e(Hm,VX),e(VX,Hqe),e(Hm,Uqe),e(Hm,nB),e(nB,Jqe),e(Hm,Yqe),e(E,Kqe),e(E,Um),e(Um,XX),e(XX,Zqe),e(Um,eOe),e(Um,sB),e(sB,oOe),e(Um,rOe),e(E,tOe),e(E,ts),e(ts,WX),e(WX,aOe),e(ts,nOe),e(ts,lB),e(lB,sOe),e(ts,lOe),e(ts,iB),e(iB,iOe),e(ts,dOe),e(E,cOe),e(E,Jm),e(Jm,QX),e(QX,fOe),e(Jm,mOe),e(Jm,dB),e(dB,gOe),e(Jm,hOe),e(E,uOe),e(E,as),e(as,HX),e(HX,pOe),e(as,_Oe),e(as,cB),e(cB,vOe),e(as,bOe),e(as,fB),e(fB,TOe),e(as,FOe),e(E,COe),e(E,ns),e(ns,UX),e(UX,EOe),e(ns,MOe),e(ns,mB),e(mB,yOe),e(ns,wOe),e(ns,gB),e(gB,AOe),e(ns,LOe),e(E,BOe),e(E,ss),e(ss,JX),e(JX,kOe),e(ss,xOe),e(ss,hB),e(hB,ROe),e(ss,SOe),e(ss,uB),e(uB,POe),e(ss,$Oe),e(E,IOe),e(E,ls),e(ls,YX),e(YX,jOe),e(ls,NOe),e(ls,pB),e(pB,DOe),e(ls,qOe),e(ls,_B),e(_B,OOe),e(ls,GOe),e(E,zOe),e(E,is),e(is,KX),e(KX,VOe),e(is,XOe),e(is,vB),e(vB,WOe),e(is,QOe),e(is,bB),e(bB,HOe),e(is,UOe),e(E,JOe),e(E,Ym),e(Ym,ZX),e(ZX,YOe),e(Ym,KOe),e(Ym,TB),e(TB,ZOe),e(Ym,eGe),e(E,oGe),e(E,Km),e(Km,eW),e(eW,rGe),e(Km,tGe),e(Km,FB),e(FB,aGe),e(Km,nGe),e(E,sGe),e(E,ds),e(ds,oW),e(oW,lGe),e(ds,iGe),e(ds,CB),e(CB,dGe),e(ds,cGe),e(ds,EB),e(EB,fGe),e(ds,mGe),e(E,gGe),e(E,cs),e(cs,rW),e(rW,hGe),e(cs,uGe),e(cs,MB),e(MB,pGe),e(cs,_Ge),e(cs,yB),e(yB,vGe),e(cs,bGe),e(E,TGe),e(E,fs),e(fs,tW),e(tW,FGe),e(fs,CGe),e(fs,wB),e(wB,EGe),e(fs,MGe),e(fs,AB),e(AB,yGe),e(fs,wGe),e(E,AGe),e(E,Zm),e(Zm,aW),e(aW,LGe),e(Zm,BGe),e(Zm,LB),e(LB,kGe),e(Zm,xGe),e(E,RGe),e(E,eg),e(eg,nW),e(nW,SGe),e(eg,PGe),e(eg,BB),e(BB,$Ge),e(eg,IGe),e(E,jGe),e(E,og),e(og,sW),e(sW,NGe),e(og,DGe),e(og,kB),e(kB,qGe),e(og,OGe),e(E,GGe),e(E,rg),e(rg,lW),e(lW,zGe),e(rg,VGe),e(rg,xB),e(xB,XGe),e(rg,WGe),e(E,QGe),e(E,tg),e(tg,iW),e(iW,HGe),e(tg,UGe),e(tg,RB),e(RB,JGe),e(tg,YGe),e(E,KGe),e(E,ag),e(ag,dW),e(dW,ZGe),e(ag,eze),e(ag,SB),e(SB,oze),e(ag,rze),e(E,tze),e(E,ms),e(ms,cW),e(cW,aze),e(ms,nze),e(ms,PB),e(PB,sze),e(ms,lze),e(ms,$B),e($B,ize),e(ms,dze),e(E,cze),e(E,gs),e(gs,fW),e(fW,fze),e(gs,mze),e(gs,IB),e(IB,gze),e(gs,hze),e(gs,jB),e(jB,uze),e(gs,pze),e(io,_ze),e(io,mW),e(mW,vze),e(io,bze),g(HE,io,null),e(No,Tze),e(No,ng),g(UE,ng,null),e(ng,Fze),e(ng,gW),e(gW,Cze),v(d,cwe,_),v(d,mi,_),e(mi,sg),e(sg,hW),g(JE,hW,null),e(mi,Eze),e(mi,uW),e(uW,Mze),v(d,fwe,_),v(d,Wt,_),g(YE,Wt,null),e(Wt,yze),e(Wt,KE),e(KE,wze),e(KE,NB),e(NB,Aze),e(KE,Lze),e(Wt,Bze),e(Wt,ZE),e(ZE,kze),e(ZE,pW),e(pW,xze),e(ZE,Rze),e(Wt,Sze),e(Wt,Ae),g(eM,Ae,null),e(Ae,Pze),e(Ae,_W),e(_W,$ze),e(Ae,Ize),e(Ae,wa),e(wa,jze),e(wa,vW),e(vW,Nze),e(wa,Dze),e(wa,bW),e(bW,qze),e(wa,Oze),e(wa,TW),e(TW,Gze),e(wa,zze),e(Ae,Vze),e(Ae,ie),e(ie,lg),e(lg,FW),e(FW,Xze),e(lg,Wze),e(lg,DB),e(DB,Qze),e(lg,Hze),e(ie,Uze),e(ie,ig),e(ig,CW),e(CW,Jze),e(ig,Yze),e(ig,qB),e(qB,Kze),e(ig,Zze),e(ie,eVe),e(ie,dg),e(dg,EW),e(EW,oVe),e(dg,rVe),e(dg,OB),e(OB,tVe),e(dg,aVe),e(ie,nVe),e(ie,cg),e(cg,MW),e(MW,sVe),e(cg,lVe),e(cg,GB),e(GB,iVe),e(cg,dVe),e(ie,cVe),e(ie,fg),e(fg,yW),e(yW,fVe),e(fg,mVe),e(fg,zB),e(zB,gVe),e(fg,hVe),e(ie,uVe),e(ie,mg),e(mg,wW),e(wW,pVe),e(mg,_Ve),e(mg,VB),e(VB,vVe),e(mg,bVe),e(ie,TVe),e(ie,gg),e(gg,AW),e(AW,FVe),e(gg,CVe),e(gg,XB),e(XB,EVe),e(gg,MVe),e(ie,yVe),e(ie,hg),e(hg,LW),e(LW,wVe),e(hg,AVe),e(hg,WB),e(WB,LVe),e(hg,BVe),e(ie,kVe),e(ie,ug),e(ug,BW),e(BW,xVe),e(ug,RVe),e(ug,QB),e(QB,SVe),e(ug,PVe),e(ie,$Ve),e(ie,pg),e(pg,kW),e(kW,IVe),e(pg,jVe),e(pg,HB),e(HB,NVe),e(pg,DVe),e(ie,qVe),e(ie,_g),e(_g,xW),e(xW,OVe),e(_g,GVe),e(_g,UB),e(UB,zVe),e(_g,VVe),e(ie,XVe),e(ie,vg),e(vg,RW),e(RW,WVe),e(vg,QVe),e(vg,JB),e(JB,HVe),e(vg,UVe),e(Ae,JVe),g(bg,Ae,null),e(Ae,YVe),e(Ae,SW),e(SW,KVe),e(Ae,ZVe),g(oM,Ae,null),v(d,mwe,_),v(d,gi,_),e(gi,Tg),e(Tg,PW),g(rM,PW,null),e(gi,eXe),e(gi,$W),e($W,oXe),v(d,gwe,_),v(d,Qt,_),g(tM,Qt,null),e(Qt,rXe),e(Qt,aM),e(aM,tXe),e(aM,YB),e(YB,aXe),e(aM,nXe),e(Qt,sXe),e(Qt,nM),e(nM,lXe),e(nM,IW),e(IW,iXe),e(nM,dXe),e(Qt,cXe),e(Qt,Le),g(sM,Le,null),e(Le,fXe),e(Le,jW),e(jW,mXe),e(Le,gXe),e(Le,hi),e(hi,hXe),e(hi,NW),e(NW,uXe),e(hi,pXe),e(hi,DW),e(DW,_Xe),e(hi,vXe),e(Le,bXe),e(Le,ye),e(ye,Fg),e(Fg,qW),e(qW,TXe),e(Fg,FXe),e(Fg,KB),e(KB,CXe),e(Fg,EXe),e(ye,MXe),e(ye,Cg),e(Cg,OW),e(OW,yXe),e(Cg,wXe),e(Cg,ZB),e(ZB,AXe),e(Cg,LXe),e(ye,BXe),e(ye,Eg),e(Eg,GW),e(GW,kXe),e(Eg,xXe),e(Eg,e9),e(e9,RXe),e(Eg,SXe),e(ye,PXe),e(ye,Mg),e(Mg,zW),e(zW,$Xe),e(Mg,IXe),e(Mg,o9),e(o9,jXe),e(Mg,NXe),e(ye,DXe),e(ye,yg),e(yg,VW),e(VW,qXe),e(yg,OXe),e(yg,r9),e(r9,GXe),e(yg,zXe),e(ye,VXe),e(ye,wg),e(wg,XW),e(XW,XXe),e(wg,WXe),e(wg,t9),e(t9,QXe),e(wg,HXe),e(ye,UXe),e(ye,Ag),e(Ag,WW),e(WW,JXe),e(Ag,YXe),e(Ag,a9),e(a9,KXe),e(Ag,ZXe),e(ye,eWe),e(ye,Lg),e(Lg,QW),e(QW,oWe),e(Lg,rWe),e(Lg,n9),e(n9,tWe),e(Lg,aWe),e(Le,nWe),g(Bg,Le,null),e(Le,sWe),e(Le,HW),e(HW,lWe),e(Le,iWe),g(lM,Le,null),v(d,hwe,_),v(d,ui,_),e(ui,kg),e(kg,UW),g(iM,UW,null),e(ui,dWe),e(ui,JW),e(JW,cWe),v(d,uwe,_),v(d,Do,_),g(dM,Do,null),e(Do,fWe),e(Do,pi),e(pi,mWe),e(pi,YW),e(YW,gWe),e(pi,hWe),e(pi,KW),e(KW,uWe),e(pi,pWe),e(Do,_We),e(Do,cM),e(cM,vWe),e(cM,ZW),e(ZW,bWe),e(cM,TWe),e(Do,FWe),e(Do,Br),g(fM,Br,null),e(Br,CWe),e(Br,eQ),e(eQ,EWe),e(Br,MWe),e(Br,_i),e(_i,yWe),e(_i,oQ),e(oQ,wWe),e(_i,AWe),e(_i,rQ),e(rQ,LWe),e(_i,BWe),e(Br,kWe),e(Br,tQ),e(tQ,xWe),e(Br,RWe),g(mM,Br,null),e(Do,SWe),e(Do,Be),g(gM,Be,null),e(Be,PWe),e(Be,aQ),e(aQ,$We),e(Be,IWe),e(Be,Aa),e(Aa,jWe),e(Aa,nQ),e(nQ,NWe),e(Aa,DWe),e(Aa,sQ),e(sQ,qWe),e(Aa,OWe),e(Aa,lQ),e(lQ,GWe),e(Aa,zWe),e(Be,VWe),e(Be,F),e(F,xg),e(xg,iQ),e(iQ,XWe),e(xg,WWe),e(xg,s9),e(s9,QWe),e(xg,HWe),e(F,UWe),e(F,Rg),e(Rg,dQ),e(dQ,JWe),e(Rg,YWe),e(Rg,l9),e(l9,KWe),e(Rg,ZWe),e(F,eQe),e(F,Sg),e(Sg,cQ),e(cQ,oQe),e(Sg,rQe),e(Sg,i9),e(i9,tQe),e(Sg,aQe),e(F,nQe),e(F,Pg),e(Pg,fQ),e(fQ,sQe),e(Pg,lQe),e(Pg,d9),e(d9,iQe),e(Pg,dQe),e(F,cQe),e(F,$g),e($g,mQ),e(mQ,fQe),e($g,mQe),e($g,c9),e(c9,gQe),e($g,hQe),e(F,uQe),e(F,Ig),e(Ig,gQ),e(gQ,pQe),e(Ig,_Qe),e(Ig,f9),e(f9,vQe),e(Ig,bQe),e(F,TQe),e(F,jg),e(jg,hQ),e(hQ,FQe),e(jg,CQe),e(jg,m9),e(m9,EQe),e(jg,MQe),e(F,yQe),e(F,Ng),e(Ng,uQ),e(uQ,wQe),e(Ng,AQe),e(Ng,g9),e(g9,LQe),e(Ng,BQe),e(F,kQe),e(F,Dg),e(Dg,pQ),e(pQ,xQe),e(Dg,RQe),e(Dg,h9),e(h9,SQe),e(Dg,PQe),e(F,$Qe),e(F,qg),e(qg,_Q),e(_Q,IQe),e(qg,jQe),e(qg,u9),e(u9,NQe),e(qg,DQe),e(F,qQe),e(F,Og),e(Og,vQ),e(vQ,OQe),e(Og,GQe),e(Og,p9),e(p9,zQe),e(Og,VQe),e(F,XQe),e(F,Gg),e(Gg,bQ),e(bQ,WQe),e(Gg,QQe),e(Gg,_9),e(_9,HQe),e(Gg,UQe),e(F,JQe),e(F,zg),e(zg,TQ),e(TQ,YQe),e(zg,KQe),e(zg,v9),e(v9,ZQe),e(zg,eHe),e(F,oHe),e(F,Vg),e(Vg,FQ),e(FQ,rHe),e(Vg,tHe),e(Vg,b9),e(b9,aHe),e(Vg,nHe),e(F,sHe),e(F,Xg),e(Xg,CQ),e(CQ,lHe),e(Xg,iHe),e(Xg,T9),e(T9,dHe),e(Xg,cHe),e(F,fHe),e(F,Wg),e(Wg,EQ),e(EQ,mHe),e(Wg,gHe),e(Wg,F9),e(F9,hHe),e(Wg,uHe),e(F,pHe),e(F,Qg),e(Qg,MQ),e(MQ,_He),e(Qg,vHe),e(Qg,C9),e(C9,bHe),e(Qg,THe),e(F,FHe),e(F,Hg),e(Hg,yQ),e(yQ,CHe),e(Hg,EHe),e(Hg,E9),e(E9,MHe),e(Hg,yHe),e(F,wHe),e(F,Ug),e(Ug,wQ),e(wQ,AHe),e(Ug,LHe),e(Ug,M9),e(M9,BHe),e(Ug,kHe),e(F,xHe),e(F,Jg),e(Jg,AQ),e(AQ,RHe),e(Jg,SHe),e(Jg,y9),e(y9,PHe),e(Jg,$He),e(F,IHe),e(F,Yg),e(Yg,LQ),e(LQ,jHe),e(Yg,NHe),e(Yg,w9),e(w9,DHe),e(Yg,qHe),e(F,OHe),e(F,Kg),e(Kg,BQ),e(BQ,GHe),e(Kg,zHe),e(Kg,A9),e(A9,VHe),e(Kg,XHe),e(F,WHe),e(F,Zg),e(Zg,kQ),e(kQ,QHe),e(Zg,HHe),e(Zg,L9),e(L9,UHe),e(Zg,JHe),e(F,YHe),e(F,eh),e(eh,xQ),e(xQ,KHe),e(eh,ZHe),e(eh,B9),e(B9,eUe),e(eh,oUe),e(F,rUe),e(F,hs),e(hs,RQ),e(RQ,tUe),e(hs,aUe),e(hs,k9),e(k9,nUe),e(hs,sUe),e(hs,x9),e(x9,lUe),e(hs,iUe),e(F,dUe),e(F,oh),e(oh,SQ),e(SQ,cUe),e(oh,fUe),e(oh,R9),e(R9,mUe),e(oh,gUe),e(F,hUe),e(F,rh),e(rh,PQ),e(PQ,uUe),e(rh,pUe),e(rh,S9),e(S9,_Ue),e(rh,vUe),e(F,bUe),e(F,th),e(th,$Q),e($Q,TUe),e(th,FUe),e(th,P9),e(P9,CUe),e(th,EUe),e(F,MUe),e(F,ah),e(ah,IQ),e(IQ,yUe),e(ah,wUe),e(ah,$9),e($9,AUe),e(ah,LUe),e(F,BUe),e(F,nh),e(nh,jQ),e(jQ,kUe),e(nh,xUe),e(nh,I9),e(I9,RUe),e(nh,SUe),e(F,PUe),e(F,sh),e(sh,NQ),e(NQ,$Ue),e(sh,IUe),e(sh,j9),e(j9,jUe),e(sh,NUe),e(F,DUe),e(F,lh),e(lh,DQ),e(DQ,qUe),e(lh,OUe),e(lh,N9),e(N9,GUe),e(lh,zUe),e(F,VUe),e(F,ih),e(ih,qQ),e(qQ,XUe),e(ih,WUe),e(ih,D9),e(D9,QUe),e(ih,HUe),e(F,UUe),e(F,dh),e(dh,OQ),e(OQ,JUe),e(dh,YUe),e(dh,q9),e(q9,KUe),e(dh,ZUe),e(F,eJe),e(F,ch),e(ch,GQ),e(GQ,oJe),e(ch,rJe),e(ch,O9),e(O9,tJe),e(ch,aJe),e(F,nJe),e(F,fh),e(fh,zQ),e(zQ,sJe),e(fh,lJe),e(fh,G9),e(G9,iJe),e(fh,dJe),e(F,cJe),e(F,mh),e(mh,VQ),e(VQ,fJe),e(mh,mJe),e(mh,z9),e(z9,gJe),e(mh,hJe),e(F,uJe),e(F,gh),e(gh,XQ),e(XQ,pJe),e(gh,_Je),e(gh,V9),e(V9,vJe),e(gh,bJe),e(F,TJe),e(F,hh),e(hh,WQ),e(WQ,FJe),e(hh,CJe),e(hh,X9),e(X9,EJe),e(hh,MJe),e(F,yJe),e(F,uh),e(uh,QQ),e(QQ,wJe),e(uh,AJe),e(uh,W9),e(W9,LJe),e(uh,BJe),e(F,kJe),e(F,ph),e(ph,HQ),e(HQ,xJe),e(ph,RJe),e(ph,Q9),e(Q9,SJe),e(ph,PJe),e(F,$Je),e(F,_h),e(_h,UQ),e(UQ,IJe),e(_h,jJe),e(_h,H9),e(H9,NJe),e(_h,DJe),e(F,qJe),e(F,vh),e(vh,JQ),e(JQ,OJe),e(vh,GJe),e(vh,U9),e(U9,zJe),e(vh,VJe),e(F,XJe),e(F,bh),e(bh,YQ),e(YQ,WJe),e(bh,QJe),e(bh,J9),e(J9,HJe),e(bh,UJe),e(F,JJe),e(F,Th),e(Th,KQ),e(KQ,YJe),e(Th,KJe),e(Th,Y9),e(Y9,ZJe),e(Th,eYe),e(F,oYe),e(F,Fh),e(Fh,ZQ),e(ZQ,rYe),e(Fh,tYe),e(Fh,K9),e(K9,aYe),e(Fh,nYe),e(F,sYe),e(F,Ch),e(Ch,eH),e(eH,lYe),e(Ch,iYe),e(Ch,Z9),e(Z9,dYe),e(Ch,cYe),e(F,fYe),e(F,Eh),e(Eh,oH),e(oH,mYe),e(Eh,gYe),e(Eh,ek),e(ek,hYe),e(Eh,uYe),e(F,pYe),e(F,Mh),e(Mh,rH),e(rH,_Ye),e(Mh,vYe),e(Mh,ok),e(ok,bYe),e(Mh,TYe),e(F,FYe),e(F,yh),e(yh,tH),e(tH,CYe),e(yh,EYe),e(yh,rk),e(rk,MYe),e(yh,yYe),e(F,wYe),e(F,wh),e(wh,aH),e(aH,AYe),e(wh,LYe),e(wh,tk),e(tk,BYe),e(wh,kYe),e(F,xYe),e(F,Ah),e(Ah,nH),e(nH,RYe),e(Ah,SYe),e(Ah,ak),e(ak,PYe),e(Ah,$Ye),e(F,IYe),e(F,Lh),e(Lh,sH),e(sH,jYe),e(Lh,NYe),e(Lh,nk),e(nk,DYe),e(Lh,qYe),e(F,OYe),e(F,Bh),e(Bh,lH),e(lH,GYe),e(Bh,zYe),e(Bh,sk),e(sk,VYe),e(Bh,XYe),e(F,WYe),e(F,kh),e(kh,iH),e(iH,QYe),e(kh,HYe),e(kh,lk),e(lk,UYe),e(kh,JYe),e(F,YYe),e(F,xh),e(xh,dH),e(dH,KYe),e(xh,ZYe),e(xh,ik),e(ik,eKe),e(xh,oKe),e(F,rKe),e(F,Rh),e(Rh,cH),e(cH,tKe),e(Rh,aKe),e(Rh,dk),e(dk,nKe),e(Rh,sKe),e(F,lKe),e(F,Sh),e(Sh,fH),e(fH,iKe),e(Sh,dKe),e(Sh,ck),e(ck,cKe),e(Sh,fKe),e(F,mKe),e(F,Ph),e(Ph,mH),e(mH,gKe),e(Ph,hKe),e(Ph,fk),e(fk,uKe),e(Ph,pKe),e(F,_Ke),e(F,$h),e($h,gH),e(gH,vKe),e($h,bKe),e($h,mk),e(mk,TKe),e($h,FKe),e(F,CKe),e(F,Ih),e(Ih,hH),e(hH,EKe),e(Ih,MKe),e(Ih,gk),e(gk,yKe),e(Ih,wKe),e(F,AKe),e(F,jh),e(jh,uH),e(uH,LKe),e(jh,BKe),e(jh,hk),e(hk,kKe),e(jh,xKe),e(F,RKe),e(F,Nh),e(Nh,pH),e(pH,SKe),e(Nh,PKe),e(Nh,uk),e(uk,$Ke),e(Nh,IKe),e(F,jKe),e(F,Dh),e(Dh,_H),e(_H,NKe),e(Dh,DKe),e(Dh,pk),e(pk,qKe),e(Dh,OKe),e(F,GKe),e(F,qh),e(qh,vH),e(vH,zKe),e(qh,VKe),e(qh,_k),e(_k,XKe),e(qh,WKe),e(F,QKe),e(F,Oh),e(Oh,bH),e(bH,HKe),e(Oh,UKe),e(Oh,vk),e(vk,JKe),e(Oh,YKe),e(F,KKe),e(F,Gh),e(Gh,TH),e(TH,ZKe),e(Gh,eZe),e(Gh,bk),e(bk,oZe),e(Gh,rZe),e(F,tZe),e(F,zh),e(zh,FH),e(FH,aZe),e(zh,nZe),e(zh,Tk),e(Tk,sZe),e(zh,lZe),e(F,iZe),e(F,Vh),e(Vh,CH),e(CH,dZe),e(Vh,cZe),e(Vh,Fk),e(Fk,fZe),e(Vh,mZe),e(F,gZe),e(F,Xh),e(Xh,EH),e(EH,hZe),e(Xh,uZe),e(Xh,Ck),e(Ck,pZe),e(Xh,_Ze),e(F,vZe),e(F,Wh),e(Wh,MH),e(MH,bZe),e(Wh,TZe),e(Wh,Ek),e(Ek,FZe),e(Wh,CZe),e(F,EZe),e(F,Qh),e(Qh,yH),e(yH,MZe),e(Qh,yZe),e(Qh,Mk),e(Mk,wZe),e(Qh,AZe),e(F,LZe),e(F,Hh),e(Hh,wH),e(wH,BZe),e(Hh,kZe),e(Hh,yk),e(yk,xZe),e(Hh,RZe),e(F,SZe),e(F,Uh),e(Uh,AH),e(AH,PZe),e(Uh,$Ze),e(Uh,wk),e(wk,IZe),e(Uh,jZe),e(F,NZe),e(F,Jh),e(Jh,LH),e(LH,DZe),e(Jh,qZe),e(Jh,Ak),e(Ak,OZe),e(Jh,GZe),e(F,zZe),e(F,Yh),e(Yh,BH),e(BH,VZe),e(Yh,XZe),e(Yh,Lk),e(Lk,WZe),e(Yh,QZe),e(F,HZe),e(F,Kh),e(Kh,kH),e(kH,UZe),e(Kh,JZe),e(Kh,Bk),e(Bk,YZe),e(Kh,KZe),e(F,ZZe),e(F,Zh),e(Zh,xH),e(xH,eeo),e(Zh,oeo),e(Zh,kk),e(kk,reo),e(Zh,teo),e(F,aeo),e(F,eu),e(eu,RH),e(RH,neo),e(eu,seo),e(eu,xk),e(xk,leo),e(eu,ieo),e(Be,deo),e(Be,ou),e(ou,ceo),e(ou,SH),e(SH,feo),e(ou,meo),e(ou,PH),e(PH,geo),e(Be,heo),e(Be,$H),e($H,ueo),e(Be,peo),g(hM,Be,null),v(d,pwe,_),v(d,vi,_),e(vi,ru),e(ru,IH),g(uM,IH,null),e(vi,_eo),e(vi,jH),e(jH,veo),v(d,_we,_),v(d,qo,_),g(pM,qo,null),e(qo,beo),e(qo,bi),e(bi,Teo),e(bi,NH),e(NH,Feo),e(bi,Ceo),e(bi,DH),e(DH,Eeo),e(bi,Meo),e(qo,yeo),e(qo,_M),e(_M,weo),e(_M,qH),e(qH,Aeo),e(_M,Leo),e(qo,Beo),e(qo,kr),g(vM,kr,null),e(kr,keo),e(kr,OH),e(OH,xeo),e(kr,Reo),e(kr,Ti),e(Ti,Seo),e(Ti,GH),e(GH,Peo),e(Ti,$eo),e(Ti,zH),e(zH,Ieo),e(Ti,jeo),e(kr,Neo),e(kr,VH),e(VH,Deo),e(kr,qeo),g(bM,kr,null),e(qo,Oeo),e(qo,ke),g(TM,ke,null),e(ke,Geo),e(ke,XH),e(XH,zeo),e(ke,Veo),e(ke,La),e(La,Xeo),e(La,WH),e(WH,Weo),e(La,Qeo),e(La,QH),e(QH,Heo),e(La,Ueo),e(La,HH),e(HH,Jeo),e(La,Yeo),e(ke,Keo),e(ke,x),e(x,tu),e(tu,UH),e(UH,Zeo),e(tu,eoo),e(tu,Rk),e(Rk,ooo),e(tu,roo),e(x,too),e(x,au),e(au,JH),e(JH,aoo),e(au,noo),e(au,Sk),e(Sk,soo),e(au,loo),e(x,ioo),e(x,nu),e(nu,YH),e(YH,doo),e(nu,coo),e(nu,Pk),e(Pk,foo),e(nu,moo),e(x,goo),e(x,su),e(su,KH),e(KH,hoo),e(su,uoo),e(su,$k),e($k,poo),e(su,_oo),e(x,voo),e(x,lu),e(lu,ZH),e(ZH,boo),e(lu,Too),e(lu,Ik),e(Ik,Foo),e(lu,Coo),e(x,Eoo),e(x,iu),e(iu,eU),e(eU,Moo),e(iu,yoo),e(iu,jk),e(jk,woo),e(iu,Aoo),e(x,Loo),e(x,du),e(du,oU),e(oU,Boo),e(du,koo),e(du,Nk),e(Nk,xoo),e(du,Roo),e(x,Soo),e(x,cu),e(cu,rU),e(rU,Poo),e(cu,$oo),e(cu,Dk),e(Dk,Ioo),e(cu,joo),e(x,Noo),e(x,fu),e(fu,tU),e(tU,Doo),e(fu,qoo),e(fu,qk),e(qk,Ooo),e(fu,Goo),e(x,zoo),e(x,mu),e(mu,aU),e(aU,Voo),e(mu,Xoo),e(mu,Ok),e(Ok,Woo),e(mu,Qoo),e(x,Hoo),e(x,gu),e(gu,nU),e(nU,Uoo),e(gu,Joo),e(gu,Gk),e(Gk,Yoo),e(gu,Koo),e(x,Zoo),e(x,hu),e(hu,sU),e(sU,ero),e(hu,oro),e(hu,zk),e(zk,rro),e(hu,tro),e(x,aro),e(x,uu),e(uu,lU),e(lU,nro),e(uu,sro),e(uu,Vk),e(Vk,lro),e(uu,iro),e(x,dro),e(x,pu),e(pu,iU),e(iU,cro),e(pu,fro),e(pu,Xk),e(Xk,mro),e(pu,gro),e(x,hro),e(x,_u),e(_u,dU),e(dU,uro),e(_u,pro),e(_u,Wk),e(Wk,_ro),e(_u,vro),e(x,bro),e(x,vu),e(vu,cU),e(cU,Tro),e(vu,Fro),e(vu,Qk),e(Qk,Cro),e(vu,Ero),e(x,Mro),e(x,bu),e(bu,fU),e(fU,yro),e(bu,wro),e(bu,Hk),e(Hk,Aro),e(bu,Lro),e(x,Bro),e(x,Tu),e(Tu,mU),e(mU,kro),e(Tu,xro),e(Tu,Uk),e(Uk,Rro),e(Tu,Sro),e(x,Pro),e(x,Fu),e(Fu,gU),e(gU,$ro),e(Fu,Iro),e(Fu,Jk),e(Jk,jro),e(Fu,Nro),e(x,Dro),e(x,Cu),e(Cu,hU),e(hU,qro),e(Cu,Oro),e(Cu,Yk),e(Yk,Gro),e(Cu,zro),e(x,Vro),e(x,Eu),e(Eu,uU),e(uU,Xro),e(Eu,Wro),e(Eu,Kk),e(Kk,Qro),e(Eu,Hro),e(x,Uro),e(x,Mu),e(Mu,pU),e(pU,Jro),e(Mu,Yro),e(Mu,Zk),e(Zk,Kro),e(Mu,Zro),e(x,eto),e(x,yu),e(yu,_U),e(_U,oto),e(yu,rto),e(yu,ex),e(ex,tto),e(yu,ato),e(x,nto),e(x,wu),e(wu,vU),e(vU,sto),e(wu,lto),e(wu,ox),e(ox,ito),e(wu,dto),e(x,cto),e(x,Au),e(Au,bU),e(bU,fto),e(Au,mto),e(Au,rx),e(rx,gto),e(Au,hto),e(x,uto),e(x,Lu),e(Lu,TU),e(TU,pto),e(Lu,_to),e(Lu,tx),e(tx,vto),e(Lu,bto),e(x,Tto),e(x,Bu),e(Bu,FU),e(FU,Fto),e(Bu,Cto),e(Bu,ax),e(ax,Eto),e(Bu,Mto),e(x,yto),e(x,ku),e(ku,CU),e(CU,wto),e(ku,Ato),e(ku,nx),e(nx,Lto),e(ku,Bto),e(x,kto),e(x,xu),e(xu,EU),e(EU,xto),e(xu,Rto),e(xu,sx),e(sx,Sto),e(xu,Pto),e(x,$to),e(x,Ru),e(Ru,MU),e(MU,Ito),e(Ru,jto),e(Ru,lx),e(lx,Nto),e(Ru,Dto),e(x,qto),e(x,Su),e(Su,yU),e(yU,Oto),e(Su,Gto),e(Su,ix),e(ix,zto),e(Su,Vto),e(x,Xto),e(x,Pu),e(Pu,wU),e(wU,Wto),e(Pu,Qto),e(Pu,dx),e(dx,Hto),e(Pu,Uto),e(x,Jto),e(x,$u),e($u,AU),e(AU,Yto),e($u,Kto),e($u,cx),e(cx,Zto),e($u,eao),e(x,oao),e(x,Iu),e(Iu,LU),e(LU,rao),e(Iu,tao),e(Iu,fx),e(fx,aao),e(Iu,nao),e(x,sao),e(x,ju),e(ju,BU),e(BU,lao),e(ju,iao),e(ju,mx),e(mx,dao),e(ju,cao),e(x,fao),e(x,Nu),e(Nu,kU),e(kU,mao),e(Nu,gao),e(Nu,gx),e(gx,hao),e(Nu,uao),e(x,pao),e(x,Du),e(Du,xU),e(xU,_ao),e(Du,vao),e(Du,hx),e(hx,bao),e(Du,Tao),e(ke,Fao),e(ke,qu),e(qu,Cao),e(qu,RU),e(RU,Eao),e(qu,Mao),e(qu,SU),e(SU,yao),e(ke,wao),e(ke,PU),e(PU,Aao),e(ke,Lao),g(FM,ke,null),v(d,vwe,_),v(d,Fi,_),e(Fi,Ou),e(Ou,$U),g(CM,$U,null),e(Fi,Bao),e(Fi,IU),e(IU,kao),v(d,bwe,_),v(d,Oo,_),g(EM,Oo,null),e(Oo,xao),e(Oo,Ci),e(Ci,Rao),e(Ci,jU),e(jU,Sao),e(Ci,Pao),e(Ci,NU),e(NU,$ao),e(Ci,Iao),e(Oo,jao),e(Oo,MM),e(MM,Nao),e(MM,DU),e(DU,Dao),e(MM,qao),e(Oo,Oao),e(Oo,xr),g(yM,xr,null),e(xr,Gao),e(xr,qU),e(qU,zao),e(xr,Vao),e(xr,Ei),e(Ei,Xao),e(Ei,OU),e(OU,Wao),e(Ei,Qao),e(Ei,GU),e(GU,Hao),e(Ei,Uao),e(xr,Jao),e(xr,zU),e(zU,Yao),e(xr,Kao),g(wM,xr,null),e(Oo,Zao),e(Oo,xe),g(AM,xe,null),e(xe,eno),e(xe,VU),e(VU,ono),e(xe,rno),e(xe,Ba),e(Ba,tno),e(Ba,XU),e(XU,ano),e(Ba,nno),e(Ba,WU),e(WU,sno),e(Ba,lno),e(Ba,QU),e(QU,ino),e(Ba,dno),e(xe,cno),e(xe,j),e(j,Gu),e(Gu,HU),e(HU,fno),e(Gu,mno),e(Gu,ux),e(ux,gno),e(Gu,hno),e(j,uno),e(j,zu),e(zu,UU),e(UU,pno),e(zu,_no),e(zu,px),e(px,vno),e(zu,bno),e(j,Tno),e(j,Vu),e(Vu,JU),e(JU,Fno),e(Vu,Cno),e(Vu,_x),e(_x,Eno),e(Vu,Mno),e(j,yno),e(j,Xu),e(Xu,YU),e(YU,wno),e(Xu,Ano),e(Xu,vx),e(vx,Lno),e(Xu,Bno),e(j,kno),e(j,Wu),e(Wu,KU),e(KU,xno),e(Wu,Rno),e(Wu,bx),e(bx,Sno),e(Wu,Pno),e(j,$no),e(j,Qu),e(Qu,ZU),e(ZU,Ino),e(Qu,jno),e(Qu,Tx),e(Tx,Nno),e(Qu,Dno),e(j,qno),e(j,Hu),e(Hu,eJ),e(eJ,Ono),e(Hu,Gno),e(Hu,Fx),e(Fx,zno),e(Hu,Vno),e(j,Xno),e(j,Uu),e(Uu,oJ),e(oJ,Wno),e(Uu,Qno),e(Uu,Cx),e(Cx,Hno),e(Uu,Uno),e(j,Jno),e(j,Ju),e(Ju,rJ),e(rJ,Yno),e(Ju,Kno),e(Ju,Ex),e(Ex,Zno),e(Ju,eso),e(j,oso),e(j,Yu),e(Yu,tJ),e(tJ,rso),e(Yu,tso),e(Yu,Mx),e(Mx,aso),e(Yu,nso),e(j,sso),e(j,Ku),e(Ku,aJ),e(aJ,lso),e(Ku,iso),e(Ku,yx),e(yx,dso),e(Ku,cso),e(j,fso),e(j,Zu),e(Zu,nJ),e(nJ,mso),e(Zu,gso),e(Zu,wx),e(wx,hso),e(Zu,uso),e(j,pso),e(j,ep),e(ep,sJ),e(sJ,_so),e(ep,vso),e(ep,Ax),e(Ax,bso),e(ep,Tso),e(j,Fso),e(j,op),e(op,lJ),e(lJ,Cso),e(op,Eso),e(op,Lx),e(Lx,Mso),e(op,yso),e(j,wso),e(j,rp),e(rp,iJ),e(iJ,Aso),e(rp,Lso),e(rp,Bx),e(Bx,Bso),e(rp,kso),e(j,xso),e(j,tp),e(tp,dJ),e(dJ,Rso),e(tp,Sso),e(tp,kx),e(kx,Pso),e(tp,$so),e(j,Iso),e(j,ap),e(ap,cJ),e(cJ,jso),e(ap,Nso),e(ap,xx),e(xx,Dso),e(ap,qso),e(j,Oso),e(j,np),e(np,fJ),e(fJ,Gso),e(np,zso),e(np,Rx),e(Rx,Vso),e(np,Xso),e(j,Wso),e(j,sp),e(sp,mJ),e(mJ,Qso),e(sp,Hso),e(sp,Sx),e(Sx,Uso),e(sp,Jso),e(j,Yso),e(j,lp),e(lp,gJ),e(gJ,Kso),e(lp,Zso),e(lp,Px),e(Px,elo),e(lp,olo),e(j,rlo),e(j,ip),e(ip,hJ),e(hJ,tlo),e(ip,alo),e(ip,$x),e($x,nlo),e(ip,slo),e(j,llo),e(j,dp),e(dp,uJ),e(uJ,ilo),e(dp,dlo),e(dp,Ix),e(Ix,clo),e(dp,flo),e(j,mlo),e(j,cp),e(cp,pJ),e(pJ,glo),e(cp,hlo),e(cp,jx),e(jx,ulo),e(cp,plo),e(j,_lo),e(j,fp),e(fp,_J),e(_J,vlo),e(fp,blo),e(fp,Nx),e(Nx,Tlo),e(fp,Flo),e(j,Clo),e(j,mp),e(mp,vJ),e(vJ,Elo),e(mp,Mlo),e(mp,Dx),e(Dx,ylo),e(mp,wlo),e(j,Alo),e(j,gp),e(gp,bJ),e(bJ,Llo),e(gp,Blo),e(gp,qx),e(qx,klo),e(gp,xlo),e(j,Rlo),e(j,hp),e(hp,TJ),e(TJ,Slo),e(hp,Plo),e(hp,Ox),e(Ox,$lo),e(hp,Ilo),e(j,jlo),e(j,up),e(up,FJ),e(FJ,Nlo),e(up,Dlo),e(up,Gx),e(Gx,qlo),e(up,Olo),e(j,Glo),e(j,pp),e(pp,CJ),e(CJ,zlo),e(pp,Vlo),e(pp,zx),e(zx,Xlo),e(pp,Wlo),e(j,Qlo),e(j,_p),e(_p,EJ),e(EJ,Hlo),e(_p,Ulo),e(_p,Vx),e(Vx,Jlo),e(_p,Ylo),e(j,Klo),e(j,vp),e(vp,MJ),e(MJ,Zlo),e(vp,eio),e(vp,Xx),e(Xx,oio),e(vp,rio),e(xe,tio),e(xe,bp),e(bp,aio),e(bp,yJ),e(yJ,nio),e(bp,sio),e(bp,wJ),e(wJ,lio),e(xe,iio),e(xe,AJ),e(AJ,dio),e(xe,cio),g(LM,xe,null),v(d,Twe,_),v(d,Mi,_),e(Mi,Tp),e(Tp,LJ),g(BM,LJ,null),e(Mi,fio),e(Mi,BJ),e(BJ,mio),v(d,Fwe,_),v(d,Go,_),g(kM,Go,null),e(Go,gio),e(Go,yi),e(yi,hio),e(yi,kJ),e(kJ,uio),e(yi,pio),e(yi,xJ),e(xJ,_io),e(yi,vio),e(Go,bio),e(Go,xM),e(xM,Tio),e(xM,RJ),e(RJ,Fio),e(xM,Cio),e(Go,Eio),e(Go,Rr),g(RM,Rr,null),e(Rr,Mio),e(Rr,SJ),e(SJ,yio),e(Rr,wio),e(Rr,wi),e(wi,Aio),e(wi,PJ),e(PJ,Lio),e(wi,Bio),e(wi,$J),e($J,kio),e(wi,xio),e(Rr,Rio),e(Rr,IJ),e(IJ,Sio),e(Rr,Pio),g(SM,Rr,null),e(Go,$io),e(Go,Re),g(PM,Re,null),e(Re,Iio),e(Re,jJ),e(jJ,jio),e(Re,Nio),e(Re,ka),e(ka,Dio),e(ka,NJ),e(NJ,qio),e(ka,Oio),e(ka,DJ),e(DJ,Gio),e(ka,zio),e(ka,qJ),e(qJ,Vio),e(ka,Xio),e(Re,Wio),e(Re,$),e($,Fp),e(Fp,OJ),e(OJ,Qio),e(Fp,Hio),e(Fp,Wx),e(Wx,Uio),e(Fp,Jio),e($,Yio),e($,Cp),e(Cp,GJ),e(GJ,Kio),e(Cp,Zio),e(Cp,Qx),e(Qx,edo),e(Cp,odo),e($,rdo),e($,Ep),e(Ep,zJ),e(zJ,tdo),e(Ep,ado),e(Ep,Hx),e(Hx,ndo),e(Ep,sdo),e($,ldo),e($,Mp),e(Mp,VJ),e(VJ,ido),e(Mp,ddo),e(Mp,Ux),e(Ux,cdo),e(Mp,fdo),e($,mdo),e($,yp),e(yp,XJ),e(XJ,gdo),e(yp,hdo),e(yp,Jx),e(Jx,udo),e(yp,pdo),e($,_do),e($,wp),e(wp,WJ),e(WJ,vdo),e(wp,bdo),e(wp,Yx),e(Yx,Tdo),e(wp,Fdo),e($,Cdo),e($,Ap),e(Ap,QJ),e(QJ,Edo),e(Ap,Mdo),e(Ap,Kx),e(Kx,ydo),e(Ap,wdo),e($,Ado),e($,Lp),e(Lp,HJ),e(HJ,Ldo),e(Lp,Bdo),e(Lp,Zx),e(Zx,kdo),e(Lp,xdo),e($,Rdo),e($,Bp),e(Bp,UJ),e(UJ,Sdo),e(Bp,Pdo),e(Bp,eR),e(eR,$do),e(Bp,Ido),e($,jdo),e($,kp),e(kp,JJ),e(JJ,Ndo),e(kp,Ddo),e(kp,oR),e(oR,qdo),e(kp,Odo),e($,Gdo),e($,xp),e(xp,YJ),e(YJ,zdo),e(xp,Vdo),e(xp,rR),e(rR,Xdo),e(xp,Wdo),e($,Qdo),e($,Rp),e(Rp,KJ),e(KJ,Hdo),e(Rp,Udo),e(Rp,tR),e(tR,Jdo),e(Rp,Ydo),e($,Kdo),e($,Sp),e(Sp,ZJ),e(ZJ,Zdo),e(Sp,eco),e(Sp,aR),e(aR,oco),e(Sp,rco),e($,tco),e($,Pp),e(Pp,eY),e(eY,aco),e(Pp,nco),e(Pp,nR),e(nR,sco),e(Pp,lco),e($,ico),e($,$p),e($p,oY),e(oY,dco),e($p,cco),e($p,sR),e(sR,fco),e($p,mco),e($,gco),e($,Ip),e(Ip,rY),e(rY,hco),e(Ip,uco),e(Ip,lR),e(lR,pco),e(Ip,_co),e($,vco),e($,jp),e(jp,tY),e(tY,bco),e(jp,Tco),e(jp,iR),e(iR,Fco),e(jp,Cco),e($,Eco),e($,Np),e(Np,aY),e(aY,Mco),e(Np,yco),e(Np,dR),e(dR,wco),e(Np,Aco),e($,Lco),e($,Dp),e(Dp,nY),e(nY,Bco),e(Dp,kco),e(Dp,cR),e(cR,xco),e(Dp,Rco),e($,Sco),e($,qp),e(qp,sY),e(sY,Pco),e(qp,$co),e(qp,fR),e(fR,Ico),e(qp,jco),e($,Nco),e($,Op),e(Op,lY),e(lY,Dco),e(Op,qco),e(Op,mR),e(mR,Oco),e(Op,Gco),e($,zco),e($,Gp),e(Gp,iY),e(iY,Vco),e(Gp,Xco),e(Gp,gR),e(gR,Wco),e(Gp,Qco),e($,Hco),e($,zp),e(zp,dY),e(dY,Uco),e(zp,Jco),e(zp,hR),e(hR,Yco),e(zp,Kco),e($,Zco),e($,Vp),e(Vp,cY),e(cY,efo),e(Vp,ofo),e(Vp,uR),e(uR,rfo),e(Vp,tfo),e($,afo),e($,Xp),e(Xp,fY),e(fY,nfo),e(Xp,sfo),e(Xp,pR),e(pR,lfo),e(Xp,ifo),e($,dfo),e($,Wp),e(Wp,mY),e(mY,cfo),e(Wp,ffo),e(Wp,_R),e(_R,mfo),e(Wp,gfo),e($,hfo),e($,Qp),e(Qp,gY),e(gY,ufo),e(Qp,pfo),e(Qp,vR),e(vR,_fo),e(Qp,vfo),e($,bfo),e($,Hp),e(Hp,hY),e(hY,Tfo),e(Hp,Ffo),e(Hp,bR),e(bR,Cfo),e(Hp,Efo),e($,Mfo),e($,Up),e(Up,uY),e(uY,yfo),e(Up,wfo),e(Up,TR),e(TR,Afo),e(Up,Lfo),e($,Bfo),e($,Jp),e(Jp,pY),e(pY,kfo),e(Jp,xfo),e(Jp,_Y),e(_Y,Rfo),e(Jp,Sfo),e($,Pfo),e($,Yp),e(Yp,vY),e(vY,$fo),e(Yp,Ifo),e(Yp,FR),e(FR,jfo),e(Yp,Nfo),e($,Dfo),e($,Kp),e(Kp,bY),e(bY,qfo),e(Kp,Ofo),e(Kp,CR),e(CR,Gfo),e(Kp,zfo),e($,Vfo),e($,Zp),e(Zp,TY),e(TY,Xfo),e(Zp,Wfo),e(Zp,ER),e(ER,Qfo),e(Zp,Hfo),e(Re,Ufo),e(Re,e_),e(e_,Jfo),e(e_,FY),e(FY,Yfo),e(e_,Kfo),e(e_,CY),e(CY,Zfo),e(Re,emo),e(Re,EY),e(EY,omo),e(Re,rmo),g($M,Re,null),v(d,Cwe,_),v(d,Ai,_),e(Ai,o_),e(o_,MY),g(IM,MY,null),e(Ai,tmo),e(Ai,yY),e(yY,amo),v(d,Ewe,_),v(d,zo,_),g(jM,zo,null),e(zo,nmo),e(zo,Li),e(Li,smo),e(Li,wY),e(wY,lmo),e(Li,imo),e(Li,AY),e(AY,dmo),e(Li,cmo),e(zo,fmo),e(zo,NM),e(NM,mmo),e(NM,LY),e(LY,gmo),e(NM,hmo),e(zo,umo),e(zo,Sr),g(DM,Sr,null),e(Sr,pmo),e(Sr,BY),e(BY,_mo),e(Sr,vmo),e(Sr,Bi),e(Bi,bmo),e(Bi,kY),e(kY,Tmo),e(Bi,Fmo),e(Bi,xY),e(xY,Cmo),e(Bi,Emo),e(Sr,Mmo),e(Sr,RY),e(RY,ymo),e(Sr,wmo),g(qM,Sr,null),e(zo,Amo),e(zo,Se),g(OM,Se,null),e(Se,Lmo),e(Se,SY),e(SY,Bmo),e(Se,kmo),e(Se,xa),e(xa,xmo),e(xa,PY),e(PY,Rmo),e(xa,Smo),e(xa,$Y),e($Y,Pmo),e(xa,$mo),e(xa,IY),e(IY,Imo),e(xa,jmo),e(Se,Nmo),e(Se,ne),e(ne,r_),e(r_,jY),e(jY,Dmo),e(r_,qmo),e(r_,MR),e(MR,Omo),e(r_,Gmo),e(ne,zmo),e(ne,t_),e(t_,NY),e(NY,Vmo),e(t_,Xmo),e(t_,yR),e(yR,Wmo),e(t_,Qmo),e(ne,Hmo),e(ne,a_),e(a_,DY),e(DY,Umo),e(a_,Jmo),e(a_,wR),e(wR,Ymo),e(a_,Kmo),e(ne,Zmo),e(ne,n_),e(n_,qY),e(qY,ego),e(n_,ogo),e(n_,AR),e(AR,rgo),e(n_,tgo),e(ne,ago),e(ne,s_),e(s_,OY),e(OY,ngo),e(s_,sgo),e(s_,LR),e(LR,lgo),e(s_,igo),e(ne,dgo),e(ne,l_),e(l_,GY),e(GY,cgo),e(l_,fgo),e(l_,BR),e(BR,mgo),e(l_,ggo),e(ne,hgo),e(ne,i_),e(i_,zY),e(zY,ugo),e(i_,pgo),e(i_,kR),e(kR,_go),e(i_,vgo),e(ne,bgo),e(ne,d_),e(d_,VY),e(VY,Tgo),e(d_,Fgo),e(d_,xR),e(xR,Cgo),e(d_,Ego),e(ne,Mgo),e(ne,c_),e(c_,XY),e(XY,ygo),e(c_,wgo),e(c_,RR),e(RR,Ago),e(c_,Lgo),e(ne,Bgo),e(ne,f_),e(f_,WY),e(WY,kgo),e(f_,xgo),e(f_,SR),e(SR,Rgo),e(f_,Sgo),e(ne,Pgo),e(ne,m_),e(m_,QY),e(QY,$go),e(m_,Igo),e(m_,PR),e(PR,jgo),e(m_,Ngo),e(ne,Dgo),e(ne,g_),e(g_,HY),e(HY,qgo),e(g_,Ogo),e(g_,$R),e($R,Ggo),e(g_,zgo),e(ne,Vgo),e(ne,h_),e(h_,UY),e(UY,Xgo),e(h_,Wgo),e(h_,IR),e(IR,Qgo),e(h_,Hgo),e(ne,Ugo),e(ne,u_),e(u_,JY),e(JY,Jgo),e(u_,Ygo),e(u_,jR),e(jR,Kgo),e(u_,Zgo),e(ne,eho),e(ne,p_),e(p_,YY),e(YY,oho),e(p_,rho),e(p_,NR),e(NR,tho),e(p_,aho),e(Se,nho),e(Se,__),e(__,sho),e(__,KY),e(KY,lho),e(__,iho),e(__,ZY),e(ZY,dho),e(Se,cho),e(Se,eK),e(eK,fho),e(Se,mho),g(GM,Se,null),v(d,Mwe,_),v(d,ki,_),e(ki,v_),e(v_,oK),g(zM,oK,null),e(ki,gho),e(ki,rK),e(rK,hho),v(d,ywe,_),v(d,Vo,_),g(VM,Vo,null),e(Vo,uho),e(Vo,xi),e(xi,pho),e(xi,tK),e(tK,_ho),e(xi,vho),e(xi,aK),e(aK,bho),e(xi,Tho),e(Vo,Fho),e(Vo,XM),e(XM,Cho),e(XM,nK),e(nK,Eho),e(XM,Mho),e(Vo,yho),e(Vo,Pr),g(WM,Pr,null),e(Pr,who),e(Pr,sK),e(sK,Aho),e(Pr,Lho),e(Pr,Ri),e(Ri,Bho),e(Ri,lK),e(lK,kho),e(Ri,xho),e(Ri,iK),e(iK,Rho),e(Ri,Sho),e(Pr,Pho),e(Pr,dK),e(dK,$ho),e(Pr,Iho),g(QM,Pr,null),e(Vo,jho),e(Vo,Pe),g(HM,Pe,null),e(Pe,Nho),e(Pe,cK),e(cK,Dho),e(Pe,qho),e(Pe,Ra),e(Ra,Oho),e(Ra,fK),e(fK,Gho),e(Ra,zho),e(Ra,mK),e(mK,Vho),e(Ra,Xho),e(Ra,gK),e(gK,Who),e(Ra,Qho),e(Pe,Hho),e(Pe,A),e(A,b_),e(b_,hK),e(hK,Uho),e(b_,Jho),e(b_,DR),e(DR,Yho),e(b_,Kho),e(A,Zho),e(A,T_),e(T_,uK),e(uK,euo),e(T_,ouo),e(T_,qR),e(qR,ruo),e(T_,tuo),e(A,auo),e(A,F_),e(F_,pK),e(pK,nuo),e(F_,suo),e(F_,OR),e(OR,luo),e(F_,iuo),e(A,duo),e(A,C_),e(C_,_K),e(_K,cuo),e(C_,fuo),e(C_,GR),e(GR,muo),e(C_,guo),e(A,huo),e(A,E_),e(E_,vK),e(vK,uuo),e(E_,puo),e(E_,zR),e(zR,_uo),e(E_,vuo),e(A,buo),e(A,M_),e(M_,bK),e(bK,Tuo),e(M_,Fuo),e(M_,VR),e(VR,Cuo),e(M_,Euo),e(A,Muo),e(A,y_),e(y_,TK),e(TK,yuo),e(y_,wuo),e(y_,XR),e(XR,Auo),e(y_,Luo),e(A,Buo),e(A,w_),e(w_,FK),e(FK,kuo),e(w_,xuo),e(w_,WR),e(WR,Ruo),e(w_,Suo),e(A,Puo),e(A,A_),e(A_,CK),e(CK,$uo),e(A_,Iuo),e(A_,QR),e(QR,juo),e(A_,Nuo),e(A,Duo),e(A,L_),e(L_,EK),e(EK,quo),e(L_,Ouo),e(L_,HR),e(HR,Guo),e(L_,zuo),e(A,Vuo),e(A,B_),e(B_,MK),e(MK,Xuo),e(B_,Wuo),e(B_,UR),e(UR,Quo),e(B_,Huo),e(A,Uuo),e(A,k_),e(k_,yK),e(yK,Juo),e(k_,Yuo),e(k_,JR),e(JR,Kuo),e(k_,Zuo),e(A,epo),e(A,x_),e(x_,wK),e(wK,opo),e(x_,rpo),e(x_,YR),e(YR,tpo),e(x_,apo),e(A,npo),e(A,R_),e(R_,AK),e(AK,spo),e(R_,lpo),e(R_,KR),e(KR,ipo),e(R_,dpo),e(A,cpo),e(A,S_),e(S_,LK),e(LK,fpo),e(S_,mpo),e(S_,ZR),e(ZR,gpo),e(S_,hpo),e(A,upo),e(A,P_),e(P_,BK),e(BK,ppo),e(P_,_po),e(P_,eS),e(eS,vpo),e(P_,bpo),e(A,Tpo),e(A,$_),e($_,kK),e(kK,Fpo),e($_,Cpo),e($_,oS),e(oS,Epo),e($_,Mpo),e(A,ypo),e(A,I_),e(I_,xK),e(xK,wpo),e(I_,Apo),e(I_,rS),e(rS,Lpo),e(I_,Bpo),e(A,kpo),e(A,j_),e(j_,RK),e(RK,xpo),e(j_,Rpo),e(j_,tS),e(tS,Spo),e(j_,Ppo),e(A,$po),e(A,N_),e(N_,SK),e(SK,Ipo),e(N_,jpo),e(N_,aS),e(aS,Npo),e(N_,Dpo),e(A,qpo),e(A,D_),e(D_,PK),e(PK,Opo),e(D_,Gpo),e(D_,nS),e(nS,zpo),e(D_,Vpo),e(A,Xpo),e(A,q_),e(q_,$K),e($K,Wpo),e(q_,Qpo),e(q_,sS),e(sS,Hpo),e(q_,Upo),e(A,Jpo),e(A,O_),e(O_,IK),e(IK,Ypo),e(O_,Kpo),e(O_,lS),e(lS,Zpo),e(O_,e_o),e(A,o_o),e(A,G_),e(G_,jK),e(jK,r_o),e(G_,t_o),e(G_,iS),e(iS,a_o),e(G_,n_o),e(A,s_o),e(A,z_),e(z_,NK),e(NK,l_o),e(z_,i_o),e(z_,dS),e(dS,d_o),e(z_,c_o),e(A,f_o),e(A,V_),e(V_,DK),e(DK,m_o),e(V_,g_o),e(V_,cS),e(cS,h_o),e(V_,u_o),e(A,p_o),e(A,X_),e(X_,qK),e(qK,__o),e(X_,v_o),e(X_,fS),e(fS,b_o),e(X_,T_o),e(A,F_o),e(A,W_),e(W_,OK),e(OK,C_o),e(W_,E_o),e(W_,mS),e(mS,M_o),e(W_,y_o),e(A,w_o),e(A,Q_),e(Q_,GK),e(GK,A_o),e(Q_,L_o),e(Q_,gS),e(gS,B_o),e(Q_,k_o),e(A,x_o),e(A,H_),e(H_,zK),e(zK,R_o),e(H_,S_o),e(H_,hS),e(hS,P_o),e(H_,$_o),e(A,I_o),e(A,U_),e(U_,VK),e(VK,j_o),e(U_,N_o),e(U_,uS),e(uS,D_o),e(U_,q_o),e(A,O_o),e(A,J_),e(J_,XK),e(XK,G_o),e(J_,z_o),e(J_,pS),e(pS,V_o),e(J_,X_o),e(A,W_o),e(A,Y_),e(Y_,WK),e(WK,Q_o),e(Y_,H_o),e(Y_,_S),e(_S,U_o),e(Y_,J_o),e(A,Y_o),e(A,K_),e(K_,QK),e(QK,K_o),e(K_,Z_o),e(K_,vS),e(vS,e2o),e(K_,o2o),e(A,r2o),e(A,Z_),e(Z_,HK),e(HK,t2o),e(Z_,a2o),e(Z_,bS),e(bS,n2o),e(Z_,s2o),e(A,l2o),e(A,e2),e(e2,UK),e(UK,i2o),e(e2,d2o),e(e2,TS),e(TS,c2o),e(e2,f2o),e(A,m2o),e(A,o2),e(o2,JK),e(JK,g2o),e(o2,h2o),e(o2,FS),e(FS,u2o),e(o2,p2o),e(A,_2o),e(A,r2),e(r2,YK),e(YK,v2o),e(r2,b2o),e(r2,CS),e(CS,T2o),e(r2,F2o),e(A,C2o),e(A,t2),e(t2,KK),e(KK,E2o),e(t2,M2o),e(t2,ES),e(ES,y2o),e(t2,w2o),e(A,A2o),e(A,a2),e(a2,ZK),e(ZK,L2o),e(a2,B2o),e(a2,MS),e(MS,k2o),e(a2,x2o),e(A,R2o),e(A,n2),e(n2,eZ),e(eZ,S2o),e(n2,P2o),e(n2,yS),e(yS,$2o),e(n2,I2o),e(A,j2o),e(A,s2),e(s2,oZ),e(oZ,N2o),e(s2,D2o),e(s2,wS),e(wS,q2o),e(s2,O2o),e(A,G2o),e(A,l2),e(l2,rZ),e(rZ,z2o),e(l2,V2o),e(l2,AS),e(AS,X2o),e(l2,W2o),e(Pe,Q2o),e(Pe,i2),e(i2,H2o),e(i2,tZ),e(tZ,U2o),e(i2,J2o),e(i2,aZ),e(aZ,Y2o),e(Pe,K2o),e(Pe,nZ),e(nZ,Z2o),e(Pe,evo),g(UM,Pe,null),v(d,wwe,_),v(d,Si,_),e(Si,d2),e(d2,sZ),g(JM,sZ,null),e(Si,ovo),e(Si,lZ),e(lZ,rvo),v(d,Awe,_),v(d,Xo,_),g(YM,Xo,null),e(Xo,tvo),e(Xo,Pi),e(Pi,avo),e(Pi,iZ),e(iZ,nvo),e(Pi,svo),e(Pi,dZ),e(dZ,lvo),e(Pi,ivo),e(Xo,dvo),e(Xo,KM),e(KM,cvo),e(KM,cZ),e(cZ,fvo),e(KM,mvo),e(Xo,gvo),e(Xo,$r),g(ZM,$r,null),e($r,hvo),e($r,fZ),e(fZ,uvo),e($r,pvo),e($r,$i),e($i,_vo),e($i,mZ),e(mZ,vvo),e($i,bvo),e($i,gZ),e(gZ,Tvo),e($i,Fvo),e($r,Cvo),e($r,hZ),e(hZ,Evo),e($r,Mvo),g(e3,$r,null),e(Xo,yvo),e(Xo,$e),g(o3,$e,null),e($e,wvo),e($e,uZ),e(uZ,Avo),e($e,Lvo),e($e,Sa),e(Sa,Bvo),e(Sa,pZ),e(pZ,kvo),e(Sa,xvo),e(Sa,_Z),e(_Z,Rvo),e(Sa,Svo),e(Sa,vZ),e(vZ,Pvo),e(Sa,$vo),e($e,Ivo),e($e,O),e(O,c2),e(c2,bZ),e(bZ,jvo),e(c2,Nvo),e(c2,LS),e(LS,Dvo),e(c2,qvo),e(O,Ovo),e(O,f2),e(f2,TZ),e(TZ,Gvo),e(f2,zvo),e(f2,BS),e(BS,Vvo),e(f2,Xvo),e(O,Wvo),e(O,m2),e(m2,FZ),e(FZ,Qvo),e(m2,Hvo),e(m2,kS),e(kS,Uvo),e(m2,Jvo),e(O,Yvo),e(O,g2),e(g2,CZ),e(CZ,Kvo),e(g2,Zvo),e(g2,xS),e(xS,e1o),e(g2,o1o),e(O,r1o),e(O,h2),e(h2,EZ),e(EZ,t1o),e(h2,a1o),e(h2,RS),e(RS,n1o),e(h2,s1o),e(O,l1o),e(O,u2),e(u2,MZ),e(MZ,i1o),e(u2,d1o),e(u2,SS),e(SS,c1o),e(u2,f1o),e(O,m1o),e(O,p2),e(p2,yZ),e(yZ,g1o),e(p2,h1o),e(p2,PS),e(PS,u1o),e(p2,p1o),e(O,_1o),e(O,_2),e(_2,wZ),e(wZ,v1o),e(_2,b1o),e(_2,$S),e($S,T1o),e(_2,F1o),e(O,C1o),e(O,v2),e(v2,AZ),e(AZ,E1o),e(v2,M1o),e(v2,IS),e(IS,y1o),e(v2,w1o),e(O,A1o),e(O,b2),e(b2,LZ),e(LZ,L1o),e(b2,B1o),e(b2,jS),e(jS,k1o),e(b2,x1o),e(O,R1o),e(O,T2),e(T2,BZ),e(BZ,S1o),e(T2,P1o),e(T2,NS),e(NS,$1o),e(T2,I1o),e(O,j1o),e(O,F2),e(F2,kZ),e(kZ,N1o),e(F2,D1o),e(F2,DS),e(DS,q1o),e(F2,O1o),e(O,G1o),e(O,C2),e(C2,xZ),e(xZ,z1o),e(C2,V1o),e(C2,qS),e(qS,X1o),e(C2,W1o),e(O,Q1o),e(O,E2),e(E2,RZ),e(RZ,H1o),e(E2,U1o),e(E2,OS),e(OS,J1o),e(E2,Y1o),e(O,K1o),e(O,M2),e(M2,SZ),e(SZ,Z1o),e(M2,e4o),e(M2,GS),e(GS,o4o),e(M2,r4o),e(O,t4o),e(O,y2),e(y2,PZ),e(PZ,a4o),e(y2,n4o),e(y2,zS),e(zS,s4o),e(y2,l4o),e(O,i4o),e(O,w2),e(w2,$Z),e($Z,d4o),e(w2,c4o),e(w2,VS),e(VS,f4o),e(w2,m4o),e(O,g4o),e(O,A2),e(A2,IZ),e(IZ,h4o),e(A2,u4o),e(A2,XS),e(XS,p4o),e(A2,_4o),e(O,v4o),e(O,L2),e(L2,jZ),e(jZ,b4o),e(L2,T4o),e(L2,WS),e(WS,F4o),e(L2,C4o),e(O,E4o),e(O,B2),e(B2,NZ),e(NZ,M4o),e(B2,y4o),e(B2,QS),e(QS,w4o),e(B2,A4o),e(O,L4o),e(O,k2),e(k2,DZ),e(DZ,B4o),e(k2,k4o),e(k2,HS),e(HS,x4o),e(k2,R4o),e(O,S4o),e(O,x2),e(x2,qZ),e(qZ,P4o),e(x2,$4o),e(x2,US),e(US,I4o),e(x2,j4o),e(O,N4o),e(O,R2),e(R2,OZ),e(OZ,D4o),e(R2,q4o),e(R2,JS),e(JS,O4o),e(R2,G4o),e(O,z4o),e(O,S2),e(S2,GZ),e(GZ,V4o),e(S2,X4o),e(S2,YS),e(YS,W4o),e(S2,Q4o),e(O,H4o),e(O,P2),e(P2,zZ),e(zZ,U4o),e(P2,J4o),e(P2,KS),e(KS,Y4o),e(P2,K4o),e(O,Z4o),e(O,$2),e($2,VZ),e(VZ,ebo),e($2,obo),e($2,ZS),e(ZS,rbo),e($2,tbo),e($e,abo),e($e,I2),e(I2,nbo),e(I2,XZ),e(XZ,sbo),e(I2,lbo),e(I2,WZ),e(WZ,ibo),e($e,dbo),e($e,QZ),e(QZ,cbo),e($e,fbo),g(r3,$e,null),v(d,Lwe,_),v(d,Ii,_),e(Ii,j2),e(j2,HZ),g(t3,HZ,null),e(Ii,mbo),e(Ii,UZ),e(UZ,gbo),v(d,Bwe,_),v(d,Wo,_),g(a3,Wo,null),e(Wo,hbo),e(Wo,ji),e(ji,ubo),e(ji,JZ),e(JZ,pbo),e(ji,_bo),e(ji,YZ),e(YZ,vbo),e(ji,bbo),e(Wo,Tbo),e(Wo,n3),e(n3,Fbo),e(n3,KZ),e(KZ,Cbo),e(n3,Ebo),e(Wo,Mbo),e(Wo,Ir),g(s3,Ir,null),e(Ir,ybo),e(Ir,ZZ),e(ZZ,wbo),e(Ir,Abo),e(Ir,Ni),e(Ni,Lbo),e(Ni,eee),e(eee,Bbo),e(Ni,kbo),e(Ni,oee),e(oee,xbo),e(Ni,Rbo),e(Ir,Sbo),e(Ir,ree),e(ree,Pbo),e(Ir,$bo),g(l3,Ir,null),e(Wo,Ibo),e(Wo,Ie),g(i3,Ie,null),e(Ie,jbo),e(Ie,tee),e(tee,Nbo),e(Ie,Dbo),e(Ie,Pa),e(Pa,qbo),e(Pa,aee),e(aee,Obo),e(Pa,Gbo),e(Pa,nee),e(nee,zbo),e(Pa,Vbo),e(Pa,see),e(see,Xbo),e(Pa,Wbo),e(Ie,Qbo),e(Ie,Ht),e(Ht,N2),e(N2,lee),e(lee,Hbo),e(N2,Ubo),e(N2,eP),e(eP,Jbo),e(N2,Ybo),e(Ht,Kbo),e(Ht,D2),e(D2,iee),e(iee,Zbo),e(D2,eTo),e(D2,oP),e(oP,oTo),e(D2,rTo),e(Ht,tTo),e(Ht,q2),e(q2,dee),e(dee,aTo),e(q2,nTo),e(q2,rP),e(rP,sTo),e(q2,lTo),e(Ht,iTo),e(Ht,O2),e(O2,cee),e(cee,dTo),e(O2,cTo),e(O2,tP),e(tP,fTo),e(O2,mTo),e(Ht,gTo),e(Ht,G2),e(G2,fee),e(fee,hTo),e(G2,uTo),e(G2,aP),e(aP,pTo),e(G2,_To),e(Ie,vTo),e(Ie,z2),e(z2,bTo),e(z2,mee),e(mee,TTo),e(z2,FTo),e(z2,gee),e(gee,CTo),e(Ie,ETo),e(Ie,hee),e(hee,MTo),e(Ie,yTo),g(d3,Ie,null),v(d,kwe,_),v(d,Di,_),e(Di,V2),e(V2,uee),g(c3,uee,null),e(Di,wTo),e(Di,pee),e(pee,ATo),v(d,xwe,_),v(d,Qo,_),g(f3,Qo,null),e(Qo,LTo),e(Qo,qi),e(qi,BTo),e(qi,_ee),e(_ee,kTo),e(qi,xTo),e(qi,vee),e(vee,RTo),e(qi,STo),e(Qo,PTo),e(Qo,m3),e(m3,$To),e(m3,bee),e(bee,ITo),e(m3,jTo),e(Qo,NTo),e(Qo,jr),g(g3,jr,null),e(jr,DTo),e(jr,Tee),e(Tee,qTo),e(jr,OTo),e(jr,Oi),e(Oi,GTo),e(Oi,Fee),e(Fee,zTo),e(Oi,VTo),e(Oi,Cee),e(Cee,XTo),e(Oi,WTo),e(jr,QTo),e(jr,Eee),e(Eee,HTo),e(jr,UTo),g(h3,jr,null),e(Qo,JTo),e(Qo,je),g(u3,je,null),e(je,YTo),e(je,Mee),e(Mee,KTo),e(je,ZTo),e(je,$a),e($a,e6o),e($a,yee),e(yee,o6o),e($a,r6o),e($a,wee),e(wee,t6o),e($a,a6o),e($a,Aee),e(Aee,n6o),e($a,s6o),e(je,l6o),e(je,N),e(N,X2),e(X2,Lee),e(Lee,i6o),e(X2,d6o),e(X2,nP),e(nP,c6o),e(X2,f6o),e(N,m6o),e(N,W2),e(W2,Bee),e(Bee,g6o),e(W2,h6o),e(W2,sP),e(sP,u6o),e(W2,p6o),e(N,_6o),e(N,Q2),e(Q2,kee),e(kee,v6o),e(Q2,b6o),e(Q2,lP),e(lP,T6o),e(Q2,F6o),e(N,C6o),e(N,H2),e(H2,xee),e(xee,E6o),e(H2,M6o),e(H2,iP),e(iP,y6o),e(H2,w6o),e(N,A6o),e(N,U2),e(U2,Ree),e(Ree,L6o),e(U2,B6o),e(U2,dP),e(dP,k6o),e(U2,x6o),e(N,R6o),e(N,J2),e(J2,See),e(See,S6o),e(J2,P6o),e(J2,cP),e(cP,$6o),e(J2,I6o),e(N,j6o),e(N,Y2),e(Y2,Pee),e(Pee,N6o),e(Y2,D6o),e(Y2,fP),e(fP,q6o),e(Y2,O6o),e(N,G6o),e(N,K2),e(K2,$ee),e($ee,z6o),e(K2,V6o),e(K2,mP),e(mP,X6o),e(K2,W6o),e(N,Q6o),e(N,Z2),e(Z2,Iee),e(Iee,H6o),e(Z2,U6o),e(Z2,gP),e(gP,J6o),e(Z2,Y6o),e(N,K6o),e(N,ev),e(ev,jee),e(jee,Z6o),e(ev,eFo),e(ev,hP),e(hP,oFo),e(ev,rFo),e(N,tFo),e(N,ov),e(ov,Nee),e(Nee,aFo),e(ov,nFo),e(ov,uP),e(uP,sFo),e(ov,lFo),e(N,iFo),e(N,rv),e(rv,Dee),e(Dee,dFo),e(rv,cFo),e(rv,pP),e(pP,fFo),e(rv,mFo),e(N,gFo),e(N,tv),e(tv,qee),e(qee,hFo),e(tv,uFo),e(tv,_P),e(_P,pFo),e(tv,_Fo),e(N,vFo),e(N,av),e(av,Oee),e(Oee,bFo),e(av,TFo),e(av,vP),e(vP,FFo),e(av,CFo),e(N,EFo),e(N,nv),e(nv,Gee),e(Gee,MFo),e(nv,yFo),e(nv,bP),e(bP,wFo),e(nv,AFo),e(N,LFo),e(N,sv),e(sv,zee),e(zee,BFo),e(sv,kFo),e(sv,TP),e(TP,xFo),e(sv,RFo),e(N,SFo),e(N,lv),e(lv,Vee),e(Vee,PFo),e(lv,$Fo),e(lv,FP),e(FP,IFo),e(lv,jFo),e(N,NFo),e(N,iv),e(iv,Xee),e(Xee,DFo),e(iv,qFo),e(iv,CP),e(CP,OFo),e(iv,GFo),e(N,zFo),e(N,dv),e(dv,Wee),e(Wee,VFo),e(dv,XFo),e(dv,EP),e(EP,WFo),e(dv,QFo),e(N,HFo),e(N,cv),e(cv,Qee),e(Qee,UFo),e(cv,JFo),e(cv,MP),e(MP,YFo),e(cv,KFo),e(N,ZFo),e(N,fv),e(fv,Hee),e(Hee,eCo),e(fv,oCo),e(fv,yP),e(yP,rCo),e(fv,tCo),e(N,aCo),e(N,mv),e(mv,Uee),e(Uee,nCo),e(mv,sCo),e(mv,wP),e(wP,lCo),e(mv,iCo),e(N,dCo),e(N,gv),e(gv,Jee),e(Jee,cCo),e(gv,fCo),e(gv,AP),e(AP,mCo),e(gv,gCo),e(N,hCo),e(N,hv),e(hv,Yee),e(Yee,uCo),e(hv,pCo),e(hv,LP),e(LP,_Co),e(hv,vCo),e(N,bCo),e(N,uv),e(uv,Kee),e(Kee,TCo),e(uv,FCo),e(uv,BP),e(BP,CCo),e(uv,ECo),e(N,MCo),e(N,pv),e(pv,Zee),e(Zee,yCo),e(pv,wCo),e(pv,kP),e(kP,ACo),e(pv,LCo),e(N,BCo),e(N,_v),e(_v,eoe),e(eoe,kCo),e(_v,xCo),e(_v,xP),e(xP,RCo),e(_v,SCo),e(N,PCo),e(N,vv),e(vv,ooe),e(ooe,$Co),e(vv,ICo),e(vv,RP),e(RP,jCo),e(vv,NCo),e(N,DCo),e(N,bv),e(bv,roe),e(roe,qCo),e(bv,OCo),e(bv,SP),e(SP,GCo),e(bv,zCo),e(N,VCo),e(N,Tv),e(Tv,toe),e(toe,XCo),e(Tv,WCo),e(Tv,PP),e(PP,QCo),e(Tv,HCo),e(N,UCo),e(N,Fv),e(Fv,aoe),e(aoe,JCo),e(Fv,YCo),e(Fv,$P),e($P,KCo),e(Fv,ZCo),e(je,eEo),e(je,Cv),e(Cv,oEo),e(Cv,noe),e(noe,rEo),e(Cv,tEo),e(Cv,soe),e(soe,aEo),e(je,nEo),e(je,loe),e(loe,sEo),e(je,lEo),g(p3,je,null),v(d,Rwe,_),v(d,Gi,_),e(Gi,Ev),e(Ev,ioe),g(_3,ioe,null),e(Gi,iEo),e(Gi,doe),e(doe,dEo),v(d,Swe,_),v(d,Ho,_),g(v3,Ho,null),e(Ho,cEo),e(Ho,zi),e(zi,fEo),e(zi,coe),e(coe,mEo),e(zi,gEo),e(zi,foe),e(foe,hEo),e(zi,uEo),e(Ho,pEo),e(Ho,b3),e(b3,_Eo),e(b3,moe),e(moe,vEo),e(b3,bEo),e(Ho,TEo),e(Ho,Nr),g(T3,Nr,null),e(Nr,FEo),e(Nr,goe),e(goe,CEo),e(Nr,EEo),e(Nr,Vi),e(Vi,MEo),e(Vi,hoe),e(hoe,yEo),e(Vi,wEo),e(Vi,uoe),e(uoe,AEo),e(Vi,LEo),e(Nr,BEo),e(Nr,poe),e(poe,kEo),e(Nr,xEo),g(F3,Nr,null),e(Ho,REo),e(Ho,Ne),g(C3,Ne,null),e(Ne,SEo),e(Ne,_oe),e(_oe,PEo),e(Ne,$Eo),e(Ne,Ia),e(Ia,IEo),e(Ia,voe),e(voe,jEo),e(Ia,NEo),e(Ia,boe),e(boe,DEo),e(Ia,qEo),e(Ia,Toe),e(Toe,OEo),e(Ia,GEo),e(Ne,zEo),e(Ne,R),e(R,Mv),e(Mv,Foe),e(Foe,VEo),e(Mv,XEo),e(Mv,IP),e(IP,WEo),e(Mv,QEo),e(R,HEo),e(R,yv),e(yv,Coe),e(Coe,UEo),e(yv,JEo),e(yv,jP),e(jP,YEo),e(yv,KEo),e(R,ZEo),e(R,wv),e(wv,Eoe),e(Eoe,eMo),e(wv,oMo),e(wv,NP),e(NP,rMo),e(wv,tMo),e(R,aMo),e(R,Av),e(Av,Moe),e(Moe,nMo),e(Av,sMo),e(Av,DP),e(DP,lMo),e(Av,iMo),e(R,dMo),e(R,Lv),e(Lv,yoe),e(yoe,cMo),e(Lv,fMo),e(Lv,qP),e(qP,mMo),e(Lv,gMo),e(R,hMo),e(R,Bv),e(Bv,woe),e(woe,uMo),e(Bv,pMo),e(Bv,OP),e(OP,_Mo),e(Bv,vMo),e(R,bMo),e(R,kv),e(kv,Aoe),e(Aoe,TMo),e(kv,FMo),e(kv,GP),e(GP,CMo),e(kv,EMo),e(R,MMo),e(R,xv),e(xv,Loe),e(Loe,yMo),e(xv,wMo),e(xv,zP),e(zP,AMo),e(xv,LMo),e(R,BMo),e(R,Rv),e(Rv,Boe),e(Boe,kMo),e(Rv,xMo),e(Rv,VP),e(VP,RMo),e(Rv,SMo),e(R,PMo),e(R,Sv),e(Sv,koe),e(koe,$Mo),e(Sv,IMo),e(Sv,XP),e(XP,jMo),e(Sv,NMo),e(R,DMo),e(R,Pv),e(Pv,xoe),e(xoe,qMo),e(Pv,OMo),e(Pv,WP),e(WP,GMo),e(Pv,zMo),e(R,VMo),e(R,$v),e($v,Roe),e(Roe,XMo),e($v,WMo),e($v,QP),e(QP,QMo),e($v,HMo),e(R,UMo),e(R,Iv),e(Iv,Soe),e(Soe,JMo),e(Iv,YMo),e(Iv,HP),e(HP,KMo),e(Iv,ZMo),e(R,e3o),e(R,jv),e(jv,Poe),e(Poe,o3o),e(jv,r3o),e(jv,UP),e(UP,t3o),e(jv,a3o),e(R,n3o),e(R,Nv),e(Nv,$oe),e($oe,s3o),e(Nv,l3o),e(Nv,JP),e(JP,i3o),e(Nv,d3o),e(R,c3o),e(R,Dv),e(Dv,Ioe),e(Ioe,f3o),e(Dv,m3o),e(Dv,YP),e(YP,g3o),e(Dv,h3o),e(R,u3o),e(R,qv),e(qv,joe),e(joe,p3o),e(qv,_3o),e(qv,KP),e(KP,v3o),e(qv,b3o),e(R,T3o),e(R,Ov),e(Ov,Noe),e(Noe,F3o),e(Ov,C3o),e(Ov,ZP),e(ZP,E3o),e(Ov,M3o),e(R,y3o),e(R,Gv),e(Gv,Doe),e(Doe,w3o),e(Gv,A3o),e(Gv,e$),e(e$,L3o),e(Gv,B3o),e(R,k3o),e(R,zv),e(zv,qoe),e(qoe,x3o),e(zv,R3o),e(zv,o$),e(o$,S3o),e(zv,P3o),e(R,$3o),e(R,Vv),e(Vv,Ooe),e(Ooe,I3o),e(Vv,j3o),e(Vv,r$),e(r$,N3o),e(Vv,D3o),e(R,q3o),e(R,Xv),e(Xv,Goe),e(Goe,O3o),e(Xv,G3o),e(Xv,t$),e(t$,z3o),e(Xv,V3o),e(R,X3o),e(R,Wv),e(Wv,zoe),e(zoe,W3o),e(Wv,Q3o),e(Wv,a$),e(a$,H3o),e(Wv,U3o),e(R,J3o),e(R,Qv),e(Qv,Voe),e(Voe,Y3o),e(Qv,K3o),e(Qv,n$),e(n$,Z3o),e(Qv,e5o),e(R,o5o),e(R,Hv),e(Hv,Xoe),e(Xoe,r5o),e(Hv,t5o),e(Hv,s$),e(s$,a5o),e(Hv,n5o),e(R,s5o),e(R,Uv),e(Uv,Woe),e(Woe,l5o),e(Uv,i5o),e(Uv,l$),e(l$,d5o),e(Uv,c5o),e(R,f5o),e(R,Jv),e(Jv,Qoe),e(Qoe,m5o),e(Jv,g5o),e(Jv,i$),e(i$,h5o),e(Jv,u5o),e(R,p5o),e(R,Yv),e(Yv,Hoe),e(Hoe,_5o),e(Yv,v5o),e(Yv,d$),e(d$,b5o),e(Yv,T5o),e(R,F5o),e(R,Kv),e(Kv,Uoe),e(Uoe,C5o),e(Kv,E5o),e(Kv,c$),e(c$,M5o),e(Kv,y5o),e(R,w5o),e(R,Zv),e(Zv,Joe),e(Joe,A5o),e(Zv,L5o),e(Zv,f$),e(f$,B5o),e(Zv,k5o),e(R,x5o),e(R,e1),e(e1,Yoe),e(Yoe,R5o),e(e1,S5o),e(e1,m$),e(m$,P5o),e(e1,$5o),e(R,I5o),e(R,o1),e(o1,Koe),e(Koe,j5o),e(o1,N5o),e(o1,g$),e(g$,D5o),e(o1,q5o),e(R,O5o),e(R,r1),e(r1,Zoe),e(Zoe,G5o),e(r1,z5o),e(r1,h$),e(h$,V5o),e(r1,X5o),e(R,W5o),e(R,t1),e(t1,ere),e(ere,Q5o),e(t1,H5o),e(t1,u$),e(u$,U5o),e(t1,J5o),e(R,Y5o),e(R,a1),e(a1,ore),e(ore,K5o),e(a1,Z5o),e(a1,p$),e(p$,eyo),e(a1,oyo),e(R,ryo),e(R,n1),e(n1,rre),e(rre,tyo),e(n1,ayo),e(n1,_$),e(_$,nyo),e(n1,syo),e(R,lyo),e(R,s1),e(s1,tre),e(tre,iyo),e(s1,dyo),e(s1,v$),e(v$,cyo),e(s1,fyo),e(Ne,myo),e(Ne,l1),e(l1,gyo),e(l1,are),e(are,hyo),e(l1,uyo),e(l1,nre),e(nre,pyo),e(Ne,_yo),e(Ne,sre),e(sre,vyo),e(Ne,byo),g(E3,Ne,null),v(d,Pwe,_),v(d,Xi,_),e(Xi,i1),e(i1,lre),g(M3,lre,null),e(Xi,Tyo),e(Xi,ire),e(ire,Fyo),v(d,$we,_),v(d,Uo,_),g(y3,Uo,null),e(Uo,Cyo),e(Uo,Wi),e(Wi,Eyo),e(Wi,dre),e(dre,Myo),e(Wi,yyo),e(Wi,cre),e(cre,wyo),e(Wi,Ayo),e(Uo,Lyo),e(Uo,w3),e(w3,Byo),e(w3,fre),e(fre,kyo),e(w3,xyo),e(Uo,Ryo),e(Uo,Dr),g(A3,Dr,null),e(Dr,Syo),e(Dr,mre),e(mre,Pyo),e(Dr,$yo),e(Dr,Qi),e(Qi,Iyo),e(Qi,gre),e(gre,jyo),e(Qi,Nyo),e(Qi,hre),e(hre,Dyo),e(Qi,qyo),e(Dr,Oyo),e(Dr,ure),e(ure,Gyo),e(Dr,zyo),g(L3,Dr,null),e(Uo,Vyo),e(Uo,De),g(B3,De,null),e(De,Xyo),e(De,pre),e(pre,Wyo),e(De,Qyo),e(De,ja),e(ja,Hyo),e(ja,_re),e(_re,Uyo),e(ja,Jyo),e(ja,vre),e(vre,Yyo),e(ja,Kyo),e(ja,bre),e(bre,Zyo),e(ja,ewo),e(De,owo),e(De,Tre),e(Tre,d1),e(d1,Fre),e(Fre,rwo),e(d1,two),e(d1,b$),e(b$,awo),e(d1,nwo),e(De,swo),e(De,c1),e(c1,lwo),e(c1,Cre),e(Cre,iwo),e(c1,dwo),e(c1,Ere),e(Ere,cwo),e(De,fwo),e(De,Mre),e(Mre,mwo),e(De,gwo),g(k3,De,null),v(d,Iwe,_),v(d,Hi,_),e(Hi,f1),e(f1,yre),g(x3,yre,null),e(Hi,hwo),e(Hi,wre),e(wre,uwo),v(d,jwe,_),v(d,Jo,_),g(R3,Jo,null),e(Jo,pwo),e(Jo,Ui),e(Ui,_wo),e(Ui,Are),e(Are,vwo),e(Ui,bwo),e(Ui,Lre),e(Lre,Two),e(Ui,Fwo),e(Jo,Cwo),e(Jo,S3),e(S3,Ewo),e(S3,Bre),e(Bre,Mwo),e(S3,ywo),e(Jo,wwo),e(Jo,qr),g(P3,qr,null),e(qr,Awo),e(qr,kre),e(kre,Lwo),e(qr,Bwo),e(qr,Ji),e(Ji,kwo),e(Ji,xre),e(xre,xwo),e(Ji,Rwo),e(Ji,Rre),e(Rre,Swo),e(Ji,Pwo),e(qr,$wo),e(qr,Sre),e(Sre,Iwo),e(qr,jwo),g($3,qr,null),e(Jo,Nwo),e(Jo,qe),g(I3,qe,null),e(qe,Dwo),e(qe,Pre),e(Pre,qwo),e(qe,Owo),e(qe,Na),e(Na,Gwo),e(Na,$re),e($re,zwo),e(Na,Vwo),e(Na,Ire),e(Ire,Xwo),e(Na,Wwo),e(Na,jre),e(jre,Qwo),e(Na,Hwo),e(qe,Uwo),e(qe,eo),e(eo,m1),e(m1,Nre),e(Nre,Jwo),e(m1,Ywo),e(m1,T$),e(T$,Kwo),e(m1,Zwo),e(eo,eAo),e(eo,us),e(us,Dre),e(Dre,oAo),e(us,rAo),e(us,F$),e(F$,tAo),e(us,aAo),e(us,C$),e(C$,nAo),e(us,sAo),e(eo,lAo),e(eo,g1),e(g1,qre),e(qre,iAo),e(g1,dAo),e(g1,E$),e(E$,cAo),e(g1,fAo),e(eo,mAo),e(eo,Jt),e(Jt,Ore),e(Ore,gAo),e(Jt,hAo),e(Jt,M$),e(M$,uAo),e(Jt,pAo),e(Jt,y$),e(y$,_Ao),e(Jt,vAo),e(Jt,w$),e(w$,bAo),e(Jt,TAo),e(eo,FAo),e(eo,h1),e(h1,Gre),e(Gre,CAo),e(h1,EAo),e(h1,A$),e(A$,MAo),e(h1,yAo),e(eo,wAo),e(eo,u1),e(u1,zre),e(zre,AAo),e(u1,LAo),e(u1,L$),e(L$,BAo),e(u1,kAo),e(eo,xAo),e(eo,p1),e(p1,Vre),e(Vre,RAo),e(p1,SAo),e(p1,B$),e(B$,PAo),e(p1,$Ao),e(qe,IAo),e(qe,_1),e(_1,jAo),e(_1,Xre),e(Xre,NAo),e(_1,DAo),e(_1,Wre),e(Wre,qAo),e(qe,OAo),e(qe,Qre),e(Qre,GAo),e(qe,zAo),g(j3,qe,null),v(d,Nwe,_),v(d,Yi,_),e(Yi,v1),e(v1,Hre),g(N3,Hre,null),e(Yi,VAo),e(Yi,Ure),e(Ure,XAo),v(d,Dwe,_),v(d,Yo,_),g(D3,Yo,null),e(Yo,WAo),e(Yo,Ki),e(Ki,QAo),e(Ki,Jre),e(Jre,HAo),e(Ki,UAo),e(Ki,Yre),e(Yre,JAo),e(Ki,YAo),e(Yo,KAo),e(Yo,q3),e(q3,ZAo),e(q3,Kre),e(Kre,e0o),e(q3,o0o),e(Yo,r0o),e(Yo,Or),g(O3,Or,null),e(Or,t0o),e(Or,Zre),e(Zre,a0o),e(Or,n0o),e(Or,Zi),e(Zi,s0o),e(Zi,ete),e(ete,l0o),e(Zi,i0o),e(Zi,ote),e(ote,d0o),e(Zi,c0o),e(Or,f0o),e(Or,rte),e(rte,m0o),e(Or,g0o),g(G3,Or,null),e(Yo,h0o),e(Yo,Oe),g(z3,Oe,null),e(Oe,u0o),e(Oe,tte),e(tte,p0o),e(Oe,_0o),e(Oe,Da),e(Da,v0o),e(Da,ate),e(ate,b0o),e(Da,T0o),e(Da,nte),e(nte,F0o),e(Da,C0o),e(Da,ste),e(ste,E0o),e(Da,M0o),e(Oe,y0o),e(Oe,lte),e(lte,b1),e(b1,ite),e(ite,w0o),e(b1,A0o),e(b1,k$),e(k$,L0o),e(b1,B0o),e(Oe,k0o),e(Oe,T1),e(T1,x0o),e(T1,dte),e(dte,R0o),e(T1,S0o),e(T1,cte),e(cte,P0o),e(Oe,$0o),e(Oe,fte),e(fte,I0o),e(Oe,j0o),g(V3,Oe,null),v(d,qwe,_),v(d,ed,_),e(ed,F1),e(F1,mte),g(X3,mte,null),e(ed,N0o),e(ed,gte),e(gte,D0o),v(d,Owe,_),v(d,Ko,_),g(W3,Ko,null),e(Ko,q0o),e(Ko,od),e(od,O0o),e(od,hte),e(hte,G0o),e(od,z0o),e(od,ute),e(ute,V0o),e(od,X0o),e(Ko,W0o),e(Ko,Q3),e(Q3,Q0o),e(Q3,pte),e(pte,H0o),e(Q3,U0o),e(Ko,J0o),e(Ko,Gr),g(H3,Gr,null),e(Gr,Y0o),e(Gr,_te),e(_te,K0o),e(Gr,Z0o),e(Gr,rd),e(rd,e7o),e(rd,vte),e(vte,o7o),e(rd,r7o),e(rd,bte),e(bte,t7o),e(rd,a7o),e(Gr,n7o),e(Gr,Tte),e(Tte,s7o),e(Gr,l7o),g(U3,Gr,null),e(Ko,i7o),e(Ko,Ge),g(J3,Ge,null),e(Ge,d7o),e(Ge,Fte),e(Fte,c7o),e(Ge,f7o),e(Ge,qa),e(qa,m7o),e(qa,Cte),e(Cte,g7o),e(qa,h7o),e(qa,Ete),e(Ete,u7o),e(qa,p7o),e(qa,Mte),e(Mte,_7o),e(qa,v7o),e(Ge,b7o),e(Ge,oo),e(oo,C1),e(C1,yte),e(yte,T7o),e(C1,F7o),e(C1,x$),e(x$,C7o),e(C1,E7o),e(oo,M7o),e(oo,E1),e(E1,wte),e(wte,y7o),e(E1,w7o),e(E1,R$),e(R$,A7o),e(E1,L7o),e(oo,B7o),e(oo,M1),e(M1,Ate),e(Ate,k7o),e(M1,x7o),e(M1,S$),e(S$,R7o),e(M1,S7o),e(oo,P7o),e(oo,y1),e(y1,Lte),e(Lte,$7o),e(y1,I7o),e(y1,P$),e(P$,j7o),e(y1,N7o),e(oo,D7o),e(oo,w1),e(w1,Bte),e(Bte,q7o),e(w1,O7o),e(w1,$$),e($$,G7o),e(w1,z7o),e(oo,V7o),e(oo,A1),e(A1,kte),e(kte,X7o),e(A1,W7o),e(A1,I$),e(I$,Q7o),e(A1,H7o),e(oo,U7o),e(oo,L1),e(L1,xte),e(xte,J7o),e(L1,Y7o),e(L1,j$),e(j$,K7o),e(L1,Z7o),e(Ge,eLo),e(Ge,B1),e(B1,oLo),e(B1,Rte),e(Rte,rLo),e(B1,tLo),e(B1,Ste),e(Ste,aLo),e(Ge,nLo),e(Ge,Pte),e(Pte,sLo),e(Ge,lLo),g(Y3,Ge,null),v(d,Gwe,_),v(d,td,_),e(td,k1),e(k1,$te),g(K3,$te,null),e(td,iLo),e(td,Ite),e(Ite,dLo),v(d,zwe,_),v(d,Zo,_),g(Z3,Zo,null),e(Zo,cLo),e(Zo,ad),e(ad,fLo),e(ad,jte),e(jte,mLo),e(ad,gLo),e(ad,Nte),e(Nte,hLo),e(ad,uLo),e(Zo,pLo),e(Zo,e5),e(e5,_Lo),e(e5,Dte),e(Dte,vLo),e(e5,bLo),e(Zo,TLo),e(Zo,zr),g(o5,zr,null),e(zr,FLo),e(zr,qte),e(qte,CLo),e(zr,ELo),e(zr,nd),e(nd,MLo),e(nd,Ote),e(Ote,yLo),e(nd,wLo),e(nd,Gte),e(Gte,ALo),e(nd,LLo),e(zr,BLo),e(zr,zte),e(zte,kLo),e(zr,xLo),g(r5,zr,null),e(Zo,RLo),e(Zo,ze),g(t5,ze,null),e(ze,SLo),e(ze,Vte),e(Vte,PLo),e(ze,$Lo),e(ze,Oa),e(Oa,ILo),e(Oa,Xte),e(Xte,jLo),e(Oa,NLo),e(Oa,Wte),e(Wte,DLo),e(Oa,qLo),e(Oa,Qte),e(Qte,OLo),e(Oa,GLo),e(ze,zLo),e(ze,sd),e(sd,x1),e(x1,Hte),e(Hte,VLo),e(x1,XLo),e(x1,N$),e(N$,WLo),e(x1,QLo),e(sd,HLo),e(sd,R1),e(R1,Ute),e(Ute,ULo),e(R1,JLo),e(R1,D$),e(D$,YLo),e(R1,KLo),e(sd,ZLo),e(sd,S1),e(S1,Jte),e(Jte,e8o),e(S1,o8o),e(S1,q$),e(q$,r8o),e(S1,t8o),e(ze,a8o),e(ze,P1),e(P1,n8o),e(P1,Yte),e(Yte,s8o),e(P1,l8o),e(P1,Kte),e(Kte,i8o),e(ze,d8o),e(ze,Zte),e(Zte,c8o),e(ze,f8o),g(a5,ze,null),v(d,Vwe,_),v(d,ld,_),e(ld,$1),e($1,eae),g(n5,eae,null),e(ld,m8o),e(ld,oae),e(oae,g8o),v(d,Xwe,_),v(d,er,_),g(s5,er,null),e(er,h8o),e(er,id),e(id,u8o),e(id,rae),e(rae,p8o),e(id,_8o),e(id,tae),e(tae,v8o),e(id,b8o),e(er,T8o),e(er,l5),e(l5,F8o),e(l5,aae),e(aae,C8o),e(l5,E8o),e(er,M8o),e(er,Vr),g(i5,Vr,null),e(Vr,y8o),e(Vr,nae),e(nae,w8o),e(Vr,A8o),e(Vr,dd),e(dd,L8o),e(dd,sae),e(sae,B8o),e(dd,k8o),e(dd,lae),e(lae,x8o),e(dd,R8o),e(Vr,S8o),e(Vr,iae),e(iae,P8o),e(Vr,$8o),g(d5,Vr,null),e(er,I8o),e(er,Ve),g(c5,Ve,null),e(Ve,j8o),e(Ve,dae),e(dae,N8o),e(Ve,D8o),e(Ve,Ga),e(Ga,q8o),e(Ga,cae),e(cae,O8o),e(Ga,G8o),e(Ga,fae),e(fae,z8o),e(Ga,V8o),e(Ga,mae),e(mae,X8o),e(Ga,W8o),e(Ve,Q8o),e(Ve,ro),e(ro,I1),e(I1,gae),e(gae,H8o),e(I1,U8o),e(I1,O$),e(O$,J8o),e(I1,Y8o),e(ro,K8o),e(ro,j1),e(j1,hae),e(hae,Z8o),e(j1,eBo),e(j1,G$),e(G$,oBo),e(j1,rBo),e(ro,tBo),e(ro,N1),e(N1,uae),e(uae,aBo),e(N1,nBo),e(N1,z$),e(z$,sBo),e(N1,lBo),e(ro,iBo),e(ro,D1),e(D1,pae),e(pae,dBo),e(D1,cBo),e(D1,V$),e(V$,fBo),e(D1,mBo),e(ro,gBo),e(ro,q1),e(q1,_ae),e(_ae,hBo),e(q1,uBo),e(q1,X$),e(X$,pBo),e(q1,_Bo),e(ro,vBo),e(ro,O1),e(O1,vae),e(vae,bBo),e(O1,TBo),e(O1,W$),e(W$,FBo),e(O1,CBo),e(ro,EBo),e(ro,G1),e(G1,bae),e(bae,MBo),e(G1,yBo),e(G1,Q$),e(Q$,wBo),e(G1,ABo),e(Ve,LBo),e(Ve,z1),e(z1,BBo),e(z1,Tae),e(Tae,kBo),e(z1,xBo),e(z1,Fae),e(Fae,RBo),e(Ve,SBo),e(Ve,Cae),e(Cae,PBo),e(Ve,$Bo),g(f5,Ve,null),v(d,Wwe,_),v(d,cd,_),e(cd,V1),e(V1,Eae),g(m5,Eae,null),e(cd,IBo),e(cd,Mae),e(Mae,jBo),v(d,Qwe,_),v(d,or,_),g(g5,or,null),e(or,NBo),e(or,fd),e(fd,DBo),e(fd,yae),e(yae,qBo),e(fd,OBo),e(fd,wae),e(wae,GBo),e(fd,zBo),e(or,VBo),e(or,h5),e(h5,XBo),e(h5,Aae),e(Aae,WBo),e(h5,QBo),e(or,HBo),e(or,Xr),g(u5,Xr,null),e(Xr,UBo),e(Xr,Lae),e(Lae,JBo),e(Xr,YBo),e(Xr,md),e(md,KBo),e(md,Bae),e(Bae,ZBo),e(md,e9o),e(md,kae),e(kae,o9o),e(md,r9o),e(Xr,t9o),e(Xr,xae),e(xae,a9o),e(Xr,n9o),g(p5,Xr,null),e(or,s9o),e(or,Xe),g(_5,Xe,null),e(Xe,l9o),e(Xe,Rae),e(Rae,i9o),e(Xe,d9o),e(Xe,za),e(za,c9o),e(za,Sae),e(Sae,f9o),e(za,m9o),e(za,Pae),e(Pae,g9o),e(za,h9o),e(za,$ae),e($ae,u9o),e(za,p9o),e(Xe,_9o),e(Xe,v5),e(v5,X1),e(X1,Iae),e(Iae,v9o),e(X1,b9o),e(X1,H$),e(H$,T9o),e(X1,F9o),e(v5,C9o),e(v5,W1),e(W1,jae),e(jae,E9o),e(W1,M9o),e(W1,U$),e(U$,y9o),e(W1,w9o),e(Xe,A9o),e(Xe,Q1),e(Q1,L9o),e(Q1,Nae),e(Nae,B9o),e(Q1,k9o),e(Q1,Dae),e(Dae,x9o),e(Xe,R9o),e(Xe,qae),e(qae,S9o),e(Xe,P9o),g(b5,Xe,null),v(d,Hwe,_),v(d,gd,_),e(gd,H1),e(H1,Oae),g(T5,Oae,null),e(gd,$9o),e(gd,Gae),e(Gae,I9o),v(d,Uwe,_),v(d,rr,_),g(F5,rr,null),e(rr,j9o),e(rr,hd),e(hd,N9o),e(hd,zae),e(zae,D9o),e(hd,q9o),e(hd,Vae),e(Vae,O9o),e(hd,G9o),e(rr,z9o),e(rr,C5),e(C5,V9o),e(C5,Xae),e(Xae,X9o),e(C5,W9o),e(rr,Q9o),e(rr,Wr),g(E5,Wr,null),e(Wr,H9o),e(Wr,Wae),e(Wae,U9o),e(Wr,J9o),e(Wr,ud),e(ud,Y9o),e(ud,Qae),e(Qae,K9o),e(ud,Z9o),e(ud,Hae),e(Hae,eko),e(ud,oko),e(Wr,rko),e(Wr,Uae),e(Uae,tko),e(Wr,ako),g(M5,Wr,null),e(rr,nko),e(rr,We),g(y5,We,null),e(We,sko),e(We,Jae),e(Jae,lko),e(We,iko),e(We,Va),e(Va,dko),e(Va,Yae),e(Yae,cko),e(Va,fko),e(Va,Kae),e(Kae,mko),e(Va,gko),e(Va,Zae),e(Zae,hko),e(Va,uko),e(We,pko),e(We,pd),e(pd,U1),e(U1,ene),e(ene,_ko),e(U1,vko),e(U1,J$),e(J$,bko),e(U1,Tko),e(pd,Fko),e(pd,J1),e(J1,one),e(one,Cko),e(J1,Eko),e(J1,Y$),e(Y$,Mko),e(J1,yko),e(pd,wko),e(pd,Y1),e(Y1,rne),e(rne,Ako),e(Y1,Lko),e(Y1,K$),e(K$,Bko),e(Y1,kko),e(We,xko),e(We,K1),e(K1,Rko),e(K1,tne),e(tne,Sko),e(K1,Pko),e(K1,ane),e(ane,$ko),e(We,Iko),e(We,nne),e(nne,jko),e(We,Nko),g(w5,We,null),v(d,Jwe,_),v(d,_d,_),e(_d,Z1),e(Z1,sne),g(A5,sne,null),e(_d,Dko),e(_d,lne),e(lne,qko),v(d,Ywe,_),v(d,tr,_),g(L5,tr,null),e(tr,Oko),e(tr,vd),e(vd,Gko),e(vd,ine),e(ine,zko),e(vd,Vko),e(vd,dne),e(dne,Xko),e(vd,Wko),e(tr,Qko),e(tr,B5),e(B5,Hko),e(B5,cne),e(cne,Uko),e(B5,Jko),e(tr,Yko),e(tr,Qr),g(k5,Qr,null),e(Qr,Kko),e(Qr,fne),e(fne,Zko),e(Qr,exo),e(Qr,bd),e(bd,oxo),e(bd,mne),e(mne,rxo),e(bd,txo),e(bd,gne),e(gne,axo),e(bd,nxo),e(Qr,sxo),e(Qr,hne),e(hne,lxo),e(Qr,ixo),g(x5,Qr,null),e(tr,dxo),e(tr,Qe),g(R5,Qe,null),e(Qe,cxo),e(Qe,une),e(une,fxo),e(Qe,mxo),e(Qe,Xa),e(Xa,gxo),e(Xa,pne),e(pne,hxo),e(Xa,uxo),e(Xa,_ne),e(_ne,pxo),e(Xa,_xo),e(Xa,vne),e(vne,vxo),e(Xa,bxo),e(Qe,Txo),e(Qe,bne),e(bne,e4),e(e4,Tne),e(Tne,Fxo),e(e4,Cxo),e(e4,Z$),e(Z$,Exo),e(e4,Mxo),e(Qe,yxo),e(Qe,o4),e(o4,wxo),e(o4,Fne),e(Fne,Axo),e(o4,Lxo),e(o4,Cne),e(Cne,Bxo),e(Qe,kxo),e(Qe,Ene),e(Ene,xxo),e(Qe,Rxo),g(S5,Qe,null),v(d,Kwe,_),v(d,Td,_),e(Td,r4),e(r4,Mne),g(P5,Mne,null),e(Td,Sxo),e(Td,yne),e(yne,Pxo),v(d,Zwe,_),v(d,ar,_),g($5,ar,null),e(ar,$xo),e(ar,Fd),e(Fd,Ixo),e(Fd,wne),e(wne,jxo),e(Fd,Nxo),e(Fd,Ane),e(Ane,Dxo),e(Fd,qxo),e(ar,Oxo),e(ar,I5),e(I5,Gxo),e(I5,Lne),e(Lne,zxo),e(I5,Vxo),e(ar,Xxo),e(ar,Hr),g(j5,Hr,null),e(Hr,Wxo),e(Hr,Bne),e(Bne,Qxo),e(Hr,Hxo),e(Hr,Cd),e(Cd,Uxo),e(Cd,kne),e(kne,Jxo),e(Cd,Yxo),e(Cd,xne),e(xne,Kxo),e(Cd,Zxo),e(Hr,eRo),e(Hr,Rne),e(Rne,oRo),e(Hr,rRo),g(N5,Hr,null),e(ar,tRo),e(ar,He),g(D5,He,null),e(He,aRo),e(He,Sne),e(Sne,nRo),e(He,sRo),e(He,Wa),e(Wa,lRo),e(Wa,Pne),e(Pne,iRo),e(Wa,dRo),e(Wa,$ne),e($ne,cRo),e(Wa,fRo),e(Wa,Ine),e(Ine,mRo),e(Wa,gRo),e(He,hRo),e(He,jne),e(jne,t4),e(t4,Nne),e(Nne,uRo),e(t4,pRo),e(t4,eI),e(eI,_Ro),e(t4,vRo),e(He,bRo),e(He,a4),e(a4,TRo),e(a4,Dne),e(Dne,FRo),e(a4,CRo),e(a4,qne),e(qne,ERo),e(He,MRo),e(He,One),e(One,yRo),e(He,wRo),g(q5,He,null),v(d,eAe,_),v(d,Ed,_),e(Ed,n4),e(n4,Gne),g(O5,Gne,null),e(Ed,ARo),e(Ed,zne),e(zne,LRo),v(d,oAe,_),v(d,nr,_),g(G5,nr,null),e(nr,BRo),e(nr,Md),e(Md,kRo),e(Md,Vne),e(Vne,xRo),e(Md,RRo),e(Md,Xne),e(Xne,SRo),e(Md,PRo),e(nr,$Ro),e(nr,z5),e(z5,IRo),e(z5,Wne),e(Wne,jRo),e(z5,NRo),e(nr,DRo),e(nr,Ur),g(V5,Ur,null),e(Ur,qRo),e(Ur,Qne),e(Qne,ORo),e(Ur,GRo),e(Ur,yd),e(yd,zRo),e(yd,Hne),e(Hne,VRo),e(yd,XRo),e(yd,Une),e(Une,WRo),e(yd,QRo),e(Ur,HRo),e(Ur,Jne),e(Jne,URo),e(Ur,JRo),g(X5,Ur,null),e(nr,YRo),e(nr,co),g(W5,co,null),e(co,KRo),e(co,Yne),e(Yne,ZRo),e(co,eSo),e(co,Qa),e(Qa,oSo),e(Qa,Kne),e(Kne,rSo),e(Qa,tSo),e(Qa,Zne),e(Zne,aSo),e(Qa,nSo),e(Qa,ese),e(ese,sSo),e(Qa,lSo),e(co,iSo),e(co,B),e(B,s4),e(s4,ose),e(ose,dSo),e(s4,cSo),e(s4,oI),e(oI,fSo),e(s4,mSo),e(B,gSo),e(B,l4),e(l4,rse),e(rse,hSo),e(l4,uSo),e(l4,rI),e(rI,pSo),e(l4,_So),e(B,vSo),e(B,i4),e(i4,tse),e(tse,bSo),e(i4,TSo),e(i4,tI),e(tI,FSo),e(i4,CSo),e(B,ESo),e(B,d4),e(d4,ase),e(ase,MSo),e(d4,ySo),e(d4,aI),e(aI,wSo),e(d4,ASo),e(B,LSo),e(B,c4),e(c4,nse),e(nse,BSo),e(c4,kSo),e(c4,nI),e(nI,xSo),e(c4,RSo),e(B,SSo),e(B,f4),e(f4,sse),e(sse,PSo),e(f4,$So),e(f4,sI),e(sI,ISo),e(f4,jSo),e(B,NSo),e(B,m4),e(m4,lse),e(lse,DSo),e(m4,qSo),e(m4,lI),e(lI,OSo),e(m4,GSo),e(B,zSo),e(B,g4),e(g4,ise),e(ise,VSo),e(g4,XSo),e(g4,iI),e(iI,WSo),e(g4,QSo),e(B,HSo),e(B,h4),e(h4,dse),e(dse,USo),e(h4,JSo),e(h4,dI),e(dI,YSo),e(h4,KSo),e(B,ZSo),e(B,u4),e(u4,cse),e(cse,ePo),e(u4,oPo),e(u4,cI),e(cI,rPo),e(u4,tPo),e(B,aPo),e(B,p4),e(p4,fse),e(fse,nPo),e(p4,sPo),e(p4,fI),e(fI,lPo),e(p4,iPo),e(B,dPo),e(B,_4),e(_4,mse),e(mse,cPo),e(_4,fPo),e(_4,mI),e(mI,mPo),e(_4,gPo),e(B,hPo),e(B,v4),e(v4,gse),e(gse,uPo),e(v4,pPo),e(v4,gI),e(gI,_Po),e(v4,vPo),e(B,bPo),e(B,b4),e(b4,hse),e(hse,TPo),e(b4,FPo),e(b4,hI),e(hI,CPo),e(b4,EPo),e(B,MPo),e(B,T4),e(T4,use),e(use,yPo),e(T4,wPo),e(T4,uI),e(uI,APo),e(T4,LPo),e(B,BPo),e(B,ps),e(ps,pse),e(pse,kPo),e(ps,xPo),e(ps,pI),e(pI,RPo),e(ps,SPo),e(ps,_I),e(_I,PPo),e(ps,$Po),e(B,IPo),e(B,F4),e(F4,_se),e(_se,jPo),e(F4,NPo),e(F4,vI),e(vI,DPo),e(F4,qPo),e(B,OPo),e(B,C4),e(C4,vse),e(vse,GPo),e(C4,zPo),e(C4,bI),e(bI,VPo),e(C4,XPo),e(B,WPo),e(B,E4),e(E4,bse),e(bse,QPo),e(E4,HPo),e(E4,TI),e(TI,UPo),e(E4,JPo),e(B,YPo),e(B,M4),e(M4,Tse),e(Tse,KPo),e(M4,ZPo),e(M4,FI),e(FI,e$o),e(M4,o$o),e(B,r$o),e(B,y4),e(y4,Fse),e(Fse,t$o),e(y4,a$o),e(y4,CI),e(CI,n$o),e(y4,s$o),e(B,l$o),e(B,w4),e(w4,Cse),e(Cse,i$o),e(w4,d$o),e(w4,EI),e(EI,c$o),e(w4,f$o),e(B,m$o),e(B,A4),e(A4,Ese),e(Ese,g$o),e(A4,h$o),e(A4,MI),e(MI,u$o),e(A4,p$o),e(B,_$o),e(B,L4),e(L4,Mse),e(Mse,v$o),e(L4,b$o),e(L4,yI),e(yI,T$o),e(L4,F$o),e(B,C$o),e(B,B4),e(B4,yse),e(yse,E$o),e(B4,M$o),e(B4,wI),e(wI,y$o),e(B4,w$o),e(B,A$o),e(B,k4),e(k4,wse),e(wse,L$o),e(k4,B$o),e(k4,AI),e(AI,k$o),e(k4,x$o),e(B,R$o),e(B,x4),e(x4,Ase),e(Ase,S$o),e(x4,P$o),e(x4,LI),e(LI,$$o),e(x4,I$o),e(B,j$o),e(B,R4),e(R4,Lse),e(Lse,N$o),e(R4,D$o),e(R4,BI),e(BI,q$o),e(R4,O$o),e(B,G$o),e(B,S4),e(S4,Bse),e(Bse,z$o),e(S4,V$o),e(S4,kI),e(kI,X$o),e(S4,W$o),e(B,Q$o),e(B,P4),e(P4,kse),e(kse,H$o),e(P4,U$o),e(P4,xI),e(xI,J$o),e(P4,Y$o),e(B,K$o),e(B,$4),e($4,xse),e(xse,Z$o),e($4,eIo),e($4,RI),e(RI,oIo),e($4,rIo),e(B,tIo),e(B,I4),e(I4,Rse),e(Rse,aIo),e(I4,nIo),e(I4,SI),e(SI,sIo),e(I4,lIo),e(B,iIo),e(B,j4),e(j4,Sse),e(Sse,dIo),e(j4,cIo),e(j4,PI),e(PI,fIo),e(j4,mIo),e(B,gIo),e(B,N4),e(N4,Pse),e(Pse,hIo),e(N4,uIo),e(N4,$I),e($I,pIo),e(N4,_Io),e(B,vIo),e(B,D4),e(D4,$se),e($se,bIo),e(D4,TIo),e(D4,II),e(II,FIo),e(D4,CIo),e(B,EIo),e(B,q4),e(q4,Ise),e(Ise,MIo),e(q4,yIo),e(q4,jI),e(jI,wIo),e(q4,AIo),e(B,LIo),e(B,O4),e(O4,jse),e(jse,BIo),e(O4,kIo),e(O4,NI),e(NI,xIo),e(O4,RIo),e(B,SIo),e(B,G4),e(G4,Nse),e(Nse,PIo),e(G4,$Io),e(G4,DI),e(DI,IIo),e(G4,jIo),e(B,NIo),e(B,z4),e(z4,Dse),e(Dse,DIo),e(z4,qIo),e(z4,qI),e(qI,OIo),e(z4,GIo),e(B,zIo),e(B,V4),e(V4,qse),e(qse,VIo),e(V4,XIo),e(V4,OI),e(OI,WIo),e(V4,QIo),e(co,HIo),e(co,Ose),e(Ose,UIo),e(co,JIo),g(Q5,co,null),v(d,rAe,_),v(d,wd,_),e(wd,X4),e(X4,Gse),g(H5,Gse,null),e(wd,YIo),e(wd,zse),e(zse,KIo),v(d,tAe,_),v(d,sr,_),g(U5,sr,null),e(sr,ZIo),e(sr,Ad),e(Ad,ejo),e(Ad,Vse),e(Vse,ojo),e(Ad,rjo),e(Ad,Xse),e(Xse,tjo),e(Ad,ajo),e(sr,njo),e(sr,J5),e(J5,sjo),e(J5,Wse),e(Wse,ljo),e(J5,ijo),e(sr,djo),e(sr,Jr),g(Y5,Jr,null),e(Jr,cjo),e(Jr,Qse),e(Qse,fjo),e(Jr,mjo),e(Jr,Ld),e(Ld,gjo),e(Ld,Hse),e(Hse,hjo),e(Ld,ujo),e(Ld,Use),e(Use,pjo),e(Ld,_jo),e(Jr,vjo),e(Jr,Jse),e(Jse,bjo),e(Jr,Tjo),g(K5,Jr,null),e(sr,Fjo),e(sr,fo),g(Z5,fo,null),e(fo,Cjo),e(fo,Yse),e(Yse,Ejo),e(fo,Mjo),e(fo,Ha),e(Ha,yjo),e(Ha,Kse),e(Kse,wjo),e(Ha,Ajo),e(Ha,Zse),e(Zse,Ljo),e(Ha,Bjo),e(Ha,ele),e(ele,kjo),e(Ha,xjo),e(fo,Rjo),e(fo,Q),e(Q,W4),e(W4,ole),e(ole,Sjo),e(W4,Pjo),e(W4,GI),e(GI,$jo),e(W4,Ijo),e(Q,jjo),e(Q,Q4),e(Q4,rle),e(rle,Njo),e(Q4,Djo),e(Q4,zI),e(zI,qjo),e(Q4,Ojo),e(Q,Gjo),e(Q,H4),e(H4,tle),e(tle,zjo),e(H4,Vjo),e(H4,VI),e(VI,Xjo),e(H4,Wjo),e(Q,Qjo),e(Q,U4),e(U4,ale),e(ale,Hjo),e(U4,Ujo),e(U4,XI),e(XI,Jjo),e(U4,Yjo),e(Q,Kjo),e(Q,J4),e(J4,nle),e(nle,Zjo),e(J4,eNo),e(J4,WI),e(WI,oNo),e(J4,rNo),e(Q,tNo),e(Q,Y4),e(Y4,sle),e(sle,aNo),e(Y4,nNo),e(Y4,QI),e(QI,sNo),e(Y4,lNo),e(Q,iNo),e(Q,K4),e(K4,lle),e(lle,dNo),e(K4,cNo),e(K4,HI),e(HI,fNo),e(K4,mNo),e(Q,gNo),e(Q,Z4),e(Z4,ile),e(ile,hNo),e(Z4,uNo),e(Z4,UI),e(UI,pNo),e(Z4,_No),e(Q,vNo),e(Q,eb),e(eb,dle),e(dle,bNo),e(eb,TNo),e(eb,JI),e(JI,FNo),e(eb,CNo),e(Q,ENo),e(Q,ob),e(ob,cle),e(cle,MNo),e(ob,yNo),e(ob,YI),e(YI,wNo),e(ob,ANo),e(Q,LNo),e(Q,rb),e(rb,fle),e(fle,BNo),e(rb,kNo),e(rb,KI),e(KI,xNo),e(rb,RNo),e(Q,SNo),e(Q,tb),e(tb,mle),e(mle,PNo),e(tb,$No),e(tb,ZI),e(ZI,INo),e(tb,jNo),e(Q,NNo),e(Q,ab),e(ab,gle),e(gle,DNo),e(ab,qNo),e(ab,ej),e(ej,ONo),e(ab,GNo),e(Q,zNo),e(Q,nb),e(nb,hle),e(hle,VNo),e(nb,XNo),e(nb,oj),e(oj,WNo),e(nb,QNo),e(Q,HNo),e(Q,sb),e(sb,ule),e(ule,UNo),e(sb,JNo),e(sb,rj),e(rj,YNo),e(sb,KNo),e(Q,ZNo),e(Q,lb),e(lb,ple),e(ple,eDo),e(lb,oDo),e(lb,tj),e(tj,rDo),e(lb,tDo),e(Q,aDo),e(Q,ib),e(ib,_le),e(_le,nDo),e(ib,sDo),e(ib,aj),e(aj,lDo),e(ib,iDo),e(Q,dDo),e(Q,db),e(db,vle),e(vle,cDo),e(db,fDo),e(db,nj),e(nj,mDo),e(db,gDo),e(Q,hDo),e(Q,cb),e(cb,ble),e(ble,uDo),e(cb,pDo),e(cb,sj),e(sj,_Do),e(cb,vDo),e(Q,bDo),e(Q,fb),e(fb,Tle),e(Tle,TDo),e(fb,FDo),e(fb,lj),e(lj,CDo),e(fb,EDo),e(Q,MDo),e(Q,mb),e(mb,Fle),e(Fle,yDo),e(mb,wDo),e(mb,ij),e(ij,ADo),e(mb,LDo),e(Q,BDo),e(Q,gb),e(gb,Cle),e(Cle,kDo),e(gb,xDo),e(gb,dj),e(dj,RDo),e(gb,SDo),e(fo,PDo),e(fo,Ele),e(Ele,$Do),e(fo,IDo),g(ey,fo,null),v(d,aAe,_),v(d,Bd,_),e(Bd,hb),e(hb,Mle),g(oy,Mle,null),e(Bd,jDo),e(Bd,yle),e(yle,NDo),v(d,nAe,_),v(d,lr,_),g(ry,lr,null),e(lr,DDo),e(lr,kd),e(kd,qDo),e(kd,wle),e(wle,ODo),e(kd,GDo),e(kd,Ale),e(Ale,zDo),e(kd,VDo),e(lr,XDo),e(lr,ty),e(ty,WDo),e(ty,Lle),e(Lle,QDo),e(ty,HDo),e(lr,UDo),e(lr,Yr),g(ay,Yr,null),e(Yr,JDo),e(Yr,Ble),e(Ble,YDo),e(Yr,KDo),e(Yr,xd),e(xd,ZDo),e(xd,kle),e(kle,eqo),e(xd,oqo),e(xd,xle),e(xle,rqo),e(xd,tqo),e(Yr,aqo),e(Yr,Rle),e(Rle,nqo),e(Yr,sqo),g(ny,Yr,null),e(lr,lqo),e(lr,mo),g(sy,mo,null),e(mo,iqo),e(mo,Sle),e(Sle,dqo),e(mo,cqo),e(mo,Ua),e(Ua,fqo),e(Ua,Ple),e(Ple,mqo),e(Ua,gqo),e(Ua,$le),e($le,hqo),e(Ua,uqo),e(Ua,Ile),e(Ile,pqo),e(Ua,_qo),e(mo,vqo),e(mo,he),e(he,ub),e(ub,jle),e(jle,bqo),e(ub,Tqo),e(ub,cj),e(cj,Fqo),e(ub,Cqo),e(he,Eqo),e(he,pb),e(pb,Nle),e(Nle,Mqo),e(pb,yqo),e(pb,fj),e(fj,wqo),e(pb,Aqo),e(he,Lqo),e(he,_b),e(_b,Dle),e(Dle,Bqo),e(_b,kqo),e(_b,mj),e(mj,xqo),e(_b,Rqo),e(he,Sqo),e(he,vb),e(vb,qle),e(qle,Pqo),e(vb,$qo),e(vb,gj),e(gj,Iqo),e(vb,jqo),e(he,Nqo),e(he,bb),e(bb,Ole),e(Ole,Dqo),e(bb,qqo),e(bb,hj),e(hj,Oqo),e(bb,Gqo),e(he,zqo),e(he,Tb),e(Tb,Gle),e(Gle,Vqo),e(Tb,Xqo),e(Tb,uj),e(uj,Wqo),e(Tb,Qqo),e(he,Hqo),e(he,Fb),e(Fb,zle),e(zle,Uqo),e(Fb,Jqo),e(Fb,pj),e(pj,Yqo),e(Fb,Kqo),e(he,Zqo),e(he,Cb),e(Cb,Vle),e(Vle,eOo),e(Cb,oOo),e(Cb,_j),e(_j,rOo),e(Cb,tOo),e(he,aOo),e(he,Eb),e(Eb,Xle),e(Xle,nOo),e(Eb,sOo),e(Eb,vj),e(vj,lOo),e(Eb,iOo),e(he,dOo),e(he,Mb),e(Mb,Wle),e(Wle,cOo),e(Mb,fOo),e(Mb,bj),e(bj,mOo),e(Mb,gOo),e(mo,hOo),e(mo,Qle),e(Qle,uOo),e(mo,pOo),g(ly,mo,null),v(d,sAe,_),v(d,Rd,_),e(Rd,yb),e(yb,Hle),g(iy,Hle,null),e(Rd,_Oo),e(Rd,Ule),e(Ule,vOo),v(d,lAe,_),v(d,ir,_),g(dy,ir,null),e(ir,bOo),e(ir,Sd),e(Sd,TOo),e(Sd,Jle),e(Jle,FOo),e(Sd,COo),e(Sd,Yle),e(Yle,EOo),e(Sd,MOo),e(ir,yOo),e(ir,cy),e(cy,wOo),e(cy,Kle),e(Kle,AOo),e(cy,LOo),e(ir,BOo),e(ir,Kr),g(fy,Kr,null),e(Kr,kOo),e(Kr,Zle),e(Zle,xOo),e(Kr,ROo),e(Kr,Pd),e(Pd,SOo),e(Pd,eie),e(eie,POo),e(Pd,$Oo),e(Pd,oie),e(oie,IOo),e(Pd,jOo),e(Kr,NOo),e(Kr,rie),e(rie,DOo),e(Kr,qOo),g(my,Kr,null),e(ir,OOo),e(ir,go),g(gy,go,null),e(go,GOo),e(go,tie),e(tie,zOo),e(go,VOo),e(go,Ja),e(Ja,XOo),e(Ja,aie),e(aie,WOo),e(Ja,QOo),e(Ja,nie),e(nie,HOo),e(Ja,UOo),e(Ja,sie),e(sie,JOo),e(Ja,YOo),e(go,KOo),e(go,lie),e(lie,wb),e(wb,iie),e(iie,ZOo),e(wb,eGo),e(wb,Tj),e(Tj,oGo),e(wb,rGo),e(go,tGo),e(go,die),e(die,aGo),e(go,nGo),g(hy,go,null),v(d,iAe,_),v(d,$d,_),e($d,Ab),e(Ab,cie),g(uy,cie,null),e($d,sGo),e($d,fie),e(fie,lGo),v(d,dAe,_),v(d,dr,_),g(py,dr,null),e(dr,iGo),e(dr,Id),e(Id,dGo),e(Id,mie),e(mie,cGo),e(Id,fGo),e(Id,gie),e(gie,mGo),e(Id,gGo),e(dr,hGo),e(dr,_y),e(_y,uGo),e(_y,hie),e(hie,pGo),e(_y,_Go),e(dr,vGo),e(dr,Zr),g(vy,Zr,null),e(Zr,bGo),e(Zr,uie),e(uie,TGo),e(Zr,FGo),e(Zr,jd),e(jd,CGo),e(jd,pie),e(pie,EGo),e(jd,MGo),e(jd,_ie),e(_ie,yGo),e(jd,wGo),e(Zr,AGo),e(Zr,vie),e(vie,LGo),e(Zr,BGo),g(by,Zr,null),e(dr,kGo),e(dr,ho),g(Ty,ho,null),e(ho,xGo),e(ho,bie),e(bie,RGo),e(ho,SGo),e(ho,Ya),e(Ya,PGo),e(Ya,Tie),e(Tie,$Go),e(Ya,IGo),e(Ya,Fie),e(Fie,jGo),e(Ya,NGo),e(Ya,Cie),e(Cie,DGo),e(Ya,qGo),e(ho,OGo),e(ho,Y),e(Y,Lb),e(Lb,Eie),e(Eie,GGo),e(Lb,zGo),e(Lb,Fj),e(Fj,VGo),e(Lb,XGo),e(Y,WGo),e(Y,Bb),e(Bb,Mie),e(Mie,QGo),e(Bb,HGo),e(Bb,Cj),e(Cj,UGo),e(Bb,JGo),e(Y,YGo),e(Y,kb),e(kb,yie),e(yie,KGo),e(kb,ZGo),e(kb,Ej),e(Ej,ezo),e(kb,ozo),e(Y,rzo),e(Y,xb),e(xb,wie),e(wie,tzo),e(xb,azo),e(xb,Mj),e(Mj,nzo),e(xb,szo),e(Y,lzo),e(Y,Rb),e(Rb,Aie),e(Aie,izo),e(Rb,dzo),e(Rb,yj),e(yj,czo),e(Rb,fzo),e(Y,mzo),e(Y,Sb),e(Sb,Lie),e(Lie,gzo),e(Sb,hzo),e(Sb,wj),e(wj,uzo),e(Sb,pzo),e(Y,_zo),e(Y,Pb),e(Pb,Bie),e(Bie,vzo),e(Pb,bzo),e(Pb,Aj),e(Aj,Tzo),e(Pb,Fzo),e(Y,Czo),e(Y,$b),e($b,kie),e(kie,Ezo),e($b,Mzo),e($b,Lj),e(Lj,yzo),e($b,wzo),e(Y,Azo),e(Y,Ib),e(Ib,xie),e(xie,Lzo),e(Ib,Bzo),e(Ib,Bj),e(Bj,kzo),e(Ib,xzo),e(Y,Rzo),e(Y,jb),e(jb,Rie),e(Rie,Szo),e(jb,Pzo),e(jb,kj),e(kj,$zo),e(jb,Izo),e(Y,jzo),e(Y,Nb),e(Nb,Sie),e(Sie,Nzo),e(Nb,Dzo),e(Nb,xj),e(xj,qzo),e(Nb,Ozo),e(Y,Gzo),e(Y,Db),e(Db,Pie),e(Pie,zzo),e(Db,Vzo),e(Db,Rj),e(Rj,Xzo),e(Db,Wzo),e(Y,Qzo),e(Y,qb),e(qb,$ie),e($ie,Hzo),e(qb,Uzo),e(qb,Sj),e(Sj,Jzo),e(qb,Yzo),e(Y,Kzo),e(Y,Ob),e(Ob,Iie),e(Iie,Zzo),e(Ob,eVo),e(Ob,Pj),e(Pj,oVo),e(Ob,rVo),e(Y,tVo),e(Y,Gb),e(Gb,jie),e(jie,aVo),e(Gb,nVo),e(Gb,$j),e($j,sVo),e(Gb,lVo),e(Y,iVo),e(Y,zb),e(zb,Nie),e(Nie,dVo),e(zb,cVo),e(zb,Ij),e(Ij,fVo),e(zb,mVo),e(Y,gVo),e(Y,Vb),e(Vb,Die),e(Die,hVo),e(Vb,uVo),e(Vb,jj),e(jj,pVo),e(Vb,_Vo),e(Y,vVo),e(Y,Xb),e(Xb,qie),e(qie,bVo),e(Xb,TVo),e(Xb,Nj),e(Nj,FVo),e(Xb,CVo),e(Y,EVo),e(Y,Wb),e(Wb,Oie),e(Oie,MVo),e(Wb,yVo),e(Wb,Dj),e(Dj,wVo),e(Wb,AVo),e(Y,LVo),e(Y,Qb),e(Qb,Gie),e(Gie,BVo),e(Qb,kVo),e(Qb,qj),e(qj,xVo),e(Qb,RVo),e(ho,SVo),e(ho,zie),e(zie,PVo),e(ho,$Vo),g(Fy,ho,null),v(d,cAe,_),v(d,Nd,_),e(Nd,Hb),e(Hb,Vie),g(Cy,Vie,null),e(Nd,IVo),e(Nd,Xie),e(Xie,jVo),v(d,fAe,_),v(d,cr,_),g(Ey,cr,null),e(cr,NVo),e(cr,Dd),e(Dd,DVo),e(Dd,Wie),e(Wie,qVo),e(Dd,OVo),e(Dd,Qie),e(Qie,GVo),e(Dd,zVo),e(cr,VVo),e(cr,My),e(My,XVo),e(My,Hie),e(Hie,WVo),e(My,QVo),e(cr,HVo),e(cr,et),g(yy,et,null),e(et,UVo),e(et,Uie),e(Uie,JVo),e(et,YVo),e(et,qd),e(qd,KVo),e(qd,Jie),e(Jie,ZVo),e(qd,eXo),e(qd,Yie),e(Yie,oXo),e(qd,rXo),e(et,tXo),e(et,Kie),e(Kie,aXo),e(et,nXo),g(wy,et,null),e(cr,sXo),e(cr,uo),g(Ay,uo,null),e(uo,lXo),e(uo,Zie),e(Zie,iXo),e(uo,dXo),e(uo,Ka),e(Ka,cXo),e(Ka,ede),e(ede,fXo),e(Ka,mXo),e(Ka,ode),e(ode,gXo),e(Ka,hXo),e(Ka,rde),e(rde,uXo),e(Ka,pXo),e(uo,_Xo),e(uo,ue),e(ue,Ub),e(Ub,tde),e(tde,vXo),e(Ub,bXo),e(Ub,Oj),e(Oj,TXo),e(Ub,FXo),e(ue,CXo),e(ue,Jb),e(Jb,ade),e(ade,EXo),e(Jb,MXo),e(Jb,Gj),e(Gj,yXo),e(Jb,wXo),e(ue,AXo),e(ue,Yb),e(Yb,nde),e(nde,LXo),e(Yb,BXo),e(Yb,zj),e(zj,kXo),e(Yb,xXo),e(ue,RXo),e(ue,Kb),e(Kb,sde),e(sde,SXo),e(Kb,PXo),e(Kb,Vj),e(Vj,$Xo),e(Kb,IXo),e(ue,jXo),e(ue,Zb),e(Zb,lde),e(lde,NXo),e(Zb,DXo),e(Zb,Xj),e(Xj,qXo),e(Zb,OXo),e(ue,GXo),e(ue,eT),e(eT,ide),e(ide,zXo),e(eT,VXo),e(eT,Wj),e(Wj,XXo),e(eT,WXo),e(ue,QXo),e(ue,oT),e(oT,dde),e(dde,HXo),e(oT,UXo),e(oT,Qj),e(Qj,JXo),e(oT,YXo),e(ue,KXo),e(ue,rT),e(rT,cde),e(cde,ZXo),e(rT,eWo),e(rT,Hj),e(Hj,oWo),e(rT,rWo),e(ue,tWo),e(ue,tT),e(tT,fde),e(fde,aWo),e(tT,nWo),e(tT,Uj),e(Uj,sWo),e(tT,lWo),e(ue,iWo),e(ue,aT),e(aT,mde),e(mde,dWo),e(aT,cWo),e(aT,Jj),e(Jj,fWo),e(aT,mWo),e(uo,gWo),e(uo,gde),e(gde,hWo),e(uo,uWo),g(Ly,uo,null),v(d,mAe,_),v(d,Od,_),e(Od,nT),e(nT,hde),g(By,hde,null),e(Od,pWo),e(Od,ude),e(ude,_Wo),v(d,gAe,_),v(d,fr,_),g(ky,fr,null),e(fr,vWo),e(fr,Gd),e(Gd,bWo),e(Gd,pde),e(pde,TWo),e(Gd,FWo),e(Gd,_de),e(_de,CWo),e(Gd,EWo),e(fr,MWo),e(fr,xy),e(xy,yWo),e(xy,vde),e(vde,wWo),e(xy,AWo),e(fr,LWo),e(fr,ot),g(Ry,ot,null),e(ot,BWo),e(ot,bde),e(bde,kWo),e(ot,xWo),e(ot,zd),e(zd,RWo),e(zd,Tde),e(Tde,SWo),e(zd,PWo),e(zd,Fde),e(Fde,$Wo),e(zd,IWo),e(ot,jWo),e(ot,Cde),e(Cde,NWo),e(ot,DWo),g(Sy,ot,null),e(fr,qWo),e(fr,po),g(Py,po,null),e(po,OWo),e(po,Ede),e(Ede,GWo),e(po,zWo),e(po,Za),e(Za,VWo),e(Za,Mde),e(Mde,XWo),e(Za,WWo),e(Za,yde),e(yde,QWo),e(Za,HWo),e(Za,wde),e(wde,UWo),e(Za,JWo),e(po,YWo),e(po,G),e(G,sT),e(sT,Ade),e(Ade,KWo),e(sT,ZWo),e(sT,Yj),e(Yj,eQo),e(sT,oQo),e(G,rQo),e(G,lT),e(lT,Lde),e(Lde,tQo),e(lT,aQo),e(lT,Kj),e(Kj,nQo),e(lT,sQo),e(G,lQo),e(G,iT),e(iT,Bde),e(Bde,iQo),e(iT,dQo),e(iT,Zj),e(Zj,cQo),e(iT,fQo),e(G,mQo),e(G,dT),e(dT,kde),e(kde,gQo),e(dT,hQo),e(dT,eN),e(eN,uQo),e(dT,pQo),e(G,_Qo),e(G,cT),e(cT,xde),e(xde,vQo),e(cT,bQo),e(cT,oN),e(oN,TQo),e(cT,FQo),e(G,CQo),e(G,fT),e(fT,Rde),e(Rde,EQo),e(fT,MQo),e(fT,rN),e(rN,yQo),e(fT,wQo),e(G,AQo),e(G,mT),e(mT,Sde),e(Sde,LQo),e(mT,BQo),e(mT,tN),e(tN,kQo),e(mT,xQo),e(G,RQo),e(G,gT),e(gT,Pde),e(Pde,SQo),e(gT,PQo),e(gT,aN),e(aN,$Qo),e(gT,IQo),e(G,jQo),e(G,hT),e(hT,$de),e($de,NQo),e(hT,DQo),e(hT,nN),e(nN,qQo),e(hT,OQo),e(G,GQo),e(G,uT),e(uT,Ide),e(Ide,zQo),e(uT,VQo),e(uT,sN),e(sN,XQo),e(uT,WQo),e(G,QQo),e(G,pT),e(pT,jde),e(jde,HQo),e(pT,UQo),e(pT,lN),e(lN,JQo),e(pT,YQo),e(G,KQo),e(G,_T),e(_T,Nde),e(Nde,ZQo),e(_T,eHo),e(_T,iN),e(iN,oHo),e(_T,rHo),e(G,tHo),e(G,vT),e(vT,Dde),e(Dde,aHo),e(vT,nHo),e(vT,dN),e(dN,sHo),e(vT,lHo),e(G,iHo),e(G,bT),e(bT,qde),e(qde,dHo),e(bT,cHo),e(bT,cN),e(cN,fHo),e(bT,mHo),e(G,gHo),e(G,TT),e(TT,Ode),e(Ode,hHo),e(TT,uHo),e(TT,fN),e(fN,pHo),e(TT,_Ho),e(G,vHo),e(G,FT),e(FT,Gde),e(Gde,bHo),e(FT,THo),e(FT,mN),e(mN,FHo),e(FT,CHo),e(G,EHo),e(G,CT),e(CT,zde),e(zde,MHo),e(CT,yHo),e(CT,gN),e(gN,wHo),e(CT,AHo),e(G,LHo),e(G,ET),e(ET,Vde),e(Vde,BHo),e(ET,kHo),e(ET,hN),e(hN,xHo),e(ET,RHo),e(G,SHo),e(G,MT),e(MT,Xde),e(Xde,PHo),e(MT,$Ho),e(MT,uN),e(uN,IHo),e(MT,jHo),e(G,NHo),e(G,yT),e(yT,Wde),e(Wde,DHo),e(yT,qHo),e(yT,pN),e(pN,OHo),e(yT,GHo),e(G,zHo),e(G,wT),e(wT,Qde),e(Qde,VHo),e(wT,XHo),e(wT,_N),e(_N,WHo),e(wT,QHo),e(G,HHo),e(G,AT),e(AT,Hde),e(Hde,UHo),e(AT,JHo),e(AT,vN),e(vN,YHo),e(AT,KHo),e(G,ZHo),e(G,LT),e(LT,Ude),e(Ude,eUo),e(LT,oUo),e(LT,bN),e(bN,rUo),e(LT,tUo),e(G,aUo),e(G,BT),e(BT,Jde),e(Jde,nUo),e(BT,sUo),e(BT,TN),e(TN,lUo),e(BT,iUo),e(G,dUo),e(G,kT),e(kT,Yde),e(Yde,cUo),e(kT,fUo),e(kT,FN),e(FN,mUo),e(kT,gUo),e(po,hUo),e(po,Kde),e(Kde,uUo),e(po,pUo),g($y,po,null),v(d,hAe,_),v(d,Vd,_),e(Vd,xT),e(xT,Zde),g(Iy,Zde,null),e(Vd,_Uo),e(Vd,ece),e(ece,vUo),v(d,uAe,_),v(d,mr,_),g(jy,mr,null),e(mr,bUo),e(mr,Xd),e(Xd,TUo),e(Xd,oce),e(oce,FUo),e(Xd,CUo),e(Xd,rce),e(rce,EUo),e(Xd,MUo),e(mr,yUo),e(mr,Ny),e(Ny,wUo),e(Ny,tce),e(tce,AUo),e(Ny,LUo),e(mr,BUo),e(mr,rt),g(Dy,rt,null),e(rt,kUo),e(rt,ace),e(ace,xUo),e(rt,RUo),e(rt,Wd),e(Wd,SUo),e(Wd,nce),e(nce,PUo),e(Wd,$Uo),e(Wd,sce),e(sce,IUo),e(Wd,jUo),e(rt,NUo),e(rt,lce),e(lce,DUo),e(rt,qUo),g(qy,rt,null),e(mr,OUo),e(mr,_o),g(Oy,_o,null),e(_o,GUo),e(_o,ice),e(ice,zUo),e(_o,VUo),e(_o,en),e(en,XUo),e(en,dce),e(dce,WUo),e(en,QUo),e(en,cce),e(cce,HUo),e(en,UUo),e(en,fce),e(fce,JUo),e(en,YUo),e(_o,KUo),e(_o,te),e(te,RT),e(RT,mce),e(mce,ZUo),e(RT,eJo),e(RT,CN),e(CN,oJo),e(RT,rJo),e(te,tJo),e(te,ST),e(ST,gce),e(gce,aJo),e(ST,nJo),e(ST,EN),e(EN,sJo),e(ST,lJo),e(te,iJo),e(te,PT),e(PT,hce),e(hce,dJo),e(PT,cJo),e(PT,MN),e(MN,fJo),e(PT,mJo),e(te,gJo),e(te,$T),e($T,uce),e(uce,hJo),e($T,uJo),e($T,yN),e(yN,pJo),e($T,_Jo),e(te,vJo),e(te,IT),e(IT,pce),e(pce,bJo),e(IT,TJo),e(IT,wN),e(wN,FJo),e(IT,CJo),e(te,EJo),e(te,jT),e(jT,_ce),e(_ce,MJo),e(jT,yJo),e(jT,AN),e(AN,wJo),e(jT,AJo),e(te,LJo),e(te,NT),e(NT,vce),e(vce,BJo),e(NT,kJo),e(NT,LN),e(LN,xJo),e(NT,RJo),e(te,SJo),e(te,DT),e(DT,bce),e(bce,PJo),e(DT,$Jo),e(DT,BN),e(BN,IJo),e(DT,jJo),e(te,NJo),e(te,qT),e(qT,Tce),e(Tce,DJo),e(qT,qJo),e(qT,kN),e(kN,OJo),e(qT,GJo),e(te,zJo),e(te,OT),e(OT,Fce),e(Fce,VJo),e(OT,XJo),e(OT,xN),e(xN,WJo),e(OT,QJo),e(te,HJo),e(te,GT),e(GT,Cce),e(Cce,UJo),e(GT,JJo),e(GT,RN),e(RN,YJo),e(GT,KJo),e(te,ZJo),e(te,zT),e(zT,Ece),e(Ece,eYo),e(zT,oYo),e(zT,SN),e(SN,rYo),e(zT,tYo),e(te,aYo),e(te,VT),e(VT,Mce),e(Mce,nYo),e(VT,sYo),e(VT,PN),e(PN,lYo),e(VT,iYo),e(te,dYo),e(te,XT),e(XT,yce),e(yce,cYo),e(XT,fYo),e(XT,$N),e($N,mYo),e(XT,gYo),e(te,hYo),e(te,WT),e(WT,wce),e(wce,uYo),e(WT,pYo),e(WT,IN),e(IN,_Yo),e(WT,vYo),e(te,bYo),e(te,QT),e(QT,Ace),e(Ace,TYo),e(QT,FYo),e(QT,jN),e(jN,CYo),e(QT,EYo),e(te,MYo),e(te,HT),e(HT,Lce),e(Lce,yYo),e(HT,wYo),e(HT,NN),e(NN,AYo),e(HT,LYo),e(_o,BYo),e(_o,Bce),e(Bce,kYo),e(_o,xYo),g(Gy,_o,null),v(d,pAe,_),v(d,Qd,_),e(Qd,UT),e(UT,kce),g(zy,kce,null),e(Qd,RYo),e(Qd,xce),e(xce,SYo),v(d,_Ae,_),v(d,gr,_),g(Vy,gr,null),e(gr,PYo),e(gr,Hd),e(Hd,$Yo),e(Hd,Rce),e(Rce,IYo),e(Hd,jYo),e(Hd,Sce),e(Sce,NYo),e(Hd,DYo),e(gr,qYo),e(gr,Xy),e(Xy,OYo),e(Xy,Pce),e(Pce,GYo),e(Xy,zYo),e(gr,VYo),e(gr,tt),g(Wy,tt,null),e(tt,XYo),e(tt,$ce),e($ce,WYo),e(tt,QYo),e(tt,Ud),e(Ud,HYo),e(Ud,Ice),e(Ice,UYo),e(Ud,JYo),e(Ud,jce),e(jce,YYo),e(Ud,KYo),e(tt,ZYo),e(tt,Nce),e(Nce,eKo),e(tt,oKo),g(Qy,tt,null),e(gr,rKo),e(gr,vo),g(Hy,vo,null),e(vo,tKo),e(vo,Dce),e(Dce,aKo),e(vo,nKo),e(vo,on),e(on,sKo),e(on,qce),e(qce,lKo),e(on,iKo),e(on,Oce),e(Oce,dKo),e(on,cKo),e(on,Gce),e(Gce,fKo),e(on,mKo),e(vo,gKo),e(vo,zce),e(zce,JT),e(JT,Vce),e(Vce,hKo),e(JT,uKo),e(JT,DN),e(DN,pKo),e(JT,_Ko),e(vo,vKo),e(vo,Xce),e(Xce,bKo),e(vo,TKo),g(Uy,vo,null),v(d,vAe,_),v(d,Jd,_),e(Jd,YT),e(YT,Wce),g(Jy,Wce,null),e(Jd,FKo),e(Jd,Qce),e(Qce,CKo),v(d,bAe,_),v(d,hr,_),g(Yy,hr,null),e(hr,EKo),e(hr,Yd),e(Yd,MKo),e(Yd,Hce),e(Hce,yKo),e(Yd,wKo),e(Yd,Uce),e(Uce,AKo),e(Yd,LKo),e(hr,BKo),e(hr,Ky),e(Ky,kKo),e(Ky,Jce),e(Jce,xKo),e(Ky,RKo),e(hr,SKo),e(hr,at),g(Zy,at,null),e(at,PKo),e(at,Yce),e(Yce,$Ko),e(at,IKo),e(at,Kd),e(Kd,jKo),e(Kd,Kce),e(Kce,NKo),e(Kd,DKo),e(Kd,Zce),e(Zce,qKo),e(Kd,OKo),e(at,GKo),e(at,efe),e(efe,zKo),e(at,VKo),g(ew,at,null),e(hr,XKo),e(hr,bo),g(ow,bo,null),e(bo,WKo),e(bo,ofe),e(ofe,QKo),e(bo,HKo),e(bo,rn),e(rn,UKo),e(rn,rfe),e(rfe,JKo),e(rn,YKo),e(rn,tfe),e(tfe,KKo),e(rn,ZKo),e(rn,afe),e(afe,eZo),e(rn,oZo),e(bo,rZo),e(bo,K),e(K,KT),e(KT,nfe),e(nfe,tZo),e(KT,aZo),e(KT,qN),e(qN,nZo),e(KT,sZo),e(K,lZo),e(K,ZT),e(ZT,sfe),e(sfe,iZo),e(ZT,dZo),e(ZT,ON),e(ON,cZo),e(ZT,fZo),e(K,mZo),e(K,e6),e(e6,lfe),e(lfe,gZo),e(e6,hZo),e(e6,GN),e(GN,uZo),e(e6,pZo),e(K,_Zo),e(K,o6),e(o6,ife),e(ife,vZo),e(o6,bZo),e(o6,zN),e(zN,TZo),e(o6,FZo),e(K,CZo),e(K,r6),e(r6,dfe),e(dfe,EZo),e(r6,MZo),e(r6,VN),e(VN,yZo),e(r6,wZo),e(K,AZo),e(K,t6),e(t6,cfe),e(cfe,LZo),e(t6,BZo),e(t6,XN),e(XN,kZo),e(t6,xZo),e(K,RZo),e(K,a6),e(a6,ffe),e(ffe,SZo),e(a6,PZo),e(a6,WN),e(WN,$Zo),e(a6,IZo),e(K,jZo),e(K,n6),e(n6,mfe),e(mfe,NZo),e(n6,DZo),e(n6,QN),e(QN,qZo),e(n6,OZo),e(K,GZo),e(K,s6),e(s6,gfe),e(gfe,zZo),e(s6,VZo),e(s6,HN),e(HN,XZo),e(s6,WZo),e(K,QZo),e(K,l6),e(l6,hfe),e(hfe,HZo),e(l6,UZo),e(l6,UN),e(UN,JZo),e(l6,YZo),e(K,KZo),e(K,i6),e(i6,ufe),e(ufe,ZZo),e(i6,eer),e(i6,JN),e(JN,oer),e(i6,rer),e(K,ter),e(K,d6),e(d6,pfe),e(pfe,aer),e(d6,ner),e(d6,YN),e(YN,ser),e(d6,ler),e(K,ier),e(K,c6),e(c6,_fe),e(_fe,der),e(c6,cer),e(c6,KN),e(KN,fer),e(c6,mer),e(K,ger),e(K,f6),e(f6,vfe),e(vfe,her),e(f6,uer),e(f6,ZN),e(ZN,per),e(f6,_er),e(K,ver),e(K,m6),e(m6,bfe),e(bfe,ber),e(m6,Ter),e(m6,eD),e(eD,Fer),e(m6,Cer),e(K,Eer),e(K,g6),e(g6,Tfe),e(Tfe,Mer),e(g6,yer),e(g6,oD),e(oD,wer),e(g6,Aer),e(K,Ler),e(K,h6),e(h6,Ffe),e(Ffe,Ber),e(h6,ker),e(h6,rD),e(rD,xer),e(h6,Rer),e(K,Ser),e(K,u6),e(u6,Cfe),e(Cfe,Per),e(u6,$er),e(u6,tD),e(tD,Ier),e(u6,jer),e(K,Ner),e(K,p6),e(p6,Efe),e(Efe,Der),e(p6,qer),e(p6,aD),e(aD,Oer),e(p6,Ger),e(K,zer),e(K,_6),e(_6,Mfe),e(Mfe,Ver),e(_6,Xer),e(_6,nD),e(nD,Wer),e(_6,Qer),e(bo,Her),e(bo,yfe),e(yfe,Uer),e(bo,Jer),g(rw,bo,null),v(d,TAe,_),v(d,Zd,_),e(Zd,v6),e(v6,wfe),g(tw,wfe,null),e(Zd,Yer),e(Zd,Afe),e(Afe,Ker),v(d,FAe,_),v(d,ur,_),g(aw,ur,null),e(ur,Zer),e(ur,ec),e(ec,eor),e(ec,Lfe),e(Lfe,oor),e(ec,ror),e(ec,Bfe),e(Bfe,tor),e(ec,aor),e(ur,nor),e(ur,nw),e(nw,sor),e(nw,kfe),e(kfe,lor),e(nw,ior),e(ur,dor),e(ur,nt),g(sw,nt,null),e(nt,cor),e(nt,xfe),e(xfe,mor),e(nt,gor),e(nt,oc),e(oc,hor),e(oc,Rfe),e(Rfe,uor),e(oc,por),e(oc,Sfe),e(Sfe,_or),e(oc,vor),e(nt,bor),e(nt,Pfe),e(Pfe,Tor),e(nt,For),g(lw,nt,null),e(ur,Cor),e(ur,To),g(iw,To,null),e(To,Eor),e(To,$fe),e($fe,Mor),e(To,yor),e(To,tn),e(tn,wor),e(tn,Ife),e(Ife,Aor),e(tn,Lor),e(tn,jfe),e(jfe,Bor),e(tn,kor),e(tn,Nfe),e(Nfe,xor),e(tn,Ror),e(To,Sor),e(To,Z),e(Z,b6),e(b6,Dfe),e(Dfe,Por),e(b6,$or),e(b6,sD),e(sD,Ior),e(b6,jor),e(Z,Nor),e(Z,T6),e(T6,qfe),e(qfe,Dor),e(T6,qor),e(T6,lD),e(lD,Oor),e(T6,Gor),e(Z,zor),e(Z,F6),e(F6,Ofe),e(Ofe,Vor),e(F6,Xor),e(F6,iD),e(iD,Wor),e(F6,Qor),e(Z,Hor),e(Z,C6),e(C6,Gfe),e(Gfe,Uor),e(C6,Jor),e(C6,dD),e(dD,Yor),e(C6,Kor),e(Z,Zor),e(Z,E6),e(E6,zfe),e(zfe,err),e(E6,orr),e(E6,cD),e(cD,rrr),e(E6,trr),e(Z,arr),e(Z,M6),e(M6,Vfe),e(Vfe,nrr),e(M6,srr),e(M6,fD),e(fD,lrr),e(M6,irr),e(Z,drr),e(Z,y6),e(y6,Xfe),e(Xfe,crr),e(y6,frr),e(y6,mD),e(mD,mrr),e(y6,grr),e(Z,hrr),e(Z,w6),e(w6,Wfe),e(Wfe,urr),e(w6,prr),e(w6,gD),e(gD,_rr),e(w6,vrr),e(Z,brr),e(Z,A6),e(A6,Qfe),e(Qfe,Trr),e(A6,Frr),e(A6,hD),e(hD,Crr),e(A6,Err),e(Z,Mrr),e(Z,L6),e(L6,Hfe),e(Hfe,yrr),e(L6,wrr),e(L6,uD),e(uD,Arr),e(L6,Lrr),e(Z,Brr),e(Z,B6),e(B6,Ufe),e(Ufe,krr),e(B6,xrr),e(B6,pD),e(pD,Rrr),e(B6,Srr),e(Z,Prr),e(Z,k6),e(k6,Jfe),e(Jfe,$rr),e(k6,Irr),e(k6,_D),e(_D,jrr),e(k6,Nrr),e(Z,Drr),e(Z,x6),e(x6,Yfe),e(Yfe,qrr),e(x6,Orr),e(x6,vD),e(vD,Grr),e(x6,zrr),e(Z,Vrr),e(Z,R6),e(R6,Kfe),e(Kfe,Xrr),e(R6,Wrr),e(R6,bD),e(bD,Qrr),e(R6,Hrr),e(Z,Urr),e(Z,S6),e(S6,Zfe),e(Zfe,Jrr),e(S6,Yrr),e(S6,TD),e(TD,Krr),e(S6,Zrr),e(Z,etr),e(Z,P6),e(P6,eme),e(eme,otr),e(P6,rtr),e(P6,FD),e(FD,ttr),e(P6,atr),e(Z,ntr),e(Z,$6),e($6,ome),e(ome,str),e($6,ltr),e($6,CD),e(CD,itr),e($6,dtr),e(Z,ctr),e(Z,I6),e(I6,rme),e(rme,ftr),e(I6,mtr),e(I6,ED),e(ED,gtr),e(I6,htr),e(Z,utr),e(Z,j6),e(j6,tme),e(tme,ptr),e(j6,_tr),e(j6,MD),e(MD,vtr),e(j6,btr),e(To,Ttr),e(To,ame),e(ame,Ftr),e(To,Ctr),g(dw,To,null),v(d,CAe,_),v(d,rc,_),e(rc,N6),e(N6,nme),g(cw,nme,null),e(rc,Etr),e(rc,sme),e(sme,Mtr),v(d,EAe,_),v(d,pr,_),g(fw,pr,null),e(pr,ytr),e(pr,tc),e(tc,wtr),e(tc,lme),e(lme,Atr),e(tc,Ltr),e(tc,ime),e(ime,Btr),e(tc,ktr),e(pr,xtr),e(pr,mw),e(mw,Rtr),e(mw,dme),e(dme,Str),e(mw,Ptr),e(pr,$tr),e(pr,st),g(gw,st,null),e(st,Itr),e(st,cme),e(cme,jtr),e(st,Ntr),e(st,ac),e(ac,Dtr),e(ac,fme),e(fme,qtr),e(ac,Otr),e(ac,mme),e(mme,Gtr),e(ac,ztr),e(st,Vtr),e(st,gme),e(gme,Xtr),e(st,Wtr),g(hw,st,null),e(pr,Qtr),e(pr,Fo),g(uw,Fo,null),e(Fo,Htr),e(Fo,hme),e(hme,Utr),e(Fo,Jtr),e(Fo,an),e(an,Ytr),e(an,ume),e(ume,Ktr),e(an,Ztr),e(an,pme),e(pme,ear),e(an,oar),e(an,_me),e(_me,rar),e(an,tar),e(Fo,aar),e(Fo,vme),e(vme,D6),e(D6,bme),e(bme,nar),e(D6,sar),e(D6,yD),e(yD,lar),e(D6,iar),e(Fo,dar),e(Fo,Tme),e(Tme,car),e(Fo,far),g(pw,Fo,null),v(d,MAe,_),v(d,nc,_),e(nc,q6),e(q6,Fme),g(_w,Fme,null),e(nc,mar),e(nc,Cme),e(Cme,gar),v(d,yAe,_),v(d,_r,_),g(vw,_r,null),e(_r,har),e(_r,sc),e(sc,uar),e(sc,Eme),e(Eme,par),e(sc,_ar),e(sc,Mme),e(Mme,bar),e(sc,Tar),e(_r,Far),e(_r,bw),e(bw,Car),e(bw,yme),e(yme,Ear),e(bw,Mar),e(_r,yar),e(_r,lt),g(Tw,lt,null),e(lt,war),e(lt,wme),e(wme,Aar),e(lt,Lar),e(lt,lc),e(lc,Bar),e(lc,Ame),e(Ame,kar),e(lc,xar),e(lc,Lme),e(Lme,Rar),e(lc,Sar),e(lt,Par),e(lt,Bme),e(Bme,$ar),e(lt,Iar),g(Fw,lt,null),e(_r,jar),e(_r,Co),g(Cw,Co,null),e(Co,Nar),e(Co,kme),e(kme,Dar),e(Co,qar),e(Co,nn),e(nn,Oar),e(nn,xme),e(xme,Gar),e(nn,zar),e(nn,Rme),e(Rme,Var),e(nn,Xar),e(nn,Sme),e(Sme,War),e(nn,Qar),e(Co,Har),e(Co,W),e(W,O6),e(O6,Pme),e(Pme,Uar),e(O6,Jar),e(O6,wD),e(wD,Yar),e(O6,Kar),e(W,Zar),e(W,G6),e(G6,$me),e($me,enr),e(G6,onr),e(G6,AD),e(AD,rnr),e(G6,tnr),e(W,anr),e(W,z6),e(z6,Ime),e(Ime,nnr),e(z6,snr),e(z6,LD),e(LD,lnr),e(z6,inr),e(W,dnr),e(W,V6),e(V6,jme),e(jme,cnr),e(V6,fnr),e(V6,BD),e(BD,mnr),e(V6,gnr),e(W,hnr),e(W,X6),e(X6,Nme),e(Nme,unr),e(X6,pnr),e(X6,kD),e(kD,_nr),e(X6,vnr),e(W,bnr),e(W,W6),e(W6,Dme),e(Dme,Tnr),e(W6,Fnr),e(W6,xD),e(xD,Cnr),e(W6,Enr),e(W,Mnr),e(W,Q6),e(Q6,qme),e(qme,ynr),e(Q6,wnr),e(Q6,RD),e(RD,Anr),e(Q6,Lnr),e(W,Bnr),e(W,H6),e(H6,Ome),e(Ome,knr),e(H6,xnr),e(H6,SD),e(SD,Rnr),e(H6,Snr),e(W,Pnr),e(W,U6),e(U6,Gme),e(Gme,$nr),e(U6,Inr),e(U6,PD),e(PD,jnr),e(U6,Nnr),e(W,Dnr),e(W,J6),e(J6,zme),e(zme,qnr),e(J6,Onr),e(J6,$D),e($D,Gnr),e(J6,znr),e(W,Vnr),e(W,Y6),e(Y6,Vme),e(Vme,Xnr),e(Y6,Wnr),e(Y6,ID),e(ID,Qnr),e(Y6,Hnr),e(W,Unr),e(W,K6),e(K6,Xme),e(Xme,Jnr),e(K6,Ynr),e(K6,jD),e(jD,Knr),e(K6,Znr),e(W,esr),e(W,Z6),e(Z6,Wme),e(Wme,osr),e(Z6,rsr),e(Z6,ND),e(ND,tsr),e(Z6,asr),e(W,nsr),e(W,eF),e(eF,Qme),e(Qme,ssr),e(eF,lsr),e(eF,DD),e(DD,isr),e(eF,dsr),e(W,csr),e(W,oF),e(oF,Hme),e(Hme,fsr),e(oF,msr),e(oF,qD),e(qD,gsr),e(oF,hsr),e(W,usr),e(W,rF),e(rF,Ume),e(Ume,psr),e(rF,_sr),e(rF,OD),e(OD,vsr),e(rF,bsr),e(W,Tsr),e(W,tF),e(tF,Jme),e(Jme,Fsr),e(tF,Csr),e(tF,GD),e(GD,Esr),e(tF,Msr),e(W,ysr),e(W,aF),e(aF,Yme),e(Yme,wsr),e(aF,Asr),e(aF,zD),e(zD,Lsr),e(aF,Bsr),e(W,ksr),e(W,nF),e(nF,Kme),e(Kme,xsr),e(nF,Rsr),e(nF,VD),e(VD,Ssr),e(nF,Psr),e(W,$sr),e(W,sF),e(sF,Zme),e(Zme,Isr),e(sF,jsr),e(sF,XD),e(XD,Nsr),e(sF,Dsr),e(W,qsr),e(W,lF),e(lF,ege),e(ege,Osr),e(lF,Gsr),e(lF,WD),e(WD,zsr),e(lF,Vsr),e(W,Xsr),e(W,iF),e(iF,oge),e(oge,Wsr),e(iF,Qsr),e(iF,QD),e(QD,Hsr),e(iF,Usr),e(W,Jsr),e(W,dF),e(dF,rge),e(rge,Ysr),e(dF,Ksr),e(dF,HD),e(HD,Zsr),e(dF,elr),e(Co,olr),e(Co,tge),e(tge,rlr),e(Co,tlr),g(Ew,Co,null),v(d,wAe,_),v(d,ic,_),e(ic,cF),e(cF,age),g(Mw,age,null),e(ic,alr),e(ic,nge),e(nge,nlr),v(d,AAe,_),v(d,vr,_),g(yw,vr,null),e(vr,slr),e(vr,dc),e(dc,llr),e(dc,sge),e(sge,ilr),e(dc,dlr),e(dc,lge),e(lge,clr),e(dc,flr),e(vr,mlr),e(vr,ww),e(ww,glr),e(ww,ige),e(ige,hlr),e(ww,ulr),e(vr,plr),e(vr,it),g(Aw,it,null),e(it,_lr),e(it,dge),e(dge,vlr),e(it,blr),e(it,cc),e(cc,Tlr),e(cc,cge),e(cge,Flr),e(cc,Clr),e(cc,fge),e(fge,Elr),e(cc,Mlr),e(it,ylr),e(it,mge),e(mge,wlr),e(it,Alr),g(Lw,it,null),e(vr,Llr),e(vr,Eo),g(Bw,Eo,null),e(Eo,Blr),e(Eo,gge),e(gge,klr),e(Eo,xlr),e(Eo,sn),e(sn,Rlr),e(sn,hge),e(hge,Slr),e(sn,Plr),e(sn,uge),e(uge,$lr),e(sn,Ilr),e(sn,pge),e(pge,jlr),e(sn,Nlr),e(Eo,Dlr),e(Eo,fc),e(fc,fF),e(fF,_ge),e(_ge,qlr),e(fF,Olr),e(fF,UD),e(UD,Glr),e(fF,zlr),e(fc,Vlr),e(fc,mF),e(mF,vge),e(vge,Xlr),e(mF,Wlr),e(mF,JD),e(JD,Qlr),e(mF,Hlr),e(fc,Ulr),e(fc,gF),e(gF,bge),e(bge,Jlr),e(gF,Ylr),e(gF,YD),e(YD,Klr),e(gF,Zlr),e(Eo,eir),e(Eo,Tge),e(Tge,oir),e(Eo,rir),g(kw,Eo,null),v(d,LAe,_),v(d,mc,_),e(mc,hF),e(hF,Fge),g(xw,Fge,null),e(mc,tir),e(mc,Cge),e(Cge,air),v(d,BAe,_),v(d,br,_),g(Rw,br,null),e(br,nir),e(br,gc),e(gc,sir),e(gc,Ege),e(Ege,lir),e(gc,iir),e(gc,Mge),e(Mge,dir),e(gc,cir),e(br,fir),e(br,Sw),e(Sw,mir),e(Sw,yge),e(yge,gir),e(Sw,hir),e(br,uir),e(br,dt),g(Pw,dt,null),e(dt,pir),e(dt,wge),e(wge,_ir),e(dt,vir),e(dt,hc),e(hc,bir),e(hc,Age),e(Age,Tir),e(hc,Fir),e(hc,Lge),e(Lge,Cir),e(hc,Eir),e(dt,Mir),e(dt,Bge),e(Bge,yir),e(dt,wir),g($w,dt,null),e(br,Air),e(br,Mo),g(Iw,Mo,null),e(Mo,Lir),e(Mo,kge),e(kge,Bir),e(Mo,kir),e(Mo,ln),e(ln,xir),e(ln,xge),e(xge,Rir),e(ln,Sir),e(ln,Rge),e(Rge,Pir),e(ln,$ir),e(ln,Sge),e(Sge,Iir),e(ln,jir),e(Mo,Nir),e(Mo,ce),e(ce,uF),e(uF,Pge),e(Pge,Dir),e(uF,qir),e(uF,KD),e(KD,Oir),e(uF,Gir),e(ce,zir),e(ce,pF),e(pF,$ge),e($ge,Vir),e(pF,Xir),e(pF,ZD),e(ZD,Wir),e(pF,Qir),e(ce,Hir),e(ce,_F),e(_F,Ige),e(Ige,Uir),e(_F,Jir),e(_F,eq),e(eq,Yir),e(_F,Kir),e(ce,Zir),e(ce,vF),e(vF,jge),e(jge,edr),e(vF,odr),e(vF,oq),e(oq,rdr),e(vF,tdr),e(ce,adr),e(ce,bF),e(bF,Nge),e(Nge,ndr),e(bF,sdr),e(bF,rq),e(rq,ldr),e(bF,idr),e(ce,ddr),e(ce,TF),e(TF,Dge),e(Dge,cdr),e(TF,fdr),e(TF,tq),e(tq,mdr),e(TF,gdr),e(ce,hdr),e(ce,FF),e(FF,qge),e(qge,udr),e(FF,pdr),e(FF,aq),e(aq,_dr),e(FF,vdr),e(ce,bdr),e(ce,CF),e(CF,Oge),e(Oge,Tdr),e(CF,Fdr),e(CF,nq),e(nq,Cdr),e(CF,Edr),e(ce,Mdr),e(ce,EF),e(EF,Gge),e(Gge,ydr),e(EF,wdr),e(EF,sq),e(sq,Adr),e(EF,Ldr),e(ce,Bdr),e(ce,MF),e(MF,zge),e(zge,kdr),e(MF,xdr),e(MF,lq),e(lq,Rdr),e(MF,Sdr),e(ce,Pdr),e(ce,yF),e(yF,Vge),e(Vge,$dr),e(yF,Idr),e(yF,iq),e(iq,jdr),e(yF,Ndr),e(Mo,Ddr),e(Mo,Xge),e(Xge,qdr),e(Mo,Odr),g(jw,Mo,null),v(d,kAe,_),v(d,uc,_),e(uc,wF),e(wF,Wge),g(Nw,Wge,null),e(uc,Gdr),e(uc,Qge),e(Qge,zdr),v(d,xAe,_),v(d,Tr,_),g(Dw,Tr,null),e(Tr,Vdr),e(Tr,pc),e(pc,Xdr),e(pc,Hge),e(Hge,Wdr),e(pc,Qdr),e(pc,Uge),e(Uge,Hdr),e(pc,Udr),e(Tr,Jdr),e(Tr,qw),e(qw,Ydr),e(qw,Jge),e(Jge,Kdr),e(qw,Zdr),e(Tr,ecr),e(Tr,ct),g(Ow,ct,null),e(ct,ocr),e(ct,Yge),e(Yge,rcr),e(ct,tcr),e(ct,_c),e(_c,acr),e(_c,Kge),e(Kge,ncr),e(_c,scr),e(_c,Zge),e(Zge,lcr),e(_c,icr),e(ct,dcr),e(ct,ehe),e(ehe,ccr),e(ct,fcr),g(Gw,ct,null),e(Tr,mcr),e(Tr,yo),g(zw,yo,null),e(yo,gcr),e(yo,ohe),e(ohe,hcr),e(yo,ucr),e(yo,dn),e(dn,pcr),e(dn,rhe),e(rhe,_cr),e(dn,vcr),e(dn,the),e(the,bcr),e(dn,Tcr),e(dn,ahe),e(ahe,Fcr),e(dn,Ccr),e(yo,Ecr),e(yo,ve),e(ve,AF),e(AF,nhe),e(nhe,Mcr),e(AF,ycr),e(AF,dq),e(dq,wcr),e(AF,Acr),e(ve,Lcr),e(ve,LF),e(LF,she),e(she,Bcr),e(LF,kcr),e(LF,cq),e(cq,xcr),e(LF,Rcr),e(ve,Scr),e(ve,BF),e(BF,lhe),e(lhe,Pcr),e(BF,$cr),e(BF,fq),e(fq,Icr),e(BF,jcr),e(ve,Ncr),e(ve,kF),e(kF,ihe),e(ihe,Dcr),e(kF,qcr),e(kF,mq),e(mq,Ocr),e(kF,Gcr),e(ve,zcr),e(ve,xF),e(xF,dhe),e(dhe,Vcr),e(xF,Xcr),e(xF,gq),e(gq,Wcr),e(xF,Qcr),e(ve,Hcr),e(ve,RF),e(RF,che),e(che,Ucr),e(RF,Jcr),e(RF,hq),e(hq,Ycr),e(RF,Kcr),e(ve,Zcr),e(ve,SF),e(SF,fhe),e(fhe,efr),e(SF,ofr),e(SF,uq),e(uq,rfr),e(SF,tfr),e(ve,afr),e(ve,PF),e(PF,mhe),e(mhe,nfr),e(PF,sfr),e(PF,pq),e(pq,lfr),e(PF,ifr),e(ve,dfr),e(ve,$F),e($F,ghe),e(ghe,cfr),e($F,ffr),e($F,_q),e(_q,mfr),e($F,gfr),e(yo,hfr),e(yo,hhe),e(hhe,ufr),e(yo,pfr),g(Vw,yo,null),v(d,RAe,_),v(d,vc,_),e(vc,IF),e(IF,uhe),g(Xw,uhe,null),e(vc,_fr),e(vc,phe),e(phe,vfr),v(d,SAe,_),v(d,Fr,_),g(Ww,Fr,null),e(Fr,bfr),e(Fr,bc),e(bc,Tfr),e(bc,_he),e(_he,Ffr),e(bc,Cfr),e(bc,vhe),e(vhe,Efr),e(bc,Mfr),e(Fr,yfr),e(Fr,Qw),e(Qw,wfr),e(Qw,bhe),e(bhe,Afr),e(Qw,Lfr),e(Fr,Bfr),e(Fr,ft),g(Hw,ft,null),e(ft,kfr),e(ft,The),e(The,xfr),e(ft,Rfr),e(ft,Tc),e(Tc,Sfr),e(Tc,Fhe),e(Fhe,Pfr),e(Tc,$fr),e(Tc,Che),e(Che,Ifr),e(Tc,jfr),e(ft,Nfr),e(ft,Ehe),e(Ehe,Dfr),e(ft,qfr),g(Uw,ft,null),e(Fr,Ofr),e(Fr,wo),g(Jw,wo,null),e(wo,Gfr),e(wo,Mhe),e(Mhe,zfr),e(wo,Vfr),e(wo,cn),e(cn,Xfr),e(cn,yhe),e(yhe,Wfr),e(cn,Qfr),e(cn,whe),e(whe,Hfr),e(cn,Ufr),e(cn,Ahe),e(Ahe,Jfr),e(cn,Yfr),e(wo,Kfr),e(wo,be),e(be,jF),e(jF,Lhe),e(Lhe,Zfr),e(jF,emr),e(jF,vq),e(vq,omr),e(jF,rmr),e(be,tmr),e(be,NF),e(NF,Bhe),e(Bhe,amr),e(NF,nmr),e(NF,bq),e(bq,smr),e(NF,lmr),e(be,imr),e(be,DF),e(DF,khe),e(khe,dmr),e(DF,cmr),e(DF,Tq),e(Tq,fmr),e(DF,mmr),e(be,gmr),e(be,qF),e(qF,xhe),e(xhe,hmr),e(qF,umr),e(qF,Fq),e(Fq,pmr),e(qF,_mr),e(be,vmr),e(be,OF),e(OF,Rhe),e(Rhe,bmr),e(OF,Tmr),e(OF,Cq),e(Cq,Fmr),e(OF,Cmr),e(be,Emr),e(be,GF),e(GF,She),e(She,Mmr),e(GF,ymr),e(GF,Eq),e(Eq,wmr),e(GF,Amr),e(be,Lmr),e(be,zF),e(zF,Phe),e(Phe,Bmr),e(zF,kmr),e(zF,Mq),e(Mq,xmr),e(zF,Rmr),e(be,Smr),e(be,VF),e(VF,$he),e($he,Pmr),e(VF,$mr),e(VF,yq),e(yq,Imr),e(VF,jmr),e(be,Nmr),e(be,XF),e(XF,Ihe),e(Ihe,Dmr),e(XF,qmr),e(XF,wq),e(wq,Omr),e(XF,Gmr),e(wo,zmr),e(wo,jhe),e(jhe,Vmr),e(wo,Xmr),g(Yw,wo,null),v(d,PAe,_),v(d,Fc,_),e(Fc,WF),e(WF,Nhe),g(Kw,Nhe,null),e(Fc,Wmr),e(Fc,Dhe),e(Dhe,Qmr),v(d,$Ae,_),v(d,Cr,_),g(Zw,Cr,null),e(Cr,Hmr),e(Cr,Cc),e(Cc,Umr),e(Cc,qhe),e(qhe,Jmr),e(Cc,Ymr),e(Cc,Ohe),e(Ohe,Kmr),e(Cc,Zmr),e(Cr,egr),e(Cr,eA),e(eA,ogr),e(eA,Ghe),e(Ghe,rgr),e(eA,tgr),e(Cr,agr),e(Cr,mt),g(oA,mt,null),e(mt,ngr),e(mt,zhe),e(zhe,sgr),e(mt,lgr),e(mt,Ec),e(Ec,igr),e(Ec,Vhe),e(Vhe,dgr),e(Ec,cgr),e(Ec,Xhe),e(Xhe,fgr),e(Ec,mgr),e(mt,ggr),e(mt,Whe),e(Whe,hgr),e(mt,ugr),g(rA,mt,null),e(Cr,pgr),e(Cr,Ao),g(tA,Ao,null),e(Ao,_gr),e(Ao,Qhe),e(Qhe,vgr),e(Ao,bgr),e(Ao,fn),e(fn,Tgr),e(fn,Hhe),e(Hhe,Fgr),e(fn,Cgr),e(fn,Uhe),e(Uhe,Egr),e(fn,Mgr),e(fn,Jhe),e(Jhe,ygr),e(fn,wgr),e(Ao,Agr),e(Ao,Te),e(Te,QF),e(QF,Yhe),e(Yhe,Lgr),e(QF,Bgr),e(QF,Aq),e(Aq,kgr),e(QF,xgr),e(Te,Rgr),e(Te,HF),e(HF,Khe),e(Khe,Sgr),e(HF,Pgr),e(HF,Lq),e(Lq,$gr),e(HF,Igr),e(Te,jgr),e(Te,UF),e(UF,Zhe),e(Zhe,Ngr),e(UF,Dgr),e(UF,Bq),e(Bq,qgr),e(UF,Ogr),e(Te,Ggr),e(Te,JF),e(JF,eue),e(eue,zgr),e(JF,Vgr),e(JF,kq),e(kq,Xgr),e(JF,Wgr),e(Te,Qgr),e(Te,YF),e(YF,oue),e(oue,Hgr),e(YF,Ugr),e(YF,xq),e(xq,Jgr),e(YF,Ygr),e(Te,Kgr),e(Te,KF),e(KF,rue),e(rue,Zgr),e(KF,ehr),e(KF,Rq),e(Rq,ohr),e(KF,rhr),e(Te,thr),e(Te,ZF),e(ZF,tue),e(tue,ahr),e(ZF,nhr),e(ZF,Sq),e(Sq,shr),e(ZF,lhr),e(Te,ihr),e(Te,eC),e(eC,aue),e(aue,dhr),e(eC,chr),e(eC,Pq),e(Pq,fhr),e(eC,mhr),e(Te,ghr),e(Te,oC),e(oC,nue),e(nue,hhr),e(oC,uhr),e(oC,$q),e($q,phr),e(oC,_hr),e(Ao,vhr),e(Ao,sue),e(sue,bhr),e(Ao,Thr),g(aA,Ao,null),v(d,IAe,_),v(d,Mc,_),e(Mc,rC),e(rC,lue),g(nA,lue,null),e(Mc,Fhr),e(Mc,iue),e(iue,Chr),v(d,jAe,_),v(d,Er,_),g(sA,Er,null),e(Er,Ehr),e(Er,yc),e(yc,Mhr),e(yc,due),e(due,yhr),e(yc,whr),e(yc,cue),e(cue,Ahr),e(yc,Lhr),e(Er,Bhr),e(Er,lA),e(lA,khr),e(lA,fue),e(fue,xhr),e(lA,Rhr),e(Er,Shr),e(Er,gt),g(iA,gt,null),e(gt,Phr),e(gt,mue),e(mue,$hr),e(gt,Ihr),e(gt,wc),e(wc,jhr),e(wc,gue),e(gue,Nhr),e(wc,Dhr),e(wc,hue),e(hue,qhr),e(wc,Ohr),e(gt,Ghr),e(gt,uue),e(uue,zhr),e(gt,Vhr),g(dA,gt,null),e(Er,Xhr),e(Er,Lo),g(cA,Lo,null),e(Lo,Whr),e(Lo,pue),e(pue,Qhr),e(Lo,Hhr),e(Lo,mn),e(mn,Uhr),e(mn,_ue),e(_ue,Jhr),e(mn,Yhr),e(mn,vue),e(vue,Khr),e(mn,Zhr),e(mn,bue),e(bue,eur),e(mn,our),e(Lo,rur),e(Lo,Fe),e(Fe,tC),e(tC,Tue),e(Tue,tur),e(tC,aur),e(tC,Iq),e(Iq,nur),e(tC,sur),e(Fe,lur),e(Fe,aC),e(aC,Fue),e(Fue,iur),e(aC,dur),e(aC,jq),e(jq,cur),e(aC,fur),e(Fe,mur),e(Fe,nC),e(nC,Cue),e(Cue,gur),e(nC,hur),e(nC,Nq),e(Nq,uur),e(nC,pur),e(Fe,_ur),e(Fe,sC),e(sC,Eue),e(Eue,vur),e(sC,bur),e(sC,Dq),e(Dq,Tur),e(sC,Fur),e(Fe,Cur),e(Fe,lC),e(lC,Mue),e(Mue,Eur),e(lC,Mur),e(lC,qq),e(qq,yur),e(lC,wur),e(Fe,Aur),e(Fe,iC),e(iC,yue),e(yue,Lur),e(iC,Bur),e(iC,Oq),e(Oq,kur),e(iC,xur),e(Fe,Rur),e(Fe,dC),e(dC,wue),e(wue,Sur),e(dC,Pur),e(dC,Gq),e(Gq,$ur),e(dC,Iur),e(Fe,jur),e(Fe,cC),e(cC,Aue),e(Aue,Nur),e(cC,Dur),e(cC,zq),e(zq,qur),e(cC,Our),e(Fe,Gur),e(Fe,fC),e(fC,Lue),e(Lue,zur),e(fC,Vur),e(fC,Vq),e(Vq,Xur),e(fC,Wur),e(Lo,Qur),e(Lo,Bue),e(Bue,Hur),e(Lo,Uur),g(fA,Lo,null),v(d,NAe,_),v(d,Ac,_),e(Ac,mC),e(mC,kue),g(mA,kue,null),e(Ac,Jur),e(Ac,xue),e(xue,Yur),v(d,DAe,_),v(d,Mr,_),g(gA,Mr,null),e(Mr,Kur),e(Mr,Lc),e(Lc,Zur),e(Lc,Rue),e(Rue,epr),e(Lc,opr),e(Lc,Sue),e(Sue,rpr),e(Lc,tpr),e(Mr,apr),e(Mr,hA),e(hA,npr),e(hA,Pue),e(Pue,spr),e(hA,lpr),e(Mr,ipr),e(Mr,ht),g(uA,ht,null),e(ht,dpr),e(ht,$ue),e($ue,cpr),e(ht,fpr),e(ht,Bc),e(Bc,mpr),e(Bc,Iue),e(Iue,gpr),e(Bc,hpr),e(Bc,jue),e(jue,upr),e(Bc,ppr),e(ht,_pr),e(ht,Nue),e(Nue,vpr),e(ht,bpr),g(pA,ht,null),e(Mr,Tpr),e(Mr,Bo),g(_A,Bo,null),e(Bo,Fpr),e(Bo,Due),e(Due,Cpr),e(Bo,Epr),e(Bo,gn),e(gn,Mpr),e(gn,que),e(que,ypr),e(gn,wpr),e(gn,Oue),e(Oue,Apr),e(gn,Lpr),e(gn,Gue),e(Gue,Bpr),e(gn,kpr),e(Bo,xpr),e(Bo,to),e(to,gC),e(gC,zue),e(zue,Rpr),e(gC,Spr),e(gC,Xq),e(Xq,Ppr),e(gC,$pr),e(to,Ipr),e(to,hC),e(hC,Vue),e(Vue,jpr),e(hC,Npr),e(hC,Wq),e(Wq,Dpr),e(hC,qpr),e(to,Opr),e(to,uC),e(uC,Xue),e(Xue,Gpr),e(uC,zpr),e(uC,Qq),e(Qq,Vpr),e(uC,Xpr),e(to,Wpr),e(to,pC),e(pC,Wue),e(Wue,Qpr),e(pC,Hpr),e(pC,Hq),e(Hq,Upr),e(pC,Jpr),e(to,Ypr),e(to,_C),e(_C,Que),e(Que,Kpr),e(_C,Zpr),e(_C,Uq),e(Uq,e_r),e(_C,o_r),e(to,r_r),e(to,vC),e(vC,Hue),e(Hue,t_r),e(vC,a_r),e(vC,Jq),e(Jq,n_r),e(vC,s_r),e(to,l_r),e(to,bC),e(bC,Uue),e(Uue,i_r),e(bC,d_r),e(bC,Yq),e(Yq,c_r),e(bC,f_r),e(Bo,m_r),e(Bo,Jue),e(Jue,g_r),e(Bo,h_r),g(vA,Bo,null),v(d,qAe,_),v(d,kc,_),e(kc,TC),e(TC,Yue),g(bA,Yue,null),e(kc,u_r),e(kc,Kue),e(Kue,p_r),v(d,OAe,_),v(d,yr,_),g(TA,yr,null),e(yr,__r),e(yr,xc),e(xc,v_r),e(xc,Zue),e(Zue,b_r),e(xc,T_r),e(xc,epe),e(epe,F_r),e(xc,C_r),e(yr,E_r),e(yr,FA),e(FA,M_r),e(FA,ope),e(ope,y_r),e(FA,w_r),e(yr,A_r),e(yr,ut),g(CA,ut,null),e(ut,L_r),e(ut,rpe),e(rpe,B_r),e(ut,k_r),e(ut,Rc),e(Rc,x_r),e(Rc,tpe),e(tpe,R_r),e(Rc,S_r),e(Rc,ape),e(ape,P_r),e(Rc,$_r),e(ut,I_r),e(ut,npe),e(npe,j_r),e(ut,N_r),g(EA,ut,null),e(yr,D_r),e(yr,ko),g(MA,ko,null),e(ko,q_r),e(ko,spe),e(spe,O_r),e(ko,G_r),e(ko,hn),e(hn,z_r),e(hn,lpe),e(lpe,V_r),e(hn,X_r),e(hn,ipe),e(ipe,W_r),e(hn,Q_r),e(hn,dpe),e(dpe,H_r),e(hn,U_r),e(ko,J_r),e(ko,ao),e(ao,FC),e(FC,cpe),e(cpe,Y_r),e(FC,K_r),e(FC,Kq),e(Kq,Z_r),e(FC,e2r),e(ao,o2r),e(ao,CC),e(CC,fpe),e(fpe,r2r),e(CC,t2r),e(CC,Zq),e(Zq,a2r),e(CC,n2r),e(ao,s2r),e(ao,EC),e(EC,mpe),e(mpe,l2r),e(EC,i2r),e(EC,eO),e(eO,d2r),e(EC,c2r),e(ao,f2r),e(ao,MC),e(MC,gpe),e(gpe,m2r),e(MC,g2r),e(MC,oO),e(oO,h2r),e(MC,u2r),e(ao,p2r),e(ao,yC),e(yC,hpe),e(hpe,_2r),e(yC,v2r),e(yC,rO),e(rO,b2r),e(yC,T2r),e(ao,F2r),e(ao,wC),e(wC,upe),e(upe,C2r),e(wC,E2r),e(wC,tO),e(tO,M2r),e(wC,y2r),e(ao,w2r),e(ao,AC),e(AC,ppe),e(ppe,A2r),e(AC,L2r),e(AC,aO),e(aO,B2r),e(AC,k2r),e(ko,x2r),e(ko,_pe),e(_pe,R2r),e(ko,S2r),g(yA,ko,null),v(d,GAe,_),v(d,Sc,_),e(Sc,LC),e(LC,vpe),g(wA,vpe,null),e(Sc,P2r),e(Sc,bpe),e(bpe,$2r),v(d,zAe,_),v(d,wr,_),g(AA,wr,null),e(wr,I2r),e(wr,Pc),e(Pc,j2r),e(Pc,Tpe),e(Tpe,N2r),e(Pc,D2r),e(Pc,Fpe),e(Fpe,q2r),e(Pc,O2r),e(wr,G2r),e(wr,LA),e(LA,z2r),e(LA,Cpe),e(Cpe,V2r),e(LA,X2r),e(wr,W2r),e(wr,pt),g(BA,pt,null),e(pt,Q2r),e(pt,Epe),e(Epe,H2r),e(pt,U2r),e(pt,$c),e($c,J2r),e($c,Mpe),e(Mpe,Y2r),e($c,K2r),e($c,ype),e(ype,Z2r),e($c,evr),e(pt,ovr),e(pt,wpe),e(wpe,rvr),e(pt,tvr),g(kA,pt,null),e(wr,avr),e(wr,xo),g(xA,xo,null),e(xo,nvr),e(xo,Ape),e(Ape,svr),e(xo,lvr),e(xo,un),e(un,ivr),e(un,Lpe),e(Lpe,dvr),e(un,cvr),e(un,Bpe),e(Bpe,fvr),e(un,mvr),e(un,kpe),e(kpe,gvr),e(un,hvr),e(xo,uvr),e(xo,xpe),e(xpe,BC),e(BC,Rpe),e(Rpe,pvr),e(BC,_vr),e(BC,nO),e(nO,vvr),e(BC,bvr),e(xo,Tvr),e(xo,Spe),e(Spe,Fvr),e(xo,Cvr),g(RA,xo,null),v(d,VAe,_),v(d,Ic,_),e(Ic,kC),e(kC,Ppe),g(SA,Ppe,null),e(Ic,Evr),e(Ic,$pe),e($pe,Mvr),v(d,XAe,_),v(d,Ar,_),g(PA,Ar,null),e(Ar,yvr),e(Ar,jc),e(jc,wvr),e(jc,Ipe),e(Ipe,Avr),e(jc,Lvr),e(jc,jpe),e(jpe,Bvr),e(jc,kvr),e(Ar,xvr),e(Ar,$A),e($A,Rvr),e($A,Npe),e(Npe,Svr),e($A,Pvr),e(Ar,$vr),e(Ar,_t),g(IA,_t,null),e(_t,Ivr),e(_t,Dpe),e(Dpe,jvr),e(_t,Nvr),e(_t,Nc),e(Nc,Dvr),e(Nc,qpe),e(qpe,qvr),e(Nc,Ovr),e(Nc,Ope),e(Ope,Gvr),e(Nc,zvr),e(_t,Vvr),e(_t,Gpe),e(Gpe,Xvr),e(_t,Wvr),g(jA,_t,null),e(Ar,Qvr),e(Ar,Ro),g(NA,Ro,null),e(Ro,Hvr),e(Ro,zpe),e(zpe,Uvr),e(Ro,Jvr),e(Ro,pn),e(pn,Yvr),e(pn,Vpe),e(Vpe,Kvr),e(pn,Zvr),e(pn,Xpe),e(Xpe,e1r),e(pn,o1r),e(pn,Wpe),e(Wpe,r1r),e(pn,t1r),e(Ro,a1r),e(Ro,DA),e(DA,xC),e(xC,Qpe),e(Qpe,n1r),e(xC,s1r),e(xC,sO),e(sO,l1r),e(xC,i1r),e(DA,d1r),e(DA,RC),e(RC,Hpe),e(Hpe,c1r),e(RC,f1r),e(RC,lO),e(lO,m1r),e(RC,g1r),e(Ro,h1r),e(Ro,Upe),e(Upe,u1r),e(Ro,p1r),g(qA,Ro,null),v(d,WAe,_),v(d,Dc,_),e(Dc,SC),e(SC,Jpe),g(OA,Jpe,null),e(Dc,_1r),e(Dc,Ype),e(Ype,v1r),v(d,QAe,_),v(d,Lr,_),g(GA,Lr,null),e(Lr,b1r),e(Lr,qc),e(qc,T1r),e(qc,Kpe),e(Kpe,F1r),e(qc,C1r),e(qc,Zpe),e(Zpe,E1r),e(qc,M1r),e(Lr,y1r),e(Lr,zA),e(zA,w1r),e(zA,e_e),e(e_e,A1r),e(zA,L1r),e(Lr,B1r),e(Lr,vt),g(VA,vt,null),e(vt,k1r),e(vt,o_e),e(o_e,x1r),e(vt,R1r),e(vt,Oc),e(Oc,S1r),e(Oc,r_e),e(r_e,P1r),e(Oc,$1r),e(Oc,t_e),e(t_e,I1r),e(Oc,j1r),e(vt,N1r),e(vt,a_e),e(a_e,D1r),e(vt,q1r),g(XA,vt,null),e(Lr,O1r),e(Lr,So),g(WA,So,null),e(So,G1r),e(So,n_e),e(n_e,z1r),e(So,V1r),e(So,_n),e(_n,X1r),e(_n,s_e),e(s_e,W1r),e(_n,Q1r),e(_n,l_e),e(l_e,H1r),e(_n,U1r),e(_n,i_e),e(i_e,J1r),e(_n,Y1r),e(So,K1r),e(So,d_e),e(d_e,PC),e(PC,c_e),e(c_e,Z1r),e(PC,e4r),e(PC,iO),e(iO,o4r),e(PC,r4r),e(So,t4r),e(So,f_e),e(f_e,a4r),e(So,n4r),g(QA,So,null),HAe=!0},p(d,[_]){const HA={};_&2&&(HA.$$scope={dirty:_,ctx:d}),Hc.$set(HA);const m_e={};_&2&&(m_e.$$scope={dirty:_,ctx:d}),bg.$set(m_e);const g_e={};_&2&&(g_e.$$scope={dirty:_,ctx:d}),Bg.$set(g_e)},i(d){HAe||(h(de.$$.fragment,d),h(Ea.$$.fragment,d),h(PE.$$.fragment,d),h($E.$$.fragment,d),h(Hc.$$.fragment,d),h(IE.$$.fragment,d),h(jE.$$.fragment,d),h(qE.$$.fragment,d),h(OE.$$.fragment,d),h(GE.$$.fragment,d),h(zE.$$.fragment,d),h(VE.$$.fragment,d),h(QE.$$.fragment,d),h(HE.$$.fragment,d),h(UE.$$.fragment,d),h(JE.$$.fragment,d),h(YE.$$.fragment,d),h(eM.$$.fragment,d),h(bg.$$.fragment,d),h(oM.$$.fragment,d),h(rM.$$.fragment,d),h(tM.$$.fragment,d),h(sM.$$.fragment,d),h(Bg.$$.fragment,d),h(lM.$$.fragment,d),h(iM.$$.fragment,d),h(dM.$$.fragment,d),h(fM.$$.fragment,d),h(mM.$$.fragment,d),h(gM.$$.fragment,d),h(hM.$$.fragment,d),h(uM.$$.fragment,d),h(pM.$$.fragment,d),h(vM.$$.fragment,d),h(bM.$$.fragment,d),h(TM.$$.fragment,d),h(FM.$$.fragment,d),h(CM.$$.fragment,d),h(EM.$$.fragment,d),h(yM.$$.fragment,d),h(wM.$$.fragment,d),h(AM.$$.fragment,d),h(LM.$$.fragment,d),h(BM.$$.fragment,d),h(kM.$$.fragment,d),h(RM.$$.fragment,d),h(SM.$$.fragment,d),h(PM.$$.fragment,d),h($M.$$.fragment,d),h(IM.$$.fragment,d),h(jM.$$.fragment,d),h(DM.$$.fragment,d),h(qM.$$.fragment,d),h(OM.$$.fragment,d),h(GM.$$.fragment,d),h(zM.$$.fragment,d),h(VM.$$.fragment,d),h(WM.$$.fragment,d),h(QM.$$.fragment,d),h(HM.$$.fragment,d),h(UM.$$.fragment,d),h(JM.$$.fragment,d),h(YM.$$.fragment,d),h(ZM.$$.fragment,d),h(e3.$$.fragment,d),h(o3.$$.fragment,d),h(r3.$$.fragment,d),h(t3.$$.fragment,d),h(a3.$$.fragment,d),h(s3.$$.fragment,d),h(l3.$$.fragment,d),h(i3.$$.fragment,d),h(d3.$$.fragment,d),h(c3.$$.fragment,d),h(f3.$$.fragment,d),h(g3.$$.fragment,d),h(h3.$$.fragment,d),h(u3.$$.fragment,d),h(p3.$$.fragment,d),h(_3.$$.fragment,d),h(v3.$$.fragment,d),h(T3.$$.fragment,d),h(F3.$$.fragment,d),h(C3.$$.fragment,d),h(E3.$$.fragment,d),h(M3.$$.fragment,d),h(y3.$$.fragment,d),h(A3.$$.fragment,d),h(L3.$$.fragment,d),h(B3.$$.fragment,d),h(k3.$$.fragment,d),h(x3.$$.fragment,d),h(R3.$$.fragment,d),h(P3.$$.fragment,d),h($3.$$.fragment,d),h(I3.$$.fragment,d),h(j3.$$.fragment,d),h(N3.$$.fragment,d),h(D3.$$.fragment,d),h(O3.$$.fragment,d),h(G3.$$.fragment,d),h(z3.$$.fragment,d),h(V3.$$.fragment,d),h(X3.$$.fragment,d),h(W3.$$.fragment,d),h(H3.$$.fragment,d),h(U3.$$.fragment,d),h(J3.$$.fragment,d),h(Y3.$$.fragment,d),h(K3.$$.fragment,d),h(Z3.$$.fragment,d),h(o5.$$.fragment,d),h(r5.$$.fragment,d),h(t5.$$.fragment,d),h(a5.$$.fragment,d),h(n5.$$.fragment,d),h(s5.$$.fragment,d),h(i5.$$.fragment,d),h(d5.$$.fragment,d),h(c5.$$.fragment,d),h(f5.$$.fragment,d),h(m5.$$.fragment,d),h(g5.$$.fragment,d),h(u5.$$.fragment,d),h(p5.$$.fragment,d),h(_5.$$.fragment,d),h(b5.$$.fragment,d),h(T5.$$.fragment,d),h(F5.$$.fragment,d),h(E5.$$.fragment,d),h(M5.$$.fragment,d),h(y5.$$.fragment,d),h(w5.$$.fragment,d),h(A5.$$.fragment,d),h(L5.$$.fragment,d),h(k5.$$.fragment,d),h(x5.$$.fragment,d),h(R5.$$.fragment,d),h(S5.$$.fragment,d),h(P5.$$.fragment,d),h($5.$$.fragment,d),h(j5.$$.fragment,d),h(N5.$$.fragment,d),h(D5.$$.fragment,d),h(q5.$$.fragment,d),h(O5.$$.fragment,d),h(G5.$$.fragment,d),h(V5.$$.fragment,d),h(X5.$$.fragment,d),h(W5.$$.fragment,d),h(Q5.$$.fragment,d),h(H5.$$.fragment,d),h(U5.$$.fragment,d),h(Y5.$$.fragment,d),h(K5.$$.fragment,d),h(Z5.$$.fragment,d),h(ey.$$.fragment,d),h(oy.$$.fragment,d),h(ry.$$.fragment,d),h(ay.$$.fragment,d),h(ny.$$.fragment,d),h(sy.$$.fragment,d),h(ly.$$.fragment,d),h(iy.$$.fragment,d),h(dy.$$.fragment,d),h(fy.$$.fragment,d),h(my.$$.fragment,d),h(gy.$$.fragment,d),h(hy.$$.fragment,d),h(uy.$$.fragment,d),h(py.$$.fragment,d),h(vy.$$.fragment,d),h(by.$$.fragment,d),h(Ty.$$.fragment,d),h(Fy.$$.fragment,d),h(Cy.$$.fragment,d),h(Ey.$$.fragment,d),h(yy.$$.fragment,d),h(wy.$$.fragment,d),h(Ay.$$.fragment,d),h(Ly.$$.fragment,d),h(By.$$.fragment,d),h(ky.$$.fragment,d),h(Ry.$$.fragment,d),h(Sy.$$.fragment,d),h(Py.$$.fragment,d),h($y.$$.fragment,d),h(Iy.$$.fragment,d),h(jy.$$.fragment,d),h(Dy.$$.fragment,d),h(qy.$$.fragment,d),h(Oy.$$.fragment,d),h(Gy.$$.fragment,d),h(zy.$$.fragment,d),h(Vy.$$.fragment,d),h(Wy.$$.fragment,d),h(Qy.$$.fragment,d),h(Hy.$$.fragment,d),h(Uy.$$.fragment,d),h(Jy.$$.fragment,d),h(Yy.$$.fragment,d),h(Zy.$$.fragment,d),h(ew.$$.fragment,d),h(ow.$$.fragment,d),h(rw.$$.fragment,d),h(tw.$$.fragment,d),h(aw.$$.fragment,d),h(sw.$$.fragment,d),h(lw.$$.fragment,d),h(iw.$$.fragment,d),h(dw.$$.fragment,d),h(cw.$$.fragment,d),h(fw.$$.fragment,d),h(gw.$$.fragment,d),h(hw.$$.fragment,d),h(uw.$$.fragment,d),h(pw.$$.fragment,d),h(_w.$$.fragment,d),h(vw.$$.fragment,d),h(Tw.$$.fragment,d),h(Fw.$$.fragment,d),h(Cw.$$.fragment,d),h(Ew.$$.fragment,d),h(Mw.$$.fragment,d),h(yw.$$.fragment,d),h(Aw.$$.fragment,d),h(Lw.$$.fragment,d),h(Bw.$$.fragment,d),h(kw.$$.fragment,d),h(xw.$$.fragment,d),h(Rw.$$.fragment,d),h(Pw.$$.fragment,d),h($w.$$.fragment,d),h(Iw.$$.fragment,d),h(jw.$$.fragment,d),h(Nw.$$.fragment,d),h(Dw.$$.fragment,d),h(Ow.$$.fragment,d),h(Gw.$$.fragment,d),h(zw.$$.fragment,d),h(Vw.$$.fragment,d),h(Xw.$$.fragment,d),h(Ww.$$.fragment,d),h(Hw.$$.fragment,d),h(Uw.$$.fragment,d),h(Jw.$$.fragment,d),h(Yw.$$.fragment,d),h(Kw.$$.fragment,d),h(Zw.$$.fragment,d),h(oA.$$.fragment,d),h(rA.$$.fragment,d),h(tA.$$.fragment,d),h(aA.$$.fragment,d),h(nA.$$.fragment,d),h(sA.$$.fragment,d),h(iA.$$.fragment,d),h(dA.$$.fragment,d),h(cA.$$.fragment,d),h(fA.$$.fragment,d),h(mA.$$.fragment,d),h(gA.$$.fragment,d),h(uA.$$.fragment,d),h(pA.$$.fragment,d),h(_A.$$.fragment,d),h(vA.$$.fragment,d),h(bA.$$.fragment,d),h(TA.$$.fragment,d),h(CA.$$.fragment,d),h(EA.$$.fragment,d),h(MA.$$.fragment,d),h(yA.$$.fragment,d),h(wA.$$.fragment,d),h(AA.$$.fragment,d),h(BA.$$.fragment,d),h(kA.$$.fragment,d),h(xA.$$.fragment,d),h(RA.$$.fragment,d),h(SA.$$.fragment,d),h(PA.$$.fragment,d),h(IA.$$.fragment,d),h(jA.$$.fragment,d),h(NA.$$.fragment,d),h(qA.$$.fragment,d),h(OA.$$.fragment,d),h(GA.$$.fragment,d),h(VA.$$.fragment,d),h(XA.$$.fragment,d),h(WA.$$.fragment,d),h(QA.$$.fragment,d),HAe=!0)},o(d){u(de.$$.fragment,d),u(Ea.$$.fragment,d),u(PE.$$.fragment,d),u($E.$$.fragment,d),u(Hc.$$.fragment,d),u(IE.$$.fragment,d),u(jE.$$.fragment,d),u(qE.$$.fragment,d),u(OE.$$.fragment,d),u(GE.$$.fragment,d),u(zE.$$.fragment,d),u(VE.$$.fragment,d),u(QE.$$.fragment,d),u(HE.$$.fragment,d),u(UE.$$.fragment,d),u(JE.$$.fragment,d),u(YE.$$.fragment,d),u(eM.$$.fragment,d),u(bg.$$.fragment,d),u(oM.$$.fragment,d),u(rM.$$.fragment,d),u(tM.$$.fragment,d),u(sM.$$.fragment,d),u(Bg.$$.fragment,d),u(lM.$$.fragment,d),u(iM.$$.fragment,d),u(dM.$$.fragment,d),u(fM.$$.fragment,d),u(mM.$$.fragment,d),u(gM.$$.fragment,d),u(hM.$$.fragment,d),u(uM.$$.fragment,d),u(pM.$$.fragment,d),u(vM.$$.fragment,d),u(bM.$$.fragment,d),u(TM.$$.fragment,d),u(FM.$$.fragment,d),u(CM.$$.fragment,d),u(EM.$$.fragment,d),u(yM.$$.fragment,d),u(wM.$$.fragment,d),u(AM.$$.fragment,d),u(LM.$$.fragment,d),u(BM.$$.fragment,d),u(kM.$$.fragment,d),u(RM.$$.fragment,d),u(SM.$$.fragment,d),u(PM.$$.fragment,d),u($M.$$.fragment,d),u(IM.$$.fragment,d),u(jM.$$.fragment,d),u(DM.$$.fragment,d),u(qM.$$.fragment,d),u(OM.$$.fragment,d),u(GM.$$.fragment,d),u(zM.$$.fragment,d),u(VM.$$.fragment,d),u(WM.$$.fragment,d),u(QM.$$.fragment,d),u(HM.$$.fragment,d),u(UM.$$.fragment,d),u(JM.$$.fragment,d),u(YM.$$.fragment,d),u(ZM.$$.fragment,d),u(e3.$$.fragment,d),u(o3.$$.fragment,d),u(r3.$$.fragment,d),u(t3.$$.fragment,d),u(a3.$$.fragment,d),u(s3.$$.fragment,d),u(l3.$$.fragment,d),u(i3.$$.fragment,d),u(d3.$$.fragment,d),u(c3.$$.fragment,d),u(f3.$$.fragment,d),u(g3.$$.fragment,d),u(h3.$$.fragment,d),u(u3.$$.fragment,d),u(p3.$$.fragment,d),u(_3.$$.fragment,d),u(v3.$$.fragment,d),u(T3.$$.fragment,d),u(F3.$$.fragment,d),u(C3.$$.fragment,d),u(E3.$$.fragment,d),u(M3.$$.fragment,d),u(y3.$$.fragment,d),u(A3.$$.fragment,d),u(L3.$$.fragment,d),u(B3.$$.fragment,d),u(k3.$$.fragment,d),u(x3.$$.fragment,d),u(R3.$$.fragment,d),u(P3.$$.fragment,d),u($3.$$.fragment,d),u(I3.$$.fragment,d),u(j3.$$.fragment,d),u(N3.$$.fragment,d),u(D3.$$.fragment,d),u(O3.$$.fragment,d),u(G3.$$.fragment,d),u(z3.$$.fragment,d),u(V3.$$.fragment,d),u(X3.$$.fragment,d),u(W3.$$.fragment,d),u(H3.$$.fragment,d),u(U3.$$.fragment,d),u(J3.$$.fragment,d),u(Y3.$$.fragment,d),u(K3.$$.fragment,d),u(Z3.$$.fragment,d),u(o5.$$.fragment,d),u(r5.$$.fragment,d),u(t5.$$.fragment,d),u(a5.$$.fragment,d),u(n5.$$.fragment,d),u(s5.$$.fragment,d),u(i5.$$.fragment,d),u(d5.$$.fragment,d),u(c5.$$.fragment,d),u(f5.$$.fragment,d),u(m5.$$.fragment,d),u(g5.$$.fragment,d),u(u5.$$.fragment,d),u(p5.$$.fragment,d),u(_5.$$.fragment,d),u(b5.$$.fragment,d),u(T5.$$.fragment,d),u(F5.$$.fragment,d),u(E5.$$.fragment,d),u(M5.$$.fragment,d),u(y5.$$.fragment,d),u(w5.$$.fragment,d),u(A5.$$.fragment,d),u(L5.$$.fragment,d),u(k5.$$.fragment,d),u(x5.$$.fragment,d),u(R5.$$.fragment,d),u(S5.$$.fragment,d),u(P5.$$.fragment,d),u($5.$$.fragment,d),u(j5.$$.fragment,d),u(N5.$$.fragment,d),u(D5.$$.fragment,d),u(q5.$$.fragment,d),u(O5.$$.fragment,d),u(G5.$$.fragment,d),u(V5.$$.fragment,d),u(X5.$$.fragment,d),u(W5.$$.fragment,d),u(Q5.$$.fragment,d),u(H5.$$.fragment,d),u(U5.$$.fragment,d),u(Y5.$$.fragment,d),u(K5.$$.fragment,d),u(Z5.$$.fragment,d),u(ey.$$.fragment,d),u(oy.$$.fragment,d),u(ry.$$.fragment,d),u(ay.$$.fragment,d),u(ny.$$.fragment,d),u(sy.$$.fragment,d),u(ly.$$.fragment,d),u(iy.$$.fragment,d),u(dy.$$.fragment,d),u(fy.$$.fragment,d),u(my.$$.fragment,d),u(gy.$$.fragment,d),u(hy.$$.fragment,d),u(uy.$$.fragment,d),u(py.$$.fragment,d),u(vy.$$.fragment,d),u(by.$$.fragment,d),u(Ty.$$.fragment,d),u(Fy.$$.fragment,d),u(Cy.$$.fragment,d),u(Ey.$$.fragment,d),u(yy.$$.fragment,d),u(wy.$$.fragment,d),u(Ay.$$.fragment,d),u(Ly.$$.fragment,d),u(By.$$.fragment,d),u(ky.$$.fragment,d),u(Ry.$$.fragment,d),u(Sy.$$.fragment,d),u(Py.$$.fragment,d),u($y.$$.fragment,d),u(Iy.$$.fragment,d),u(jy.$$.fragment,d),u(Dy.$$.fragment,d),u(qy.$$.fragment,d),u(Oy.$$.fragment,d),u(Gy.$$.fragment,d),u(zy.$$.fragment,d),u(Vy.$$.fragment,d),u(Wy.$$.fragment,d),u(Qy.$$.fragment,d),u(Hy.$$.fragment,d),u(Uy.$$.fragment,d),u(Jy.$$.fragment,d),u(Yy.$$.fragment,d),u(Zy.$$.fragment,d),u(ew.$$.fragment,d),u(ow.$$.fragment,d),u(rw.$$.fragment,d),u(tw.$$.fragment,d),u(aw.$$.fragment,d),u(sw.$$.fragment,d),u(lw.$$.fragment,d),u(iw.$$.fragment,d),u(dw.$$.fragment,d),u(cw.$$.fragment,d),u(fw.$$.fragment,d),u(gw.$$.fragment,d),u(hw.$$.fragment,d),u(uw.$$.fragment,d),u(pw.$$.fragment,d),u(_w.$$.fragment,d),u(vw.$$.fragment,d),u(Tw.$$.fragment,d),u(Fw.$$.fragment,d),u(Cw.$$.fragment,d),u(Ew.$$.fragment,d),u(Mw.$$.fragment,d),u(yw.$$.fragment,d),u(Aw.$$.fragment,d),u(Lw.$$.fragment,d),u(Bw.$$.fragment,d),u(kw.$$.fragment,d),u(xw.$$.fragment,d),u(Rw.$$.fragment,d),u(Pw.$$.fragment,d),u($w.$$.fragment,d),u(Iw.$$.fragment,d),u(jw.$$.fragment,d),u(Nw.$$.fragment,d),u(Dw.$$.fragment,d),u(Ow.$$.fragment,d),u(Gw.$$.fragment,d),u(zw.$$.fragment,d),u(Vw.$$.fragment,d),u(Xw.$$.fragment,d),u(Ww.$$.fragment,d),u(Hw.$$.fragment,d),u(Uw.$$.fragment,d),u(Jw.$$.fragment,d),u(Yw.$$.fragment,d),u(Kw.$$.fragment,d),u(Zw.$$.fragment,d),u(oA.$$.fragment,d),u(rA.$$.fragment,d),u(tA.$$.fragment,d),u(aA.$$.fragment,d),u(nA.$$.fragment,d),u(sA.$$.fragment,d),u(iA.$$.fragment,d),u(dA.$$.fragment,d),u(cA.$$.fragment,d),u(fA.$$.fragment,d),u(mA.$$.fragment,d),u(gA.$$.fragment,d),u(uA.$$.fragment,d),u(pA.$$.fragment,d),u(_A.$$.fragment,d),u(vA.$$.fragment,d),u(bA.$$.fragment,d),u(TA.$$.fragment,d),u(CA.$$.fragment,d),u(EA.$$.fragment,d),u(MA.$$.fragment,d),u(yA.$$.fragment,d),u(wA.$$.fragment,d),u(AA.$$.fragment,d),u(BA.$$.fragment,d),u(kA.$$.fragment,d),u(xA.$$.fragment,d),u(RA.$$.fragment,d),u(SA.$$.fragment,d),u(PA.$$.fragment,d),u(IA.$$.fragment,d),u(jA.$$.fragment,d),u(NA.$$.fragment,d),u(qA.$$.fragment,d),u(OA.$$.fragment,d),u(GA.$$.fragment,d),u(VA.$$.fragment,d),u(XA.$$.fragment,d),u(WA.$$.fragment,d),u(QA.$$.fragment,d),HAe=!1},d(d){t(J),d&&t(we),d&&t(se),p(de),d&&t(zc),d&&t(Ut),d&&t(Me),d&&t(no),d&&t(Xc),p(Ea,d),d&&t(so),d&&t(ge),d&&t(Io),d&&t(Ma),d&&t(owe),d&&t(ii),p(PE),d&&t(rwe),d&&t(Cn),d&&t(twe),p($E,d),d&&t(awe),d&&t(H0),d&&t(nwe),p(Hc,d),d&&t(swe),d&&t(di),p(IE),d&&t(lwe),d&&t(jo),p(jE),p(qE),p(OE),p(GE),d&&t(iwe),d&&t(fi),p(zE),d&&t(dwe),d&&t(No),p(VE),p(QE),p(HE),p(UE),d&&t(cwe),d&&t(mi),p(JE),d&&t(fwe),d&&t(Wt),p(YE),p(eM),p(bg),p(oM),d&&t(mwe),d&&t(gi),p(rM),d&&t(gwe),d&&t(Qt),p(tM),p(sM),p(Bg),p(lM),d&&t(hwe),d&&t(ui),p(iM),d&&t(uwe),d&&t(Do),p(dM),p(fM),p(mM),p(gM),p(hM),d&&t(pwe),d&&t(vi),p(uM),d&&t(_we),d&&t(qo),p(pM),p(vM),p(bM),p(TM),p(FM),d&&t(vwe),d&&t(Fi),p(CM),d&&t(bwe),d&&t(Oo),p(EM),p(yM),p(wM),p(AM),p(LM),d&&t(Twe),d&&t(Mi),p(BM),d&&t(Fwe),d&&t(Go),p(kM),p(RM),p(SM),p(PM),p($M),d&&t(Cwe),d&&t(Ai),p(IM),d&&t(Ewe),d&&t(zo),p(jM),p(DM),p(qM),p(OM),p(GM),d&&t(Mwe),d&&t(ki),p(zM),d&&t(ywe),d&&t(Vo),p(VM),p(WM),p(QM),p(HM),p(UM),d&&t(wwe),d&&t(Si),p(JM),d&&t(Awe),d&&t(Xo),p(YM),p(ZM),p(e3),p(o3),p(r3),d&&t(Lwe),d&&t(Ii),p(t3),d&&t(Bwe),d&&t(Wo),p(a3),p(s3),p(l3),p(i3),p(d3),d&&t(kwe),d&&t(Di),p(c3),d&&t(xwe),d&&t(Qo),p(f3),p(g3),p(h3),p(u3),p(p3),d&&t(Rwe),d&&t(Gi),p(_3),d&&t(Swe),d&&t(Ho),p(v3),p(T3),p(F3),p(C3),p(E3),d&&t(Pwe),d&&t(Xi),p(M3),d&&t($we),d&&t(Uo),p(y3),p(A3),p(L3),p(B3),p(k3),d&&t(Iwe),d&&t(Hi),p(x3),d&&t(jwe),d&&t(Jo),p(R3),p(P3),p($3),p(I3),p(j3),d&&t(Nwe),d&&t(Yi),p(N3),d&&t(Dwe),d&&t(Yo),p(D3),p(O3),p(G3),p(z3),p(V3),d&&t(qwe),d&&t(ed),p(X3),d&&t(Owe),d&&t(Ko),p(W3),p(H3),p(U3),p(J3),p(Y3),d&&t(Gwe),d&&t(td),p(K3),d&&t(zwe),d&&t(Zo),p(Z3),p(o5),p(r5),p(t5),p(a5),d&&t(Vwe),d&&t(ld),p(n5),d&&t(Xwe),d&&t(er),p(s5),p(i5),p(d5),p(c5),p(f5),d&&t(Wwe),d&&t(cd),p(m5),d&&t(Qwe),d&&t(or),p(g5),p(u5),p(p5),p(_5),p(b5),d&&t(Hwe),d&&t(gd),p(T5),d&&t(Uwe),d&&t(rr),p(F5),p(E5),p(M5),p(y5),p(w5),d&&t(Jwe),d&&t(_d),p(A5),d&&t(Ywe),d&&t(tr),p(L5),p(k5),p(x5),p(R5),p(S5),d&&t(Kwe),d&&t(Td),p(P5),d&&t(Zwe),d&&t(ar),p($5),p(j5),p(N5),p(D5),p(q5),d&&t(eAe),d&&t(Ed),p(O5),d&&t(oAe),d&&t(nr),p(G5),p(V5),p(X5),p(W5),p(Q5),d&&t(rAe),d&&t(wd),p(H5),d&&t(tAe),d&&t(sr),p(U5),p(Y5),p(K5),p(Z5),p(ey),d&&t(aAe),d&&t(Bd),p(oy),d&&t(nAe),d&&t(lr),p(ry),p(ay),p(ny),p(sy),p(ly),d&&t(sAe),d&&t(Rd),p(iy),d&&t(lAe),d&&t(ir),p(dy),p(fy),p(my),p(gy),p(hy),d&&t(iAe),d&&t($d),p(uy),d&&t(dAe),d&&t(dr),p(py),p(vy),p(by),p(Ty),p(Fy),d&&t(cAe),d&&t(Nd),p(Cy),d&&t(fAe),d&&t(cr),p(Ey),p(yy),p(wy),p(Ay),p(Ly),d&&t(mAe),d&&t(Od),p(By),d&&t(gAe),d&&t(fr),p(ky),p(Ry),p(Sy),p(Py),p($y),d&&t(hAe),d&&t(Vd),p(Iy),d&&t(uAe),d&&t(mr),p(jy),p(Dy),p(qy),p(Oy),p(Gy),d&&t(pAe),d&&t(Qd),p(zy),d&&t(_Ae),d&&t(gr),p(Vy),p(Wy),p(Qy),p(Hy),p(Uy),d&&t(vAe),d&&t(Jd),p(Jy),d&&t(bAe),d&&t(hr),p(Yy),p(Zy),p(ew),p(ow),p(rw),d&&t(TAe),d&&t(Zd),p(tw),d&&t(FAe),d&&t(ur),p(aw),p(sw),p(lw),p(iw),p(dw),d&&t(CAe),d&&t(rc),p(cw),d&&t(EAe),d&&t(pr),p(fw),p(gw),p(hw),p(uw),p(pw),d&&t(MAe),d&&t(nc),p(_w),d&&t(yAe),d&&t(_r),p(vw),p(Tw),p(Fw),p(Cw),p(Ew),d&&t(wAe),d&&t(ic),p(Mw),d&&t(AAe),d&&t(vr),p(yw),p(Aw),p(Lw),p(Bw),p(kw),d&&t(LAe),d&&t(mc),p(xw),d&&t(BAe),d&&t(br),p(Rw),p(Pw),p($w),p(Iw),p(jw),d&&t(kAe),d&&t(uc),p(Nw),d&&t(xAe),d&&t(Tr),p(Dw),p(Ow),p(Gw),p(zw),p(Vw),d&&t(RAe),d&&t(vc),p(Xw),d&&t(SAe),d&&t(Fr),p(Ww),p(Hw),p(Uw),p(Jw),p(Yw),d&&t(PAe),d&&t(Fc),p(Kw),d&&t($Ae),d&&t(Cr),p(Zw),p(oA),p(rA),p(tA),p(aA),d&&t(IAe),d&&t(Mc),p(nA),d&&t(jAe),d&&t(Er),p(sA),p(iA),p(dA),p(cA),p(fA),d&&t(NAe),d&&t(Ac),p(mA),d&&t(DAe),d&&t(Mr),p(gA),p(uA),p(pA),p(_A),p(vA),d&&t(qAe),d&&t(kc),p(bA),d&&t(OAe),d&&t(yr),p(TA),p(CA),p(EA),p(MA),p(yA),d&&t(GAe),d&&t(Sc),p(wA),d&&t(zAe),d&&t(wr),p(AA),p(BA),p(kA),p(xA),p(RA),d&&t(VAe),d&&t(Ic),p(SA),d&&t(XAe),d&&t(Ar),p(PA),p(IA),p(jA),p(NA),p(qA),d&&t(WAe),d&&t(Dc),p(OA),d&&t(QAe),d&&t(Lr),p(GA),p(VA),p(XA),p(WA),p(QA)}}}const Jrt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function Yrt(ei,J,we){let{fw:se}=J;return ei.$$set=me=>{"fw"in me&&we(0,se=me.fw)},[se]}class att extends Grt{constructor(J){super();zrt(this,J,Yrt,Urt,Vrt,{fw:0})}}export{att as default,Jrt as metadata};
