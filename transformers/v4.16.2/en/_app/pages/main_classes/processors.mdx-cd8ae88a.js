import{S as Ai,i as Li,s as Di,e as a,k as i,w as h,t as l,M as ki,c as r,d as s,m as f,a as o,x as d,h as n,b as c,F as t,g as m,y as u,L as Ni,q as v,o as _,B as g}from"../../chunks/vendor-ab4e3193.js";import{D as P}from"../../chunks/Docstring-b69c0bd4.js";import{C as Ml}from"../../chunks/CodeBlock-516df0c5.js";import{I as ve}from"../../chunks/IconCopyLink-d992940d.js";import"../../chunks/CopyButton-204b56db.js";function Ti(Ka){let k,nt,q,I,At,_e,Ya,Lt,Za,Ts,it,er,Vs,V,F,Dt,ge,tr,kt,sr,Cs,y,ar,ft,rr,or,pt,lr,nr,ct,ir,fr,mt,pr,cr,Qs,$,Ee,mr,Nt,hr,dr,R,$e,ur,xe,vr,ht,_r,gr,Er,X,we,$r,Tt,xr,wr,z,be,br,Vt,Pr,yr,H,Pe,qr,ye,Sr,dt,Ir,Ar,Lr,B,qe,Dr,Se,kr,ut,Nr,Tr,Vr,J,Ie,Cr,Ct,Qr,Os,A,Ae,Or,Qt,Mr,jr,W,Le,Gr,Ot,Ur,Ms,L,De,Fr,Mt,Rr,Xr,K,ke,zr,jt,Hr,js,C,Y,Gt,Ne,Br,Ut,Jr,Gs,Z,Te,Wr,Kr,Ve,Yr,Us,vt,Zr,Fs,_t,eo,Rs,E,Ft,Rt,to,so,Xt,zt,ao,ro,Ht,Bt,oo,lo,Jt,Wt,no,io,Kt,Yt,fo,po,Zt,es,co,mo,ts,ss,ho,uo,as,rs,vo,_o,os,ls,go,Xs,ee,Eo,gt,$o,xo,zs,Et,wo,Hs,Q,te,ns,Ce,bo,is,Po,Bs,se,yo,Qe,qo,So,Js,O,ae,fs,Oe,Io,ps,Ao,Ws,M,Me,Lo,Do,je,cs,ko,No,Ks,Ge,To,Ue,Vo,Ys,$t,Co,Zs,xt,ms,hs,Qo,ea,wt,Oo,ta,re,Mo,Fe,jo,Go,sa,j,oe,ds,Re,Uo,us,Fo,aa,D,Xe,Ro,Xo,ze,zo,Ho,He,Bo,Jo,ra,bt,Wo,oa,G,le,vs,Be,Ko,_s,Yo,la,Pt,Zo,na,ne,gs,Es,el,tl,$s,xs,sl,ia,Je,al,ws,rl,fa,b,We,ol,bs,ll,nl,ie,Ke,il,Ps,fl,pl,S,Ye,cl,Ze,ml,ys,hl,dl,ul,qs,vl,_l,et,gl,fe,tt,El,Ss,$l,pa,pe,xl,Is,wl,bl,ca,yt,Pl,ma,ce,yl,As,ql,Sl,ha,U,me,Ls,st,Il,Ds,Al,da,qt,Ll,ua,at,va,he,Dl,ks,kl,Nl,_a,rt,ga,de,Tl,ot,Vl,Cl,Ea;return _e=new ve({}),ge=new ve({}),Ee=new P({props:{name:"class transformers.DataProcessor",anchor:"transformers.DataProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/data/processors/utils.py#L81"}}),$e=new P({props:{name:"get_dev_examples",anchor:"transformers.DataProcessor.get_dev_examples",parameters:[{name:"data_dir",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/data/processors/utils.py#L98"}}),we=new P({props:{name:"get_example_from_tensor_dict",anchor:"transformers.DataProcessor.get_example_from_tensor_dict",parameters:[{name:"tensor_dict",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/data/processors/utils.py#L84"}}),be=new P({props:{name:"get_labels",anchor:"transformers.DataProcessor.get_labels",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/data/processors/utils.py#L106"}}),Pe=new P({props:{name:"get_test_examples",anchor:"transformers.DataProcessor.get_test_examples",parameters:[{name:"data_dir",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/data/processors/utils.py#L102"}}),qe=new P({props:{name:"get_train_examples",anchor:"transformers.DataProcessor.get_train_examples",parameters:[{name:"data_dir",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/data/processors/utils.py#L94"}}),Ie=new P({props:{name:"tfds_map",anchor:"transformers.DataProcessor.tfds_map",parameters:[{name:"example",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/data/processors/utils.py#L110"}}),Ae=new P({props:{name:"class transformers.InputExample",anchor:"transformers.InputExample",parameters:[{name:"guid",val:": str"},{name:"text_a",val:": str"},{name:"text_b",val:": typing.Optional[str] = None"},{name:"label",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/data/processors/utils.py#L31"}}),Le=new P({props:{name:"to_json_string",anchor:"transformers.InputExample.to_json_string",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/data/processors/utils.py#L50"}}),De=new P({props:{name:"class transformers.InputFeatures",anchor:"transformers.InputFeatures",parameters:[{name:"input_ids",val:": typing.List[int]"},{name:"attention_mask",val:": typing.Optional[typing.List[int]] = None"},{name:"token_type_ids",val:": typing.Optional[typing.List[int]] = None"},{name:"label",val:": typing.Union[int, float, NoneType] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/data/processors/utils.py#L56"}}),ke=new P({props:{name:"to_json_string",anchor:"transformers.InputFeatures.to_json_string",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/data/processors/utils.py#L76"}}),Ne=new ve({}),Ce=new ve({}),Oe=new ve({}),Re=new ve({}),Be=new ve({}),We=new P({props:{name:"class transformers.data.processors.squad.SquadProcessor",anchor:"transformers.data.processors.squad.SquadProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/data/processors/squad.py#L543"}}),Ke=new P({props:{name:"get_dev_examples",anchor:"transformers.data.processors.squad.SquadProcessor.get_dev_examples",parameters:[{name:"data_dir",val:""},{name:"filename",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/data/processors/squad.py#L631"}}),Ye=new P({props:{name:"get_examples_from_dataset",anchor:"transformers.data.processors.squad.SquadProcessor.get_examples_from_dataset",parameters:[{name:"dataset",val:""},{name:"evaluate",val:" = False"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/data/processors/squad.py#L576",returnDescription:`
<p>List of SquadExample</p>
`}}),et=new Ml({props:{code:`import tensorflow_datasets as tfds

dataset = tfds.load("squad")

training_examples = get_examples_from_dataset(dataset, evaluate=False)
evaluation_examples = get_examples_from_dataset(dataset, evaluate=True),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow_datasets <span class="hljs-keyword">as</span> tfds

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = tfds.load(<span class="hljs-string">&quot;squad&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>training_examples = get_examples_from_dataset(dataset, evaluate=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>evaluation_examples = get_examples_from_dataset(dataset, evaluate=<span class="hljs-literal">True</span>)`}}),tt=new P({props:{name:"get_train_examples",anchor:"transformers.data.processors.squad.SquadProcessor.get_train_examples",parameters:[{name:"data_dir",val:""},{name:"filename",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/data/processors/squad.py#L609"}}),st=new ve({}),at=new Ml({props:{code:`# Loading a V2 processor
processor = SquadV2Processor()
examples = processor.get_dev_examples(squad_v2_data_dir)

# Loading a V1 processor
processor = SquadV1Processor()
examples = processor.get_dev_examples(squad_v1_data_dir)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=not evaluate,
),`,highlighted:`<span class="hljs-comment"># Loading a V2 processor</span>
processor = SquadV2Processor()
examples = processor.get_dev_examples(squad_v2_data_dir)

<span class="hljs-comment"># Loading a V1 processor</span>
processor = SquadV1Processor()
examples = processor.get_dev_examples(squad_v1_data_dir)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=<span class="hljs-keyword">not</span> evaluate,
)`}}),rt=new Ml({props:{code:`# tensorflow_datasets only handle Squad V1.
tfds_examples = tfds.load("squad")
examples = SquadV1Processor().get_examples_from_dataset(tfds_examples, evaluate=evaluate)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=not evaluate,
),`,highlighted:`<span class="hljs-comment"># tensorflow_datasets only handle Squad V1.</span>
tfds_examples = tfds.load(<span class="hljs-string">&quot;squad&quot;</span>)
examples = SquadV1Processor().get_examples_from_dataset(tfds_examples, evaluate=evaluate)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=<span class="hljs-keyword">not</span> evaluate,
)`}}),{c(){k=a("meta"),nt=i(),q=a("h1"),I=a("a"),At=a("span"),h(_e.$$.fragment),Ya=i(),Lt=a("span"),Za=l("Processors"),Ts=i(),it=a("p"),er=l(`This library includes processors for several traditional tasks. These processors can be used to process a dataset into
examples that can be fed to a model.`),Vs=i(),V=a("h2"),F=a("a"),Dt=a("span"),h(ge.$$.fragment),tr=i(),kt=a("span"),sr=l("Processors"),Cs=i(),y=a("p"),ar=l(`All processors follow the same architecture which is that of the
`),ft=a("a"),rr=l("DataProcessor"),or=l(`. The processor returns a list of
`),pt=a("a"),lr=l("InputExample"),nr=l(`. These
`),ct=a("a"),ir=l("InputExample"),fr=l(` can be converted to
`),mt=a("a"),pr=l("InputFeatures"),cr=l(" in order to be fed to the model."),Qs=i(),$=a("div"),h(Ee.$$.fragment),mr=i(),Nt=a("p"),hr=l("Base class for data converters for sequence classification data sets."),dr=i(),R=a("div"),h($e.$$.fragment),ur=i(),xe=a("p"),vr=l("Gets a collection of "),ht=a("a"),_r=l("InputExample"),gr=l(" for the dev set."),Er=i(),X=a("div"),h(we.$$.fragment),$r=i(),Tt=a("p"),xr=l("Gets an example from a dict with tensorflow tensors."),wr=i(),z=a("div"),h(be.$$.fragment),br=i(),Vt=a("p"),Pr=l("Gets the list of labels for this data set."),yr=i(),H=a("div"),h(Pe.$$.fragment),qr=i(),ye=a("p"),Sr=l("Gets a collection of "),dt=a("a"),Ir=l("InputExample"),Ar=l(" for the test set."),Lr=i(),B=a("div"),h(qe.$$.fragment),Dr=i(),Se=a("p"),kr=l("Gets a collection of "),ut=a("a"),Nr=l("InputExample"),Tr=l(" for the train set."),Vr=i(),J=a("div"),h(Ie.$$.fragment),Cr=i(),Ct=a("p"),Qr=l(`Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are. This method converts
examples to the correct format.`),Os=i(),A=a("div"),h(Ae.$$.fragment),Or=i(),Qt=a("p"),Mr=l("A single training/test example for simple sequence classification."),jr=i(),W=a("div"),h(Le.$$.fragment),Gr=i(),Ot=a("p"),Ur=l("Serializes this instance to a JSON string."),Ms=i(),L=a("div"),h(De.$$.fragment),Fr=i(),Mt=a("p"),Rr=l("A single set of features of data. Property names are the same names as the corresponding inputs to a model."),Xr=i(),K=a("div"),h(ke.$$.fragment),zr=i(),jt=a("p"),Hr=l("Serializes this instance to a JSON string."),js=i(),C=a("h2"),Y=a("a"),Gt=a("span"),h(Ne.$$.fragment),Br=i(),Ut=a("span"),Jr=l("GLUE"),Gs=i(),Z=a("p"),Te=a("a"),Wr=l("General Language Understanding Evaluation (GLUE)"),Kr=l(` is a benchmark that evaluates the
performance of models across a diverse set of existing NLU tasks. It was released together with the paper `),Ve=a("a"),Yr=l(`GLUE: A
multi-task benchmark and analysis platform for natural language understanding`),Us=i(),vt=a("p"),Zr=l(`This library hosts a total of 10 processors for the following tasks: MRPC, MNLI, MNLI (mismatched), CoLA, SST2, STSB,
QQP, QNLI, RTE and WNLI.`),Fs=i(),_t=a("p"),eo=l("Those processors are:"),Rs=i(),E=a("ul"),Ft=a("li"),Rt=a("code"),to=l("MrpcProcessor"),so=i(),Xt=a("li"),zt=a("code"),ao=l("MnliProcessor"),ro=i(),Ht=a("li"),Bt=a("code"),oo=l("MnliMismatchedProcessor"),lo=i(),Jt=a("li"),Wt=a("code"),no=l("Sst2Processor"),io=i(),Kt=a("li"),Yt=a("code"),fo=l("StsbProcessor"),po=i(),Zt=a("li"),es=a("code"),co=l("QqpProcessor"),mo=i(),ts=a("li"),ss=a("code"),ho=l("QnliProcessor"),uo=i(),as=a("li"),rs=a("code"),vo=l("RteProcessor"),_o=i(),os=a("li"),ls=a("code"),go=l("WnliProcessor"),Xs=i(),ee=a("p"),Eo=l(`Additionally, the following method can be used to load values from a data file and convert them to a list of
`),gt=a("a"),$o=l("InputExample"),xo=l("."),zs=i(),Et=a("p"),wo=l("automethod,transformers.data.processors.glue.glue_convert_examples_to_features"),Hs=i(),Q=a("h3"),te=a("a"),ns=a("span"),h(Ce.$$.fragment),bo=i(),is=a("span"),Po=l("Example usage"),Bs=i(),se=a("p"),yo=l("An example using these processors is given in the "),Qe=a("a"),qo=l("run_glue.py"),So=l(" script."),Js=i(),O=a("h2"),ae=a("a"),fs=a("span"),h(Oe.$$.fragment),Io=i(),ps=a("span"),Ao=l("XNLI"),Ws=i(),M=a("p"),Me=a("a"),Lo=l("The Cross-Lingual NLI Corpus (XNLI)"),Do=l(` is a benchmark that evaluates the
quality of cross-lingual text representations. XNLI is crowd-sourced dataset based on `),je=a("a"),cs=a("em"),ko=l("MultiNLI"),No=l(`: pairs of text are labeled with textual entailment annotations for 15
different languages (including both high-resource language such as English and low-resource languages such as Swahili).`),Ks=i(),Ge=a("p"),To=l("It was released together with the paper "),Ue=a("a"),Vo=l("XNLI: Evaluating Cross-lingual Sentence Representations"),Ys=i(),$t=a("p"),Co=l("This library hosts the processor to load the XNLI data:"),Zs=i(),xt=a("ul"),ms=a("li"),hs=a("code"),Qo=l("XnliProcessor"),ea=i(),wt=a("p"),Oo=l("Please note that since the gold labels are available on the test set, evaluation is performed on the test set."),ta=i(),re=a("p"),Mo=l("An example using these processors is given in the "),Fe=a("a"),jo=l("run_xnli.py"),Go=l(" script."),sa=i(),j=a("h2"),oe=a("a"),ds=a("span"),h(Re.$$.fragment),Uo=i(),us=a("span"),Fo=l("SQuAD"),aa=i(),D=a("p"),Xe=a("a"),Ro=l("The Stanford Question Answering Dataset (SQuAD)"),Xo=l(` is a benchmark that
evaluates the performance of models on question answering. Two versions are available, v1.1 and v2.0. The first version
(v1.1) was released together with the paper `),ze=a("a"),zo=l("SQuAD: 100,000+ Questions for Machine Comprehension of Text"),Ho=l(". The second version (v2.0) was released alongside the paper "),He=a("a"),Bo=l(`Know What You Don\u2019t
Know: Unanswerable Questions for SQuAD`),Jo=l("."),ra=i(),bt=a("p"),Wo=l("This library hosts a processor for each of the two versions:"),oa=i(),G=a("h3"),le=a("a"),vs=a("span"),h(Be.$$.fragment),Ko=i(),_s=a("span"),Yo=l("Processors"),la=i(),Pt=a("p"),Zo=l("Those processors are:"),na=i(),ne=a("ul"),gs=a("li"),Es=a("code"),el=l("SquadV1Processor"),tl=i(),$s=a("li"),xs=a("code"),sl=l("SquadV2Processor"),ia=i(),Je=a("p"),al=l("They both inherit from the abstract class "),ws=a("code"),rl=l("SquadProcessor"),fa=i(),b=a("div"),h(We.$$.fragment),ol=i(),bs=a("p"),ll=l(`Processor for the SQuAD data set. overridden by SquadV1Processor and SquadV2Processor, used by the version 1.1 and
version 2.0 of SQuAD, respectively.`),nl=i(),ie=a("div"),h(Ke.$$.fragment),il=i(),Ps=a("p"),fl=l("Returns the evaluation example from the data directory."),pl=i(),S=a("div"),h(Ye.$$.fragment),cl=i(),Ze=a("p"),ml=l("Creates a list of "),ys=a("code"),hl=l("SquadExample"),dl=l("using a TFDS dataset."),ul=i(),qs=a("p"),vl=l("Examples:"),_l=i(),h(et.$$.fragment),gl=i(),fe=a("div"),h(tt.$$.fragment),El=i(),Ss=a("p"),$l=l("Returns the training examples from the data directory."),pa=i(),pe=a("p"),xl=l(`Additionally, the following method can be used to convert SQuAD examples into
`),Is=a("code"),wl=l("SquadFeatures"),bl=l(" that can be used as model inputs."),ca=i(),yt=a("p"),Pl=l("automethod,transformers.data.processors.squad.squad_convert_examples_to_features"),ma=i(),ce=a("p"),yl=l(`These processors as well as the aforementionned method can be used with files containing the data as well as with the
`),As=a("em"),ql=l("tensorflow_datasets"),Sl=l(" package. Examples are given below."),ha=i(),U=a("h3"),me=a("a"),Ls=a("span"),h(st.$$.fragment),Il=i(),Ds=a("span"),Al=l("Example usage"),da=i(),qt=a("p"),Ll=l("Here is an example using the processors as well as the conversion method using data files:"),ua=i(),h(at.$$.fragment),va=i(),he=a("p"),Dl=l("Using "),ks=a("em"),kl=l("tensorflow_datasets"),Nl=l(" is as easy as using a data file:"),_a=i(),h(rt.$$.fragment),ga=i(),de=a("p"),Tl=l("Another example using these processors is given in the "),ot=a("a"),Vl=l("run_squad.py"),Cl=l(" script."),this.h()},l(e){const p=ki('[data-svelte="svelte-1phssyn"]',document.head);k=r(p,"META",{name:!0,content:!0}),p.forEach(s),nt=f(e),q=r(e,"H1",{class:!0});var $a=o(q);I=r($a,"A",{id:!0,class:!0,href:!0});var jl=o(I);At=r(jl,"SPAN",{});var Gl=o(At);d(_e.$$.fragment,Gl),Gl.forEach(s),jl.forEach(s),Ya=f($a),Lt=r($a,"SPAN",{});var Ul=o(Lt);Za=n(Ul,"Processors"),Ul.forEach(s),$a.forEach(s),Ts=f(e),it=r(e,"P",{});var Fl=o(it);er=n(Fl,`This library includes processors for several traditional tasks. These processors can be used to process a dataset into
examples that can be fed to a model.`),Fl.forEach(s),Vs=f(e),V=r(e,"H2",{class:!0});var xa=o(V);F=r(xa,"A",{id:!0,class:!0,href:!0});var Rl=o(F);Dt=r(Rl,"SPAN",{});var Xl=o(Dt);d(ge.$$.fragment,Xl),Xl.forEach(s),Rl.forEach(s),tr=f(xa),kt=r(xa,"SPAN",{});var zl=o(kt);sr=n(zl,"Processors"),zl.forEach(s),xa.forEach(s),Cs=f(e),y=r(e,"P",{});var N=o(y);ar=n(N,`All processors follow the same architecture which is that of the
`),ft=r(N,"A",{href:!0});var Hl=o(ft);rr=n(Hl,"DataProcessor"),Hl.forEach(s),or=n(N,`. The processor returns a list of
`),pt=r(N,"A",{href:!0});var Bl=o(pt);lr=n(Bl,"InputExample"),Bl.forEach(s),nr=n(N,`. These
`),ct=r(N,"A",{href:!0});var Jl=o(ct);ir=n(Jl,"InputExample"),Jl.forEach(s),fr=n(N,` can be converted to
`),mt=r(N,"A",{href:!0});var Wl=o(mt);pr=n(Wl,"InputFeatures"),Wl.forEach(s),cr=n(N," in order to be fed to the model."),N.forEach(s),Qs=f(e),$=r(e,"DIV",{class:!0});var w=o($);d(Ee.$$.fragment,w),mr=f(w),Nt=r(w,"P",{});var Kl=o(Nt);hr=n(Kl,"Base class for data converters for sequence classification data sets."),Kl.forEach(s),dr=f(w),R=r(w,"DIV",{class:!0});var wa=o(R);d($e.$$.fragment,wa),ur=f(wa),xe=r(wa,"P",{});var ba=o(xe);vr=n(ba,"Gets a collection of "),ht=r(ba,"A",{href:!0});var Yl=o(ht);_r=n(Yl,"InputExample"),Yl.forEach(s),gr=n(ba," for the dev set."),ba.forEach(s),wa.forEach(s),Er=f(w),X=r(w,"DIV",{class:!0});var Pa=o(X);d(we.$$.fragment,Pa),$r=f(Pa),Tt=r(Pa,"P",{});var Zl=o(Tt);xr=n(Zl,"Gets an example from a dict with tensorflow tensors."),Zl.forEach(s),Pa.forEach(s),wr=f(w),z=r(w,"DIV",{class:!0});var ya=o(z);d(be.$$.fragment,ya),br=f(ya),Vt=r(ya,"P",{});var en=o(Vt);Pr=n(en,"Gets the list of labels for this data set."),en.forEach(s),ya.forEach(s),yr=f(w),H=r(w,"DIV",{class:!0});var qa=o(H);d(Pe.$$.fragment,qa),qr=f(qa),ye=r(qa,"P",{});var Sa=o(ye);Sr=n(Sa,"Gets a collection of "),dt=r(Sa,"A",{href:!0});var tn=o(dt);Ir=n(tn,"InputExample"),tn.forEach(s),Ar=n(Sa," for the test set."),Sa.forEach(s),qa.forEach(s),Lr=f(w),B=r(w,"DIV",{class:!0});var Ia=o(B);d(qe.$$.fragment,Ia),Dr=f(Ia),Se=r(Ia,"P",{});var Aa=o(Se);kr=n(Aa,"Gets a collection of "),ut=r(Aa,"A",{href:!0});var sn=o(ut);Nr=n(sn,"InputExample"),sn.forEach(s),Tr=n(Aa," for the train set."),Aa.forEach(s),Ia.forEach(s),Vr=f(w),J=r(w,"DIV",{class:!0});var La=o(J);d(Ie.$$.fragment,La),Cr=f(La),Ct=r(La,"P",{});var an=o(Ct);Qr=n(an,`Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are. This method converts
examples to the correct format.`),an.forEach(s),La.forEach(s),w.forEach(s),Os=f(e),A=r(e,"DIV",{class:!0});var St=o(A);d(Ae.$$.fragment,St),Or=f(St),Qt=r(St,"P",{});var rn=o(Qt);Mr=n(rn,"A single training/test example for simple sequence classification."),rn.forEach(s),jr=f(St),W=r(St,"DIV",{class:!0});var Da=o(W);d(Le.$$.fragment,Da),Gr=f(Da),Ot=r(Da,"P",{});var on=o(Ot);Ur=n(on,"Serializes this instance to a JSON string."),on.forEach(s),Da.forEach(s),St.forEach(s),Ms=f(e),L=r(e,"DIV",{class:!0});var It=o(L);d(De.$$.fragment,It),Fr=f(It),Mt=r(It,"P",{});var ln=o(Mt);Rr=n(ln,"A single set of features of data. Property names are the same names as the corresponding inputs to a model."),ln.forEach(s),Xr=f(It),K=r(It,"DIV",{class:!0});var ka=o(K);d(ke.$$.fragment,ka),zr=f(ka),jt=r(ka,"P",{});var nn=o(jt);Hr=n(nn,"Serializes this instance to a JSON string."),nn.forEach(s),ka.forEach(s),It.forEach(s),js=f(e),C=r(e,"H2",{class:!0});var Na=o(C);Y=r(Na,"A",{id:!0,class:!0,href:!0});var fn=o(Y);Gt=r(fn,"SPAN",{});var pn=o(Gt);d(Ne.$$.fragment,pn),pn.forEach(s),fn.forEach(s),Br=f(Na),Ut=r(Na,"SPAN",{});var cn=o(Ut);Jr=n(cn,"GLUE"),cn.forEach(s),Na.forEach(s),Gs=f(e),Z=r(e,"P",{});var Ta=o(Z);Te=r(Ta,"A",{href:!0,rel:!0});var mn=o(Te);Wr=n(mn,"General Language Understanding Evaluation (GLUE)"),mn.forEach(s),Kr=n(Ta,` is a benchmark that evaluates the
performance of models across a diverse set of existing NLU tasks. It was released together with the paper `),Ve=r(Ta,"A",{href:!0,rel:!0});var hn=o(Ve);Yr=n(hn,`GLUE: A
multi-task benchmark and analysis platform for natural language understanding`),hn.forEach(s),Ta.forEach(s),Us=f(e),vt=r(e,"P",{});var dn=o(vt);Zr=n(dn,`This library hosts a total of 10 processors for the following tasks: MRPC, MNLI, MNLI (mismatched), CoLA, SST2, STSB,
QQP, QNLI, RTE and WNLI.`),dn.forEach(s),Fs=f(e),_t=r(e,"P",{});var un=o(_t);eo=n(un,"Those processors are:"),un.forEach(s),Rs=f(e),E=r(e,"UL",{});var x=o(E);Ft=r(x,"LI",{});var vn=o(Ft);Rt=r(vn,"CODE",{});var _n=o(Rt);to=n(_n,"MrpcProcessor"),_n.forEach(s),vn.forEach(s),so=f(x),Xt=r(x,"LI",{});var gn=o(Xt);zt=r(gn,"CODE",{});var En=o(zt);ao=n(En,"MnliProcessor"),En.forEach(s),gn.forEach(s),ro=f(x),Ht=r(x,"LI",{});var $n=o(Ht);Bt=r($n,"CODE",{});var xn=o(Bt);oo=n(xn,"MnliMismatchedProcessor"),xn.forEach(s),$n.forEach(s),lo=f(x),Jt=r(x,"LI",{});var wn=o(Jt);Wt=r(wn,"CODE",{});var bn=o(Wt);no=n(bn,"Sst2Processor"),bn.forEach(s),wn.forEach(s),io=f(x),Kt=r(x,"LI",{});var Pn=o(Kt);Yt=r(Pn,"CODE",{});var yn=o(Yt);fo=n(yn,"StsbProcessor"),yn.forEach(s),Pn.forEach(s),po=f(x),Zt=r(x,"LI",{});var qn=o(Zt);es=r(qn,"CODE",{});var Sn=o(es);co=n(Sn,"QqpProcessor"),Sn.forEach(s),qn.forEach(s),mo=f(x),ts=r(x,"LI",{});var In=o(ts);ss=r(In,"CODE",{});var An=o(ss);ho=n(An,"QnliProcessor"),An.forEach(s),In.forEach(s),uo=f(x),as=r(x,"LI",{});var Ln=o(as);rs=r(Ln,"CODE",{});var Dn=o(rs);vo=n(Dn,"RteProcessor"),Dn.forEach(s),Ln.forEach(s),_o=f(x),os=r(x,"LI",{});var kn=o(os);ls=r(kn,"CODE",{});var Nn=o(ls);go=n(Nn,"WnliProcessor"),Nn.forEach(s),kn.forEach(s),x.forEach(s),Xs=f(e),ee=r(e,"P",{});var Va=o(ee);Eo=n(Va,`Additionally, the following method can be used to load values from a data file and convert them to a list of
`),gt=r(Va,"A",{href:!0});var Tn=o(gt);$o=n(Tn,"InputExample"),Tn.forEach(s),xo=n(Va,"."),Va.forEach(s),zs=f(e),Et=r(e,"P",{});var Vn=o(Et);wo=n(Vn,"automethod,transformers.data.processors.glue.glue_convert_examples_to_features"),Vn.forEach(s),Hs=f(e),Q=r(e,"H3",{class:!0});var Ca=o(Q);te=r(Ca,"A",{id:!0,class:!0,href:!0});var Cn=o(te);ns=r(Cn,"SPAN",{});var Qn=o(ns);d(Ce.$$.fragment,Qn),Qn.forEach(s),Cn.forEach(s),bo=f(Ca),is=r(Ca,"SPAN",{});var On=o(is);Po=n(On,"Example usage"),On.forEach(s),Ca.forEach(s),Bs=f(e),se=r(e,"P",{});var Qa=o(se);yo=n(Qa,"An example using these processors is given in the "),Qe=r(Qa,"A",{href:!0,rel:!0});var Mn=o(Qe);qo=n(Mn,"run_glue.py"),Mn.forEach(s),So=n(Qa," script."),Qa.forEach(s),Js=f(e),O=r(e,"H2",{class:!0});var Oa=o(O);ae=r(Oa,"A",{id:!0,class:!0,href:!0});var jn=o(ae);fs=r(jn,"SPAN",{});var Gn=o(fs);d(Oe.$$.fragment,Gn),Gn.forEach(s),jn.forEach(s),Io=f(Oa),ps=r(Oa,"SPAN",{});var Un=o(ps);Ao=n(Un,"XNLI"),Un.forEach(s),Oa.forEach(s),Ws=f(e),M=r(e,"P",{});var Ns=o(M);Me=r(Ns,"A",{href:!0,rel:!0});var Fn=o(Me);Lo=n(Fn,"The Cross-Lingual NLI Corpus (XNLI)"),Fn.forEach(s),Do=n(Ns,` is a benchmark that evaluates the
quality of cross-lingual text representations. XNLI is crowd-sourced dataset based on `),je=r(Ns,"A",{href:!0,rel:!0});var Rn=o(je);cs=r(Rn,"EM",{});var Xn=o(cs);ko=n(Xn,"MultiNLI"),Xn.forEach(s),Rn.forEach(s),No=n(Ns,`: pairs of text are labeled with textual entailment annotations for 15
different languages (including both high-resource language such as English and low-resource languages such as Swahili).`),Ns.forEach(s),Ks=f(e),Ge=r(e,"P",{});var Ql=o(Ge);To=n(Ql,"It was released together with the paper "),Ue=r(Ql,"A",{href:!0,rel:!0});var zn=o(Ue);Vo=n(zn,"XNLI: Evaluating Cross-lingual Sentence Representations"),zn.forEach(s),Ql.forEach(s),Ys=f(e),$t=r(e,"P",{});var Hn=o($t);Co=n(Hn,"This library hosts the processor to load the XNLI data:"),Hn.forEach(s),Zs=f(e),xt=r(e,"UL",{});var Bn=o(xt);ms=r(Bn,"LI",{});var Jn=o(ms);hs=r(Jn,"CODE",{});var Wn=o(hs);Qo=n(Wn,"XnliProcessor"),Wn.forEach(s),Jn.forEach(s),Bn.forEach(s),ea=f(e),wt=r(e,"P",{});var Kn=o(wt);Oo=n(Kn,"Please note that since the gold labels are available on the test set, evaluation is performed on the test set."),Kn.forEach(s),ta=f(e),re=r(e,"P",{});var Ma=o(re);Mo=n(Ma,"An example using these processors is given in the "),Fe=r(Ma,"A",{href:!0,rel:!0});var Yn=o(Fe);jo=n(Yn,"run_xnli.py"),Yn.forEach(s),Go=n(Ma," script."),Ma.forEach(s),sa=f(e),j=r(e,"H2",{class:!0});var ja=o(j);oe=r(ja,"A",{id:!0,class:!0,href:!0});var Zn=o(oe);ds=r(Zn,"SPAN",{});var ei=o(ds);d(Re.$$.fragment,ei),ei.forEach(s),Zn.forEach(s),Uo=f(ja),us=r(ja,"SPAN",{});var ti=o(us);Fo=n(ti,"SQuAD"),ti.forEach(s),ja.forEach(s),aa=f(e),D=r(e,"P",{});var lt=o(D);Xe=r(lt,"A",{href:!0,rel:!0});var si=o(Xe);Ro=n(si,"The Stanford Question Answering Dataset (SQuAD)"),si.forEach(s),Xo=n(lt,` is a benchmark that
evaluates the performance of models on question answering. Two versions are available, v1.1 and v2.0. The first version
(v1.1) was released together with the paper `),ze=r(lt,"A",{href:!0,rel:!0});var ai=o(ze);zo=n(ai,"SQuAD: 100,000+ Questions for Machine Comprehension of Text"),ai.forEach(s),Ho=n(lt,". The second version (v2.0) was released alongside the paper "),He=r(lt,"A",{href:!0,rel:!0});var ri=o(He);Bo=n(ri,`Know What You Don\u2019t
Know: Unanswerable Questions for SQuAD`),ri.forEach(s),Jo=n(lt,"."),lt.forEach(s),ra=f(e),bt=r(e,"P",{});var oi=o(bt);Wo=n(oi,"This library hosts a processor for each of the two versions:"),oi.forEach(s),oa=f(e),G=r(e,"H3",{class:!0});var Ga=o(G);le=r(Ga,"A",{id:!0,class:!0,href:!0});var li=o(le);vs=r(li,"SPAN",{});var ni=o(vs);d(Be.$$.fragment,ni),ni.forEach(s),li.forEach(s),Ko=f(Ga),_s=r(Ga,"SPAN",{});var ii=o(_s);Yo=n(ii,"Processors"),ii.forEach(s),Ga.forEach(s),la=f(e),Pt=r(e,"P",{});var fi=o(Pt);Zo=n(fi,"Those processors are:"),fi.forEach(s),na=f(e),ne=r(e,"UL",{});var Ua=o(ne);gs=r(Ua,"LI",{});var pi=o(gs);Es=r(pi,"CODE",{});var ci=o(Es);el=n(ci,"SquadV1Processor"),ci.forEach(s),pi.forEach(s),tl=f(Ua),$s=r(Ua,"LI",{});var mi=o($s);xs=r(mi,"CODE",{});var hi=o(xs);sl=n(hi,"SquadV2Processor"),hi.forEach(s),mi.forEach(s),Ua.forEach(s),ia=f(e),Je=r(e,"P",{});var Ol=o(Je);al=n(Ol,"They both inherit from the abstract class "),ws=r(Ol,"CODE",{});var di=o(ws);rl=n(di,"SquadProcessor"),di.forEach(s),Ol.forEach(s),fa=f(e),b=r(e,"DIV",{class:!0});var T=o(b);d(We.$$.fragment,T),ol=f(T),bs=r(T,"P",{});var ui=o(bs);ll=n(ui,`Processor for the SQuAD data set. overridden by SquadV1Processor and SquadV2Processor, used by the version 1.1 and
version 2.0 of SQuAD, respectively.`),ui.forEach(s),nl=f(T),ie=r(T,"DIV",{class:!0});var Fa=o(ie);d(Ke.$$.fragment,Fa),il=f(Fa),Ps=r(Fa,"P",{});var vi=o(Ps);fl=n(vi,"Returns the evaluation example from the data directory."),vi.forEach(s),Fa.forEach(s),pl=f(T),S=r(T,"DIV",{class:!0});var ue=o(S);d(Ye.$$.fragment,ue),cl=f(ue),Ze=r(ue,"P",{});var Ra=o(Ze);ml=n(Ra,"Creates a list of "),ys=r(Ra,"CODE",{});var _i=o(ys);hl=n(_i,"SquadExample"),_i.forEach(s),dl=n(Ra,"using a TFDS dataset."),Ra.forEach(s),ul=f(ue),qs=r(ue,"P",{});var gi=o(qs);vl=n(gi,"Examples:"),gi.forEach(s),_l=f(ue),d(et.$$.fragment,ue),ue.forEach(s),gl=f(T),fe=r(T,"DIV",{class:!0});var Xa=o(fe);d(tt.$$.fragment,Xa),El=f(Xa),Ss=r(Xa,"P",{});var Ei=o(Ss);$l=n(Ei,"Returns the training examples from the data directory."),Ei.forEach(s),Xa.forEach(s),T.forEach(s),pa=f(e),pe=r(e,"P",{});var za=o(pe);xl=n(za,`Additionally, the following method can be used to convert SQuAD examples into
`),Is=r(za,"CODE",{});var $i=o(Is);wl=n($i,"SquadFeatures"),$i.forEach(s),bl=n(za," that can be used as model inputs."),za.forEach(s),ca=f(e),yt=r(e,"P",{});var xi=o(yt);Pl=n(xi,"automethod,transformers.data.processors.squad.squad_convert_examples_to_features"),xi.forEach(s),ma=f(e),ce=r(e,"P",{});var Ha=o(ce);yl=n(Ha,`These processors as well as the aforementionned method can be used with files containing the data as well as with the
`),As=r(Ha,"EM",{});var wi=o(As);ql=n(wi,"tensorflow_datasets"),wi.forEach(s),Sl=n(Ha," package. Examples are given below."),Ha.forEach(s),ha=f(e),U=r(e,"H3",{class:!0});var Ba=o(U);me=r(Ba,"A",{id:!0,class:!0,href:!0});var bi=o(me);Ls=r(bi,"SPAN",{});var Pi=o(Ls);d(st.$$.fragment,Pi),Pi.forEach(s),bi.forEach(s),Il=f(Ba),Ds=r(Ba,"SPAN",{});var yi=o(Ds);Al=n(yi,"Example usage"),yi.forEach(s),Ba.forEach(s),da=f(e),qt=r(e,"P",{});var qi=o(qt);Ll=n(qi,"Here is an example using the processors as well as the conversion method using data files:"),qi.forEach(s),ua=f(e),d(at.$$.fragment,e),va=f(e),he=r(e,"P",{});var Ja=o(he);Dl=n(Ja,"Using "),ks=r(Ja,"EM",{});var Si=o(ks);kl=n(Si,"tensorflow_datasets"),Si.forEach(s),Nl=n(Ja," is as easy as using a data file:"),Ja.forEach(s),_a=f(e),d(rt.$$.fragment,e),ga=f(e),de=r(e,"P",{});var Wa=o(de);Tl=n(Wa,"Another example using these processors is given in the "),ot=r(Wa,"A",{href:!0,rel:!0});var Ii=o(ot);Vl=n(Ii,"run_squad.py"),Ii.forEach(s),Cl=n(Wa," script."),Wa.forEach(s),this.h()},h(){c(k,"name","hf:doc:metadata"),c(k,"content",JSON.stringify(Vi)),c(I,"id","processors"),c(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I,"href","#processors"),c(q,"class","relative group"),c(F,"id","transformers.DataProcessor"),c(F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F,"href","#transformers.DataProcessor"),c(V,"class","relative group"),c(ft,"href","/docs/transformers/v4.16.2/en/main_classes/processors#transformers.DataProcessor"),c(pt,"href","/docs/transformers/v4.16.2/en/main_classes/processors#transformers.InputExample"),c(ct,"href","/docs/transformers/v4.16.2/en/main_classes/processors#transformers.InputExample"),c(mt,"href","/docs/transformers/v4.16.2/en/main_classes/processors#transformers.InputFeatures"),c(ht,"href","/docs/transformers/v4.16.2/en/main_classes/processors#transformers.InputExample"),c(R,"class","docstring"),c(X,"class","docstring"),c(z,"class","docstring"),c(dt,"href","/docs/transformers/v4.16.2/en/main_classes/processors#transformers.InputExample"),c(H,"class","docstring"),c(ut,"href","/docs/transformers/v4.16.2/en/main_classes/processors#transformers.InputExample"),c(B,"class","docstring"),c(J,"class","docstring"),c($,"class","docstring"),c(W,"class","docstring"),c(A,"class","docstring"),c(K,"class","docstring"),c(L,"class","docstring"),c(Y,"id","glue"),c(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y,"href","#glue"),c(C,"class","relative group"),c(Te,"href","https://gluebenchmark.com/"),c(Te,"rel","nofollow"),c(Ve,"href","https://openreview.net/pdf?id=rJ4km2R5t7"),c(Ve,"rel","nofollow"),c(gt,"href","/docs/transformers/v4.16.2/en/main_classes/processors#transformers.InputExample"),c(te,"id","example-usage"),c(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(te,"href","#example-usage"),c(Q,"class","relative group"),c(Qe,"href","https://github.com/huggingface/transformers/tree/master/examples/legacy/text-classification/run_glue.py"),c(Qe,"rel","nofollow"),c(ae,"id","xnli"),c(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ae,"href","#xnli"),c(O,"class","relative group"),c(Me,"href","https://www.nyu.edu/projects/bowman/xnli/"),c(Me,"rel","nofollow"),c(je,"href","http://www.nyu.edu/projects/bowman/multinli/"),c(je,"rel","nofollow"),c(Ue,"href","https://arxiv.org/abs/1809.05053"),c(Ue,"rel","nofollow"),c(Fe,"href","https://github.com/huggingface/transformers/tree/master/examples/legacy/text-classification/run_xnli.py"),c(Fe,"rel","nofollow"),c(oe,"id","squad"),c(oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oe,"href","#squad"),c(j,"class","relative group"),c(Xe,"href","https://rajpurkar.github.io/SQuAD-explorer//"),c(Xe,"rel","nofollow"),c(ze,"href","https://arxiv.org/abs/1606.05250"),c(ze,"rel","nofollow"),c(He,"href","https://arxiv.org/abs/1806.03822"),c(He,"rel","nofollow"),c(le,"id","transformers.data.processors.squad.SquadProcessor"),c(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(le,"href","#transformers.data.processors.squad.SquadProcessor"),c(G,"class","relative group"),c(ie,"class","docstring"),c(S,"class","docstring"),c(fe,"class","docstring"),c(b,"class","docstring"),c(me,"id","example-usage"),c(me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(me,"href","#example-usage"),c(U,"class","relative group"),c(ot,"href","https://github.com/huggingface/transformers/tree/master/examples/legacy/question-answering/run_squad.py"),c(ot,"rel","nofollow")},m(e,p){t(document.head,k),m(e,nt,p),m(e,q,p),t(q,I),t(I,At),u(_e,At,null),t(q,Ya),t(q,Lt),t(Lt,Za),m(e,Ts,p),m(e,it,p),t(it,er),m(e,Vs,p),m(e,V,p),t(V,F),t(F,Dt),u(ge,Dt,null),t(V,tr),t(V,kt),t(kt,sr),m(e,Cs,p),m(e,y,p),t(y,ar),t(y,ft),t(ft,rr),t(y,or),t(y,pt),t(pt,lr),t(y,nr),t(y,ct),t(ct,ir),t(y,fr),t(y,mt),t(mt,pr),t(y,cr),m(e,Qs,p),m(e,$,p),u(Ee,$,null),t($,mr),t($,Nt),t(Nt,hr),t($,dr),t($,R),u($e,R,null),t(R,ur),t(R,xe),t(xe,vr),t(xe,ht),t(ht,_r),t(xe,gr),t($,Er),t($,X),u(we,X,null),t(X,$r),t(X,Tt),t(Tt,xr),t($,wr),t($,z),u(be,z,null),t(z,br),t(z,Vt),t(Vt,Pr),t($,yr),t($,H),u(Pe,H,null),t(H,qr),t(H,ye),t(ye,Sr),t(ye,dt),t(dt,Ir),t(ye,Ar),t($,Lr),t($,B),u(qe,B,null),t(B,Dr),t(B,Se),t(Se,kr),t(Se,ut),t(ut,Nr),t(Se,Tr),t($,Vr),t($,J),u(Ie,J,null),t(J,Cr),t(J,Ct),t(Ct,Qr),m(e,Os,p),m(e,A,p),u(Ae,A,null),t(A,Or),t(A,Qt),t(Qt,Mr),t(A,jr),t(A,W),u(Le,W,null),t(W,Gr),t(W,Ot),t(Ot,Ur),m(e,Ms,p),m(e,L,p),u(De,L,null),t(L,Fr),t(L,Mt),t(Mt,Rr),t(L,Xr),t(L,K),u(ke,K,null),t(K,zr),t(K,jt),t(jt,Hr),m(e,js,p),m(e,C,p),t(C,Y),t(Y,Gt),u(Ne,Gt,null),t(C,Br),t(C,Ut),t(Ut,Jr),m(e,Gs,p),m(e,Z,p),t(Z,Te),t(Te,Wr),t(Z,Kr),t(Z,Ve),t(Ve,Yr),m(e,Us,p),m(e,vt,p),t(vt,Zr),m(e,Fs,p),m(e,_t,p),t(_t,eo),m(e,Rs,p),m(e,E,p),t(E,Ft),t(Ft,Rt),t(Rt,to),t(E,so),t(E,Xt),t(Xt,zt),t(zt,ao),t(E,ro),t(E,Ht),t(Ht,Bt),t(Bt,oo),t(E,lo),t(E,Jt),t(Jt,Wt),t(Wt,no),t(E,io),t(E,Kt),t(Kt,Yt),t(Yt,fo),t(E,po),t(E,Zt),t(Zt,es),t(es,co),t(E,mo),t(E,ts),t(ts,ss),t(ss,ho),t(E,uo),t(E,as),t(as,rs),t(rs,vo),t(E,_o),t(E,os),t(os,ls),t(ls,go),m(e,Xs,p),m(e,ee,p),t(ee,Eo),t(ee,gt),t(gt,$o),t(ee,xo),m(e,zs,p),m(e,Et,p),t(Et,wo),m(e,Hs,p),m(e,Q,p),t(Q,te),t(te,ns),u(Ce,ns,null),t(Q,bo),t(Q,is),t(is,Po),m(e,Bs,p),m(e,se,p),t(se,yo),t(se,Qe),t(Qe,qo),t(se,So),m(e,Js,p),m(e,O,p),t(O,ae),t(ae,fs),u(Oe,fs,null),t(O,Io),t(O,ps),t(ps,Ao),m(e,Ws,p),m(e,M,p),t(M,Me),t(Me,Lo),t(M,Do),t(M,je),t(je,cs),t(cs,ko),t(M,No),m(e,Ks,p),m(e,Ge,p),t(Ge,To),t(Ge,Ue),t(Ue,Vo),m(e,Ys,p),m(e,$t,p),t($t,Co),m(e,Zs,p),m(e,xt,p),t(xt,ms),t(ms,hs),t(hs,Qo),m(e,ea,p),m(e,wt,p),t(wt,Oo),m(e,ta,p),m(e,re,p),t(re,Mo),t(re,Fe),t(Fe,jo),t(re,Go),m(e,sa,p),m(e,j,p),t(j,oe),t(oe,ds),u(Re,ds,null),t(j,Uo),t(j,us),t(us,Fo),m(e,aa,p),m(e,D,p),t(D,Xe),t(Xe,Ro),t(D,Xo),t(D,ze),t(ze,zo),t(D,Ho),t(D,He),t(He,Bo),t(D,Jo),m(e,ra,p),m(e,bt,p),t(bt,Wo),m(e,oa,p),m(e,G,p),t(G,le),t(le,vs),u(Be,vs,null),t(G,Ko),t(G,_s),t(_s,Yo),m(e,la,p),m(e,Pt,p),t(Pt,Zo),m(e,na,p),m(e,ne,p),t(ne,gs),t(gs,Es),t(Es,el),t(ne,tl),t(ne,$s),t($s,xs),t(xs,sl),m(e,ia,p),m(e,Je,p),t(Je,al),t(Je,ws),t(ws,rl),m(e,fa,p),m(e,b,p),u(We,b,null),t(b,ol),t(b,bs),t(bs,ll),t(b,nl),t(b,ie),u(Ke,ie,null),t(ie,il),t(ie,Ps),t(Ps,fl),t(b,pl),t(b,S),u(Ye,S,null),t(S,cl),t(S,Ze),t(Ze,ml),t(Ze,ys),t(ys,hl),t(Ze,dl),t(S,ul),t(S,qs),t(qs,vl),t(S,_l),u(et,S,null),t(b,gl),t(b,fe),u(tt,fe,null),t(fe,El),t(fe,Ss),t(Ss,$l),m(e,pa,p),m(e,pe,p),t(pe,xl),t(pe,Is),t(Is,wl),t(pe,bl),m(e,ca,p),m(e,yt,p),t(yt,Pl),m(e,ma,p),m(e,ce,p),t(ce,yl),t(ce,As),t(As,ql),t(ce,Sl),m(e,ha,p),m(e,U,p),t(U,me),t(me,Ls),u(st,Ls,null),t(U,Il),t(U,Ds),t(Ds,Al),m(e,da,p),m(e,qt,p),t(qt,Ll),m(e,ua,p),u(at,e,p),m(e,va,p),m(e,he,p),t(he,Dl),t(he,ks),t(ks,kl),t(he,Nl),m(e,_a,p),u(rt,e,p),m(e,ga,p),m(e,de,p),t(de,Tl),t(de,ot),t(ot,Vl),t(de,Cl),Ea=!0},p:Ni,i(e){Ea||(v(_e.$$.fragment,e),v(ge.$$.fragment,e),v(Ee.$$.fragment,e),v($e.$$.fragment,e),v(we.$$.fragment,e),v(be.$$.fragment,e),v(Pe.$$.fragment,e),v(qe.$$.fragment,e),v(Ie.$$.fragment,e),v(Ae.$$.fragment,e),v(Le.$$.fragment,e),v(De.$$.fragment,e),v(ke.$$.fragment,e),v(Ne.$$.fragment,e),v(Ce.$$.fragment,e),v(Oe.$$.fragment,e),v(Re.$$.fragment,e),v(Be.$$.fragment,e),v(We.$$.fragment,e),v(Ke.$$.fragment,e),v(Ye.$$.fragment,e),v(et.$$.fragment,e),v(tt.$$.fragment,e),v(st.$$.fragment,e),v(at.$$.fragment,e),v(rt.$$.fragment,e),Ea=!0)},o(e){_(_e.$$.fragment,e),_(ge.$$.fragment,e),_(Ee.$$.fragment,e),_($e.$$.fragment,e),_(we.$$.fragment,e),_(be.$$.fragment,e),_(Pe.$$.fragment,e),_(qe.$$.fragment,e),_(Ie.$$.fragment,e),_(Ae.$$.fragment,e),_(Le.$$.fragment,e),_(De.$$.fragment,e),_(ke.$$.fragment,e),_(Ne.$$.fragment,e),_(Ce.$$.fragment,e),_(Oe.$$.fragment,e),_(Re.$$.fragment,e),_(Be.$$.fragment,e),_(We.$$.fragment,e),_(Ke.$$.fragment,e),_(Ye.$$.fragment,e),_(et.$$.fragment,e),_(tt.$$.fragment,e),_(st.$$.fragment,e),_(at.$$.fragment,e),_(rt.$$.fragment,e),Ea=!1},d(e){s(k),e&&s(nt),e&&s(q),g(_e),e&&s(Ts),e&&s(it),e&&s(Vs),e&&s(V),g(ge),e&&s(Cs),e&&s(y),e&&s(Qs),e&&s($),g(Ee),g($e),g(we),g(be),g(Pe),g(qe),g(Ie),e&&s(Os),e&&s(A),g(Ae),g(Le),e&&s(Ms),e&&s(L),g(De),g(ke),e&&s(js),e&&s(C),g(Ne),e&&s(Gs),e&&s(Z),e&&s(Us),e&&s(vt),e&&s(Fs),e&&s(_t),e&&s(Rs),e&&s(E),e&&s(Xs),e&&s(ee),e&&s(zs),e&&s(Et),e&&s(Hs),e&&s(Q),g(Ce),e&&s(Bs),e&&s(se),e&&s(Js),e&&s(O),g(Oe),e&&s(Ws),e&&s(M),e&&s(Ks),e&&s(Ge),e&&s(Ys),e&&s($t),e&&s(Zs),e&&s(xt),e&&s(ea),e&&s(wt),e&&s(ta),e&&s(re),e&&s(sa),e&&s(j),g(Re),e&&s(aa),e&&s(D),e&&s(ra),e&&s(bt),e&&s(oa),e&&s(G),g(Be),e&&s(la),e&&s(Pt),e&&s(na),e&&s(ne),e&&s(ia),e&&s(Je),e&&s(fa),e&&s(b),g(We),g(Ke),g(Ye),g(et),g(tt),e&&s(pa),e&&s(pe),e&&s(ca),e&&s(yt),e&&s(ma),e&&s(ce),e&&s(ha),e&&s(U),g(st),e&&s(da),e&&s(qt),e&&s(ua),g(at,e),e&&s(va),e&&s(he),e&&s(_a),g(rt,e),e&&s(ga),e&&s(de)}}}const Vi={local:"processors",sections:[{local:"transformers.DataProcessor",title:"Processors"},{local:"glue",sections:[{local:"example-usage",title:"Example usage"}],title:"GLUE"},{local:"xnli",title:"XNLI"},{local:"squad",sections:[{local:"transformers.data.processors.squad.SquadProcessor",title:"Processors"},{local:"example-usage",title:"Example usage"}],title:"SQuAD"}],title:"Processors"};function Ci(Ka,k,nt){let{fw:q}=k;return Ka.$$set=I=>{"fw"in I&&nt(0,q=I.fw)},[q]}class Ui extends Ai{constructor(k){super();Li(this,k,Ci,Ti,Di,{fw:0})}}export{Ui as default,Vi as metadata};
