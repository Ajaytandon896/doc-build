import{S as Ima,i as Nma,s as qma,e as a,k as l,w as F,t as o,M as jma,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as v,y as M,q as E,o as C,B as w,v as Dma,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as Dvt}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function Gma($){let g,b,u,m,p,d,h,yo,rd,Mm,pt,td,ad,b9,Em,Ve,He,nd,Zn,F9,es,os,T9,sd,rs,M9,ld,Cm,Qa;return{c(){g=a("p"),b=o("If your "),u=a("code"),m=o("NewModelConfig"),p=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),yo=o(`, make sure its
`),rd=a("code"),Mm=o("model_type"),pt=o(" attribute is set to the same key you use when registering the config (here "),td=a("code"),ad=o('"new-model"'),b9=o(")."),Em=l(),Ve=a("p"),He=o("Likewise, if your "),nd=a("code"),Zn=o("NewModel"),F9=o(" is a subclass of "),es=a("a"),os=o("PreTrainedModel"),T9=o(`, make sure its
`),sd=a("code"),rs=o("config_class"),M9=o(` attribute is set to the same class you use when registering the model (here
`),ld=a("code"),Cm=o("NewModelConfig"),Qa=o(")."),this.h()},l(Je){g=n(Je,"P",{});var Ae=s(g);b=r(Ae,"If your "),u=n(Ae,"CODE",{});var CB=s(u);m=r(CB,"NewModelConfig"),CB.forEach(t),p=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var id=s(d);h=r(id,"PretrainedConfig"),id.forEach(t),yo=r(Ae,`, make sure its
`),rd=n(Ae,"CODE",{});var wB=s(rd);Mm=r(wB,"model_type"),wB.forEach(t),pt=r(Ae," attribute is set to the same key you use when registering the config (here "),td=n(Ae,"CODE",{});var AB=s(td);ad=r(AB,'"new-model"'),AB.forEach(t),b9=r(Ae,")."),Ae.forEach(t),Em=i(Je),Ve=n(Je,"P",{});var xo=s(Ve);He=r(xo,"Likewise, if your "),nd=n(xo,"CODE",{});var Wa=s(nd);Zn=r(Wa,"NewModel"),Wa.forEach(t),F9=r(xo," is a subclass of "),es=n(xo,"A",{href:!0});var LB=s(es);os=r(LB,"PreTrainedModel"),LB.forEach(t),T9=r(xo,`, make sure its
`),sd=n(xo,"CODE",{});var wm=s(sd);rs=r(wm,"config_class"),wm.forEach(t),M9=r(xo,` attribute is set to the same class you use when registering the model (here
`),ld=n(xo,"CODE",{});var yB=s(ld);Cm=r(yB,"NewModelConfig"),yB.forEach(t),Qa=r(xo,")."),xo.forEach(t),this.h()},h(){c(es,"href","/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel")},m(Je,Ae){v(Je,g,Ae),e(g,b),e(g,u),e(u,m),e(g,p),e(g,d),e(d,h),e(g,yo),e(g,rd),e(rd,Mm),e(g,pt),e(g,td),e(td,ad),e(g,b9),v(Je,Em,Ae),v(Je,Ve,Ae),e(Ve,He),e(Ve,nd),e(nd,Zn),e(Ve,F9),e(Ve,es),e(es,os),e(Ve,T9),e(Ve,sd),e(sd,rs),e(Ve,M9),e(Ve,ld),e(ld,Cm),e(Ve,Qa)},d(Je){Je&&t(g),Je&&t(Em),Je&&t(Ve)}}}function Oma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Vma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Xma($){let g,b,u,m,p;return{c(){g=a("p"),b=o("Passing "),u=a("code"),m=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Passing "),u=n(h,"CODE",{});var yo=s(u);m=r(yo,"use_auth_token=True"),yo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){v(d,g,h),e(g,b),e(g,u),e(u,m),e(g,p)},d(d){d&&t(g)}}}function zma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Qma($){let g,b,u,m,p;return{c(){g=a("p"),b=o("Passing "),u=a("code"),m=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Passing "),u=n(h,"CODE",{});var yo=s(u);m=r(yo,"use_auth_token=True"),yo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){v(d,g,h),e(g,b),e(g,u),e(u,m),e(g,p)},d(d){d&&t(g)}}}function Wma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Uma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Hma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Jma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Yma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Kma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Zma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function ega($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function oga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function rga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function tga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function aga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function nga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function sga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function lga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function iga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function dga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function cga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function fga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function mga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function gga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function hga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function uga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function pga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="3dc6de3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;3dc6de3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function _ga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="3dc6de3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="3dc6de3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;3dc6de3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;3dc6de3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function vga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function bga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Fga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Tga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Mga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Ega($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Cga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function wga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Aga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Lga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function yga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function xga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function $ga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function kga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Sga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Rga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Pga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Bga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Iga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Nga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function qga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function jga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Dga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Gga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Oga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Vga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Xga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function zga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Qga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Wga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Uga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Hga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Jga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Yga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Kga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Zga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function eha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function oha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function rha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function tha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function aha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function nha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function sha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function lha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function iha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function dha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function cha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function fha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function mha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function gha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function hha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="3dc6de3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;3dc6de3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function uha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="3dc6de3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="3dc6de3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;3dc6de3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;3dc6de3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function pha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function _ha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function vha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function bha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Fha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Tha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Mha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Eha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Cha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function wha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Aha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Lha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function yha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function xha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function $ha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function kha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Sha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Rha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Pha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Bha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Iha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Nha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function qha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function jha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Dha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Gha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Oha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Vha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Xha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function zha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Qha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Wha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Uha($){let g,b,u,m,p,d,h,yo,rd,Mm,pt,td,ad,b9,Em,Ve,He,nd,Zn,F9,es,os,T9,sd,rs,M9,ld,Cm,Qa,Je,Ae,CB,id,wB,AB,xo,Wa,LB,wm,yB,iro,kYe,dd,Am,Hie,E9,dro,Jie,cro,SYe,ts,fro,Yie,mro,gro,Kie,hro,uro,RYe,C9,PYe,xB,pro,BYe,Lm,IYe,cd,ym,Zie,w9,_ro,ede,vro,NYe,$o,A9,bro,L9,Fro,$B,Tro,Mro,Ero,y9,Cro,ode,wro,Aro,Lro,Pr,x9,yro,rde,xro,$ro,fd,kro,tde,Sro,Rro,ade,Pro,Bro,Iro,A,xm,nde,Nro,qro,kB,jro,Dro,Gro,$m,sde,Oro,Vro,SB,Xro,zro,Qro,km,lde,Wro,Uro,RB,Hro,Jro,Yro,Sm,ide,Kro,Zro,PB,eto,oto,rto,Rm,dde,tto,ato,BB,nto,sto,lto,Pm,cde,ito,dto,IB,cto,fto,mto,Bm,fde,gto,hto,NB,uto,pto,_to,Im,mde,vto,bto,qB,Fto,Tto,Mto,Nm,gde,Eto,Cto,jB,wto,Ato,Lto,qm,hde,yto,xto,DB,$to,kto,Sto,jm,ude,Rto,Pto,GB,Bto,Ito,Nto,Dm,pde,qto,jto,OB,Dto,Gto,Oto,Gm,_de,Vto,Xto,VB,zto,Qto,Wto,Om,vde,Uto,Hto,XB,Jto,Yto,Kto,Vm,bde,Zto,eao,zB,oao,rao,tao,Xm,Fde,aao,nao,QB,sao,lao,iao,zm,Tde,dao,cao,WB,fao,mao,gao,Qm,Mde,hao,uao,UB,pao,_ao,vao,Wm,Ede,bao,Fao,HB,Tao,Mao,Eao,Um,Cde,Cao,wao,JB,Aao,Lao,yao,Hm,wde,xao,$ao,YB,kao,Sao,Rao,Jm,Ade,Pao,Bao,KB,Iao,Nao,qao,Ym,Lde,jao,Dao,ZB,Gao,Oao,Vao,Km,yde,Xao,zao,eI,Qao,Wao,Uao,Zm,xde,Hao,Jao,oI,Yao,Kao,Zao,eg,$de,eno,ono,rI,rno,tno,ano,og,kde,nno,sno,tI,lno,ino,dno,rg,Sde,cno,fno,aI,mno,gno,hno,tg,Rde,uno,pno,nI,_no,vno,bno,ag,Pde,Fno,Tno,sI,Mno,Eno,Cno,ng,Bde,wno,Ano,lI,Lno,yno,xno,sg,Ide,$no,kno,iI,Sno,Rno,Pno,lg,Nde,Bno,Ino,dI,Nno,qno,jno,ig,qde,Dno,Gno,cI,Ono,Vno,Xno,dg,jde,zno,Qno,fI,Wno,Uno,Hno,cg,Dde,Jno,Yno,mI,Kno,Zno,eso,fg,Gde,oso,rso,gI,tso,aso,nso,mg,Ode,sso,lso,hI,iso,dso,cso,gg,Vde,fso,mso,uI,gso,hso,uso,hg,Xde,pso,_so,pI,vso,bso,Fso,ug,zde,Tso,Mso,_I,Eso,Cso,wso,pg,Qde,Aso,Lso,vI,yso,xso,$so,_g,Wde,kso,Sso,bI,Rso,Pso,Bso,vg,Ude,Iso,Nso,FI,qso,jso,Dso,bg,Hde,Gso,Oso,TI,Vso,Xso,zso,Fg,Jde,Qso,Wso,MI,Uso,Hso,Jso,Tg,Yde,Yso,Kso,EI,Zso,elo,olo,Mg,Kde,rlo,tlo,CI,alo,nlo,slo,Eg,Zde,llo,ilo,wI,dlo,clo,flo,Cg,ece,mlo,glo,AI,hlo,ulo,plo,wg,oce,_lo,vlo,LI,blo,Flo,Tlo,Ag,rce,Mlo,Elo,yI,Clo,wlo,Alo,Lg,tce,Llo,ylo,xI,xlo,$lo,klo,yg,ace,Slo,Rlo,$I,Plo,Blo,Ilo,xg,nce,Nlo,qlo,kI,jlo,Dlo,Glo,$g,sce,Olo,Vlo,SI,Xlo,zlo,Qlo,kg,lce,Wlo,Ulo,RI,Hlo,Jlo,Ylo,Sg,ice,Klo,Zlo,PI,eio,oio,rio,Rg,dce,tio,aio,BI,nio,sio,lio,Pg,cce,iio,dio,II,cio,fio,mio,Bg,fce,gio,hio,NI,uio,pio,_io,Ig,mce,vio,bio,qI,Fio,Tio,Mio,Ng,gce,Eio,Cio,jI,wio,Aio,Lio,qg,hce,yio,xio,DI,$io,kio,Sio,jg,uce,Rio,Pio,GI,Bio,Iio,Nio,Dg,pce,qio,jio,OI,Dio,Gio,Oio,Gg,_ce,Vio,Xio,VI,zio,Qio,Wio,Og,vce,Uio,Hio,XI,Jio,Yio,Kio,Vg,bce,Zio,edo,zI,odo,rdo,tdo,Xg,Fce,ado,ndo,QI,sdo,ldo,ido,zg,Tce,ddo,cdo,WI,fdo,mdo,gdo,Qg,Mce,hdo,udo,UI,pdo,_do,vdo,Wg,Ece,bdo,Fdo,HI,Tdo,Mdo,Edo,Ug,Cce,Cdo,wdo,JI,Ado,Ldo,ydo,Hg,wce,xdo,$do,YI,kdo,Sdo,Rdo,Jg,Ace,Pdo,Bdo,KI,Ido,Ndo,qdo,Yg,Lce,jdo,Ddo,ZI,Gdo,Odo,Vdo,Kg,yce,Xdo,zdo,eN,Qdo,Wdo,Udo,Zg,xce,Hdo,Jdo,oN,Ydo,Kdo,Zdo,eh,$ce,eco,oco,rN,rco,tco,aco,oh,kce,nco,sco,tN,lco,ico,dco,rh,Sce,cco,fco,aN,mco,gco,hco,th,Rce,uco,pco,nN,_co,vco,bco,ah,Pce,Fco,Tco,sN,Mco,Eco,Cco,nh,Bce,wco,Aco,lN,Lco,yco,xco,sh,Ice,$co,kco,iN,Sco,Rco,Pco,lh,Nce,Bco,Ico,dN,Nco,qco,jco,ih,qce,Dco,Gco,cN,Oco,Vco,Xco,dh,jce,zco,Qco,fN,Wco,Uco,Hco,ch,Dce,Jco,Yco,mN,Kco,Zco,efo,fh,Gce,ofo,rfo,gN,tfo,afo,nfo,mh,Oce,sfo,lfo,hN,ifo,dfo,cfo,gh,Vce,ffo,mfo,uN,gfo,hfo,ufo,hh,Xce,pfo,_fo,pN,vfo,bfo,Ffo,uh,zce,Tfo,Mfo,_N,Efo,Cfo,wfo,ph,Qce,Afo,Lfo,vN,yfo,xfo,$fo,_h,Wce,kfo,Sfo,bN,Rfo,Pfo,Bfo,vh,Uce,Ifo,Nfo,FN,qfo,jfo,Dfo,bh,Hce,Gfo,Ofo,TN,Vfo,Xfo,zfo,Fh,Jce,Qfo,Wfo,MN,Ufo,Hfo,Jfo,Th,Yce,Yfo,Kfo,EN,Zfo,emo,omo,Mh,Kce,rmo,tmo,CN,amo,nmo,smo,Eh,Zce,lmo,imo,wN,dmo,cmo,fmo,Ch,efe,mmo,gmo,AN,hmo,umo,pmo,wh,ofe,_mo,vmo,LN,bmo,Fmo,Tmo,Ah,rfe,Mmo,Emo,yN,Cmo,wmo,Amo,Lh,tfe,Lmo,ymo,xN,xmo,$mo,kmo,yh,afe,Smo,Rmo,$N,Pmo,Bmo,Imo,xh,nfe,Nmo,qmo,kN,jmo,Dmo,Gmo,$h,sfe,Omo,Vmo,SN,Xmo,zmo,Qmo,kh,lfe,Wmo,Umo,RN,Hmo,Jmo,Ymo,Sh,ife,Kmo,Zmo,PN,ego,ogo,rgo,Rh,dfe,tgo,ago,BN,ngo,sgo,lgo,Ph,cfe,igo,dgo,IN,cgo,fgo,mgo,Bh,ffe,ggo,hgo,NN,ugo,pgo,_go,Ih,mfe,vgo,bgo,qN,Fgo,Tgo,Mgo,Nh,gfe,Ego,Cgo,jN,wgo,Ago,Lgo,qh,hfe,ygo,xgo,DN,$go,kgo,Sgo,jh,ufe,Rgo,Pgo,GN,Bgo,Igo,Ngo,Dh,pfe,qgo,jgo,ON,Dgo,Ggo,Ogo,Gh,_fe,Vgo,Xgo,VN,zgo,Qgo,Wgo,Oh,vfe,Ugo,Hgo,XN,Jgo,Ygo,Kgo,Vh,bfe,Zgo,eho,zN,oho,rho,tho,Xh,Ffe,aho,nho,QN,sho,lho,iho,zh,Tfe,dho,cho,WN,fho,mho,gho,Qh,hho,Wh,$9,uho,Mfe,pho,qYe,md,Uh,Efe,k9,_ho,Cfe,vho,jYe,ko,S9,bho,R9,Fho,UN,Tho,Mho,Eho,P9,Cho,wfe,who,Aho,Lho,Br,B9,yho,Afe,xho,$ho,Ua,kho,Lfe,Sho,Rho,yfe,Pho,Bho,xfe,Iho,Nho,qho,k,as,$fe,jho,Dho,HN,Gho,Oho,JN,Vho,Xho,zho,ns,kfe,Qho,Who,YN,Uho,Hho,KN,Jho,Yho,Kho,ss,Sfe,Zho,euo,ZN,ouo,ruo,eq,tuo,auo,nuo,Hh,Rfe,suo,luo,oq,iuo,duo,cuo,ls,Pfe,fuo,muo,rq,guo,huo,tq,uuo,puo,_uo,Jh,Bfe,vuo,buo,aq,Fuo,Tuo,Muo,Yh,Ife,Euo,Cuo,nq,wuo,Auo,Luo,Kh,Nfe,yuo,xuo,sq,$uo,kuo,Suo,is,qfe,Ruo,Puo,lq,Buo,Iuo,iq,Nuo,quo,juo,ds,jfe,Duo,Guo,dq,Ouo,Vuo,cq,Xuo,zuo,Quo,cs,Dfe,Wuo,Uuo,fq,Huo,Juo,mq,Yuo,Kuo,Zuo,Zh,Gfe,epo,opo,gq,rpo,tpo,apo,eu,Ofe,npo,spo,hq,lpo,ipo,dpo,ou,Vfe,cpo,fpo,uq,mpo,gpo,hpo,fs,Xfe,upo,ppo,pq,_po,vpo,_q,bpo,Fpo,Tpo,ru,zfe,Mpo,Epo,vq,Cpo,wpo,Apo,ms,Qfe,Lpo,ypo,bq,xpo,$po,Fq,kpo,Spo,Rpo,gs,Wfe,Ppo,Bpo,Tq,Ipo,Npo,Mq,qpo,jpo,Dpo,hs,Ufe,Gpo,Opo,Eq,Vpo,Xpo,Cq,zpo,Qpo,Wpo,us,Hfe,Upo,Hpo,wq,Jpo,Ypo,Aq,Kpo,Zpo,e_o,tu,Jfe,o_o,r_o,Lq,t_o,a_o,n_o,ps,Yfe,s_o,l_o,yq,i_o,d_o,xq,c_o,f_o,m_o,_s,Kfe,g_o,h_o,$q,u_o,p_o,kq,__o,v_o,b_o,vs,Zfe,F_o,T_o,Sq,M_o,E_o,Rq,C_o,w_o,A_o,bs,eme,L_o,y_o,Pq,x_o,$_o,Bq,k_o,S_o,R_o,Fs,ome,P_o,B_o,Iq,I_o,N_o,Nq,q_o,j_o,D_o,Ts,rme,G_o,O_o,qq,V_o,X_o,jq,z_o,Q_o,W_o,Ms,tme,U_o,H_o,Dq,J_o,Y_o,Gq,K_o,Z_o,e2o,au,ame,o2o,r2o,Oq,t2o,a2o,n2o,Es,nme,s2o,l2o,Vq,i2o,d2o,Xq,c2o,f2o,m2o,nu,sme,g2o,h2o,zq,u2o,p2o,_2o,Cs,lme,v2o,b2o,Qq,F2o,T2o,Wq,M2o,E2o,C2o,ws,ime,w2o,A2o,Uq,L2o,y2o,Hq,x2o,$2o,k2o,As,dme,S2o,R2o,Jq,P2o,B2o,Yq,I2o,N2o,q2o,su,cme,j2o,D2o,Kq,G2o,O2o,V2o,Ls,fme,X2o,z2o,Zq,Q2o,W2o,ej,U2o,H2o,J2o,ys,mme,Y2o,K2o,oj,Z2o,evo,rj,ovo,rvo,tvo,xs,gme,avo,nvo,tj,svo,lvo,aj,ivo,dvo,cvo,lu,hme,fvo,mvo,nj,gvo,hvo,uvo,$s,ume,pvo,_vo,sj,vvo,bvo,lj,Fvo,Tvo,Mvo,ks,pme,Evo,Cvo,ij,wvo,Avo,dj,Lvo,yvo,xvo,Ss,_me,$vo,kvo,cj,Svo,Rvo,fj,Pvo,Bvo,Ivo,Rs,vme,Nvo,qvo,mj,jvo,Dvo,gj,Gvo,Ovo,Vvo,Ps,bme,Xvo,zvo,hj,Qvo,Wvo,uj,Uvo,Hvo,Jvo,Bs,Fme,Yvo,Kvo,pj,Zvo,e4o,_j,o4o,r4o,t4o,Is,Tme,a4o,n4o,vj,s4o,l4o,bj,i4o,d4o,c4o,Ns,Mme,f4o,m4o,Fj,g4o,h4o,Tj,u4o,p4o,_4o,iu,Eme,v4o,b4o,Mj,F4o,T4o,M4o,qs,Cme,E4o,C4o,Ej,w4o,A4o,Cj,L4o,y4o,x4o,du,wme,$4o,k4o,wj,S4o,R4o,P4o,cu,Ame,B4o,I4o,Aj,N4o,q4o,j4o,js,Lme,D4o,G4o,Lj,O4o,V4o,yj,X4o,z4o,Q4o,Ds,yme,W4o,U4o,xj,H4o,J4o,$j,Y4o,K4o,Z4o,Gs,xme,ebo,obo,kj,rbo,tbo,Sj,abo,nbo,sbo,fu,$me,lbo,ibo,Rj,dbo,cbo,fbo,Os,kme,mbo,gbo,Pj,hbo,ubo,Bj,pbo,_bo,vbo,Vs,Sme,bbo,Fbo,Ij,Tbo,Mbo,Nj,Ebo,Cbo,wbo,Xs,Rme,Abo,Lbo,qj,ybo,xbo,jj,$bo,kbo,Sbo,zs,Pme,Rbo,Pbo,Dj,Bbo,Ibo,Gj,Nbo,qbo,jbo,Qs,Bme,Dbo,Gbo,Oj,Obo,Vbo,Vj,Xbo,zbo,Qbo,Ws,Ime,Wbo,Ubo,Xj,Hbo,Jbo,zj,Ybo,Kbo,Zbo,Us,Nme,e1o,o1o,Qj,r1o,t1o,Wj,a1o,n1o,s1o,Hs,qme,l1o,i1o,Uj,d1o,c1o,Hj,f1o,m1o,g1o,mu,jme,h1o,u1o,Jj,p1o,_1o,v1o,Js,Dme,b1o,F1o,Yj,T1o,M1o,Kj,E1o,C1o,w1o,Ys,Gme,A1o,L1o,Zj,y1o,x1o,eD,$1o,k1o,S1o,gu,Ome,R1o,P1o,oD,B1o,I1o,N1o,hu,Vme,q1o,j1o,rD,D1o,G1o,O1o,uu,Xme,V1o,X1o,tD,z1o,Q1o,W1o,pu,zme,U1o,H1o,aD,J1o,Y1o,K1o,Ks,Qme,Z1o,e0o,nD,o0o,r0o,sD,t0o,a0o,n0o,_u,Wme,s0o,l0o,lD,i0o,d0o,c0o,Zs,Ume,f0o,m0o,iD,g0o,h0o,dD,u0o,p0o,_0o,el,Hme,v0o,b0o,cD,F0o,T0o,fD,M0o,E0o,C0o,ol,Jme,w0o,A0o,mD,L0o,y0o,gD,x0o,$0o,k0o,rl,Yme,S0o,R0o,hD,P0o,B0o,uD,I0o,N0o,q0o,tl,Kme,j0o,D0o,pD,G0o,O0o,_D,V0o,X0o,z0o,al,Zme,Q0o,W0o,vD,U0o,H0o,bD,J0o,Y0o,K0o,vu,ege,Z0o,eFo,FD,oFo,rFo,tFo,bu,oge,aFo,nFo,TD,sFo,lFo,iFo,nl,rge,dFo,cFo,MD,fFo,mFo,ED,gFo,hFo,uFo,sl,tge,pFo,_Fo,CD,vFo,bFo,wD,FFo,TFo,MFo,ll,age,EFo,CFo,AD,wFo,AFo,LD,LFo,yFo,xFo,Fu,nge,$Fo,kFo,yD,SFo,RFo,PFo,Tu,sge,BFo,IFo,xD,NFo,qFo,jFo,Mu,lge,DFo,GFo,$D,OFo,VFo,XFo,il,ige,zFo,QFo,kD,WFo,UFo,SD,HFo,JFo,YFo,dl,dge,KFo,ZFo,RD,eTo,oTo,PD,rTo,tTo,aTo,Eu,cge,nTo,sTo,BD,lTo,iTo,dTo,Cu,fge,cTo,fTo,ID,mTo,gTo,hTo,wu,mge,uTo,pTo,ND,_To,vTo,bTo,cl,gge,FTo,TTo,qD,MTo,ETo,jD,CTo,wTo,ATo,fl,hge,LTo,yTo,DD,xTo,$To,GD,kTo,STo,RTo,Au,uge,PTo,BTo,OD,ITo,NTo,qTo,Lu,pge,jTo,DTo,VD,GTo,OTo,VTo,ml,_ge,XTo,zTo,XD,QTo,WTo,zD,UTo,HTo,JTo,gl,vge,YTo,KTo,QD,ZTo,eMo,WD,oMo,rMo,tMo,hl,bge,aMo,nMo,UD,sMo,lMo,HD,iMo,dMo,cMo,ul,Fge,fMo,mMo,JD,gMo,hMo,YD,uMo,pMo,_Mo,yu,vMo,xu,I9,bMo,Tge,FMo,DYe,gd,$u,Mge,N9,TMo,Ege,MMo,GYe,So,q9,EMo,j9,CMo,KD,wMo,AMo,LMo,D9,yMo,Cge,xMo,$Mo,kMo,Ye,G9,SMo,wge,RMo,PMo,Ha,BMo,Age,IMo,NMo,Lge,qMo,jMo,yge,DMo,GMo,OMo,W,ku,xge,VMo,XMo,ZD,zMo,QMo,WMo,Su,$ge,UMo,HMo,eG,JMo,YMo,KMo,Ru,kge,ZMo,eEo,oG,oEo,rEo,tEo,Pu,Sge,aEo,nEo,rG,sEo,lEo,iEo,Bu,Rge,dEo,cEo,tG,fEo,mEo,gEo,Iu,Pge,hEo,uEo,aG,pEo,_Eo,vEo,Nu,Bge,bEo,FEo,nG,TEo,MEo,EEo,qu,Ige,CEo,wEo,sG,AEo,LEo,yEo,ju,Nge,xEo,$Eo,lG,kEo,SEo,REo,Du,qge,PEo,BEo,iG,IEo,NEo,qEo,Gu,jge,jEo,DEo,dG,GEo,OEo,VEo,Ou,Dge,XEo,zEo,cG,QEo,WEo,UEo,Vu,Gge,HEo,JEo,fG,YEo,KEo,ZEo,Xu,Oge,eCo,oCo,mG,rCo,tCo,aCo,zu,Vge,nCo,sCo,gG,lCo,iCo,dCo,Qu,Xge,cCo,fCo,hG,mCo,gCo,hCo,Wu,zge,uCo,pCo,uG,_Co,vCo,bCo,Uu,Qge,FCo,TCo,pG,MCo,ECo,CCo,Hu,Wge,wCo,ACo,_G,LCo,yCo,xCo,Ju,Uge,$Co,kCo,vG,SCo,RCo,PCo,Yu,Hge,BCo,ICo,bG,NCo,qCo,jCo,Ku,Jge,DCo,GCo,FG,OCo,VCo,XCo,Zu,Yge,zCo,QCo,TG,WCo,UCo,HCo,ep,Kge,JCo,YCo,MG,KCo,ZCo,e3o,op,Zge,o3o,r3o,EG,t3o,a3o,n3o,rp,ehe,s3o,l3o,CG,i3o,d3o,c3o,tp,ohe,f3o,m3o,wG,g3o,h3o,u3o,ap,rhe,p3o,_3o,AG,v3o,b3o,F3o,np,the,T3o,M3o,LG,E3o,C3o,w3o,sp,ahe,A3o,L3o,yG,y3o,x3o,$3o,lp,nhe,k3o,S3o,xG,R3o,P3o,B3o,ip,she,I3o,N3o,$G,q3o,j3o,D3o,dp,lhe,G3o,O3o,kG,V3o,X3o,z3o,cp,ihe,Q3o,W3o,SG,U3o,H3o,J3o,fp,dhe,Y3o,K3o,RG,Z3o,e5o,o5o,mp,che,r5o,t5o,PG,a5o,n5o,s5o,gp,fhe,l5o,i5o,BG,d5o,c5o,f5o,hp,mhe,m5o,g5o,IG,h5o,u5o,p5o,up,ghe,_5o,v5o,NG,b5o,F5o,T5o,pp,M5o,_p,E5o,vp,O9,C5o,hhe,w5o,OYe,hd,bp,uhe,V9,A5o,phe,L5o,VYe,Ro,X9,y5o,z9,x5o,qG,$5o,k5o,S5o,Q9,R5o,_he,P5o,B5o,I5o,Ke,W9,N5o,vhe,q5o,j5o,ud,D5o,bhe,G5o,O5o,Fhe,V5o,X5o,z5o,ie,Fp,The,Q5o,W5o,jG,U5o,H5o,J5o,Tp,Mhe,Y5o,K5o,DG,Z5o,ewo,owo,Mp,Ehe,rwo,two,GG,awo,nwo,swo,Ep,Che,lwo,iwo,OG,dwo,cwo,fwo,Cp,whe,mwo,gwo,VG,hwo,uwo,pwo,wp,Ahe,_wo,vwo,XG,bwo,Fwo,Two,Ap,Lhe,Mwo,Ewo,zG,Cwo,wwo,Awo,Lp,yhe,Lwo,ywo,QG,xwo,$wo,kwo,yp,xhe,Swo,Rwo,WG,Pwo,Bwo,Iwo,xp,$he,Nwo,qwo,UG,jwo,Dwo,Gwo,$p,khe,Owo,Vwo,HG,Xwo,zwo,Qwo,kp,She,Wwo,Uwo,JG,Hwo,Jwo,Ywo,Sp,Rhe,Kwo,Zwo,YG,eAo,oAo,rAo,Rp,Phe,tAo,aAo,KG,nAo,sAo,lAo,Pp,Bhe,iAo,dAo,ZG,cAo,fAo,mAo,Bp,Ihe,gAo,hAo,eO,uAo,pAo,_Ao,Ip,Nhe,vAo,bAo,oO,FAo,TAo,MAo,Np,qhe,EAo,CAo,rO,wAo,AAo,LAo,qp,jhe,yAo,xAo,tO,$Ao,kAo,SAo,jp,Dhe,RAo,PAo,aO,BAo,IAo,NAo,Dp,Ghe,qAo,jAo,nO,DAo,GAo,OAo,Gp,VAo,Op,XAo,Vp,U9,zAo,Ohe,QAo,XYe,pd,Xp,Vhe,H9,WAo,Xhe,UAo,zYe,Po,J9,HAo,_d,JAo,sO,YAo,KAo,lO,ZAo,e6o,o6o,Y9,r6o,zhe,t6o,a6o,n6o,_t,K9,s6o,Qhe,l6o,i6o,vd,d6o,Whe,c6o,f6o,iO,m6o,g6o,h6o,zp,u6o,Ze,Z9,p6o,Uhe,_6o,v6o,Ja,b6o,Hhe,F6o,T6o,Jhe,M6o,E6o,Yhe,C6o,w6o,A6o,y,Qp,Khe,L6o,y6o,dO,x6o,$6o,k6o,Wp,Zhe,S6o,R6o,cO,P6o,B6o,I6o,Up,eue,N6o,q6o,fO,j6o,D6o,G6o,Hp,oue,O6o,V6o,mO,X6o,z6o,Q6o,Jp,rue,W6o,U6o,gO,H6o,J6o,Y6o,Yp,tue,K6o,Z6o,hO,e7o,o7o,r7o,Kp,aue,t7o,a7o,uO,n7o,s7o,l7o,Zp,nue,i7o,d7o,pO,c7o,f7o,m7o,e_,sue,g7o,h7o,_O,u7o,p7o,_7o,o_,lue,v7o,b7o,vO,F7o,T7o,M7o,r_,iue,E7o,C7o,bO,w7o,A7o,L7o,t_,due,y7o,x7o,FO,$7o,k7o,S7o,a_,cue,R7o,P7o,TO,B7o,I7o,N7o,n_,fue,q7o,j7o,MO,D7o,G7o,O7o,s_,mue,V7o,X7o,EO,z7o,Q7o,W7o,l_,gue,U7o,H7o,CO,J7o,Y7o,K7o,i_,hue,Z7o,eLo,wO,oLo,rLo,tLo,d_,uue,aLo,nLo,AO,sLo,lLo,iLo,c_,pue,dLo,cLo,LO,fLo,mLo,gLo,f_,_ue,hLo,uLo,yO,pLo,_Lo,vLo,m_,vue,bLo,FLo,xO,TLo,MLo,ELo,g_,bue,CLo,wLo,$O,ALo,LLo,yLo,h_,Fue,xLo,$Lo,kO,kLo,SLo,RLo,u_,Tue,PLo,BLo,SO,ILo,NLo,qLo,p_,Mue,jLo,DLo,RO,GLo,OLo,VLo,__,Eue,XLo,zLo,PO,QLo,WLo,ULo,v_,Cue,HLo,JLo,BO,YLo,KLo,ZLo,b_,wue,eyo,oyo,IO,ryo,tyo,ayo,F_,Aue,nyo,syo,NO,lyo,iyo,dyo,T_,Lue,cyo,fyo,qO,myo,gyo,hyo,M_,yue,uyo,pyo,jO,_yo,vyo,byo,E_,xue,Fyo,Tyo,DO,Myo,Eyo,Cyo,C_,$ue,wyo,Ayo,GO,Lyo,yyo,xyo,w_,kue,$yo,kyo,OO,Syo,Ryo,Pyo,A_,Sue,Byo,Iyo,VO,Nyo,qyo,jyo,L_,Rue,Dyo,Gyo,XO,Oyo,Vyo,Xyo,pl,Pue,zyo,Qyo,zO,Wyo,Uyo,QO,Hyo,Jyo,Yyo,y_,Bue,Kyo,Zyo,WO,e8o,o8o,r8o,x_,Iue,t8o,a8o,UO,n8o,s8o,l8o,$_,Nue,i8o,d8o,HO,c8o,f8o,m8o,k_,que,g8o,h8o,JO,u8o,p8o,_8o,S_,jue,v8o,b8o,YO,F8o,T8o,M8o,R_,Due,E8o,C8o,KO,w8o,A8o,L8o,P_,Gue,y8o,x8o,ZO,$8o,k8o,S8o,B_,Oue,R8o,P8o,eV,B8o,I8o,N8o,I_,Vue,q8o,j8o,oV,D8o,G8o,O8o,N_,Xue,V8o,X8o,rV,z8o,Q8o,W8o,q_,zue,U8o,H8o,tV,J8o,Y8o,K8o,j_,Que,Z8o,e9o,aV,o9o,r9o,t9o,D_,Wue,a9o,n9o,nV,s9o,l9o,i9o,G_,Uue,d9o,c9o,sV,f9o,m9o,g9o,O_,Hue,h9o,u9o,lV,p9o,_9o,v9o,V_,Jue,b9o,F9o,iV,T9o,M9o,E9o,X_,Yue,C9o,w9o,dV,A9o,L9o,y9o,z_,Kue,x9o,$9o,cV,k9o,S9o,R9o,Q_,Zue,P9o,B9o,fV,I9o,N9o,q9o,W_,epe,j9o,D9o,mV,G9o,O9o,V9o,U_,ope,X9o,z9o,gV,Q9o,W9o,U9o,H_,rpe,H9o,J9o,hV,Y9o,K9o,Z9o,J_,tpe,exo,oxo,uV,rxo,txo,axo,Y_,ape,nxo,sxo,pV,lxo,ixo,dxo,K_,npe,cxo,fxo,_V,mxo,gxo,hxo,Z_,spe,uxo,pxo,vV,_xo,vxo,bxo,e2,lpe,Fxo,Txo,bV,Mxo,Exo,Cxo,o2,ipe,wxo,Axo,FV,Lxo,yxo,xxo,r2,dpe,$xo,kxo,TV,Sxo,Rxo,Pxo,t2,cpe,Bxo,Ixo,MV,Nxo,qxo,jxo,a2,fpe,Dxo,Gxo,EV,Oxo,Vxo,Xxo,n2,mpe,zxo,Qxo,CV,Wxo,Uxo,Hxo,s2,gpe,Jxo,Yxo,wV,Kxo,Zxo,e$o,l2,hpe,o$o,r$o,AV,t$o,a$o,n$o,i2,upe,s$o,l$o,LV,i$o,d$o,c$o,d2,ppe,f$o,m$o,yV,g$o,h$o,u$o,c2,_pe,p$o,_$o,xV,v$o,b$o,F$o,f2,vpe,T$o,M$o,$V,E$o,C$o,w$o,m2,bpe,A$o,L$o,kV,y$o,x$o,$$o,g2,Fpe,k$o,S$o,SV,R$o,P$o,B$o,h2,Tpe,I$o,N$o,RV,q$o,j$o,D$o,u2,Mpe,G$o,O$o,PV,V$o,X$o,z$o,p2,Epe,Q$o,W$o,BV,U$o,H$o,J$o,_2,Cpe,Y$o,K$o,IV,Z$o,eko,oko,v2,wpe,rko,tko,NV,ako,nko,sko,b2,Ape,lko,iko,qV,dko,cko,fko,F2,Lpe,mko,gko,jV,hko,uko,pko,T2,ype,_ko,vko,DV,bko,Fko,Tko,M2,xpe,Mko,Eko,GV,Cko,wko,Ako,E2,$pe,Lko,yko,OV,xko,$ko,kko,C2,kpe,Sko,Rko,VV,Pko,Bko,Iko,w2,Spe,Nko,qko,XV,jko,Dko,Gko,A2,Rpe,Oko,Vko,zV,Xko,zko,Qko,L2,Ppe,Wko,Uko,QV,Hko,Jko,Yko,y2,Bpe,Kko,Zko,WV,eSo,oSo,rSo,x2,Ipe,tSo,aSo,UV,nSo,sSo,lSo,$2,Npe,iSo,dSo,HV,cSo,fSo,mSo,k2,qpe,gSo,hSo,JV,uSo,pSo,_So,S2,jpe,vSo,bSo,YV,FSo,TSo,MSo,R2,Dpe,ESo,CSo,KV,wSo,ASo,LSo,P2,Gpe,ySo,xSo,ZV,$So,kSo,SSo,B2,Ope,RSo,PSo,eX,BSo,ISo,NSo,I2,Vpe,qSo,jSo,oX,DSo,GSo,OSo,N2,Xpe,VSo,XSo,rX,zSo,QSo,WSo,q2,zpe,USo,HSo,tX,JSo,YSo,KSo,j2,Qpe,ZSo,eRo,aX,oRo,rRo,tRo,D2,Wpe,aRo,nRo,nX,sRo,lRo,iRo,G2,Upe,dRo,cRo,sX,fRo,mRo,gRo,O2,Hpe,hRo,uRo,lX,pRo,_Ro,vRo,V2,Jpe,bRo,FRo,iX,TRo,MRo,ERo,X2,Ype,CRo,wRo,dX,ARo,LRo,yRo,z2,Kpe,xRo,$Ro,cX,kRo,SRo,RRo,Q2,Zpe,PRo,BRo,fX,IRo,NRo,qRo,W2,e_e,jRo,DRo,mX,GRo,ORo,VRo,U2,o_e,XRo,zRo,gX,QRo,WRo,URo,H2,r_e,HRo,JRo,hX,YRo,KRo,ZRo,J2,t_e,ePo,oPo,uX,rPo,tPo,aPo,Y2,a_e,nPo,sPo,pX,lPo,iPo,dPo,K2,n_e,cPo,fPo,_X,mPo,gPo,hPo,Z2,s_e,uPo,pPo,vX,_Po,vPo,bPo,ev,l_e,FPo,TPo,bX,MPo,EPo,CPo,ov,i_e,wPo,APo,FX,LPo,yPo,xPo,rv,$Po,d_e,kPo,SPo,c_e,RPo,PPo,tv,QYe,bd,av,f_e,ex,BPo,m_e,IPo,WYe,Bo,ox,NPo,Fd,qPo,TX,jPo,DPo,MX,GPo,OPo,VPo,rx,XPo,g_e,zPo,QPo,WPo,vt,tx,UPo,h_e,HPo,JPo,Td,YPo,u_e,KPo,ZPo,EX,eBo,oBo,rBo,nv,tBo,eo,ax,aBo,p_e,nBo,sBo,Ya,lBo,__e,iBo,dBo,v_e,cBo,fBo,b_e,mBo,gBo,hBo,G,sv,F_e,uBo,pBo,CX,_Bo,vBo,bBo,lv,T_e,FBo,TBo,wX,MBo,EBo,CBo,iv,M_e,wBo,ABo,AX,LBo,yBo,xBo,dv,E_e,$Bo,kBo,LX,SBo,RBo,PBo,cv,C_e,BBo,IBo,yX,NBo,qBo,jBo,fv,w_e,DBo,GBo,xX,OBo,VBo,XBo,mv,A_e,zBo,QBo,$X,WBo,UBo,HBo,gv,L_e,JBo,YBo,kX,KBo,ZBo,eIo,hv,y_e,oIo,rIo,SX,tIo,aIo,nIo,uv,x_e,sIo,lIo,RX,iIo,dIo,cIo,pv,$_e,fIo,mIo,PX,gIo,hIo,uIo,_v,k_e,pIo,_Io,BX,vIo,bIo,FIo,vv,S_e,TIo,MIo,IX,EIo,CIo,wIo,bv,R_e,AIo,LIo,NX,yIo,xIo,$Io,Fv,P_e,kIo,SIo,qX,RIo,PIo,BIo,Tv,B_e,IIo,NIo,jX,qIo,jIo,DIo,Mv,I_e,GIo,OIo,DX,VIo,XIo,zIo,Ev,N_e,QIo,WIo,GX,UIo,HIo,JIo,Cv,q_e,YIo,KIo,OX,ZIo,eNo,oNo,wv,j_e,rNo,tNo,VX,aNo,nNo,sNo,Av,D_e,lNo,iNo,XX,dNo,cNo,fNo,Lv,G_e,mNo,gNo,zX,hNo,uNo,pNo,yv,O_e,_No,vNo,QX,bNo,FNo,TNo,xv,V_e,MNo,ENo,WX,CNo,wNo,ANo,$v,X_e,LNo,yNo,UX,xNo,$No,kNo,kv,z_e,SNo,RNo,HX,PNo,BNo,INo,Sv,Q_e,NNo,qNo,JX,jNo,DNo,GNo,Rv,W_e,ONo,VNo,YX,XNo,zNo,QNo,Pv,U_e,WNo,UNo,KX,HNo,JNo,YNo,Bv,H_e,KNo,ZNo,ZX,eqo,oqo,rqo,Iv,J_e,tqo,aqo,ez,nqo,sqo,lqo,Nv,Y_e,iqo,dqo,oz,cqo,fqo,mqo,qv,K_e,gqo,hqo,rz,uqo,pqo,_qo,jv,Z_e,vqo,bqo,tz,Fqo,Tqo,Mqo,Dv,e2e,Eqo,Cqo,az,wqo,Aqo,Lqo,Gv,o2e,yqo,xqo,nz,$qo,kqo,Sqo,Ov,r2e,Rqo,Pqo,sz,Bqo,Iqo,Nqo,Vv,t2e,qqo,jqo,lz,Dqo,Gqo,Oqo,Xv,a2e,Vqo,Xqo,iz,zqo,Qqo,Wqo,zv,n2e,Uqo,Hqo,dz,Jqo,Yqo,Kqo,Qv,s2e,Zqo,ejo,cz,ojo,rjo,tjo,Wv,l2e,ajo,njo,fz,sjo,ljo,ijo,Uv,i2e,djo,cjo,mz,fjo,mjo,gjo,Hv,d2e,hjo,ujo,gz,pjo,_jo,vjo,Jv,c2e,bjo,Fjo,hz,Tjo,Mjo,Ejo,Yv,f2e,Cjo,wjo,uz,Ajo,Ljo,yjo,Kv,m2e,xjo,$jo,pz,kjo,Sjo,Rjo,Zv,g2e,Pjo,Bjo,_z,Ijo,Njo,qjo,e4,jjo,h2e,Djo,Gjo,u2e,Ojo,Vjo,o4,UYe,Md,r4,p2e,nx,Xjo,_2e,zjo,HYe,Io,sx,Qjo,Ed,Wjo,vz,Ujo,Hjo,bz,Jjo,Yjo,Kjo,lx,Zjo,v2e,eDo,oDo,rDo,bt,ix,tDo,b2e,aDo,nDo,Cd,sDo,F2e,lDo,iDo,Fz,dDo,cDo,fDo,t4,mDo,oo,dx,gDo,T2e,hDo,uDo,Ka,pDo,M2e,_Do,vDo,E2e,bDo,FDo,C2e,TDo,MDo,EDo,z,a4,w2e,CDo,wDo,Tz,ADo,LDo,yDo,n4,A2e,xDo,$Do,Mz,kDo,SDo,RDo,s4,L2e,PDo,BDo,Ez,IDo,NDo,qDo,l4,y2e,jDo,DDo,Cz,GDo,ODo,VDo,i4,x2e,XDo,zDo,wz,QDo,WDo,UDo,d4,$2e,HDo,JDo,Az,YDo,KDo,ZDo,c4,k2e,eGo,oGo,Lz,rGo,tGo,aGo,f4,S2e,nGo,sGo,yz,lGo,iGo,dGo,m4,R2e,cGo,fGo,xz,mGo,gGo,hGo,g4,P2e,uGo,pGo,$z,_Go,vGo,bGo,h4,B2e,FGo,TGo,kz,MGo,EGo,CGo,u4,I2e,wGo,AGo,Sz,LGo,yGo,xGo,p4,N2e,$Go,kGo,Rz,SGo,RGo,PGo,_4,q2e,BGo,IGo,Pz,NGo,qGo,jGo,v4,j2e,DGo,GGo,Bz,OGo,VGo,XGo,b4,D2e,zGo,QGo,Iz,WGo,UGo,HGo,F4,G2e,JGo,YGo,Nz,KGo,ZGo,eOo,T4,O2e,oOo,rOo,qz,tOo,aOo,nOo,M4,V2e,sOo,lOo,jz,iOo,dOo,cOo,E4,X2e,fOo,mOo,Dz,gOo,hOo,uOo,C4,z2e,pOo,_Oo,Gz,vOo,bOo,FOo,w4,Q2e,TOo,MOo,Oz,EOo,COo,wOo,A4,W2e,AOo,LOo,Vz,yOo,xOo,$Oo,L4,U2e,kOo,SOo,Xz,ROo,POo,BOo,y4,H2e,IOo,NOo,zz,qOo,jOo,DOo,x4,J2e,GOo,OOo,Qz,VOo,XOo,zOo,$4,Y2e,QOo,WOo,Wz,UOo,HOo,JOo,k4,K2e,YOo,KOo,Uz,ZOo,eVo,oVo,S4,Z2e,rVo,tVo,Hz,aVo,nVo,sVo,R4,eve,lVo,iVo,Jz,dVo,cVo,fVo,P4,ove,mVo,gVo,Yz,hVo,uVo,pVo,B4,rve,_Vo,vVo,Kz,bVo,FVo,TVo,I4,tve,MVo,EVo,Zz,CVo,wVo,AVo,N4,ave,LVo,yVo,eQ,xVo,$Vo,kVo,q4,nve,SVo,RVo,oQ,PVo,BVo,IVo,j4,sve,NVo,qVo,rQ,jVo,DVo,GVo,D4,lve,OVo,VVo,tQ,XVo,zVo,QVo,G4,ive,WVo,UVo,aQ,HVo,JVo,YVo,O4,dve,KVo,ZVo,nQ,eXo,oXo,rXo,V4,cve,tXo,aXo,sQ,nXo,sXo,lXo,X4,fve,iXo,dXo,lQ,cXo,fXo,mXo,z4,gXo,mve,hXo,uXo,gve,pXo,_Xo,Q4,JYe,wd,W4,hve,cx,vXo,uve,bXo,YYe,No,fx,FXo,Ad,TXo,iQ,MXo,EXo,dQ,CXo,wXo,AXo,mx,LXo,pve,yXo,xXo,$Xo,Ft,gx,kXo,_ve,SXo,RXo,Ld,PXo,vve,BXo,IXo,cQ,NXo,qXo,jXo,U4,DXo,ro,hx,GXo,bve,OXo,VXo,Za,XXo,Fve,zXo,QXo,Tve,WXo,UXo,Mve,HXo,JXo,YXo,U,H4,Eve,KXo,ZXo,fQ,ezo,ozo,rzo,J4,Cve,tzo,azo,mQ,nzo,szo,lzo,Y4,wve,izo,dzo,gQ,czo,fzo,mzo,K4,Ave,gzo,hzo,hQ,uzo,pzo,_zo,Z4,Lve,vzo,bzo,uQ,Fzo,Tzo,Mzo,eb,yve,Ezo,Czo,pQ,wzo,Azo,Lzo,ob,xve,yzo,xzo,_Q,$zo,kzo,Szo,rb,$ve,Rzo,Pzo,vQ,Bzo,Izo,Nzo,tb,kve,qzo,jzo,bQ,Dzo,Gzo,Ozo,ab,Sve,Vzo,Xzo,FQ,zzo,Qzo,Wzo,nb,Rve,Uzo,Hzo,TQ,Jzo,Yzo,Kzo,sb,Pve,Zzo,eQo,MQ,oQo,rQo,tQo,lb,Bve,aQo,nQo,EQ,sQo,lQo,iQo,ib,Ive,dQo,cQo,CQ,fQo,mQo,gQo,db,Nve,hQo,uQo,wQ,pQo,_Qo,vQo,cb,qve,bQo,FQo,AQ,TQo,MQo,EQo,fb,jve,CQo,wQo,LQ,AQo,LQo,yQo,mb,Dve,xQo,$Qo,yQ,kQo,SQo,RQo,gb,Gve,PQo,BQo,xQ,IQo,NQo,qQo,hb,Ove,jQo,DQo,$Q,GQo,OQo,VQo,ub,Vve,XQo,zQo,kQ,QQo,WQo,UQo,pb,Xve,HQo,JQo,SQ,YQo,KQo,ZQo,_b,zve,eWo,oWo,RQ,rWo,tWo,aWo,vb,Qve,nWo,sWo,PQ,lWo,iWo,dWo,bb,Wve,cWo,fWo,BQ,mWo,gWo,hWo,Fb,Uve,uWo,pWo,IQ,_Wo,vWo,bWo,Tb,Hve,FWo,TWo,NQ,MWo,EWo,CWo,Mb,Jve,wWo,AWo,qQ,LWo,yWo,xWo,Eb,Yve,$Wo,kWo,jQ,SWo,RWo,PWo,Cb,Kve,BWo,IWo,DQ,NWo,qWo,jWo,wb,Zve,DWo,GWo,GQ,OWo,VWo,XWo,Ab,e4e,zWo,QWo,OQ,WWo,UWo,HWo,Lb,o4e,JWo,YWo,VQ,KWo,ZWo,eUo,yb,r4e,oUo,rUo,XQ,tUo,aUo,nUo,xb,t4e,sUo,lUo,a4e,iUo,dUo,cUo,$b,n4e,fUo,mUo,zQ,gUo,hUo,uUo,kb,s4e,pUo,_Uo,QQ,vUo,bUo,FUo,Sb,l4e,TUo,MUo,WQ,EUo,CUo,wUo,Rb,i4e,AUo,LUo,UQ,yUo,xUo,$Uo,Pb,kUo,d4e,SUo,RUo,c4e,PUo,BUo,Bb,KYe,yd,Ib,f4e,ux,IUo,m4e,NUo,ZYe,qo,px,qUo,xd,jUo,HQ,DUo,GUo,JQ,OUo,VUo,XUo,_x,zUo,g4e,QUo,WUo,UUo,Tt,vx,HUo,h4e,JUo,YUo,$d,KUo,u4e,ZUo,eHo,YQ,oHo,rHo,tHo,Nb,aHo,to,bx,nHo,p4e,sHo,lHo,en,iHo,_4e,dHo,cHo,v4e,fHo,mHo,b4e,gHo,hHo,uHo,fe,qb,F4e,pHo,_Ho,KQ,vHo,bHo,FHo,jb,T4e,THo,MHo,ZQ,EHo,CHo,wHo,Db,M4e,AHo,LHo,eW,yHo,xHo,$Ho,Gb,E4e,kHo,SHo,oW,RHo,PHo,BHo,Ob,C4e,IHo,NHo,rW,qHo,jHo,DHo,Vb,w4e,GHo,OHo,tW,VHo,XHo,zHo,Xb,A4e,QHo,WHo,aW,UHo,HHo,JHo,zb,L4e,YHo,KHo,nW,ZHo,eJo,oJo,Qb,y4e,rJo,tJo,sW,aJo,nJo,sJo,Wb,x4e,lJo,iJo,lW,dJo,cJo,fJo,Ub,$4e,mJo,gJo,iW,hJo,uJo,pJo,Hb,k4e,_Jo,vJo,dW,bJo,FJo,TJo,Jb,S4e,MJo,EJo,cW,CJo,wJo,AJo,Yb,R4e,LJo,yJo,fW,xJo,$Jo,kJo,Kb,P4e,SJo,RJo,mW,PJo,BJo,IJo,Zb,B4e,NJo,qJo,gW,jJo,DJo,GJo,e1,I4e,OJo,VJo,hW,XJo,zJo,QJo,o1,N4e,WJo,UJo,uW,HJo,JJo,YJo,r1,q4e,KJo,ZJo,pW,eYo,oYo,rYo,t1,j4e,tYo,aYo,_W,nYo,sYo,lYo,a1,iYo,D4e,dYo,cYo,G4e,fYo,mYo,n1,eKe,kd,s1,O4e,Fx,gYo,V4e,hYo,oKe,jo,Tx,uYo,Sd,pYo,vW,_Yo,vYo,bW,bYo,FYo,TYo,Mx,MYo,X4e,EYo,CYo,wYo,Mt,Ex,AYo,z4e,LYo,yYo,Rd,xYo,Q4e,$Yo,kYo,FW,SYo,RYo,PYo,l1,BYo,ao,Cx,IYo,W4e,NYo,qYo,on,jYo,U4e,DYo,GYo,H4e,OYo,VYo,J4e,XYo,zYo,QYo,q,i1,Y4e,WYo,UYo,TW,HYo,JYo,YYo,d1,K4e,KYo,ZYo,MW,eKo,oKo,rKo,c1,Z4e,tKo,aKo,EW,nKo,sKo,lKo,f1,ebe,iKo,dKo,CW,cKo,fKo,mKo,m1,obe,gKo,hKo,wW,uKo,pKo,_Ko,g1,rbe,vKo,bKo,AW,FKo,TKo,MKo,h1,tbe,EKo,CKo,LW,wKo,AKo,LKo,u1,abe,yKo,xKo,yW,$Ko,kKo,SKo,p1,nbe,RKo,PKo,xW,BKo,IKo,NKo,_1,sbe,qKo,jKo,$W,DKo,GKo,OKo,v1,lbe,VKo,XKo,kW,zKo,QKo,WKo,b1,ibe,UKo,HKo,SW,JKo,YKo,KKo,F1,dbe,ZKo,eZo,RW,oZo,rZo,tZo,T1,cbe,aZo,nZo,PW,sZo,lZo,iZo,M1,fbe,dZo,cZo,BW,fZo,mZo,gZo,E1,mbe,hZo,uZo,IW,pZo,_Zo,vZo,C1,gbe,bZo,FZo,NW,TZo,MZo,EZo,w1,hbe,CZo,wZo,qW,AZo,LZo,yZo,A1,ube,xZo,$Zo,jW,kZo,SZo,RZo,L1,pbe,PZo,BZo,DW,IZo,NZo,qZo,y1,_be,jZo,DZo,GW,GZo,OZo,VZo,x1,vbe,XZo,zZo,OW,QZo,WZo,UZo,$1,bbe,HZo,JZo,VW,YZo,KZo,ZZo,k1,Fbe,eer,oer,XW,rer,ter,aer,S1,Tbe,ner,ser,zW,ler,ier,der,R1,Mbe,cer,fer,QW,mer,ger,her,P1,Ebe,uer,per,WW,_er,ver,ber,B1,Cbe,Fer,Ter,UW,Mer,Eer,Cer,I1,wbe,wer,Aer,HW,Ler,yer,xer,N1,Abe,$er,ker,JW,Ser,Rer,Per,q1,Lbe,Ber,Ier,YW,Ner,qer,jer,j1,ybe,Der,Ger,KW,Oer,Ver,Xer,D1,xbe,zer,Qer,ZW,Wer,Uer,Her,G1,$be,Jer,Yer,eU,Ker,Zer,eor,O1,kbe,oor,ror,oU,tor,aor,nor,V1,Sbe,sor,lor,rU,ior,dor,cor,X1,Rbe,mor,gor,tU,hor,uor,por,z1,Pbe,_or,vor,aU,bor,For,Tor,Q1,Bbe,Mor,Eor,nU,Cor,wor,Aor,W1,Ibe,Lor,yor,sU,xor,$or,kor,U1,Nbe,Sor,Ror,lU,Por,Bor,Ior,H1,qbe,Nor,qor,iU,jor,Dor,Gor,J1,jbe,Oor,Vor,dU,Xor,zor,Qor,Y1,Dbe,Wor,Uor,cU,Hor,Jor,Yor,K1,Gbe,Kor,Zor,fU,err,orr,rrr,Z1,Obe,trr,arr,mU,nrr,srr,lrr,e0,Vbe,irr,drr,gU,crr,frr,mrr,o0,Xbe,grr,hrr,hU,urr,prr,_rr,r0,zbe,vrr,brr,uU,Frr,Trr,Mrr,t0,Qbe,Err,Crr,pU,wrr,Arr,Lrr,a0,Wbe,yrr,xrr,_U,$rr,krr,Srr,n0,Ube,Rrr,Prr,vU,Brr,Irr,Nrr,s0,Hbe,qrr,jrr,bU,Drr,Grr,Orr,l0,Vrr,Jbe,Xrr,zrr,Ybe,Qrr,Wrr,i0,rKe,Pd,d0,Kbe,wx,Urr,Zbe,Hrr,tKe,Do,Ax,Jrr,Bd,Yrr,FU,Krr,Zrr,TU,etr,otr,rtr,Lx,ttr,e1e,atr,ntr,str,Et,yx,ltr,o1e,itr,dtr,Id,ctr,r1e,ftr,mtr,MU,gtr,htr,utr,c0,ptr,no,xx,_tr,t1e,vtr,btr,rn,Ftr,a1e,Ttr,Mtr,n1e,Etr,Ctr,s1e,wtr,Atr,Ltr,Z,f0,l1e,ytr,xtr,EU,$tr,ktr,Str,m0,i1e,Rtr,Ptr,CU,Btr,Itr,Ntr,g0,d1e,qtr,jtr,wU,Dtr,Gtr,Otr,h0,c1e,Vtr,Xtr,AU,ztr,Qtr,Wtr,u0,f1e,Utr,Htr,LU,Jtr,Ytr,Ktr,p0,m1e,Ztr,ear,yU,oar,rar,tar,_0,g1e,aar,nar,xU,sar,lar,iar,v0,h1e,dar,car,$U,far,mar,gar,b0,u1e,har,uar,kU,par,_ar,bar,F0,p1e,Far,Tar,SU,Mar,Ear,Car,T0,_1e,war,Aar,RU,Lar,yar,xar,M0,v1e,$ar,kar,PU,Sar,Rar,Par,E0,b1e,Bar,Iar,BU,Nar,qar,jar,C0,F1e,Dar,Gar,IU,Oar,Var,Xar,w0,T1e,zar,Qar,NU,War,Uar,Har,A0,M1e,Jar,Yar,qU,Kar,Zar,enr,L0,E1e,onr,rnr,jU,tnr,anr,nnr,y0,C1e,snr,lnr,DU,inr,dnr,cnr,x0,w1e,fnr,mnr,GU,gnr,hnr,unr,$0,A1e,pnr,_nr,OU,vnr,bnr,Fnr,k0,L1e,Tnr,Mnr,VU,Enr,Cnr,wnr,S0,y1e,Anr,Lnr,XU,ynr,xnr,$nr,R0,x1e,knr,Snr,zU,Rnr,Pnr,Bnr,P0,$1e,Inr,Nnr,QU,qnr,jnr,Dnr,B0,k1e,Gnr,Onr,WU,Vnr,Xnr,znr,I0,S1e,Qnr,Wnr,UU,Unr,Hnr,Jnr,N0,R1e,Ynr,Knr,HU,Znr,esr,osr,q0,P1e,rsr,tsr,JU,asr,nsr,ssr,j0,B1e,lsr,isr,YU,dsr,csr,fsr,D0,I1e,msr,gsr,KU,hsr,usr,psr,G0,N1e,_sr,vsr,ZU,bsr,Fsr,Tsr,O0,q1e,Msr,Esr,eH,Csr,wsr,Asr,V0,Lsr,j1e,ysr,xsr,D1e,$sr,ksr,X0,aKe,Nd,z0,G1e,$x,Ssr,O1e,Rsr,nKe,Go,kx,Psr,qd,Bsr,oH,Isr,Nsr,rH,qsr,jsr,Dsr,Sx,Gsr,V1e,Osr,Vsr,Xsr,Ct,Rx,zsr,X1e,Qsr,Wsr,jd,Usr,z1e,Hsr,Jsr,tH,Ysr,Ksr,Zsr,Q0,elr,so,Px,olr,Q1e,rlr,tlr,tn,alr,W1e,nlr,slr,U1e,llr,ilr,H1e,dlr,clr,flr,Ue,W0,J1e,mlr,glr,aH,hlr,ulr,plr,U0,Y1e,_lr,vlr,nH,blr,Flr,Tlr,H0,K1e,Mlr,Elr,sH,Clr,wlr,Alr,J0,Z1e,Llr,ylr,lH,xlr,$lr,klr,Y0,e0e,Slr,Rlr,iH,Plr,Blr,Ilr,K0,o0e,Nlr,qlr,dH,jlr,Dlr,Glr,Z0,r0e,Olr,Vlr,cH,Xlr,zlr,Qlr,eF,Wlr,t0e,Ulr,Hlr,a0e,Jlr,Ylr,oF,sKe,Dd,rF,n0e,Bx,Klr,s0e,Zlr,lKe,Oo,Ix,eir,Gd,oir,fH,rir,tir,mH,air,nir,sir,Nx,lir,l0e,iir,dir,cir,wt,qx,fir,i0e,mir,gir,Od,hir,d0e,uir,pir,gH,_ir,vir,bir,tF,Fir,lo,jx,Tir,c0e,Mir,Eir,an,Cir,f0e,wir,Air,m0e,Lir,yir,g0e,xir,$ir,kir,H,aF,h0e,Sir,Rir,hH,Pir,Bir,Iir,nF,u0e,Nir,qir,uH,jir,Dir,Gir,sF,p0e,Oir,Vir,pH,Xir,zir,Qir,lF,_0e,Wir,Uir,_H,Hir,Jir,Yir,iF,v0e,Kir,Zir,vH,edr,odr,rdr,dF,b0e,tdr,adr,bH,ndr,sdr,ldr,cF,F0e,idr,ddr,FH,cdr,fdr,mdr,fF,T0e,gdr,hdr,TH,udr,pdr,_dr,mF,M0e,vdr,bdr,MH,Fdr,Tdr,Mdr,gF,E0e,Edr,Cdr,EH,wdr,Adr,Ldr,hF,C0e,ydr,xdr,CH,$dr,kdr,Sdr,uF,w0e,Rdr,Pdr,wH,Bdr,Idr,Ndr,pF,A0e,qdr,jdr,AH,Ddr,Gdr,Odr,_F,L0e,Vdr,Xdr,LH,zdr,Qdr,Wdr,vF,y0e,Udr,Hdr,yH,Jdr,Ydr,Kdr,bF,x0e,Zdr,ecr,xH,ocr,rcr,tcr,FF,$0e,acr,ncr,$H,scr,lcr,icr,TF,k0e,dcr,ccr,kH,fcr,mcr,gcr,MF,S0e,hcr,ucr,SH,pcr,_cr,vcr,EF,R0e,bcr,Fcr,RH,Tcr,Mcr,Ecr,CF,P0e,Ccr,wcr,PH,Acr,Lcr,ycr,wF,B0e,xcr,$cr,BH,kcr,Scr,Rcr,AF,I0e,Pcr,Bcr,IH,Icr,Ncr,qcr,LF,N0e,jcr,Dcr,NH,Gcr,Ocr,Vcr,yF,q0e,Xcr,zcr,qH,Qcr,Wcr,Ucr,xF,j0e,Hcr,Jcr,jH,Ycr,Kcr,Zcr,$F,D0e,efr,ofr,DH,rfr,tfr,afr,kF,G0e,nfr,sfr,GH,lfr,ifr,dfr,SF,O0e,cfr,ffr,OH,mfr,gfr,hfr,RF,V0e,ufr,pfr,VH,_fr,vfr,bfr,PF,X0e,Ffr,Tfr,XH,Mfr,Efr,Cfr,BF,z0e,wfr,Afr,zH,Lfr,yfr,xfr,IF,Q0e,$fr,kfr,QH,Sfr,Rfr,Pfr,NF,W0e,Bfr,Ifr,WH,Nfr,qfr,jfr,qF,U0e,Dfr,Gfr,UH,Ofr,Vfr,Xfr,jF,H0e,zfr,Qfr,HH,Wfr,Ufr,Hfr,DF,J0e,Jfr,Yfr,JH,Kfr,Zfr,emr,GF,Y0e,omr,rmr,YH,tmr,amr,nmr,OF,smr,K0e,lmr,imr,Z0e,dmr,cmr,VF,iKe,Vd,XF,eFe,Dx,fmr,oFe,mmr,dKe,Vo,Gx,gmr,Xd,hmr,KH,umr,pmr,ZH,_mr,vmr,bmr,Ox,Fmr,rFe,Tmr,Mmr,Emr,At,Vx,Cmr,tFe,wmr,Amr,zd,Lmr,aFe,ymr,xmr,eJ,$mr,kmr,Smr,zF,Rmr,io,Xx,Pmr,nFe,Bmr,Imr,nn,Nmr,sFe,qmr,jmr,lFe,Dmr,Gmr,iFe,Omr,Vmr,Xmr,V,QF,dFe,zmr,Qmr,oJ,Wmr,Umr,Hmr,WF,cFe,Jmr,Ymr,rJ,Kmr,Zmr,egr,UF,fFe,ogr,rgr,tJ,tgr,agr,ngr,HF,mFe,sgr,lgr,aJ,igr,dgr,cgr,JF,gFe,fgr,mgr,nJ,ggr,hgr,ugr,YF,hFe,pgr,_gr,sJ,vgr,bgr,Fgr,KF,uFe,Tgr,Mgr,lJ,Egr,Cgr,wgr,ZF,pFe,Agr,Lgr,iJ,ygr,xgr,$gr,eT,_Fe,kgr,Sgr,dJ,Rgr,Pgr,Bgr,oT,vFe,Igr,Ngr,cJ,qgr,jgr,Dgr,rT,bFe,Ggr,Ogr,fJ,Vgr,Xgr,zgr,tT,FFe,Qgr,Wgr,mJ,Ugr,Hgr,Jgr,aT,TFe,Ygr,Kgr,gJ,Zgr,ehr,ohr,nT,MFe,rhr,thr,hJ,ahr,nhr,shr,sT,EFe,lhr,ihr,uJ,dhr,chr,fhr,lT,CFe,mhr,ghr,pJ,hhr,uhr,phr,iT,wFe,_hr,vhr,_J,bhr,Fhr,Thr,dT,AFe,Mhr,Ehr,vJ,Chr,whr,Ahr,cT,LFe,Lhr,yhr,bJ,xhr,$hr,khr,fT,yFe,Shr,Rhr,FJ,Phr,Bhr,Ihr,mT,xFe,Nhr,qhr,TJ,jhr,Dhr,Ghr,gT,$Fe,Ohr,Vhr,MJ,Xhr,zhr,Qhr,hT,kFe,Whr,Uhr,EJ,Hhr,Jhr,Yhr,uT,SFe,Khr,Zhr,CJ,eur,our,rur,pT,RFe,tur,aur,wJ,nur,sur,lur,_T,PFe,iur,dur,AJ,cur,fur,mur,vT,BFe,gur,hur,LJ,uur,pur,_ur,bT,IFe,vur,bur,yJ,Fur,Tur,Mur,FT,NFe,Eur,Cur,xJ,wur,Aur,Lur,TT,qFe,yur,xur,$J,$ur,kur,Sur,MT,jFe,Rur,Pur,kJ,Bur,Iur,Nur,ET,DFe,qur,jur,SJ,Dur,Gur,Our,CT,GFe,Vur,Xur,RJ,zur,Qur,Wur,wT,OFe,Uur,Hur,PJ,Jur,Yur,Kur,AT,VFe,Zur,epr,BJ,opr,rpr,tpr,LT,XFe,apr,npr,IJ,spr,lpr,ipr,yT,zFe,dpr,cpr,NJ,fpr,mpr,gpr,xT,QFe,hpr,upr,qJ,ppr,_pr,vpr,$T,WFe,bpr,Fpr,jJ,Tpr,Mpr,Epr,kT,UFe,Cpr,wpr,DJ,Apr,Lpr,ypr,ST,HFe,xpr,$pr,GJ,kpr,Spr,Rpr,RT,JFe,Ppr,Bpr,OJ,Ipr,Npr,qpr,PT,YFe,jpr,Dpr,VJ,Gpr,Opr,Vpr,BT,KFe,Xpr,zpr,XJ,Qpr,Wpr,Upr,IT,Hpr,ZFe,Jpr,Ypr,eTe,Kpr,Zpr,NT,cKe,Qd,qT,oTe,zx,e_r,rTe,o_r,fKe,Xo,Qx,r_r,Wd,t_r,zJ,a_r,n_r,QJ,s_r,l_r,i_r,Wx,d_r,tTe,c_r,f_r,m_r,Lt,Ux,g_r,aTe,h_r,u_r,Ud,p_r,nTe,__r,v_r,WJ,b_r,F_r,T_r,jT,M_r,co,Hx,E_r,sTe,C_r,w_r,sn,A_r,lTe,L_r,y_r,iTe,x_r,$_r,dTe,k_r,S_r,R_r,cTe,DT,fTe,P_r,B_r,UJ,I_r,N_r,q_r,GT,j_r,mTe,D_r,G_r,gTe,O_r,V_r,OT,mKe,Hd,VT,hTe,Jx,X_r,uTe,z_r,gKe,zo,Yx,Q_r,Jd,W_r,HJ,U_r,H_r,JJ,J_r,Y_r,K_r,Kx,Z_r,pTe,e2r,o2r,r2r,yt,Zx,t2r,_Te,a2r,n2r,Yd,s2r,vTe,l2r,i2r,YJ,d2r,c2r,f2r,XT,m2r,fo,e$,g2r,bTe,h2r,u2r,ln,p2r,FTe,_2r,v2r,TTe,b2r,F2r,MTe,T2r,M2r,E2r,Kd,zT,ETe,C2r,w2r,KJ,A2r,L2r,y2r,QT,CTe,x2r,$2r,ZJ,k2r,S2r,R2r,WT,wTe,P2r,B2r,eY,I2r,N2r,q2r,UT,j2r,ATe,D2r,G2r,LTe,O2r,V2r,HT,hKe,Zd,JT,yTe,o$,X2r,xTe,z2r,uKe,Qo,r$,Q2r,ec,W2r,oY,U2r,H2r,rY,J2r,Y2r,K2r,t$,Z2r,$Te,evr,ovr,rvr,xt,a$,tvr,kTe,avr,nvr,oc,svr,STe,lvr,ivr,tY,dvr,cvr,fvr,YT,mvr,mo,n$,gvr,RTe,hvr,uvr,dn,pvr,PTe,_vr,vvr,BTe,bvr,Fvr,ITe,Tvr,Mvr,Evr,ve,KT,NTe,Cvr,wvr,aY,Avr,Lvr,yvr,ZT,qTe,xvr,$vr,nY,kvr,Svr,Rvr,eM,jTe,Pvr,Bvr,sY,Ivr,Nvr,qvr,oM,DTe,jvr,Dvr,lY,Gvr,Ovr,Vvr,_l,GTe,Xvr,zvr,iY,Qvr,Wvr,dY,Uvr,Hvr,Jvr,rM,OTe,Yvr,Kvr,cY,Zvr,e4r,o4r,vl,VTe,r4r,t4r,fY,a4r,n4r,mY,s4r,l4r,i4r,tM,XTe,d4r,c4r,gY,f4r,m4r,g4r,$t,zTe,h4r,u4r,hY,p4r,_4r,uY,v4r,b4r,pY,F4r,T4r,M4r,aM,QTe,E4r,C4r,_Y,w4r,A4r,L4r,nM,WTe,y4r,x4r,vY,$4r,k4r,S4r,sM,UTe,R4r,P4r,bY,B4r,I4r,N4r,lM,HTe,q4r,j4r,FY,D4r,G4r,O4r,iM,JTe,V4r,X4r,TY,z4r,Q4r,W4r,dM,YTe,U4r,H4r,MY,J4r,Y4r,K4r,cM,KTe,Z4r,ebr,EY,obr,rbr,tbr,fM,ZTe,abr,nbr,CY,sbr,lbr,ibr,mM,dbr,eMe,cbr,fbr,oMe,mbr,gbr,gM,pKe,rc,hM,rMe,s$,hbr,tMe,ubr,_Ke,Wo,l$,pbr,tc,_br,wY,vbr,bbr,AY,Fbr,Tbr,Mbr,i$,Ebr,aMe,Cbr,wbr,Abr,kt,d$,Lbr,nMe,ybr,xbr,ac,$br,sMe,kbr,Sbr,LY,Rbr,Pbr,Bbr,uM,Ibr,go,c$,Nbr,lMe,qbr,jbr,cn,Dbr,iMe,Gbr,Obr,dMe,Vbr,Xbr,cMe,zbr,Qbr,Wbr,fMe,pM,mMe,Ubr,Hbr,yY,Jbr,Ybr,Kbr,_M,Zbr,gMe,e1r,o1r,hMe,r1r,t1r,vM,vKe,nc,bM,uMe,f$,a1r,pMe,n1r,bKe,Uo,m$,s1r,sc,l1r,xY,i1r,d1r,$Y,c1r,f1r,m1r,g$,g1r,_Me,h1r,u1r,p1r,St,h$,_1r,vMe,v1r,b1r,lc,F1r,bMe,T1r,M1r,kY,E1r,C1r,w1r,FM,A1r,ho,u$,L1r,FMe,y1r,x1r,fn,$1r,TMe,k1r,S1r,MMe,R1r,P1r,EMe,B1r,I1r,N1r,CMe,TM,wMe,q1r,j1r,SY,D1r,G1r,O1r,MM,V1r,AMe,X1r,z1r,LMe,Q1r,W1r,EM,FKe,ic,CM,yMe,p$,U1r,xMe,H1r,TKe,Ho,_$,J1r,dc,Y1r,RY,K1r,Z1r,PY,e0r,o0r,r0r,v$,t0r,$Me,a0r,n0r,s0r,Rt,b$,l0r,kMe,i0r,d0r,cc,c0r,SMe,f0r,m0r,BY,g0r,h0r,u0r,wM,p0r,uo,F$,_0r,RMe,v0r,b0r,mn,F0r,PMe,T0r,M0r,BMe,E0r,C0r,IMe,w0r,A0r,L0r,NMe,AM,qMe,y0r,x0r,IY,$0r,k0r,S0r,LM,R0r,jMe,P0r,B0r,DMe,I0r,N0r,yM,MKe,fc,xM,GMe,T$,q0r,OMe,j0r,EKe,Jo,M$,D0r,mc,G0r,NY,O0r,V0r,qY,X0r,z0r,Q0r,E$,W0r,VMe,U0r,H0r,J0r,Pt,C$,Y0r,XMe,K0r,Z0r,gc,eFr,zMe,oFr,rFr,jY,tFr,aFr,nFr,$M,sFr,po,w$,lFr,QMe,iFr,dFr,gn,cFr,WMe,fFr,mFr,UMe,gFr,hFr,HMe,uFr,pFr,_Fr,Pe,kM,JMe,vFr,bFr,DY,FFr,TFr,MFr,SM,YMe,EFr,CFr,GY,wFr,AFr,LFr,RM,KMe,yFr,xFr,OY,$Fr,kFr,SFr,PM,ZMe,RFr,PFr,VY,BFr,IFr,NFr,BM,eEe,qFr,jFr,XY,DFr,GFr,OFr,IM,oEe,VFr,XFr,zY,zFr,QFr,WFr,NM,rEe,UFr,HFr,QY,JFr,YFr,KFr,qM,tEe,ZFr,eTr,WY,oTr,rTr,tTr,jM,aEe,aTr,nTr,UY,sTr,lTr,iTr,DM,dTr,nEe,cTr,fTr,sEe,mTr,gTr,GM,CKe,hc,OM,lEe,A$,hTr,iEe,uTr,wKe,Yo,L$,pTr,uc,_Tr,HY,vTr,bTr,JY,FTr,TTr,MTr,y$,ETr,dEe,CTr,wTr,ATr,Bt,x$,LTr,cEe,yTr,xTr,pc,$Tr,fEe,kTr,STr,YY,RTr,PTr,BTr,VM,ITr,_o,$$,NTr,mEe,qTr,jTr,hn,DTr,gEe,GTr,OTr,hEe,VTr,XTr,uEe,zTr,QTr,WTr,ft,XM,pEe,UTr,HTr,KY,JTr,YTr,KTr,zM,_Ee,ZTr,eMr,ZY,oMr,rMr,tMr,QM,vEe,aMr,nMr,eK,sMr,lMr,iMr,WM,bEe,dMr,cMr,oK,fMr,mMr,gMr,UM,FEe,hMr,uMr,rK,pMr,_Mr,vMr,HM,bMr,TEe,FMr,TMr,MEe,MMr,EMr,JM,AKe,_c,YM,EEe,k$,CMr,CEe,wMr,LKe,Ko,S$,AMr,vc,LMr,tK,yMr,xMr,aK,$Mr,kMr,SMr,R$,RMr,wEe,PMr,BMr,IMr,It,P$,NMr,AEe,qMr,jMr,bc,DMr,LEe,GMr,OMr,nK,VMr,XMr,zMr,KM,QMr,vo,B$,WMr,yEe,UMr,HMr,un,JMr,xEe,YMr,KMr,$Ee,ZMr,eEr,kEe,oEr,rEr,tEr,Le,ZM,SEe,aEr,nEr,sK,sEr,lEr,iEr,eE,REe,dEr,cEr,lK,fEr,mEr,gEr,oE,PEe,hEr,uEr,iK,pEr,_Er,vEr,rE,BEe,bEr,FEr,dK,TEr,MEr,EEr,tE,IEe,CEr,wEr,cK,AEr,LEr,yEr,aE,NEe,xEr,$Er,fK,kEr,SEr,REr,nE,qEe,PEr,BEr,mK,IEr,NEr,qEr,sE,jEe,jEr,DEr,gK,GEr,OEr,VEr,lE,DEe,XEr,zEr,hK,QEr,WEr,UEr,iE,GEe,HEr,JEr,uK,YEr,KEr,ZEr,dE,eCr,OEe,oCr,rCr,VEe,tCr,aCr,cE,yKe,Fc,fE,XEe,I$,nCr,zEe,sCr,xKe,Zo,N$,lCr,Tc,iCr,pK,dCr,cCr,_K,fCr,mCr,gCr,q$,hCr,QEe,uCr,pCr,_Cr,Nt,j$,vCr,WEe,bCr,FCr,Mc,TCr,UEe,MCr,ECr,vK,CCr,wCr,ACr,mE,LCr,bo,D$,yCr,HEe,xCr,$Cr,pn,kCr,JEe,SCr,RCr,YEe,PCr,BCr,KEe,ICr,NCr,qCr,G$,gE,ZEe,jCr,DCr,bK,GCr,OCr,VCr,hE,eCe,XCr,zCr,FK,QCr,WCr,UCr,uE,HCr,oCe,JCr,YCr,rCe,KCr,ZCr,pE,$Ke,Ec,_E,tCe,O$,e3r,aCe,o3r,kKe,er,V$,r3r,Cc,t3r,TK,a3r,n3r,MK,s3r,l3r,i3r,X$,d3r,nCe,c3r,f3r,m3r,qt,z$,g3r,sCe,h3r,u3r,wc,p3r,lCe,_3r,v3r,EK,b3r,F3r,T3r,vE,M3r,Fo,Q$,E3r,iCe,C3r,w3r,_n,A3r,dCe,L3r,y3r,cCe,x3r,$3r,fCe,k3r,S3r,R3r,mt,bE,mCe,P3r,B3r,CK,I3r,N3r,q3r,FE,gCe,j3r,D3r,wK,G3r,O3r,V3r,TE,hCe,X3r,z3r,AK,Q3r,W3r,U3r,ME,uCe,H3r,J3r,LK,Y3r,K3r,Z3r,EE,pCe,e5r,o5r,yK,r5r,t5r,a5r,CE,n5r,_Ce,s5r,l5r,vCe,i5r,d5r,wE,SKe,Ac,AE,bCe,W$,c5r,FCe,f5r,RKe,or,U$,m5r,Lc,g5r,xK,h5r,u5r,$K,p5r,_5r,v5r,H$,b5r,TCe,F5r,T5r,M5r,jt,J$,E5r,MCe,C5r,w5r,yc,A5r,ECe,L5r,y5r,kK,x5r,$5r,k5r,LE,S5r,To,Y$,R5r,CCe,P5r,B5r,vn,I5r,wCe,N5r,q5r,ACe,j5r,D5r,LCe,G5r,O5r,V5r,bn,yE,yCe,X5r,z5r,SK,Q5r,W5r,U5r,xE,xCe,H5r,J5r,RK,Y5r,K5r,Z5r,$E,$Ce,ewr,owr,PK,rwr,twr,awr,kE,kCe,nwr,swr,BK,lwr,iwr,dwr,SE,cwr,SCe,fwr,mwr,RCe,gwr,hwr,RE,PKe,xc,PE,PCe,K$,uwr,BCe,pwr,BKe,rr,Z$,_wr,$c,vwr,IK,bwr,Fwr,NK,Twr,Mwr,Ewr,ek,Cwr,ICe,wwr,Awr,Lwr,Dt,ok,ywr,NCe,xwr,$wr,kc,kwr,qCe,Swr,Rwr,qK,Pwr,Bwr,Iwr,BE,Nwr,Mo,rk,qwr,jCe,jwr,Dwr,Fn,Gwr,DCe,Owr,Vwr,GCe,Xwr,zwr,OCe,Qwr,Wwr,Uwr,tk,IE,VCe,Hwr,Jwr,jK,Ywr,Kwr,Zwr,NE,XCe,eAr,oAr,DK,rAr,tAr,aAr,qE,nAr,zCe,sAr,lAr,QCe,iAr,dAr,jE,IKe,Sc,DE,WCe,ak,cAr,UCe,fAr,NKe,tr,nk,mAr,Rc,gAr,GK,hAr,uAr,OK,pAr,_Ar,vAr,sk,bAr,HCe,FAr,TAr,MAr,Gt,lk,EAr,JCe,CAr,wAr,Pc,AAr,YCe,LAr,yAr,VK,xAr,$Ar,kAr,GE,SAr,Eo,ik,RAr,KCe,PAr,BAr,Tn,IAr,ZCe,NAr,qAr,e3e,jAr,DAr,o3e,GAr,OAr,VAr,r3e,OE,t3e,XAr,zAr,XK,QAr,WAr,UAr,VE,HAr,a3e,JAr,YAr,n3e,KAr,ZAr,XE,qKe,Bc,zE,s3e,dk,e6r,l3e,o6r,jKe,ar,ck,r6r,Ic,t6r,zK,a6r,n6r,QK,s6r,l6r,i6r,fk,d6r,i3e,c6r,f6r,m6r,Ot,mk,g6r,d3e,h6r,u6r,Nc,p6r,c3e,_6r,v6r,WK,b6r,F6r,T6r,QE,M6r,Co,gk,E6r,f3e,C6r,w6r,Mn,A6r,m3e,L6r,y6r,g3e,x6r,$6r,h3e,k6r,S6r,R6r,gt,WE,u3e,P6r,B6r,UK,I6r,N6r,q6r,UE,p3e,j6r,D6r,HK,G6r,O6r,V6r,HE,_3e,X6r,z6r,JK,Q6r,W6r,U6r,JE,v3e,H6r,J6r,YK,Y6r,K6r,Z6r,YE,b3e,e7r,o7r,KK,r7r,t7r,a7r,KE,n7r,F3e,s7r,l7r,T3e,i7r,d7r,ZE,DKe,qc,eC,M3e,hk,c7r,E3e,f7r,GKe,nr,uk,m7r,jc,g7r,ZK,h7r,u7r,eZ,p7r,_7r,v7r,pk,b7r,C3e,F7r,T7r,M7r,Vt,_k,E7r,w3e,C7r,w7r,Dc,A7r,A3e,L7r,y7r,oZ,x7r,$7r,k7r,oC,S7r,wo,vk,R7r,L3e,P7r,B7r,En,I7r,y3e,N7r,q7r,x3e,j7r,D7r,$3e,G7r,O7r,V7r,k3e,rC,S3e,X7r,z7r,rZ,Q7r,W7r,U7r,tC,H7r,R3e,J7r,Y7r,P3e,K7r,Z7r,aC,OKe,Gc,nC,B3e,bk,eLr,I3e,oLr,VKe,sr,Fk,rLr,Oc,tLr,tZ,aLr,nLr,aZ,sLr,lLr,iLr,Tk,dLr,N3e,cLr,fLr,mLr,Xt,Mk,gLr,q3e,hLr,uLr,Vc,pLr,j3e,_Lr,vLr,nZ,bLr,FLr,TLr,sC,MLr,Ir,Ek,ELr,D3e,CLr,wLr,Cn,ALr,G3e,LLr,yLr,O3e,xLr,$Lr,V3e,kLr,SLr,RLr,N,lC,X3e,PLr,BLr,sZ,ILr,NLr,qLr,iC,z3e,jLr,DLr,lZ,GLr,OLr,VLr,dC,Q3e,XLr,zLr,iZ,QLr,WLr,ULr,cC,W3e,HLr,JLr,dZ,YLr,KLr,ZLr,fC,U3e,eyr,oyr,cZ,ryr,tyr,ayr,mC,H3e,nyr,syr,fZ,lyr,iyr,dyr,gC,J3e,cyr,fyr,mZ,myr,gyr,hyr,hC,Y3e,uyr,pyr,gZ,_yr,vyr,byr,uC,K3e,Fyr,Tyr,hZ,Myr,Eyr,Cyr,pC,Z3e,wyr,Ayr,uZ,Lyr,yyr,xyr,_C,e5e,$yr,kyr,pZ,Syr,Ryr,Pyr,vC,o5e,Byr,Iyr,_Z,Nyr,qyr,jyr,bC,r5e,Dyr,Gyr,vZ,Oyr,Vyr,Xyr,FC,t5e,zyr,Qyr,bZ,Wyr,Uyr,Hyr,TC,a5e,Jyr,Yyr,FZ,Kyr,Zyr,e8r,MC,n5e,o8r,r8r,TZ,t8r,a8r,n8r,EC,s5e,s8r,l8r,MZ,i8r,d8r,c8r,CC,l5e,f8r,m8r,EZ,g8r,h8r,u8r,bl,i5e,p8r,_8r,CZ,v8r,b8r,wZ,F8r,T8r,M8r,wC,d5e,E8r,C8r,AZ,w8r,A8r,L8r,AC,c5e,y8r,x8r,LZ,$8r,k8r,S8r,LC,f5e,R8r,P8r,yZ,B8r,I8r,N8r,yC,m5e,q8r,j8r,xZ,D8r,G8r,O8r,xC,g5e,V8r,X8r,$Z,z8r,Q8r,W8r,$C,h5e,U8r,H8r,kZ,J8r,Y8r,K8r,kC,u5e,Z8r,e9r,SZ,o9r,r9r,t9r,SC,p5e,a9r,n9r,RZ,s9r,l9r,i9r,RC,_5e,d9r,c9r,PZ,f9r,m9r,g9r,PC,v5e,h9r,u9r,BZ,p9r,_9r,v9r,BC,b5e,b9r,F9r,IZ,T9r,M9r,E9r,IC,F5e,C9r,w9r,NZ,A9r,L9r,y9r,NC,T5e,x9r,$9r,qZ,k9r,S9r,R9r,qC,M5e,P9r,B9r,jZ,I9r,N9r,q9r,jC,E5e,j9r,D9r,DZ,G9r,O9r,V9r,DC,C5e,X9r,z9r,GZ,Q9r,W9r,U9r,GC,w5e,H9r,J9r,OZ,Y9r,K9r,Z9r,OC,A5e,exr,oxr,VZ,rxr,txr,axr,VC,L5e,nxr,sxr,XZ,lxr,ixr,dxr,XC,y5e,cxr,fxr,zZ,mxr,gxr,hxr,zC,x5e,uxr,pxr,QZ,_xr,vxr,bxr,QC,$5e,Fxr,Txr,WZ,Mxr,Exr,Cxr,WC,k5e,wxr,Axr,UZ,Lxr,yxr,xxr,UC,S5e,$xr,kxr,HZ,Sxr,Rxr,Pxr,HC,R5e,Bxr,Ixr,JZ,Nxr,qxr,jxr,JC,P5e,Dxr,Gxr,YZ,Oxr,Vxr,Xxr,YC,B5e,zxr,Qxr,KZ,Wxr,Uxr,Hxr,KC,I5e,Jxr,Yxr,ZZ,Kxr,Zxr,e$r,ZC,N5e,o$r,r$r,eee,t$r,a$r,n$r,e3,q5e,s$r,l$r,oee,i$r,d$r,c$r,o3,j5e,f$r,m$r,ree,g$r,h$r,u$r,r3,D5e,p$r,_$r,tee,v$r,b$r,F$r,t3,G5e,T$r,M$r,aee,E$r,C$r,w$r,a3,O5e,A$r,L$r,nee,y$r,x$r,$$r,n3,V5e,k$r,S$r,see,R$r,P$r,B$r,s3,XKe,Xc,l3,X5e,Ck,I$r,z5e,N$r,zKe,lr,wk,q$r,zc,j$r,lee,D$r,G$r,iee,O$r,V$r,X$r,Ak,z$r,Q5e,Q$r,W$r,U$r,zt,Lk,H$r,W5e,J$r,Y$r,Qc,K$r,U5e,Z$r,ekr,dee,okr,rkr,tkr,i3,akr,Nr,yk,nkr,H5e,skr,lkr,wn,ikr,J5e,dkr,ckr,Y5e,fkr,mkr,K5e,gkr,hkr,ukr,se,d3,Z5e,pkr,_kr,cee,vkr,bkr,Fkr,c3,ewe,Tkr,Mkr,fee,Ekr,Ckr,wkr,f3,owe,Akr,Lkr,mee,ykr,xkr,$kr,m3,rwe,kkr,Skr,gee,Rkr,Pkr,Bkr,g3,twe,Ikr,Nkr,hee,qkr,jkr,Dkr,h3,awe,Gkr,Okr,uee,Vkr,Xkr,zkr,u3,nwe,Qkr,Wkr,pee,Ukr,Hkr,Jkr,p3,swe,Ykr,Kkr,_ee,Zkr,eSr,oSr,_3,lwe,rSr,tSr,vee,aSr,nSr,sSr,v3,iwe,lSr,iSr,bee,dSr,cSr,fSr,b3,dwe,mSr,gSr,Fee,hSr,uSr,pSr,F3,cwe,_Sr,vSr,Tee,bSr,FSr,TSr,T3,fwe,MSr,ESr,Mee,CSr,wSr,ASr,M3,mwe,LSr,ySr,Eee,xSr,$Sr,kSr,E3,gwe,SSr,RSr,Cee,PSr,BSr,ISr,C3,hwe,NSr,qSr,wee,jSr,DSr,GSr,w3,uwe,OSr,VSr,Aee,XSr,zSr,QSr,A3,pwe,WSr,USr,Lee,HSr,JSr,YSr,L3,_we,KSr,ZSr,yee,eRr,oRr,rRr,y3,vwe,tRr,aRr,xee,nRr,sRr,lRr,x3,bwe,iRr,dRr,$ee,cRr,fRr,mRr,$3,Fwe,gRr,hRr,kee,uRr,pRr,_Rr,k3,Twe,vRr,bRr,See,FRr,TRr,MRr,S3,QKe,Wc,R3,Mwe,xk,ERr,Ewe,CRr,WKe,ir,$k,wRr,Uc,ARr,Ree,LRr,yRr,Pee,xRr,$Rr,kRr,kk,SRr,Cwe,RRr,PRr,BRr,Qt,Sk,IRr,wwe,NRr,qRr,Hc,jRr,Awe,DRr,GRr,Bee,ORr,VRr,XRr,P3,zRr,qr,Rk,QRr,Lwe,WRr,URr,An,HRr,ywe,JRr,YRr,xwe,KRr,ZRr,$we,ePr,oPr,rPr,Me,B3,kwe,tPr,aPr,Iee,nPr,sPr,lPr,I3,Swe,iPr,dPr,Nee,cPr,fPr,mPr,N3,Rwe,gPr,hPr,qee,uPr,pPr,_Pr,q3,Pwe,vPr,bPr,jee,FPr,TPr,MPr,j3,Bwe,EPr,CPr,Dee,wPr,APr,LPr,D3,Iwe,yPr,xPr,Gee,$Pr,kPr,SPr,G3,Nwe,RPr,PPr,Oee,BPr,IPr,NPr,O3,qwe,qPr,jPr,Vee,DPr,GPr,OPr,V3,jwe,VPr,XPr,Xee,zPr,QPr,WPr,X3,Dwe,UPr,HPr,zee,JPr,YPr,KPr,z3,Gwe,ZPr,eBr,Qee,oBr,rBr,tBr,Q3,Owe,aBr,nBr,Wee,sBr,lBr,iBr,W3,Vwe,dBr,cBr,Uee,fBr,mBr,gBr,U3,Xwe,hBr,uBr,Hee,pBr,_Br,vBr,H3,UKe,Jc,J3,zwe,Pk,bBr,Qwe,FBr,HKe,dr,Bk,TBr,Yc,MBr,Jee,EBr,CBr,Yee,wBr,ABr,LBr,Ik,yBr,Wwe,xBr,$Br,kBr,Wt,Nk,SBr,Uwe,RBr,PBr,Kc,BBr,Hwe,IBr,NBr,Kee,qBr,jBr,DBr,Y3,GBr,jr,qk,OBr,Jwe,VBr,XBr,Ln,zBr,Ywe,QBr,WBr,Kwe,UBr,HBr,Zwe,JBr,YBr,KBr,Be,K3,eAe,ZBr,eIr,Zee,oIr,rIr,tIr,Z3,oAe,aIr,nIr,eoe,sIr,lIr,iIr,Fl,rAe,dIr,cIr,ooe,fIr,mIr,roe,gIr,hIr,uIr,e5,tAe,pIr,_Ir,toe,vIr,bIr,FIr,o5,aAe,TIr,MIr,aoe,EIr,CIr,wIr,r5,nAe,AIr,LIr,noe,yIr,xIr,$Ir,t5,sAe,kIr,SIr,soe,RIr,PIr,BIr,a5,lAe,IIr,NIr,loe,qIr,jIr,DIr,n5,iAe,GIr,OIr,ioe,VIr,XIr,zIr,s5,JKe,Zc,l5,dAe,jk,QIr,cAe,WIr,YKe,cr,Dk,UIr,ef,HIr,doe,JIr,YIr,coe,KIr,ZIr,eNr,Gk,oNr,fAe,rNr,tNr,aNr,Ut,Ok,nNr,mAe,sNr,lNr,of,iNr,gAe,dNr,cNr,foe,fNr,mNr,gNr,i5,hNr,Dr,Vk,uNr,hAe,pNr,_Nr,yn,vNr,uAe,bNr,FNr,pAe,TNr,MNr,_Ae,ENr,CNr,wNr,rf,d5,vAe,ANr,LNr,moe,yNr,xNr,$Nr,c5,bAe,kNr,SNr,goe,RNr,PNr,BNr,f5,FAe,INr,NNr,hoe,qNr,jNr,DNr,m5,KKe,tf,g5,TAe,Xk,GNr,MAe,ONr,ZKe,fr,zk,VNr,af,XNr,uoe,zNr,QNr,poe,WNr,UNr,HNr,Qk,JNr,EAe,YNr,KNr,ZNr,Ht,Wk,eqr,CAe,oqr,rqr,nf,tqr,wAe,aqr,nqr,_oe,sqr,lqr,iqr,h5,dqr,Gr,Uk,cqr,AAe,fqr,mqr,xn,gqr,LAe,hqr,uqr,yAe,pqr,_qr,xAe,vqr,bqr,Fqr,me,u5,$Ae,Tqr,Mqr,voe,Eqr,Cqr,wqr,p5,kAe,Aqr,Lqr,boe,yqr,xqr,$qr,_5,SAe,kqr,Sqr,Foe,Rqr,Pqr,Bqr,v5,RAe,Iqr,Nqr,Toe,qqr,jqr,Dqr,b5,PAe,Gqr,Oqr,Moe,Vqr,Xqr,zqr,F5,BAe,Qqr,Wqr,Eoe,Uqr,Hqr,Jqr,T5,IAe,Yqr,Kqr,Coe,Zqr,ejr,ojr,M5,NAe,rjr,tjr,woe,ajr,njr,sjr,E5,qAe,ljr,ijr,Aoe,djr,cjr,fjr,C5,jAe,mjr,gjr,Loe,hjr,ujr,pjr,w5,DAe,_jr,vjr,yoe,bjr,Fjr,Tjr,A5,GAe,Mjr,Ejr,xoe,Cjr,wjr,Ajr,L5,OAe,Ljr,yjr,$oe,xjr,$jr,kjr,y5,VAe,Sjr,Rjr,koe,Pjr,Bjr,Ijr,x5,XAe,Njr,qjr,Soe,jjr,Djr,Gjr,$5,zAe,Ojr,Vjr,Roe,Xjr,zjr,Qjr,k5,QAe,Wjr,Ujr,Poe,Hjr,Jjr,Yjr,S5,WAe,Kjr,Zjr,Boe,eDr,oDr,rDr,R5,UAe,tDr,aDr,Ioe,nDr,sDr,lDr,P5,HAe,iDr,dDr,Noe,cDr,fDr,mDr,B5,eZe,sf,I5,JAe,Hk,gDr,YAe,hDr,oZe,mr,Jk,uDr,lf,pDr,qoe,_Dr,vDr,joe,bDr,FDr,TDr,Yk,MDr,KAe,EDr,CDr,wDr,Jt,Kk,ADr,ZAe,LDr,yDr,df,xDr,e6e,$Dr,kDr,Doe,SDr,RDr,PDr,N5,BDr,Or,Zk,IDr,o6e,NDr,qDr,$n,jDr,r6e,DDr,GDr,t6e,ODr,VDr,a6e,XDr,zDr,QDr,ye,q5,n6e,WDr,UDr,Goe,HDr,JDr,YDr,j5,s6e,KDr,ZDr,Ooe,eGr,oGr,rGr,D5,l6e,tGr,aGr,Voe,nGr,sGr,lGr,G5,i6e,iGr,dGr,Xoe,cGr,fGr,mGr,O5,d6e,gGr,hGr,zoe,uGr,pGr,_Gr,V5,c6e,vGr,bGr,Qoe,FGr,TGr,MGr,X5,f6e,EGr,CGr,Woe,wGr,AGr,LGr,z5,m6e,yGr,xGr,Uoe,$Gr,kGr,SGr,Q5,g6e,RGr,PGr,Hoe,BGr,IGr,NGr,W5,h6e,qGr,jGr,Joe,DGr,GGr,OGr,U5,rZe,cf,H5,u6e,eS,VGr,p6e,XGr,tZe,gr,oS,zGr,ff,QGr,Yoe,WGr,UGr,Koe,HGr,JGr,YGr,rS,KGr,_6e,ZGr,eOr,oOr,Yt,tS,rOr,v6e,tOr,aOr,mf,nOr,b6e,sOr,lOr,Zoe,iOr,dOr,cOr,J5,fOr,Vr,aS,mOr,F6e,gOr,hOr,kn,uOr,T6e,pOr,_Or,M6e,vOr,bOr,E6e,FOr,TOr,MOr,re,Y5,C6e,EOr,COr,ere,wOr,AOr,LOr,K5,w6e,yOr,xOr,ore,$Or,kOr,SOr,Z5,A6e,ROr,POr,rre,BOr,IOr,NOr,ew,L6e,qOr,jOr,tre,DOr,GOr,OOr,ow,y6e,VOr,XOr,are,zOr,QOr,WOr,rw,x6e,UOr,HOr,nre,JOr,YOr,KOr,tw,$6e,ZOr,eVr,sre,oVr,rVr,tVr,aw,k6e,aVr,nVr,lre,sVr,lVr,iVr,nw,S6e,dVr,cVr,ire,fVr,mVr,gVr,sw,R6e,hVr,uVr,dre,pVr,_Vr,vVr,lw,P6e,bVr,FVr,cre,TVr,MVr,EVr,iw,B6e,CVr,wVr,fre,AVr,LVr,yVr,dw,I6e,xVr,$Vr,mre,kVr,SVr,RVr,cw,N6e,PVr,BVr,gre,IVr,NVr,qVr,fw,q6e,jVr,DVr,hre,GVr,OVr,VVr,mw,j6e,XVr,zVr,ure,QVr,WVr,UVr,gw,D6e,HVr,JVr,pre,YVr,KVr,ZVr,hw,G6e,eXr,oXr,_re,rXr,tXr,aXr,uw,O6e,nXr,sXr,vre,lXr,iXr,dXr,pw,V6e,cXr,fXr,bre,mXr,gXr,hXr,_w,X6e,uXr,pXr,Fre,_Xr,vXr,bXr,vw,z6e,FXr,TXr,Tre,MXr,EXr,CXr,bw,Q6e,wXr,AXr,Mre,LXr,yXr,xXr,Fw,W6e,$Xr,kXr,Ere,SXr,RXr,PXr,Tw,U6e,BXr,IXr,Cre,NXr,qXr,jXr,Mw,H6e,DXr,GXr,wre,OXr,VXr,XXr,Ew,J6e,zXr,QXr,Are,WXr,UXr,HXr,Cw,aZe,gf,ww,Y6e,nS,JXr,K6e,YXr,nZe,hr,sS,KXr,hf,ZXr,Lre,ezr,ozr,yre,rzr,tzr,azr,lS,nzr,Z6e,szr,lzr,izr,Kt,iS,dzr,e7e,czr,fzr,uf,mzr,o7e,gzr,hzr,xre,uzr,pzr,_zr,Aw,vzr,Xr,dS,bzr,r7e,Fzr,Tzr,Sn,Mzr,t7e,Ezr,Czr,a7e,wzr,Azr,n7e,Lzr,yzr,xzr,be,Lw,s7e,$zr,kzr,$re,Szr,Rzr,Pzr,yw,l7e,Bzr,Izr,kre,Nzr,qzr,jzr,xw,i7e,Dzr,Gzr,Sre,Ozr,Vzr,Xzr,$w,d7e,zzr,Qzr,Rre,Wzr,Uzr,Hzr,kw,c7e,Jzr,Yzr,Pre,Kzr,Zzr,eQr,Sw,f7e,oQr,rQr,Bre,tQr,aQr,nQr,Rw,m7e,sQr,lQr,Ire,iQr,dQr,cQr,Pw,g7e,fQr,mQr,Nre,gQr,hQr,uQr,Bw,h7e,pQr,_Qr,qre,vQr,bQr,FQr,Iw,u7e,TQr,MQr,jre,EQr,CQr,wQr,Nw,p7e,AQr,LQr,Dre,yQr,xQr,$Qr,qw,_7e,kQr,SQr,Gre,RQr,PQr,BQr,jw,v7e,IQr,NQr,Ore,qQr,jQr,DQr,Dw,b7e,GQr,OQr,Vre,VQr,XQr,zQr,Gw,F7e,QQr,WQr,Xre,UQr,HQr,JQr,Ow,T7e,YQr,KQr,zre,ZQr,eWr,oWr,Vw,M7e,rWr,tWr,Qre,aWr,nWr,sWr,Xw,sZe,pf,zw,E7e,cS,lWr,C7e,iWr,lZe,ur,fS,dWr,_f,cWr,Wre,fWr,mWr,Ure,gWr,hWr,uWr,mS,pWr,w7e,_Wr,vWr,bWr,Zt,gS,FWr,A7e,TWr,MWr,vf,EWr,L7e,CWr,wWr,Hre,AWr,LWr,yWr,Qw,xWr,zr,hS,$Wr,y7e,kWr,SWr,Rn,RWr,x7e,PWr,BWr,$7e,IWr,NWr,k7e,qWr,jWr,DWr,uS,Ww,S7e,GWr,OWr,Jre,VWr,XWr,zWr,Uw,R7e,QWr,WWr,Yre,UWr,HWr,JWr,Hw,iZe,bf,Jw,P7e,pS,YWr,B7e,KWr,dZe,pr,_S,ZWr,Ff,eUr,Kre,oUr,rUr,Zre,tUr,aUr,nUr,vS,sUr,I7e,lUr,iUr,dUr,ea,bS,cUr,N7e,fUr,mUr,Tf,gUr,q7e,hUr,uUr,ete,pUr,_Ur,vUr,Yw,bUr,Qr,FS,FUr,j7e,TUr,MUr,Pn,EUr,D7e,CUr,wUr,G7e,AUr,LUr,O7e,yUr,xUr,$Ur,V7e,Kw,X7e,kUr,SUr,ote,RUr,PUr,BUr,Zw,cZe,Mf,eA,z7e,TS,IUr,Q7e,NUr,fZe,_r,MS,qUr,Ef,jUr,rte,DUr,GUr,tte,OUr,VUr,XUr,ES,zUr,W7e,QUr,WUr,UUr,oa,CS,HUr,U7e,JUr,YUr,Cf,KUr,H7e,ZUr,eHr,ate,oHr,rHr,tHr,oA,aHr,Wr,wS,nHr,J7e,sHr,lHr,Bn,iHr,Y7e,dHr,cHr,K7e,fHr,mHr,Z7e,gHr,hHr,uHr,eLe,rA,oLe,pHr,_Hr,nte,vHr,bHr,FHr,tA,mZe,wf,aA,rLe,AS,THr,tLe,MHr,gZe,vr,LS,EHr,Af,CHr,ste,wHr,AHr,lte,LHr,yHr,xHr,yS,$Hr,aLe,kHr,SHr,RHr,ra,xS,PHr,nLe,BHr,IHr,Lf,NHr,sLe,qHr,jHr,ite,DHr,GHr,OHr,nA,VHr,Ur,$S,XHr,lLe,zHr,QHr,In,WHr,iLe,UHr,HHr,dLe,JHr,YHr,cLe,KHr,ZHr,eJr,de,sA,fLe,oJr,rJr,dte,tJr,aJr,nJr,lA,mLe,sJr,lJr,cte,iJr,dJr,cJr,iA,gLe,fJr,mJr,fte,gJr,hJr,uJr,dA,hLe,pJr,_Jr,mte,vJr,bJr,FJr,cA,uLe,TJr,MJr,gte,EJr,CJr,wJr,fA,pLe,AJr,LJr,hte,yJr,xJr,$Jr,mA,_Le,kJr,SJr,ute,RJr,PJr,BJr,gA,vLe,IJr,NJr,pte,qJr,jJr,DJr,hA,bLe,GJr,OJr,_te,VJr,XJr,zJr,uA,FLe,QJr,WJr,vte,UJr,HJr,JJr,pA,TLe,YJr,KJr,bte,ZJr,eYr,oYr,_A,MLe,rYr,tYr,Fte,aYr,nYr,sYr,vA,ELe,lYr,iYr,Tte,dYr,cYr,fYr,bA,CLe,mYr,gYr,Mte,hYr,uYr,pYr,FA,wLe,_Yr,vYr,Ete,bYr,FYr,TYr,TA,ALe,MYr,EYr,Cte,CYr,wYr,AYr,MA,LLe,LYr,yYr,wte,xYr,$Yr,kYr,EA,yLe,SYr,RYr,Ate,PYr,BYr,IYr,CA,xLe,NYr,qYr,Lte,jYr,DYr,GYr,wA,$Le,OYr,VYr,yte,XYr,zYr,QYr,AA,kLe,WYr,UYr,xte,HYr,JYr,YYr,LA,hZe,yf,yA,SLe,kS,KYr,RLe,ZYr,uZe,br,SS,eKr,xf,oKr,$te,rKr,tKr,kte,aKr,nKr,sKr,RS,lKr,PLe,iKr,dKr,cKr,ta,PS,fKr,BLe,mKr,gKr,$f,hKr,ILe,uKr,pKr,Ste,_Kr,vKr,bKr,xA,FKr,Hr,BS,TKr,NLe,MKr,EKr,Nn,CKr,qLe,wKr,AKr,jLe,LKr,yKr,DLe,xKr,$Kr,kKr,ce,$A,GLe,SKr,RKr,Rte,PKr,BKr,IKr,kA,OLe,NKr,qKr,Pte,jKr,DKr,GKr,SA,VLe,OKr,VKr,Bte,XKr,zKr,QKr,RA,XLe,WKr,UKr,Ite,HKr,JKr,YKr,PA,zLe,KKr,ZKr,Nte,eZr,oZr,rZr,BA,QLe,tZr,aZr,qte,nZr,sZr,lZr,IA,WLe,iZr,dZr,jte,cZr,fZr,mZr,NA,ULe,gZr,hZr,Dte,uZr,pZr,_Zr,qA,HLe,vZr,bZr,Gte,FZr,TZr,MZr,jA,JLe,EZr,CZr,Ote,wZr,AZr,LZr,DA,YLe,yZr,xZr,Vte,$Zr,kZr,SZr,GA,KLe,RZr,PZr,Xte,BZr,IZr,NZr,OA,ZLe,qZr,jZr,zte,DZr,GZr,OZr,VA,eye,VZr,XZr,Qte,zZr,QZr,WZr,XA,oye,UZr,HZr,Wte,JZr,YZr,KZr,zA,rye,ZZr,eet,Ute,oet,ret,tet,QA,tye,aet,net,Hte,set,iet,det,WA,aye,cet,fet,Jte,met,get,het,UA,nye,uet,pet,Yte,_et,vet,bet,HA,sye,Fet,Tet,Kte,Met,Eet,Cet,JA,lye,wet,Aet,Zte,Let,yet,xet,YA,pZe,kf,KA,iye,IS,$et,dye,ket,_Ze,Fr,NS,Set,Sf,Ret,eae,Pet,Bet,oae,Iet,Net,qet,qS,jet,cye,Det,Get,Oet,aa,jS,Vet,fye,Xet,zet,Rf,Qet,mye,Wet,Uet,rae,Het,Jet,Yet,ZA,Ket,Jr,DS,Zet,gye,eot,oot,qn,rot,hye,tot,aot,uye,not,sot,pye,lot,iot,dot,_ye,e6,vye,cot,fot,tae,mot,got,hot,o6,vZe,Pf,r6,bye,GS,uot,Fye,pot,bZe,Tr,OS,_ot,Bf,vot,aae,bot,Fot,nae,Tot,Mot,Eot,VS,Cot,Tye,wot,Aot,Lot,na,XS,yot,Mye,xot,$ot,If,kot,Eye,Sot,Rot,sae,Pot,Bot,Iot,t6,Not,Yr,zS,qot,Cye,jot,Dot,jn,Got,wye,Oot,Vot,Aye,Xot,zot,Lye,Qot,Wot,Uot,yye,a6,xye,Hot,Jot,lae,Yot,Kot,Zot,n6,FZe,Nf,s6,$ye,QS,ert,kye,ort,TZe,Mr,WS,rrt,qf,trt,iae,art,nrt,dae,srt,lrt,irt,US,drt,Sye,crt,frt,mrt,sa,HS,grt,Rye,hrt,urt,jf,prt,Pye,_rt,vrt,cae,brt,Frt,Trt,l6,Mrt,Kr,JS,Ert,Bye,Crt,wrt,Dn,Art,Iye,Lrt,yrt,Nye,xrt,$rt,qye,krt,Srt,Rrt,te,i6,jye,Prt,Brt,fae,Irt,Nrt,qrt,d6,Dye,jrt,Drt,mae,Grt,Ort,Vrt,c6,Gye,Xrt,zrt,gae,Qrt,Wrt,Urt,f6,Oye,Hrt,Jrt,hae,Yrt,Krt,Zrt,m6,Vye,ett,ott,uae,rtt,ttt,att,g6,Xye,ntt,stt,pae,ltt,itt,dtt,h6,zye,ctt,ftt,_ae,mtt,gtt,htt,u6,Qye,utt,ptt,vae,_tt,vtt,btt,p6,Wye,Ftt,Ttt,bae,Mtt,Ett,Ctt,_6,Uye,wtt,Att,Fae,Ltt,ytt,xtt,v6,Hye,$tt,ktt,Tae,Stt,Rtt,Ptt,b6,Jye,Btt,Itt,Mae,Ntt,qtt,jtt,F6,Yye,Dtt,Gtt,Eae,Ott,Vtt,Xtt,T6,Kye,ztt,Qtt,Cae,Wtt,Utt,Htt,M6,Zye,Jtt,Ytt,wae,Ktt,Ztt,eat,E6,e8e,oat,rat,Aae,tat,aat,nat,C6,o8e,sat,lat,Lae,iat,dat,cat,w6,r8e,fat,mat,yae,gat,hat,uat,A6,t8e,pat,_at,xae,vat,bat,Fat,L6,a8e,Tat,Mat,$ae,Eat,Cat,wat,y6,n8e,Aat,Lat,kae,yat,xat,$at,x6,s8e,kat,Sat,Sae,Rat,Pat,Bat,$6,l8e,Iat,Nat,Rae,qat,jat,Dat,k6,i8e,Gat,Oat,Pae,Vat,Xat,zat,S6,d8e,Qat,Wat,Bae,Uat,Hat,Jat,R6,c8e,Yat,Kat,Iae,Zat,ent,ont,P6,f8e,rnt,tnt,Nae,ant,nnt,snt,B6,MZe,Df,I6,m8e,YS,lnt,g8e,int,EZe,Er,KS,dnt,Gf,cnt,qae,fnt,mnt,jae,gnt,hnt,unt,ZS,pnt,h8e,_nt,vnt,bnt,la,eR,Fnt,u8e,Tnt,Mnt,Of,Ent,p8e,Cnt,wnt,Dae,Ant,Lnt,ynt,N6,xnt,Zr,oR,$nt,_8e,knt,Snt,Gn,Rnt,v8e,Pnt,Bnt,b8e,Int,Nnt,F8e,qnt,jnt,Dnt,xe,q6,T8e,Gnt,Ont,Gae,Vnt,Xnt,znt,j6,M8e,Qnt,Wnt,Oae,Unt,Hnt,Jnt,D6,E8e,Ynt,Knt,Vae,Znt,est,ost,G6,C8e,rst,tst,Xae,ast,nst,sst,O6,w8e,lst,ist,zae,dst,cst,fst,V6,A8e,mst,gst,Qae,hst,ust,pst,X6,L8e,_st,vst,Wae,bst,Fst,Tst,z6,y8e,Mst,Est,Uae,Cst,wst,Ast,Q6,x8e,Lst,yst,Hae,xst,$st,kst,W6,$8e,Sst,Rst,Jae,Pst,Bst,Ist,U6,CZe,Vf,H6,k8e,rR,Nst,S8e,qst,wZe,Cr,tR,jst,Xf,Dst,Yae,Gst,Ost,Kae,Vst,Xst,zst,aR,Qst,R8e,Wst,Ust,Hst,ia,nR,Jst,P8e,Yst,Kst,zf,Zst,B8e,elt,olt,Zae,rlt,tlt,alt,J6,nlt,et,sR,slt,I8e,llt,ilt,On,dlt,N8e,clt,flt,q8e,mlt,glt,j8e,hlt,ult,plt,Ee,Y6,D8e,_lt,vlt,ene,blt,Flt,Tlt,K6,G8e,Mlt,Elt,one,Clt,wlt,Alt,Z6,O8e,Llt,ylt,rne,xlt,$lt,klt,e7,V8e,Slt,Rlt,tne,Plt,Blt,Ilt,o7,X8e,Nlt,qlt,ane,jlt,Dlt,Glt,r7,z8e,Olt,Vlt,nne,Xlt,zlt,Qlt,t7,Q8e,Wlt,Ult,sne,Hlt,Jlt,Ylt,a7,W8e,Klt,Zlt,lne,eit,oit,rit,n7,U8e,tit,ait,ine,nit,sit,lit,s7,H8e,iit,dit,dne,cit,fit,mit,l7,J8e,git,hit,cne,uit,pit,_it,i7,Y8e,vit,bit,fne,Fit,Tit,Mit,d7,K8e,Eit,Cit,mne,wit,Ait,Lit,c7,AZe,Qf,f7,Z8e,lR,yit,e9e,xit,LZe,wr,iR,$it,Wf,kit,gne,Sit,Rit,hne,Pit,Bit,Iit,dR,Nit,o9e,qit,jit,Dit,da,cR,Git,r9e,Oit,Vit,Uf,Xit,t9e,zit,Qit,une,Wit,Uit,Hit,m7,Jit,ot,fR,Yit,a9e,Kit,Zit,Vn,edt,n9e,odt,rdt,s9e,tdt,adt,l9e,ndt,sdt,ldt,$e,g7,i9e,idt,ddt,pne,cdt,fdt,mdt,h7,d9e,gdt,hdt,_ne,udt,pdt,_dt,u7,c9e,vdt,bdt,vne,Fdt,Tdt,Mdt,p7,f9e,Edt,Cdt,bne,wdt,Adt,Ldt,_7,m9e,ydt,xdt,Fne,$dt,kdt,Sdt,v7,g9e,Rdt,Pdt,Tne,Bdt,Idt,Ndt,b7,h9e,qdt,jdt,Mne,Ddt,Gdt,Odt,F7,u9e,Vdt,Xdt,Ene,zdt,Qdt,Wdt,T7,p9e,Udt,Hdt,Cne,Jdt,Ydt,Kdt,M7,_9e,Zdt,ect,wne,oct,rct,tct,E7,yZe,Hf,C7,v9e,mR,act,b9e,nct,xZe,Ar,gR,sct,Jf,lct,Ane,ict,dct,Lne,cct,fct,mct,hR,gct,F9e,hct,uct,pct,ca,uR,_ct,T9e,vct,bct,Yf,Fct,M9e,Tct,Mct,yne,Ect,Cct,wct,w7,Act,rt,pR,Lct,E9e,yct,xct,Xn,$ct,C9e,kct,Sct,w9e,Rct,Pct,A9e,Bct,Ict,Nct,ke,A7,L9e,qct,jct,xne,Dct,Gct,Oct,L7,y9e,Vct,Xct,$ne,zct,Qct,Wct,y7,x9e,Uct,Hct,kne,Jct,Yct,Kct,x7,$9e,Zct,eft,Sne,oft,rft,tft,$7,k9e,aft,nft,Rne,sft,lft,ift,k7,S9e,dft,cft,Pne,fft,mft,gft,S7,R9e,hft,uft,Bne,pft,_ft,vft,R7,P9e,bft,Fft,Ine,Tft,Mft,Eft,P7,B9e,Cft,wft,Nne,Aft,Lft,yft,B7,I9e,xft,$ft,qne,kft,Sft,Rft,I7,$Ze,Kf,N7,N9e,_R,Pft,q9e,Bft,kZe,Lr,vR,Ift,Zf,Nft,jne,qft,jft,Dne,Dft,Gft,Oft,bR,Vft,j9e,Xft,zft,Qft,fa,FR,Wft,D9e,Uft,Hft,em,Jft,G9e,Yft,Kft,Gne,Zft,emt,omt,q7,rmt,tt,TR,tmt,O9e,amt,nmt,zn,smt,V9e,lmt,imt,X9e,dmt,cmt,z9e,fmt,mmt,gmt,Se,j7,Q9e,hmt,umt,One,pmt,_mt,vmt,D7,W9e,bmt,Fmt,Vne,Tmt,Mmt,Emt,G7,U9e,Cmt,wmt,Xne,Amt,Lmt,ymt,O7,H9e,xmt,$mt,zne,kmt,Smt,Rmt,V7,J9e,Pmt,Bmt,Qne,Imt,Nmt,qmt,X7,Y9e,jmt,Dmt,Wne,Gmt,Omt,Vmt,z7,K9e,Xmt,zmt,Une,Qmt,Wmt,Umt,Q7,Z9e,Hmt,Jmt,Hne,Ymt,Kmt,Zmt,W7,exe,egt,ogt,Jne,rgt,tgt,agt,U7,oxe,ngt,sgt,Yne,lgt,igt,dgt,H7,SZe,om,J7,rxe,MR,cgt,txe,fgt,RZe,yr,ER,mgt,rm,ggt,Kne,hgt,ugt,Zne,pgt,_gt,vgt,CR,bgt,axe,Fgt,Tgt,Mgt,ma,wR,Egt,nxe,Cgt,wgt,tm,Agt,sxe,Lgt,ygt,ese,xgt,$gt,kgt,Y7,Sgt,at,AR,Rgt,lxe,Pgt,Bgt,Qn,Igt,ixe,Ngt,qgt,dxe,jgt,Dgt,cxe,Ggt,Ogt,Vgt,Re,K7,fxe,Xgt,zgt,ose,Qgt,Wgt,Ugt,Z7,mxe,Hgt,Jgt,rse,Ygt,Kgt,Zgt,eL,gxe,eht,oht,tse,rht,tht,aht,oL,hxe,nht,sht,ase,lht,iht,dht,rL,uxe,cht,fht,nse,mht,ght,hht,tL,pxe,uht,pht,sse,_ht,vht,bht,aL,_xe,Fht,Tht,lse,Mht,Eht,Cht,nL,vxe,wht,Aht,ise,Lht,yht,xht,sL,bxe,$ht,kht,dse,Sht,Rht,Pht,lL,Fxe,Bht,Iht,cse,Nht,qht,jht,iL,PZe,am,dL,Txe,LR,Dht,Mxe,Ght,BZe,xr,yR,Oht,nm,Vht,fse,Xht,zht,mse,Qht,Wht,Uht,xR,Hht,Exe,Jht,Yht,Kht,ga,$R,Zht,Cxe,eut,out,sm,rut,wxe,tut,aut,gse,nut,sut,lut,cL,iut,nt,kR,dut,Axe,cut,fut,Wn,mut,Lxe,gut,hut,yxe,uut,put,xxe,_ut,vut,but,Xe,fL,$xe,Fut,Tut,hse,Mut,Eut,Cut,mL,kxe,wut,Aut,use,Lut,yut,xut,gL,Sxe,$ut,kut,pse,Sut,Rut,Put,hL,Rxe,But,Iut,_se,Nut,qut,jut,uL,Pxe,Dut,Gut,vse,Out,Vut,Xut,pL,Bxe,zut,Qut,bse,Wut,Uut,Hut,_L,Ixe,Jut,Yut,Fse,Kut,Zut,ept,vL,Nxe,opt,rpt,Tse,tpt,apt,npt,bL,IZe,lm,FL,qxe,SR,spt,jxe,lpt,NZe,$r,RR,ipt,im,dpt,Mse,cpt,fpt,Ese,mpt,gpt,hpt,PR,upt,Dxe,ppt,_pt,vpt,ha,BR,bpt,Gxe,Fpt,Tpt,dm,Mpt,Oxe,Ept,Cpt,Cse,wpt,Apt,Lpt,TL,ypt,st,IR,xpt,Vxe,$pt,kpt,Un,Spt,Xxe,Rpt,Ppt,zxe,Bpt,Ipt,Qxe,Npt,qpt,jpt,ze,ML,Wxe,Dpt,Gpt,wse,Opt,Vpt,Xpt,EL,Uxe,zpt,Qpt,Ase,Wpt,Upt,Hpt,CL,Hxe,Jpt,Ypt,Lse,Kpt,Zpt,e_t,wL,Jxe,o_t,r_t,yse,t_t,a_t,n_t,AL,Yxe,s_t,l_t,xse,i_t,d_t,c_t,LL,Kxe,f_t,m_t,$se,g_t,h_t,u_t,yL,Zxe,p_t,__t,kse,v_t,b_t,F_t,xL,e$e,T_t,M_t,Sse,E_t,C_t,w_t,$L,qZe,cm,kL,o$e,NR,A_t,r$e,L_t,jZe,kr,qR,y_t,fm,x_t,Rse,$_t,k_t,Pse,S_t,R_t,P_t,jR,B_t,t$e,I_t,N_t,q_t,ua,DR,j_t,a$e,D_t,G_t,mm,O_t,n$e,V_t,X_t,Bse,z_t,Q_t,W_t,SL,U_t,lt,GR,H_t,s$e,J_t,Y_t,Hn,K_t,l$e,Z_t,e2t,i$e,o2t,r2t,d$e,t2t,a2t,n2t,c$e,RL,f$e,s2t,l2t,Ise,i2t,d2t,c2t,PL,DZe,gm,BL,m$e,OR,f2t,g$e,m2t,GZe,Sr,VR,g2t,hm,h2t,Nse,u2t,p2t,qse,_2t,v2t,b2t,XR,F2t,h$e,T2t,M2t,E2t,pa,zR,C2t,u$e,w2t,A2t,um,L2t,p$e,y2t,x2t,jse,$2t,k2t,S2t,IL,R2t,it,QR,P2t,_$e,B2t,I2t,Jn,N2t,v$e,q2t,j2t,b$e,D2t,G2t,F$e,O2t,V2t,X2t,WR,NL,T$e,z2t,Q2t,Dse,W2t,U2t,H2t,qL,M$e,J2t,Y2t,Gse,K2t,Z2t,evt,jL,OZe,pm,DL,E$e,UR,ovt,C$e,rvt,VZe,Rr,HR,tvt,_m,avt,Ose,nvt,svt,Vse,lvt,ivt,dvt,JR,cvt,w$e,fvt,mvt,gvt,_a,YR,hvt,A$e,uvt,pvt,vm,_vt,L$e,vvt,bvt,Xse,Fvt,Tvt,Mvt,GL,Evt,dt,KR,Cvt,y$e,wvt,Avt,Yn,Lvt,x$e,yvt,xvt,$$e,$vt,kvt,k$e,Svt,Rvt,Pvt,S$e,OL,R$e,Bvt,Ivt,zse,Nvt,qvt,jvt,VL,XZe;return d=new oe({}),Qa=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),E9=new oe({}),C9=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Lm=new Dvt({props:{warning:!0,$$slots:{default:[Gma]},$$scope:{ctx:$}}}),w9=new oe({}),A9=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/configuration_auto.py#L635"}}),x9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/configuration_auto.py#L658"}}),Qh=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[Oma]},$$scope:{ctx:$}}}),$9=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/configuration_auto.py#L781"}}),k9=new oe({}),S9=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/tokenization_auto.py#L426"}}),B9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/v4.22.0/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/tokenization_auto.py#L440"}}),yu=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[Vma]},$$scope:{ctx:$}}}),I9=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/tokenization_auto.py#L641"}}),N9=new oe({}),q9=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/feature_extraction_auto.py#L200"}}),G9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/v4.22.0/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/feature_extraction_auto.py#L214"}}),pp=new Dvt({props:{$$slots:{default:[Xma]},$$scope:{ctx:$}}}),_p=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[zma]},$$scope:{ctx:$}}}),O9=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/feature_extraction_auto.py#L341"}}),V9=new oe({}),X9=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/processing_auto.py#L92"}}),W9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/processing_auto.py#L106"}}),Gp=new Dvt({props:{$$slots:{default:[Qma]},$$scope:{ctx:$}}}),Op=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[Wma]},$$scope:{ctx:$}}}),U9=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/processing_auto.py#L259"}}),H9=new oe({}),J9=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L833"}}),K9=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),zp=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[Uma]},$$scope:{ctx:$}}}),Z9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),tv=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[Hma]},$$scope:{ctx:$}}}),ex=new oe({}),ox=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L840"}}),tx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),nv=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[Jma]},$$scope:{ctx:$}}}),ax=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),o4=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Yma]},$$scope:{ctx:$}}}),nx=new oe({}),sx=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L855"}}),ix=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),t4=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[Kma]},$$scope:{ctx:$}}}),dx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),Q4=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Zma]},$$scope:{ctx:$}}}),cx=new oe({}),fx=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L862"}}),gx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),U4=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[ega]},$$scope:{ctx:$}}}),hx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),Bb=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[oga]},$$scope:{ctx:$}}}),ux=new oe({}),px=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L869"}}),vx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),Nb=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[rga]},$$scope:{ctx:$}}}),bx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),n1=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[tga]},$$scope:{ctx:$}}}),Fx=new oe({}),Tx=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L878"}}),Ex=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),l1=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[aga]},$$scope:{ctx:$}}}),Cx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),i0=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[nga]},$$scope:{ctx:$}}}),wx=new oe({}),Ax=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L934"}}),yx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),c0=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[sga]},$$scope:{ctx:$}}}),xx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),X0=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[lga]},$$scope:{ctx:$}}}),$x=new oe({}),kx=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L941"}}),Rx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),Q0=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[iga]},$$scope:{ctx:$}}}),Px=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),oF=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[dga]},$$scope:{ctx:$}}}),Bx=new oe({}),Ix=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L927"}}),qx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),tF=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[cga]},$$scope:{ctx:$}}}),jx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),VF=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[fga]},$$scope:{ctx:$}}}),Dx=new oe({}),Gx=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L887"}}),Vx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),zF=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[mga]},$$scope:{ctx:$}}}),Xx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),NT=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[gga]},$$scope:{ctx:$}}}),zx=new oe({}),Qx=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L894"}}),Ux=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),jT=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[hga]},$$scope:{ctx:$}}}),Hx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),OT=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[uga]},$$scope:{ctx:$}}}),Jx=new oe({}),Yx=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L916"}}),Zx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),XT=new B({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[pga]},$$scope:{ctx:$}}}),e$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),HT=new B({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[_ga]},$$scope:{ctx:$}}}),o$=new oe({}),r$=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L950"}}),a$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/v4.22.0/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/v4.22.0/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),YT=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[vga]},$$scope:{ctx:$}}}),n$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),gM=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[bga]},$$scope:{ctx:$}}}),s$=new oe({}),l$=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L989"}}),d$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),uM=new B({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[Fga]},$$scope:{ctx:$}}}),c$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),vM=new B({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[Tga]},$$scope:{ctx:$}}}),f$=new oe({}),m$=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L996"}}),h$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),FM=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[Mga]},$$scope:{ctx:$}}}),u$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),EM=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Ega]},$$scope:{ctx:$}}}),p$=new oe({}),_$=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L905"}}),b$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),wM=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[Cga]},$$scope:{ctx:$}}}),F$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),yM=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[wga]},$$scope:{ctx:$}}}),T$=new oe({}),M$=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L1003"}}),C$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),$M=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[Aga]},$$scope:{ctx:$}}}),w$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),GM=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[Lga]},$$scope:{ctx:$}}}),A$=new oe({}),L$=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L1026"}}),x$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),VM=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[yga]},$$scope:{ctx:$}}}),$$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),JM=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[xga]},$$scope:{ctx:$}}}),k$=new oe({}),S$=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L1010"}}),P$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),KM=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[$ga]},$$scope:{ctx:$}}}),B$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),cE=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[kga]},$$scope:{ctx:$}}}),I$=new oe({}),N$=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L1017"}}),j$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),mE=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Sga]},$$scope:{ctx:$}}}),D$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),pE=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Rga]},$$scope:{ctx:$}}}),O$=new oe({}),V$=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L1035"}}),z$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),vE=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[Pga]},$$scope:{ctx:$}}}),Q$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),wE=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[Bga]},$$scope:{ctx:$}}}),W$=new oe({}),U$=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L1042"}}),J$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),LE=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[Iga]},$$scope:{ctx:$}}}),Y$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),RE=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[Nga]},$$scope:{ctx:$}}}),K$=new oe({}),Z$=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L982"}}),ok=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),BE=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[qga]},$$scope:{ctx:$}}}),rk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),jE=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[jga]},$$scope:{ctx:$}}}),ak=new oe({}),nk=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L957"}}),lk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),GE=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[Dga]},$$scope:{ctx:$}}}),ik=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),XE=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[Gga]},$$scope:{ctx:$}}}),dk=new oe({}),ck=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L964"}}),mk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),QE=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[Oga]},$$scope:{ctx:$}}}),gk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),ZE=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[Vga]},$$scope:{ctx:$}}}),hk=new oe({}),uk=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_auto.py#L973"}}),_k=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),oC=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[Xga]},$$scope:{ctx:$}}}),vk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),aC=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[zga]},$$scope:{ctx:$}}}),bk=new oe({}),Fk=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_tf_auto.py#L433"}}),Mk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),sC=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[Qga]},$$scope:{ctx:$}}}),Ek=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),s3=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[Wga]},$$scope:{ctx:$}}}),Ck=new oe({}),wk=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_tf_auto.py#L440"}}),Lk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),i3=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[Uga]},$$scope:{ctx:$}}}),yk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),S3=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Hga]},$$scope:{ctx:$}}}),xk=new oe({}),$k=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_tf_auto.py#L455"}}),Sk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),P3=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[Jga]},$$scope:{ctx:$}}}),Rk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),H3=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Yga]},$$scope:{ctx:$}}}),Pk=new oe({}),Bk=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_tf_auto.py#L471"}}),Nk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/v4.22.0/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),Y3=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[Kga]},$$scope:{ctx:$}}}),qk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),s5=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Zga]},$$scope:{ctx:$}}}),jk=new oe({}),Dk=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_tf_auto.py#L480"}}),Ok=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),i5=new B({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[eha]},$$scope:{ctx:$}}}),Vk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),m5=new B({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[oha]},$$scope:{ctx:$}}}),Xk=new oe({}),zk=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_tf_auto.py#L496"}}),Wk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),h5=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[rha]},$$scope:{ctx:$}}}),Uk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),B5=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[tha]},$$scope:{ctx:$}}}),Hk=new oe({}),Jk=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_tf_auto.py#L503"}}),Kk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),N5=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[aha]},$$scope:{ctx:$}}}),Zk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),U5=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[nha]},$$scope:{ctx:$}}}),eS=new oe({}),oS=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_tf_auto.py#L512"}}),tS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),J5=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[sha]},$$scope:{ctx:$}}}),aS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),Cw=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[lha]},$$scope:{ctx:$}}}),nS=new oe({}),sS=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_tf_auto.py#L559"}}),iS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),Aw=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[iha]},$$scope:{ctx:$}}}),dS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),Xw=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[dha]},$$scope:{ctx:$}}}),cS=new oe({}),fS=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_tf_auto.py#L566"}}),gS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),Qw=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[cha]},$$scope:{ctx:$}}}),hS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),Hw=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[fha]},$$scope:{ctx:$}}}),pS=new oe({}),_S=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_tf_auto.py#L539"}}),bS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),Yw=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[mha]},$$scope:{ctx:$}}}),FS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),Zw=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[gha]},$$scope:{ctx:$}}}),TS=new oe({}),MS=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_tf_auto.py#L528"}}),CS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),oA=new B({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[hha]},$$scope:{ctx:$}}}),wS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),tA=new B({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[uha]},$$scope:{ctx:$}}}),AS=new oe({}),LS=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_tf_auto.py#L550"}}),xS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),nA=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[pha]},$$scope:{ctx:$}}}),$S=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),LA=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[_ha]},$$scope:{ctx:$}}}),kS=new oe({}),SS=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_tf_auto.py#L521"}}),PS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),xA=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[vha]},$$scope:{ctx:$}}}),BS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),YA=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[bha]},$$scope:{ctx:$}}}),IS=new oe({}),NS=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_tf_auto.py#L489"}}),jS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),ZA=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[Fha]},$$scope:{ctx:$}}}),DS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),o6=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Tha]},$$scope:{ctx:$}}}),GS=new oe({}),OS=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_tf_auto.py#L575"}}),XS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),t6=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Mha]},$$scope:{ctx:$}}}),zS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),n6=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Eha]},$$scope:{ctx:$}}}),QS=new oe({}),WS=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),HS=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),l6=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[Cha]},$$scope:{ctx:$}}}),JS=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),B6=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[wha]},$$scope:{ctx:$}}}),YS=new oe({}),KS=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),eR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),N6=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[Aha]},$$scope:{ctx:$}}}),oR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),U6=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Lha]},$$scope:{ctx:$}}}),rR=new oe({}),tR=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),nR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),J6=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[yha]},$$scope:{ctx:$}}}),sR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),c7=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[xha]},$$scope:{ctx:$}}}),lR=new oe({}),iR=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),cR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),m7=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[$ha]},$$scope:{ctx:$}}}),fR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),E7=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[kha]},$$scope:{ctx:$}}}),mR=new oe({}),gR=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),uR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),w7=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Sha]},$$scope:{ctx:$}}}),pR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),I7=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Rha]},$$scope:{ctx:$}}}),_R=new oe({}),vR=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),FR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),q7=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Pha]},$$scope:{ctx:$}}}),TR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),H7=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Bha]},$$scope:{ctx:$}}}),MR=new oe({}),ER=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),wR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),Y7=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Iha]},$$scope:{ctx:$}}}),AR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),iL=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Nha]},$$scope:{ctx:$}}}),LR=new oe({}),yR=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),$R=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),cL=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[qha]},$$scope:{ctx:$}}}),kR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),bL=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[jha]},$$scope:{ctx:$}}}),SR=new oe({}),RR=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),BR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),TL=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Dha]},$$scope:{ctx:$}}}),IR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),$L=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Gha]},$$scope:{ctx:$}}}),NR=new oe({}),qR=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),DR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),SL=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Oha]},$$scope:{ctx:$}}}),GR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),PL=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Vha]},$$scope:{ctx:$}}}),OR=new oe({}),VR=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),zR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),IL=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[Xha]},$$scope:{ctx:$}}}),QR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),jL=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[zha]},$$scope:{ctx:$}}}),UR=new oe({}),HR=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),YR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.0/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.0/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L389"}}),GL=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[Qha]},$$scope:{ctx:$}}}),KR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/auto/auto_factory.py#L417"}}),VL=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Wha]},$$scope:{ctx:$}}}),{c(){g=a("meta"),b=l(),u=a("h1"),m=a("a"),p=a("span"),F(d.$$.fragment),h=l(),yo=a("span"),rd=o("Auto Classes"),Mm=l(),pt=a("p"),td=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ad=a("code"),b9=o("from_pretrained()"),Em=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Ve=l(),He=a("p"),nd=o("Instantiating one of "),Zn=a("a"),F9=o("AutoConfig"),es=o(", "),os=a("a"),T9=o("AutoModel"),sd=o(`, and
`),rs=a("a"),M9=o("AutoTokenizer"),ld=o(" will directly create a class of the relevant architecture. For instance"),Cm=l(),F(Qa.$$.fragment),Je=l(),Ae=a("p"),CB=o("will create a model that is an instance of "),id=a("a"),wB=o("BertModel"),AB=o("."),xo=l(),Wa=a("p"),LB=o("There is one class of "),wm=a("code"),yB=o("AutoModel"),iro=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),kYe=l(),dd=a("h2"),Am=a("a"),Hie=a("span"),F(E9.$$.fragment),dro=l(),Jie=a("span"),cro=o("Extending the Auto Classes"),SYe=l(),ts=a("p"),fro=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Yie=a("code"),mro=o("NewModel"),gro=o(", make sure you have a "),Kie=a("code"),hro=o("NewModelConfig"),uro=o(` then you can add those to the auto
classes like this:`),RYe=l(),F(C9.$$.fragment),PYe=l(),xB=a("p"),pro=o("You will then be able to use the auto classes like you would usually do!"),BYe=l(),F(Lm.$$.fragment),IYe=l(),cd=a("h2"),ym=a("a"),Zie=a("span"),F(w9.$$.fragment),_ro=l(),ede=a("span"),vro=o("AutoConfig"),NYe=l(),$o=a("div"),F(A9.$$.fragment),bro=l(),L9=a("p"),Fro=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),$B=a("a"),Tro=o("from_pretrained()"),Mro=o(" class method."),Ero=l(),y9=a("p"),Cro=o("This class cannot be instantiated directly using "),ode=a("code"),wro=o("__init__()"),Aro=o(" (throws an error)."),Lro=l(),Pr=a("div"),F(x9.$$.fragment),yro=l(),rde=a("p"),xro=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),$ro=l(),fd=a("p"),kro=o("The configuration class to instantiate is selected based on the "),tde=a("code"),Sro=o("model_type"),Rro=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),ade=a("code"),Pro=o("pretrained_model_name_or_path"),Bro=o(":"),Iro=l(),A=a("ul"),xm=a("li"),nde=a("strong"),Nro=o("albert"),qro=o(" \u2014 "),kB=a("a"),jro=o("AlbertConfig"),Dro=o(" (ALBERT model)"),Gro=l(),$m=a("li"),sde=a("strong"),Oro=o("bart"),Vro=o(" \u2014 "),SB=a("a"),Xro=o("BartConfig"),zro=o(" (BART model)"),Qro=l(),km=a("li"),lde=a("strong"),Wro=o("beit"),Uro=o(" \u2014 "),RB=a("a"),Hro=o("BeitConfig"),Jro=o(" (BEiT model)"),Yro=l(),Sm=a("li"),ide=a("strong"),Kro=o("bert"),Zro=o(" \u2014 "),PB=a("a"),eto=o("BertConfig"),oto=o(" (BERT model)"),rto=l(),Rm=a("li"),dde=a("strong"),tto=o("bert-generation"),ato=o(" \u2014 "),BB=a("a"),nto=o("BertGenerationConfig"),sto=o(" (Bert Generation model)"),lto=l(),Pm=a("li"),cde=a("strong"),ito=o("big_bird"),dto=o(" \u2014 "),IB=a("a"),cto=o("BigBirdConfig"),fto=o(" (BigBird model)"),mto=l(),Bm=a("li"),fde=a("strong"),gto=o("bigbird_pegasus"),hto=o(" \u2014 "),NB=a("a"),uto=o("BigBirdPegasusConfig"),pto=o(" (BigBird-Pegasus model)"),_to=l(),Im=a("li"),mde=a("strong"),vto=o("blenderbot"),bto=o(" \u2014 "),qB=a("a"),Fto=o("BlenderbotConfig"),Tto=o(" (Blenderbot model)"),Mto=l(),Nm=a("li"),gde=a("strong"),Eto=o("blenderbot-small"),Cto=o(" \u2014 "),jB=a("a"),wto=o("BlenderbotSmallConfig"),Ato=o(" (BlenderbotSmall model)"),Lto=l(),qm=a("li"),hde=a("strong"),yto=o("bloom"),xto=o(" \u2014 "),DB=a("a"),$to=o("BloomConfig"),kto=o(" (BLOOM model)"),Sto=l(),jm=a("li"),ude=a("strong"),Rto=o("camembert"),Pto=o(" \u2014 "),GB=a("a"),Bto=o("CamembertConfig"),Ito=o(" (CamemBERT model)"),Nto=l(),Dm=a("li"),pde=a("strong"),qto=o("canine"),jto=o(" \u2014 "),OB=a("a"),Dto=o("CanineConfig"),Gto=o(" (CANINE model)"),Oto=l(),Gm=a("li"),_de=a("strong"),Vto=o("clip"),Xto=o(" \u2014 "),VB=a("a"),zto=o("CLIPConfig"),Qto=o(" (CLIP model)"),Wto=l(),Om=a("li"),vde=a("strong"),Uto=o("codegen"),Hto=o(" \u2014 "),XB=a("a"),Jto=o("CodeGenConfig"),Yto=o(" (CodeGen model)"),Kto=l(),Vm=a("li"),bde=a("strong"),Zto=o("convbert"),eao=o(" \u2014 "),zB=a("a"),oao=o("ConvBertConfig"),rao=o(" (ConvBERT model)"),tao=l(),Xm=a("li"),Fde=a("strong"),aao=o("convnext"),nao=o(" \u2014 "),QB=a("a"),sao=o("ConvNextConfig"),lao=o(" (ConvNeXT model)"),iao=l(),zm=a("li"),Tde=a("strong"),dao=o("ctrl"),cao=o(" \u2014 "),WB=a("a"),fao=o("CTRLConfig"),mao=o(" (CTRL model)"),gao=l(),Qm=a("li"),Mde=a("strong"),hao=o("cvt"),uao=o(" \u2014 "),UB=a("a"),pao=o("CvtConfig"),_ao=o(" (CvT model)"),vao=l(),Wm=a("li"),Ede=a("strong"),bao=o("data2vec-audio"),Fao=o(" \u2014 "),HB=a("a"),Tao=o("Data2VecAudioConfig"),Mao=o(" (Data2VecAudio model)"),Eao=l(),Um=a("li"),Cde=a("strong"),Cao=o("data2vec-text"),wao=o(" \u2014 "),JB=a("a"),Aao=o("Data2VecTextConfig"),Lao=o(" (Data2VecText model)"),yao=l(),Hm=a("li"),wde=a("strong"),xao=o("data2vec-vision"),$ao=o(" \u2014 "),YB=a("a"),kao=o("Data2VecVisionConfig"),Sao=o(" (Data2VecVision model)"),Rao=l(),Jm=a("li"),Ade=a("strong"),Pao=o("deberta"),Bao=o(" \u2014 "),KB=a("a"),Iao=o("DebertaConfig"),Nao=o(" (DeBERTa model)"),qao=l(),Ym=a("li"),Lde=a("strong"),jao=o("deberta-v2"),Dao=o(" \u2014 "),ZB=a("a"),Gao=o("DebertaV2Config"),Oao=o(" (DeBERTa-v2 model)"),Vao=l(),Km=a("li"),yde=a("strong"),Xao=o("decision_transformer"),zao=o(" \u2014 "),eI=a("a"),Qao=o("DecisionTransformerConfig"),Wao=o(" (Decision Transformer model)"),Uao=l(),Zm=a("li"),xde=a("strong"),Hao=o("deit"),Jao=o(" \u2014 "),oI=a("a"),Yao=o("DeiTConfig"),Kao=o(" (DeiT model)"),Zao=l(),eg=a("li"),$de=a("strong"),eno=o("detr"),ono=o(" \u2014 "),rI=a("a"),rno=o("DetrConfig"),tno=o(" (DETR model)"),ano=l(),og=a("li"),kde=a("strong"),nno=o("distilbert"),sno=o(" \u2014 "),tI=a("a"),lno=o("DistilBertConfig"),ino=o(" (DistilBERT model)"),dno=l(),rg=a("li"),Sde=a("strong"),cno=o("donut-swin"),fno=o(" \u2014 "),aI=a("a"),mno=o("DonutSwinConfig"),gno=o(" (DonutSwin model)"),hno=l(),tg=a("li"),Rde=a("strong"),uno=o("dpr"),pno=o(" \u2014 "),nI=a("a"),_no=o("DPRConfig"),vno=o(" (DPR model)"),bno=l(),ag=a("li"),Pde=a("strong"),Fno=o("dpt"),Tno=o(" \u2014 "),sI=a("a"),Mno=o("DPTConfig"),Eno=o(" (DPT model)"),Cno=l(),ng=a("li"),Bde=a("strong"),wno=o("electra"),Ano=o(" \u2014 "),lI=a("a"),Lno=o("ElectraConfig"),yno=o(" (ELECTRA model)"),xno=l(),sg=a("li"),Ide=a("strong"),$no=o("encoder-decoder"),kno=o(" \u2014 "),iI=a("a"),Sno=o("EncoderDecoderConfig"),Rno=o(" (Encoder decoder model)"),Pno=l(),lg=a("li"),Nde=a("strong"),Bno=o("ernie"),Ino=o(" \u2014 "),dI=a("a"),Nno=o("ErnieConfig"),qno=o(" (ERNIE model)"),jno=l(),ig=a("li"),qde=a("strong"),Dno=o("flaubert"),Gno=o(" \u2014 "),cI=a("a"),Ono=o("FlaubertConfig"),Vno=o(" (FlauBERT model)"),Xno=l(),dg=a("li"),jde=a("strong"),zno=o("flava"),Qno=o(" \u2014 "),fI=a("a"),Wno=o("FlavaConfig"),Uno=o(" (FLAVA model)"),Hno=l(),cg=a("li"),Dde=a("strong"),Jno=o("fnet"),Yno=o(" \u2014 "),mI=a("a"),Kno=o("FNetConfig"),Zno=o(" (FNet model)"),eso=l(),fg=a("li"),Gde=a("strong"),oso=o("fsmt"),rso=o(" \u2014 "),gI=a("a"),tso=o("FSMTConfig"),aso=o(" (FairSeq Machine-Translation model)"),nso=l(),mg=a("li"),Ode=a("strong"),sso=o("funnel"),lso=o(" \u2014 "),hI=a("a"),iso=o("FunnelConfig"),dso=o(" (Funnel Transformer model)"),cso=l(),gg=a("li"),Vde=a("strong"),fso=o("glpn"),mso=o(" \u2014 "),uI=a("a"),gso=o("GLPNConfig"),hso=o(" (GLPN model)"),uso=l(),hg=a("li"),Xde=a("strong"),pso=o("gpt2"),_so=o(" \u2014 "),pI=a("a"),vso=o("GPT2Config"),bso=o(" (OpenAI GPT-2 model)"),Fso=l(),ug=a("li"),zde=a("strong"),Tso=o("gpt_neo"),Mso=o(" \u2014 "),_I=a("a"),Eso=o("GPTNeoConfig"),Cso=o(" (GPT Neo model)"),wso=l(),pg=a("li"),Qde=a("strong"),Aso=o("gpt_neox"),Lso=o(" \u2014 "),vI=a("a"),yso=o("GPTNeoXConfig"),xso=o(" (GPT NeoX model)"),$so=l(),_g=a("li"),Wde=a("strong"),kso=o("gptj"),Sso=o(" \u2014 "),bI=a("a"),Rso=o("GPTJConfig"),Pso=o(" (GPT-J model)"),Bso=l(),vg=a("li"),Ude=a("strong"),Iso=o("groupvit"),Nso=o(" \u2014 "),FI=a("a"),qso=o("GroupViTConfig"),jso=o(" (GroupViT model)"),Dso=l(),bg=a("li"),Hde=a("strong"),Gso=o("hubert"),Oso=o(" \u2014 "),TI=a("a"),Vso=o("HubertConfig"),Xso=o(" (Hubert model)"),zso=l(),Fg=a("li"),Jde=a("strong"),Qso=o("ibert"),Wso=o(" \u2014 "),MI=a("a"),Uso=o("IBertConfig"),Hso=o(" (I-BERT model)"),Jso=l(),Tg=a("li"),Yde=a("strong"),Yso=o("imagegpt"),Kso=o(" \u2014 "),EI=a("a"),Zso=o("ImageGPTConfig"),elo=o(" (ImageGPT model)"),olo=l(),Mg=a("li"),Kde=a("strong"),rlo=o("layoutlm"),tlo=o(" \u2014 "),CI=a("a"),alo=o("LayoutLMConfig"),nlo=o(" (LayoutLM model)"),slo=l(),Eg=a("li"),Zde=a("strong"),llo=o("layoutlmv2"),ilo=o(" \u2014 "),wI=a("a"),dlo=o("LayoutLMv2Config"),clo=o(" (LayoutLMv2 model)"),flo=l(),Cg=a("li"),ece=a("strong"),mlo=o("layoutlmv3"),glo=o(" \u2014 "),AI=a("a"),hlo=o("LayoutLMv3Config"),ulo=o(" (LayoutLMv3 model)"),plo=l(),wg=a("li"),oce=a("strong"),_lo=o("led"),vlo=o(" \u2014 "),LI=a("a"),blo=o("LEDConfig"),Flo=o(" (LED model)"),Tlo=l(),Ag=a("li"),rce=a("strong"),Mlo=o("levit"),Elo=o(" \u2014 "),yI=a("a"),Clo=o("LevitConfig"),wlo=o(" (LeViT model)"),Alo=l(),Lg=a("li"),tce=a("strong"),Llo=o("longformer"),ylo=o(" \u2014 "),xI=a("a"),xlo=o("LongformerConfig"),$lo=o(" (Longformer model)"),klo=l(),yg=a("li"),ace=a("strong"),Slo=o("longt5"),Rlo=o(" \u2014 "),$I=a("a"),Plo=o("LongT5Config"),Blo=o(" (LongT5 model)"),Ilo=l(),xg=a("li"),nce=a("strong"),Nlo=o("luke"),qlo=o(" \u2014 "),kI=a("a"),jlo=o("LukeConfig"),Dlo=o(" (LUKE model)"),Glo=l(),$g=a("li"),sce=a("strong"),Olo=o("lxmert"),Vlo=o(" \u2014 "),SI=a("a"),Xlo=o("LxmertConfig"),zlo=o(" (LXMERT model)"),Qlo=l(),kg=a("li"),lce=a("strong"),Wlo=o("m2m_100"),Ulo=o(" \u2014 "),RI=a("a"),Hlo=o("M2M100Config"),Jlo=o(" (M2M100 model)"),Ylo=l(),Sg=a("li"),ice=a("strong"),Klo=o("marian"),Zlo=o(" \u2014 "),PI=a("a"),eio=o("MarianConfig"),oio=o(" (Marian model)"),rio=l(),Rg=a("li"),dce=a("strong"),tio=o("maskformer"),aio=o(" \u2014 "),BI=a("a"),nio=o("MaskFormerConfig"),sio=o(" (MaskFormer model)"),lio=l(),Pg=a("li"),cce=a("strong"),iio=o("mbart"),dio=o(" \u2014 "),II=a("a"),cio=o("MBartConfig"),fio=o(" (mBART model)"),mio=l(),Bg=a("li"),fce=a("strong"),gio=o("mctct"),hio=o(" \u2014 "),NI=a("a"),uio=o("MCTCTConfig"),pio=o(" (M-CTC-T model)"),_io=l(),Ig=a("li"),mce=a("strong"),vio=o("megatron-bert"),bio=o(" \u2014 "),qI=a("a"),Fio=o("MegatronBertConfig"),Tio=o(" (Megatron-BERT model)"),Mio=l(),Ng=a("li"),gce=a("strong"),Eio=o("mobilebert"),Cio=o(" \u2014 "),jI=a("a"),wio=o("MobileBertConfig"),Aio=o(" (MobileBERT model)"),Lio=l(),qg=a("li"),hce=a("strong"),yio=o("mobilevit"),xio=o(" \u2014 "),DI=a("a"),$io=o("MobileViTConfig"),kio=o(" (MobileViT model)"),Sio=l(),jg=a("li"),uce=a("strong"),Rio=o("mpnet"),Pio=o(" \u2014 "),GI=a("a"),Bio=o("MPNetConfig"),Iio=o(" (MPNet model)"),Nio=l(),Dg=a("li"),pce=a("strong"),qio=o("mt5"),jio=o(" \u2014 "),OI=a("a"),Dio=o("MT5Config"),Gio=o(" (MT5 model)"),Oio=l(),Gg=a("li"),_ce=a("strong"),Vio=o("mvp"),Xio=o(" \u2014 "),VI=a("a"),zio=o("MvpConfig"),Qio=o(" (MVP model)"),Wio=l(),Og=a("li"),vce=a("strong"),Uio=o("nezha"),Hio=o(" \u2014 "),XI=a("a"),Jio=o("NezhaConfig"),Yio=o(" (Nezha model)"),Kio=l(),Vg=a("li"),bce=a("strong"),Zio=o("nystromformer"),edo=o(" \u2014 "),zI=a("a"),odo=o("NystromformerConfig"),rdo=o(" (Nystr\xF6mformer model)"),tdo=l(),Xg=a("li"),Fce=a("strong"),ado=o("openai-gpt"),ndo=o(" \u2014 "),QI=a("a"),sdo=o("OpenAIGPTConfig"),ldo=o(" (OpenAI GPT model)"),ido=l(),zg=a("li"),Tce=a("strong"),ddo=o("opt"),cdo=o(" \u2014 "),WI=a("a"),fdo=o("OPTConfig"),mdo=o(" (OPT model)"),gdo=l(),Qg=a("li"),Mce=a("strong"),hdo=o("owlvit"),udo=o(" \u2014 "),UI=a("a"),pdo=o("OwlViTConfig"),_do=o(" (OWL-ViT model)"),vdo=l(),Wg=a("li"),Ece=a("strong"),bdo=o("pegasus"),Fdo=o(" \u2014 "),HI=a("a"),Tdo=o("PegasusConfig"),Mdo=o(" (Pegasus model)"),Edo=l(),Ug=a("li"),Cce=a("strong"),Cdo=o("pegasus_x"),wdo=o(" \u2014 "),JI=a("a"),Ado=o("PegasusXConfig"),Ldo=o(" (PEGASUS-X model)"),ydo=l(),Hg=a("li"),wce=a("strong"),xdo=o("perceiver"),$do=o(" \u2014 "),YI=a("a"),kdo=o("PerceiverConfig"),Sdo=o(" (Perceiver model)"),Rdo=l(),Jg=a("li"),Ace=a("strong"),Pdo=o("plbart"),Bdo=o(" \u2014 "),KI=a("a"),Ido=o("PLBartConfig"),Ndo=o(" (PLBart model)"),qdo=l(),Yg=a("li"),Lce=a("strong"),jdo=o("poolformer"),Ddo=o(" \u2014 "),ZI=a("a"),Gdo=o("PoolFormerConfig"),Odo=o(" (PoolFormer model)"),Vdo=l(),Kg=a("li"),yce=a("strong"),Xdo=o("prophetnet"),zdo=o(" \u2014 "),eN=a("a"),Qdo=o("ProphetNetConfig"),Wdo=o(" (ProphetNet model)"),Udo=l(),Zg=a("li"),xce=a("strong"),Hdo=o("qdqbert"),Jdo=o(" \u2014 "),oN=a("a"),Ydo=o("QDQBertConfig"),Kdo=o(" (QDQBert model)"),Zdo=l(),eh=a("li"),$ce=a("strong"),eco=o("rag"),oco=o(" \u2014 "),rN=a("a"),rco=o("RagConfig"),tco=o(" (RAG model)"),aco=l(),oh=a("li"),kce=a("strong"),nco=o("realm"),sco=o(" \u2014 "),tN=a("a"),lco=o("RealmConfig"),ico=o(" (REALM model)"),dco=l(),rh=a("li"),Sce=a("strong"),cco=o("reformer"),fco=o(" \u2014 "),aN=a("a"),mco=o("ReformerConfig"),gco=o(" (Reformer model)"),hco=l(),th=a("li"),Rce=a("strong"),uco=o("regnet"),pco=o(" \u2014 "),nN=a("a"),_co=o("RegNetConfig"),vco=o(" (RegNet model)"),bco=l(),ah=a("li"),Pce=a("strong"),Fco=o("rembert"),Tco=o(" \u2014 "),sN=a("a"),Mco=o("RemBertConfig"),Eco=o(" (RemBERT model)"),Cco=l(),nh=a("li"),Bce=a("strong"),wco=o("resnet"),Aco=o(" \u2014 "),lN=a("a"),Lco=o("ResNetConfig"),yco=o(" (ResNet model)"),xco=l(),sh=a("li"),Ice=a("strong"),$co=o("retribert"),kco=o(" \u2014 "),iN=a("a"),Sco=o("RetriBertConfig"),Rco=o(" (RetriBERT model)"),Pco=l(),lh=a("li"),Nce=a("strong"),Bco=o("roberta"),Ico=o(" \u2014 "),dN=a("a"),Nco=o("RobertaConfig"),qco=o(" (RoBERTa model)"),jco=l(),ih=a("li"),qce=a("strong"),Dco=o("roformer"),Gco=o(" \u2014 "),cN=a("a"),Oco=o("RoFormerConfig"),Vco=o(" (RoFormer model)"),Xco=l(),dh=a("li"),jce=a("strong"),zco=o("segformer"),Qco=o(" \u2014 "),fN=a("a"),Wco=o("SegformerConfig"),Uco=o(" (SegFormer model)"),Hco=l(),ch=a("li"),Dce=a("strong"),Jco=o("sew"),Yco=o(" \u2014 "),mN=a("a"),Kco=o("SEWConfig"),Zco=o(" (SEW model)"),efo=l(),fh=a("li"),Gce=a("strong"),ofo=o("sew-d"),rfo=o(" \u2014 "),gN=a("a"),tfo=o("SEWDConfig"),afo=o(" (SEW-D model)"),nfo=l(),mh=a("li"),Oce=a("strong"),sfo=o("speech-encoder-decoder"),lfo=o(" \u2014 "),hN=a("a"),ifo=o("SpeechEncoderDecoderConfig"),dfo=o(" (Speech Encoder decoder model)"),cfo=l(),gh=a("li"),Vce=a("strong"),ffo=o("speech_to_text"),mfo=o(" \u2014 "),uN=a("a"),gfo=o("Speech2TextConfig"),hfo=o(" (Speech2Text model)"),ufo=l(),hh=a("li"),Xce=a("strong"),pfo=o("speech_to_text_2"),_fo=o(" \u2014 "),pN=a("a"),vfo=o("Speech2Text2Config"),bfo=o(" (Speech2Text2 model)"),Ffo=l(),uh=a("li"),zce=a("strong"),Tfo=o("splinter"),Mfo=o(" \u2014 "),_N=a("a"),Efo=o("SplinterConfig"),Cfo=o(" (Splinter model)"),wfo=l(),ph=a("li"),Qce=a("strong"),Afo=o("squeezebert"),Lfo=o(" \u2014 "),vN=a("a"),yfo=o("SqueezeBertConfig"),xfo=o(" (SqueezeBERT model)"),$fo=l(),_h=a("li"),Wce=a("strong"),kfo=o("swin"),Sfo=o(" \u2014 "),bN=a("a"),Rfo=o("SwinConfig"),Pfo=o(" (Swin Transformer model)"),Bfo=l(),vh=a("li"),Uce=a("strong"),Ifo=o("swinv2"),Nfo=o(" \u2014 "),FN=a("a"),qfo=o("Swinv2Config"),jfo=o(" (Swin Transformer V2 model)"),Dfo=l(),bh=a("li"),Hce=a("strong"),Gfo=o("t5"),Ofo=o(" \u2014 "),TN=a("a"),Vfo=o("T5Config"),Xfo=o(" (T5 model)"),zfo=l(),Fh=a("li"),Jce=a("strong"),Qfo=o("tapas"),Wfo=o(" \u2014 "),MN=a("a"),Ufo=o("TapasConfig"),Hfo=o(" (TAPAS model)"),Jfo=l(),Th=a("li"),Yce=a("strong"),Yfo=o("trajectory_transformer"),Kfo=o(" \u2014 "),EN=a("a"),Zfo=o("TrajectoryTransformerConfig"),emo=o(" (Trajectory Transformer model)"),omo=l(),Mh=a("li"),Kce=a("strong"),rmo=o("transfo-xl"),tmo=o(" \u2014 "),CN=a("a"),amo=o("TransfoXLConfig"),nmo=o(" (Transformer-XL model)"),smo=l(),Eh=a("li"),Zce=a("strong"),lmo=o("trocr"),imo=o(" \u2014 "),wN=a("a"),dmo=o("TrOCRConfig"),cmo=o(" (TrOCR model)"),fmo=l(),Ch=a("li"),efe=a("strong"),mmo=o("unispeech"),gmo=o(" \u2014 "),AN=a("a"),hmo=o("UniSpeechConfig"),umo=o(" (UniSpeech model)"),pmo=l(),wh=a("li"),ofe=a("strong"),_mo=o("unispeech-sat"),vmo=o(" \u2014 "),LN=a("a"),bmo=o("UniSpeechSatConfig"),Fmo=o(" (UniSpeechSat model)"),Tmo=l(),Ah=a("li"),rfe=a("strong"),Mmo=o("van"),Emo=o(" \u2014 "),yN=a("a"),Cmo=o("VanConfig"),wmo=o(" (VAN model)"),Amo=l(),Lh=a("li"),tfe=a("strong"),Lmo=o("videomae"),ymo=o(" \u2014 "),xN=a("a"),xmo=o("VideoMAEConfig"),$mo=o(" (VideoMAE model)"),kmo=l(),yh=a("li"),afe=a("strong"),Smo=o("vilt"),Rmo=o(" \u2014 "),$N=a("a"),Pmo=o("ViltConfig"),Bmo=o(" (ViLT model)"),Imo=l(),xh=a("li"),nfe=a("strong"),Nmo=o("vision-encoder-decoder"),qmo=o(" \u2014 "),kN=a("a"),jmo=o("VisionEncoderDecoderConfig"),Dmo=o(" (Vision Encoder decoder model)"),Gmo=l(),$h=a("li"),sfe=a("strong"),Omo=o("vision-text-dual-encoder"),Vmo=o(" \u2014 "),SN=a("a"),Xmo=o("VisionTextDualEncoderConfig"),zmo=o(" (VisionTextDualEncoder model)"),Qmo=l(),kh=a("li"),lfe=a("strong"),Wmo=o("visual_bert"),Umo=o(" \u2014 "),RN=a("a"),Hmo=o("VisualBertConfig"),Jmo=o(" (VisualBERT model)"),Ymo=l(),Sh=a("li"),ife=a("strong"),Kmo=o("vit"),Zmo=o(" \u2014 "),PN=a("a"),ego=o("ViTConfig"),ogo=o(" (ViT model)"),rgo=l(),Rh=a("li"),dfe=a("strong"),tgo=o("vit_mae"),ago=o(" \u2014 "),BN=a("a"),ngo=o("ViTMAEConfig"),sgo=o(" (ViTMAE model)"),lgo=l(),Ph=a("li"),cfe=a("strong"),igo=o("wav2vec2"),dgo=o(" \u2014 "),IN=a("a"),cgo=o("Wav2Vec2Config"),fgo=o(" (Wav2Vec2 model)"),mgo=l(),Bh=a("li"),ffe=a("strong"),ggo=o("wav2vec2-conformer"),hgo=o(" \u2014 "),NN=a("a"),ugo=o("Wav2Vec2ConformerConfig"),pgo=o(" (Wav2Vec2-Conformer model)"),_go=l(),Ih=a("li"),mfe=a("strong"),vgo=o("wavlm"),bgo=o(" \u2014 "),qN=a("a"),Fgo=o("WavLMConfig"),Tgo=o(" (WavLM model)"),Mgo=l(),Nh=a("li"),gfe=a("strong"),Ego=o("xclip"),Cgo=o(" \u2014 "),jN=a("a"),wgo=o("XCLIPConfig"),Ago=o(" (X-CLIP model)"),Lgo=l(),qh=a("li"),hfe=a("strong"),ygo=o("xglm"),xgo=o(" \u2014 "),DN=a("a"),$go=o("XGLMConfig"),kgo=o(" (XGLM model)"),Sgo=l(),jh=a("li"),ufe=a("strong"),Rgo=o("xlm"),Pgo=o(" \u2014 "),GN=a("a"),Bgo=o("XLMConfig"),Igo=o(" (XLM model)"),Ngo=l(),Dh=a("li"),pfe=a("strong"),qgo=o("xlm-prophetnet"),jgo=o(" \u2014 "),ON=a("a"),Dgo=o("XLMProphetNetConfig"),Ggo=o(" (XLM-ProphetNet model)"),Ogo=l(),Gh=a("li"),_fe=a("strong"),Vgo=o("xlm-roberta"),Xgo=o(" \u2014 "),VN=a("a"),zgo=o("XLMRobertaConfig"),Qgo=o(" (XLM-RoBERTa model)"),Wgo=l(),Oh=a("li"),vfe=a("strong"),Ugo=o("xlm-roberta-xl"),Hgo=o(" \u2014 "),XN=a("a"),Jgo=o("XLMRobertaXLConfig"),Ygo=o(" (XLM-RoBERTa-XL model)"),Kgo=l(),Vh=a("li"),bfe=a("strong"),Zgo=o("xlnet"),eho=o(" \u2014 "),zN=a("a"),oho=o("XLNetConfig"),rho=o(" (XLNet model)"),tho=l(),Xh=a("li"),Ffe=a("strong"),aho=o("yolos"),nho=o(" \u2014 "),QN=a("a"),sho=o("YolosConfig"),lho=o(" (YOLOS model)"),iho=l(),zh=a("li"),Tfe=a("strong"),dho=o("yoso"),cho=o(" \u2014 "),WN=a("a"),fho=o("YosoConfig"),mho=o(" (YOSO model)"),gho=l(),F(Qh.$$.fragment),hho=l(),Wh=a("div"),F($9.$$.fragment),uho=l(),Mfe=a("p"),pho=o("Register a new configuration for this class."),qYe=l(),md=a("h2"),Uh=a("a"),Efe=a("span"),F(k9.$$.fragment),_ho=l(),Cfe=a("span"),vho=o("AutoTokenizer"),jYe=l(),ko=a("div"),F(S9.$$.fragment),bho=l(),R9=a("p"),Fho=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),UN=a("a"),Tho=o("AutoTokenizer.from_pretrained()"),Mho=o(" class method."),Eho=l(),P9=a("p"),Cho=o("This class cannot be instantiated directly using "),wfe=a("code"),who=o("__init__()"),Aho=o(" (throws an error)."),Lho=l(),Br=a("div"),F(B9.$$.fragment),yho=l(),Afe=a("p"),xho=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),$ho=l(),Ua=a("p"),kho=o("The tokenizer class to instantiate is selected based on the "),Lfe=a("code"),Sho=o("model_type"),Rho=o(` property of the config object (either
passed as an argument or loaded from `),yfe=a("code"),Pho=o("pretrained_model_name_or_path"),Bho=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xfe=a("code"),Iho=o("pretrained_model_name_or_path"),Nho=o(":"),qho=l(),k=a("ul"),as=a("li"),$fe=a("strong"),jho=o("albert"),Dho=o(" \u2014 "),HN=a("a"),Gho=o("AlbertTokenizer"),Oho=o(" or "),JN=a("a"),Vho=o("AlbertTokenizerFast"),Xho=o(" (ALBERT model)"),zho=l(),ns=a("li"),kfe=a("strong"),Qho=o("bart"),Who=o(" \u2014 "),YN=a("a"),Uho=o("BartTokenizer"),Hho=o(" or "),KN=a("a"),Jho=o("BartTokenizerFast"),Yho=o(" (BART model)"),Kho=l(),ss=a("li"),Sfe=a("strong"),Zho=o("barthez"),euo=o(" \u2014 "),ZN=a("a"),ouo=o("BarthezTokenizer"),ruo=o(" or "),eq=a("a"),tuo=o("BarthezTokenizerFast"),auo=o(" (BARThez model)"),nuo=l(),Hh=a("li"),Rfe=a("strong"),suo=o("bartpho"),luo=o(" \u2014 "),oq=a("a"),iuo=o("BartphoTokenizer"),duo=o(" (BARTpho model)"),cuo=l(),ls=a("li"),Pfe=a("strong"),fuo=o("bert"),muo=o(" \u2014 "),rq=a("a"),guo=o("BertTokenizer"),huo=o(" or "),tq=a("a"),uuo=o("BertTokenizerFast"),puo=o(" (BERT model)"),_uo=l(),Jh=a("li"),Bfe=a("strong"),vuo=o("bert-generation"),buo=o(" \u2014 "),aq=a("a"),Fuo=o("BertGenerationTokenizer"),Tuo=o(" (Bert Generation model)"),Muo=l(),Yh=a("li"),Ife=a("strong"),Euo=o("bert-japanese"),Cuo=o(" \u2014 "),nq=a("a"),wuo=o("BertJapaneseTokenizer"),Auo=o(" (BertJapanese model)"),Luo=l(),Kh=a("li"),Nfe=a("strong"),yuo=o("bertweet"),xuo=o(" \u2014 "),sq=a("a"),$uo=o("BertweetTokenizer"),kuo=o(" (BERTweet model)"),Suo=l(),is=a("li"),qfe=a("strong"),Ruo=o("big_bird"),Puo=o(" \u2014 "),lq=a("a"),Buo=o("BigBirdTokenizer"),Iuo=o(" or "),iq=a("a"),Nuo=o("BigBirdTokenizerFast"),quo=o(" (BigBird model)"),juo=l(),ds=a("li"),jfe=a("strong"),Duo=o("bigbird_pegasus"),Guo=o(" \u2014 "),dq=a("a"),Ouo=o("PegasusTokenizer"),Vuo=o(" or "),cq=a("a"),Xuo=o("PegasusTokenizerFast"),zuo=o(" (BigBird-Pegasus model)"),Quo=l(),cs=a("li"),Dfe=a("strong"),Wuo=o("blenderbot"),Uuo=o(" \u2014 "),fq=a("a"),Huo=o("BlenderbotTokenizer"),Juo=o(" or "),mq=a("a"),Yuo=o("BlenderbotTokenizerFast"),Kuo=o(" (Blenderbot model)"),Zuo=l(),Zh=a("li"),Gfe=a("strong"),epo=o("blenderbot-small"),opo=o(" \u2014 "),gq=a("a"),rpo=o("BlenderbotSmallTokenizer"),tpo=o(" (BlenderbotSmall model)"),apo=l(),eu=a("li"),Ofe=a("strong"),npo=o("bloom"),spo=o(" \u2014 "),hq=a("a"),lpo=o("BloomTokenizerFast"),ipo=o(" (BLOOM model)"),dpo=l(),ou=a("li"),Vfe=a("strong"),cpo=o("byt5"),fpo=o(" \u2014 "),uq=a("a"),mpo=o("ByT5Tokenizer"),gpo=o(" (ByT5 model)"),hpo=l(),fs=a("li"),Xfe=a("strong"),upo=o("camembert"),ppo=o(" \u2014 "),pq=a("a"),_po=o("CamembertTokenizer"),vpo=o(" or "),_q=a("a"),bpo=o("CamembertTokenizerFast"),Fpo=o(" (CamemBERT model)"),Tpo=l(),ru=a("li"),zfe=a("strong"),Mpo=o("canine"),Epo=o(" \u2014 "),vq=a("a"),Cpo=o("CanineTokenizer"),wpo=o(" (CANINE model)"),Apo=l(),ms=a("li"),Qfe=a("strong"),Lpo=o("clip"),ypo=o(" \u2014 "),bq=a("a"),xpo=o("CLIPTokenizer"),$po=o(" or "),Fq=a("a"),kpo=o("CLIPTokenizerFast"),Spo=o(" (CLIP model)"),Rpo=l(),gs=a("li"),Wfe=a("strong"),Ppo=o("codegen"),Bpo=o(" \u2014 "),Tq=a("a"),Ipo=o("CodeGenTokenizer"),Npo=o(" or "),Mq=a("a"),qpo=o("CodeGenTokenizerFast"),jpo=o(" (CodeGen model)"),Dpo=l(),hs=a("li"),Ufe=a("strong"),Gpo=o("convbert"),Opo=o(" \u2014 "),Eq=a("a"),Vpo=o("ConvBertTokenizer"),Xpo=o(" or "),Cq=a("a"),zpo=o("ConvBertTokenizerFast"),Qpo=o(" (ConvBERT model)"),Wpo=l(),us=a("li"),Hfe=a("strong"),Upo=o("cpm"),Hpo=o(" \u2014 "),wq=a("a"),Jpo=o("CpmTokenizer"),Ypo=o(" or "),Aq=a("a"),Kpo=o("CpmTokenizerFast"),Zpo=o(" (CPM model)"),e_o=l(),tu=a("li"),Jfe=a("strong"),o_o=o("ctrl"),r_o=o(" \u2014 "),Lq=a("a"),t_o=o("CTRLTokenizer"),a_o=o(" (CTRL model)"),n_o=l(),ps=a("li"),Yfe=a("strong"),s_o=o("data2vec-text"),l_o=o(" \u2014 "),yq=a("a"),i_o=o("RobertaTokenizer"),d_o=o(" or "),xq=a("a"),c_o=o("RobertaTokenizerFast"),f_o=o(" (Data2VecText model)"),m_o=l(),_s=a("li"),Kfe=a("strong"),g_o=o("deberta"),h_o=o(" \u2014 "),$q=a("a"),u_o=o("DebertaTokenizer"),p_o=o(" or "),kq=a("a"),__o=o("DebertaTokenizerFast"),v_o=o(" (DeBERTa model)"),b_o=l(),vs=a("li"),Zfe=a("strong"),F_o=o("deberta-v2"),T_o=o(" \u2014 "),Sq=a("a"),M_o=o("DebertaV2Tokenizer"),E_o=o(" or "),Rq=a("a"),C_o=o("DebertaV2TokenizerFast"),w_o=o(" (DeBERTa-v2 model)"),A_o=l(),bs=a("li"),eme=a("strong"),L_o=o("distilbert"),y_o=o(" \u2014 "),Pq=a("a"),x_o=o("DistilBertTokenizer"),$_o=o(" or "),Bq=a("a"),k_o=o("DistilBertTokenizerFast"),S_o=o(" (DistilBERT model)"),R_o=l(),Fs=a("li"),ome=a("strong"),P_o=o("dpr"),B_o=o(" \u2014 "),Iq=a("a"),I_o=o("DPRQuestionEncoderTokenizer"),N_o=o(" or "),Nq=a("a"),q_o=o("DPRQuestionEncoderTokenizerFast"),j_o=o(" (DPR model)"),D_o=l(),Ts=a("li"),rme=a("strong"),G_o=o("electra"),O_o=o(" \u2014 "),qq=a("a"),V_o=o("ElectraTokenizer"),X_o=o(" or "),jq=a("a"),z_o=o("ElectraTokenizerFast"),Q_o=o(" (ELECTRA model)"),W_o=l(),Ms=a("li"),tme=a("strong"),U_o=o("ernie"),H_o=o(" \u2014 "),Dq=a("a"),J_o=o("BertTokenizer"),Y_o=o(" or "),Gq=a("a"),K_o=o("BertTokenizerFast"),Z_o=o(" (ERNIE model)"),e2o=l(),au=a("li"),ame=a("strong"),o2o=o("flaubert"),r2o=o(" \u2014 "),Oq=a("a"),t2o=o("FlaubertTokenizer"),a2o=o(" (FlauBERT model)"),n2o=l(),Es=a("li"),nme=a("strong"),s2o=o("fnet"),l2o=o(" \u2014 "),Vq=a("a"),i2o=o("FNetTokenizer"),d2o=o(" or "),Xq=a("a"),c2o=o("FNetTokenizerFast"),f2o=o(" (FNet model)"),m2o=l(),nu=a("li"),sme=a("strong"),g2o=o("fsmt"),h2o=o(" \u2014 "),zq=a("a"),u2o=o("FSMTTokenizer"),p2o=o(" (FairSeq Machine-Translation model)"),_2o=l(),Cs=a("li"),lme=a("strong"),v2o=o("funnel"),b2o=o(" \u2014 "),Qq=a("a"),F2o=o("FunnelTokenizer"),T2o=o(" or "),Wq=a("a"),M2o=o("FunnelTokenizerFast"),E2o=o(" (Funnel Transformer model)"),C2o=l(),ws=a("li"),ime=a("strong"),w2o=o("gpt2"),A2o=o(" \u2014 "),Uq=a("a"),L2o=o("GPT2Tokenizer"),y2o=o(" or "),Hq=a("a"),x2o=o("GPT2TokenizerFast"),$2o=o(" (OpenAI GPT-2 model)"),k2o=l(),As=a("li"),dme=a("strong"),S2o=o("gpt_neo"),R2o=o(" \u2014 "),Jq=a("a"),P2o=o("GPT2Tokenizer"),B2o=o(" or "),Yq=a("a"),I2o=o("GPT2TokenizerFast"),N2o=o(" (GPT Neo model)"),q2o=l(),su=a("li"),cme=a("strong"),j2o=o("gpt_neox"),D2o=o(" \u2014 "),Kq=a("a"),G2o=o("GPTNeoXTokenizerFast"),O2o=o(" (GPT NeoX model)"),V2o=l(),Ls=a("li"),fme=a("strong"),X2o=o("gptj"),z2o=o(" \u2014 "),Zq=a("a"),Q2o=o("GPT2Tokenizer"),W2o=o(" or "),ej=a("a"),U2o=o("GPT2TokenizerFast"),H2o=o(" (GPT-J model)"),J2o=l(),ys=a("li"),mme=a("strong"),Y2o=o("groupvit"),K2o=o(" \u2014 "),oj=a("a"),Z2o=o("CLIPTokenizer"),evo=o(" or "),rj=a("a"),ovo=o("CLIPTokenizerFast"),rvo=o(" (GroupViT model)"),tvo=l(),xs=a("li"),gme=a("strong"),avo=o("herbert"),nvo=o(" \u2014 "),tj=a("a"),svo=o("HerbertTokenizer"),lvo=o(" or "),aj=a("a"),ivo=o("HerbertTokenizerFast"),dvo=o(" (HerBERT model)"),cvo=l(),lu=a("li"),hme=a("strong"),fvo=o("hubert"),mvo=o(" \u2014 "),nj=a("a"),gvo=o("Wav2Vec2CTCTokenizer"),hvo=o(" (Hubert model)"),uvo=l(),$s=a("li"),ume=a("strong"),pvo=o("ibert"),_vo=o(" \u2014 "),sj=a("a"),vvo=o("RobertaTokenizer"),bvo=o(" or "),lj=a("a"),Fvo=o("RobertaTokenizerFast"),Tvo=o(" (I-BERT model)"),Mvo=l(),ks=a("li"),pme=a("strong"),Evo=o("layoutlm"),Cvo=o(" \u2014 "),ij=a("a"),wvo=o("LayoutLMTokenizer"),Avo=o(" or "),dj=a("a"),Lvo=o("LayoutLMTokenizerFast"),yvo=o(" (LayoutLM model)"),xvo=l(),Ss=a("li"),_me=a("strong"),$vo=o("layoutlmv2"),kvo=o(" \u2014 "),cj=a("a"),Svo=o("LayoutLMv2Tokenizer"),Rvo=o(" or "),fj=a("a"),Pvo=o("LayoutLMv2TokenizerFast"),Bvo=o(" (LayoutLMv2 model)"),Ivo=l(),Rs=a("li"),vme=a("strong"),Nvo=o("layoutlmv3"),qvo=o(" \u2014 "),mj=a("a"),jvo=o("LayoutLMv3Tokenizer"),Dvo=o(" or "),gj=a("a"),Gvo=o("LayoutLMv3TokenizerFast"),Ovo=o(" (LayoutLMv3 model)"),Vvo=l(),Ps=a("li"),bme=a("strong"),Xvo=o("layoutxlm"),zvo=o(" \u2014 "),hj=a("a"),Qvo=o("LayoutXLMTokenizer"),Wvo=o(" or "),uj=a("a"),Uvo=o("LayoutXLMTokenizerFast"),Hvo=o(" (LayoutXLM model)"),Jvo=l(),Bs=a("li"),Fme=a("strong"),Yvo=o("led"),Kvo=o(" \u2014 "),pj=a("a"),Zvo=o("LEDTokenizer"),e4o=o(" or "),_j=a("a"),o4o=o("LEDTokenizerFast"),r4o=o(" (LED model)"),t4o=l(),Is=a("li"),Tme=a("strong"),a4o=o("longformer"),n4o=o(" \u2014 "),vj=a("a"),s4o=o("LongformerTokenizer"),l4o=o(" or "),bj=a("a"),i4o=o("LongformerTokenizerFast"),d4o=o(" (Longformer model)"),c4o=l(),Ns=a("li"),Mme=a("strong"),f4o=o("longt5"),m4o=o(" \u2014 "),Fj=a("a"),g4o=o("T5Tokenizer"),h4o=o(" or "),Tj=a("a"),u4o=o("T5TokenizerFast"),p4o=o(" (LongT5 model)"),_4o=l(),iu=a("li"),Eme=a("strong"),v4o=o("luke"),b4o=o(" \u2014 "),Mj=a("a"),F4o=o("LukeTokenizer"),T4o=o(" (LUKE model)"),M4o=l(),qs=a("li"),Cme=a("strong"),E4o=o("lxmert"),C4o=o(" \u2014 "),Ej=a("a"),w4o=o("LxmertTokenizer"),A4o=o(" or "),Cj=a("a"),L4o=o("LxmertTokenizerFast"),y4o=o(" (LXMERT model)"),x4o=l(),du=a("li"),wme=a("strong"),$4o=o("m2m_100"),k4o=o(" \u2014 "),wj=a("a"),S4o=o("M2M100Tokenizer"),R4o=o(" (M2M100 model)"),P4o=l(),cu=a("li"),Ame=a("strong"),B4o=o("marian"),I4o=o(" \u2014 "),Aj=a("a"),N4o=o("MarianTokenizer"),q4o=o(" (Marian model)"),j4o=l(),js=a("li"),Lme=a("strong"),D4o=o("mbart"),G4o=o(" \u2014 "),Lj=a("a"),O4o=o("MBartTokenizer"),V4o=o(" or "),yj=a("a"),X4o=o("MBartTokenizerFast"),z4o=o(" (mBART model)"),Q4o=l(),Ds=a("li"),yme=a("strong"),W4o=o("mbart50"),U4o=o(" \u2014 "),xj=a("a"),H4o=o("MBart50Tokenizer"),J4o=o(" or "),$j=a("a"),Y4o=o("MBart50TokenizerFast"),K4o=o(" (mBART-50 model)"),Z4o=l(),Gs=a("li"),xme=a("strong"),ebo=o("megatron-bert"),obo=o(" \u2014 "),kj=a("a"),rbo=o("BertTokenizer"),tbo=o(" or "),Sj=a("a"),abo=o("BertTokenizerFast"),nbo=o(" (Megatron-BERT model)"),sbo=l(),fu=a("li"),$me=a("strong"),lbo=o("mluke"),ibo=o(" \u2014 "),Rj=a("a"),dbo=o("MLukeTokenizer"),cbo=o(" (mLUKE model)"),fbo=l(),Os=a("li"),kme=a("strong"),mbo=o("mobilebert"),gbo=o(" \u2014 "),Pj=a("a"),hbo=o("MobileBertTokenizer"),ubo=o(" or "),Bj=a("a"),pbo=o("MobileBertTokenizerFast"),_bo=o(" (MobileBERT model)"),vbo=l(),Vs=a("li"),Sme=a("strong"),bbo=o("mpnet"),Fbo=o(" \u2014 "),Ij=a("a"),Tbo=o("MPNetTokenizer"),Mbo=o(" or "),Nj=a("a"),Ebo=o("MPNetTokenizerFast"),Cbo=o(" (MPNet model)"),wbo=l(),Xs=a("li"),Rme=a("strong"),Abo=o("mt5"),Lbo=o(" \u2014 "),qj=a("a"),ybo=o("MT5Tokenizer"),xbo=o(" or "),jj=a("a"),$bo=o("MT5TokenizerFast"),kbo=o(" (MT5 model)"),Sbo=l(),zs=a("li"),Pme=a("strong"),Rbo=o("mvp"),Pbo=o(" \u2014 "),Dj=a("a"),Bbo=o("MvpTokenizer"),Ibo=o(" or "),Gj=a("a"),Nbo=o("MvpTokenizerFast"),qbo=o(" (MVP model)"),jbo=l(),Qs=a("li"),Bme=a("strong"),Dbo=o("nezha"),Gbo=o(" \u2014 "),Oj=a("a"),Obo=o("BertTokenizer"),Vbo=o(" or "),Vj=a("a"),Xbo=o("BertTokenizerFast"),zbo=o(" (Nezha model)"),Qbo=l(),Ws=a("li"),Ime=a("strong"),Wbo=o("nllb"),Ubo=o(" \u2014 "),Xj=a("a"),Hbo=o("NllbTokenizer"),Jbo=o(" or "),zj=a("a"),Ybo=o("NllbTokenizerFast"),Kbo=o(" (NLLB model)"),Zbo=l(),Us=a("li"),Nme=a("strong"),e1o=o("nystromformer"),o1o=o(" \u2014 "),Qj=a("a"),r1o=o("AlbertTokenizer"),t1o=o(" or "),Wj=a("a"),a1o=o("AlbertTokenizerFast"),n1o=o(" (Nystr\xF6mformer model)"),s1o=l(),Hs=a("li"),qme=a("strong"),l1o=o("openai-gpt"),i1o=o(" \u2014 "),Uj=a("a"),d1o=o("OpenAIGPTTokenizer"),c1o=o(" or "),Hj=a("a"),f1o=o("OpenAIGPTTokenizerFast"),m1o=o(" (OpenAI GPT model)"),g1o=l(),mu=a("li"),jme=a("strong"),h1o=o("opt"),u1o=o(" \u2014 "),Jj=a("a"),p1o=o("GPT2Tokenizer"),_1o=o(" (OPT model)"),v1o=l(),Js=a("li"),Dme=a("strong"),b1o=o("owlvit"),F1o=o(" \u2014 "),Yj=a("a"),T1o=o("CLIPTokenizer"),M1o=o(" or "),Kj=a("a"),E1o=o("CLIPTokenizerFast"),C1o=o(" (OWL-ViT model)"),w1o=l(),Ys=a("li"),Gme=a("strong"),A1o=o("pegasus"),L1o=o(" \u2014 "),Zj=a("a"),y1o=o("PegasusTokenizer"),x1o=o(" or "),eD=a("a"),$1o=o("PegasusTokenizerFast"),k1o=o(" (Pegasus model)"),S1o=l(),gu=a("li"),Ome=a("strong"),R1o=o("perceiver"),P1o=o(" \u2014 "),oD=a("a"),B1o=o("PerceiverTokenizer"),I1o=o(" (Perceiver model)"),N1o=l(),hu=a("li"),Vme=a("strong"),q1o=o("phobert"),j1o=o(" \u2014 "),rD=a("a"),D1o=o("PhobertTokenizer"),G1o=o(" (PhoBERT model)"),O1o=l(),uu=a("li"),Xme=a("strong"),V1o=o("plbart"),X1o=o(" \u2014 "),tD=a("a"),z1o=o("PLBartTokenizer"),Q1o=o(" (PLBart model)"),W1o=l(),pu=a("li"),zme=a("strong"),U1o=o("prophetnet"),H1o=o(" \u2014 "),aD=a("a"),J1o=o("ProphetNetTokenizer"),Y1o=o(" (ProphetNet model)"),K1o=l(),Ks=a("li"),Qme=a("strong"),Z1o=o("qdqbert"),e0o=o(" \u2014 "),nD=a("a"),o0o=o("BertTokenizer"),r0o=o(" or "),sD=a("a"),t0o=o("BertTokenizerFast"),a0o=o(" (QDQBert model)"),n0o=l(),_u=a("li"),Wme=a("strong"),s0o=o("rag"),l0o=o(" \u2014 "),lD=a("a"),i0o=o("RagTokenizer"),d0o=o(" (RAG model)"),c0o=l(),Zs=a("li"),Ume=a("strong"),f0o=o("realm"),m0o=o(" \u2014 "),iD=a("a"),g0o=o("RealmTokenizer"),h0o=o(" or "),dD=a("a"),u0o=o("RealmTokenizerFast"),p0o=o(" (REALM model)"),_0o=l(),el=a("li"),Hme=a("strong"),v0o=o("reformer"),b0o=o(" \u2014 "),cD=a("a"),F0o=o("ReformerTokenizer"),T0o=o(" or "),fD=a("a"),M0o=o("ReformerTokenizerFast"),E0o=o(" (Reformer model)"),C0o=l(),ol=a("li"),Jme=a("strong"),w0o=o("rembert"),A0o=o(" \u2014 "),mD=a("a"),L0o=o("RemBertTokenizer"),y0o=o(" or "),gD=a("a"),x0o=o("RemBertTokenizerFast"),$0o=o(" (RemBERT model)"),k0o=l(),rl=a("li"),Yme=a("strong"),S0o=o("retribert"),R0o=o(" \u2014 "),hD=a("a"),P0o=o("RetriBertTokenizer"),B0o=o(" or "),uD=a("a"),I0o=o("RetriBertTokenizerFast"),N0o=o(" (RetriBERT model)"),q0o=l(),tl=a("li"),Kme=a("strong"),j0o=o("roberta"),D0o=o(" \u2014 "),pD=a("a"),G0o=o("RobertaTokenizer"),O0o=o(" or "),_D=a("a"),V0o=o("RobertaTokenizerFast"),X0o=o(" (RoBERTa model)"),z0o=l(),al=a("li"),Zme=a("strong"),Q0o=o("roformer"),W0o=o(" \u2014 "),vD=a("a"),U0o=o("RoFormerTokenizer"),H0o=o(" or "),bD=a("a"),J0o=o("RoFormerTokenizerFast"),Y0o=o(" (RoFormer model)"),K0o=l(),vu=a("li"),ege=a("strong"),Z0o=o("speech_to_text"),eFo=o(" \u2014 "),FD=a("a"),oFo=o("Speech2TextTokenizer"),rFo=o(" (Speech2Text model)"),tFo=l(),bu=a("li"),oge=a("strong"),aFo=o("speech_to_text_2"),nFo=o(" \u2014 "),TD=a("a"),sFo=o("Speech2Text2Tokenizer"),lFo=o(" (Speech2Text2 model)"),iFo=l(),nl=a("li"),rge=a("strong"),dFo=o("splinter"),cFo=o(" \u2014 "),MD=a("a"),fFo=o("SplinterTokenizer"),mFo=o(" or "),ED=a("a"),gFo=o("SplinterTokenizerFast"),hFo=o(" (Splinter model)"),uFo=l(),sl=a("li"),tge=a("strong"),pFo=o("squeezebert"),_Fo=o(" \u2014 "),CD=a("a"),vFo=o("SqueezeBertTokenizer"),bFo=o(" or "),wD=a("a"),FFo=o("SqueezeBertTokenizerFast"),TFo=o(" (SqueezeBERT model)"),MFo=l(),ll=a("li"),age=a("strong"),EFo=o("t5"),CFo=o(" \u2014 "),AD=a("a"),wFo=o("T5Tokenizer"),AFo=o(" or "),LD=a("a"),LFo=o("T5TokenizerFast"),yFo=o(" (T5 model)"),xFo=l(),Fu=a("li"),nge=a("strong"),$Fo=o("tapas"),kFo=o(" \u2014 "),yD=a("a"),SFo=o("TapasTokenizer"),RFo=o(" (TAPAS model)"),PFo=l(),Tu=a("li"),sge=a("strong"),BFo=o("tapex"),IFo=o(" \u2014 "),xD=a("a"),NFo=o("TapexTokenizer"),qFo=o(" (TAPEX model)"),jFo=l(),Mu=a("li"),lge=a("strong"),DFo=o("transfo-xl"),GFo=o(" \u2014 "),$D=a("a"),OFo=o("TransfoXLTokenizer"),VFo=o(" (Transformer-XL model)"),XFo=l(),il=a("li"),ige=a("strong"),zFo=o("vilt"),QFo=o(" \u2014 "),kD=a("a"),WFo=o("BertTokenizer"),UFo=o(" or "),SD=a("a"),HFo=o("BertTokenizerFast"),JFo=o(" (ViLT model)"),YFo=l(),dl=a("li"),dge=a("strong"),KFo=o("visual_bert"),ZFo=o(" \u2014 "),RD=a("a"),eTo=o("BertTokenizer"),oTo=o(" or "),PD=a("a"),rTo=o("BertTokenizerFast"),tTo=o(" (VisualBERT model)"),aTo=l(),Eu=a("li"),cge=a("strong"),nTo=o("wav2vec2"),sTo=o(" \u2014 "),BD=a("a"),lTo=o("Wav2Vec2CTCTokenizer"),iTo=o(" (Wav2Vec2 model)"),dTo=l(),Cu=a("li"),fge=a("strong"),cTo=o("wav2vec2-conformer"),fTo=o(" \u2014 "),ID=a("a"),mTo=o("Wav2Vec2CTCTokenizer"),gTo=o(" (Wav2Vec2-Conformer model)"),hTo=l(),wu=a("li"),mge=a("strong"),uTo=o("wav2vec2_phoneme"),pTo=o(" \u2014 "),ND=a("a"),_To=o("Wav2Vec2PhonemeCTCTokenizer"),vTo=o(" (Wav2Vec2Phoneme model)"),bTo=l(),cl=a("li"),gge=a("strong"),FTo=o("xclip"),TTo=o(" \u2014 "),qD=a("a"),MTo=o("CLIPTokenizer"),ETo=o(" or "),jD=a("a"),CTo=o("CLIPTokenizerFast"),wTo=o(" (X-CLIP model)"),ATo=l(),fl=a("li"),hge=a("strong"),LTo=o("xglm"),yTo=o(" \u2014 "),DD=a("a"),xTo=o("XGLMTokenizer"),$To=o(" or "),GD=a("a"),kTo=o("XGLMTokenizerFast"),STo=o(" (XGLM model)"),RTo=l(),Au=a("li"),uge=a("strong"),PTo=o("xlm"),BTo=o(" \u2014 "),OD=a("a"),ITo=o("XLMTokenizer"),NTo=o(" (XLM model)"),qTo=l(),Lu=a("li"),pge=a("strong"),jTo=o("xlm-prophetnet"),DTo=o(" \u2014 "),VD=a("a"),GTo=o("XLMProphetNetTokenizer"),OTo=o(" (XLM-ProphetNet model)"),VTo=l(),ml=a("li"),_ge=a("strong"),XTo=o("xlm-roberta"),zTo=o(" \u2014 "),XD=a("a"),QTo=o("XLMRobertaTokenizer"),WTo=o(" or "),zD=a("a"),UTo=o("XLMRobertaTokenizerFast"),HTo=o(" (XLM-RoBERTa model)"),JTo=l(),gl=a("li"),vge=a("strong"),YTo=o("xlm-roberta-xl"),KTo=o(" \u2014 "),QD=a("a"),ZTo=o("XLMRobertaTokenizer"),eMo=o(" or "),WD=a("a"),oMo=o("XLMRobertaTokenizerFast"),rMo=o(" (XLM-RoBERTa-XL model)"),tMo=l(),hl=a("li"),bge=a("strong"),aMo=o("xlnet"),nMo=o(" \u2014 "),UD=a("a"),sMo=o("XLNetTokenizer"),lMo=o(" or "),HD=a("a"),iMo=o("XLNetTokenizerFast"),dMo=o(" (XLNet model)"),cMo=l(),ul=a("li"),Fge=a("strong"),fMo=o("yoso"),mMo=o(" \u2014 "),JD=a("a"),gMo=o("AlbertTokenizer"),hMo=o(" or "),YD=a("a"),uMo=o("AlbertTokenizerFast"),pMo=o(" (YOSO model)"),_Mo=l(),F(yu.$$.fragment),vMo=l(),xu=a("div"),F(I9.$$.fragment),bMo=l(),Tge=a("p"),FMo=o("Register a new tokenizer in this mapping."),DYe=l(),gd=a("h2"),$u=a("a"),Mge=a("span"),F(N9.$$.fragment),TMo=l(),Ege=a("span"),MMo=o("AutoFeatureExtractor"),GYe=l(),So=a("div"),F(q9.$$.fragment),EMo=l(),j9=a("p"),CMo=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),KD=a("a"),wMo=o("AutoFeatureExtractor.from_pretrained()"),AMo=o(" class method."),LMo=l(),D9=a("p"),yMo=o("This class cannot be instantiated directly using "),Cge=a("code"),xMo=o("__init__()"),$Mo=o(" (throws an error)."),kMo=l(),Ye=a("div"),F(G9.$$.fragment),SMo=l(),wge=a("p"),RMo=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),PMo=l(),Ha=a("p"),BMo=o("The feature extractor class to instantiate is selected based on the "),Age=a("code"),IMo=o("model_type"),NMo=o(` property of the config object
(either passed as an argument or loaded from `),Lge=a("code"),qMo=o("pretrained_model_name_or_path"),jMo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),yge=a("code"),DMo=o("pretrained_model_name_or_path"),GMo=o(":"),OMo=l(),W=a("ul"),ku=a("li"),xge=a("strong"),VMo=o("beit"),XMo=o(" \u2014 "),ZD=a("a"),zMo=o("BeitFeatureExtractor"),QMo=o(" (BEiT model)"),WMo=l(),Su=a("li"),$ge=a("strong"),UMo=o("clip"),HMo=o(" \u2014 "),eG=a("a"),JMo=o("CLIPFeatureExtractor"),YMo=o(" (CLIP model)"),KMo=l(),Ru=a("li"),kge=a("strong"),ZMo=o("convnext"),eEo=o(" \u2014 "),oG=a("a"),oEo=o("ConvNextFeatureExtractor"),rEo=o(" (ConvNeXT model)"),tEo=l(),Pu=a("li"),Sge=a("strong"),aEo=o("cvt"),nEo=o(" \u2014 "),rG=a("a"),sEo=o("ConvNextFeatureExtractor"),lEo=o(" (CvT model)"),iEo=l(),Bu=a("li"),Rge=a("strong"),dEo=o("data2vec-audio"),cEo=o(" \u2014 "),tG=a("a"),fEo=o("Wav2Vec2FeatureExtractor"),mEo=o(" (Data2VecAudio model)"),gEo=l(),Iu=a("li"),Pge=a("strong"),hEo=o("data2vec-vision"),uEo=o(" \u2014 "),aG=a("a"),pEo=o("BeitFeatureExtractor"),_Eo=o(" (Data2VecVision model)"),vEo=l(),Nu=a("li"),Bge=a("strong"),bEo=o("deit"),FEo=o(" \u2014 "),nG=a("a"),TEo=o("DeiTFeatureExtractor"),MEo=o(" (DeiT model)"),EEo=l(),qu=a("li"),Ige=a("strong"),CEo=o("detr"),wEo=o(" \u2014 "),sG=a("a"),AEo=o("DetrFeatureExtractor"),LEo=o(" (DETR model)"),yEo=l(),ju=a("li"),Nge=a("strong"),xEo=o("donut"),$Eo=o(" \u2014 "),lG=a("a"),kEo=o("DonutFeatureExtractor"),SEo=o(" (Donut model)"),REo=l(),Du=a("li"),qge=a("strong"),PEo=o("dpt"),BEo=o(" \u2014 "),iG=a("a"),IEo=o("DPTFeatureExtractor"),NEo=o(" (DPT model)"),qEo=l(),Gu=a("li"),jge=a("strong"),jEo=o("flava"),DEo=o(" \u2014 "),dG=a("a"),GEo=o("FlavaFeatureExtractor"),OEo=o(" (FLAVA model)"),VEo=l(),Ou=a("li"),Dge=a("strong"),XEo=o("glpn"),zEo=o(" \u2014 "),cG=a("a"),QEo=o("GLPNFeatureExtractor"),WEo=o(" (GLPN model)"),UEo=l(),Vu=a("li"),Gge=a("strong"),HEo=o("groupvit"),JEo=o(" \u2014 "),fG=a("a"),YEo=o("CLIPFeatureExtractor"),KEo=o(" (GroupViT model)"),ZEo=l(),Xu=a("li"),Oge=a("strong"),eCo=o("hubert"),oCo=o(" \u2014 "),mG=a("a"),rCo=o("Wav2Vec2FeatureExtractor"),tCo=o(" (Hubert model)"),aCo=l(),zu=a("li"),Vge=a("strong"),nCo=o("imagegpt"),sCo=o(" \u2014 "),gG=a("a"),lCo=o("ImageGPTFeatureExtractor"),iCo=o(" (ImageGPT model)"),dCo=l(),Qu=a("li"),Xge=a("strong"),cCo=o("layoutlmv2"),fCo=o(" \u2014 "),hG=a("a"),mCo=o("LayoutLMv2FeatureExtractor"),gCo=o(" (LayoutLMv2 model)"),hCo=l(),Wu=a("li"),zge=a("strong"),uCo=o("layoutlmv3"),pCo=o(" \u2014 "),uG=a("a"),_Co=o("LayoutLMv3FeatureExtractor"),vCo=o(" (LayoutLMv3 model)"),bCo=l(),Uu=a("li"),Qge=a("strong"),FCo=o("levit"),TCo=o(" \u2014 "),pG=a("a"),MCo=o("LevitFeatureExtractor"),ECo=o(" (LeViT model)"),CCo=l(),Hu=a("li"),Wge=a("strong"),wCo=o("maskformer"),ACo=o(" \u2014 "),_G=a("a"),LCo=o("MaskFormerFeatureExtractor"),yCo=o(" (MaskFormer model)"),xCo=l(),Ju=a("li"),Uge=a("strong"),$Co=o("mctct"),kCo=o(" \u2014 "),vG=a("a"),SCo=o("MCTCTFeatureExtractor"),RCo=o(" (M-CTC-T model)"),PCo=l(),Yu=a("li"),Hge=a("strong"),BCo=o("mobilevit"),ICo=o(" \u2014 "),bG=a("a"),NCo=o("MobileViTFeatureExtractor"),qCo=o(" (MobileViT model)"),jCo=l(),Ku=a("li"),Jge=a("strong"),DCo=o("owlvit"),GCo=o(" \u2014 "),FG=a("a"),OCo=o("OwlViTFeatureExtractor"),VCo=o(" (OWL-ViT model)"),XCo=l(),Zu=a("li"),Yge=a("strong"),zCo=o("perceiver"),QCo=o(" \u2014 "),TG=a("a"),WCo=o("PerceiverFeatureExtractor"),UCo=o(" (Perceiver model)"),HCo=l(),ep=a("li"),Kge=a("strong"),JCo=o("poolformer"),YCo=o(" \u2014 "),MG=a("a"),KCo=o("PoolFormerFeatureExtractor"),ZCo=o(" (PoolFormer model)"),e3o=l(),op=a("li"),Zge=a("strong"),o3o=o("regnet"),r3o=o(" \u2014 "),EG=a("a"),t3o=o("ConvNextFeatureExtractor"),a3o=o(" (RegNet model)"),n3o=l(),rp=a("li"),ehe=a("strong"),s3o=o("resnet"),l3o=o(" \u2014 "),CG=a("a"),i3o=o("ConvNextFeatureExtractor"),d3o=o(" (ResNet model)"),c3o=l(),tp=a("li"),ohe=a("strong"),f3o=o("segformer"),m3o=o(" \u2014 "),wG=a("a"),g3o=o("SegformerFeatureExtractor"),h3o=o(" (SegFormer model)"),u3o=l(),ap=a("li"),rhe=a("strong"),p3o=o("speech_to_text"),_3o=o(" \u2014 "),AG=a("a"),v3o=o("Speech2TextFeatureExtractor"),b3o=o(" (Speech2Text model)"),F3o=l(),np=a("li"),the=a("strong"),T3o=o("swin"),M3o=o(" \u2014 "),LG=a("a"),E3o=o("ViTFeatureExtractor"),C3o=o(" (Swin Transformer model)"),w3o=l(),sp=a("li"),ahe=a("strong"),A3o=o("swinv2"),L3o=o(" \u2014 "),yG=a("a"),y3o=o("ViTFeatureExtractor"),x3o=o(" (Swin Transformer V2 model)"),$3o=l(),lp=a("li"),nhe=a("strong"),k3o=o("van"),S3o=o(" \u2014 "),xG=a("a"),R3o=o("ConvNextFeatureExtractor"),P3o=o(" (VAN model)"),B3o=l(),ip=a("li"),she=a("strong"),I3o=o("videomae"),N3o=o(" \u2014 "),$G=a("a"),q3o=o("VideoMAEFeatureExtractor"),j3o=o(" (VideoMAE model)"),D3o=l(),dp=a("li"),lhe=a("strong"),G3o=o("vilt"),O3o=o(" \u2014 "),kG=a("a"),V3o=o("ViltFeatureExtractor"),X3o=o(" (ViLT model)"),z3o=l(),cp=a("li"),ihe=a("strong"),Q3o=o("vit"),W3o=o(" \u2014 "),SG=a("a"),U3o=o("ViTFeatureExtractor"),H3o=o(" (ViT model)"),J3o=l(),fp=a("li"),dhe=a("strong"),Y3o=o("vit_mae"),K3o=o(" \u2014 "),RG=a("a"),Z3o=o("ViTFeatureExtractor"),e5o=o(" (ViTMAE model)"),o5o=l(),mp=a("li"),che=a("strong"),r5o=o("wav2vec2"),t5o=o(" \u2014 "),PG=a("a"),a5o=o("Wav2Vec2FeatureExtractor"),n5o=o(" (Wav2Vec2 model)"),s5o=l(),gp=a("li"),fhe=a("strong"),l5o=o("wav2vec2-conformer"),i5o=o(" \u2014 "),BG=a("a"),d5o=o("Wav2Vec2FeatureExtractor"),c5o=o(" (Wav2Vec2-Conformer model)"),f5o=l(),hp=a("li"),mhe=a("strong"),m5o=o("xclip"),g5o=o(" \u2014 "),IG=a("a"),h5o=o("CLIPFeatureExtractor"),u5o=o(" (X-CLIP model)"),p5o=l(),up=a("li"),ghe=a("strong"),_5o=o("yolos"),v5o=o(" \u2014 "),NG=a("a"),b5o=o("YolosFeatureExtractor"),F5o=o(" (YOLOS model)"),T5o=l(),F(pp.$$.fragment),M5o=l(),F(_p.$$.fragment),E5o=l(),vp=a("div"),F(O9.$$.fragment),C5o=l(),hhe=a("p"),w5o=o("Register a new feature extractor for this class."),OYe=l(),hd=a("h2"),bp=a("a"),uhe=a("span"),F(V9.$$.fragment),A5o=l(),phe=a("span"),L5o=o("AutoProcessor"),VYe=l(),Ro=a("div"),F(X9.$$.fragment),y5o=l(),z9=a("p"),x5o=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),qG=a("a"),$5o=o("AutoProcessor.from_pretrained()"),k5o=o(" class method."),S5o=l(),Q9=a("p"),R5o=o("This class cannot be instantiated directly using "),_he=a("code"),P5o=o("__init__()"),B5o=o(" (throws an error)."),I5o=l(),Ke=a("div"),F(W9.$$.fragment),N5o=l(),vhe=a("p"),q5o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),j5o=l(),ud=a("p"),D5o=o("The processor class to instantiate is selected based on the "),bhe=a("code"),G5o=o("model_type"),O5o=o(` property of the config object (either
passed as an argument or loaded from `),Fhe=a("code"),V5o=o("pretrained_model_name_or_path"),X5o=o(" if possible):"),z5o=l(),ie=a("ul"),Fp=a("li"),The=a("strong"),Q5o=o("clip"),W5o=o(" \u2014 "),jG=a("a"),U5o=o("CLIPProcessor"),H5o=o(" (CLIP model)"),J5o=l(),Tp=a("li"),Mhe=a("strong"),Y5o=o("donut"),K5o=o(" \u2014 "),DG=a("a"),Z5o=o("DonutProcessor"),ewo=o(" (Donut model)"),owo=l(),Mp=a("li"),Ehe=a("strong"),rwo=o("flava"),two=o(" \u2014 "),GG=a("a"),awo=o("FlavaProcessor"),nwo=o(" (FLAVA model)"),swo=l(),Ep=a("li"),Che=a("strong"),lwo=o("groupvit"),iwo=o(" \u2014 "),OG=a("a"),dwo=o("CLIPProcessor"),cwo=o(" (GroupViT model)"),fwo=l(),Cp=a("li"),whe=a("strong"),mwo=o("layoutlmv2"),gwo=o(" \u2014 "),VG=a("a"),hwo=o("LayoutLMv2Processor"),uwo=o(" (LayoutLMv2 model)"),pwo=l(),wp=a("li"),Ahe=a("strong"),_wo=o("layoutlmv3"),vwo=o(" \u2014 "),XG=a("a"),bwo=o("LayoutLMv3Processor"),Fwo=o(" (LayoutLMv3 model)"),Two=l(),Ap=a("li"),Lhe=a("strong"),Mwo=o("layoutxlm"),Ewo=o(" \u2014 "),zG=a("a"),Cwo=o("LayoutXLMProcessor"),wwo=o(" (LayoutXLM model)"),Awo=l(),Lp=a("li"),yhe=a("strong"),Lwo=o("owlvit"),ywo=o(" \u2014 "),QG=a("a"),xwo=o("OwlViTProcessor"),$wo=o(" (OWL-ViT model)"),kwo=l(),yp=a("li"),xhe=a("strong"),Swo=o("sew"),Rwo=o(" \u2014 "),WG=a("a"),Pwo=o("Wav2Vec2Processor"),Bwo=o(" (SEW model)"),Iwo=l(),xp=a("li"),$he=a("strong"),Nwo=o("sew-d"),qwo=o(" \u2014 "),UG=a("a"),jwo=o("Wav2Vec2Processor"),Dwo=o(" (SEW-D model)"),Gwo=l(),$p=a("li"),khe=a("strong"),Owo=o("speech_to_text"),Vwo=o(" \u2014 "),HG=a("a"),Xwo=o("Speech2TextProcessor"),zwo=o(" (Speech2Text model)"),Qwo=l(),kp=a("li"),She=a("strong"),Wwo=o("speech_to_text_2"),Uwo=o(" \u2014 "),JG=a("a"),Hwo=o("Speech2Text2Processor"),Jwo=o(" (Speech2Text2 model)"),Ywo=l(),Sp=a("li"),Rhe=a("strong"),Kwo=o("trocr"),Zwo=o(" \u2014 "),YG=a("a"),eAo=o("TrOCRProcessor"),oAo=o(" (TrOCR model)"),rAo=l(),Rp=a("li"),Phe=a("strong"),tAo=o("unispeech"),aAo=o(" \u2014 "),KG=a("a"),nAo=o("Wav2Vec2Processor"),sAo=o(" (UniSpeech model)"),lAo=l(),Pp=a("li"),Bhe=a("strong"),iAo=o("unispeech-sat"),dAo=o(" \u2014 "),ZG=a("a"),cAo=o("Wav2Vec2Processor"),fAo=o(" (UniSpeechSat model)"),mAo=l(),Bp=a("li"),Ihe=a("strong"),gAo=o("vilt"),hAo=o(" \u2014 "),eO=a("a"),uAo=o("ViltProcessor"),pAo=o(" (ViLT model)"),_Ao=l(),Ip=a("li"),Nhe=a("strong"),vAo=o("vision-text-dual-encoder"),bAo=o(" \u2014 "),oO=a("a"),FAo=o("VisionTextDualEncoderProcessor"),TAo=o(" (VisionTextDualEncoder model)"),MAo=l(),Np=a("li"),qhe=a("strong"),EAo=o("wav2vec2"),CAo=o(" \u2014 "),rO=a("a"),wAo=o("Wav2Vec2Processor"),AAo=o(" (Wav2Vec2 model)"),LAo=l(),qp=a("li"),jhe=a("strong"),yAo=o("wav2vec2-conformer"),xAo=o(" \u2014 "),tO=a("a"),$Ao=o("Wav2Vec2Processor"),kAo=o(" (Wav2Vec2-Conformer model)"),SAo=l(),jp=a("li"),Dhe=a("strong"),RAo=o("wavlm"),PAo=o(" \u2014 "),aO=a("a"),BAo=o("Wav2Vec2Processor"),IAo=o(" (WavLM model)"),NAo=l(),Dp=a("li"),Ghe=a("strong"),qAo=o("xclip"),jAo=o(" \u2014 "),nO=a("a"),DAo=o("CLIPProcessor"),GAo=o(" (X-CLIP model)"),OAo=l(),F(Gp.$$.fragment),VAo=l(),F(Op.$$.fragment),XAo=l(),Vp=a("div"),F(U9.$$.fragment),zAo=l(),Ohe=a("p"),QAo=o("Register a new processor for this class."),XYe=l(),pd=a("h2"),Xp=a("a"),Vhe=a("span"),F(H9.$$.fragment),WAo=l(),Xhe=a("span"),UAo=o("AutoModel"),zYe=l(),Po=a("div"),F(J9.$$.fragment),HAo=l(),_d=a("p"),JAo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),sO=a("a"),YAo=o("from_pretrained()"),KAo=o(" class method or the "),lO=a("a"),ZAo=o("from_config()"),e6o=o(` class
method.`),o6o=l(),Y9=a("p"),r6o=o("This class cannot be instantiated directly using "),zhe=a("code"),t6o=o("__init__()"),a6o=o(" (throws an error)."),n6o=l(),_t=a("div"),F(K9.$$.fragment),s6o=l(),Qhe=a("p"),l6o=o("Instantiates one of the base model classes of the library from a configuration."),i6o=l(),vd=a("p"),d6o=o(`Note:
Loading a model from its configuration file does `),Whe=a("strong"),c6o=o("not"),f6o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iO=a("a"),m6o=o("from_pretrained()"),g6o=o(" to load the model weights."),h6o=l(),F(zp.$$.fragment),u6o=l(),Ze=a("div"),F(Z9.$$.fragment),p6o=l(),Uhe=a("p"),_6o=o("Instantiate one of the base model classes of the library from a pretrained model."),v6o=l(),Ja=a("p"),b6o=o("The model class to instantiate is selected based on the "),Hhe=a("code"),F6o=o("model_type"),T6o=o(` property of the config object (either
passed as an argument or loaded from `),Jhe=a("code"),M6o=o("pretrained_model_name_or_path"),E6o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yhe=a("code"),C6o=o("pretrained_model_name_or_path"),w6o=o(":"),A6o=l(),y=a("ul"),Qp=a("li"),Khe=a("strong"),L6o=o("albert"),y6o=o(" \u2014 "),dO=a("a"),x6o=o("AlbertModel"),$6o=o(" (ALBERT model)"),k6o=l(),Wp=a("li"),Zhe=a("strong"),S6o=o("bart"),R6o=o(" \u2014 "),cO=a("a"),P6o=o("BartModel"),B6o=o(" (BART model)"),I6o=l(),Up=a("li"),eue=a("strong"),N6o=o("beit"),q6o=o(" \u2014 "),fO=a("a"),j6o=o("BeitModel"),D6o=o(" (BEiT model)"),G6o=l(),Hp=a("li"),oue=a("strong"),O6o=o("bert"),V6o=o(" \u2014 "),mO=a("a"),X6o=o("BertModel"),z6o=o(" (BERT model)"),Q6o=l(),Jp=a("li"),rue=a("strong"),W6o=o("bert-generation"),U6o=o(" \u2014 "),gO=a("a"),H6o=o("BertGenerationEncoder"),J6o=o(" (Bert Generation model)"),Y6o=l(),Yp=a("li"),tue=a("strong"),K6o=o("big_bird"),Z6o=o(" \u2014 "),hO=a("a"),e7o=o("BigBirdModel"),o7o=o(" (BigBird model)"),r7o=l(),Kp=a("li"),aue=a("strong"),t7o=o("bigbird_pegasus"),a7o=o(" \u2014 "),uO=a("a"),n7o=o("BigBirdPegasusModel"),s7o=o(" (BigBird-Pegasus model)"),l7o=l(),Zp=a("li"),nue=a("strong"),i7o=o("blenderbot"),d7o=o(" \u2014 "),pO=a("a"),c7o=o("BlenderbotModel"),f7o=o(" (Blenderbot model)"),m7o=l(),e_=a("li"),sue=a("strong"),g7o=o("blenderbot-small"),h7o=o(" \u2014 "),_O=a("a"),u7o=o("BlenderbotSmallModel"),p7o=o(" (BlenderbotSmall model)"),_7o=l(),o_=a("li"),lue=a("strong"),v7o=o("bloom"),b7o=o(" \u2014 "),vO=a("a"),F7o=o("BloomModel"),T7o=o(" (BLOOM model)"),M7o=l(),r_=a("li"),iue=a("strong"),E7o=o("camembert"),C7o=o(" \u2014 "),bO=a("a"),w7o=o("CamembertModel"),A7o=o(" (CamemBERT model)"),L7o=l(),t_=a("li"),due=a("strong"),y7o=o("canine"),x7o=o(" \u2014 "),FO=a("a"),$7o=o("CanineModel"),k7o=o(" (CANINE model)"),S7o=l(),a_=a("li"),cue=a("strong"),R7o=o("clip"),P7o=o(" \u2014 "),TO=a("a"),B7o=o("CLIPModel"),I7o=o(" (CLIP model)"),N7o=l(),n_=a("li"),fue=a("strong"),q7o=o("codegen"),j7o=o(" \u2014 "),MO=a("a"),D7o=o("CodeGenModel"),G7o=o(" (CodeGen model)"),O7o=l(),s_=a("li"),mue=a("strong"),V7o=o("convbert"),X7o=o(" \u2014 "),EO=a("a"),z7o=o("ConvBertModel"),Q7o=o(" (ConvBERT model)"),W7o=l(),l_=a("li"),gue=a("strong"),U7o=o("convnext"),H7o=o(" \u2014 "),CO=a("a"),J7o=o("ConvNextModel"),Y7o=o(" (ConvNeXT model)"),K7o=l(),i_=a("li"),hue=a("strong"),Z7o=o("ctrl"),eLo=o(" \u2014 "),wO=a("a"),oLo=o("CTRLModel"),rLo=o(" (CTRL model)"),tLo=l(),d_=a("li"),uue=a("strong"),aLo=o("cvt"),nLo=o(" \u2014 "),AO=a("a"),sLo=o("CvtModel"),lLo=o(" (CvT model)"),iLo=l(),c_=a("li"),pue=a("strong"),dLo=o("data2vec-audio"),cLo=o(" \u2014 "),LO=a("a"),fLo=o("Data2VecAudioModel"),mLo=o(" (Data2VecAudio model)"),gLo=l(),f_=a("li"),_ue=a("strong"),hLo=o("data2vec-text"),uLo=o(" \u2014 "),yO=a("a"),pLo=o("Data2VecTextModel"),_Lo=o(" (Data2VecText model)"),vLo=l(),m_=a("li"),vue=a("strong"),bLo=o("data2vec-vision"),FLo=o(" \u2014 "),xO=a("a"),TLo=o("Data2VecVisionModel"),MLo=o(" (Data2VecVision model)"),ELo=l(),g_=a("li"),bue=a("strong"),CLo=o("deberta"),wLo=o(" \u2014 "),$O=a("a"),ALo=o("DebertaModel"),LLo=o(" (DeBERTa model)"),yLo=l(),h_=a("li"),Fue=a("strong"),xLo=o("deberta-v2"),$Lo=o(" \u2014 "),kO=a("a"),kLo=o("DebertaV2Model"),SLo=o(" (DeBERTa-v2 model)"),RLo=l(),u_=a("li"),Tue=a("strong"),PLo=o("decision_transformer"),BLo=o(" \u2014 "),SO=a("a"),ILo=o("DecisionTransformerModel"),NLo=o(" (Decision Transformer model)"),qLo=l(),p_=a("li"),Mue=a("strong"),jLo=o("deit"),DLo=o(" \u2014 "),RO=a("a"),GLo=o("DeiTModel"),OLo=o(" (DeiT model)"),VLo=l(),__=a("li"),Eue=a("strong"),XLo=o("detr"),zLo=o(" \u2014 "),PO=a("a"),QLo=o("DetrModel"),WLo=o(" (DETR model)"),ULo=l(),v_=a("li"),Cue=a("strong"),HLo=o("distilbert"),JLo=o(" \u2014 "),BO=a("a"),YLo=o("DistilBertModel"),KLo=o(" (DistilBERT model)"),ZLo=l(),b_=a("li"),wue=a("strong"),eyo=o("donut-swin"),oyo=o(" \u2014 "),IO=a("a"),ryo=o("DonutSwinModel"),tyo=o(" (DonutSwin model)"),ayo=l(),F_=a("li"),Aue=a("strong"),nyo=o("dpr"),syo=o(" \u2014 "),NO=a("a"),lyo=o("DPRQuestionEncoder"),iyo=o(" (DPR model)"),dyo=l(),T_=a("li"),Lue=a("strong"),cyo=o("dpt"),fyo=o(" \u2014 "),qO=a("a"),myo=o("DPTModel"),gyo=o(" (DPT model)"),hyo=l(),M_=a("li"),yue=a("strong"),uyo=o("electra"),pyo=o(" \u2014 "),jO=a("a"),_yo=o("ElectraModel"),vyo=o(" (ELECTRA model)"),byo=l(),E_=a("li"),xue=a("strong"),Fyo=o("ernie"),Tyo=o(" \u2014 "),DO=a("a"),Myo=o("ErnieModel"),Eyo=o(" (ERNIE model)"),Cyo=l(),C_=a("li"),$ue=a("strong"),wyo=o("flaubert"),Ayo=o(" \u2014 "),GO=a("a"),Lyo=o("FlaubertModel"),yyo=o(" (FlauBERT model)"),xyo=l(),w_=a("li"),kue=a("strong"),$yo=o("flava"),kyo=o(" \u2014 "),OO=a("a"),Syo=o("FlavaModel"),Ryo=o(" (FLAVA model)"),Pyo=l(),A_=a("li"),Sue=a("strong"),Byo=o("fnet"),Iyo=o(" \u2014 "),VO=a("a"),Nyo=o("FNetModel"),qyo=o(" (FNet model)"),jyo=l(),L_=a("li"),Rue=a("strong"),Dyo=o("fsmt"),Gyo=o(" \u2014 "),XO=a("a"),Oyo=o("FSMTModel"),Vyo=o(" (FairSeq Machine-Translation model)"),Xyo=l(),pl=a("li"),Pue=a("strong"),zyo=o("funnel"),Qyo=o(" \u2014 "),zO=a("a"),Wyo=o("FunnelModel"),Uyo=o(" or "),QO=a("a"),Hyo=o("FunnelBaseModel"),Jyo=o(" (Funnel Transformer model)"),Yyo=l(),y_=a("li"),Bue=a("strong"),Kyo=o("glpn"),Zyo=o(" \u2014 "),WO=a("a"),e8o=o("GLPNModel"),o8o=o(" (GLPN model)"),r8o=l(),x_=a("li"),Iue=a("strong"),t8o=o("gpt2"),a8o=o(" \u2014 "),UO=a("a"),n8o=o("GPT2Model"),s8o=o(" (OpenAI GPT-2 model)"),l8o=l(),$_=a("li"),Nue=a("strong"),i8o=o("gpt_neo"),d8o=o(" \u2014 "),HO=a("a"),c8o=o("GPTNeoModel"),f8o=o(" (GPT Neo model)"),m8o=l(),k_=a("li"),que=a("strong"),g8o=o("gpt_neox"),h8o=o(" \u2014 "),JO=a("a"),u8o=o("GPTNeoXModel"),p8o=o(" (GPT NeoX model)"),_8o=l(),S_=a("li"),jue=a("strong"),v8o=o("gptj"),b8o=o(" \u2014 "),YO=a("a"),F8o=o("GPTJModel"),T8o=o(" (GPT-J model)"),M8o=l(),R_=a("li"),Due=a("strong"),E8o=o("groupvit"),C8o=o(" \u2014 "),KO=a("a"),w8o=o("GroupViTModel"),A8o=o(" (GroupViT model)"),L8o=l(),P_=a("li"),Gue=a("strong"),y8o=o("hubert"),x8o=o(" \u2014 "),ZO=a("a"),$8o=o("HubertModel"),k8o=o(" (Hubert model)"),S8o=l(),B_=a("li"),Oue=a("strong"),R8o=o("ibert"),P8o=o(" \u2014 "),eV=a("a"),B8o=o("IBertModel"),I8o=o(" (I-BERT model)"),N8o=l(),I_=a("li"),Vue=a("strong"),q8o=o("imagegpt"),j8o=o(" \u2014 "),oV=a("a"),D8o=o("ImageGPTModel"),G8o=o(" (ImageGPT model)"),O8o=l(),N_=a("li"),Xue=a("strong"),V8o=o("layoutlm"),X8o=o(" \u2014 "),rV=a("a"),z8o=o("LayoutLMModel"),Q8o=o(" (LayoutLM model)"),W8o=l(),q_=a("li"),zue=a("strong"),U8o=o("layoutlmv2"),H8o=o(" \u2014 "),tV=a("a"),J8o=o("LayoutLMv2Model"),Y8o=o(" (LayoutLMv2 model)"),K8o=l(),j_=a("li"),Que=a("strong"),Z8o=o("layoutlmv3"),e9o=o(" \u2014 "),aV=a("a"),o9o=o("LayoutLMv3Model"),r9o=o(" (LayoutLMv3 model)"),t9o=l(),D_=a("li"),Wue=a("strong"),a9o=o("led"),n9o=o(" \u2014 "),nV=a("a"),s9o=o("LEDModel"),l9o=o(" (LED model)"),i9o=l(),G_=a("li"),Uue=a("strong"),d9o=o("levit"),c9o=o(" \u2014 "),sV=a("a"),f9o=o("LevitModel"),m9o=o(" (LeViT model)"),g9o=l(),O_=a("li"),Hue=a("strong"),h9o=o("longformer"),u9o=o(" \u2014 "),lV=a("a"),p9o=o("LongformerModel"),_9o=o(" (Longformer model)"),v9o=l(),V_=a("li"),Jue=a("strong"),b9o=o("longt5"),F9o=o(" \u2014 "),iV=a("a"),T9o=o("LongT5Model"),M9o=o(" (LongT5 model)"),E9o=l(),X_=a("li"),Yue=a("strong"),C9o=o("luke"),w9o=o(" \u2014 "),dV=a("a"),A9o=o("LukeModel"),L9o=o(" (LUKE model)"),y9o=l(),z_=a("li"),Kue=a("strong"),x9o=o("lxmert"),$9o=o(" \u2014 "),cV=a("a"),k9o=o("LxmertModel"),S9o=o(" (LXMERT model)"),R9o=l(),Q_=a("li"),Zue=a("strong"),P9o=o("m2m_100"),B9o=o(" \u2014 "),fV=a("a"),I9o=o("M2M100Model"),N9o=o(" (M2M100 model)"),q9o=l(),W_=a("li"),epe=a("strong"),j9o=o("marian"),D9o=o(" \u2014 "),mV=a("a"),G9o=o("MarianModel"),O9o=o(" (Marian model)"),V9o=l(),U_=a("li"),ope=a("strong"),X9o=o("maskformer"),z9o=o(" \u2014 "),gV=a("a"),Q9o=o("MaskFormerModel"),W9o=o(" (MaskFormer model)"),U9o=l(),H_=a("li"),rpe=a("strong"),H9o=o("mbart"),J9o=o(" \u2014 "),hV=a("a"),Y9o=o("MBartModel"),K9o=o(" (mBART model)"),Z9o=l(),J_=a("li"),tpe=a("strong"),exo=o("mctct"),oxo=o(" \u2014 "),uV=a("a"),rxo=o("MCTCTModel"),txo=o(" (M-CTC-T model)"),axo=l(),Y_=a("li"),ape=a("strong"),nxo=o("megatron-bert"),sxo=o(" \u2014 "),pV=a("a"),lxo=o("MegatronBertModel"),ixo=o(" (Megatron-BERT model)"),dxo=l(),K_=a("li"),npe=a("strong"),cxo=o("mobilebert"),fxo=o(" \u2014 "),_V=a("a"),mxo=o("MobileBertModel"),gxo=o(" (MobileBERT model)"),hxo=l(),Z_=a("li"),spe=a("strong"),uxo=o("mobilevit"),pxo=o(" \u2014 "),vV=a("a"),_xo=o("MobileViTModel"),vxo=o(" (MobileViT model)"),bxo=l(),e2=a("li"),lpe=a("strong"),Fxo=o("mpnet"),Txo=o(" \u2014 "),bV=a("a"),Mxo=o("MPNetModel"),Exo=o(" (MPNet model)"),Cxo=l(),o2=a("li"),ipe=a("strong"),wxo=o("mt5"),Axo=o(" \u2014 "),FV=a("a"),Lxo=o("MT5Model"),yxo=o(" (MT5 model)"),xxo=l(),r2=a("li"),dpe=a("strong"),$xo=o("mvp"),kxo=o(" \u2014 "),TV=a("a"),Sxo=o("MvpModel"),Rxo=o(" (MVP model)"),Pxo=l(),t2=a("li"),cpe=a("strong"),Bxo=o("nezha"),Ixo=o(" \u2014 "),MV=a("a"),Nxo=o("NezhaModel"),qxo=o(" (Nezha model)"),jxo=l(),a2=a("li"),fpe=a("strong"),Dxo=o("nllb"),Gxo=o(" \u2014 "),EV=a("a"),Oxo=o("M2M100Model"),Vxo=o(" (NLLB model)"),Xxo=l(),n2=a("li"),mpe=a("strong"),zxo=o("nystromformer"),Qxo=o(" \u2014 "),CV=a("a"),Wxo=o("NystromformerModel"),Uxo=o(" (Nystr\xF6mformer model)"),Hxo=l(),s2=a("li"),gpe=a("strong"),Jxo=o("openai-gpt"),Yxo=o(" \u2014 "),wV=a("a"),Kxo=o("OpenAIGPTModel"),Zxo=o(" (OpenAI GPT model)"),e$o=l(),l2=a("li"),hpe=a("strong"),o$o=o("opt"),r$o=o(" \u2014 "),AV=a("a"),t$o=o("OPTModel"),a$o=o(" (OPT model)"),n$o=l(),i2=a("li"),upe=a("strong"),s$o=o("owlvit"),l$o=o(" \u2014 "),LV=a("a"),i$o=o("OwlViTModel"),d$o=o(" (OWL-ViT model)"),c$o=l(),d2=a("li"),ppe=a("strong"),f$o=o("pegasus"),m$o=o(" \u2014 "),yV=a("a"),g$o=o("PegasusModel"),h$o=o(" (Pegasus model)"),u$o=l(),c2=a("li"),_pe=a("strong"),p$o=o("pegasus_x"),_$o=o(" \u2014 "),xV=a("a"),v$o=o("PegasusXModel"),b$o=o(" (PEGASUS-X model)"),F$o=l(),f2=a("li"),vpe=a("strong"),T$o=o("perceiver"),M$o=o(" \u2014 "),$V=a("a"),E$o=o("PerceiverModel"),C$o=o(" (Perceiver model)"),w$o=l(),m2=a("li"),bpe=a("strong"),A$o=o("plbart"),L$o=o(" \u2014 "),kV=a("a"),y$o=o("PLBartModel"),x$o=o(" (PLBart model)"),$$o=l(),g2=a("li"),Fpe=a("strong"),k$o=o("poolformer"),S$o=o(" \u2014 "),SV=a("a"),R$o=o("PoolFormerModel"),P$o=o(" (PoolFormer model)"),B$o=l(),h2=a("li"),Tpe=a("strong"),I$o=o("prophetnet"),N$o=o(" \u2014 "),RV=a("a"),q$o=o("ProphetNetModel"),j$o=o(" (ProphetNet model)"),D$o=l(),u2=a("li"),Mpe=a("strong"),G$o=o("qdqbert"),O$o=o(" \u2014 "),PV=a("a"),V$o=o("QDQBertModel"),X$o=o(" (QDQBert model)"),z$o=l(),p2=a("li"),Epe=a("strong"),Q$o=o("reformer"),W$o=o(" \u2014 "),BV=a("a"),U$o=o("ReformerModel"),H$o=o(" (Reformer model)"),J$o=l(),_2=a("li"),Cpe=a("strong"),Y$o=o("regnet"),K$o=o(" \u2014 "),IV=a("a"),Z$o=o("RegNetModel"),eko=o(" (RegNet model)"),oko=l(),v2=a("li"),wpe=a("strong"),rko=o("rembert"),tko=o(" \u2014 "),NV=a("a"),ako=o("RemBertModel"),nko=o(" (RemBERT model)"),sko=l(),b2=a("li"),Ape=a("strong"),lko=o("resnet"),iko=o(" \u2014 "),qV=a("a"),dko=o("ResNetModel"),cko=o(" (ResNet model)"),fko=l(),F2=a("li"),Lpe=a("strong"),mko=o("retribert"),gko=o(" \u2014 "),jV=a("a"),hko=o("RetriBertModel"),uko=o(" (RetriBERT model)"),pko=l(),T2=a("li"),ype=a("strong"),_ko=o("roberta"),vko=o(" \u2014 "),DV=a("a"),bko=o("RobertaModel"),Fko=o(" (RoBERTa model)"),Tko=l(),M2=a("li"),xpe=a("strong"),Mko=o("roformer"),Eko=o(" \u2014 "),GV=a("a"),Cko=o("RoFormerModel"),wko=o(" (RoFormer model)"),Ako=l(),E2=a("li"),$pe=a("strong"),Lko=o("segformer"),yko=o(" \u2014 "),OV=a("a"),xko=o("SegformerModel"),$ko=o(" (SegFormer model)"),kko=l(),C2=a("li"),kpe=a("strong"),Sko=o("sew"),Rko=o(" \u2014 "),VV=a("a"),Pko=o("SEWModel"),Bko=o(" (SEW model)"),Iko=l(),w2=a("li"),Spe=a("strong"),Nko=o("sew-d"),qko=o(" \u2014 "),XV=a("a"),jko=o("SEWDModel"),Dko=o(" (SEW-D model)"),Gko=l(),A2=a("li"),Rpe=a("strong"),Oko=o("speech_to_text"),Vko=o(" \u2014 "),zV=a("a"),Xko=o("Speech2TextModel"),zko=o(" (Speech2Text model)"),Qko=l(),L2=a("li"),Ppe=a("strong"),Wko=o("splinter"),Uko=o(" \u2014 "),QV=a("a"),Hko=o("SplinterModel"),Jko=o(" (Splinter model)"),Yko=l(),y2=a("li"),Bpe=a("strong"),Kko=o("squeezebert"),Zko=o(" \u2014 "),WV=a("a"),eSo=o("SqueezeBertModel"),oSo=o(" (SqueezeBERT model)"),rSo=l(),x2=a("li"),Ipe=a("strong"),tSo=o("swin"),aSo=o(" \u2014 "),UV=a("a"),nSo=o("SwinModel"),sSo=o(" (Swin Transformer model)"),lSo=l(),$2=a("li"),Npe=a("strong"),iSo=o("swinv2"),dSo=o(" \u2014 "),HV=a("a"),cSo=o("Swinv2Model"),fSo=o(" (Swin Transformer V2 model)"),mSo=l(),k2=a("li"),qpe=a("strong"),gSo=o("t5"),hSo=o(" \u2014 "),JV=a("a"),uSo=o("T5Model"),pSo=o(" (T5 model)"),_So=l(),S2=a("li"),jpe=a("strong"),vSo=o("tapas"),bSo=o(" \u2014 "),YV=a("a"),FSo=o("TapasModel"),TSo=o(" (TAPAS model)"),MSo=l(),R2=a("li"),Dpe=a("strong"),ESo=o("trajectory_transformer"),CSo=o(" \u2014 "),KV=a("a"),wSo=o("TrajectoryTransformerModel"),ASo=o(" (Trajectory Transformer model)"),LSo=l(),P2=a("li"),Gpe=a("strong"),ySo=o("transfo-xl"),xSo=o(" \u2014 "),ZV=a("a"),$So=o("TransfoXLModel"),kSo=o(" (Transformer-XL model)"),SSo=l(),B2=a("li"),Ope=a("strong"),RSo=o("unispeech"),PSo=o(" \u2014 "),eX=a("a"),BSo=o("UniSpeechModel"),ISo=o(" (UniSpeech model)"),NSo=l(),I2=a("li"),Vpe=a("strong"),qSo=o("unispeech-sat"),jSo=o(" \u2014 "),oX=a("a"),DSo=o("UniSpeechSatModel"),GSo=o(" (UniSpeechSat model)"),OSo=l(),N2=a("li"),Xpe=a("strong"),VSo=o("van"),XSo=o(" \u2014 "),rX=a("a"),zSo=o("VanModel"),QSo=o(" (VAN model)"),WSo=l(),q2=a("li"),zpe=a("strong"),USo=o("videomae"),HSo=o(" \u2014 "),tX=a("a"),JSo=o("VideoMAEModel"),YSo=o(" (VideoMAE model)"),KSo=l(),j2=a("li"),Qpe=a("strong"),ZSo=o("vilt"),eRo=o(" \u2014 "),aX=a("a"),oRo=o("ViltModel"),rRo=o(" (ViLT model)"),tRo=l(),D2=a("li"),Wpe=a("strong"),aRo=o("vision-text-dual-encoder"),nRo=o(" \u2014 "),nX=a("a"),sRo=o("VisionTextDualEncoderModel"),lRo=o(" (VisionTextDualEncoder model)"),iRo=l(),G2=a("li"),Upe=a("strong"),dRo=o("visual_bert"),cRo=o(" \u2014 "),sX=a("a"),fRo=o("VisualBertModel"),mRo=o(" (VisualBERT model)"),gRo=l(),O2=a("li"),Hpe=a("strong"),hRo=o("vit"),uRo=o(" \u2014 "),lX=a("a"),pRo=o("ViTModel"),_Ro=o(" (ViT model)"),vRo=l(),V2=a("li"),Jpe=a("strong"),bRo=o("vit_mae"),FRo=o(" \u2014 "),iX=a("a"),TRo=o("ViTMAEModel"),MRo=o(" (ViTMAE model)"),ERo=l(),X2=a("li"),Ype=a("strong"),CRo=o("wav2vec2"),wRo=o(" \u2014 "),dX=a("a"),ARo=o("Wav2Vec2Model"),LRo=o(" (Wav2Vec2 model)"),yRo=l(),z2=a("li"),Kpe=a("strong"),xRo=o("wav2vec2-conformer"),$Ro=o(" \u2014 "),cX=a("a"),kRo=o("Wav2Vec2ConformerModel"),SRo=o(" (Wav2Vec2-Conformer model)"),RRo=l(),Q2=a("li"),Zpe=a("strong"),PRo=o("wavlm"),BRo=o(" \u2014 "),fX=a("a"),IRo=o("WavLMModel"),NRo=o(" (WavLM model)"),qRo=l(),W2=a("li"),e_e=a("strong"),jRo=o("xclip"),DRo=o(" \u2014 "),mX=a("a"),GRo=o("XCLIPModel"),ORo=o(" (X-CLIP model)"),VRo=l(),U2=a("li"),o_e=a("strong"),XRo=o("xglm"),zRo=o(" \u2014 "),gX=a("a"),QRo=o("XGLMModel"),WRo=o(" (XGLM model)"),URo=l(),H2=a("li"),r_e=a("strong"),HRo=o("xlm"),JRo=o(" \u2014 "),hX=a("a"),YRo=o("XLMModel"),KRo=o(" (XLM model)"),ZRo=l(),J2=a("li"),t_e=a("strong"),ePo=o("xlm-prophetnet"),oPo=o(" \u2014 "),uX=a("a"),rPo=o("XLMProphetNetModel"),tPo=o(" (XLM-ProphetNet model)"),aPo=l(),Y2=a("li"),a_e=a("strong"),nPo=o("xlm-roberta"),sPo=o(" \u2014 "),pX=a("a"),lPo=o("XLMRobertaModel"),iPo=o(" (XLM-RoBERTa model)"),dPo=l(),K2=a("li"),n_e=a("strong"),cPo=o("xlm-roberta-xl"),fPo=o(" \u2014 "),_X=a("a"),mPo=o("XLMRobertaXLModel"),gPo=o(" (XLM-RoBERTa-XL model)"),hPo=l(),Z2=a("li"),s_e=a("strong"),uPo=o("xlnet"),pPo=o(" \u2014 "),vX=a("a"),_Po=o("XLNetModel"),vPo=o(" (XLNet model)"),bPo=l(),ev=a("li"),l_e=a("strong"),FPo=o("yolos"),TPo=o(" \u2014 "),bX=a("a"),MPo=o("YolosModel"),EPo=o(" (YOLOS model)"),CPo=l(),ov=a("li"),i_e=a("strong"),wPo=o("yoso"),APo=o(" \u2014 "),FX=a("a"),LPo=o("YosoModel"),yPo=o(" (YOSO model)"),xPo=l(),rv=a("p"),$Po=o("The model is set in evaluation mode by default using "),d_e=a("code"),kPo=o("model.eval()"),SPo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c_e=a("code"),RPo=o("model.train()"),PPo=l(),F(tv.$$.fragment),QYe=l(),bd=a("h2"),av=a("a"),f_e=a("span"),F(ex.$$.fragment),BPo=l(),m_e=a("span"),IPo=o("AutoModelForPreTraining"),WYe=l(),Bo=a("div"),F(ox.$$.fragment),NPo=l(),Fd=a("p"),qPo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),TX=a("a"),jPo=o("from_pretrained()"),DPo=o(" class method or the "),MX=a("a"),GPo=o("from_config()"),OPo=o(` class
method.`),VPo=l(),rx=a("p"),XPo=o("This class cannot be instantiated directly using "),g_e=a("code"),zPo=o("__init__()"),QPo=o(" (throws an error)."),WPo=l(),vt=a("div"),F(tx.$$.fragment),UPo=l(),h_e=a("p"),HPo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),JPo=l(),Td=a("p"),YPo=o(`Note:
Loading a model from its configuration file does `),u_e=a("strong"),KPo=o("not"),ZPo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EX=a("a"),eBo=o("from_pretrained()"),oBo=o(" to load the model weights."),rBo=l(),F(nv.$$.fragment),tBo=l(),eo=a("div"),F(ax.$$.fragment),aBo=l(),p_e=a("p"),nBo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),sBo=l(),Ya=a("p"),lBo=o("The model class to instantiate is selected based on the "),__e=a("code"),iBo=o("model_type"),dBo=o(` property of the config object (either
passed as an argument or loaded from `),v_e=a("code"),cBo=o("pretrained_model_name_or_path"),fBo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b_e=a("code"),mBo=o("pretrained_model_name_or_path"),gBo=o(":"),hBo=l(),G=a("ul"),sv=a("li"),F_e=a("strong"),uBo=o("albert"),pBo=o(" \u2014 "),CX=a("a"),_Bo=o("AlbertForPreTraining"),vBo=o(" (ALBERT model)"),bBo=l(),lv=a("li"),T_e=a("strong"),FBo=o("bart"),TBo=o(" \u2014 "),wX=a("a"),MBo=o("BartForConditionalGeneration"),EBo=o(" (BART model)"),CBo=l(),iv=a("li"),M_e=a("strong"),wBo=o("bert"),ABo=o(" \u2014 "),AX=a("a"),LBo=o("BertForPreTraining"),yBo=o(" (BERT model)"),xBo=l(),dv=a("li"),E_e=a("strong"),$Bo=o("big_bird"),kBo=o(" \u2014 "),LX=a("a"),SBo=o("BigBirdForPreTraining"),RBo=o(" (BigBird model)"),PBo=l(),cv=a("li"),C_e=a("strong"),BBo=o("bloom"),IBo=o(" \u2014 "),yX=a("a"),NBo=o("BloomForCausalLM"),qBo=o(" (BLOOM model)"),jBo=l(),fv=a("li"),w_e=a("strong"),DBo=o("camembert"),GBo=o(" \u2014 "),xX=a("a"),OBo=o("CamembertForMaskedLM"),VBo=o(" (CamemBERT model)"),XBo=l(),mv=a("li"),A_e=a("strong"),zBo=o("ctrl"),QBo=o(" \u2014 "),$X=a("a"),WBo=o("CTRLLMHeadModel"),UBo=o(" (CTRL model)"),HBo=l(),gv=a("li"),L_e=a("strong"),JBo=o("data2vec-text"),YBo=o(" \u2014 "),kX=a("a"),KBo=o("Data2VecTextForMaskedLM"),ZBo=o(" (Data2VecText model)"),eIo=l(),hv=a("li"),y_e=a("strong"),oIo=o("deberta"),rIo=o(" \u2014 "),SX=a("a"),tIo=o("DebertaForMaskedLM"),aIo=o(" (DeBERTa model)"),nIo=l(),uv=a("li"),x_e=a("strong"),sIo=o("deberta-v2"),lIo=o(" \u2014 "),RX=a("a"),iIo=o("DebertaV2ForMaskedLM"),dIo=o(" (DeBERTa-v2 model)"),cIo=l(),pv=a("li"),$_e=a("strong"),fIo=o("distilbert"),mIo=o(" \u2014 "),PX=a("a"),gIo=o("DistilBertForMaskedLM"),hIo=o(" (DistilBERT model)"),uIo=l(),_v=a("li"),k_e=a("strong"),pIo=o("electra"),_Io=o(" \u2014 "),BX=a("a"),vIo=o("ElectraForPreTraining"),bIo=o(" (ELECTRA model)"),FIo=l(),vv=a("li"),S_e=a("strong"),TIo=o("ernie"),MIo=o(" \u2014 "),IX=a("a"),EIo=o("ErnieForPreTraining"),CIo=o(" (ERNIE model)"),wIo=l(),bv=a("li"),R_e=a("strong"),AIo=o("flaubert"),LIo=o(" \u2014 "),NX=a("a"),yIo=o("FlaubertWithLMHeadModel"),xIo=o(" (FlauBERT model)"),$Io=l(),Fv=a("li"),P_e=a("strong"),kIo=o("flava"),SIo=o(" \u2014 "),qX=a("a"),RIo=o("FlavaForPreTraining"),PIo=o(" (FLAVA model)"),BIo=l(),Tv=a("li"),B_e=a("strong"),IIo=o("fnet"),NIo=o(" \u2014 "),jX=a("a"),qIo=o("FNetForPreTraining"),jIo=o(" (FNet model)"),DIo=l(),Mv=a("li"),I_e=a("strong"),GIo=o("fsmt"),OIo=o(" \u2014 "),DX=a("a"),VIo=o("FSMTForConditionalGeneration"),XIo=o(" (FairSeq Machine-Translation model)"),zIo=l(),Ev=a("li"),N_e=a("strong"),QIo=o("funnel"),WIo=o(" \u2014 "),GX=a("a"),UIo=o("FunnelForPreTraining"),HIo=o(" (Funnel Transformer model)"),JIo=l(),Cv=a("li"),q_e=a("strong"),YIo=o("gpt2"),KIo=o(" \u2014 "),OX=a("a"),ZIo=o("GPT2LMHeadModel"),eNo=o(" (OpenAI GPT-2 model)"),oNo=l(),wv=a("li"),j_e=a("strong"),rNo=o("ibert"),tNo=o(" \u2014 "),VX=a("a"),aNo=o("IBertForMaskedLM"),nNo=o(" (I-BERT model)"),sNo=l(),Av=a("li"),D_e=a("strong"),lNo=o("layoutlm"),iNo=o(" \u2014 "),XX=a("a"),dNo=o("LayoutLMForMaskedLM"),cNo=o(" (LayoutLM model)"),fNo=l(),Lv=a("li"),G_e=a("strong"),mNo=o("longformer"),gNo=o(" \u2014 "),zX=a("a"),hNo=o("LongformerForMaskedLM"),uNo=o(" (Longformer model)"),pNo=l(),yv=a("li"),O_e=a("strong"),_No=o("luke"),vNo=o(" \u2014 "),QX=a("a"),bNo=o("LukeForMaskedLM"),FNo=o(" (LUKE model)"),TNo=l(),xv=a("li"),V_e=a("strong"),MNo=o("lxmert"),ENo=o(" \u2014 "),WX=a("a"),CNo=o("LxmertForPreTraining"),wNo=o(" (LXMERT model)"),ANo=l(),$v=a("li"),X_e=a("strong"),LNo=o("megatron-bert"),yNo=o(" \u2014 "),UX=a("a"),xNo=o("MegatronBertForPreTraining"),$No=o(" (Megatron-BERT model)"),kNo=l(),kv=a("li"),z_e=a("strong"),SNo=o("mobilebert"),RNo=o(" \u2014 "),HX=a("a"),PNo=o("MobileBertForPreTraining"),BNo=o(" (MobileBERT model)"),INo=l(),Sv=a("li"),Q_e=a("strong"),NNo=o("mpnet"),qNo=o(" \u2014 "),JX=a("a"),jNo=o("MPNetForMaskedLM"),DNo=o(" (MPNet model)"),GNo=l(),Rv=a("li"),W_e=a("strong"),ONo=o("mvp"),VNo=o(" \u2014 "),YX=a("a"),XNo=o("MvpForConditionalGeneration"),zNo=o(" (MVP model)"),QNo=l(),Pv=a("li"),U_e=a("strong"),WNo=o("nezha"),UNo=o(" \u2014 "),KX=a("a"),HNo=o("NezhaForPreTraining"),JNo=o(" (Nezha model)"),YNo=l(),Bv=a("li"),H_e=a("strong"),KNo=o("openai-gpt"),ZNo=o(" \u2014 "),ZX=a("a"),eqo=o("OpenAIGPTLMHeadModel"),oqo=o(" (OpenAI GPT model)"),rqo=l(),Iv=a("li"),J_e=a("strong"),tqo=o("retribert"),aqo=o(" \u2014 "),ez=a("a"),nqo=o("RetriBertModel"),sqo=o(" (RetriBERT model)"),lqo=l(),Nv=a("li"),Y_e=a("strong"),iqo=o("roberta"),dqo=o(" \u2014 "),oz=a("a"),cqo=o("RobertaForMaskedLM"),fqo=o(" (RoBERTa model)"),mqo=l(),qv=a("li"),K_e=a("strong"),gqo=o("splinter"),hqo=o(" \u2014 "),rz=a("a"),uqo=o("SplinterForPreTraining"),pqo=o(" (Splinter model)"),_qo=l(),jv=a("li"),Z_e=a("strong"),vqo=o("squeezebert"),bqo=o(" \u2014 "),tz=a("a"),Fqo=o("SqueezeBertForMaskedLM"),Tqo=o(" (SqueezeBERT model)"),Mqo=l(),Dv=a("li"),e2e=a("strong"),Eqo=o("t5"),Cqo=o(" \u2014 "),az=a("a"),wqo=o("T5ForConditionalGeneration"),Aqo=o(" (T5 model)"),Lqo=l(),Gv=a("li"),o2e=a("strong"),yqo=o("tapas"),xqo=o(" \u2014 "),nz=a("a"),$qo=o("TapasForMaskedLM"),kqo=o(" (TAPAS model)"),Sqo=l(),Ov=a("li"),r2e=a("strong"),Rqo=o("transfo-xl"),Pqo=o(" \u2014 "),sz=a("a"),Bqo=o("TransfoXLLMHeadModel"),Iqo=o(" (Transformer-XL model)"),Nqo=l(),Vv=a("li"),t2e=a("strong"),qqo=o("unispeech"),jqo=o(" \u2014 "),lz=a("a"),Dqo=o("UniSpeechForPreTraining"),Gqo=o(" (UniSpeech model)"),Oqo=l(),Xv=a("li"),a2e=a("strong"),Vqo=o("unispeech-sat"),Xqo=o(" \u2014 "),iz=a("a"),zqo=o("UniSpeechSatForPreTraining"),Qqo=o(" (UniSpeechSat model)"),Wqo=l(),zv=a("li"),n2e=a("strong"),Uqo=o("videomae"),Hqo=o(" \u2014 "),dz=a("a"),Jqo=o("VideoMAEForPreTraining"),Yqo=o(" (VideoMAE model)"),Kqo=l(),Qv=a("li"),s2e=a("strong"),Zqo=o("visual_bert"),ejo=o(" \u2014 "),cz=a("a"),ojo=o("VisualBertForPreTraining"),rjo=o(" (VisualBERT model)"),tjo=l(),Wv=a("li"),l2e=a("strong"),ajo=o("vit_mae"),njo=o(" \u2014 "),fz=a("a"),sjo=o("ViTMAEForPreTraining"),ljo=o(" (ViTMAE model)"),ijo=l(),Uv=a("li"),i2e=a("strong"),djo=o("wav2vec2"),cjo=o(" \u2014 "),mz=a("a"),fjo=o("Wav2Vec2ForPreTraining"),mjo=o(" (Wav2Vec2 model)"),gjo=l(),Hv=a("li"),d2e=a("strong"),hjo=o("wav2vec2-conformer"),ujo=o(" \u2014 "),gz=a("a"),pjo=o("Wav2Vec2ConformerForPreTraining"),_jo=o(" (Wav2Vec2-Conformer model)"),vjo=l(),Jv=a("li"),c2e=a("strong"),bjo=o("xlm"),Fjo=o(" \u2014 "),hz=a("a"),Tjo=o("XLMWithLMHeadModel"),Mjo=o(" (XLM model)"),Ejo=l(),Yv=a("li"),f2e=a("strong"),Cjo=o("xlm-roberta"),wjo=o(" \u2014 "),uz=a("a"),Ajo=o("XLMRobertaForMaskedLM"),Ljo=o(" (XLM-RoBERTa model)"),yjo=l(),Kv=a("li"),m2e=a("strong"),xjo=o("xlm-roberta-xl"),$jo=o(" \u2014 "),pz=a("a"),kjo=o("XLMRobertaXLForMaskedLM"),Sjo=o(" (XLM-RoBERTa-XL model)"),Rjo=l(),Zv=a("li"),g2e=a("strong"),Pjo=o("xlnet"),Bjo=o(" \u2014 "),_z=a("a"),Ijo=o("XLNetLMHeadModel"),Njo=o(" (XLNet model)"),qjo=l(),e4=a("p"),jjo=o("The model is set in evaluation mode by default using "),h2e=a("code"),Djo=o("model.eval()"),Gjo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u2e=a("code"),Ojo=o("model.train()"),Vjo=l(),F(o4.$$.fragment),UYe=l(),Md=a("h2"),r4=a("a"),p2e=a("span"),F(nx.$$.fragment),Xjo=l(),_2e=a("span"),zjo=o("AutoModelForCausalLM"),HYe=l(),Io=a("div"),F(sx.$$.fragment),Qjo=l(),Ed=a("p"),Wjo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),vz=a("a"),Ujo=o("from_pretrained()"),Hjo=o(" class method or the "),bz=a("a"),Jjo=o("from_config()"),Yjo=o(` class
method.`),Kjo=l(),lx=a("p"),Zjo=o("This class cannot be instantiated directly using "),v2e=a("code"),eDo=o("__init__()"),oDo=o(" (throws an error)."),rDo=l(),bt=a("div"),F(ix.$$.fragment),tDo=l(),b2e=a("p"),aDo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),nDo=l(),Cd=a("p"),sDo=o(`Note:
Loading a model from its configuration file does `),F2e=a("strong"),lDo=o("not"),iDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=a("a"),dDo=o("from_pretrained()"),cDo=o(" to load the model weights."),fDo=l(),F(t4.$$.fragment),mDo=l(),oo=a("div"),F(dx.$$.fragment),gDo=l(),T2e=a("p"),hDo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),uDo=l(),Ka=a("p"),pDo=o("The model class to instantiate is selected based on the "),M2e=a("code"),_Do=o("model_type"),vDo=o(` property of the config object (either
passed as an argument or loaded from `),E2e=a("code"),bDo=o("pretrained_model_name_or_path"),FDo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C2e=a("code"),TDo=o("pretrained_model_name_or_path"),MDo=o(":"),EDo=l(),z=a("ul"),a4=a("li"),w2e=a("strong"),CDo=o("bart"),wDo=o(" \u2014 "),Tz=a("a"),ADo=o("BartForCausalLM"),LDo=o(" (BART model)"),yDo=l(),n4=a("li"),A2e=a("strong"),xDo=o("bert"),$Do=o(" \u2014 "),Mz=a("a"),kDo=o("BertLMHeadModel"),SDo=o(" (BERT model)"),RDo=l(),s4=a("li"),L2e=a("strong"),PDo=o("bert-generation"),BDo=o(" \u2014 "),Ez=a("a"),IDo=o("BertGenerationDecoder"),NDo=o(" (Bert Generation model)"),qDo=l(),l4=a("li"),y2e=a("strong"),jDo=o("big_bird"),DDo=o(" \u2014 "),Cz=a("a"),GDo=o("BigBirdForCausalLM"),ODo=o(" (BigBird model)"),VDo=l(),i4=a("li"),x2e=a("strong"),XDo=o("bigbird_pegasus"),zDo=o(" \u2014 "),wz=a("a"),QDo=o("BigBirdPegasusForCausalLM"),WDo=o(" (BigBird-Pegasus model)"),UDo=l(),d4=a("li"),$2e=a("strong"),HDo=o("blenderbot"),JDo=o(" \u2014 "),Az=a("a"),YDo=o("BlenderbotForCausalLM"),KDo=o(" (Blenderbot model)"),ZDo=l(),c4=a("li"),k2e=a("strong"),eGo=o("blenderbot-small"),oGo=o(" \u2014 "),Lz=a("a"),rGo=o("BlenderbotSmallForCausalLM"),tGo=o(" (BlenderbotSmall model)"),aGo=l(),f4=a("li"),S2e=a("strong"),nGo=o("bloom"),sGo=o(" \u2014 "),yz=a("a"),lGo=o("BloomForCausalLM"),iGo=o(" (BLOOM model)"),dGo=l(),m4=a("li"),R2e=a("strong"),cGo=o("camembert"),fGo=o(" \u2014 "),xz=a("a"),mGo=o("CamembertForCausalLM"),gGo=o(" (CamemBERT model)"),hGo=l(),g4=a("li"),P2e=a("strong"),uGo=o("codegen"),pGo=o(" \u2014 "),$z=a("a"),_Go=o("CodeGenForCausalLM"),vGo=o(" (CodeGen model)"),bGo=l(),h4=a("li"),B2e=a("strong"),FGo=o("ctrl"),TGo=o(" \u2014 "),kz=a("a"),MGo=o("CTRLLMHeadModel"),EGo=o(" (CTRL model)"),CGo=l(),u4=a("li"),I2e=a("strong"),wGo=o("data2vec-text"),AGo=o(" \u2014 "),Sz=a("a"),LGo=o("Data2VecTextForCausalLM"),yGo=o(" (Data2VecText model)"),xGo=l(),p4=a("li"),N2e=a("strong"),$Go=o("electra"),kGo=o(" \u2014 "),Rz=a("a"),SGo=o("ElectraForCausalLM"),RGo=o(" (ELECTRA model)"),PGo=l(),_4=a("li"),q2e=a("strong"),BGo=o("ernie"),IGo=o(" \u2014 "),Pz=a("a"),NGo=o("ErnieForCausalLM"),qGo=o(" (ERNIE model)"),jGo=l(),v4=a("li"),j2e=a("strong"),DGo=o("gpt2"),GGo=o(" \u2014 "),Bz=a("a"),OGo=o("GPT2LMHeadModel"),VGo=o(" (OpenAI GPT-2 model)"),XGo=l(),b4=a("li"),D2e=a("strong"),zGo=o("gpt_neo"),QGo=o(" \u2014 "),Iz=a("a"),WGo=o("GPTNeoForCausalLM"),UGo=o(" (GPT Neo model)"),HGo=l(),F4=a("li"),G2e=a("strong"),JGo=o("gpt_neox"),YGo=o(" \u2014 "),Nz=a("a"),KGo=o("GPTNeoXForCausalLM"),ZGo=o(" (GPT NeoX model)"),eOo=l(),T4=a("li"),O2e=a("strong"),oOo=o("gptj"),rOo=o(" \u2014 "),qz=a("a"),tOo=o("GPTJForCausalLM"),aOo=o(" (GPT-J model)"),nOo=l(),M4=a("li"),V2e=a("strong"),sOo=o("marian"),lOo=o(" \u2014 "),jz=a("a"),iOo=o("MarianForCausalLM"),dOo=o(" (Marian model)"),cOo=l(),E4=a("li"),X2e=a("strong"),fOo=o("mbart"),mOo=o(" \u2014 "),Dz=a("a"),gOo=o("MBartForCausalLM"),hOo=o(" (mBART model)"),uOo=l(),C4=a("li"),z2e=a("strong"),pOo=o("megatron-bert"),_Oo=o(" \u2014 "),Gz=a("a"),vOo=o("MegatronBertForCausalLM"),bOo=o(" (Megatron-BERT model)"),FOo=l(),w4=a("li"),Q2e=a("strong"),TOo=o("mvp"),MOo=o(" \u2014 "),Oz=a("a"),EOo=o("MvpForCausalLM"),COo=o(" (MVP model)"),wOo=l(),A4=a("li"),W2e=a("strong"),AOo=o("openai-gpt"),LOo=o(" \u2014 "),Vz=a("a"),yOo=o("OpenAIGPTLMHeadModel"),xOo=o(" (OpenAI GPT model)"),$Oo=l(),L4=a("li"),U2e=a("strong"),kOo=o("opt"),SOo=o(" \u2014 "),Xz=a("a"),ROo=o("OPTForCausalLM"),POo=o(" (OPT model)"),BOo=l(),y4=a("li"),H2e=a("strong"),IOo=o("pegasus"),NOo=o(" \u2014 "),zz=a("a"),qOo=o("PegasusForCausalLM"),jOo=o(" (Pegasus model)"),DOo=l(),x4=a("li"),J2e=a("strong"),GOo=o("plbart"),OOo=o(" \u2014 "),Qz=a("a"),VOo=o("PLBartForCausalLM"),XOo=o(" (PLBart model)"),zOo=l(),$4=a("li"),Y2e=a("strong"),QOo=o("prophetnet"),WOo=o(" \u2014 "),Wz=a("a"),UOo=o("ProphetNetForCausalLM"),HOo=o(" (ProphetNet model)"),JOo=l(),k4=a("li"),K2e=a("strong"),YOo=o("qdqbert"),KOo=o(" \u2014 "),Uz=a("a"),ZOo=o("QDQBertLMHeadModel"),eVo=o(" (QDQBert model)"),oVo=l(),S4=a("li"),Z2e=a("strong"),rVo=o("reformer"),tVo=o(" \u2014 "),Hz=a("a"),aVo=o("ReformerModelWithLMHead"),nVo=o(" (Reformer model)"),sVo=l(),R4=a("li"),eve=a("strong"),lVo=o("rembert"),iVo=o(" \u2014 "),Jz=a("a"),dVo=o("RemBertForCausalLM"),cVo=o(" (RemBERT model)"),fVo=l(),P4=a("li"),ove=a("strong"),mVo=o("roberta"),gVo=o(" \u2014 "),Yz=a("a"),hVo=o("RobertaForCausalLM"),uVo=o(" (RoBERTa model)"),pVo=l(),B4=a("li"),rve=a("strong"),_Vo=o("roformer"),vVo=o(" \u2014 "),Kz=a("a"),bVo=o("RoFormerForCausalLM"),FVo=o(" (RoFormer model)"),TVo=l(),I4=a("li"),tve=a("strong"),MVo=o("speech_to_text_2"),EVo=o(" \u2014 "),Zz=a("a"),CVo=o("Speech2Text2ForCausalLM"),wVo=o(" (Speech2Text2 model)"),AVo=l(),N4=a("li"),ave=a("strong"),LVo=o("transfo-xl"),yVo=o(" \u2014 "),eQ=a("a"),xVo=o("TransfoXLLMHeadModel"),$Vo=o(" (Transformer-XL model)"),kVo=l(),q4=a("li"),nve=a("strong"),SVo=o("trocr"),RVo=o(" \u2014 "),oQ=a("a"),PVo=o("TrOCRForCausalLM"),BVo=o(" (TrOCR model)"),IVo=l(),j4=a("li"),sve=a("strong"),NVo=o("xglm"),qVo=o(" \u2014 "),rQ=a("a"),jVo=o("XGLMForCausalLM"),DVo=o(" (XGLM model)"),GVo=l(),D4=a("li"),lve=a("strong"),OVo=o("xlm"),VVo=o(" \u2014 "),tQ=a("a"),XVo=o("XLMWithLMHeadModel"),zVo=o(" (XLM model)"),QVo=l(),G4=a("li"),ive=a("strong"),WVo=o("xlm-prophetnet"),UVo=o(" \u2014 "),aQ=a("a"),HVo=o("XLMProphetNetForCausalLM"),JVo=o(" (XLM-ProphetNet model)"),YVo=l(),O4=a("li"),dve=a("strong"),KVo=o("xlm-roberta"),ZVo=o(" \u2014 "),nQ=a("a"),eXo=o("XLMRobertaForCausalLM"),oXo=o(" (XLM-RoBERTa model)"),rXo=l(),V4=a("li"),cve=a("strong"),tXo=o("xlm-roberta-xl"),aXo=o(" \u2014 "),sQ=a("a"),nXo=o("XLMRobertaXLForCausalLM"),sXo=o(" (XLM-RoBERTa-XL model)"),lXo=l(),X4=a("li"),fve=a("strong"),iXo=o("xlnet"),dXo=o(" \u2014 "),lQ=a("a"),cXo=o("XLNetLMHeadModel"),fXo=o(" (XLNet model)"),mXo=l(),z4=a("p"),gXo=o("The model is set in evaluation mode by default using "),mve=a("code"),hXo=o("model.eval()"),uXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gve=a("code"),pXo=o("model.train()"),_Xo=l(),F(Q4.$$.fragment),JYe=l(),wd=a("h2"),W4=a("a"),hve=a("span"),F(cx.$$.fragment),vXo=l(),uve=a("span"),bXo=o("AutoModelForMaskedLM"),YYe=l(),No=a("div"),F(fx.$$.fragment),FXo=l(),Ad=a("p"),TXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),iQ=a("a"),MXo=o("from_pretrained()"),EXo=o(" class method or the "),dQ=a("a"),CXo=o("from_config()"),wXo=o(` class
method.`),AXo=l(),mx=a("p"),LXo=o("This class cannot be instantiated directly using "),pve=a("code"),yXo=o("__init__()"),xXo=o(" (throws an error)."),$Xo=l(),Ft=a("div"),F(gx.$$.fragment),kXo=l(),_ve=a("p"),SXo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),RXo=l(),Ld=a("p"),PXo=o(`Note:
Loading a model from its configuration file does `),vve=a("strong"),BXo=o("not"),IXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=a("a"),NXo=o("from_pretrained()"),qXo=o(" to load the model weights."),jXo=l(),F(U4.$$.fragment),DXo=l(),ro=a("div"),F(hx.$$.fragment),GXo=l(),bve=a("p"),OXo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),VXo=l(),Za=a("p"),XXo=o("The model class to instantiate is selected based on the "),Fve=a("code"),zXo=o("model_type"),QXo=o(` property of the config object (either
passed as an argument or loaded from `),Tve=a("code"),WXo=o("pretrained_model_name_or_path"),UXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mve=a("code"),HXo=o("pretrained_model_name_or_path"),JXo=o(":"),YXo=l(),U=a("ul"),H4=a("li"),Eve=a("strong"),KXo=o("albert"),ZXo=o(" \u2014 "),fQ=a("a"),ezo=o("AlbertForMaskedLM"),ozo=o(" (ALBERT model)"),rzo=l(),J4=a("li"),Cve=a("strong"),tzo=o("bart"),azo=o(" \u2014 "),mQ=a("a"),nzo=o("BartForConditionalGeneration"),szo=o(" (BART model)"),lzo=l(),Y4=a("li"),wve=a("strong"),izo=o("bert"),dzo=o(" \u2014 "),gQ=a("a"),czo=o("BertForMaskedLM"),fzo=o(" (BERT model)"),mzo=l(),K4=a("li"),Ave=a("strong"),gzo=o("big_bird"),hzo=o(" \u2014 "),hQ=a("a"),uzo=o("BigBirdForMaskedLM"),pzo=o(" (BigBird model)"),_zo=l(),Z4=a("li"),Lve=a("strong"),vzo=o("camembert"),bzo=o(" \u2014 "),uQ=a("a"),Fzo=o("CamembertForMaskedLM"),Tzo=o(" (CamemBERT model)"),Mzo=l(),eb=a("li"),yve=a("strong"),Ezo=o("convbert"),Czo=o(" \u2014 "),pQ=a("a"),wzo=o("ConvBertForMaskedLM"),Azo=o(" (ConvBERT model)"),Lzo=l(),ob=a("li"),xve=a("strong"),yzo=o("data2vec-text"),xzo=o(" \u2014 "),_Q=a("a"),$zo=o("Data2VecTextForMaskedLM"),kzo=o(" (Data2VecText model)"),Szo=l(),rb=a("li"),$ve=a("strong"),Rzo=o("deberta"),Pzo=o(" \u2014 "),vQ=a("a"),Bzo=o("DebertaForMaskedLM"),Izo=o(" (DeBERTa model)"),Nzo=l(),tb=a("li"),kve=a("strong"),qzo=o("deberta-v2"),jzo=o(" \u2014 "),bQ=a("a"),Dzo=o("DebertaV2ForMaskedLM"),Gzo=o(" (DeBERTa-v2 model)"),Ozo=l(),ab=a("li"),Sve=a("strong"),Vzo=o("distilbert"),Xzo=o(" \u2014 "),FQ=a("a"),zzo=o("DistilBertForMaskedLM"),Qzo=o(" (DistilBERT model)"),Wzo=l(),nb=a("li"),Rve=a("strong"),Uzo=o("electra"),Hzo=o(" \u2014 "),TQ=a("a"),Jzo=o("ElectraForMaskedLM"),Yzo=o(" (ELECTRA model)"),Kzo=l(),sb=a("li"),Pve=a("strong"),Zzo=o("ernie"),eQo=o(" \u2014 "),MQ=a("a"),oQo=o("ErnieForMaskedLM"),rQo=o(" (ERNIE model)"),tQo=l(),lb=a("li"),Bve=a("strong"),aQo=o("flaubert"),nQo=o(" \u2014 "),EQ=a("a"),sQo=o("FlaubertWithLMHeadModel"),lQo=o(" (FlauBERT model)"),iQo=l(),ib=a("li"),Ive=a("strong"),dQo=o("fnet"),cQo=o(" \u2014 "),CQ=a("a"),fQo=o("FNetForMaskedLM"),mQo=o(" (FNet model)"),gQo=l(),db=a("li"),Nve=a("strong"),hQo=o("funnel"),uQo=o(" \u2014 "),wQ=a("a"),pQo=o("FunnelForMaskedLM"),_Qo=o(" (Funnel Transformer model)"),vQo=l(),cb=a("li"),qve=a("strong"),bQo=o("ibert"),FQo=o(" \u2014 "),AQ=a("a"),TQo=o("IBertForMaskedLM"),MQo=o(" (I-BERT model)"),EQo=l(),fb=a("li"),jve=a("strong"),CQo=o("layoutlm"),wQo=o(" \u2014 "),LQ=a("a"),AQo=o("LayoutLMForMaskedLM"),LQo=o(" (LayoutLM model)"),yQo=l(),mb=a("li"),Dve=a("strong"),xQo=o("longformer"),$Qo=o(" \u2014 "),yQ=a("a"),kQo=o("LongformerForMaskedLM"),SQo=o(" (Longformer model)"),RQo=l(),gb=a("li"),Gve=a("strong"),PQo=o("luke"),BQo=o(" \u2014 "),xQ=a("a"),IQo=o("LukeForMaskedLM"),NQo=o(" (LUKE model)"),qQo=l(),hb=a("li"),Ove=a("strong"),jQo=o("mbart"),DQo=o(" \u2014 "),$Q=a("a"),GQo=o("MBartForConditionalGeneration"),OQo=o(" (mBART model)"),VQo=l(),ub=a("li"),Vve=a("strong"),XQo=o("megatron-bert"),zQo=o(" \u2014 "),kQ=a("a"),QQo=o("MegatronBertForMaskedLM"),WQo=o(" (Megatron-BERT model)"),UQo=l(),pb=a("li"),Xve=a("strong"),HQo=o("mobilebert"),JQo=o(" \u2014 "),SQ=a("a"),YQo=o("MobileBertForMaskedLM"),KQo=o(" (MobileBERT model)"),ZQo=l(),_b=a("li"),zve=a("strong"),eWo=o("mpnet"),oWo=o(" \u2014 "),RQ=a("a"),rWo=o("MPNetForMaskedLM"),tWo=o(" (MPNet model)"),aWo=l(),vb=a("li"),Qve=a("strong"),nWo=o("mvp"),sWo=o(" \u2014 "),PQ=a("a"),lWo=o("MvpForConditionalGeneration"),iWo=o(" (MVP model)"),dWo=l(),bb=a("li"),Wve=a("strong"),cWo=o("nezha"),fWo=o(" \u2014 "),BQ=a("a"),mWo=o("NezhaForMaskedLM"),gWo=o(" (Nezha model)"),hWo=l(),Fb=a("li"),Uve=a("strong"),uWo=o("nystromformer"),pWo=o(" \u2014 "),IQ=a("a"),_Wo=o("NystromformerForMaskedLM"),vWo=o(" (Nystr\xF6mformer model)"),bWo=l(),Tb=a("li"),Hve=a("strong"),FWo=o("perceiver"),TWo=o(" \u2014 "),NQ=a("a"),MWo=o("PerceiverForMaskedLM"),EWo=o(" (Perceiver model)"),CWo=l(),Mb=a("li"),Jve=a("strong"),wWo=o("qdqbert"),AWo=o(" \u2014 "),qQ=a("a"),LWo=o("QDQBertForMaskedLM"),yWo=o(" (QDQBert model)"),xWo=l(),Eb=a("li"),Yve=a("strong"),$Wo=o("reformer"),kWo=o(" \u2014 "),jQ=a("a"),SWo=o("ReformerForMaskedLM"),RWo=o(" (Reformer model)"),PWo=l(),Cb=a("li"),Kve=a("strong"),BWo=o("rembert"),IWo=o(" \u2014 "),DQ=a("a"),NWo=o("RemBertForMaskedLM"),qWo=o(" (RemBERT model)"),jWo=l(),wb=a("li"),Zve=a("strong"),DWo=o("roberta"),GWo=o(" \u2014 "),GQ=a("a"),OWo=o("RobertaForMaskedLM"),VWo=o(" (RoBERTa model)"),XWo=l(),Ab=a("li"),e4e=a("strong"),zWo=o("roformer"),QWo=o(" \u2014 "),OQ=a("a"),WWo=o("RoFormerForMaskedLM"),UWo=o(" (RoFormer model)"),HWo=l(),Lb=a("li"),o4e=a("strong"),JWo=o("squeezebert"),YWo=o(" \u2014 "),VQ=a("a"),KWo=o("SqueezeBertForMaskedLM"),ZWo=o(" (SqueezeBERT model)"),eUo=l(),yb=a("li"),r4e=a("strong"),oUo=o("tapas"),rUo=o(" \u2014 "),XQ=a("a"),tUo=o("TapasForMaskedLM"),aUo=o(" (TAPAS model)"),nUo=l(),xb=a("li"),t4e=a("strong"),sUo=o("wav2vec2"),lUo=o(" \u2014 "),a4e=a("code"),iUo=o("Wav2Vec2ForMaskedLM"),dUo=o(" (Wav2Vec2 model)"),cUo=l(),$b=a("li"),n4e=a("strong"),fUo=o("xlm"),mUo=o(" \u2014 "),zQ=a("a"),gUo=o("XLMWithLMHeadModel"),hUo=o(" (XLM model)"),uUo=l(),kb=a("li"),s4e=a("strong"),pUo=o("xlm-roberta"),_Uo=o(" \u2014 "),QQ=a("a"),vUo=o("XLMRobertaForMaskedLM"),bUo=o(" (XLM-RoBERTa model)"),FUo=l(),Sb=a("li"),l4e=a("strong"),TUo=o("xlm-roberta-xl"),MUo=o(" \u2014 "),WQ=a("a"),EUo=o("XLMRobertaXLForMaskedLM"),CUo=o(" (XLM-RoBERTa-XL model)"),wUo=l(),Rb=a("li"),i4e=a("strong"),AUo=o("yoso"),LUo=o(" \u2014 "),UQ=a("a"),yUo=o("YosoForMaskedLM"),xUo=o(" (YOSO model)"),$Uo=l(),Pb=a("p"),kUo=o("The model is set in evaluation mode by default using "),d4e=a("code"),SUo=o("model.eval()"),RUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c4e=a("code"),PUo=o("model.train()"),BUo=l(),F(Bb.$$.fragment),KYe=l(),yd=a("h2"),Ib=a("a"),f4e=a("span"),F(ux.$$.fragment),IUo=l(),m4e=a("span"),NUo=o("AutoModelForSeq2SeqLM"),ZYe=l(),qo=a("div"),F(px.$$.fragment),qUo=l(),xd=a("p"),jUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),HQ=a("a"),DUo=o("from_pretrained()"),GUo=o(" class method or the "),JQ=a("a"),OUo=o("from_config()"),VUo=o(` class
method.`),XUo=l(),_x=a("p"),zUo=o("This class cannot be instantiated directly using "),g4e=a("code"),QUo=o("__init__()"),WUo=o(" (throws an error)."),UUo=l(),Tt=a("div"),F(vx.$$.fragment),HUo=l(),h4e=a("p"),JUo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),YUo=l(),$d=a("p"),KUo=o(`Note:
Loading a model from its configuration file does `),u4e=a("strong"),ZUo=o("not"),eHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YQ=a("a"),oHo=o("from_pretrained()"),rHo=o(" to load the model weights."),tHo=l(),F(Nb.$$.fragment),aHo=l(),to=a("div"),F(bx.$$.fragment),nHo=l(),p4e=a("p"),sHo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),lHo=l(),en=a("p"),iHo=o("The model class to instantiate is selected based on the "),_4e=a("code"),dHo=o("model_type"),cHo=o(` property of the config object (either
passed as an argument or loaded from `),v4e=a("code"),fHo=o("pretrained_model_name_or_path"),mHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b4e=a("code"),gHo=o("pretrained_model_name_or_path"),hHo=o(":"),uHo=l(),fe=a("ul"),qb=a("li"),F4e=a("strong"),pHo=o("bart"),_Ho=o(" \u2014 "),KQ=a("a"),vHo=o("BartForConditionalGeneration"),bHo=o(" (BART model)"),FHo=l(),jb=a("li"),T4e=a("strong"),THo=o("bigbird_pegasus"),MHo=o(" \u2014 "),ZQ=a("a"),EHo=o("BigBirdPegasusForConditionalGeneration"),CHo=o(" (BigBird-Pegasus model)"),wHo=l(),Db=a("li"),M4e=a("strong"),AHo=o("blenderbot"),LHo=o(" \u2014 "),eW=a("a"),yHo=o("BlenderbotForConditionalGeneration"),xHo=o(" (Blenderbot model)"),$Ho=l(),Gb=a("li"),E4e=a("strong"),kHo=o("blenderbot-small"),SHo=o(" \u2014 "),oW=a("a"),RHo=o("BlenderbotSmallForConditionalGeneration"),PHo=o(" (BlenderbotSmall model)"),BHo=l(),Ob=a("li"),C4e=a("strong"),IHo=o("encoder-decoder"),NHo=o(" \u2014 "),rW=a("a"),qHo=o("EncoderDecoderModel"),jHo=o(" (Encoder decoder model)"),DHo=l(),Vb=a("li"),w4e=a("strong"),GHo=o("fsmt"),OHo=o(" \u2014 "),tW=a("a"),VHo=o("FSMTForConditionalGeneration"),XHo=o(" (FairSeq Machine-Translation model)"),zHo=l(),Xb=a("li"),A4e=a("strong"),QHo=o("led"),WHo=o(" \u2014 "),aW=a("a"),UHo=o("LEDForConditionalGeneration"),HHo=o(" (LED model)"),JHo=l(),zb=a("li"),L4e=a("strong"),YHo=o("longt5"),KHo=o(" \u2014 "),nW=a("a"),ZHo=o("LongT5ForConditionalGeneration"),eJo=o(" (LongT5 model)"),oJo=l(),Qb=a("li"),y4e=a("strong"),rJo=o("m2m_100"),tJo=o(" \u2014 "),sW=a("a"),aJo=o("M2M100ForConditionalGeneration"),nJo=o(" (M2M100 model)"),sJo=l(),Wb=a("li"),x4e=a("strong"),lJo=o("marian"),iJo=o(" \u2014 "),lW=a("a"),dJo=o("MarianMTModel"),cJo=o(" (Marian model)"),fJo=l(),Ub=a("li"),$4e=a("strong"),mJo=o("mbart"),gJo=o(" \u2014 "),iW=a("a"),hJo=o("MBartForConditionalGeneration"),uJo=o(" (mBART model)"),pJo=l(),Hb=a("li"),k4e=a("strong"),_Jo=o("mt5"),vJo=o(" \u2014 "),dW=a("a"),bJo=o("MT5ForConditionalGeneration"),FJo=o(" (MT5 model)"),TJo=l(),Jb=a("li"),S4e=a("strong"),MJo=o("mvp"),EJo=o(" \u2014 "),cW=a("a"),CJo=o("MvpForConditionalGeneration"),wJo=o(" (MVP model)"),AJo=l(),Yb=a("li"),R4e=a("strong"),LJo=o("nllb"),yJo=o(" \u2014 "),fW=a("a"),xJo=o("M2M100ForConditionalGeneration"),$Jo=o(" (NLLB model)"),kJo=l(),Kb=a("li"),P4e=a("strong"),SJo=o("pegasus"),RJo=o(" \u2014 "),mW=a("a"),PJo=o("PegasusForConditionalGeneration"),BJo=o(" (Pegasus model)"),IJo=l(),Zb=a("li"),B4e=a("strong"),NJo=o("pegasus_x"),qJo=o(" \u2014 "),gW=a("a"),jJo=o("PegasusXForConditionalGeneration"),DJo=o(" (PEGASUS-X model)"),GJo=l(),e1=a("li"),I4e=a("strong"),OJo=o("plbart"),VJo=o(" \u2014 "),hW=a("a"),XJo=o("PLBartForConditionalGeneration"),zJo=o(" (PLBart model)"),QJo=l(),o1=a("li"),N4e=a("strong"),WJo=o("prophetnet"),UJo=o(" \u2014 "),uW=a("a"),HJo=o("ProphetNetForConditionalGeneration"),JJo=o(" (ProphetNet model)"),YJo=l(),r1=a("li"),q4e=a("strong"),KJo=o("t5"),ZJo=o(" \u2014 "),pW=a("a"),eYo=o("T5ForConditionalGeneration"),oYo=o(" (T5 model)"),rYo=l(),t1=a("li"),j4e=a("strong"),tYo=o("xlm-prophetnet"),aYo=o(" \u2014 "),_W=a("a"),nYo=o("XLMProphetNetForConditionalGeneration"),sYo=o(" (XLM-ProphetNet model)"),lYo=l(),a1=a("p"),iYo=o("The model is set in evaluation mode by default using "),D4e=a("code"),dYo=o("model.eval()"),cYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),G4e=a("code"),fYo=o("model.train()"),mYo=l(),F(n1.$$.fragment),eKe=l(),kd=a("h2"),s1=a("a"),O4e=a("span"),F(Fx.$$.fragment),gYo=l(),V4e=a("span"),hYo=o("AutoModelForSequenceClassification"),oKe=l(),jo=a("div"),F(Tx.$$.fragment),uYo=l(),Sd=a("p"),pYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),vW=a("a"),_Yo=o("from_pretrained()"),vYo=o(" class method or the "),bW=a("a"),bYo=o("from_config()"),FYo=o(` class
method.`),TYo=l(),Mx=a("p"),MYo=o("This class cannot be instantiated directly using "),X4e=a("code"),EYo=o("__init__()"),CYo=o(" (throws an error)."),wYo=l(),Mt=a("div"),F(Ex.$$.fragment),AYo=l(),z4e=a("p"),LYo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),yYo=l(),Rd=a("p"),xYo=o(`Note:
Loading a model from its configuration file does `),Q4e=a("strong"),$Yo=o("not"),kYo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FW=a("a"),SYo=o("from_pretrained()"),RYo=o(" to load the model weights."),PYo=l(),F(l1.$$.fragment),BYo=l(),ao=a("div"),F(Cx.$$.fragment),IYo=l(),W4e=a("p"),NYo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),qYo=l(),on=a("p"),jYo=o("The model class to instantiate is selected based on the "),U4e=a("code"),DYo=o("model_type"),GYo=o(` property of the config object (either
passed as an argument or loaded from `),H4e=a("code"),OYo=o("pretrained_model_name_or_path"),VYo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J4e=a("code"),XYo=o("pretrained_model_name_or_path"),zYo=o(":"),QYo=l(),q=a("ul"),i1=a("li"),Y4e=a("strong"),WYo=o("albert"),UYo=o(" \u2014 "),TW=a("a"),HYo=o("AlbertForSequenceClassification"),JYo=o(" (ALBERT model)"),YYo=l(),d1=a("li"),K4e=a("strong"),KYo=o("bart"),ZYo=o(" \u2014 "),MW=a("a"),eKo=o("BartForSequenceClassification"),oKo=o(" (BART model)"),rKo=l(),c1=a("li"),Z4e=a("strong"),tKo=o("bert"),aKo=o(" \u2014 "),EW=a("a"),nKo=o("BertForSequenceClassification"),sKo=o(" (BERT model)"),lKo=l(),f1=a("li"),ebe=a("strong"),iKo=o("big_bird"),dKo=o(" \u2014 "),CW=a("a"),cKo=o("BigBirdForSequenceClassification"),fKo=o(" (BigBird model)"),mKo=l(),m1=a("li"),obe=a("strong"),gKo=o("bigbird_pegasus"),hKo=o(" \u2014 "),wW=a("a"),uKo=o("BigBirdPegasusForSequenceClassification"),pKo=o(" (BigBird-Pegasus model)"),_Ko=l(),g1=a("li"),rbe=a("strong"),vKo=o("bloom"),bKo=o(" \u2014 "),AW=a("a"),FKo=o("BloomForSequenceClassification"),TKo=o(" (BLOOM model)"),MKo=l(),h1=a("li"),tbe=a("strong"),EKo=o("camembert"),CKo=o(" \u2014 "),LW=a("a"),wKo=o("CamembertForSequenceClassification"),AKo=o(" (CamemBERT model)"),LKo=l(),u1=a("li"),abe=a("strong"),yKo=o("canine"),xKo=o(" \u2014 "),yW=a("a"),$Ko=o("CanineForSequenceClassification"),kKo=o(" (CANINE model)"),SKo=l(),p1=a("li"),nbe=a("strong"),RKo=o("convbert"),PKo=o(" \u2014 "),xW=a("a"),BKo=o("ConvBertForSequenceClassification"),IKo=o(" (ConvBERT model)"),NKo=l(),_1=a("li"),sbe=a("strong"),qKo=o("ctrl"),jKo=o(" \u2014 "),$W=a("a"),DKo=o("CTRLForSequenceClassification"),GKo=o(" (CTRL model)"),OKo=l(),v1=a("li"),lbe=a("strong"),VKo=o("data2vec-text"),XKo=o(" \u2014 "),kW=a("a"),zKo=o("Data2VecTextForSequenceClassification"),QKo=o(" (Data2VecText model)"),WKo=l(),b1=a("li"),ibe=a("strong"),UKo=o("deberta"),HKo=o(" \u2014 "),SW=a("a"),JKo=o("DebertaForSequenceClassification"),YKo=o(" (DeBERTa model)"),KKo=l(),F1=a("li"),dbe=a("strong"),ZKo=o("deberta-v2"),eZo=o(" \u2014 "),RW=a("a"),oZo=o("DebertaV2ForSequenceClassification"),rZo=o(" (DeBERTa-v2 model)"),tZo=l(),T1=a("li"),cbe=a("strong"),aZo=o("distilbert"),nZo=o(" \u2014 "),PW=a("a"),sZo=o("DistilBertForSequenceClassification"),lZo=o(" (DistilBERT model)"),iZo=l(),M1=a("li"),fbe=a("strong"),dZo=o("electra"),cZo=o(" \u2014 "),BW=a("a"),fZo=o("ElectraForSequenceClassification"),mZo=o(" (ELECTRA model)"),gZo=l(),E1=a("li"),mbe=a("strong"),hZo=o("ernie"),uZo=o(" \u2014 "),IW=a("a"),pZo=o("ErnieForSequenceClassification"),_Zo=o(" (ERNIE model)"),vZo=l(),C1=a("li"),gbe=a("strong"),bZo=o("flaubert"),FZo=o(" \u2014 "),NW=a("a"),TZo=o("FlaubertForSequenceClassification"),MZo=o(" (FlauBERT model)"),EZo=l(),w1=a("li"),hbe=a("strong"),CZo=o("fnet"),wZo=o(" \u2014 "),qW=a("a"),AZo=o("FNetForSequenceClassification"),LZo=o(" (FNet model)"),yZo=l(),A1=a("li"),ube=a("strong"),xZo=o("funnel"),$Zo=o(" \u2014 "),jW=a("a"),kZo=o("FunnelForSequenceClassification"),SZo=o(" (Funnel Transformer model)"),RZo=l(),L1=a("li"),pbe=a("strong"),PZo=o("gpt2"),BZo=o(" \u2014 "),DW=a("a"),IZo=o("GPT2ForSequenceClassification"),NZo=o(" (OpenAI GPT-2 model)"),qZo=l(),y1=a("li"),_be=a("strong"),jZo=o("gpt_neo"),DZo=o(" \u2014 "),GW=a("a"),GZo=o("GPTNeoForSequenceClassification"),OZo=o(" (GPT Neo model)"),VZo=l(),x1=a("li"),vbe=a("strong"),XZo=o("gptj"),zZo=o(" \u2014 "),OW=a("a"),QZo=o("GPTJForSequenceClassification"),WZo=o(" (GPT-J model)"),UZo=l(),$1=a("li"),bbe=a("strong"),HZo=o("ibert"),JZo=o(" \u2014 "),VW=a("a"),YZo=o("IBertForSequenceClassification"),KZo=o(" (I-BERT model)"),ZZo=l(),k1=a("li"),Fbe=a("strong"),eer=o("layoutlm"),oer=o(" \u2014 "),XW=a("a"),rer=o("LayoutLMForSequenceClassification"),ter=o(" (LayoutLM model)"),aer=l(),S1=a("li"),Tbe=a("strong"),ner=o("layoutlmv2"),ser=o(" \u2014 "),zW=a("a"),ler=o("LayoutLMv2ForSequenceClassification"),ier=o(" (LayoutLMv2 model)"),der=l(),R1=a("li"),Mbe=a("strong"),cer=o("layoutlmv3"),fer=o(" \u2014 "),QW=a("a"),mer=o("LayoutLMv3ForSequenceClassification"),ger=o(" (LayoutLMv3 model)"),her=l(),P1=a("li"),Ebe=a("strong"),uer=o("led"),per=o(" \u2014 "),WW=a("a"),_er=o("LEDForSequenceClassification"),ver=o(" (LED model)"),ber=l(),B1=a("li"),Cbe=a("strong"),Fer=o("longformer"),Ter=o(" \u2014 "),UW=a("a"),Mer=o("LongformerForSequenceClassification"),Eer=o(" (Longformer model)"),Cer=l(),I1=a("li"),wbe=a("strong"),wer=o("luke"),Aer=o(" \u2014 "),HW=a("a"),Ler=o("LukeForSequenceClassification"),yer=o(" (LUKE model)"),xer=l(),N1=a("li"),Abe=a("strong"),$er=o("mbart"),ker=o(" \u2014 "),JW=a("a"),Ser=o("MBartForSequenceClassification"),Rer=o(" (mBART model)"),Per=l(),q1=a("li"),Lbe=a("strong"),Ber=o("megatron-bert"),Ier=o(" \u2014 "),YW=a("a"),Ner=o("MegatronBertForSequenceClassification"),qer=o(" (Megatron-BERT model)"),jer=l(),j1=a("li"),ybe=a("strong"),Der=o("mobilebert"),Ger=o(" \u2014 "),KW=a("a"),Oer=o("MobileBertForSequenceClassification"),Ver=o(" (MobileBERT model)"),Xer=l(),D1=a("li"),xbe=a("strong"),zer=o("mpnet"),Qer=o(" \u2014 "),ZW=a("a"),Wer=o("MPNetForSequenceClassification"),Uer=o(" (MPNet model)"),Her=l(),G1=a("li"),$be=a("strong"),Jer=o("mvp"),Yer=o(" \u2014 "),eU=a("a"),Ker=o("MvpForSequenceClassification"),Zer=o(" (MVP model)"),eor=l(),O1=a("li"),kbe=a("strong"),oor=o("nezha"),ror=o(" \u2014 "),oU=a("a"),tor=o("NezhaForSequenceClassification"),aor=o(" (Nezha model)"),nor=l(),V1=a("li"),Sbe=a("strong"),sor=o("nystromformer"),lor=o(" \u2014 "),rU=a("a"),ior=o("NystromformerForSequenceClassification"),dor=o(" (Nystr\xF6mformer model)"),cor=l(),X1=a("li"),Rbe=a("strong"),mor=o("openai-gpt"),gor=o(" \u2014 "),tU=a("a"),hor=o("OpenAIGPTForSequenceClassification"),uor=o(" (OpenAI GPT model)"),por=l(),z1=a("li"),Pbe=a("strong"),_or=o("opt"),vor=o(" \u2014 "),aU=a("a"),bor=o("OPTForSequenceClassification"),For=o(" (OPT model)"),Tor=l(),Q1=a("li"),Bbe=a("strong"),Mor=o("perceiver"),Eor=o(" \u2014 "),nU=a("a"),Cor=o("PerceiverForSequenceClassification"),wor=o(" (Perceiver model)"),Aor=l(),W1=a("li"),Ibe=a("strong"),Lor=o("plbart"),yor=o(" \u2014 "),sU=a("a"),xor=o("PLBartForSequenceClassification"),$or=o(" (PLBart model)"),kor=l(),U1=a("li"),Nbe=a("strong"),Sor=o("qdqbert"),Ror=o(" \u2014 "),lU=a("a"),Por=o("QDQBertForSequenceClassification"),Bor=o(" (QDQBert model)"),Ior=l(),H1=a("li"),qbe=a("strong"),Nor=o("reformer"),qor=o(" \u2014 "),iU=a("a"),jor=o("ReformerForSequenceClassification"),Dor=o(" (Reformer model)"),Gor=l(),J1=a("li"),jbe=a("strong"),Oor=o("rembert"),Vor=o(" \u2014 "),dU=a("a"),Xor=o("RemBertForSequenceClassification"),zor=o(" (RemBERT model)"),Qor=l(),Y1=a("li"),Dbe=a("strong"),Wor=o("roberta"),Uor=o(" \u2014 "),cU=a("a"),Hor=o("RobertaForSequenceClassification"),Jor=o(" (RoBERTa model)"),Yor=l(),K1=a("li"),Gbe=a("strong"),Kor=o("roformer"),Zor=o(" \u2014 "),fU=a("a"),err=o("RoFormerForSequenceClassification"),orr=o(" (RoFormer model)"),rrr=l(),Z1=a("li"),Obe=a("strong"),trr=o("squeezebert"),arr=o(" \u2014 "),mU=a("a"),nrr=o("SqueezeBertForSequenceClassification"),srr=o(" (SqueezeBERT model)"),lrr=l(),e0=a("li"),Vbe=a("strong"),irr=o("tapas"),drr=o(" \u2014 "),gU=a("a"),crr=o("TapasForSequenceClassification"),frr=o(" (TAPAS model)"),mrr=l(),o0=a("li"),Xbe=a("strong"),grr=o("transfo-xl"),hrr=o(" \u2014 "),hU=a("a"),urr=o("TransfoXLForSequenceClassification"),prr=o(" (Transformer-XL model)"),_rr=l(),r0=a("li"),zbe=a("strong"),vrr=o("xlm"),brr=o(" \u2014 "),uU=a("a"),Frr=o("XLMForSequenceClassification"),Trr=o(" (XLM model)"),Mrr=l(),t0=a("li"),Qbe=a("strong"),Err=o("xlm-roberta"),Crr=o(" \u2014 "),pU=a("a"),wrr=o("XLMRobertaForSequenceClassification"),Arr=o(" (XLM-RoBERTa model)"),Lrr=l(),a0=a("li"),Wbe=a("strong"),yrr=o("xlm-roberta-xl"),xrr=o(" \u2014 "),_U=a("a"),$rr=o("XLMRobertaXLForSequenceClassification"),krr=o(" (XLM-RoBERTa-XL model)"),Srr=l(),n0=a("li"),Ube=a("strong"),Rrr=o("xlnet"),Prr=o(" \u2014 "),vU=a("a"),Brr=o("XLNetForSequenceClassification"),Irr=o(" (XLNet model)"),Nrr=l(),s0=a("li"),Hbe=a("strong"),qrr=o("yoso"),jrr=o(" \u2014 "),bU=a("a"),Drr=o("YosoForSequenceClassification"),Grr=o(" (YOSO model)"),Orr=l(),l0=a("p"),Vrr=o("The model is set in evaluation mode by default using "),Jbe=a("code"),Xrr=o("model.eval()"),zrr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ybe=a("code"),Qrr=o("model.train()"),Wrr=l(),F(i0.$$.fragment),rKe=l(),Pd=a("h2"),d0=a("a"),Kbe=a("span"),F(wx.$$.fragment),Urr=l(),Zbe=a("span"),Hrr=o("AutoModelForMultipleChoice"),tKe=l(),Do=a("div"),F(Ax.$$.fragment),Jrr=l(),Bd=a("p"),Yrr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),FU=a("a"),Krr=o("from_pretrained()"),Zrr=o(" class method or the "),TU=a("a"),etr=o("from_config()"),otr=o(` class
method.`),rtr=l(),Lx=a("p"),ttr=o("This class cannot be instantiated directly using "),e1e=a("code"),atr=o("__init__()"),ntr=o(" (throws an error)."),str=l(),Et=a("div"),F(yx.$$.fragment),ltr=l(),o1e=a("p"),itr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),dtr=l(),Id=a("p"),ctr=o(`Note:
Loading a model from its configuration file does `),r1e=a("strong"),ftr=o("not"),mtr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MU=a("a"),gtr=o("from_pretrained()"),htr=o(" to load the model weights."),utr=l(),F(c0.$$.fragment),ptr=l(),no=a("div"),F(xx.$$.fragment),_tr=l(),t1e=a("p"),vtr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),btr=l(),rn=a("p"),Ftr=o("The model class to instantiate is selected based on the "),a1e=a("code"),Ttr=o("model_type"),Mtr=o(` property of the config object (either
passed as an argument or loaded from `),n1e=a("code"),Etr=o("pretrained_model_name_or_path"),Ctr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s1e=a("code"),wtr=o("pretrained_model_name_or_path"),Atr=o(":"),Ltr=l(),Z=a("ul"),f0=a("li"),l1e=a("strong"),ytr=o("albert"),xtr=o(" \u2014 "),EU=a("a"),$tr=o("AlbertForMultipleChoice"),ktr=o(" (ALBERT model)"),Str=l(),m0=a("li"),i1e=a("strong"),Rtr=o("bert"),Ptr=o(" \u2014 "),CU=a("a"),Btr=o("BertForMultipleChoice"),Itr=o(" (BERT model)"),Ntr=l(),g0=a("li"),d1e=a("strong"),qtr=o("big_bird"),jtr=o(" \u2014 "),wU=a("a"),Dtr=o("BigBirdForMultipleChoice"),Gtr=o(" (BigBird model)"),Otr=l(),h0=a("li"),c1e=a("strong"),Vtr=o("camembert"),Xtr=o(" \u2014 "),AU=a("a"),ztr=o("CamembertForMultipleChoice"),Qtr=o(" (CamemBERT model)"),Wtr=l(),u0=a("li"),f1e=a("strong"),Utr=o("canine"),Htr=o(" \u2014 "),LU=a("a"),Jtr=o("CanineForMultipleChoice"),Ytr=o(" (CANINE model)"),Ktr=l(),p0=a("li"),m1e=a("strong"),Ztr=o("convbert"),ear=o(" \u2014 "),yU=a("a"),oar=o("ConvBertForMultipleChoice"),rar=o(" (ConvBERT model)"),tar=l(),_0=a("li"),g1e=a("strong"),aar=o("data2vec-text"),nar=o(" \u2014 "),xU=a("a"),sar=o("Data2VecTextForMultipleChoice"),lar=o(" (Data2VecText model)"),iar=l(),v0=a("li"),h1e=a("strong"),dar=o("deberta-v2"),car=o(" \u2014 "),$U=a("a"),far=o("DebertaV2ForMultipleChoice"),mar=o(" (DeBERTa-v2 model)"),gar=l(),b0=a("li"),u1e=a("strong"),har=o("distilbert"),uar=o(" \u2014 "),kU=a("a"),par=o("DistilBertForMultipleChoice"),_ar=o(" (DistilBERT model)"),bar=l(),F0=a("li"),p1e=a("strong"),Far=o("electra"),Tar=o(" \u2014 "),SU=a("a"),Mar=o("ElectraForMultipleChoice"),Ear=o(" (ELECTRA model)"),Car=l(),T0=a("li"),_1e=a("strong"),war=o("ernie"),Aar=o(" \u2014 "),RU=a("a"),Lar=o("ErnieForMultipleChoice"),yar=o(" (ERNIE model)"),xar=l(),M0=a("li"),v1e=a("strong"),$ar=o("flaubert"),kar=o(" \u2014 "),PU=a("a"),Sar=o("FlaubertForMultipleChoice"),Rar=o(" (FlauBERT model)"),Par=l(),E0=a("li"),b1e=a("strong"),Bar=o("fnet"),Iar=o(" \u2014 "),BU=a("a"),Nar=o("FNetForMultipleChoice"),qar=o(" (FNet model)"),jar=l(),C0=a("li"),F1e=a("strong"),Dar=o("funnel"),Gar=o(" \u2014 "),IU=a("a"),Oar=o("FunnelForMultipleChoice"),Var=o(" (Funnel Transformer model)"),Xar=l(),w0=a("li"),T1e=a("strong"),zar=o("ibert"),Qar=o(" \u2014 "),NU=a("a"),War=o("IBertForMultipleChoice"),Uar=o(" (I-BERT model)"),Har=l(),A0=a("li"),M1e=a("strong"),Jar=o("longformer"),Yar=o(" \u2014 "),qU=a("a"),Kar=o("LongformerForMultipleChoice"),Zar=o(" (Longformer model)"),enr=l(),L0=a("li"),E1e=a("strong"),onr=o("luke"),rnr=o(" \u2014 "),jU=a("a"),tnr=o("LukeForMultipleChoice"),anr=o(" (LUKE model)"),nnr=l(),y0=a("li"),C1e=a("strong"),snr=o("megatron-bert"),lnr=o(" \u2014 "),DU=a("a"),inr=o("MegatronBertForMultipleChoice"),dnr=o(" (Megatron-BERT model)"),cnr=l(),x0=a("li"),w1e=a("strong"),fnr=o("mobilebert"),mnr=o(" \u2014 "),GU=a("a"),gnr=o("MobileBertForMultipleChoice"),hnr=o(" (MobileBERT model)"),unr=l(),$0=a("li"),A1e=a("strong"),pnr=o("mpnet"),_nr=o(" \u2014 "),OU=a("a"),vnr=o("MPNetForMultipleChoice"),bnr=o(" (MPNet model)"),Fnr=l(),k0=a("li"),L1e=a("strong"),Tnr=o("nezha"),Mnr=o(" \u2014 "),VU=a("a"),Enr=o("NezhaForMultipleChoice"),Cnr=o(" (Nezha model)"),wnr=l(),S0=a("li"),y1e=a("strong"),Anr=o("nystromformer"),Lnr=o(" \u2014 "),XU=a("a"),ynr=o("NystromformerForMultipleChoice"),xnr=o(" (Nystr\xF6mformer model)"),$nr=l(),R0=a("li"),x1e=a("strong"),knr=o("qdqbert"),Snr=o(" \u2014 "),zU=a("a"),Rnr=o("QDQBertForMultipleChoice"),Pnr=o(" (QDQBert model)"),Bnr=l(),P0=a("li"),$1e=a("strong"),Inr=o("rembert"),Nnr=o(" \u2014 "),QU=a("a"),qnr=o("RemBertForMultipleChoice"),jnr=o(" (RemBERT model)"),Dnr=l(),B0=a("li"),k1e=a("strong"),Gnr=o("roberta"),Onr=o(" \u2014 "),WU=a("a"),Vnr=o("RobertaForMultipleChoice"),Xnr=o(" (RoBERTa model)"),znr=l(),I0=a("li"),S1e=a("strong"),Qnr=o("roformer"),Wnr=o(" \u2014 "),UU=a("a"),Unr=o("RoFormerForMultipleChoice"),Hnr=o(" (RoFormer model)"),Jnr=l(),N0=a("li"),R1e=a("strong"),Ynr=o("squeezebert"),Knr=o(" \u2014 "),HU=a("a"),Znr=o("SqueezeBertForMultipleChoice"),esr=o(" (SqueezeBERT model)"),osr=l(),q0=a("li"),P1e=a("strong"),rsr=o("xlm"),tsr=o(" \u2014 "),JU=a("a"),asr=o("XLMForMultipleChoice"),nsr=o(" (XLM model)"),ssr=l(),j0=a("li"),B1e=a("strong"),lsr=o("xlm-roberta"),isr=o(" \u2014 "),YU=a("a"),dsr=o("XLMRobertaForMultipleChoice"),csr=o(" (XLM-RoBERTa model)"),fsr=l(),D0=a("li"),I1e=a("strong"),msr=o("xlm-roberta-xl"),gsr=o(" \u2014 "),KU=a("a"),hsr=o("XLMRobertaXLForMultipleChoice"),usr=o(" (XLM-RoBERTa-XL model)"),psr=l(),G0=a("li"),N1e=a("strong"),_sr=o("xlnet"),vsr=o(" \u2014 "),ZU=a("a"),bsr=o("XLNetForMultipleChoice"),Fsr=o(" (XLNet model)"),Tsr=l(),O0=a("li"),q1e=a("strong"),Msr=o("yoso"),Esr=o(" \u2014 "),eH=a("a"),Csr=o("YosoForMultipleChoice"),wsr=o(" (YOSO model)"),Asr=l(),V0=a("p"),Lsr=o("The model is set in evaluation mode by default using "),j1e=a("code"),ysr=o("model.eval()"),xsr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D1e=a("code"),$sr=o("model.train()"),ksr=l(),F(X0.$$.fragment),aKe=l(),Nd=a("h2"),z0=a("a"),G1e=a("span"),F($x.$$.fragment),Ssr=l(),O1e=a("span"),Rsr=o("AutoModelForNextSentencePrediction"),nKe=l(),Go=a("div"),F(kx.$$.fragment),Psr=l(),qd=a("p"),Bsr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),oH=a("a"),Isr=o("from_pretrained()"),Nsr=o(" class method or the "),rH=a("a"),qsr=o("from_config()"),jsr=o(` class
method.`),Dsr=l(),Sx=a("p"),Gsr=o("This class cannot be instantiated directly using "),V1e=a("code"),Osr=o("__init__()"),Vsr=o(" (throws an error)."),Xsr=l(),Ct=a("div"),F(Rx.$$.fragment),zsr=l(),X1e=a("p"),Qsr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Wsr=l(),jd=a("p"),Usr=o(`Note:
Loading a model from its configuration file does `),z1e=a("strong"),Hsr=o("not"),Jsr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tH=a("a"),Ysr=o("from_pretrained()"),Ksr=o(" to load the model weights."),Zsr=l(),F(Q0.$$.fragment),elr=l(),so=a("div"),F(Px.$$.fragment),olr=l(),Q1e=a("p"),rlr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),tlr=l(),tn=a("p"),alr=o("The model class to instantiate is selected based on the "),W1e=a("code"),nlr=o("model_type"),slr=o(` property of the config object (either
passed as an argument or loaded from `),U1e=a("code"),llr=o("pretrained_model_name_or_path"),ilr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H1e=a("code"),dlr=o("pretrained_model_name_or_path"),clr=o(":"),flr=l(),Ue=a("ul"),W0=a("li"),J1e=a("strong"),mlr=o("bert"),glr=o(" \u2014 "),aH=a("a"),hlr=o("BertForNextSentencePrediction"),ulr=o(" (BERT model)"),plr=l(),U0=a("li"),Y1e=a("strong"),_lr=o("ernie"),vlr=o(" \u2014 "),nH=a("a"),blr=o("ErnieForNextSentencePrediction"),Flr=o(" (ERNIE model)"),Tlr=l(),H0=a("li"),K1e=a("strong"),Mlr=o("fnet"),Elr=o(" \u2014 "),sH=a("a"),Clr=o("FNetForNextSentencePrediction"),wlr=o(" (FNet model)"),Alr=l(),J0=a("li"),Z1e=a("strong"),Llr=o("megatron-bert"),ylr=o(" \u2014 "),lH=a("a"),xlr=o("MegatronBertForNextSentencePrediction"),$lr=o(" (Megatron-BERT model)"),klr=l(),Y0=a("li"),e0e=a("strong"),Slr=o("mobilebert"),Rlr=o(" \u2014 "),iH=a("a"),Plr=o("MobileBertForNextSentencePrediction"),Blr=o(" (MobileBERT model)"),Ilr=l(),K0=a("li"),o0e=a("strong"),Nlr=o("nezha"),qlr=o(" \u2014 "),dH=a("a"),jlr=o("NezhaForNextSentencePrediction"),Dlr=o(" (Nezha model)"),Glr=l(),Z0=a("li"),r0e=a("strong"),Olr=o("qdqbert"),Vlr=o(" \u2014 "),cH=a("a"),Xlr=o("QDQBertForNextSentencePrediction"),zlr=o(" (QDQBert model)"),Qlr=l(),eF=a("p"),Wlr=o("The model is set in evaluation mode by default using "),t0e=a("code"),Ulr=o("model.eval()"),Hlr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a0e=a("code"),Jlr=o("model.train()"),Ylr=l(),F(oF.$$.fragment),sKe=l(),Dd=a("h2"),rF=a("a"),n0e=a("span"),F(Bx.$$.fragment),Klr=l(),s0e=a("span"),Zlr=o("AutoModelForTokenClassification"),lKe=l(),Oo=a("div"),F(Ix.$$.fragment),eir=l(),Gd=a("p"),oir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),fH=a("a"),rir=o("from_pretrained()"),tir=o(" class method or the "),mH=a("a"),air=o("from_config()"),nir=o(` class
method.`),sir=l(),Nx=a("p"),lir=o("This class cannot be instantiated directly using "),l0e=a("code"),iir=o("__init__()"),dir=o(" (throws an error)."),cir=l(),wt=a("div"),F(qx.$$.fragment),fir=l(),i0e=a("p"),mir=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),gir=l(),Od=a("p"),hir=o(`Note:
Loading a model from its configuration file does `),d0e=a("strong"),uir=o("not"),pir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gH=a("a"),_ir=o("from_pretrained()"),vir=o(" to load the model weights."),bir=l(),F(tF.$$.fragment),Fir=l(),lo=a("div"),F(jx.$$.fragment),Tir=l(),c0e=a("p"),Mir=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Eir=l(),an=a("p"),Cir=o("The model class to instantiate is selected based on the "),f0e=a("code"),wir=o("model_type"),Air=o(` property of the config object (either
passed as an argument or loaded from `),m0e=a("code"),Lir=o("pretrained_model_name_or_path"),yir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g0e=a("code"),xir=o("pretrained_model_name_or_path"),$ir=o(":"),kir=l(),H=a("ul"),aF=a("li"),h0e=a("strong"),Sir=o("albert"),Rir=o(" \u2014 "),hH=a("a"),Pir=o("AlbertForTokenClassification"),Bir=o(" (ALBERT model)"),Iir=l(),nF=a("li"),u0e=a("strong"),Nir=o("bert"),qir=o(" \u2014 "),uH=a("a"),jir=o("BertForTokenClassification"),Dir=o(" (BERT model)"),Gir=l(),sF=a("li"),p0e=a("strong"),Oir=o("big_bird"),Vir=o(" \u2014 "),pH=a("a"),Xir=o("BigBirdForTokenClassification"),zir=o(" (BigBird model)"),Qir=l(),lF=a("li"),_0e=a("strong"),Wir=o("bloom"),Uir=o(" \u2014 "),_H=a("a"),Hir=o("BloomForTokenClassification"),Jir=o(" (BLOOM model)"),Yir=l(),iF=a("li"),v0e=a("strong"),Kir=o("camembert"),Zir=o(" \u2014 "),vH=a("a"),edr=o("CamembertForTokenClassification"),odr=o(" (CamemBERT model)"),rdr=l(),dF=a("li"),b0e=a("strong"),tdr=o("canine"),adr=o(" \u2014 "),bH=a("a"),ndr=o("CanineForTokenClassification"),sdr=o(" (CANINE model)"),ldr=l(),cF=a("li"),F0e=a("strong"),idr=o("convbert"),ddr=o(" \u2014 "),FH=a("a"),cdr=o("ConvBertForTokenClassification"),fdr=o(" (ConvBERT model)"),mdr=l(),fF=a("li"),T0e=a("strong"),gdr=o("data2vec-text"),hdr=o(" \u2014 "),TH=a("a"),udr=o("Data2VecTextForTokenClassification"),pdr=o(" (Data2VecText model)"),_dr=l(),mF=a("li"),M0e=a("strong"),vdr=o("deberta"),bdr=o(" \u2014 "),MH=a("a"),Fdr=o("DebertaForTokenClassification"),Tdr=o(" (DeBERTa model)"),Mdr=l(),gF=a("li"),E0e=a("strong"),Edr=o("deberta-v2"),Cdr=o(" \u2014 "),EH=a("a"),wdr=o("DebertaV2ForTokenClassification"),Adr=o(" (DeBERTa-v2 model)"),Ldr=l(),hF=a("li"),C0e=a("strong"),ydr=o("distilbert"),xdr=o(" \u2014 "),CH=a("a"),$dr=o("DistilBertForTokenClassification"),kdr=o(" (DistilBERT model)"),Sdr=l(),uF=a("li"),w0e=a("strong"),Rdr=o("electra"),Pdr=o(" \u2014 "),wH=a("a"),Bdr=o("ElectraForTokenClassification"),Idr=o(" (ELECTRA model)"),Ndr=l(),pF=a("li"),A0e=a("strong"),qdr=o("ernie"),jdr=o(" \u2014 "),AH=a("a"),Ddr=o("ErnieForTokenClassification"),Gdr=o(" (ERNIE model)"),Odr=l(),_F=a("li"),L0e=a("strong"),Vdr=o("flaubert"),Xdr=o(" \u2014 "),LH=a("a"),zdr=o("FlaubertForTokenClassification"),Qdr=o(" (FlauBERT model)"),Wdr=l(),vF=a("li"),y0e=a("strong"),Udr=o("fnet"),Hdr=o(" \u2014 "),yH=a("a"),Jdr=o("FNetForTokenClassification"),Ydr=o(" (FNet model)"),Kdr=l(),bF=a("li"),x0e=a("strong"),Zdr=o("funnel"),ecr=o(" \u2014 "),xH=a("a"),ocr=o("FunnelForTokenClassification"),rcr=o(" (Funnel Transformer model)"),tcr=l(),FF=a("li"),$0e=a("strong"),acr=o("gpt2"),ncr=o(" \u2014 "),$H=a("a"),scr=o("GPT2ForTokenClassification"),lcr=o(" (OpenAI GPT-2 model)"),icr=l(),TF=a("li"),k0e=a("strong"),dcr=o("ibert"),ccr=o(" \u2014 "),kH=a("a"),fcr=o("IBertForTokenClassification"),mcr=o(" (I-BERT model)"),gcr=l(),MF=a("li"),S0e=a("strong"),hcr=o("layoutlm"),ucr=o(" \u2014 "),SH=a("a"),pcr=o("LayoutLMForTokenClassification"),_cr=o(" (LayoutLM model)"),vcr=l(),EF=a("li"),R0e=a("strong"),bcr=o("layoutlmv2"),Fcr=o(" \u2014 "),RH=a("a"),Tcr=o("LayoutLMv2ForTokenClassification"),Mcr=o(" (LayoutLMv2 model)"),Ecr=l(),CF=a("li"),P0e=a("strong"),Ccr=o("layoutlmv3"),wcr=o(" \u2014 "),PH=a("a"),Acr=o("LayoutLMv3ForTokenClassification"),Lcr=o(" (LayoutLMv3 model)"),ycr=l(),wF=a("li"),B0e=a("strong"),xcr=o("longformer"),$cr=o(" \u2014 "),BH=a("a"),kcr=o("LongformerForTokenClassification"),Scr=o(" (Longformer model)"),Rcr=l(),AF=a("li"),I0e=a("strong"),Pcr=o("luke"),Bcr=o(" \u2014 "),IH=a("a"),Icr=o("LukeForTokenClassification"),Ncr=o(" (LUKE model)"),qcr=l(),LF=a("li"),N0e=a("strong"),jcr=o("megatron-bert"),Dcr=o(" \u2014 "),NH=a("a"),Gcr=o("MegatronBertForTokenClassification"),Ocr=o(" (Megatron-BERT model)"),Vcr=l(),yF=a("li"),q0e=a("strong"),Xcr=o("mobilebert"),zcr=o(" \u2014 "),qH=a("a"),Qcr=o("MobileBertForTokenClassification"),Wcr=o(" (MobileBERT model)"),Ucr=l(),xF=a("li"),j0e=a("strong"),Hcr=o("mpnet"),Jcr=o(" \u2014 "),jH=a("a"),Ycr=o("MPNetForTokenClassification"),Kcr=o(" (MPNet model)"),Zcr=l(),$F=a("li"),D0e=a("strong"),efr=o("nezha"),ofr=o(" \u2014 "),DH=a("a"),rfr=o("NezhaForTokenClassification"),tfr=o(" (Nezha model)"),afr=l(),kF=a("li"),G0e=a("strong"),nfr=o("nystromformer"),sfr=o(" \u2014 "),GH=a("a"),lfr=o("NystromformerForTokenClassification"),ifr=o(" (Nystr\xF6mformer model)"),dfr=l(),SF=a("li"),O0e=a("strong"),cfr=o("qdqbert"),ffr=o(" \u2014 "),OH=a("a"),mfr=o("QDQBertForTokenClassification"),gfr=o(" (QDQBert model)"),hfr=l(),RF=a("li"),V0e=a("strong"),ufr=o("rembert"),pfr=o(" \u2014 "),VH=a("a"),_fr=o("RemBertForTokenClassification"),vfr=o(" (RemBERT model)"),bfr=l(),PF=a("li"),X0e=a("strong"),Ffr=o("roberta"),Tfr=o(" \u2014 "),XH=a("a"),Mfr=o("RobertaForTokenClassification"),Efr=o(" (RoBERTa model)"),Cfr=l(),BF=a("li"),z0e=a("strong"),wfr=o("roformer"),Afr=o(" \u2014 "),zH=a("a"),Lfr=o("RoFormerForTokenClassification"),yfr=o(" (RoFormer model)"),xfr=l(),IF=a("li"),Q0e=a("strong"),$fr=o("squeezebert"),kfr=o(" \u2014 "),QH=a("a"),Sfr=o("SqueezeBertForTokenClassification"),Rfr=o(" (SqueezeBERT model)"),Pfr=l(),NF=a("li"),W0e=a("strong"),Bfr=o("xlm"),Ifr=o(" \u2014 "),WH=a("a"),Nfr=o("XLMForTokenClassification"),qfr=o(" (XLM model)"),jfr=l(),qF=a("li"),U0e=a("strong"),Dfr=o("xlm-roberta"),Gfr=o(" \u2014 "),UH=a("a"),Ofr=o("XLMRobertaForTokenClassification"),Vfr=o(" (XLM-RoBERTa model)"),Xfr=l(),jF=a("li"),H0e=a("strong"),zfr=o("xlm-roberta-xl"),Qfr=o(" \u2014 "),HH=a("a"),Wfr=o("XLMRobertaXLForTokenClassification"),Ufr=o(" (XLM-RoBERTa-XL model)"),Hfr=l(),DF=a("li"),J0e=a("strong"),Jfr=o("xlnet"),Yfr=o(" \u2014 "),JH=a("a"),Kfr=o("XLNetForTokenClassification"),Zfr=o(" (XLNet model)"),emr=l(),GF=a("li"),Y0e=a("strong"),omr=o("yoso"),rmr=o(" \u2014 "),YH=a("a"),tmr=o("YosoForTokenClassification"),amr=o(" (YOSO model)"),nmr=l(),OF=a("p"),smr=o("The model is set in evaluation mode by default using "),K0e=a("code"),lmr=o("model.eval()"),imr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z0e=a("code"),dmr=o("model.train()"),cmr=l(),F(VF.$$.fragment),iKe=l(),Vd=a("h2"),XF=a("a"),eFe=a("span"),F(Dx.$$.fragment),fmr=l(),oFe=a("span"),mmr=o("AutoModelForQuestionAnswering"),dKe=l(),Vo=a("div"),F(Gx.$$.fragment),gmr=l(),Xd=a("p"),hmr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),KH=a("a"),umr=o("from_pretrained()"),pmr=o(" class method or the "),ZH=a("a"),_mr=o("from_config()"),vmr=o(` class
method.`),bmr=l(),Ox=a("p"),Fmr=o("This class cannot be instantiated directly using "),rFe=a("code"),Tmr=o("__init__()"),Mmr=o(" (throws an error)."),Emr=l(),At=a("div"),F(Vx.$$.fragment),Cmr=l(),tFe=a("p"),wmr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Amr=l(),zd=a("p"),Lmr=o(`Note:
Loading a model from its configuration file does `),aFe=a("strong"),ymr=o("not"),xmr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eJ=a("a"),$mr=o("from_pretrained()"),kmr=o(" to load the model weights."),Smr=l(),F(zF.$$.fragment),Rmr=l(),io=a("div"),F(Xx.$$.fragment),Pmr=l(),nFe=a("p"),Bmr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Imr=l(),nn=a("p"),Nmr=o("The model class to instantiate is selected based on the "),sFe=a("code"),qmr=o("model_type"),jmr=o(` property of the config object (either
passed as an argument or loaded from `),lFe=a("code"),Dmr=o("pretrained_model_name_or_path"),Gmr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iFe=a("code"),Omr=o("pretrained_model_name_or_path"),Vmr=o(":"),Xmr=l(),V=a("ul"),QF=a("li"),dFe=a("strong"),zmr=o("albert"),Qmr=o(" \u2014 "),oJ=a("a"),Wmr=o("AlbertForQuestionAnswering"),Umr=o(" (ALBERT model)"),Hmr=l(),WF=a("li"),cFe=a("strong"),Jmr=o("bart"),Ymr=o(" \u2014 "),rJ=a("a"),Kmr=o("BartForQuestionAnswering"),Zmr=o(" (BART model)"),egr=l(),UF=a("li"),fFe=a("strong"),ogr=o("bert"),rgr=o(" \u2014 "),tJ=a("a"),tgr=o("BertForQuestionAnswering"),agr=o(" (BERT model)"),ngr=l(),HF=a("li"),mFe=a("strong"),sgr=o("big_bird"),lgr=o(" \u2014 "),aJ=a("a"),igr=o("BigBirdForQuestionAnswering"),dgr=o(" (BigBird model)"),cgr=l(),JF=a("li"),gFe=a("strong"),fgr=o("bigbird_pegasus"),mgr=o(" \u2014 "),nJ=a("a"),ggr=o("BigBirdPegasusForQuestionAnswering"),hgr=o(" (BigBird-Pegasus model)"),ugr=l(),YF=a("li"),hFe=a("strong"),pgr=o("camembert"),_gr=o(" \u2014 "),sJ=a("a"),vgr=o("CamembertForQuestionAnswering"),bgr=o(" (CamemBERT model)"),Fgr=l(),KF=a("li"),uFe=a("strong"),Tgr=o("canine"),Mgr=o(" \u2014 "),lJ=a("a"),Egr=o("CanineForQuestionAnswering"),Cgr=o(" (CANINE model)"),wgr=l(),ZF=a("li"),pFe=a("strong"),Agr=o("convbert"),Lgr=o(" \u2014 "),iJ=a("a"),ygr=o("ConvBertForQuestionAnswering"),xgr=o(" (ConvBERT model)"),$gr=l(),eT=a("li"),_Fe=a("strong"),kgr=o("data2vec-text"),Sgr=o(" \u2014 "),dJ=a("a"),Rgr=o("Data2VecTextForQuestionAnswering"),Pgr=o(" (Data2VecText model)"),Bgr=l(),oT=a("li"),vFe=a("strong"),Igr=o("deberta"),Ngr=o(" \u2014 "),cJ=a("a"),qgr=o("DebertaForQuestionAnswering"),jgr=o(" (DeBERTa model)"),Dgr=l(),rT=a("li"),bFe=a("strong"),Ggr=o("deberta-v2"),Ogr=o(" \u2014 "),fJ=a("a"),Vgr=o("DebertaV2ForQuestionAnswering"),Xgr=o(" (DeBERTa-v2 model)"),zgr=l(),tT=a("li"),FFe=a("strong"),Qgr=o("distilbert"),Wgr=o(" \u2014 "),mJ=a("a"),Ugr=o("DistilBertForQuestionAnswering"),Hgr=o(" (DistilBERT model)"),Jgr=l(),aT=a("li"),TFe=a("strong"),Ygr=o("electra"),Kgr=o(" \u2014 "),gJ=a("a"),Zgr=o("ElectraForQuestionAnswering"),ehr=o(" (ELECTRA model)"),ohr=l(),nT=a("li"),MFe=a("strong"),rhr=o("ernie"),thr=o(" \u2014 "),hJ=a("a"),ahr=o("ErnieForQuestionAnswering"),nhr=o(" (ERNIE model)"),shr=l(),sT=a("li"),EFe=a("strong"),lhr=o("flaubert"),ihr=o(" \u2014 "),uJ=a("a"),dhr=o("FlaubertForQuestionAnsweringSimple"),chr=o(" (FlauBERT model)"),fhr=l(),lT=a("li"),CFe=a("strong"),mhr=o("fnet"),ghr=o(" \u2014 "),pJ=a("a"),hhr=o("FNetForQuestionAnswering"),uhr=o(" (FNet model)"),phr=l(),iT=a("li"),wFe=a("strong"),_hr=o("funnel"),vhr=o(" \u2014 "),_J=a("a"),bhr=o("FunnelForQuestionAnswering"),Fhr=o(" (Funnel Transformer model)"),Thr=l(),dT=a("li"),AFe=a("strong"),Mhr=o("gptj"),Ehr=o(" \u2014 "),vJ=a("a"),Chr=o("GPTJForQuestionAnswering"),whr=o(" (GPT-J model)"),Ahr=l(),cT=a("li"),LFe=a("strong"),Lhr=o("ibert"),yhr=o(" \u2014 "),bJ=a("a"),xhr=o("IBertForQuestionAnswering"),$hr=o(" (I-BERT model)"),khr=l(),fT=a("li"),yFe=a("strong"),Shr=o("layoutlmv2"),Rhr=o(" \u2014 "),FJ=a("a"),Phr=o("LayoutLMv2ForQuestionAnswering"),Bhr=o(" (LayoutLMv2 model)"),Ihr=l(),mT=a("li"),xFe=a("strong"),Nhr=o("layoutlmv3"),qhr=o(" \u2014 "),TJ=a("a"),jhr=o("LayoutLMv3ForQuestionAnswering"),Dhr=o(" (LayoutLMv3 model)"),Ghr=l(),gT=a("li"),$Fe=a("strong"),Ohr=o("led"),Vhr=o(" \u2014 "),MJ=a("a"),Xhr=o("LEDForQuestionAnswering"),zhr=o(" (LED model)"),Qhr=l(),hT=a("li"),kFe=a("strong"),Whr=o("longformer"),Uhr=o(" \u2014 "),EJ=a("a"),Hhr=o("LongformerForQuestionAnswering"),Jhr=o(" (Longformer model)"),Yhr=l(),uT=a("li"),SFe=a("strong"),Khr=o("luke"),Zhr=o(" \u2014 "),CJ=a("a"),eur=o("LukeForQuestionAnswering"),our=o(" (LUKE model)"),rur=l(),pT=a("li"),RFe=a("strong"),tur=o("lxmert"),aur=o(" \u2014 "),wJ=a("a"),nur=o("LxmertForQuestionAnswering"),sur=o(" (LXMERT model)"),lur=l(),_T=a("li"),PFe=a("strong"),iur=o("mbart"),dur=o(" \u2014 "),AJ=a("a"),cur=o("MBartForQuestionAnswering"),fur=o(" (mBART model)"),mur=l(),vT=a("li"),BFe=a("strong"),gur=o("megatron-bert"),hur=o(" \u2014 "),LJ=a("a"),uur=o("MegatronBertForQuestionAnswering"),pur=o(" (Megatron-BERT model)"),_ur=l(),bT=a("li"),IFe=a("strong"),vur=o("mobilebert"),bur=o(" \u2014 "),yJ=a("a"),Fur=o("MobileBertForQuestionAnswering"),Tur=o(" (MobileBERT model)"),Mur=l(),FT=a("li"),NFe=a("strong"),Eur=o("mpnet"),Cur=o(" \u2014 "),xJ=a("a"),wur=o("MPNetForQuestionAnswering"),Aur=o(" (MPNet model)"),Lur=l(),TT=a("li"),qFe=a("strong"),yur=o("mvp"),xur=o(" \u2014 "),$J=a("a"),$ur=o("MvpForQuestionAnswering"),kur=o(" (MVP model)"),Sur=l(),MT=a("li"),jFe=a("strong"),Rur=o("nezha"),Pur=o(" \u2014 "),kJ=a("a"),Bur=o("NezhaForQuestionAnswering"),Iur=o(" (Nezha model)"),Nur=l(),ET=a("li"),DFe=a("strong"),qur=o("nystromformer"),jur=o(" \u2014 "),SJ=a("a"),Dur=o("NystromformerForQuestionAnswering"),Gur=o(" (Nystr\xF6mformer model)"),Our=l(),CT=a("li"),GFe=a("strong"),Vur=o("qdqbert"),Xur=o(" \u2014 "),RJ=a("a"),zur=o("QDQBertForQuestionAnswering"),Qur=o(" (QDQBert model)"),Wur=l(),wT=a("li"),OFe=a("strong"),Uur=o("reformer"),Hur=o(" \u2014 "),PJ=a("a"),Jur=o("ReformerForQuestionAnswering"),Yur=o(" (Reformer model)"),Kur=l(),AT=a("li"),VFe=a("strong"),Zur=o("rembert"),epr=o(" \u2014 "),BJ=a("a"),opr=o("RemBertForQuestionAnswering"),rpr=o(" (RemBERT model)"),tpr=l(),LT=a("li"),XFe=a("strong"),apr=o("roberta"),npr=o(" \u2014 "),IJ=a("a"),spr=o("RobertaForQuestionAnswering"),lpr=o(" (RoBERTa model)"),ipr=l(),yT=a("li"),zFe=a("strong"),dpr=o("roformer"),cpr=o(" \u2014 "),NJ=a("a"),fpr=o("RoFormerForQuestionAnswering"),mpr=o(" (RoFormer model)"),gpr=l(),xT=a("li"),QFe=a("strong"),hpr=o("splinter"),upr=o(" \u2014 "),qJ=a("a"),ppr=o("SplinterForQuestionAnswering"),_pr=o(" (Splinter model)"),vpr=l(),$T=a("li"),WFe=a("strong"),bpr=o("squeezebert"),Fpr=o(" \u2014 "),jJ=a("a"),Tpr=o("SqueezeBertForQuestionAnswering"),Mpr=o(" (SqueezeBERT model)"),Epr=l(),kT=a("li"),UFe=a("strong"),Cpr=o("xlm"),wpr=o(" \u2014 "),DJ=a("a"),Apr=o("XLMForQuestionAnsweringSimple"),Lpr=o(" (XLM model)"),ypr=l(),ST=a("li"),HFe=a("strong"),xpr=o("xlm-roberta"),$pr=o(" \u2014 "),GJ=a("a"),kpr=o("XLMRobertaForQuestionAnswering"),Spr=o(" (XLM-RoBERTa model)"),Rpr=l(),RT=a("li"),JFe=a("strong"),Ppr=o("xlm-roberta-xl"),Bpr=o(" \u2014 "),OJ=a("a"),Ipr=o("XLMRobertaXLForQuestionAnswering"),Npr=o(" (XLM-RoBERTa-XL model)"),qpr=l(),PT=a("li"),YFe=a("strong"),jpr=o("xlnet"),Dpr=o(" \u2014 "),VJ=a("a"),Gpr=o("XLNetForQuestionAnsweringSimple"),Opr=o(" (XLNet model)"),Vpr=l(),BT=a("li"),KFe=a("strong"),Xpr=o("yoso"),zpr=o(" \u2014 "),XJ=a("a"),Qpr=o("YosoForQuestionAnswering"),Wpr=o(" (YOSO model)"),Upr=l(),IT=a("p"),Hpr=o("The model is set in evaluation mode by default using "),ZFe=a("code"),Jpr=o("model.eval()"),Ypr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),eTe=a("code"),Kpr=o("model.train()"),Zpr=l(),F(NT.$$.fragment),cKe=l(),Qd=a("h2"),qT=a("a"),oTe=a("span"),F(zx.$$.fragment),e_r=l(),rTe=a("span"),o_r=o("AutoModelForTableQuestionAnswering"),fKe=l(),Xo=a("div"),F(Qx.$$.fragment),r_r=l(),Wd=a("p"),t_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),zJ=a("a"),a_r=o("from_pretrained()"),n_r=o(" class method or the "),QJ=a("a"),s_r=o("from_config()"),l_r=o(` class
method.`),i_r=l(),Wx=a("p"),d_r=o("This class cannot be instantiated directly using "),tTe=a("code"),c_r=o("__init__()"),f_r=o(" (throws an error)."),m_r=l(),Lt=a("div"),F(Ux.$$.fragment),g_r=l(),aTe=a("p"),h_r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),u_r=l(),Ud=a("p"),p_r=o(`Note:
Loading a model from its configuration file does `),nTe=a("strong"),__r=o("not"),v_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WJ=a("a"),b_r=o("from_pretrained()"),F_r=o(" to load the model weights."),T_r=l(),F(jT.$$.fragment),M_r=l(),co=a("div"),F(Hx.$$.fragment),E_r=l(),sTe=a("p"),C_r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),w_r=l(),sn=a("p"),A_r=o("The model class to instantiate is selected based on the "),lTe=a("code"),L_r=o("model_type"),y_r=o(` property of the config object (either
passed as an argument or loaded from `),iTe=a("code"),x_r=o("pretrained_model_name_or_path"),$_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dTe=a("code"),k_r=o("pretrained_model_name_or_path"),S_r=o(":"),R_r=l(),cTe=a("ul"),DT=a("li"),fTe=a("strong"),P_r=o("tapas"),B_r=o(" \u2014 "),UJ=a("a"),I_r=o("TapasForQuestionAnswering"),N_r=o(" (TAPAS model)"),q_r=l(),GT=a("p"),j_r=o("The model is set in evaluation mode by default using "),mTe=a("code"),D_r=o("model.eval()"),G_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gTe=a("code"),O_r=o("model.train()"),V_r=l(),F(OT.$$.fragment),mKe=l(),Hd=a("h2"),VT=a("a"),hTe=a("span"),F(Jx.$$.fragment),X_r=l(),uTe=a("span"),z_r=o("AutoModelForDocumentQuestionAnswering"),gKe=l(),zo=a("div"),F(Yx.$$.fragment),Q_r=l(),Jd=a("p"),W_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),HJ=a("a"),U_r=o("from_pretrained()"),H_r=o(" class method or the "),JJ=a("a"),J_r=o("from_config()"),Y_r=o(` class
method.`),K_r=l(),Kx=a("p"),Z_r=o("This class cannot be instantiated directly using "),pTe=a("code"),e2r=o("__init__()"),o2r=o(" (throws an error)."),r2r=l(),yt=a("div"),F(Zx.$$.fragment),t2r=l(),_Te=a("p"),a2r=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),n2r=l(),Yd=a("p"),s2r=o(`Note:
Loading a model from its configuration file does `),vTe=a("strong"),l2r=o("not"),i2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YJ=a("a"),d2r=o("from_pretrained()"),c2r=o(" to load the model weights."),f2r=l(),F(XT.$$.fragment),m2r=l(),fo=a("div"),F(e$.$$.fragment),g2r=l(),bTe=a("p"),h2r=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),u2r=l(),ln=a("p"),p2r=o("The model class to instantiate is selected based on the "),FTe=a("code"),_2r=o("model_type"),v2r=o(` property of the config object (either
passed as an argument or loaded from `),TTe=a("code"),b2r=o("pretrained_model_name_or_path"),F2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MTe=a("code"),T2r=o("pretrained_model_name_or_path"),M2r=o(":"),E2r=l(),Kd=a("ul"),zT=a("li"),ETe=a("strong"),C2r=o("layoutlm"),w2r=o(" \u2014 "),KJ=a("a"),A2r=o("LayoutLMForQuestionAnswering"),L2r=o(" (LayoutLM model)"),y2r=l(),QT=a("li"),CTe=a("strong"),x2r=o("layoutlmv2"),$2r=o(" \u2014 "),ZJ=a("a"),k2r=o("LayoutLMv2ForQuestionAnswering"),S2r=o(" (LayoutLMv2 model)"),R2r=l(),WT=a("li"),wTe=a("strong"),P2r=o("layoutlmv3"),B2r=o(" \u2014 "),eY=a("a"),I2r=o("LayoutLMv3ForQuestionAnswering"),N2r=o(" (LayoutLMv3 model)"),q2r=l(),UT=a("p"),j2r=o("The model is set in evaluation mode by default using "),ATe=a("code"),D2r=o("model.eval()"),G2r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LTe=a("code"),O2r=o("model.train()"),V2r=l(),F(HT.$$.fragment),hKe=l(),Zd=a("h2"),JT=a("a"),yTe=a("span"),F(o$.$$.fragment),X2r=l(),xTe=a("span"),z2r=o("AutoModelForImageClassification"),uKe=l(),Qo=a("div"),F(r$.$$.fragment),Q2r=l(),ec=a("p"),W2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),oY=a("a"),U2r=o("from_pretrained()"),H2r=o(" class method or the "),rY=a("a"),J2r=o("from_config()"),Y2r=o(` class
method.`),K2r=l(),t$=a("p"),Z2r=o("This class cannot be instantiated directly using "),$Te=a("code"),evr=o("__init__()"),ovr=o(" (throws an error)."),rvr=l(),xt=a("div"),F(a$.$$.fragment),tvr=l(),kTe=a("p"),avr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),nvr=l(),oc=a("p"),svr=o(`Note:
Loading a model from its configuration file does `),STe=a("strong"),lvr=o("not"),ivr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tY=a("a"),dvr=o("from_pretrained()"),cvr=o(" to load the model weights."),fvr=l(),F(YT.$$.fragment),mvr=l(),mo=a("div"),F(n$.$$.fragment),gvr=l(),RTe=a("p"),hvr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),uvr=l(),dn=a("p"),pvr=o("The model class to instantiate is selected based on the "),PTe=a("code"),_vr=o("model_type"),vvr=o(` property of the config object (either
passed as an argument or loaded from `),BTe=a("code"),bvr=o("pretrained_model_name_or_path"),Fvr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ITe=a("code"),Tvr=o("pretrained_model_name_or_path"),Mvr=o(":"),Evr=l(),ve=a("ul"),KT=a("li"),NTe=a("strong"),Cvr=o("beit"),wvr=o(" \u2014 "),aY=a("a"),Avr=o("BeitForImageClassification"),Lvr=o(" (BEiT model)"),yvr=l(),ZT=a("li"),qTe=a("strong"),xvr=o("convnext"),$vr=o(" \u2014 "),nY=a("a"),kvr=o("ConvNextForImageClassification"),Svr=o(" (ConvNeXT model)"),Rvr=l(),eM=a("li"),jTe=a("strong"),Pvr=o("cvt"),Bvr=o(" \u2014 "),sY=a("a"),Ivr=o("CvtForImageClassification"),Nvr=o(" (CvT model)"),qvr=l(),oM=a("li"),DTe=a("strong"),jvr=o("data2vec-vision"),Dvr=o(" \u2014 "),lY=a("a"),Gvr=o("Data2VecVisionForImageClassification"),Ovr=o(" (Data2VecVision model)"),Vvr=l(),_l=a("li"),GTe=a("strong"),Xvr=o("deit"),zvr=o(" \u2014 "),iY=a("a"),Qvr=o("DeiTForImageClassification"),Wvr=o(" or "),dY=a("a"),Uvr=o("DeiTForImageClassificationWithTeacher"),Hvr=o(" (DeiT model)"),Jvr=l(),rM=a("li"),OTe=a("strong"),Yvr=o("imagegpt"),Kvr=o(" \u2014 "),cY=a("a"),Zvr=o("ImageGPTForImageClassification"),e4r=o(" (ImageGPT model)"),o4r=l(),vl=a("li"),VTe=a("strong"),r4r=o("levit"),t4r=o(" \u2014 "),fY=a("a"),a4r=o("LevitForImageClassification"),n4r=o(" or "),mY=a("a"),s4r=o("LevitForImageClassificationWithTeacher"),l4r=o(" (LeViT model)"),i4r=l(),tM=a("li"),XTe=a("strong"),d4r=o("mobilevit"),c4r=o(" \u2014 "),gY=a("a"),f4r=o("MobileViTForImageClassification"),m4r=o(" (MobileViT model)"),g4r=l(),$t=a("li"),zTe=a("strong"),h4r=o("perceiver"),u4r=o(" \u2014 "),hY=a("a"),p4r=o("PerceiverForImageClassificationLearned"),_4r=o(" or "),uY=a("a"),v4r=o("PerceiverForImageClassificationFourier"),b4r=o(" or "),pY=a("a"),F4r=o("PerceiverForImageClassificationConvProcessing"),T4r=o(" (Perceiver model)"),M4r=l(),aM=a("li"),QTe=a("strong"),E4r=o("poolformer"),C4r=o(" \u2014 "),_Y=a("a"),w4r=o("PoolFormerForImageClassification"),A4r=o(" (PoolFormer model)"),L4r=l(),nM=a("li"),WTe=a("strong"),y4r=o("regnet"),x4r=o(" \u2014 "),vY=a("a"),$4r=o("RegNetForImageClassification"),k4r=o(" (RegNet model)"),S4r=l(),sM=a("li"),UTe=a("strong"),R4r=o("resnet"),P4r=o(" \u2014 "),bY=a("a"),B4r=o("ResNetForImageClassification"),I4r=o(" (ResNet model)"),N4r=l(),lM=a("li"),HTe=a("strong"),q4r=o("segformer"),j4r=o(" \u2014 "),FY=a("a"),D4r=o("SegformerForImageClassification"),G4r=o(" (SegFormer model)"),O4r=l(),iM=a("li"),JTe=a("strong"),V4r=o("swin"),X4r=o(" \u2014 "),TY=a("a"),z4r=o("SwinForImageClassification"),Q4r=o(" (Swin Transformer model)"),W4r=l(),dM=a("li"),YTe=a("strong"),U4r=o("swinv2"),H4r=o(" \u2014 "),MY=a("a"),J4r=o("Swinv2ForImageClassification"),Y4r=o(" (Swin Transformer V2 model)"),K4r=l(),cM=a("li"),KTe=a("strong"),Z4r=o("van"),ebr=o(" \u2014 "),EY=a("a"),obr=o("VanForImageClassification"),rbr=o(" (VAN model)"),tbr=l(),fM=a("li"),ZTe=a("strong"),abr=o("vit"),nbr=o(" \u2014 "),CY=a("a"),sbr=o("ViTForImageClassification"),lbr=o(" (ViT model)"),ibr=l(),mM=a("p"),dbr=o("The model is set in evaluation mode by default using "),eMe=a("code"),cbr=o("model.eval()"),fbr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),oMe=a("code"),mbr=o("model.train()"),gbr=l(),F(gM.$$.fragment),pKe=l(),rc=a("h2"),hM=a("a"),rMe=a("span"),F(s$.$$.fragment),hbr=l(),tMe=a("span"),ubr=o("AutoModelForVideoClassification"),_Ke=l(),Wo=a("div"),F(l$.$$.fragment),pbr=l(),tc=a("p"),_br=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),wY=a("a"),vbr=o("from_pretrained()"),bbr=o(" class method or the "),AY=a("a"),Fbr=o("from_config()"),Tbr=o(` class
method.`),Mbr=l(),i$=a("p"),Ebr=o("This class cannot be instantiated directly using "),aMe=a("code"),Cbr=o("__init__()"),wbr=o(" (throws an error)."),Abr=l(),kt=a("div"),F(d$.$$.fragment),Lbr=l(),nMe=a("p"),ybr=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),xbr=l(),ac=a("p"),$br=o(`Note:
Loading a model from its configuration file does `),sMe=a("strong"),kbr=o("not"),Sbr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LY=a("a"),Rbr=o("from_pretrained()"),Pbr=o(" to load the model weights."),Bbr=l(),F(uM.$$.fragment),Ibr=l(),go=a("div"),F(c$.$$.fragment),Nbr=l(),lMe=a("p"),qbr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),jbr=l(),cn=a("p"),Dbr=o("The model class to instantiate is selected based on the "),iMe=a("code"),Gbr=o("model_type"),Obr=o(` property of the config object (either
passed as an argument or loaded from `),dMe=a("code"),Vbr=o("pretrained_model_name_or_path"),Xbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cMe=a("code"),zbr=o("pretrained_model_name_or_path"),Qbr=o(":"),Wbr=l(),fMe=a("ul"),pM=a("li"),mMe=a("strong"),Ubr=o("videomae"),Hbr=o(" \u2014 "),yY=a("a"),Jbr=o("VideoMAEForVideoClassification"),Ybr=o(" (VideoMAE model)"),Kbr=l(),_M=a("p"),Zbr=o("The model is set in evaluation mode by default using "),gMe=a("code"),e1r=o("model.eval()"),o1r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hMe=a("code"),r1r=o("model.train()"),t1r=l(),F(vM.$$.fragment),vKe=l(),nc=a("h2"),bM=a("a"),uMe=a("span"),F(f$.$$.fragment),a1r=l(),pMe=a("span"),n1r=o("AutoModelForVision2Seq"),bKe=l(),Uo=a("div"),F(m$.$$.fragment),s1r=l(),sc=a("p"),l1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),xY=a("a"),i1r=o("from_pretrained()"),d1r=o(" class method or the "),$Y=a("a"),c1r=o("from_config()"),f1r=o(` class
method.`),m1r=l(),g$=a("p"),g1r=o("This class cannot be instantiated directly using "),_Me=a("code"),h1r=o("__init__()"),u1r=o(" (throws an error)."),p1r=l(),St=a("div"),F(h$.$$.fragment),_1r=l(),vMe=a("p"),v1r=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),b1r=l(),lc=a("p"),F1r=o(`Note:
Loading a model from its configuration file does `),bMe=a("strong"),T1r=o("not"),M1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kY=a("a"),E1r=o("from_pretrained()"),C1r=o(" to load the model weights."),w1r=l(),F(FM.$$.fragment),A1r=l(),ho=a("div"),F(u$.$$.fragment),L1r=l(),FMe=a("p"),y1r=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),x1r=l(),fn=a("p"),$1r=o("The model class to instantiate is selected based on the "),TMe=a("code"),k1r=o("model_type"),S1r=o(` property of the config object (either
passed as an argument or loaded from `),MMe=a("code"),R1r=o("pretrained_model_name_or_path"),P1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EMe=a("code"),B1r=o("pretrained_model_name_or_path"),I1r=o(":"),N1r=l(),CMe=a("ul"),TM=a("li"),wMe=a("strong"),q1r=o("vision-encoder-decoder"),j1r=o(" \u2014 "),SY=a("a"),D1r=o("VisionEncoderDecoderModel"),G1r=o(" (Vision Encoder decoder model)"),O1r=l(),MM=a("p"),V1r=o("The model is set in evaluation mode by default using "),AMe=a("code"),X1r=o("model.eval()"),z1r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LMe=a("code"),Q1r=o("model.train()"),W1r=l(),F(EM.$$.fragment),FKe=l(),ic=a("h2"),CM=a("a"),yMe=a("span"),F(p$.$$.fragment),U1r=l(),xMe=a("span"),H1r=o("AutoModelForVisualQuestionAnswering"),TKe=l(),Ho=a("div"),F(_$.$$.fragment),J1r=l(),dc=a("p"),Y1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),RY=a("a"),K1r=o("from_pretrained()"),Z1r=o(" class method or the "),PY=a("a"),e0r=o("from_config()"),o0r=o(` class
method.`),r0r=l(),v$=a("p"),t0r=o("This class cannot be instantiated directly using "),$Me=a("code"),a0r=o("__init__()"),n0r=o(" (throws an error)."),s0r=l(),Rt=a("div"),F(b$.$$.fragment),l0r=l(),kMe=a("p"),i0r=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),d0r=l(),cc=a("p"),c0r=o(`Note:
Loading a model from its configuration file does `),SMe=a("strong"),f0r=o("not"),m0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BY=a("a"),g0r=o("from_pretrained()"),h0r=o(" to load the model weights."),u0r=l(),F(wM.$$.fragment),p0r=l(),uo=a("div"),F(F$.$$.fragment),_0r=l(),RMe=a("p"),v0r=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),b0r=l(),mn=a("p"),F0r=o("The model class to instantiate is selected based on the "),PMe=a("code"),T0r=o("model_type"),M0r=o(` property of the config object (either
passed as an argument or loaded from `),BMe=a("code"),E0r=o("pretrained_model_name_or_path"),C0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IMe=a("code"),w0r=o("pretrained_model_name_or_path"),A0r=o(":"),L0r=l(),NMe=a("ul"),AM=a("li"),qMe=a("strong"),y0r=o("vilt"),x0r=o(" \u2014 "),IY=a("a"),$0r=o("ViltForQuestionAnswering"),k0r=o(" (ViLT model)"),S0r=l(),LM=a("p"),R0r=o("The model is set in evaluation mode by default using "),jMe=a("code"),P0r=o("model.eval()"),B0r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),DMe=a("code"),I0r=o("model.train()"),N0r=l(),F(yM.$$.fragment),MKe=l(),fc=a("h2"),xM=a("a"),GMe=a("span"),F(T$.$$.fragment),q0r=l(),OMe=a("span"),j0r=o("AutoModelForAudioClassification"),EKe=l(),Jo=a("div"),F(M$.$$.fragment),D0r=l(),mc=a("p"),G0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),NY=a("a"),O0r=o("from_pretrained()"),V0r=o(" class method or the "),qY=a("a"),X0r=o("from_config()"),z0r=o(` class
method.`),Q0r=l(),E$=a("p"),W0r=o("This class cannot be instantiated directly using "),VMe=a("code"),U0r=o("__init__()"),H0r=o(" (throws an error)."),J0r=l(),Pt=a("div"),F(C$.$$.fragment),Y0r=l(),XMe=a("p"),K0r=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Z0r=l(),gc=a("p"),eFr=o(`Note:
Loading a model from its configuration file does `),zMe=a("strong"),oFr=o("not"),rFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jY=a("a"),tFr=o("from_pretrained()"),aFr=o(" to load the model weights."),nFr=l(),F($M.$$.fragment),sFr=l(),po=a("div"),F(w$.$$.fragment),lFr=l(),QMe=a("p"),iFr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),dFr=l(),gn=a("p"),cFr=o("The model class to instantiate is selected based on the "),WMe=a("code"),fFr=o("model_type"),mFr=o(` property of the config object (either
passed as an argument or loaded from `),UMe=a("code"),gFr=o("pretrained_model_name_or_path"),hFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HMe=a("code"),uFr=o("pretrained_model_name_or_path"),pFr=o(":"),_Fr=l(),Pe=a("ul"),kM=a("li"),JMe=a("strong"),vFr=o("data2vec-audio"),bFr=o(" \u2014 "),DY=a("a"),FFr=o("Data2VecAudioForSequenceClassification"),TFr=o(" (Data2VecAudio model)"),MFr=l(),SM=a("li"),YMe=a("strong"),EFr=o("hubert"),CFr=o(" \u2014 "),GY=a("a"),wFr=o("HubertForSequenceClassification"),AFr=o(" (Hubert model)"),LFr=l(),RM=a("li"),KMe=a("strong"),yFr=o("sew"),xFr=o(" \u2014 "),OY=a("a"),$Fr=o("SEWForSequenceClassification"),kFr=o(" (SEW model)"),SFr=l(),PM=a("li"),ZMe=a("strong"),RFr=o("sew-d"),PFr=o(" \u2014 "),VY=a("a"),BFr=o("SEWDForSequenceClassification"),IFr=o(" (SEW-D model)"),NFr=l(),BM=a("li"),eEe=a("strong"),qFr=o("unispeech"),jFr=o(" \u2014 "),XY=a("a"),DFr=o("UniSpeechForSequenceClassification"),GFr=o(" (UniSpeech model)"),OFr=l(),IM=a("li"),oEe=a("strong"),VFr=o("unispeech-sat"),XFr=o(" \u2014 "),zY=a("a"),zFr=o("UniSpeechSatForSequenceClassification"),QFr=o(" (UniSpeechSat model)"),WFr=l(),NM=a("li"),rEe=a("strong"),UFr=o("wav2vec2"),HFr=o(" \u2014 "),QY=a("a"),JFr=o("Wav2Vec2ForSequenceClassification"),YFr=o(" (Wav2Vec2 model)"),KFr=l(),qM=a("li"),tEe=a("strong"),ZFr=o("wav2vec2-conformer"),eTr=o(" \u2014 "),WY=a("a"),oTr=o("Wav2Vec2ConformerForSequenceClassification"),rTr=o(" (Wav2Vec2-Conformer model)"),tTr=l(),jM=a("li"),aEe=a("strong"),aTr=o("wavlm"),nTr=o(" \u2014 "),UY=a("a"),sTr=o("WavLMForSequenceClassification"),lTr=o(" (WavLM model)"),iTr=l(),DM=a("p"),dTr=o("The model is set in evaluation mode by default using "),nEe=a("code"),cTr=o("model.eval()"),fTr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sEe=a("code"),mTr=o("model.train()"),gTr=l(),F(GM.$$.fragment),CKe=l(),hc=a("h2"),OM=a("a"),lEe=a("span"),F(A$.$$.fragment),hTr=l(),iEe=a("span"),uTr=o("AutoModelForAudioFrameClassification"),wKe=l(),Yo=a("div"),F(L$.$$.fragment),pTr=l(),uc=a("p"),_Tr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),HY=a("a"),vTr=o("from_pretrained()"),bTr=o(" class method or the "),JY=a("a"),FTr=o("from_config()"),TTr=o(` class
method.`),MTr=l(),y$=a("p"),ETr=o("This class cannot be instantiated directly using "),dEe=a("code"),CTr=o("__init__()"),wTr=o(" (throws an error)."),ATr=l(),Bt=a("div"),F(x$.$$.fragment),LTr=l(),cEe=a("p"),yTr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),xTr=l(),pc=a("p"),$Tr=o(`Note:
Loading a model from its configuration file does `),fEe=a("strong"),kTr=o("not"),STr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YY=a("a"),RTr=o("from_pretrained()"),PTr=o(" to load the model weights."),BTr=l(),F(VM.$$.fragment),ITr=l(),_o=a("div"),F($$.$$.fragment),NTr=l(),mEe=a("p"),qTr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),jTr=l(),hn=a("p"),DTr=o("The model class to instantiate is selected based on the "),gEe=a("code"),GTr=o("model_type"),OTr=o(` property of the config object (either
passed as an argument or loaded from `),hEe=a("code"),VTr=o("pretrained_model_name_or_path"),XTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uEe=a("code"),zTr=o("pretrained_model_name_or_path"),QTr=o(":"),WTr=l(),ft=a("ul"),XM=a("li"),pEe=a("strong"),UTr=o("data2vec-audio"),HTr=o(" \u2014 "),KY=a("a"),JTr=o("Data2VecAudioForAudioFrameClassification"),YTr=o(" (Data2VecAudio model)"),KTr=l(),zM=a("li"),_Ee=a("strong"),ZTr=o("unispeech-sat"),eMr=o(" \u2014 "),ZY=a("a"),oMr=o("UniSpeechSatForAudioFrameClassification"),rMr=o(" (UniSpeechSat model)"),tMr=l(),QM=a("li"),vEe=a("strong"),aMr=o("wav2vec2"),nMr=o(" \u2014 "),eK=a("a"),sMr=o("Wav2Vec2ForAudioFrameClassification"),lMr=o(" (Wav2Vec2 model)"),iMr=l(),WM=a("li"),bEe=a("strong"),dMr=o("wav2vec2-conformer"),cMr=o(" \u2014 "),oK=a("a"),fMr=o("Wav2Vec2ConformerForAudioFrameClassification"),mMr=o(" (Wav2Vec2-Conformer model)"),gMr=l(),UM=a("li"),FEe=a("strong"),hMr=o("wavlm"),uMr=o(" \u2014 "),rK=a("a"),pMr=o("WavLMForAudioFrameClassification"),_Mr=o(" (WavLM model)"),vMr=l(),HM=a("p"),bMr=o("The model is set in evaluation mode by default using "),TEe=a("code"),FMr=o("model.eval()"),TMr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),MEe=a("code"),MMr=o("model.train()"),EMr=l(),F(JM.$$.fragment),AKe=l(),_c=a("h2"),YM=a("a"),EEe=a("span"),F(k$.$$.fragment),CMr=l(),CEe=a("span"),wMr=o("AutoModelForCTC"),LKe=l(),Ko=a("div"),F(S$.$$.fragment),AMr=l(),vc=a("p"),LMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),tK=a("a"),yMr=o("from_pretrained()"),xMr=o(" class method or the "),aK=a("a"),$Mr=o("from_config()"),kMr=o(` class
method.`),SMr=l(),R$=a("p"),RMr=o("This class cannot be instantiated directly using "),wEe=a("code"),PMr=o("__init__()"),BMr=o(" (throws an error)."),IMr=l(),It=a("div"),F(P$.$$.fragment),NMr=l(),AEe=a("p"),qMr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),jMr=l(),bc=a("p"),DMr=o(`Note:
Loading a model from its configuration file does `),LEe=a("strong"),GMr=o("not"),OMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=a("a"),VMr=o("from_pretrained()"),XMr=o(" to load the model weights."),zMr=l(),F(KM.$$.fragment),QMr=l(),vo=a("div"),F(B$.$$.fragment),WMr=l(),yEe=a("p"),UMr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),HMr=l(),un=a("p"),JMr=o("The model class to instantiate is selected based on the "),xEe=a("code"),YMr=o("model_type"),KMr=o(` property of the config object (either
passed as an argument or loaded from `),$Ee=a("code"),ZMr=o("pretrained_model_name_or_path"),eEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kEe=a("code"),oEr=o("pretrained_model_name_or_path"),rEr=o(":"),tEr=l(),Le=a("ul"),ZM=a("li"),SEe=a("strong"),aEr=o("data2vec-audio"),nEr=o(" \u2014 "),sK=a("a"),sEr=o("Data2VecAudioForCTC"),lEr=o(" (Data2VecAudio model)"),iEr=l(),eE=a("li"),REe=a("strong"),dEr=o("hubert"),cEr=o(" \u2014 "),lK=a("a"),fEr=o("HubertForCTC"),mEr=o(" (Hubert model)"),gEr=l(),oE=a("li"),PEe=a("strong"),hEr=o("mctct"),uEr=o(" \u2014 "),iK=a("a"),pEr=o("MCTCTForCTC"),_Er=o(" (M-CTC-T model)"),vEr=l(),rE=a("li"),BEe=a("strong"),bEr=o("sew"),FEr=o(" \u2014 "),dK=a("a"),TEr=o("SEWForCTC"),MEr=o(" (SEW model)"),EEr=l(),tE=a("li"),IEe=a("strong"),CEr=o("sew-d"),wEr=o(" \u2014 "),cK=a("a"),AEr=o("SEWDForCTC"),LEr=o(" (SEW-D model)"),yEr=l(),aE=a("li"),NEe=a("strong"),xEr=o("unispeech"),$Er=o(" \u2014 "),fK=a("a"),kEr=o("UniSpeechForCTC"),SEr=o(" (UniSpeech model)"),REr=l(),nE=a("li"),qEe=a("strong"),PEr=o("unispeech-sat"),BEr=o(" \u2014 "),mK=a("a"),IEr=o("UniSpeechSatForCTC"),NEr=o(" (UniSpeechSat model)"),qEr=l(),sE=a("li"),jEe=a("strong"),jEr=o("wav2vec2"),DEr=o(" \u2014 "),gK=a("a"),GEr=o("Wav2Vec2ForCTC"),OEr=o(" (Wav2Vec2 model)"),VEr=l(),lE=a("li"),DEe=a("strong"),XEr=o("wav2vec2-conformer"),zEr=o(" \u2014 "),hK=a("a"),QEr=o("Wav2Vec2ConformerForCTC"),WEr=o(" (Wav2Vec2-Conformer model)"),UEr=l(),iE=a("li"),GEe=a("strong"),HEr=o("wavlm"),JEr=o(" \u2014 "),uK=a("a"),YEr=o("WavLMForCTC"),KEr=o(" (WavLM model)"),ZEr=l(),dE=a("p"),eCr=o("The model is set in evaluation mode by default using "),OEe=a("code"),oCr=o("model.eval()"),rCr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),VEe=a("code"),tCr=o("model.train()"),aCr=l(),F(cE.$$.fragment),yKe=l(),Fc=a("h2"),fE=a("a"),XEe=a("span"),F(I$.$$.fragment),nCr=l(),zEe=a("span"),sCr=o("AutoModelForSpeechSeq2Seq"),xKe=l(),Zo=a("div"),F(N$.$$.fragment),lCr=l(),Tc=a("p"),iCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),pK=a("a"),dCr=o("from_pretrained()"),cCr=o(" class method or the "),_K=a("a"),fCr=o("from_config()"),mCr=o(` class
method.`),gCr=l(),q$=a("p"),hCr=o("This class cannot be instantiated directly using "),QEe=a("code"),uCr=o("__init__()"),pCr=o(" (throws an error)."),_Cr=l(),Nt=a("div"),F(j$.$$.fragment),vCr=l(),WEe=a("p"),bCr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),FCr=l(),Mc=a("p"),TCr=o(`Note:
Loading a model from its configuration file does `),UEe=a("strong"),MCr=o("not"),ECr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vK=a("a"),CCr=o("from_pretrained()"),wCr=o(" to load the model weights."),ACr=l(),F(mE.$$.fragment),LCr=l(),bo=a("div"),F(D$.$$.fragment),yCr=l(),HEe=a("p"),xCr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),$Cr=l(),pn=a("p"),kCr=o("The model class to instantiate is selected based on the "),JEe=a("code"),SCr=o("model_type"),RCr=o(` property of the config object (either
passed as an argument or loaded from `),YEe=a("code"),PCr=o("pretrained_model_name_or_path"),BCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KEe=a("code"),ICr=o("pretrained_model_name_or_path"),NCr=o(":"),qCr=l(),G$=a("ul"),gE=a("li"),ZEe=a("strong"),jCr=o("speech-encoder-decoder"),DCr=o(" \u2014 "),bK=a("a"),GCr=o("SpeechEncoderDecoderModel"),OCr=o(" (Speech Encoder decoder model)"),VCr=l(),hE=a("li"),eCe=a("strong"),XCr=o("speech_to_text"),zCr=o(" \u2014 "),FK=a("a"),QCr=o("Speech2TextForConditionalGeneration"),WCr=o(" (Speech2Text model)"),UCr=l(),uE=a("p"),HCr=o("The model is set in evaluation mode by default using "),oCe=a("code"),JCr=o("model.eval()"),YCr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rCe=a("code"),KCr=o("model.train()"),ZCr=l(),F(pE.$$.fragment),$Ke=l(),Ec=a("h2"),_E=a("a"),tCe=a("span"),F(O$.$$.fragment),e3r=l(),aCe=a("span"),o3r=o("AutoModelForAudioXVector"),kKe=l(),er=a("div"),F(V$.$$.fragment),r3r=l(),Cc=a("p"),t3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),TK=a("a"),a3r=o("from_pretrained()"),n3r=o(" class method or the "),MK=a("a"),s3r=o("from_config()"),l3r=o(` class
method.`),i3r=l(),X$=a("p"),d3r=o("This class cannot be instantiated directly using "),nCe=a("code"),c3r=o("__init__()"),f3r=o(" (throws an error)."),m3r=l(),qt=a("div"),F(z$.$$.fragment),g3r=l(),sCe=a("p"),h3r=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),u3r=l(),wc=a("p"),p3r=o(`Note:
Loading a model from its configuration file does `),lCe=a("strong"),_3r=o("not"),v3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EK=a("a"),b3r=o("from_pretrained()"),F3r=o(" to load the model weights."),T3r=l(),F(vE.$$.fragment),M3r=l(),Fo=a("div"),F(Q$.$$.fragment),E3r=l(),iCe=a("p"),C3r=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),w3r=l(),_n=a("p"),A3r=o("The model class to instantiate is selected based on the "),dCe=a("code"),L3r=o("model_type"),y3r=o(` property of the config object (either
passed as an argument or loaded from `),cCe=a("code"),x3r=o("pretrained_model_name_or_path"),$3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fCe=a("code"),k3r=o("pretrained_model_name_or_path"),S3r=o(":"),R3r=l(),mt=a("ul"),bE=a("li"),mCe=a("strong"),P3r=o("data2vec-audio"),B3r=o(" \u2014 "),CK=a("a"),I3r=o("Data2VecAudioForXVector"),N3r=o(" (Data2VecAudio model)"),q3r=l(),FE=a("li"),gCe=a("strong"),j3r=o("unispeech-sat"),D3r=o(" \u2014 "),wK=a("a"),G3r=o("UniSpeechSatForXVector"),O3r=o(" (UniSpeechSat model)"),V3r=l(),TE=a("li"),hCe=a("strong"),X3r=o("wav2vec2"),z3r=o(" \u2014 "),AK=a("a"),Q3r=o("Wav2Vec2ForXVector"),W3r=o(" (Wav2Vec2 model)"),U3r=l(),ME=a("li"),uCe=a("strong"),H3r=o("wav2vec2-conformer"),J3r=o(" \u2014 "),LK=a("a"),Y3r=o("Wav2Vec2ConformerForXVector"),K3r=o(" (Wav2Vec2-Conformer model)"),Z3r=l(),EE=a("li"),pCe=a("strong"),e5r=o("wavlm"),o5r=o(" \u2014 "),yK=a("a"),r5r=o("WavLMForXVector"),t5r=o(" (WavLM model)"),a5r=l(),CE=a("p"),n5r=o("The model is set in evaluation mode by default using "),_Ce=a("code"),s5r=o("model.eval()"),l5r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vCe=a("code"),i5r=o("model.train()"),d5r=l(),F(wE.$$.fragment),SKe=l(),Ac=a("h2"),AE=a("a"),bCe=a("span"),F(W$.$$.fragment),c5r=l(),FCe=a("span"),f5r=o("AutoModelForMaskedImageModeling"),RKe=l(),or=a("div"),F(U$.$$.fragment),m5r=l(),Lc=a("p"),g5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),xK=a("a"),h5r=o("from_pretrained()"),u5r=o(" class method or the "),$K=a("a"),p5r=o("from_config()"),_5r=o(` class
method.`),v5r=l(),H$=a("p"),b5r=o("This class cannot be instantiated directly using "),TCe=a("code"),F5r=o("__init__()"),T5r=o(" (throws an error)."),M5r=l(),jt=a("div"),F(J$.$$.fragment),E5r=l(),MCe=a("p"),C5r=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),w5r=l(),yc=a("p"),A5r=o(`Note:
Loading a model from its configuration file does `),ECe=a("strong"),L5r=o("not"),y5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kK=a("a"),x5r=o("from_pretrained()"),$5r=o(" to load the model weights."),k5r=l(),F(LE.$$.fragment),S5r=l(),To=a("div"),F(Y$.$$.fragment),R5r=l(),CCe=a("p"),P5r=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),B5r=l(),vn=a("p"),I5r=o("The model class to instantiate is selected based on the "),wCe=a("code"),N5r=o("model_type"),q5r=o(` property of the config object (either
passed as an argument or loaded from `),ACe=a("code"),j5r=o("pretrained_model_name_or_path"),D5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LCe=a("code"),G5r=o("pretrained_model_name_or_path"),O5r=o(":"),V5r=l(),bn=a("ul"),yE=a("li"),yCe=a("strong"),X5r=o("deit"),z5r=o(" \u2014 "),SK=a("a"),Q5r=o("DeiTForMaskedImageModeling"),W5r=o(" (DeiT model)"),U5r=l(),xE=a("li"),xCe=a("strong"),H5r=o("swin"),J5r=o(" \u2014 "),RK=a("a"),Y5r=o("SwinForMaskedImageModeling"),K5r=o(" (Swin Transformer model)"),Z5r=l(),$E=a("li"),$Ce=a("strong"),ewr=o("swinv2"),owr=o(" \u2014 "),PK=a("a"),rwr=o("Swinv2ForMaskedImageModeling"),twr=o(" (Swin Transformer V2 model)"),awr=l(),kE=a("li"),kCe=a("strong"),nwr=o("vit"),swr=o(" \u2014 "),BK=a("a"),lwr=o("ViTForMaskedImageModeling"),iwr=o(" (ViT model)"),dwr=l(),SE=a("p"),cwr=o("The model is set in evaluation mode by default using "),SCe=a("code"),fwr=o("model.eval()"),mwr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),RCe=a("code"),gwr=o("model.train()"),hwr=l(),F(RE.$$.fragment),PKe=l(),xc=a("h2"),PE=a("a"),PCe=a("span"),F(K$.$$.fragment),uwr=l(),BCe=a("span"),pwr=o("AutoModelForObjectDetection"),BKe=l(),rr=a("div"),F(Z$.$$.fragment),_wr=l(),$c=a("p"),vwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),IK=a("a"),bwr=o("from_pretrained()"),Fwr=o(" class method or the "),NK=a("a"),Twr=o("from_config()"),Mwr=o(` class
method.`),Ewr=l(),ek=a("p"),Cwr=o("This class cannot be instantiated directly using "),ICe=a("code"),wwr=o("__init__()"),Awr=o(" (throws an error)."),Lwr=l(),Dt=a("div"),F(ok.$$.fragment),ywr=l(),NCe=a("p"),xwr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),$wr=l(),kc=a("p"),kwr=o(`Note:
Loading a model from its configuration file does `),qCe=a("strong"),Swr=o("not"),Rwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qK=a("a"),Pwr=o("from_pretrained()"),Bwr=o(" to load the model weights."),Iwr=l(),F(BE.$$.fragment),Nwr=l(),Mo=a("div"),F(rk.$$.fragment),qwr=l(),jCe=a("p"),jwr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Dwr=l(),Fn=a("p"),Gwr=o("The model class to instantiate is selected based on the "),DCe=a("code"),Owr=o("model_type"),Vwr=o(` property of the config object (either
passed as an argument or loaded from `),GCe=a("code"),Xwr=o("pretrained_model_name_or_path"),zwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),OCe=a("code"),Qwr=o("pretrained_model_name_or_path"),Wwr=o(":"),Uwr=l(),tk=a("ul"),IE=a("li"),VCe=a("strong"),Hwr=o("detr"),Jwr=o(" \u2014 "),jK=a("a"),Ywr=o("DetrForObjectDetection"),Kwr=o(" (DETR model)"),Zwr=l(),NE=a("li"),XCe=a("strong"),eAr=o("yolos"),oAr=o(" \u2014 "),DK=a("a"),rAr=o("YolosForObjectDetection"),tAr=o(" (YOLOS model)"),aAr=l(),qE=a("p"),nAr=o("The model is set in evaluation mode by default using "),zCe=a("code"),sAr=o("model.eval()"),lAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),QCe=a("code"),iAr=o("model.train()"),dAr=l(),F(jE.$$.fragment),IKe=l(),Sc=a("h2"),DE=a("a"),WCe=a("span"),F(ak.$$.fragment),cAr=l(),UCe=a("span"),fAr=o("AutoModelForImageSegmentation"),NKe=l(),tr=a("div"),F(nk.$$.fragment),mAr=l(),Rc=a("p"),gAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),GK=a("a"),hAr=o("from_pretrained()"),uAr=o(" class method or the "),OK=a("a"),pAr=o("from_config()"),_Ar=o(` class
method.`),vAr=l(),sk=a("p"),bAr=o("This class cannot be instantiated directly using "),HCe=a("code"),FAr=o("__init__()"),TAr=o(" (throws an error)."),MAr=l(),Gt=a("div"),F(lk.$$.fragment),EAr=l(),JCe=a("p"),CAr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),wAr=l(),Pc=a("p"),AAr=o(`Note:
Loading a model from its configuration file does `),YCe=a("strong"),LAr=o("not"),yAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VK=a("a"),xAr=o("from_pretrained()"),$Ar=o(" to load the model weights."),kAr=l(),F(GE.$$.fragment),SAr=l(),Eo=a("div"),F(ik.$$.fragment),RAr=l(),KCe=a("p"),PAr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),BAr=l(),Tn=a("p"),IAr=o("The model class to instantiate is selected based on the "),ZCe=a("code"),NAr=o("model_type"),qAr=o(` property of the config object (either
passed as an argument or loaded from `),e3e=a("code"),jAr=o("pretrained_model_name_or_path"),DAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o3e=a("code"),GAr=o("pretrained_model_name_or_path"),OAr=o(":"),VAr=l(),r3e=a("ul"),OE=a("li"),t3e=a("strong"),XAr=o("detr"),zAr=o(" \u2014 "),XK=a("a"),QAr=o("DetrForSegmentation"),WAr=o(" (DETR model)"),UAr=l(),VE=a("p"),HAr=o("The model is set in evaluation mode by default using "),a3e=a("code"),JAr=o("model.eval()"),YAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n3e=a("code"),KAr=o("model.train()"),ZAr=l(),F(XE.$$.fragment),qKe=l(),Bc=a("h2"),zE=a("a"),s3e=a("span"),F(dk.$$.fragment),e6r=l(),l3e=a("span"),o6r=o("AutoModelForSemanticSegmentation"),jKe=l(),ar=a("div"),F(ck.$$.fragment),r6r=l(),Ic=a("p"),t6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zK=a("a"),a6r=o("from_pretrained()"),n6r=o(" class method or the "),QK=a("a"),s6r=o("from_config()"),l6r=o(` class
method.`),i6r=l(),fk=a("p"),d6r=o("This class cannot be instantiated directly using "),i3e=a("code"),c6r=o("__init__()"),f6r=o(" (throws an error)."),m6r=l(),Ot=a("div"),F(mk.$$.fragment),g6r=l(),d3e=a("p"),h6r=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),u6r=l(),Nc=a("p"),p6r=o(`Note:
Loading a model from its configuration file does `),c3e=a("strong"),_6r=o("not"),v6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WK=a("a"),b6r=o("from_pretrained()"),F6r=o(" to load the model weights."),T6r=l(),F(QE.$$.fragment),M6r=l(),Co=a("div"),F(gk.$$.fragment),E6r=l(),f3e=a("p"),C6r=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),w6r=l(),Mn=a("p"),A6r=o("The model class to instantiate is selected based on the "),m3e=a("code"),L6r=o("model_type"),y6r=o(` property of the config object (either
passed as an argument or loaded from `),g3e=a("code"),x6r=o("pretrained_model_name_or_path"),$6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h3e=a("code"),k6r=o("pretrained_model_name_or_path"),S6r=o(":"),R6r=l(),gt=a("ul"),WE=a("li"),u3e=a("strong"),P6r=o("beit"),B6r=o(" \u2014 "),UK=a("a"),I6r=o("BeitForSemanticSegmentation"),N6r=o(" (BEiT model)"),q6r=l(),UE=a("li"),p3e=a("strong"),j6r=o("data2vec-vision"),D6r=o(" \u2014 "),HK=a("a"),G6r=o("Data2VecVisionForSemanticSegmentation"),O6r=o(" (Data2VecVision model)"),V6r=l(),HE=a("li"),_3e=a("strong"),X6r=o("dpt"),z6r=o(" \u2014 "),JK=a("a"),Q6r=o("DPTForSemanticSegmentation"),W6r=o(" (DPT model)"),U6r=l(),JE=a("li"),v3e=a("strong"),H6r=o("mobilevit"),J6r=o(" \u2014 "),YK=a("a"),Y6r=o("MobileViTForSemanticSegmentation"),K6r=o(" (MobileViT model)"),Z6r=l(),YE=a("li"),b3e=a("strong"),e7r=o("segformer"),o7r=o(" \u2014 "),KK=a("a"),r7r=o("SegformerForSemanticSegmentation"),t7r=o(" (SegFormer model)"),a7r=l(),KE=a("p"),n7r=o("The model is set in evaluation mode by default using "),F3e=a("code"),s7r=o("model.eval()"),l7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T3e=a("code"),i7r=o("model.train()"),d7r=l(),F(ZE.$$.fragment),DKe=l(),qc=a("h2"),eC=a("a"),M3e=a("span"),F(hk.$$.fragment),c7r=l(),E3e=a("span"),f7r=o("AutoModelForInstanceSegmentation"),GKe=l(),nr=a("div"),F(uk.$$.fragment),m7r=l(),jc=a("p"),g7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),ZK=a("a"),h7r=o("from_pretrained()"),u7r=o(" class method or the "),eZ=a("a"),p7r=o("from_config()"),_7r=o(` class
method.`),v7r=l(),pk=a("p"),b7r=o("This class cannot be instantiated directly using "),C3e=a("code"),F7r=o("__init__()"),T7r=o(" (throws an error)."),M7r=l(),Vt=a("div"),F(_k.$$.fragment),E7r=l(),w3e=a("p"),C7r=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),w7r=l(),Dc=a("p"),A7r=o(`Note:
Loading a model from its configuration file does `),A3e=a("strong"),L7r=o("not"),y7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oZ=a("a"),x7r=o("from_pretrained()"),$7r=o(" to load the model weights."),k7r=l(),F(oC.$$.fragment),S7r=l(),wo=a("div"),F(vk.$$.fragment),R7r=l(),L3e=a("p"),P7r=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),B7r=l(),En=a("p"),I7r=o("The model class to instantiate is selected based on the "),y3e=a("code"),N7r=o("model_type"),q7r=o(` property of the config object (either
passed as an argument or loaded from `),x3e=a("code"),j7r=o("pretrained_model_name_or_path"),D7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$3e=a("code"),G7r=o("pretrained_model_name_or_path"),O7r=o(":"),V7r=l(),k3e=a("ul"),rC=a("li"),S3e=a("strong"),X7r=o("maskformer"),z7r=o(" \u2014 "),rZ=a("a"),Q7r=o("MaskFormerForInstanceSegmentation"),W7r=o(" (MaskFormer model)"),U7r=l(),tC=a("p"),H7r=o("The model is set in evaluation mode by default using "),R3e=a("code"),J7r=o("model.eval()"),Y7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P3e=a("code"),K7r=o("model.train()"),Z7r=l(),F(aC.$$.fragment),OKe=l(),Gc=a("h2"),nC=a("a"),B3e=a("span"),F(bk.$$.fragment),eLr=l(),I3e=a("span"),oLr=o("TFAutoModel"),VKe=l(),sr=a("div"),F(Fk.$$.fragment),rLr=l(),Oc=a("p"),tLr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),tZ=a("a"),aLr=o("from_pretrained()"),nLr=o(" class method or the "),aZ=a("a"),sLr=o("from_config()"),lLr=o(` class
method.`),iLr=l(),Tk=a("p"),dLr=o("This class cannot be instantiated directly using "),N3e=a("code"),cLr=o("__init__()"),fLr=o(" (throws an error)."),mLr=l(),Xt=a("div"),F(Mk.$$.fragment),gLr=l(),q3e=a("p"),hLr=o("Instantiates one of the base model classes of the library from a configuration."),uLr=l(),Vc=a("p"),pLr=o(`Note:
Loading a model from its configuration file does `),j3e=a("strong"),_Lr=o("not"),vLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nZ=a("a"),bLr=o("from_pretrained()"),FLr=o(" to load the model weights."),TLr=l(),F(sC.$$.fragment),MLr=l(),Ir=a("div"),F(Ek.$$.fragment),ELr=l(),D3e=a("p"),CLr=o("Instantiate one of the base model classes of the library from a pretrained model."),wLr=l(),Cn=a("p"),ALr=o("The model class to instantiate is selected based on the "),G3e=a("code"),LLr=o("model_type"),yLr=o(` property of the config object (either
passed as an argument or loaded from `),O3e=a("code"),xLr=o("pretrained_model_name_or_path"),$Lr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V3e=a("code"),kLr=o("pretrained_model_name_or_path"),SLr=o(":"),RLr=l(),N=a("ul"),lC=a("li"),X3e=a("strong"),PLr=o("albert"),BLr=o(" \u2014 "),sZ=a("a"),ILr=o("TFAlbertModel"),NLr=o(" (ALBERT model)"),qLr=l(),iC=a("li"),z3e=a("strong"),jLr=o("bart"),DLr=o(" \u2014 "),lZ=a("a"),GLr=o("TFBartModel"),OLr=o(" (BART model)"),VLr=l(),dC=a("li"),Q3e=a("strong"),XLr=o("bert"),zLr=o(" \u2014 "),iZ=a("a"),QLr=o("TFBertModel"),WLr=o(" (BERT model)"),ULr=l(),cC=a("li"),W3e=a("strong"),HLr=o("blenderbot"),JLr=o(" \u2014 "),dZ=a("a"),YLr=o("TFBlenderbotModel"),KLr=o(" (Blenderbot model)"),ZLr=l(),fC=a("li"),U3e=a("strong"),eyr=o("blenderbot-small"),oyr=o(" \u2014 "),cZ=a("a"),ryr=o("TFBlenderbotSmallModel"),tyr=o(" (BlenderbotSmall model)"),ayr=l(),mC=a("li"),H3e=a("strong"),nyr=o("camembert"),syr=o(" \u2014 "),fZ=a("a"),lyr=o("TFCamembertModel"),iyr=o(" (CamemBERT model)"),dyr=l(),gC=a("li"),J3e=a("strong"),cyr=o("clip"),fyr=o(" \u2014 "),mZ=a("a"),myr=o("TFCLIPModel"),gyr=o(" (CLIP model)"),hyr=l(),hC=a("li"),Y3e=a("strong"),uyr=o("convbert"),pyr=o(" \u2014 "),gZ=a("a"),_yr=o("TFConvBertModel"),vyr=o(" (ConvBERT model)"),byr=l(),uC=a("li"),K3e=a("strong"),Fyr=o("convnext"),Tyr=o(" \u2014 "),hZ=a("a"),Myr=o("TFConvNextModel"),Eyr=o(" (ConvNeXT model)"),Cyr=l(),pC=a("li"),Z3e=a("strong"),wyr=o("ctrl"),Ayr=o(" \u2014 "),uZ=a("a"),Lyr=o("TFCTRLModel"),yyr=o(" (CTRL model)"),xyr=l(),_C=a("li"),e5e=a("strong"),$yr=o("data2vec-vision"),kyr=o(" \u2014 "),pZ=a("a"),Syr=o("TFData2VecVisionModel"),Ryr=o(" (Data2VecVision model)"),Pyr=l(),vC=a("li"),o5e=a("strong"),Byr=o("deberta"),Iyr=o(" \u2014 "),_Z=a("a"),Nyr=o("TFDebertaModel"),qyr=o(" (DeBERTa model)"),jyr=l(),bC=a("li"),r5e=a("strong"),Dyr=o("deberta-v2"),Gyr=o(" \u2014 "),vZ=a("a"),Oyr=o("TFDebertaV2Model"),Vyr=o(" (DeBERTa-v2 model)"),Xyr=l(),FC=a("li"),t5e=a("strong"),zyr=o("deit"),Qyr=o(" \u2014 "),bZ=a("a"),Wyr=o("TFDeiTModel"),Uyr=o(" (DeiT model)"),Hyr=l(),TC=a("li"),a5e=a("strong"),Jyr=o("distilbert"),Yyr=o(" \u2014 "),FZ=a("a"),Kyr=o("TFDistilBertModel"),Zyr=o(" (DistilBERT model)"),e8r=l(),MC=a("li"),n5e=a("strong"),o8r=o("dpr"),r8r=o(" \u2014 "),TZ=a("a"),t8r=o("TFDPRQuestionEncoder"),a8r=o(" (DPR model)"),n8r=l(),EC=a("li"),s5e=a("strong"),s8r=o("electra"),l8r=o(" \u2014 "),MZ=a("a"),i8r=o("TFElectraModel"),d8r=o(" (ELECTRA model)"),c8r=l(),CC=a("li"),l5e=a("strong"),f8r=o("flaubert"),m8r=o(" \u2014 "),EZ=a("a"),g8r=o("TFFlaubertModel"),h8r=o(" (FlauBERT model)"),u8r=l(),bl=a("li"),i5e=a("strong"),p8r=o("funnel"),_8r=o(" \u2014 "),CZ=a("a"),v8r=o("TFFunnelModel"),b8r=o(" or "),wZ=a("a"),F8r=o("TFFunnelBaseModel"),T8r=o(" (Funnel Transformer model)"),M8r=l(),wC=a("li"),d5e=a("strong"),E8r=o("gpt2"),C8r=o(" \u2014 "),AZ=a("a"),w8r=o("TFGPT2Model"),A8r=o(" (OpenAI GPT-2 model)"),L8r=l(),AC=a("li"),c5e=a("strong"),y8r=o("gptj"),x8r=o(" \u2014 "),LZ=a("a"),$8r=o("TFGPTJModel"),k8r=o(" (GPT-J model)"),S8r=l(),LC=a("li"),f5e=a("strong"),R8r=o("hubert"),P8r=o(" \u2014 "),yZ=a("a"),B8r=o("TFHubertModel"),I8r=o(" (Hubert model)"),N8r=l(),yC=a("li"),m5e=a("strong"),q8r=o("layoutlm"),j8r=o(" \u2014 "),xZ=a("a"),D8r=o("TFLayoutLMModel"),G8r=o(" (LayoutLM model)"),O8r=l(),xC=a("li"),g5e=a("strong"),V8r=o("layoutlmv3"),X8r=o(" \u2014 "),$Z=a("a"),z8r=o("TFLayoutLMv3Model"),Q8r=o(" (LayoutLMv3 model)"),W8r=l(),$C=a("li"),h5e=a("strong"),U8r=o("led"),H8r=o(" \u2014 "),kZ=a("a"),J8r=o("TFLEDModel"),Y8r=o(" (LED model)"),K8r=l(),kC=a("li"),u5e=a("strong"),Z8r=o("longformer"),e9r=o(" \u2014 "),SZ=a("a"),o9r=o("TFLongformerModel"),r9r=o(" (Longformer model)"),t9r=l(),SC=a("li"),p5e=a("strong"),a9r=o("lxmert"),n9r=o(" \u2014 "),RZ=a("a"),s9r=o("TFLxmertModel"),l9r=o(" (LXMERT model)"),i9r=l(),RC=a("li"),_5e=a("strong"),d9r=o("marian"),c9r=o(" \u2014 "),PZ=a("a"),f9r=o("TFMarianModel"),m9r=o(" (Marian model)"),g9r=l(),PC=a("li"),v5e=a("strong"),h9r=o("mbart"),u9r=o(" \u2014 "),BZ=a("a"),p9r=o("TFMBartModel"),_9r=o(" (mBART model)"),v9r=l(),BC=a("li"),b5e=a("strong"),b9r=o("mobilebert"),F9r=o(" \u2014 "),IZ=a("a"),T9r=o("TFMobileBertModel"),M9r=o(" (MobileBERT model)"),E9r=l(),IC=a("li"),F5e=a("strong"),C9r=o("mobilevit"),w9r=o(" \u2014 "),NZ=a("a"),A9r=o("TFMobileViTModel"),L9r=o(" (MobileViT model)"),y9r=l(),NC=a("li"),T5e=a("strong"),x9r=o("mpnet"),$9r=o(" \u2014 "),qZ=a("a"),k9r=o("TFMPNetModel"),S9r=o(" (MPNet model)"),R9r=l(),qC=a("li"),M5e=a("strong"),P9r=o("mt5"),B9r=o(" \u2014 "),jZ=a("a"),I9r=o("TFMT5Model"),N9r=o(" (MT5 model)"),q9r=l(),jC=a("li"),E5e=a("strong"),j9r=o("openai-gpt"),D9r=o(" \u2014 "),DZ=a("a"),G9r=o("TFOpenAIGPTModel"),O9r=o(" (OpenAI GPT model)"),V9r=l(),DC=a("li"),C5e=a("strong"),X9r=o("opt"),z9r=o(" \u2014 "),GZ=a("a"),Q9r=o("TFOPTModel"),W9r=o(" (OPT model)"),U9r=l(),GC=a("li"),w5e=a("strong"),H9r=o("pegasus"),J9r=o(" \u2014 "),OZ=a("a"),Y9r=o("TFPegasusModel"),K9r=o(" (Pegasus model)"),Z9r=l(),OC=a("li"),A5e=a("strong"),exr=o("regnet"),oxr=o(" \u2014 "),VZ=a("a"),rxr=o("TFRegNetModel"),txr=o(" (RegNet model)"),axr=l(),VC=a("li"),L5e=a("strong"),nxr=o("rembert"),sxr=o(" \u2014 "),XZ=a("a"),lxr=o("TFRemBertModel"),ixr=o(" (RemBERT model)"),dxr=l(),XC=a("li"),y5e=a("strong"),cxr=o("resnet"),fxr=o(" \u2014 "),zZ=a("a"),mxr=o("TFResNetModel"),gxr=o(" (ResNet model)"),hxr=l(),zC=a("li"),x5e=a("strong"),uxr=o("roberta"),pxr=o(" \u2014 "),QZ=a("a"),_xr=o("TFRobertaModel"),vxr=o(" (RoBERTa model)"),bxr=l(),QC=a("li"),$5e=a("strong"),Fxr=o("roformer"),Txr=o(" \u2014 "),WZ=a("a"),Mxr=o("TFRoFormerModel"),Exr=o(" (RoFormer model)"),Cxr=l(),WC=a("li"),k5e=a("strong"),wxr=o("segformer"),Axr=o(" \u2014 "),UZ=a("a"),Lxr=o("TFSegformerModel"),yxr=o(" (SegFormer model)"),xxr=l(),UC=a("li"),S5e=a("strong"),$xr=o("speech_to_text"),kxr=o(" \u2014 "),HZ=a("a"),Sxr=o("TFSpeech2TextModel"),Rxr=o(" (Speech2Text model)"),Pxr=l(),HC=a("li"),R5e=a("strong"),Bxr=o("swin"),Ixr=o(" \u2014 "),JZ=a("a"),Nxr=o("TFSwinModel"),qxr=o(" (Swin Transformer model)"),jxr=l(),JC=a("li"),P5e=a("strong"),Dxr=o("t5"),Gxr=o(" \u2014 "),YZ=a("a"),Oxr=o("TFT5Model"),Vxr=o(" (T5 model)"),Xxr=l(),YC=a("li"),B5e=a("strong"),zxr=o("tapas"),Qxr=o(" \u2014 "),KZ=a("a"),Wxr=o("TFTapasModel"),Uxr=o(" (TAPAS model)"),Hxr=l(),KC=a("li"),I5e=a("strong"),Jxr=o("transfo-xl"),Yxr=o(" \u2014 "),ZZ=a("a"),Kxr=o("TFTransfoXLModel"),Zxr=o(" (Transformer-XL model)"),e$r=l(),ZC=a("li"),N5e=a("strong"),o$r=o("vit"),r$r=o(" \u2014 "),eee=a("a"),t$r=o("TFViTModel"),a$r=o(" (ViT model)"),n$r=l(),e3=a("li"),q5e=a("strong"),s$r=o("vit_mae"),l$r=o(" \u2014 "),oee=a("a"),i$r=o("TFViTMAEModel"),d$r=o(" (ViTMAE model)"),c$r=l(),o3=a("li"),j5e=a("strong"),f$r=o("wav2vec2"),m$r=o(" \u2014 "),ree=a("a"),g$r=o("TFWav2Vec2Model"),h$r=o(" (Wav2Vec2 model)"),u$r=l(),r3=a("li"),D5e=a("strong"),p$r=o("xglm"),_$r=o(" \u2014 "),tee=a("a"),v$r=o("TFXGLMModel"),b$r=o(" (XGLM model)"),F$r=l(),t3=a("li"),G5e=a("strong"),T$r=o("xlm"),M$r=o(" \u2014 "),aee=a("a"),E$r=o("TFXLMModel"),C$r=o(" (XLM model)"),w$r=l(),a3=a("li"),O5e=a("strong"),A$r=o("xlm-roberta"),L$r=o(" \u2014 "),nee=a("a"),y$r=o("TFXLMRobertaModel"),x$r=o(" (XLM-RoBERTa model)"),$$r=l(),n3=a("li"),V5e=a("strong"),k$r=o("xlnet"),S$r=o(" \u2014 "),see=a("a"),R$r=o("TFXLNetModel"),P$r=o(" (XLNet model)"),B$r=l(),F(s3.$$.fragment),XKe=l(),Xc=a("h2"),l3=a("a"),X5e=a("span"),F(Ck.$$.fragment),I$r=l(),z5e=a("span"),N$r=o("TFAutoModelForPreTraining"),zKe=l(),lr=a("div"),F(wk.$$.fragment),q$r=l(),zc=a("p"),j$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),lee=a("a"),D$r=o("from_pretrained()"),G$r=o(" class method or the "),iee=a("a"),O$r=o("from_config()"),V$r=o(` class
method.`),X$r=l(),Ak=a("p"),z$r=o("This class cannot be instantiated directly using "),Q5e=a("code"),Q$r=o("__init__()"),W$r=o(" (throws an error)."),U$r=l(),zt=a("div"),F(Lk.$$.fragment),H$r=l(),W5e=a("p"),J$r=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Y$r=l(),Qc=a("p"),K$r=o(`Note:
Loading a model from its configuration file does `),U5e=a("strong"),Z$r=o("not"),ekr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dee=a("a"),okr=o("from_pretrained()"),rkr=o(" to load the model weights."),tkr=l(),F(i3.$$.fragment),akr=l(),Nr=a("div"),F(yk.$$.fragment),nkr=l(),H5e=a("p"),skr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),lkr=l(),wn=a("p"),ikr=o("The model class to instantiate is selected based on the "),J5e=a("code"),dkr=o("model_type"),ckr=o(` property of the config object (either
passed as an argument or loaded from `),Y5e=a("code"),fkr=o("pretrained_model_name_or_path"),mkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K5e=a("code"),gkr=o("pretrained_model_name_or_path"),hkr=o(":"),ukr=l(),se=a("ul"),d3=a("li"),Z5e=a("strong"),pkr=o("albert"),_kr=o(" \u2014 "),cee=a("a"),vkr=o("TFAlbertForPreTraining"),bkr=o(" (ALBERT model)"),Fkr=l(),c3=a("li"),ewe=a("strong"),Tkr=o("bart"),Mkr=o(" \u2014 "),fee=a("a"),Ekr=o("TFBartForConditionalGeneration"),Ckr=o(" (BART model)"),wkr=l(),f3=a("li"),owe=a("strong"),Akr=o("bert"),Lkr=o(" \u2014 "),mee=a("a"),ykr=o("TFBertForPreTraining"),xkr=o(" (BERT model)"),$kr=l(),m3=a("li"),rwe=a("strong"),kkr=o("camembert"),Skr=o(" \u2014 "),gee=a("a"),Rkr=o("TFCamembertForMaskedLM"),Pkr=o(" (CamemBERT model)"),Bkr=l(),g3=a("li"),twe=a("strong"),Ikr=o("ctrl"),Nkr=o(" \u2014 "),hee=a("a"),qkr=o("TFCTRLLMHeadModel"),jkr=o(" (CTRL model)"),Dkr=l(),h3=a("li"),awe=a("strong"),Gkr=o("distilbert"),Okr=o(" \u2014 "),uee=a("a"),Vkr=o("TFDistilBertForMaskedLM"),Xkr=o(" (DistilBERT model)"),zkr=l(),u3=a("li"),nwe=a("strong"),Qkr=o("electra"),Wkr=o(" \u2014 "),pee=a("a"),Ukr=o("TFElectraForPreTraining"),Hkr=o(" (ELECTRA model)"),Jkr=l(),p3=a("li"),swe=a("strong"),Ykr=o("flaubert"),Kkr=o(" \u2014 "),_ee=a("a"),Zkr=o("TFFlaubertWithLMHeadModel"),eSr=o(" (FlauBERT model)"),oSr=l(),_3=a("li"),lwe=a("strong"),rSr=o("funnel"),tSr=o(" \u2014 "),vee=a("a"),aSr=o("TFFunnelForPreTraining"),nSr=o(" (Funnel Transformer model)"),sSr=l(),v3=a("li"),iwe=a("strong"),lSr=o("gpt2"),iSr=o(" \u2014 "),bee=a("a"),dSr=o("TFGPT2LMHeadModel"),cSr=o(" (OpenAI GPT-2 model)"),fSr=l(),b3=a("li"),dwe=a("strong"),mSr=o("layoutlm"),gSr=o(" \u2014 "),Fee=a("a"),hSr=o("TFLayoutLMForMaskedLM"),uSr=o(" (LayoutLM model)"),pSr=l(),F3=a("li"),cwe=a("strong"),_Sr=o("lxmert"),vSr=o(" \u2014 "),Tee=a("a"),bSr=o("TFLxmertForPreTraining"),FSr=o(" (LXMERT model)"),TSr=l(),T3=a("li"),fwe=a("strong"),MSr=o("mobilebert"),ESr=o(" \u2014 "),Mee=a("a"),CSr=o("TFMobileBertForPreTraining"),wSr=o(" (MobileBERT model)"),ASr=l(),M3=a("li"),mwe=a("strong"),LSr=o("mpnet"),ySr=o(" \u2014 "),Eee=a("a"),xSr=o("TFMPNetForMaskedLM"),$Sr=o(" (MPNet model)"),kSr=l(),E3=a("li"),gwe=a("strong"),SSr=o("openai-gpt"),RSr=o(" \u2014 "),Cee=a("a"),PSr=o("TFOpenAIGPTLMHeadModel"),BSr=o(" (OpenAI GPT model)"),ISr=l(),C3=a("li"),hwe=a("strong"),NSr=o("roberta"),qSr=o(" \u2014 "),wee=a("a"),jSr=o("TFRobertaForMaskedLM"),DSr=o(" (RoBERTa model)"),GSr=l(),w3=a("li"),uwe=a("strong"),OSr=o("t5"),VSr=o(" \u2014 "),Aee=a("a"),XSr=o("TFT5ForConditionalGeneration"),zSr=o(" (T5 model)"),QSr=l(),A3=a("li"),pwe=a("strong"),WSr=o("tapas"),USr=o(" \u2014 "),Lee=a("a"),HSr=o("TFTapasForMaskedLM"),JSr=o(" (TAPAS model)"),YSr=l(),L3=a("li"),_we=a("strong"),KSr=o("transfo-xl"),ZSr=o(" \u2014 "),yee=a("a"),eRr=o("TFTransfoXLLMHeadModel"),oRr=o(" (Transformer-XL model)"),rRr=l(),y3=a("li"),vwe=a("strong"),tRr=o("vit_mae"),aRr=o(" \u2014 "),xee=a("a"),nRr=o("TFViTMAEForPreTraining"),sRr=o(" (ViTMAE model)"),lRr=l(),x3=a("li"),bwe=a("strong"),iRr=o("xlm"),dRr=o(" \u2014 "),$ee=a("a"),cRr=o("TFXLMWithLMHeadModel"),fRr=o(" (XLM model)"),mRr=l(),$3=a("li"),Fwe=a("strong"),gRr=o("xlm-roberta"),hRr=o(" \u2014 "),kee=a("a"),uRr=o("TFXLMRobertaForMaskedLM"),pRr=o(" (XLM-RoBERTa model)"),_Rr=l(),k3=a("li"),Twe=a("strong"),vRr=o("xlnet"),bRr=o(" \u2014 "),See=a("a"),FRr=o("TFXLNetLMHeadModel"),TRr=o(" (XLNet model)"),MRr=l(),F(S3.$$.fragment),QKe=l(),Wc=a("h2"),R3=a("a"),Mwe=a("span"),F(xk.$$.fragment),ERr=l(),Ewe=a("span"),CRr=o("TFAutoModelForCausalLM"),WKe=l(),ir=a("div"),F($k.$$.fragment),wRr=l(),Uc=a("p"),ARr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Ree=a("a"),LRr=o("from_pretrained()"),yRr=o(" class method or the "),Pee=a("a"),xRr=o("from_config()"),$Rr=o(` class
method.`),kRr=l(),kk=a("p"),SRr=o("This class cannot be instantiated directly using "),Cwe=a("code"),RRr=o("__init__()"),PRr=o(" (throws an error)."),BRr=l(),Qt=a("div"),F(Sk.$$.fragment),IRr=l(),wwe=a("p"),NRr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),qRr=l(),Hc=a("p"),jRr=o(`Note:
Loading a model from its configuration file does `),Awe=a("strong"),DRr=o("not"),GRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bee=a("a"),ORr=o("from_pretrained()"),VRr=o(" to load the model weights."),XRr=l(),F(P3.$$.fragment),zRr=l(),qr=a("div"),F(Rk.$$.fragment),QRr=l(),Lwe=a("p"),WRr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),URr=l(),An=a("p"),HRr=o("The model class to instantiate is selected based on the "),ywe=a("code"),JRr=o("model_type"),YRr=o(` property of the config object (either
passed as an argument or loaded from `),xwe=a("code"),KRr=o("pretrained_model_name_or_path"),ZRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$we=a("code"),ePr=o("pretrained_model_name_or_path"),oPr=o(":"),rPr=l(),Me=a("ul"),B3=a("li"),kwe=a("strong"),tPr=o("bert"),aPr=o(" \u2014 "),Iee=a("a"),nPr=o("TFBertLMHeadModel"),sPr=o(" (BERT model)"),lPr=l(),I3=a("li"),Swe=a("strong"),iPr=o("camembert"),dPr=o(" \u2014 "),Nee=a("a"),cPr=o("TFCamembertForCausalLM"),fPr=o(" (CamemBERT model)"),mPr=l(),N3=a("li"),Rwe=a("strong"),gPr=o("ctrl"),hPr=o(" \u2014 "),qee=a("a"),uPr=o("TFCTRLLMHeadModel"),pPr=o(" (CTRL model)"),_Pr=l(),q3=a("li"),Pwe=a("strong"),vPr=o("gpt2"),bPr=o(" \u2014 "),jee=a("a"),FPr=o("TFGPT2LMHeadModel"),TPr=o(" (OpenAI GPT-2 model)"),MPr=l(),j3=a("li"),Bwe=a("strong"),EPr=o("gptj"),CPr=o(" \u2014 "),Dee=a("a"),wPr=o("TFGPTJForCausalLM"),APr=o(" (GPT-J model)"),LPr=l(),D3=a("li"),Iwe=a("strong"),yPr=o("openai-gpt"),xPr=o(" \u2014 "),Gee=a("a"),$Pr=o("TFOpenAIGPTLMHeadModel"),kPr=o(" (OpenAI GPT model)"),SPr=l(),G3=a("li"),Nwe=a("strong"),RPr=o("opt"),PPr=o(" \u2014 "),Oee=a("a"),BPr=o("TFOPTForCausalLM"),IPr=o(" (OPT model)"),NPr=l(),O3=a("li"),qwe=a("strong"),qPr=o("rembert"),jPr=o(" \u2014 "),Vee=a("a"),DPr=o("TFRemBertForCausalLM"),GPr=o(" (RemBERT model)"),OPr=l(),V3=a("li"),jwe=a("strong"),VPr=o("roberta"),XPr=o(" \u2014 "),Xee=a("a"),zPr=o("TFRobertaForCausalLM"),QPr=o(" (RoBERTa model)"),WPr=l(),X3=a("li"),Dwe=a("strong"),UPr=o("roformer"),HPr=o(" \u2014 "),zee=a("a"),JPr=o("TFRoFormerForCausalLM"),YPr=o(" (RoFormer model)"),KPr=l(),z3=a("li"),Gwe=a("strong"),ZPr=o("transfo-xl"),eBr=o(" \u2014 "),Qee=a("a"),oBr=o("TFTransfoXLLMHeadModel"),rBr=o(" (Transformer-XL model)"),tBr=l(),Q3=a("li"),Owe=a("strong"),aBr=o("xglm"),nBr=o(" \u2014 "),Wee=a("a"),sBr=o("TFXGLMForCausalLM"),lBr=o(" (XGLM model)"),iBr=l(),W3=a("li"),Vwe=a("strong"),dBr=o("xlm"),cBr=o(" \u2014 "),Uee=a("a"),fBr=o("TFXLMWithLMHeadModel"),mBr=o(" (XLM model)"),gBr=l(),U3=a("li"),Xwe=a("strong"),hBr=o("xlnet"),uBr=o(" \u2014 "),Hee=a("a"),pBr=o("TFXLNetLMHeadModel"),_Br=o(" (XLNet model)"),vBr=l(),F(H3.$$.fragment),UKe=l(),Jc=a("h2"),J3=a("a"),zwe=a("span"),F(Pk.$$.fragment),bBr=l(),Qwe=a("span"),FBr=o("TFAutoModelForImageClassification"),HKe=l(),dr=a("div"),F(Bk.$$.fragment),TBr=l(),Yc=a("p"),MBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Jee=a("a"),EBr=o("from_pretrained()"),CBr=o(" class method or the "),Yee=a("a"),wBr=o("from_config()"),ABr=o(` class
method.`),LBr=l(),Ik=a("p"),yBr=o("This class cannot be instantiated directly using "),Wwe=a("code"),xBr=o("__init__()"),$Br=o(" (throws an error)."),kBr=l(),Wt=a("div"),F(Nk.$$.fragment),SBr=l(),Uwe=a("p"),RBr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),PBr=l(),Kc=a("p"),BBr=o(`Note:
Loading a model from its configuration file does `),Hwe=a("strong"),IBr=o("not"),NBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kee=a("a"),qBr=o("from_pretrained()"),jBr=o(" to load the model weights."),DBr=l(),F(Y3.$$.fragment),GBr=l(),jr=a("div"),F(qk.$$.fragment),OBr=l(),Jwe=a("p"),VBr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),XBr=l(),Ln=a("p"),zBr=o("The model class to instantiate is selected based on the "),Ywe=a("code"),QBr=o("model_type"),WBr=o(` property of the config object (either
passed as an argument or loaded from `),Kwe=a("code"),UBr=o("pretrained_model_name_or_path"),HBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zwe=a("code"),JBr=o("pretrained_model_name_or_path"),YBr=o(":"),KBr=l(),Be=a("ul"),K3=a("li"),eAe=a("strong"),ZBr=o("convnext"),eIr=o(" \u2014 "),Zee=a("a"),oIr=o("TFConvNextForImageClassification"),rIr=o(" (ConvNeXT model)"),tIr=l(),Z3=a("li"),oAe=a("strong"),aIr=o("data2vec-vision"),nIr=o(" \u2014 "),eoe=a("a"),sIr=o("TFData2VecVisionForImageClassification"),lIr=o(" (Data2VecVision model)"),iIr=l(),Fl=a("li"),rAe=a("strong"),dIr=o("deit"),cIr=o(" \u2014 "),ooe=a("a"),fIr=o("TFDeiTForImageClassification"),mIr=o(" or "),roe=a("a"),gIr=o("TFDeiTForImageClassificationWithTeacher"),hIr=o(" (DeiT model)"),uIr=l(),e5=a("li"),tAe=a("strong"),pIr=o("mobilevit"),_Ir=o(" \u2014 "),toe=a("a"),vIr=o("TFMobileViTForImageClassification"),bIr=o(" (MobileViT model)"),FIr=l(),o5=a("li"),aAe=a("strong"),TIr=o("regnet"),MIr=o(" \u2014 "),aoe=a("a"),EIr=o("TFRegNetForImageClassification"),CIr=o(" (RegNet model)"),wIr=l(),r5=a("li"),nAe=a("strong"),AIr=o("resnet"),LIr=o(" \u2014 "),noe=a("a"),yIr=o("TFResNetForImageClassification"),xIr=o(" (ResNet model)"),$Ir=l(),t5=a("li"),sAe=a("strong"),kIr=o("segformer"),SIr=o(" \u2014 "),soe=a("a"),RIr=o("TFSegformerForImageClassification"),PIr=o(" (SegFormer model)"),BIr=l(),a5=a("li"),lAe=a("strong"),IIr=o("swin"),NIr=o(" \u2014 "),loe=a("a"),qIr=o("TFSwinForImageClassification"),jIr=o(" (Swin Transformer model)"),DIr=l(),n5=a("li"),iAe=a("strong"),GIr=o("vit"),OIr=o(" \u2014 "),ioe=a("a"),VIr=o("TFViTForImageClassification"),XIr=o(" (ViT model)"),zIr=l(),F(s5.$$.fragment),JKe=l(),Zc=a("h2"),l5=a("a"),dAe=a("span"),F(jk.$$.fragment),QIr=l(),cAe=a("span"),WIr=o("TFAutoModelForSemanticSegmentation"),YKe=l(),cr=a("div"),F(Dk.$$.fragment),UIr=l(),ef=a("p"),HIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),doe=a("a"),JIr=o("from_pretrained()"),YIr=o(" class method or the "),coe=a("a"),KIr=o("from_config()"),ZIr=o(` class
method.`),eNr=l(),Gk=a("p"),oNr=o("This class cannot be instantiated directly using "),fAe=a("code"),rNr=o("__init__()"),tNr=o(" (throws an error)."),aNr=l(),Ut=a("div"),F(Ok.$$.fragment),nNr=l(),mAe=a("p"),sNr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),lNr=l(),of=a("p"),iNr=o(`Note:
Loading a model from its configuration file does `),gAe=a("strong"),dNr=o("not"),cNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),foe=a("a"),fNr=o("from_pretrained()"),mNr=o(" to load the model weights."),gNr=l(),F(i5.$$.fragment),hNr=l(),Dr=a("div"),F(Vk.$$.fragment),uNr=l(),hAe=a("p"),pNr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),_Nr=l(),yn=a("p"),vNr=o("The model class to instantiate is selected based on the "),uAe=a("code"),bNr=o("model_type"),FNr=o(` property of the config object (either
passed as an argument or loaded from `),pAe=a("code"),TNr=o("pretrained_model_name_or_path"),MNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Ae=a("code"),ENr=o("pretrained_model_name_or_path"),CNr=o(":"),wNr=l(),rf=a("ul"),d5=a("li"),vAe=a("strong"),ANr=o("data2vec-vision"),LNr=o(" \u2014 "),moe=a("a"),yNr=o("TFData2VecVisionForSemanticSegmentation"),xNr=o(" (Data2VecVision model)"),$Nr=l(),c5=a("li"),bAe=a("strong"),kNr=o("mobilevit"),SNr=o(" \u2014 "),goe=a("a"),RNr=o("TFMobileViTForSemanticSegmentation"),PNr=o(" (MobileViT model)"),BNr=l(),f5=a("li"),FAe=a("strong"),INr=o("segformer"),NNr=o(" \u2014 "),hoe=a("a"),qNr=o("TFSegformerForSemanticSegmentation"),jNr=o(" (SegFormer model)"),DNr=l(),F(m5.$$.fragment),KKe=l(),tf=a("h2"),g5=a("a"),TAe=a("span"),F(Xk.$$.fragment),GNr=l(),MAe=a("span"),ONr=o("TFAutoModelForMaskedLM"),ZKe=l(),fr=a("div"),F(zk.$$.fragment),VNr=l(),af=a("p"),XNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),uoe=a("a"),zNr=o("from_pretrained()"),QNr=o(" class method or the "),poe=a("a"),WNr=o("from_config()"),UNr=o(` class
method.`),HNr=l(),Qk=a("p"),JNr=o("This class cannot be instantiated directly using "),EAe=a("code"),YNr=o("__init__()"),KNr=o(" (throws an error)."),ZNr=l(),Ht=a("div"),F(Wk.$$.fragment),eqr=l(),CAe=a("p"),oqr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),rqr=l(),nf=a("p"),tqr=o(`Note:
Loading a model from its configuration file does `),wAe=a("strong"),aqr=o("not"),nqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_oe=a("a"),sqr=o("from_pretrained()"),lqr=o(" to load the model weights."),iqr=l(),F(h5.$$.fragment),dqr=l(),Gr=a("div"),F(Uk.$$.fragment),cqr=l(),AAe=a("p"),fqr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),mqr=l(),xn=a("p"),gqr=o("The model class to instantiate is selected based on the "),LAe=a("code"),hqr=o("model_type"),uqr=o(` property of the config object (either
passed as an argument or loaded from `),yAe=a("code"),pqr=o("pretrained_model_name_or_path"),_qr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xAe=a("code"),vqr=o("pretrained_model_name_or_path"),bqr=o(":"),Fqr=l(),me=a("ul"),u5=a("li"),$Ae=a("strong"),Tqr=o("albert"),Mqr=o(" \u2014 "),voe=a("a"),Eqr=o("TFAlbertForMaskedLM"),Cqr=o(" (ALBERT model)"),wqr=l(),p5=a("li"),kAe=a("strong"),Aqr=o("bert"),Lqr=o(" \u2014 "),boe=a("a"),yqr=o("TFBertForMaskedLM"),xqr=o(" (BERT model)"),$qr=l(),_5=a("li"),SAe=a("strong"),kqr=o("camembert"),Sqr=o(" \u2014 "),Foe=a("a"),Rqr=o("TFCamembertForMaskedLM"),Pqr=o(" (CamemBERT model)"),Bqr=l(),v5=a("li"),RAe=a("strong"),Iqr=o("convbert"),Nqr=o(" \u2014 "),Toe=a("a"),qqr=o("TFConvBertForMaskedLM"),jqr=o(" (ConvBERT model)"),Dqr=l(),b5=a("li"),PAe=a("strong"),Gqr=o("deberta"),Oqr=o(" \u2014 "),Moe=a("a"),Vqr=o("TFDebertaForMaskedLM"),Xqr=o(" (DeBERTa model)"),zqr=l(),F5=a("li"),BAe=a("strong"),Qqr=o("deberta-v2"),Wqr=o(" \u2014 "),Eoe=a("a"),Uqr=o("TFDebertaV2ForMaskedLM"),Hqr=o(" (DeBERTa-v2 model)"),Jqr=l(),T5=a("li"),IAe=a("strong"),Yqr=o("distilbert"),Kqr=o(" \u2014 "),Coe=a("a"),Zqr=o("TFDistilBertForMaskedLM"),ejr=o(" (DistilBERT model)"),ojr=l(),M5=a("li"),NAe=a("strong"),rjr=o("electra"),tjr=o(" \u2014 "),woe=a("a"),ajr=o("TFElectraForMaskedLM"),njr=o(" (ELECTRA model)"),sjr=l(),E5=a("li"),qAe=a("strong"),ljr=o("flaubert"),ijr=o(" \u2014 "),Aoe=a("a"),djr=o("TFFlaubertWithLMHeadModel"),cjr=o(" (FlauBERT model)"),fjr=l(),C5=a("li"),jAe=a("strong"),mjr=o("funnel"),gjr=o(" \u2014 "),Loe=a("a"),hjr=o("TFFunnelForMaskedLM"),ujr=o(" (Funnel Transformer model)"),pjr=l(),w5=a("li"),DAe=a("strong"),_jr=o("layoutlm"),vjr=o(" \u2014 "),yoe=a("a"),bjr=o("TFLayoutLMForMaskedLM"),Fjr=o(" (LayoutLM model)"),Tjr=l(),A5=a("li"),GAe=a("strong"),Mjr=o("longformer"),Ejr=o(" \u2014 "),xoe=a("a"),Cjr=o("TFLongformerForMaskedLM"),wjr=o(" (Longformer model)"),Ajr=l(),L5=a("li"),OAe=a("strong"),Ljr=o("mobilebert"),yjr=o(" \u2014 "),$oe=a("a"),xjr=o("TFMobileBertForMaskedLM"),$jr=o(" (MobileBERT model)"),kjr=l(),y5=a("li"),VAe=a("strong"),Sjr=o("mpnet"),Rjr=o(" \u2014 "),koe=a("a"),Pjr=o("TFMPNetForMaskedLM"),Bjr=o(" (MPNet model)"),Ijr=l(),x5=a("li"),XAe=a("strong"),Njr=o("rembert"),qjr=o(" \u2014 "),Soe=a("a"),jjr=o("TFRemBertForMaskedLM"),Djr=o(" (RemBERT model)"),Gjr=l(),$5=a("li"),zAe=a("strong"),Ojr=o("roberta"),Vjr=o(" \u2014 "),Roe=a("a"),Xjr=o("TFRobertaForMaskedLM"),zjr=o(" (RoBERTa model)"),Qjr=l(),k5=a("li"),QAe=a("strong"),Wjr=o("roformer"),Ujr=o(" \u2014 "),Poe=a("a"),Hjr=o("TFRoFormerForMaskedLM"),Jjr=o(" (RoFormer model)"),Yjr=l(),S5=a("li"),WAe=a("strong"),Kjr=o("tapas"),Zjr=o(" \u2014 "),Boe=a("a"),eDr=o("TFTapasForMaskedLM"),oDr=o(" (TAPAS model)"),rDr=l(),R5=a("li"),UAe=a("strong"),tDr=o("xlm"),aDr=o(" \u2014 "),Ioe=a("a"),nDr=o("TFXLMWithLMHeadModel"),sDr=o(" (XLM model)"),lDr=l(),P5=a("li"),HAe=a("strong"),iDr=o("xlm-roberta"),dDr=o(" \u2014 "),Noe=a("a"),cDr=o("TFXLMRobertaForMaskedLM"),fDr=o(" (XLM-RoBERTa model)"),mDr=l(),F(B5.$$.fragment),eZe=l(),sf=a("h2"),I5=a("a"),JAe=a("span"),F(Hk.$$.fragment),gDr=l(),YAe=a("span"),hDr=o("TFAutoModelForSeq2SeqLM"),oZe=l(),mr=a("div"),F(Jk.$$.fragment),uDr=l(),lf=a("p"),pDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),qoe=a("a"),_Dr=o("from_pretrained()"),vDr=o(" class method or the "),joe=a("a"),bDr=o("from_config()"),FDr=o(` class
method.`),TDr=l(),Yk=a("p"),MDr=o("This class cannot be instantiated directly using "),KAe=a("code"),EDr=o("__init__()"),CDr=o(" (throws an error)."),wDr=l(),Jt=a("div"),F(Kk.$$.fragment),ADr=l(),ZAe=a("p"),LDr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),yDr=l(),df=a("p"),xDr=o(`Note:
Loading a model from its configuration file does `),e6e=a("strong"),$Dr=o("not"),kDr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Doe=a("a"),SDr=o("from_pretrained()"),RDr=o(" to load the model weights."),PDr=l(),F(N5.$$.fragment),BDr=l(),Or=a("div"),F(Zk.$$.fragment),IDr=l(),o6e=a("p"),NDr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),qDr=l(),$n=a("p"),jDr=o("The model class to instantiate is selected based on the "),r6e=a("code"),DDr=o("model_type"),GDr=o(` property of the config object (either
passed as an argument or loaded from `),t6e=a("code"),ODr=o("pretrained_model_name_or_path"),VDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a6e=a("code"),XDr=o("pretrained_model_name_or_path"),zDr=o(":"),QDr=l(),ye=a("ul"),q5=a("li"),n6e=a("strong"),WDr=o("bart"),UDr=o(" \u2014 "),Goe=a("a"),HDr=o("TFBartForConditionalGeneration"),JDr=o(" (BART model)"),YDr=l(),j5=a("li"),s6e=a("strong"),KDr=o("blenderbot"),ZDr=o(" \u2014 "),Ooe=a("a"),eGr=o("TFBlenderbotForConditionalGeneration"),oGr=o(" (Blenderbot model)"),rGr=l(),D5=a("li"),l6e=a("strong"),tGr=o("blenderbot-small"),aGr=o(" \u2014 "),Voe=a("a"),nGr=o("TFBlenderbotSmallForConditionalGeneration"),sGr=o(" (BlenderbotSmall model)"),lGr=l(),G5=a("li"),i6e=a("strong"),iGr=o("encoder-decoder"),dGr=o(" \u2014 "),Xoe=a("a"),cGr=o("TFEncoderDecoderModel"),fGr=o(" (Encoder decoder model)"),mGr=l(),O5=a("li"),d6e=a("strong"),gGr=o("led"),hGr=o(" \u2014 "),zoe=a("a"),uGr=o("TFLEDForConditionalGeneration"),pGr=o(" (LED model)"),_Gr=l(),V5=a("li"),c6e=a("strong"),vGr=o("marian"),bGr=o(" \u2014 "),Qoe=a("a"),FGr=o("TFMarianMTModel"),TGr=o(" (Marian model)"),MGr=l(),X5=a("li"),f6e=a("strong"),EGr=o("mbart"),CGr=o(" \u2014 "),Woe=a("a"),wGr=o("TFMBartForConditionalGeneration"),AGr=o(" (mBART model)"),LGr=l(),z5=a("li"),m6e=a("strong"),yGr=o("mt5"),xGr=o(" \u2014 "),Uoe=a("a"),$Gr=o("TFMT5ForConditionalGeneration"),kGr=o(" (MT5 model)"),SGr=l(),Q5=a("li"),g6e=a("strong"),RGr=o("pegasus"),PGr=o(" \u2014 "),Hoe=a("a"),BGr=o("TFPegasusForConditionalGeneration"),IGr=o(" (Pegasus model)"),NGr=l(),W5=a("li"),h6e=a("strong"),qGr=o("t5"),jGr=o(" \u2014 "),Joe=a("a"),DGr=o("TFT5ForConditionalGeneration"),GGr=o(" (T5 model)"),OGr=l(),F(U5.$$.fragment),rZe=l(),cf=a("h2"),H5=a("a"),u6e=a("span"),F(eS.$$.fragment),VGr=l(),p6e=a("span"),XGr=o("TFAutoModelForSequenceClassification"),tZe=l(),gr=a("div"),F(oS.$$.fragment),zGr=l(),ff=a("p"),QGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Yoe=a("a"),WGr=o("from_pretrained()"),UGr=o(" class method or the "),Koe=a("a"),HGr=o("from_config()"),JGr=o(` class
method.`),YGr=l(),rS=a("p"),KGr=o("This class cannot be instantiated directly using "),_6e=a("code"),ZGr=o("__init__()"),eOr=o(" (throws an error)."),oOr=l(),Yt=a("div"),F(tS.$$.fragment),rOr=l(),v6e=a("p"),tOr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),aOr=l(),mf=a("p"),nOr=o(`Note:
Loading a model from its configuration file does `),b6e=a("strong"),sOr=o("not"),lOr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zoe=a("a"),iOr=o("from_pretrained()"),dOr=o(" to load the model weights."),cOr=l(),F(J5.$$.fragment),fOr=l(),Vr=a("div"),F(aS.$$.fragment),mOr=l(),F6e=a("p"),gOr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),hOr=l(),kn=a("p"),uOr=o("The model class to instantiate is selected based on the "),T6e=a("code"),pOr=o("model_type"),_Or=o(` property of the config object (either
passed as an argument or loaded from `),M6e=a("code"),vOr=o("pretrained_model_name_or_path"),bOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E6e=a("code"),FOr=o("pretrained_model_name_or_path"),TOr=o(":"),MOr=l(),re=a("ul"),Y5=a("li"),C6e=a("strong"),EOr=o("albert"),COr=o(" \u2014 "),ere=a("a"),wOr=o("TFAlbertForSequenceClassification"),AOr=o(" (ALBERT model)"),LOr=l(),K5=a("li"),w6e=a("strong"),yOr=o("bert"),xOr=o(" \u2014 "),ore=a("a"),$Or=o("TFBertForSequenceClassification"),kOr=o(" (BERT model)"),SOr=l(),Z5=a("li"),A6e=a("strong"),ROr=o("camembert"),POr=o(" \u2014 "),rre=a("a"),BOr=o("TFCamembertForSequenceClassification"),IOr=o(" (CamemBERT model)"),NOr=l(),ew=a("li"),L6e=a("strong"),qOr=o("convbert"),jOr=o(" \u2014 "),tre=a("a"),DOr=o("TFConvBertForSequenceClassification"),GOr=o(" (ConvBERT model)"),OOr=l(),ow=a("li"),y6e=a("strong"),VOr=o("ctrl"),XOr=o(" \u2014 "),are=a("a"),zOr=o("TFCTRLForSequenceClassification"),QOr=o(" (CTRL model)"),WOr=l(),rw=a("li"),x6e=a("strong"),UOr=o("deberta"),HOr=o(" \u2014 "),nre=a("a"),JOr=o("TFDebertaForSequenceClassification"),YOr=o(" (DeBERTa model)"),KOr=l(),tw=a("li"),$6e=a("strong"),ZOr=o("deberta-v2"),eVr=o(" \u2014 "),sre=a("a"),oVr=o("TFDebertaV2ForSequenceClassification"),rVr=o(" (DeBERTa-v2 model)"),tVr=l(),aw=a("li"),k6e=a("strong"),aVr=o("distilbert"),nVr=o(" \u2014 "),lre=a("a"),sVr=o("TFDistilBertForSequenceClassification"),lVr=o(" (DistilBERT model)"),iVr=l(),nw=a("li"),S6e=a("strong"),dVr=o("electra"),cVr=o(" \u2014 "),ire=a("a"),fVr=o("TFElectraForSequenceClassification"),mVr=o(" (ELECTRA model)"),gVr=l(),sw=a("li"),R6e=a("strong"),hVr=o("flaubert"),uVr=o(" \u2014 "),dre=a("a"),pVr=o("TFFlaubertForSequenceClassification"),_Vr=o(" (FlauBERT model)"),vVr=l(),lw=a("li"),P6e=a("strong"),bVr=o("funnel"),FVr=o(" \u2014 "),cre=a("a"),TVr=o("TFFunnelForSequenceClassification"),MVr=o(" (Funnel Transformer model)"),EVr=l(),iw=a("li"),B6e=a("strong"),CVr=o("gpt2"),wVr=o(" \u2014 "),fre=a("a"),AVr=o("TFGPT2ForSequenceClassification"),LVr=o(" (OpenAI GPT-2 model)"),yVr=l(),dw=a("li"),I6e=a("strong"),xVr=o("gptj"),$Vr=o(" \u2014 "),mre=a("a"),kVr=o("TFGPTJForSequenceClassification"),SVr=o(" (GPT-J model)"),RVr=l(),cw=a("li"),N6e=a("strong"),PVr=o("layoutlm"),BVr=o(" \u2014 "),gre=a("a"),IVr=o("TFLayoutLMForSequenceClassification"),NVr=o(" (LayoutLM model)"),qVr=l(),fw=a("li"),q6e=a("strong"),jVr=o("layoutlmv3"),DVr=o(" \u2014 "),hre=a("a"),GVr=o("TFLayoutLMv3ForSequenceClassification"),OVr=o(" (LayoutLMv3 model)"),VVr=l(),mw=a("li"),j6e=a("strong"),XVr=o("longformer"),zVr=o(" \u2014 "),ure=a("a"),QVr=o("TFLongformerForSequenceClassification"),WVr=o(" (Longformer model)"),UVr=l(),gw=a("li"),D6e=a("strong"),HVr=o("mobilebert"),JVr=o(" \u2014 "),pre=a("a"),YVr=o("TFMobileBertForSequenceClassification"),KVr=o(" (MobileBERT model)"),ZVr=l(),hw=a("li"),G6e=a("strong"),eXr=o("mpnet"),oXr=o(" \u2014 "),_re=a("a"),rXr=o("TFMPNetForSequenceClassification"),tXr=o(" (MPNet model)"),aXr=l(),uw=a("li"),O6e=a("strong"),nXr=o("openai-gpt"),sXr=o(" \u2014 "),vre=a("a"),lXr=o("TFOpenAIGPTForSequenceClassification"),iXr=o(" (OpenAI GPT model)"),dXr=l(),pw=a("li"),V6e=a("strong"),cXr=o("rembert"),fXr=o(" \u2014 "),bre=a("a"),mXr=o("TFRemBertForSequenceClassification"),gXr=o(" (RemBERT model)"),hXr=l(),_w=a("li"),X6e=a("strong"),uXr=o("roberta"),pXr=o(" \u2014 "),Fre=a("a"),_Xr=o("TFRobertaForSequenceClassification"),vXr=o(" (RoBERTa model)"),bXr=l(),vw=a("li"),z6e=a("strong"),FXr=o("roformer"),TXr=o(" \u2014 "),Tre=a("a"),MXr=o("TFRoFormerForSequenceClassification"),EXr=o(" (RoFormer model)"),CXr=l(),bw=a("li"),Q6e=a("strong"),wXr=o("tapas"),AXr=o(" \u2014 "),Mre=a("a"),LXr=o("TFTapasForSequenceClassification"),yXr=o(" (TAPAS model)"),xXr=l(),Fw=a("li"),W6e=a("strong"),$Xr=o("transfo-xl"),kXr=o(" \u2014 "),Ere=a("a"),SXr=o("TFTransfoXLForSequenceClassification"),RXr=o(" (Transformer-XL model)"),PXr=l(),Tw=a("li"),U6e=a("strong"),BXr=o("xlm"),IXr=o(" \u2014 "),Cre=a("a"),NXr=o("TFXLMForSequenceClassification"),qXr=o(" (XLM model)"),jXr=l(),Mw=a("li"),H6e=a("strong"),DXr=o("xlm-roberta"),GXr=o(" \u2014 "),wre=a("a"),OXr=o("TFXLMRobertaForSequenceClassification"),VXr=o(" (XLM-RoBERTa model)"),XXr=l(),Ew=a("li"),J6e=a("strong"),zXr=o("xlnet"),QXr=o(" \u2014 "),Are=a("a"),WXr=o("TFXLNetForSequenceClassification"),UXr=o(" (XLNet model)"),HXr=l(),F(Cw.$$.fragment),aZe=l(),gf=a("h2"),ww=a("a"),Y6e=a("span"),F(nS.$$.fragment),JXr=l(),K6e=a("span"),YXr=o("TFAutoModelForMultipleChoice"),nZe=l(),hr=a("div"),F(sS.$$.fragment),KXr=l(),hf=a("p"),ZXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Lre=a("a"),ezr=o("from_pretrained()"),ozr=o(" class method or the "),yre=a("a"),rzr=o("from_config()"),tzr=o(` class
method.`),azr=l(),lS=a("p"),nzr=o("This class cannot be instantiated directly using "),Z6e=a("code"),szr=o("__init__()"),lzr=o(" (throws an error)."),izr=l(),Kt=a("div"),F(iS.$$.fragment),dzr=l(),e7e=a("p"),czr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),fzr=l(),uf=a("p"),mzr=o(`Note:
Loading a model from its configuration file does `),o7e=a("strong"),gzr=o("not"),hzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xre=a("a"),uzr=o("from_pretrained()"),pzr=o(" to load the model weights."),_zr=l(),F(Aw.$$.fragment),vzr=l(),Xr=a("div"),F(dS.$$.fragment),bzr=l(),r7e=a("p"),Fzr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Tzr=l(),Sn=a("p"),Mzr=o("The model class to instantiate is selected based on the "),t7e=a("code"),Ezr=o("model_type"),Czr=o(` property of the config object (either
passed as an argument or loaded from `),a7e=a("code"),wzr=o("pretrained_model_name_or_path"),Azr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n7e=a("code"),Lzr=o("pretrained_model_name_or_path"),yzr=o(":"),xzr=l(),be=a("ul"),Lw=a("li"),s7e=a("strong"),$zr=o("albert"),kzr=o(" \u2014 "),$re=a("a"),Szr=o("TFAlbertForMultipleChoice"),Rzr=o(" (ALBERT model)"),Pzr=l(),yw=a("li"),l7e=a("strong"),Bzr=o("bert"),Izr=o(" \u2014 "),kre=a("a"),Nzr=o("TFBertForMultipleChoice"),qzr=o(" (BERT model)"),jzr=l(),xw=a("li"),i7e=a("strong"),Dzr=o("camembert"),Gzr=o(" \u2014 "),Sre=a("a"),Ozr=o("TFCamembertForMultipleChoice"),Vzr=o(" (CamemBERT model)"),Xzr=l(),$w=a("li"),d7e=a("strong"),zzr=o("convbert"),Qzr=o(" \u2014 "),Rre=a("a"),Wzr=o("TFConvBertForMultipleChoice"),Uzr=o(" (ConvBERT model)"),Hzr=l(),kw=a("li"),c7e=a("strong"),Jzr=o("distilbert"),Yzr=o(" \u2014 "),Pre=a("a"),Kzr=o("TFDistilBertForMultipleChoice"),Zzr=o(" (DistilBERT model)"),eQr=l(),Sw=a("li"),f7e=a("strong"),oQr=o("electra"),rQr=o(" \u2014 "),Bre=a("a"),tQr=o("TFElectraForMultipleChoice"),aQr=o(" (ELECTRA model)"),nQr=l(),Rw=a("li"),m7e=a("strong"),sQr=o("flaubert"),lQr=o(" \u2014 "),Ire=a("a"),iQr=o("TFFlaubertForMultipleChoice"),dQr=o(" (FlauBERT model)"),cQr=l(),Pw=a("li"),g7e=a("strong"),fQr=o("funnel"),mQr=o(" \u2014 "),Nre=a("a"),gQr=o("TFFunnelForMultipleChoice"),hQr=o(" (Funnel Transformer model)"),uQr=l(),Bw=a("li"),h7e=a("strong"),pQr=o("longformer"),_Qr=o(" \u2014 "),qre=a("a"),vQr=o("TFLongformerForMultipleChoice"),bQr=o(" (Longformer model)"),FQr=l(),Iw=a("li"),u7e=a("strong"),TQr=o("mobilebert"),MQr=o(" \u2014 "),jre=a("a"),EQr=o("TFMobileBertForMultipleChoice"),CQr=o(" (MobileBERT model)"),wQr=l(),Nw=a("li"),p7e=a("strong"),AQr=o("mpnet"),LQr=o(" \u2014 "),Dre=a("a"),yQr=o("TFMPNetForMultipleChoice"),xQr=o(" (MPNet model)"),$Qr=l(),qw=a("li"),_7e=a("strong"),kQr=o("rembert"),SQr=o(" \u2014 "),Gre=a("a"),RQr=o("TFRemBertForMultipleChoice"),PQr=o(" (RemBERT model)"),BQr=l(),jw=a("li"),v7e=a("strong"),IQr=o("roberta"),NQr=o(" \u2014 "),Ore=a("a"),qQr=o("TFRobertaForMultipleChoice"),jQr=o(" (RoBERTa model)"),DQr=l(),Dw=a("li"),b7e=a("strong"),GQr=o("roformer"),OQr=o(" \u2014 "),Vre=a("a"),VQr=o("TFRoFormerForMultipleChoice"),XQr=o(" (RoFormer model)"),zQr=l(),Gw=a("li"),F7e=a("strong"),QQr=o("xlm"),WQr=o(" \u2014 "),Xre=a("a"),UQr=o("TFXLMForMultipleChoice"),HQr=o(" (XLM model)"),JQr=l(),Ow=a("li"),T7e=a("strong"),YQr=o("xlm-roberta"),KQr=o(" \u2014 "),zre=a("a"),ZQr=o("TFXLMRobertaForMultipleChoice"),eWr=o(" (XLM-RoBERTa model)"),oWr=l(),Vw=a("li"),M7e=a("strong"),rWr=o("xlnet"),tWr=o(" \u2014 "),Qre=a("a"),aWr=o("TFXLNetForMultipleChoice"),nWr=o(" (XLNet model)"),sWr=l(),F(Xw.$$.fragment),sZe=l(),pf=a("h2"),zw=a("a"),E7e=a("span"),F(cS.$$.fragment),lWr=l(),C7e=a("span"),iWr=o("TFAutoModelForNextSentencePrediction"),lZe=l(),ur=a("div"),F(fS.$$.fragment),dWr=l(),_f=a("p"),cWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Wre=a("a"),fWr=o("from_pretrained()"),mWr=o(" class method or the "),Ure=a("a"),gWr=o("from_config()"),hWr=o(` class
method.`),uWr=l(),mS=a("p"),pWr=o("This class cannot be instantiated directly using "),w7e=a("code"),_Wr=o("__init__()"),vWr=o(" (throws an error)."),bWr=l(),Zt=a("div"),F(gS.$$.fragment),FWr=l(),A7e=a("p"),TWr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),MWr=l(),vf=a("p"),EWr=o(`Note:
Loading a model from its configuration file does `),L7e=a("strong"),CWr=o("not"),wWr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Hre=a("a"),AWr=o("from_pretrained()"),LWr=o(" to load the model weights."),yWr=l(),F(Qw.$$.fragment),xWr=l(),zr=a("div"),F(hS.$$.fragment),$Wr=l(),y7e=a("p"),kWr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),SWr=l(),Rn=a("p"),RWr=o("The model class to instantiate is selected based on the "),x7e=a("code"),PWr=o("model_type"),BWr=o(` property of the config object (either
passed as an argument or loaded from `),$7e=a("code"),IWr=o("pretrained_model_name_or_path"),NWr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k7e=a("code"),qWr=o("pretrained_model_name_or_path"),jWr=o(":"),DWr=l(),uS=a("ul"),Ww=a("li"),S7e=a("strong"),GWr=o("bert"),OWr=o(" \u2014 "),Jre=a("a"),VWr=o("TFBertForNextSentencePrediction"),XWr=o(" (BERT model)"),zWr=l(),Uw=a("li"),R7e=a("strong"),QWr=o("mobilebert"),WWr=o(" \u2014 "),Yre=a("a"),UWr=o("TFMobileBertForNextSentencePrediction"),HWr=o(" (MobileBERT model)"),JWr=l(),F(Hw.$$.fragment),iZe=l(),bf=a("h2"),Jw=a("a"),P7e=a("span"),F(pS.$$.fragment),YWr=l(),B7e=a("span"),KWr=o("TFAutoModelForTableQuestionAnswering"),dZe=l(),pr=a("div"),F(_S.$$.fragment),ZWr=l(),Ff=a("p"),eUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Kre=a("a"),oUr=o("from_pretrained()"),rUr=o(" class method or the "),Zre=a("a"),tUr=o("from_config()"),aUr=o(` class
method.`),nUr=l(),vS=a("p"),sUr=o("This class cannot be instantiated directly using "),I7e=a("code"),lUr=o("__init__()"),iUr=o(" (throws an error)."),dUr=l(),ea=a("div"),F(bS.$$.fragment),cUr=l(),N7e=a("p"),fUr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),mUr=l(),Tf=a("p"),gUr=o(`Note:
Loading a model from its configuration file does `),q7e=a("strong"),hUr=o("not"),uUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ete=a("a"),pUr=o("from_pretrained()"),_Ur=o(" to load the model weights."),vUr=l(),F(Yw.$$.fragment),bUr=l(),Qr=a("div"),F(FS.$$.fragment),FUr=l(),j7e=a("p"),TUr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),MUr=l(),Pn=a("p"),EUr=o("The model class to instantiate is selected based on the "),D7e=a("code"),CUr=o("model_type"),wUr=o(` property of the config object (either
passed as an argument or loaded from `),G7e=a("code"),AUr=o("pretrained_model_name_or_path"),LUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O7e=a("code"),yUr=o("pretrained_model_name_or_path"),xUr=o(":"),$Ur=l(),V7e=a("ul"),Kw=a("li"),X7e=a("strong"),kUr=o("tapas"),SUr=o(" \u2014 "),ote=a("a"),RUr=o("TFTapasForQuestionAnswering"),PUr=o(" (TAPAS model)"),BUr=l(),F(Zw.$$.fragment),cZe=l(),Mf=a("h2"),eA=a("a"),z7e=a("span"),F(TS.$$.fragment),IUr=l(),Q7e=a("span"),NUr=o("TFAutoModelForDocumentQuestionAnswering"),fZe=l(),_r=a("div"),F(MS.$$.fragment),qUr=l(),Ef=a("p"),jUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),rte=a("a"),DUr=o("from_pretrained()"),GUr=o(" class method or the "),tte=a("a"),OUr=o("from_config()"),VUr=o(` class
method.`),XUr=l(),ES=a("p"),zUr=o("This class cannot be instantiated directly using "),W7e=a("code"),QUr=o("__init__()"),WUr=o(" (throws an error)."),UUr=l(),oa=a("div"),F(CS.$$.fragment),HUr=l(),U7e=a("p"),JUr=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),YUr=l(),Cf=a("p"),KUr=o(`Note:
Loading a model from its configuration file does `),H7e=a("strong"),ZUr=o("not"),eHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ate=a("a"),oHr=o("from_pretrained()"),rHr=o(" to load the model weights."),tHr=l(),F(oA.$$.fragment),aHr=l(),Wr=a("div"),F(wS.$$.fragment),nHr=l(),J7e=a("p"),sHr=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),lHr=l(),Bn=a("p"),iHr=o("The model class to instantiate is selected based on the "),Y7e=a("code"),dHr=o("model_type"),cHr=o(` property of the config object (either
passed as an argument or loaded from `),K7e=a("code"),fHr=o("pretrained_model_name_or_path"),mHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z7e=a("code"),gHr=o("pretrained_model_name_or_path"),hHr=o(":"),uHr=l(),eLe=a("ul"),rA=a("li"),oLe=a("strong"),pHr=o("layoutlm"),_Hr=o(" \u2014 "),nte=a("a"),vHr=o("TFLayoutLMForQuestionAnswering"),bHr=o(" (LayoutLM model)"),FHr=l(),F(tA.$$.fragment),mZe=l(),wf=a("h2"),aA=a("a"),rLe=a("span"),F(AS.$$.fragment),THr=l(),tLe=a("span"),MHr=o("TFAutoModelForTokenClassification"),gZe=l(),vr=a("div"),F(LS.$$.fragment),EHr=l(),Af=a("p"),CHr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ste=a("a"),wHr=o("from_pretrained()"),AHr=o(" class method or the "),lte=a("a"),LHr=o("from_config()"),yHr=o(` class
method.`),xHr=l(),yS=a("p"),$Hr=o("This class cannot be instantiated directly using "),aLe=a("code"),kHr=o("__init__()"),SHr=o(" (throws an error)."),RHr=l(),ra=a("div"),F(xS.$$.fragment),PHr=l(),nLe=a("p"),BHr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),IHr=l(),Lf=a("p"),NHr=o(`Note:
Loading a model from its configuration file does `),sLe=a("strong"),qHr=o("not"),jHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ite=a("a"),DHr=o("from_pretrained()"),GHr=o(" to load the model weights."),OHr=l(),F(nA.$$.fragment),VHr=l(),Ur=a("div"),F($S.$$.fragment),XHr=l(),lLe=a("p"),zHr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),QHr=l(),In=a("p"),WHr=o("The model class to instantiate is selected based on the "),iLe=a("code"),UHr=o("model_type"),HHr=o(` property of the config object (either
passed as an argument or loaded from `),dLe=a("code"),JHr=o("pretrained_model_name_or_path"),YHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cLe=a("code"),KHr=o("pretrained_model_name_or_path"),ZHr=o(":"),eJr=l(),de=a("ul"),sA=a("li"),fLe=a("strong"),oJr=o("albert"),rJr=o(" \u2014 "),dte=a("a"),tJr=o("TFAlbertForTokenClassification"),aJr=o(" (ALBERT model)"),nJr=l(),lA=a("li"),mLe=a("strong"),sJr=o("bert"),lJr=o(" \u2014 "),cte=a("a"),iJr=o("TFBertForTokenClassification"),dJr=o(" (BERT model)"),cJr=l(),iA=a("li"),gLe=a("strong"),fJr=o("camembert"),mJr=o(" \u2014 "),fte=a("a"),gJr=o("TFCamembertForTokenClassification"),hJr=o(" (CamemBERT model)"),uJr=l(),dA=a("li"),hLe=a("strong"),pJr=o("convbert"),_Jr=o(" \u2014 "),mte=a("a"),vJr=o("TFConvBertForTokenClassification"),bJr=o(" (ConvBERT model)"),FJr=l(),cA=a("li"),uLe=a("strong"),TJr=o("deberta"),MJr=o(" \u2014 "),gte=a("a"),EJr=o("TFDebertaForTokenClassification"),CJr=o(" (DeBERTa model)"),wJr=l(),fA=a("li"),pLe=a("strong"),AJr=o("deberta-v2"),LJr=o(" \u2014 "),hte=a("a"),yJr=o("TFDebertaV2ForTokenClassification"),xJr=o(" (DeBERTa-v2 model)"),$Jr=l(),mA=a("li"),_Le=a("strong"),kJr=o("distilbert"),SJr=o(" \u2014 "),ute=a("a"),RJr=o("TFDistilBertForTokenClassification"),PJr=o(" (DistilBERT model)"),BJr=l(),gA=a("li"),vLe=a("strong"),IJr=o("electra"),NJr=o(" \u2014 "),pte=a("a"),qJr=o("TFElectraForTokenClassification"),jJr=o(" (ELECTRA model)"),DJr=l(),hA=a("li"),bLe=a("strong"),GJr=o("flaubert"),OJr=o(" \u2014 "),_te=a("a"),VJr=o("TFFlaubertForTokenClassification"),XJr=o(" (FlauBERT model)"),zJr=l(),uA=a("li"),FLe=a("strong"),QJr=o("funnel"),WJr=o(" \u2014 "),vte=a("a"),UJr=o("TFFunnelForTokenClassification"),HJr=o(" (Funnel Transformer model)"),JJr=l(),pA=a("li"),TLe=a("strong"),YJr=o("layoutlm"),KJr=o(" \u2014 "),bte=a("a"),ZJr=o("TFLayoutLMForTokenClassification"),eYr=o(" (LayoutLM model)"),oYr=l(),_A=a("li"),MLe=a("strong"),rYr=o("layoutlmv3"),tYr=o(" \u2014 "),Fte=a("a"),aYr=o("TFLayoutLMv3ForTokenClassification"),nYr=o(" (LayoutLMv3 model)"),sYr=l(),vA=a("li"),ELe=a("strong"),lYr=o("longformer"),iYr=o(" \u2014 "),Tte=a("a"),dYr=o("TFLongformerForTokenClassification"),cYr=o(" (Longformer model)"),fYr=l(),bA=a("li"),CLe=a("strong"),mYr=o("mobilebert"),gYr=o(" \u2014 "),Mte=a("a"),hYr=o("TFMobileBertForTokenClassification"),uYr=o(" (MobileBERT model)"),pYr=l(),FA=a("li"),wLe=a("strong"),_Yr=o("mpnet"),vYr=o(" \u2014 "),Ete=a("a"),bYr=o("TFMPNetForTokenClassification"),FYr=o(" (MPNet model)"),TYr=l(),TA=a("li"),ALe=a("strong"),MYr=o("rembert"),EYr=o(" \u2014 "),Cte=a("a"),CYr=o("TFRemBertForTokenClassification"),wYr=o(" (RemBERT model)"),AYr=l(),MA=a("li"),LLe=a("strong"),LYr=o("roberta"),yYr=o(" \u2014 "),wte=a("a"),xYr=o("TFRobertaForTokenClassification"),$Yr=o(" (RoBERTa model)"),kYr=l(),EA=a("li"),yLe=a("strong"),SYr=o("roformer"),RYr=o(" \u2014 "),Ate=a("a"),PYr=o("TFRoFormerForTokenClassification"),BYr=o(" (RoFormer model)"),IYr=l(),CA=a("li"),xLe=a("strong"),NYr=o("xlm"),qYr=o(" \u2014 "),Lte=a("a"),jYr=o("TFXLMForTokenClassification"),DYr=o(" (XLM model)"),GYr=l(),wA=a("li"),$Le=a("strong"),OYr=o("xlm-roberta"),VYr=o(" \u2014 "),yte=a("a"),XYr=o("TFXLMRobertaForTokenClassification"),zYr=o(" (XLM-RoBERTa model)"),QYr=l(),AA=a("li"),kLe=a("strong"),WYr=o("xlnet"),UYr=o(" \u2014 "),xte=a("a"),HYr=o("TFXLNetForTokenClassification"),JYr=o(" (XLNet model)"),YYr=l(),F(LA.$$.fragment),hZe=l(),yf=a("h2"),yA=a("a"),SLe=a("span"),F(kS.$$.fragment),KYr=l(),RLe=a("span"),ZYr=o("TFAutoModelForQuestionAnswering"),uZe=l(),br=a("div"),F(SS.$$.fragment),eKr=l(),xf=a("p"),oKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),$te=a("a"),rKr=o("from_pretrained()"),tKr=o(" class method or the "),kte=a("a"),aKr=o("from_config()"),nKr=o(` class
method.`),sKr=l(),RS=a("p"),lKr=o("This class cannot be instantiated directly using "),PLe=a("code"),iKr=o("__init__()"),dKr=o(" (throws an error)."),cKr=l(),ta=a("div"),F(PS.$$.fragment),fKr=l(),BLe=a("p"),mKr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),gKr=l(),$f=a("p"),hKr=o(`Note:
Loading a model from its configuration file does `),ILe=a("strong"),uKr=o("not"),pKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ste=a("a"),_Kr=o("from_pretrained()"),vKr=o(" to load the model weights."),bKr=l(),F(xA.$$.fragment),FKr=l(),Hr=a("div"),F(BS.$$.fragment),TKr=l(),NLe=a("p"),MKr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),EKr=l(),Nn=a("p"),CKr=o("The model class to instantiate is selected based on the "),qLe=a("code"),wKr=o("model_type"),AKr=o(` property of the config object (either
passed as an argument or loaded from `),jLe=a("code"),LKr=o("pretrained_model_name_or_path"),yKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DLe=a("code"),xKr=o("pretrained_model_name_or_path"),$Kr=o(":"),kKr=l(),ce=a("ul"),$A=a("li"),GLe=a("strong"),SKr=o("albert"),RKr=o(" \u2014 "),Rte=a("a"),PKr=o("TFAlbertForQuestionAnswering"),BKr=o(" (ALBERT model)"),IKr=l(),kA=a("li"),OLe=a("strong"),NKr=o("bert"),qKr=o(" \u2014 "),Pte=a("a"),jKr=o("TFBertForQuestionAnswering"),DKr=o(" (BERT model)"),GKr=l(),SA=a("li"),VLe=a("strong"),OKr=o("camembert"),VKr=o(" \u2014 "),Bte=a("a"),XKr=o("TFCamembertForQuestionAnswering"),zKr=o(" (CamemBERT model)"),QKr=l(),RA=a("li"),XLe=a("strong"),WKr=o("convbert"),UKr=o(" \u2014 "),Ite=a("a"),HKr=o("TFConvBertForQuestionAnswering"),JKr=o(" (ConvBERT model)"),YKr=l(),PA=a("li"),zLe=a("strong"),KKr=o("deberta"),ZKr=o(" \u2014 "),Nte=a("a"),eZr=o("TFDebertaForQuestionAnswering"),oZr=o(" (DeBERTa model)"),rZr=l(),BA=a("li"),QLe=a("strong"),tZr=o("deberta-v2"),aZr=o(" \u2014 "),qte=a("a"),nZr=o("TFDebertaV2ForQuestionAnswering"),sZr=o(" (DeBERTa-v2 model)"),lZr=l(),IA=a("li"),WLe=a("strong"),iZr=o("distilbert"),dZr=o(" \u2014 "),jte=a("a"),cZr=o("TFDistilBertForQuestionAnswering"),fZr=o(" (DistilBERT model)"),mZr=l(),NA=a("li"),ULe=a("strong"),gZr=o("electra"),hZr=o(" \u2014 "),Dte=a("a"),uZr=o("TFElectraForQuestionAnswering"),pZr=o(" (ELECTRA model)"),_Zr=l(),qA=a("li"),HLe=a("strong"),vZr=o("flaubert"),bZr=o(" \u2014 "),Gte=a("a"),FZr=o("TFFlaubertForQuestionAnsweringSimple"),TZr=o(" (FlauBERT model)"),MZr=l(),jA=a("li"),JLe=a("strong"),EZr=o("funnel"),CZr=o(" \u2014 "),Ote=a("a"),wZr=o("TFFunnelForQuestionAnswering"),AZr=o(" (Funnel Transformer model)"),LZr=l(),DA=a("li"),YLe=a("strong"),yZr=o("gptj"),xZr=o(" \u2014 "),Vte=a("a"),$Zr=o("TFGPTJForQuestionAnswering"),kZr=o(" (GPT-J model)"),SZr=l(),GA=a("li"),KLe=a("strong"),RZr=o("layoutlmv3"),PZr=o(" \u2014 "),Xte=a("a"),BZr=o("TFLayoutLMv3ForQuestionAnswering"),IZr=o(" (LayoutLMv3 model)"),NZr=l(),OA=a("li"),ZLe=a("strong"),qZr=o("longformer"),jZr=o(" \u2014 "),zte=a("a"),DZr=o("TFLongformerForQuestionAnswering"),GZr=o(" (Longformer model)"),OZr=l(),VA=a("li"),eye=a("strong"),VZr=o("mobilebert"),XZr=o(" \u2014 "),Qte=a("a"),zZr=o("TFMobileBertForQuestionAnswering"),QZr=o(" (MobileBERT model)"),WZr=l(),XA=a("li"),oye=a("strong"),UZr=o("mpnet"),HZr=o(" \u2014 "),Wte=a("a"),JZr=o("TFMPNetForQuestionAnswering"),YZr=o(" (MPNet model)"),KZr=l(),zA=a("li"),rye=a("strong"),ZZr=o("rembert"),eet=o(" \u2014 "),Ute=a("a"),oet=o("TFRemBertForQuestionAnswering"),ret=o(" (RemBERT model)"),tet=l(),QA=a("li"),tye=a("strong"),aet=o("roberta"),net=o(" \u2014 "),Hte=a("a"),set=o("TFRobertaForQuestionAnswering"),iet=o(" (RoBERTa model)"),det=l(),WA=a("li"),aye=a("strong"),cet=o("roformer"),fet=o(" \u2014 "),Jte=a("a"),met=o("TFRoFormerForQuestionAnswering"),get=o(" (RoFormer model)"),het=l(),UA=a("li"),nye=a("strong"),uet=o("xlm"),pet=o(" \u2014 "),Yte=a("a"),_et=o("TFXLMForQuestionAnsweringSimple"),vet=o(" (XLM model)"),bet=l(),HA=a("li"),sye=a("strong"),Fet=o("xlm-roberta"),Tet=o(" \u2014 "),Kte=a("a"),Met=o("TFXLMRobertaForQuestionAnswering"),Eet=o(" (XLM-RoBERTa model)"),Cet=l(),JA=a("li"),lye=a("strong"),wet=o("xlnet"),Aet=o(" \u2014 "),Zte=a("a"),Let=o("TFXLNetForQuestionAnsweringSimple"),yet=o(" (XLNet model)"),xet=l(),F(YA.$$.fragment),pZe=l(),kf=a("h2"),KA=a("a"),iye=a("span"),F(IS.$$.fragment),$et=l(),dye=a("span"),ket=o("TFAutoModelForVision2Seq"),_Ze=l(),Fr=a("div"),F(NS.$$.fragment),Set=l(),Sf=a("p"),Ret=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),eae=a("a"),Pet=o("from_pretrained()"),Bet=o(" class method or the "),oae=a("a"),Iet=o("from_config()"),Net=o(` class
method.`),qet=l(),qS=a("p"),jet=o("This class cannot be instantiated directly using "),cye=a("code"),Det=o("__init__()"),Get=o(" (throws an error)."),Oet=l(),aa=a("div"),F(jS.$$.fragment),Vet=l(),fye=a("p"),Xet=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),zet=l(),Rf=a("p"),Qet=o(`Note:
Loading a model from its configuration file does `),mye=a("strong"),Wet=o("not"),Uet=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rae=a("a"),Het=o("from_pretrained()"),Jet=o(" to load the model weights."),Yet=l(),F(ZA.$$.fragment),Ket=l(),Jr=a("div"),F(DS.$$.fragment),Zet=l(),gye=a("p"),eot=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),oot=l(),qn=a("p"),rot=o("The model class to instantiate is selected based on the "),hye=a("code"),tot=o("model_type"),aot=o(` property of the config object (either
passed as an argument or loaded from `),uye=a("code"),not=o("pretrained_model_name_or_path"),sot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pye=a("code"),lot=o("pretrained_model_name_or_path"),iot=o(":"),dot=l(),_ye=a("ul"),e6=a("li"),vye=a("strong"),cot=o("vision-encoder-decoder"),fot=o(" \u2014 "),tae=a("a"),mot=o("TFVisionEncoderDecoderModel"),got=o(" (Vision Encoder decoder model)"),hot=l(),F(o6.$$.fragment),vZe=l(),Pf=a("h2"),r6=a("a"),bye=a("span"),F(GS.$$.fragment),uot=l(),Fye=a("span"),pot=o("TFAutoModelForSpeechSeq2Seq"),bZe=l(),Tr=a("div"),F(OS.$$.fragment),_ot=l(),Bf=a("p"),vot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),aae=a("a"),bot=o("from_pretrained()"),Fot=o(" class method or the "),nae=a("a"),Tot=o("from_config()"),Mot=o(` class
method.`),Eot=l(),VS=a("p"),Cot=o("This class cannot be instantiated directly using "),Tye=a("code"),wot=o("__init__()"),Aot=o(" (throws an error)."),Lot=l(),na=a("div"),F(XS.$$.fragment),yot=l(),Mye=a("p"),xot=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),$ot=l(),If=a("p"),kot=o(`Note:
Loading a model from its configuration file does `),Eye=a("strong"),Sot=o("not"),Rot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sae=a("a"),Pot=o("from_pretrained()"),Bot=o(" to load the model weights."),Iot=l(),F(t6.$$.fragment),Not=l(),Yr=a("div"),F(zS.$$.fragment),qot=l(),Cye=a("p"),jot=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Dot=l(),jn=a("p"),Got=o("The model class to instantiate is selected based on the "),wye=a("code"),Oot=o("model_type"),Vot=o(` property of the config object (either
passed as an argument or loaded from `),Aye=a("code"),Xot=o("pretrained_model_name_or_path"),zot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lye=a("code"),Qot=o("pretrained_model_name_or_path"),Wot=o(":"),Uot=l(),yye=a("ul"),a6=a("li"),xye=a("strong"),Hot=o("speech_to_text"),Jot=o(" \u2014 "),lae=a("a"),Yot=o("TFSpeech2TextForConditionalGeneration"),Kot=o(" (Speech2Text model)"),Zot=l(),F(n6.$$.fragment),FZe=l(),Nf=a("h2"),s6=a("a"),$ye=a("span"),F(QS.$$.fragment),ert=l(),kye=a("span"),ort=o("FlaxAutoModel"),TZe=l(),Mr=a("div"),F(WS.$$.fragment),rrt=l(),qf=a("p"),trt=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),iae=a("a"),art=o("from_pretrained()"),nrt=o(" class method or the "),dae=a("a"),srt=o("from_config()"),lrt=o(` class
method.`),irt=l(),US=a("p"),drt=o("This class cannot be instantiated directly using "),Sye=a("code"),crt=o("__init__()"),frt=o(" (throws an error)."),mrt=l(),sa=a("div"),F(HS.$$.fragment),grt=l(),Rye=a("p"),hrt=o("Instantiates one of the base model classes of the library from a configuration."),urt=l(),jf=a("p"),prt=o(`Note:
Loading a model from its configuration file does `),Pye=a("strong"),_rt=o("not"),vrt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cae=a("a"),brt=o("from_pretrained()"),Frt=o(" to load the model weights."),Trt=l(),F(l6.$$.fragment),Mrt=l(),Kr=a("div"),F(JS.$$.fragment),Ert=l(),Bye=a("p"),Crt=o("Instantiate one of the base model classes of the library from a pretrained model."),wrt=l(),Dn=a("p"),Art=o("The model class to instantiate is selected based on the "),Iye=a("code"),Lrt=o("model_type"),yrt=o(` property of the config object (either
passed as an argument or loaded from `),Nye=a("code"),xrt=o("pretrained_model_name_or_path"),$rt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qye=a("code"),krt=o("pretrained_model_name_or_path"),Srt=o(":"),Rrt=l(),te=a("ul"),i6=a("li"),jye=a("strong"),Prt=o("albert"),Brt=o(" \u2014 "),fae=a("a"),Irt=o("FlaxAlbertModel"),Nrt=o(" (ALBERT model)"),qrt=l(),d6=a("li"),Dye=a("strong"),jrt=o("bart"),Drt=o(" \u2014 "),mae=a("a"),Grt=o("FlaxBartModel"),Ort=o(" (BART model)"),Vrt=l(),c6=a("li"),Gye=a("strong"),Xrt=o("beit"),zrt=o(" \u2014 "),gae=a("a"),Qrt=o("FlaxBeitModel"),Wrt=o(" (BEiT model)"),Urt=l(),f6=a("li"),Oye=a("strong"),Hrt=o("bert"),Jrt=o(" \u2014 "),hae=a("a"),Yrt=o("FlaxBertModel"),Krt=o(" (BERT model)"),Zrt=l(),m6=a("li"),Vye=a("strong"),ett=o("big_bird"),ott=o(" \u2014 "),uae=a("a"),rtt=o("FlaxBigBirdModel"),ttt=o(" (BigBird model)"),att=l(),g6=a("li"),Xye=a("strong"),ntt=o("blenderbot"),stt=o(" \u2014 "),pae=a("a"),ltt=o("FlaxBlenderbotModel"),itt=o(" (Blenderbot model)"),dtt=l(),h6=a("li"),zye=a("strong"),ctt=o("blenderbot-small"),ftt=o(" \u2014 "),_ae=a("a"),mtt=o("FlaxBlenderbotSmallModel"),gtt=o(" (BlenderbotSmall model)"),htt=l(),u6=a("li"),Qye=a("strong"),utt=o("clip"),ptt=o(" \u2014 "),vae=a("a"),_tt=o("FlaxCLIPModel"),vtt=o(" (CLIP model)"),btt=l(),p6=a("li"),Wye=a("strong"),Ftt=o("distilbert"),Ttt=o(" \u2014 "),bae=a("a"),Mtt=o("FlaxDistilBertModel"),Ett=o(" (DistilBERT model)"),Ctt=l(),_6=a("li"),Uye=a("strong"),wtt=o("electra"),Att=o(" \u2014 "),Fae=a("a"),Ltt=o("FlaxElectraModel"),ytt=o(" (ELECTRA model)"),xtt=l(),v6=a("li"),Hye=a("strong"),$tt=o("gpt2"),ktt=o(" \u2014 "),Tae=a("a"),Stt=o("FlaxGPT2Model"),Rtt=o(" (OpenAI GPT-2 model)"),Ptt=l(),b6=a("li"),Jye=a("strong"),Btt=o("gpt_neo"),Itt=o(" \u2014 "),Mae=a("a"),Ntt=o("FlaxGPTNeoModel"),qtt=o(" (GPT Neo model)"),jtt=l(),F6=a("li"),Yye=a("strong"),Dtt=o("gptj"),Gtt=o(" \u2014 "),Eae=a("a"),Ott=o("FlaxGPTJModel"),Vtt=o(" (GPT-J model)"),Xtt=l(),T6=a("li"),Kye=a("strong"),ztt=o("longt5"),Qtt=o(" \u2014 "),Cae=a("a"),Wtt=o("FlaxLongT5Model"),Utt=o(" (LongT5 model)"),Htt=l(),M6=a("li"),Zye=a("strong"),Jtt=o("marian"),Ytt=o(" \u2014 "),wae=a("a"),Ktt=o("FlaxMarianModel"),Ztt=o(" (Marian model)"),eat=l(),E6=a("li"),e8e=a("strong"),oat=o("mbart"),rat=o(" \u2014 "),Aae=a("a"),tat=o("FlaxMBartModel"),aat=o(" (mBART model)"),nat=l(),C6=a("li"),o8e=a("strong"),sat=o("mt5"),lat=o(" \u2014 "),Lae=a("a"),iat=o("FlaxMT5Model"),dat=o(" (MT5 model)"),cat=l(),w6=a("li"),r8e=a("strong"),fat=o("opt"),mat=o(" \u2014 "),yae=a("a"),gat=o("FlaxOPTModel"),hat=o(" (OPT model)"),uat=l(),A6=a("li"),t8e=a("strong"),pat=o("pegasus"),_at=o(" \u2014 "),xae=a("a"),vat=o("FlaxPegasusModel"),bat=o(" (Pegasus model)"),Fat=l(),L6=a("li"),a8e=a("strong"),Tat=o("roberta"),Mat=o(" \u2014 "),$ae=a("a"),Eat=o("FlaxRobertaModel"),Cat=o(" (RoBERTa model)"),wat=l(),y6=a("li"),n8e=a("strong"),Aat=o("roformer"),Lat=o(" \u2014 "),kae=a("a"),yat=o("FlaxRoFormerModel"),xat=o(" (RoFormer model)"),$at=l(),x6=a("li"),s8e=a("strong"),kat=o("t5"),Sat=o(" \u2014 "),Sae=a("a"),Rat=o("FlaxT5Model"),Pat=o(" (T5 model)"),Bat=l(),$6=a("li"),l8e=a("strong"),Iat=o("vision-text-dual-encoder"),Nat=o(" \u2014 "),Rae=a("a"),qat=o("FlaxVisionTextDualEncoderModel"),jat=o(" (VisionTextDualEncoder model)"),Dat=l(),k6=a("li"),i8e=a("strong"),Gat=o("vit"),Oat=o(" \u2014 "),Pae=a("a"),Vat=o("FlaxViTModel"),Xat=o(" (ViT model)"),zat=l(),S6=a("li"),d8e=a("strong"),Qat=o("wav2vec2"),Wat=o(" \u2014 "),Bae=a("a"),Uat=o("FlaxWav2Vec2Model"),Hat=o(" (Wav2Vec2 model)"),Jat=l(),R6=a("li"),c8e=a("strong"),Yat=o("xglm"),Kat=o(" \u2014 "),Iae=a("a"),Zat=o("FlaxXGLMModel"),ent=o(" (XGLM model)"),ont=l(),P6=a("li"),f8e=a("strong"),rnt=o("xlm-roberta"),tnt=o(" \u2014 "),Nae=a("a"),ant=o("FlaxXLMRobertaModel"),nnt=o(" (XLM-RoBERTa model)"),snt=l(),F(B6.$$.fragment),MZe=l(),Df=a("h2"),I6=a("a"),m8e=a("span"),F(YS.$$.fragment),lnt=l(),g8e=a("span"),int=o("FlaxAutoModelForCausalLM"),EZe=l(),Er=a("div"),F(KS.$$.fragment),dnt=l(),Gf=a("p"),cnt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),qae=a("a"),fnt=o("from_pretrained()"),mnt=o(" class method or the "),jae=a("a"),gnt=o("from_config()"),hnt=o(` class
method.`),unt=l(),ZS=a("p"),pnt=o("This class cannot be instantiated directly using "),h8e=a("code"),_nt=o("__init__()"),vnt=o(" (throws an error)."),bnt=l(),la=a("div"),F(eR.$$.fragment),Fnt=l(),u8e=a("p"),Tnt=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Mnt=l(),Of=a("p"),Ent=o(`Note:
Loading a model from its configuration file does `),p8e=a("strong"),Cnt=o("not"),wnt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Dae=a("a"),Ant=o("from_pretrained()"),Lnt=o(" to load the model weights."),ynt=l(),F(N6.$$.fragment),xnt=l(),Zr=a("div"),F(oR.$$.fragment),$nt=l(),_8e=a("p"),knt=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Snt=l(),Gn=a("p"),Rnt=o("The model class to instantiate is selected based on the "),v8e=a("code"),Pnt=o("model_type"),Bnt=o(` property of the config object (either
passed as an argument or loaded from `),b8e=a("code"),Int=o("pretrained_model_name_or_path"),Nnt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F8e=a("code"),qnt=o("pretrained_model_name_or_path"),jnt=o(":"),Dnt=l(),xe=a("ul"),q6=a("li"),T8e=a("strong"),Gnt=o("bart"),Ont=o(" \u2014 "),Gae=a("a"),Vnt=o("FlaxBartForCausalLM"),Xnt=o(" (BART model)"),znt=l(),j6=a("li"),M8e=a("strong"),Qnt=o("bert"),Wnt=o(" \u2014 "),Oae=a("a"),Unt=o("FlaxBertForCausalLM"),Hnt=o(" (BERT model)"),Jnt=l(),D6=a("li"),E8e=a("strong"),Ynt=o("big_bird"),Knt=o(" \u2014 "),Vae=a("a"),Znt=o("FlaxBigBirdForCausalLM"),est=o(" (BigBird model)"),ost=l(),G6=a("li"),C8e=a("strong"),rst=o("electra"),tst=o(" \u2014 "),Xae=a("a"),ast=o("FlaxElectraForCausalLM"),nst=o(" (ELECTRA model)"),sst=l(),O6=a("li"),w8e=a("strong"),lst=o("gpt2"),ist=o(" \u2014 "),zae=a("a"),dst=o("FlaxGPT2LMHeadModel"),cst=o(" (OpenAI GPT-2 model)"),fst=l(),V6=a("li"),A8e=a("strong"),mst=o("gpt_neo"),gst=o(" \u2014 "),Qae=a("a"),hst=o("FlaxGPTNeoForCausalLM"),ust=o(" (GPT Neo model)"),pst=l(),X6=a("li"),L8e=a("strong"),_st=o("gptj"),vst=o(" \u2014 "),Wae=a("a"),bst=o("FlaxGPTJForCausalLM"),Fst=o(" (GPT-J model)"),Tst=l(),z6=a("li"),y8e=a("strong"),Mst=o("opt"),Est=o(" \u2014 "),Uae=a("a"),Cst=o("FlaxOPTForCausalLM"),wst=o(" (OPT model)"),Ast=l(),Q6=a("li"),x8e=a("strong"),Lst=o("roberta"),yst=o(" \u2014 "),Hae=a("a"),xst=o("FlaxRobertaForCausalLM"),$st=o(" (RoBERTa model)"),kst=l(),W6=a("li"),$8e=a("strong"),Sst=o("xglm"),Rst=o(" \u2014 "),Jae=a("a"),Pst=o("FlaxXGLMForCausalLM"),Bst=o(" (XGLM model)"),Ist=l(),F(U6.$$.fragment),CZe=l(),Vf=a("h2"),H6=a("a"),k8e=a("span"),F(rR.$$.fragment),Nst=l(),S8e=a("span"),qst=o("FlaxAutoModelForPreTraining"),wZe=l(),Cr=a("div"),F(tR.$$.fragment),jst=l(),Xf=a("p"),Dst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Yae=a("a"),Gst=o("from_pretrained()"),Ost=o(" class method or the "),Kae=a("a"),Vst=o("from_config()"),Xst=o(` class
method.`),zst=l(),aR=a("p"),Qst=o("This class cannot be instantiated directly using "),R8e=a("code"),Wst=o("__init__()"),Ust=o(" (throws an error)."),Hst=l(),ia=a("div"),F(nR.$$.fragment),Jst=l(),P8e=a("p"),Yst=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Kst=l(),zf=a("p"),Zst=o(`Note:
Loading a model from its configuration file does `),B8e=a("strong"),elt=o("not"),olt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zae=a("a"),rlt=o("from_pretrained()"),tlt=o(" to load the model weights."),alt=l(),F(J6.$$.fragment),nlt=l(),et=a("div"),F(sR.$$.fragment),slt=l(),I8e=a("p"),llt=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ilt=l(),On=a("p"),dlt=o("The model class to instantiate is selected based on the "),N8e=a("code"),clt=o("model_type"),flt=o(` property of the config object (either
passed as an argument or loaded from `),q8e=a("code"),mlt=o("pretrained_model_name_or_path"),glt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j8e=a("code"),hlt=o("pretrained_model_name_or_path"),ult=o(":"),plt=l(),Ee=a("ul"),Y6=a("li"),D8e=a("strong"),_lt=o("albert"),vlt=o(" \u2014 "),ene=a("a"),blt=o("FlaxAlbertForPreTraining"),Flt=o(" (ALBERT model)"),Tlt=l(),K6=a("li"),G8e=a("strong"),Mlt=o("bart"),Elt=o(" \u2014 "),one=a("a"),Clt=o("FlaxBartForConditionalGeneration"),wlt=o(" (BART model)"),Alt=l(),Z6=a("li"),O8e=a("strong"),Llt=o("bert"),ylt=o(" \u2014 "),rne=a("a"),xlt=o("FlaxBertForPreTraining"),$lt=o(" (BERT model)"),klt=l(),e7=a("li"),V8e=a("strong"),Slt=o("big_bird"),Rlt=o(" \u2014 "),tne=a("a"),Plt=o("FlaxBigBirdForPreTraining"),Blt=o(" (BigBird model)"),Ilt=l(),o7=a("li"),X8e=a("strong"),Nlt=o("electra"),qlt=o(" \u2014 "),ane=a("a"),jlt=o("FlaxElectraForPreTraining"),Dlt=o(" (ELECTRA model)"),Glt=l(),r7=a("li"),z8e=a("strong"),Olt=o("longt5"),Vlt=o(" \u2014 "),nne=a("a"),Xlt=o("FlaxLongT5ForConditionalGeneration"),zlt=o(" (LongT5 model)"),Qlt=l(),t7=a("li"),Q8e=a("strong"),Wlt=o("mbart"),Ult=o(" \u2014 "),sne=a("a"),Hlt=o("FlaxMBartForConditionalGeneration"),Jlt=o(" (mBART model)"),Ylt=l(),a7=a("li"),W8e=a("strong"),Klt=o("mt5"),Zlt=o(" \u2014 "),lne=a("a"),eit=o("FlaxMT5ForConditionalGeneration"),oit=o(" (MT5 model)"),rit=l(),n7=a("li"),U8e=a("strong"),tit=o("roberta"),ait=o(" \u2014 "),ine=a("a"),nit=o("FlaxRobertaForMaskedLM"),sit=o(" (RoBERTa model)"),lit=l(),s7=a("li"),H8e=a("strong"),iit=o("roformer"),dit=o(" \u2014 "),dne=a("a"),cit=o("FlaxRoFormerForMaskedLM"),fit=o(" (RoFormer model)"),mit=l(),l7=a("li"),J8e=a("strong"),git=o("t5"),hit=o(" \u2014 "),cne=a("a"),uit=o("FlaxT5ForConditionalGeneration"),pit=o(" (T5 model)"),_it=l(),i7=a("li"),Y8e=a("strong"),vit=o("wav2vec2"),bit=o(" \u2014 "),fne=a("a"),Fit=o("FlaxWav2Vec2ForPreTraining"),Tit=o(" (Wav2Vec2 model)"),Mit=l(),d7=a("li"),K8e=a("strong"),Eit=o("xlm-roberta"),Cit=o(" \u2014 "),mne=a("a"),wit=o("FlaxXLMRobertaForMaskedLM"),Ait=o(" (XLM-RoBERTa model)"),Lit=l(),F(c7.$$.fragment),AZe=l(),Qf=a("h2"),f7=a("a"),Z8e=a("span"),F(lR.$$.fragment),yit=l(),e9e=a("span"),xit=o("FlaxAutoModelForMaskedLM"),LZe=l(),wr=a("div"),F(iR.$$.fragment),$it=l(),Wf=a("p"),kit=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),gne=a("a"),Sit=o("from_pretrained()"),Rit=o(" class method or the "),hne=a("a"),Pit=o("from_config()"),Bit=o(` class
method.`),Iit=l(),dR=a("p"),Nit=o("This class cannot be instantiated directly using "),o9e=a("code"),qit=o("__init__()"),jit=o(" (throws an error)."),Dit=l(),da=a("div"),F(cR.$$.fragment),Git=l(),r9e=a("p"),Oit=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Vit=l(),Uf=a("p"),Xit=o(`Note:
Loading a model from its configuration file does `),t9e=a("strong"),zit=o("not"),Qit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),une=a("a"),Wit=o("from_pretrained()"),Uit=o(" to load the model weights."),Hit=l(),F(m7.$$.fragment),Jit=l(),ot=a("div"),F(fR.$$.fragment),Yit=l(),a9e=a("p"),Kit=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Zit=l(),Vn=a("p"),edt=o("The model class to instantiate is selected based on the "),n9e=a("code"),odt=o("model_type"),rdt=o(` property of the config object (either
passed as an argument or loaded from `),s9e=a("code"),tdt=o("pretrained_model_name_or_path"),adt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l9e=a("code"),ndt=o("pretrained_model_name_or_path"),sdt=o(":"),ldt=l(),$e=a("ul"),g7=a("li"),i9e=a("strong"),idt=o("albert"),ddt=o(" \u2014 "),pne=a("a"),cdt=o("FlaxAlbertForMaskedLM"),fdt=o(" (ALBERT model)"),mdt=l(),h7=a("li"),d9e=a("strong"),gdt=o("bart"),hdt=o(" \u2014 "),_ne=a("a"),udt=o("FlaxBartForConditionalGeneration"),pdt=o(" (BART model)"),_dt=l(),u7=a("li"),c9e=a("strong"),vdt=o("bert"),bdt=o(" \u2014 "),vne=a("a"),Fdt=o("FlaxBertForMaskedLM"),Tdt=o(" (BERT model)"),Mdt=l(),p7=a("li"),f9e=a("strong"),Edt=o("big_bird"),Cdt=o(" \u2014 "),bne=a("a"),wdt=o("FlaxBigBirdForMaskedLM"),Adt=o(" (BigBird model)"),Ldt=l(),_7=a("li"),m9e=a("strong"),ydt=o("distilbert"),xdt=o(" \u2014 "),Fne=a("a"),$dt=o("FlaxDistilBertForMaskedLM"),kdt=o(" (DistilBERT model)"),Sdt=l(),v7=a("li"),g9e=a("strong"),Rdt=o("electra"),Pdt=o(" \u2014 "),Tne=a("a"),Bdt=o("FlaxElectraForMaskedLM"),Idt=o(" (ELECTRA model)"),Ndt=l(),b7=a("li"),h9e=a("strong"),qdt=o("mbart"),jdt=o(" \u2014 "),Mne=a("a"),Ddt=o("FlaxMBartForConditionalGeneration"),Gdt=o(" (mBART model)"),Odt=l(),F7=a("li"),u9e=a("strong"),Vdt=o("roberta"),Xdt=o(" \u2014 "),Ene=a("a"),zdt=o("FlaxRobertaForMaskedLM"),Qdt=o(" (RoBERTa model)"),Wdt=l(),T7=a("li"),p9e=a("strong"),Udt=o("roformer"),Hdt=o(" \u2014 "),Cne=a("a"),Jdt=o("FlaxRoFormerForMaskedLM"),Ydt=o(" (RoFormer model)"),Kdt=l(),M7=a("li"),_9e=a("strong"),Zdt=o("xlm-roberta"),ect=o(" \u2014 "),wne=a("a"),oct=o("FlaxXLMRobertaForMaskedLM"),rct=o(" (XLM-RoBERTa model)"),tct=l(),F(E7.$$.fragment),yZe=l(),Hf=a("h2"),C7=a("a"),v9e=a("span"),F(mR.$$.fragment),act=l(),b9e=a("span"),nct=o("FlaxAutoModelForSeq2SeqLM"),xZe=l(),Ar=a("div"),F(gR.$$.fragment),sct=l(),Jf=a("p"),lct=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Ane=a("a"),ict=o("from_pretrained()"),dct=o(" class method or the "),Lne=a("a"),cct=o("from_config()"),fct=o(` class
method.`),mct=l(),hR=a("p"),gct=o("This class cannot be instantiated directly using "),F9e=a("code"),hct=o("__init__()"),uct=o(" (throws an error)."),pct=l(),ca=a("div"),F(uR.$$.fragment),_ct=l(),T9e=a("p"),vct=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),bct=l(),Yf=a("p"),Fct=o(`Note:
Loading a model from its configuration file does `),M9e=a("strong"),Tct=o("not"),Mct=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yne=a("a"),Ect=o("from_pretrained()"),Cct=o(" to load the model weights."),wct=l(),F(w7.$$.fragment),Act=l(),rt=a("div"),F(pR.$$.fragment),Lct=l(),E9e=a("p"),yct=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),xct=l(),Xn=a("p"),$ct=o("The model class to instantiate is selected based on the "),C9e=a("code"),kct=o("model_type"),Sct=o(` property of the config object (either
passed as an argument or loaded from `),w9e=a("code"),Rct=o("pretrained_model_name_or_path"),Pct=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A9e=a("code"),Bct=o("pretrained_model_name_or_path"),Ict=o(":"),Nct=l(),ke=a("ul"),A7=a("li"),L9e=a("strong"),qct=o("bart"),jct=o(" \u2014 "),xne=a("a"),Dct=o("FlaxBartForConditionalGeneration"),Gct=o(" (BART model)"),Oct=l(),L7=a("li"),y9e=a("strong"),Vct=o("blenderbot"),Xct=o(" \u2014 "),$ne=a("a"),zct=o("FlaxBlenderbotForConditionalGeneration"),Qct=o(" (Blenderbot model)"),Wct=l(),y7=a("li"),x9e=a("strong"),Uct=o("blenderbot-small"),Hct=o(" \u2014 "),kne=a("a"),Jct=o("FlaxBlenderbotSmallForConditionalGeneration"),Yct=o(" (BlenderbotSmall model)"),Kct=l(),x7=a("li"),$9e=a("strong"),Zct=o("encoder-decoder"),eft=o(" \u2014 "),Sne=a("a"),oft=o("FlaxEncoderDecoderModel"),rft=o(" (Encoder decoder model)"),tft=l(),$7=a("li"),k9e=a("strong"),aft=o("longt5"),nft=o(" \u2014 "),Rne=a("a"),sft=o("FlaxLongT5ForConditionalGeneration"),lft=o(" (LongT5 model)"),ift=l(),k7=a("li"),S9e=a("strong"),dft=o("marian"),cft=o(" \u2014 "),Pne=a("a"),fft=o("FlaxMarianMTModel"),mft=o(" (Marian model)"),gft=l(),S7=a("li"),R9e=a("strong"),hft=o("mbart"),uft=o(" \u2014 "),Bne=a("a"),pft=o("FlaxMBartForConditionalGeneration"),_ft=o(" (mBART model)"),vft=l(),R7=a("li"),P9e=a("strong"),bft=o("mt5"),Fft=o(" \u2014 "),Ine=a("a"),Tft=o("FlaxMT5ForConditionalGeneration"),Mft=o(" (MT5 model)"),Eft=l(),P7=a("li"),B9e=a("strong"),Cft=o("pegasus"),wft=o(" \u2014 "),Nne=a("a"),Aft=o("FlaxPegasusForConditionalGeneration"),Lft=o(" (Pegasus model)"),yft=l(),B7=a("li"),I9e=a("strong"),xft=o("t5"),$ft=o(" \u2014 "),qne=a("a"),kft=o("FlaxT5ForConditionalGeneration"),Sft=o(" (T5 model)"),Rft=l(),F(I7.$$.fragment),$Ze=l(),Kf=a("h2"),N7=a("a"),N9e=a("span"),F(_R.$$.fragment),Pft=l(),q9e=a("span"),Bft=o("FlaxAutoModelForSequenceClassification"),kZe=l(),Lr=a("div"),F(vR.$$.fragment),Ift=l(),Zf=a("p"),Nft=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),jne=a("a"),qft=o("from_pretrained()"),jft=o(" class method or the "),Dne=a("a"),Dft=o("from_config()"),Gft=o(` class
method.`),Oft=l(),bR=a("p"),Vft=o("This class cannot be instantiated directly using "),j9e=a("code"),Xft=o("__init__()"),zft=o(" (throws an error)."),Qft=l(),fa=a("div"),F(FR.$$.fragment),Wft=l(),D9e=a("p"),Uft=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Hft=l(),em=a("p"),Jft=o(`Note:
Loading a model from its configuration file does `),G9e=a("strong"),Yft=o("not"),Kft=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gne=a("a"),Zft=o("from_pretrained()"),emt=o(" to load the model weights."),omt=l(),F(q7.$$.fragment),rmt=l(),tt=a("div"),F(TR.$$.fragment),tmt=l(),O9e=a("p"),amt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),nmt=l(),zn=a("p"),smt=o("The model class to instantiate is selected based on the "),V9e=a("code"),lmt=o("model_type"),imt=o(` property of the config object (either
passed as an argument or loaded from `),X9e=a("code"),dmt=o("pretrained_model_name_or_path"),cmt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z9e=a("code"),fmt=o("pretrained_model_name_or_path"),mmt=o(":"),gmt=l(),Se=a("ul"),j7=a("li"),Q9e=a("strong"),hmt=o("albert"),umt=o(" \u2014 "),One=a("a"),pmt=o("FlaxAlbertForSequenceClassification"),_mt=o(" (ALBERT model)"),vmt=l(),D7=a("li"),W9e=a("strong"),bmt=o("bart"),Fmt=o(" \u2014 "),Vne=a("a"),Tmt=o("FlaxBartForSequenceClassification"),Mmt=o(" (BART model)"),Emt=l(),G7=a("li"),U9e=a("strong"),Cmt=o("bert"),wmt=o(" \u2014 "),Xne=a("a"),Amt=o("FlaxBertForSequenceClassification"),Lmt=o(" (BERT model)"),ymt=l(),O7=a("li"),H9e=a("strong"),xmt=o("big_bird"),$mt=o(" \u2014 "),zne=a("a"),kmt=o("FlaxBigBirdForSequenceClassification"),Smt=o(" (BigBird model)"),Rmt=l(),V7=a("li"),J9e=a("strong"),Pmt=o("distilbert"),Bmt=o(" \u2014 "),Qne=a("a"),Imt=o("FlaxDistilBertForSequenceClassification"),Nmt=o(" (DistilBERT model)"),qmt=l(),X7=a("li"),Y9e=a("strong"),jmt=o("electra"),Dmt=o(" \u2014 "),Wne=a("a"),Gmt=o("FlaxElectraForSequenceClassification"),Omt=o(" (ELECTRA model)"),Vmt=l(),z7=a("li"),K9e=a("strong"),Xmt=o("mbart"),zmt=o(" \u2014 "),Une=a("a"),Qmt=o("FlaxMBartForSequenceClassification"),Wmt=o(" (mBART model)"),Umt=l(),Q7=a("li"),Z9e=a("strong"),Hmt=o("roberta"),Jmt=o(" \u2014 "),Hne=a("a"),Ymt=o("FlaxRobertaForSequenceClassification"),Kmt=o(" (RoBERTa model)"),Zmt=l(),W7=a("li"),exe=a("strong"),egt=o("roformer"),ogt=o(" \u2014 "),Jne=a("a"),rgt=o("FlaxRoFormerForSequenceClassification"),tgt=o(" (RoFormer model)"),agt=l(),U7=a("li"),oxe=a("strong"),ngt=o("xlm-roberta"),sgt=o(" \u2014 "),Yne=a("a"),lgt=o("FlaxXLMRobertaForSequenceClassification"),igt=o(" (XLM-RoBERTa model)"),dgt=l(),F(H7.$$.fragment),SZe=l(),om=a("h2"),J7=a("a"),rxe=a("span"),F(MR.$$.fragment),cgt=l(),txe=a("span"),fgt=o("FlaxAutoModelForQuestionAnswering"),RZe=l(),yr=a("div"),F(ER.$$.fragment),mgt=l(),rm=a("p"),ggt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Kne=a("a"),hgt=o("from_pretrained()"),ugt=o(" class method or the "),Zne=a("a"),pgt=o("from_config()"),_gt=o(` class
method.`),vgt=l(),CR=a("p"),bgt=o("This class cannot be instantiated directly using "),axe=a("code"),Fgt=o("__init__()"),Tgt=o(" (throws an error)."),Mgt=l(),ma=a("div"),F(wR.$$.fragment),Egt=l(),nxe=a("p"),Cgt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),wgt=l(),tm=a("p"),Agt=o(`Note:
Loading a model from its configuration file does `),sxe=a("strong"),Lgt=o("not"),ygt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ese=a("a"),xgt=o("from_pretrained()"),$gt=o(" to load the model weights."),kgt=l(),F(Y7.$$.fragment),Sgt=l(),at=a("div"),F(AR.$$.fragment),Rgt=l(),lxe=a("p"),Pgt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Bgt=l(),Qn=a("p"),Igt=o("The model class to instantiate is selected based on the "),ixe=a("code"),Ngt=o("model_type"),qgt=o(` property of the config object (either
passed as an argument or loaded from `),dxe=a("code"),jgt=o("pretrained_model_name_or_path"),Dgt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cxe=a("code"),Ggt=o("pretrained_model_name_or_path"),Ogt=o(":"),Vgt=l(),Re=a("ul"),K7=a("li"),fxe=a("strong"),Xgt=o("albert"),zgt=o(" \u2014 "),ose=a("a"),Qgt=o("FlaxAlbertForQuestionAnswering"),Wgt=o(" (ALBERT model)"),Ugt=l(),Z7=a("li"),mxe=a("strong"),Hgt=o("bart"),Jgt=o(" \u2014 "),rse=a("a"),Ygt=o("FlaxBartForQuestionAnswering"),Kgt=o(" (BART model)"),Zgt=l(),eL=a("li"),gxe=a("strong"),eht=o("bert"),oht=o(" \u2014 "),tse=a("a"),rht=o("FlaxBertForQuestionAnswering"),tht=o(" (BERT model)"),aht=l(),oL=a("li"),hxe=a("strong"),nht=o("big_bird"),sht=o(" \u2014 "),ase=a("a"),lht=o("FlaxBigBirdForQuestionAnswering"),iht=o(" (BigBird model)"),dht=l(),rL=a("li"),uxe=a("strong"),cht=o("distilbert"),fht=o(" \u2014 "),nse=a("a"),mht=o("FlaxDistilBertForQuestionAnswering"),ght=o(" (DistilBERT model)"),hht=l(),tL=a("li"),pxe=a("strong"),uht=o("electra"),pht=o(" \u2014 "),sse=a("a"),_ht=o("FlaxElectraForQuestionAnswering"),vht=o(" (ELECTRA model)"),bht=l(),aL=a("li"),_xe=a("strong"),Fht=o("mbart"),Tht=o(" \u2014 "),lse=a("a"),Mht=o("FlaxMBartForQuestionAnswering"),Eht=o(" (mBART model)"),Cht=l(),nL=a("li"),vxe=a("strong"),wht=o("roberta"),Aht=o(" \u2014 "),ise=a("a"),Lht=o("FlaxRobertaForQuestionAnswering"),yht=o(" (RoBERTa model)"),xht=l(),sL=a("li"),bxe=a("strong"),$ht=o("roformer"),kht=o(" \u2014 "),dse=a("a"),Sht=o("FlaxRoFormerForQuestionAnswering"),Rht=o(" (RoFormer model)"),Pht=l(),lL=a("li"),Fxe=a("strong"),Bht=o("xlm-roberta"),Iht=o(" \u2014 "),cse=a("a"),Nht=o("FlaxXLMRobertaForQuestionAnswering"),qht=o(" (XLM-RoBERTa model)"),jht=l(),F(iL.$$.fragment),PZe=l(),am=a("h2"),dL=a("a"),Txe=a("span"),F(LR.$$.fragment),Dht=l(),Mxe=a("span"),Ght=o("FlaxAutoModelForTokenClassification"),BZe=l(),xr=a("div"),F(yR.$$.fragment),Oht=l(),nm=a("p"),Vht=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),fse=a("a"),Xht=o("from_pretrained()"),zht=o(" class method or the "),mse=a("a"),Qht=o("from_config()"),Wht=o(` class
method.`),Uht=l(),xR=a("p"),Hht=o("This class cannot be instantiated directly using "),Exe=a("code"),Jht=o("__init__()"),Yht=o(" (throws an error)."),Kht=l(),ga=a("div"),F($R.$$.fragment),Zht=l(),Cxe=a("p"),eut=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),out=l(),sm=a("p"),rut=o(`Note:
Loading a model from its configuration file does `),wxe=a("strong"),tut=o("not"),aut=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gse=a("a"),nut=o("from_pretrained()"),sut=o(" to load the model weights."),lut=l(),F(cL.$$.fragment),iut=l(),nt=a("div"),F(kR.$$.fragment),dut=l(),Axe=a("p"),cut=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),fut=l(),Wn=a("p"),mut=o("The model class to instantiate is selected based on the "),Lxe=a("code"),gut=o("model_type"),hut=o(` property of the config object (either
passed as an argument or loaded from `),yxe=a("code"),uut=o("pretrained_model_name_or_path"),put=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xxe=a("code"),_ut=o("pretrained_model_name_or_path"),vut=o(":"),but=l(),Xe=a("ul"),fL=a("li"),$xe=a("strong"),Fut=o("albert"),Tut=o(" \u2014 "),hse=a("a"),Mut=o("FlaxAlbertForTokenClassification"),Eut=o(" (ALBERT model)"),Cut=l(),mL=a("li"),kxe=a("strong"),wut=o("bert"),Aut=o(" \u2014 "),use=a("a"),Lut=o("FlaxBertForTokenClassification"),yut=o(" (BERT model)"),xut=l(),gL=a("li"),Sxe=a("strong"),$ut=o("big_bird"),kut=o(" \u2014 "),pse=a("a"),Sut=o("FlaxBigBirdForTokenClassification"),Rut=o(" (BigBird model)"),Put=l(),hL=a("li"),Rxe=a("strong"),But=o("distilbert"),Iut=o(" \u2014 "),_se=a("a"),Nut=o("FlaxDistilBertForTokenClassification"),qut=o(" (DistilBERT model)"),jut=l(),uL=a("li"),Pxe=a("strong"),Dut=o("electra"),Gut=o(" \u2014 "),vse=a("a"),Out=o("FlaxElectraForTokenClassification"),Vut=o(" (ELECTRA model)"),Xut=l(),pL=a("li"),Bxe=a("strong"),zut=o("roberta"),Qut=o(" \u2014 "),bse=a("a"),Wut=o("FlaxRobertaForTokenClassification"),Uut=o(" (RoBERTa model)"),Hut=l(),_L=a("li"),Ixe=a("strong"),Jut=o("roformer"),Yut=o(" \u2014 "),Fse=a("a"),Kut=o("FlaxRoFormerForTokenClassification"),Zut=o(" (RoFormer model)"),ept=l(),vL=a("li"),Nxe=a("strong"),opt=o("xlm-roberta"),rpt=o(" \u2014 "),Tse=a("a"),tpt=o("FlaxXLMRobertaForTokenClassification"),apt=o(" (XLM-RoBERTa model)"),npt=l(),F(bL.$$.fragment),IZe=l(),lm=a("h2"),FL=a("a"),qxe=a("span"),F(SR.$$.fragment),spt=l(),jxe=a("span"),lpt=o("FlaxAutoModelForMultipleChoice"),NZe=l(),$r=a("div"),F(RR.$$.fragment),ipt=l(),im=a("p"),dpt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Mse=a("a"),cpt=o("from_pretrained()"),fpt=o(" class method or the "),Ese=a("a"),mpt=o("from_config()"),gpt=o(` class
method.`),hpt=l(),PR=a("p"),upt=o("This class cannot be instantiated directly using "),Dxe=a("code"),ppt=o("__init__()"),_pt=o(" (throws an error)."),vpt=l(),ha=a("div"),F(BR.$$.fragment),bpt=l(),Gxe=a("p"),Fpt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Tpt=l(),dm=a("p"),Mpt=o(`Note:
Loading a model from its configuration file does `),Oxe=a("strong"),Ept=o("not"),Cpt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cse=a("a"),wpt=o("from_pretrained()"),Apt=o(" to load the model weights."),Lpt=l(),F(TL.$$.fragment),ypt=l(),st=a("div"),F(IR.$$.fragment),xpt=l(),Vxe=a("p"),$pt=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),kpt=l(),Un=a("p"),Spt=o("The model class to instantiate is selected based on the "),Xxe=a("code"),Rpt=o("model_type"),Ppt=o(` property of the config object (either
passed as an argument or loaded from `),zxe=a("code"),Bpt=o("pretrained_model_name_or_path"),Ipt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qxe=a("code"),Npt=o("pretrained_model_name_or_path"),qpt=o(":"),jpt=l(),ze=a("ul"),ML=a("li"),Wxe=a("strong"),Dpt=o("albert"),Gpt=o(" \u2014 "),wse=a("a"),Opt=o("FlaxAlbertForMultipleChoice"),Vpt=o(" (ALBERT model)"),Xpt=l(),EL=a("li"),Uxe=a("strong"),zpt=o("bert"),Qpt=o(" \u2014 "),Ase=a("a"),Wpt=o("FlaxBertForMultipleChoice"),Upt=o(" (BERT model)"),Hpt=l(),CL=a("li"),Hxe=a("strong"),Jpt=o("big_bird"),Ypt=o(" \u2014 "),Lse=a("a"),Kpt=o("FlaxBigBirdForMultipleChoice"),Zpt=o(" (BigBird model)"),e_t=l(),wL=a("li"),Jxe=a("strong"),o_t=o("distilbert"),r_t=o(" \u2014 "),yse=a("a"),t_t=o("FlaxDistilBertForMultipleChoice"),a_t=o(" (DistilBERT model)"),n_t=l(),AL=a("li"),Yxe=a("strong"),s_t=o("electra"),l_t=o(" \u2014 "),xse=a("a"),i_t=o("FlaxElectraForMultipleChoice"),d_t=o(" (ELECTRA model)"),c_t=l(),LL=a("li"),Kxe=a("strong"),f_t=o("roberta"),m_t=o(" \u2014 "),$se=a("a"),g_t=o("FlaxRobertaForMultipleChoice"),h_t=o(" (RoBERTa model)"),u_t=l(),yL=a("li"),Zxe=a("strong"),p_t=o("roformer"),__t=o(" \u2014 "),kse=a("a"),v_t=o("FlaxRoFormerForMultipleChoice"),b_t=o(" (RoFormer model)"),F_t=l(),xL=a("li"),e$e=a("strong"),T_t=o("xlm-roberta"),M_t=o(" \u2014 "),Sse=a("a"),E_t=o("FlaxXLMRobertaForMultipleChoice"),C_t=o(" (XLM-RoBERTa model)"),w_t=l(),F($L.$$.fragment),qZe=l(),cm=a("h2"),kL=a("a"),o$e=a("span"),F(NR.$$.fragment),A_t=l(),r$e=a("span"),L_t=o("FlaxAutoModelForNextSentencePrediction"),jZe=l(),kr=a("div"),F(qR.$$.fragment),y_t=l(),fm=a("p"),x_t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Rse=a("a"),$_t=o("from_pretrained()"),k_t=o(" class method or the "),Pse=a("a"),S_t=o("from_config()"),R_t=o(` class
method.`),P_t=l(),jR=a("p"),B_t=o("This class cannot be instantiated directly using "),t$e=a("code"),I_t=o("__init__()"),N_t=o(" (throws an error)."),q_t=l(),ua=a("div"),F(DR.$$.fragment),j_t=l(),a$e=a("p"),D_t=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),G_t=l(),mm=a("p"),O_t=o(`Note:
Loading a model from its configuration file does `),n$e=a("strong"),V_t=o("not"),X_t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bse=a("a"),z_t=o("from_pretrained()"),Q_t=o(" to load the model weights."),W_t=l(),F(SL.$$.fragment),U_t=l(),lt=a("div"),F(GR.$$.fragment),H_t=l(),s$e=a("p"),J_t=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Y_t=l(),Hn=a("p"),K_t=o("The model class to instantiate is selected based on the "),l$e=a("code"),Z_t=o("model_type"),e2t=o(` property of the config object (either
passed as an argument or loaded from `),i$e=a("code"),o2t=o("pretrained_model_name_or_path"),r2t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d$e=a("code"),t2t=o("pretrained_model_name_or_path"),a2t=o(":"),n2t=l(),c$e=a("ul"),RL=a("li"),f$e=a("strong"),s2t=o("bert"),l2t=o(" \u2014 "),Ise=a("a"),i2t=o("FlaxBertForNextSentencePrediction"),d2t=o(" (BERT model)"),c2t=l(),F(PL.$$.fragment),DZe=l(),gm=a("h2"),BL=a("a"),m$e=a("span"),F(OR.$$.fragment),f2t=l(),g$e=a("span"),m2t=o("FlaxAutoModelForImageClassification"),GZe=l(),Sr=a("div"),F(VR.$$.fragment),g2t=l(),hm=a("p"),h2t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Nse=a("a"),u2t=o("from_pretrained()"),p2t=o(" class method or the "),qse=a("a"),_2t=o("from_config()"),v2t=o(` class
method.`),b2t=l(),XR=a("p"),F2t=o("This class cannot be instantiated directly using "),h$e=a("code"),T2t=o("__init__()"),M2t=o(" (throws an error)."),E2t=l(),pa=a("div"),F(zR.$$.fragment),C2t=l(),u$e=a("p"),w2t=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),A2t=l(),um=a("p"),L2t=o(`Note:
Loading a model from its configuration file does `),p$e=a("strong"),y2t=o("not"),x2t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jse=a("a"),$2t=o("from_pretrained()"),k2t=o(" to load the model weights."),S2t=l(),F(IL.$$.fragment),R2t=l(),it=a("div"),F(QR.$$.fragment),P2t=l(),_$e=a("p"),B2t=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),I2t=l(),Jn=a("p"),N2t=o("The model class to instantiate is selected based on the "),v$e=a("code"),q2t=o("model_type"),j2t=o(` property of the config object (either
passed as an argument or loaded from `),b$e=a("code"),D2t=o("pretrained_model_name_or_path"),G2t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F$e=a("code"),O2t=o("pretrained_model_name_or_path"),V2t=o(":"),X2t=l(),WR=a("ul"),NL=a("li"),T$e=a("strong"),z2t=o("beit"),Q2t=o(" \u2014 "),Dse=a("a"),W2t=o("FlaxBeitForImageClassification"),U2t=o(" (BEiT model)"),H2t=l(),qL=a("li"),M$e=a("strong"),J2t=o("vit"),Y2t=o(" \u2014 "),Gse=a("a"),K2t=o("FlaxViTForImageClassification"),Z2t=o(" (ViT model)"),evt=l(),F(jL.$$.fragment),OZe=l(),pm=a("h2"),DL=a("a"),E$e=a("span"),F(UR.$$.fragment),ovt=l(),C$e=a("span"),rvt=o("FlaxAutoModelForVision2Seq"),VZe=l(),Rr=a("div"),F(HR.$$.fragment),tvt=l(),_m=a("p"),avt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Ose=a("a"),nvt=o("from_pretrained()"),svt=o(" class method or the "),Vse=a("a"),lvt=o("from_config()"),ivt=o(` class
method.`),dvt=l(),JR=a("p"),cvt=o("This class cannot be instantiated directly using "),w$e=a("code"),fvt=o("__init__()"),mvt=o(" (throws an error)."),gvt=l(),_a=a("div"),F(YR.$$.fragment),hvt=l(),A$e=a("p"),uvt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),pvt=l(),vm=a("p"),_vt=o(`Note:
Loading a model from its configuration file does `),L$e=a("strong"),vvt=o("not"),bvt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xse=a("a"),Fvt=o("from_pretrained()"),Tvt=o(" to load the model weights."),Mvt=l(),F(GL.$$.fragment),Evt=l(),dt=a("div"),F(KR.$$.fragment),Cvt=l(),y$e=a("p"),wvt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Avt=l(),Yn=a("p"),Lvt=o("The model class to instantiate is selected based on the "),x$e=a("code"),yvt=o("model_type"),xvt=o(` property of the config object (either
passed as an argument or loaded from `),$$e=a("code"),$vt=o("pretrained_model_name_or_path"),kvt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k$e=a("code"),Svt=o("pretrained_model_name_or_path"),Rvt=o(":"),Pvt=l(),S$e=a("ul"),OL=a("li"),R$e=a("strong"),Bvt=o("vision-encoder-decoder"),Ivt=o(" \u2014 "),zse=a("a"),Nvt=o("FlaxVisionEncoderDecoderModel"),qvt=o(" (Vision Encoder decoder model)"),jvt=l(),F(VL.$$.fragment),this.h()},l(f){const _=jma('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),b=i(f),u=n(f,"H1",{class:!0});var ZR=s(u);m=n(ZR,"A",{id:!0,class:!0,href:!0});var P$e=s(m);p=n(P$e,"SPAN",{});var B$e=s(p);T(d.$$.fragment,B$e),B$e.forEach(t),P$e.forEach(t),h=i(ZR),yo=n(ZR,"SPAN",{});var I$e=s(yo);rd=r(I$e,"Auto Classes"),I$e.forEach(t),ZR.forEach(t),Mm=i(f),pt=n(f,"P",{});var eP=s(pt);td=r(eP,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ad=n(eP,"CODE",{});var N$e=s(ad);b9=r(N$e,"from_pretrained()"),N$e.forEach(t),Em=r(eP,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),eP.forEach(t),Ve=i(f),He=n(f,"P",{});var Kn=s(He);nd=r(Kn,"Instantiating one of "),Zn=n(Kn,"A",{href:!0});var q$e=s(Zn);F9=r(q$e,"AutoConfig"),q$e.forEach(t),es=r(Kn,", "),os=n(Kn,"A",{href:!0});var j$e=s(os);T9=r(j$e,"AutoModel"),j$e.forEach(t),sd=r(Kn,`, and
`),rs=n(Kn,"A",{href:!0});var D$e=s(rs);M9=r(D$e,"AutoTokenizer"),D$e.forEach(t),ld=r(Kn," will directly create a class of the relevant architecture. For instance"),Kn.forEach(t),Cm=i(f),T(Qa.$$.fragment,f),Je=i(f),Ae=n(f,"P",{});var oP=s(Ae);CB=r(oP,"will create a model that is an instance of "),id=n(oP,"A",{href:!0});var G$e=s(id);wB=r(G$e,"BertModel"),G$e.forEach(t),AB=r(oP,"."),oP.forEach(t),xo=i(f),Wa=n(f,"P",{});var rP=s(Wa);LB=r(rP,"There is one class of "),wm=n(rP,"CODE",{});var O$e=s(wm);yB=r(O$e,"AutoModel"),O$e.forEach(t),iro=r(rP," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),rP.forEach(t),kYe=i(f),dd=n(f,"H2",{class:!0});var tP=s(dd);Am=n(tP,"A",{id:!0,class:!0,href:!0});var V$e=s(Am);Hie=n(V$e,"SPAN",{});var X$e=s(Hie);T(E9.$$.fragment,X$e),X$e.forEach(t),V$e.forEach(t),dro=i(tP),Jie=n(tP,"SPAN",{});var z$e=s(Jie);cro=r(z$e,"Extending the Auto Classes"),z$e.forEach(t),tP.forEach(t),SYe=i(f),ts=n(f,"P",{});var bm=s(ts);fro=r(bm,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Yie=n(bm,"CODE",{});var Q$e=s(Yie);mro=r(Q$e,"NewModel"),Q$e.forEach(t),gro=r(bm,", make sure you have a "),Kie=n(bm,"CODE",{});var W$e=s(Kie);hro=r(W$e,"NewModelConfig"),W$e.forEach(t),uro=r(bm,` then you can add those to the auto
classes like this:`),bm.forEach(t),RYe=i(f),T(C9.$$.fragment,f),PYe=i(f),xB=n(f,"P",{});var U$e=s(xB);pro=r(U$e,"You will then be able to use the auto classes like you would usually do!"),U$e.forEach(t),BYe=i(f),T(Lm.$$.fragment,f),IYe=i(f),cd=n(f,"H2",{class:!0});var aP=s(cd);ym=n(aP,"A",{id:!0,class:!0,href:!0});var H$e=s(ym);Zie=n(H$e,"SPAN",{});var J$e=s(Zie);T(w9.$$.fragment,J$e),J$e.forEach(t),H$e.forEach(t),_ro=i(aP),ede=n(aP,"SPAN",{});var Y$e=s(ede);vro=r(Y$e,"AutoConfig"),Y$e.forEach(t),aP.forEach(t),NYe=i(f),$o=n(f,"DIV",{class:!0});var ht=s($o);T(A9.$$.fragment,ht),bro=i(ht),L9=n(ht,"P",{});var nP=s(L9);Fro=r(nP,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),$B=n(nP,"A",{href:!0});var K$e=s($B);Tro=r(K$e,"from_pretrained()"),K$e.forEach(t),Mro=r(nP," class method."),nP.forEach(t),Ero=i(ht),y9=n(ht,"P",{});var sP=s(y9);Cro=r(sP,"This class cannot be instantiated directly using "),ode=n(sP,"CODE",{});var Z$e=s(ode);wro=r(Z$e,"__init__()"),Z$e.forEach(t),Aro=r(sP," (throws an error)."),sP.forEach(t),Lro=i(ht),Pr=n(ht,"DIV",{class:!0});var ut=s(Pr);T(x9.$$.fragment,ut),yro=i(ut),rde=n(ut,"P",{});var eke=s(rde);xro=r(eke,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),eke.forEach(t),$ro=i(ut),fd=n(ut,"P",{});var Fm=s(fd);kro=r(Fm,"The configuration class to instantiate is selected based on the "),tde=n(Fm,"CODE",{});var oke=s(tde);Sro=r(oke,"model_type"),oke.forEach(t),Rro=r(Fm,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),ade=n(Fm,"CODE",{});var rke=s(ade);Pro=r(rke,"pretrained_model_name_or_path"),rke.forEach(t),Bro=r(Fm,":"),Fm.forEach(t),Iro=i(ut),A=n(ut,"UL",{});var L=s(A);xm=n(L,"LI",{});var XL=s(xm);nde=n(XL,"STRONG",{});var tke=s(nde);Nro=r(tke,"albert"),tke.forEach(t),qro=r(XL," \u2014 "),kB=n(XL,"A",{href:!0});var ake=s(kB);jro=r(ake,"AlbertConfig"),ake.forEach(t),Dro=r(XL," (ALBERT model)"),XL.forEach(t),Gro=i(L),$m=n(L,"LI",{});var zL=s($m);sde=n(zL,"STRONG",{});var nke=s(sde);Oro=r(nke,"bart"),nke.forEach(t),Vro=r(zL," \u2014 "),SB=n(zL,"A",{href:!0});var ske=s(SB);Xro=r(ske,"BartConfig"),ske.forEach(t),zro=r(zL," (BART model)"),zL.forEach(t),Qro=i(L),km=n(L,"LI",{});var QL=s(km);lde=n(QL,"STRONG",{});var lke=s(lde);Wro=r(lke,"beit"),lke.forEach(t),Uro=r(QL," \u2014 "),RB=n(QL,"A",{href:!0});var ike=s(RB);Hro=r(ike,"BeitConfig"),ike.forEach(t),Jro=r(QL," (BEiT model)"),QL.forEach(t),Yro=i(L),Sm=n(L,"LI",{});var WL=s(Sm);ide=n(WL,"STRONG",{});var dke=s(ide);Kro=r(dke,"bert"),dke.forEach(t),Zro=r(WL," \u2014 "),PB=n(WL,"A",{href:!0});var cke=s(PB);eto=r(cke,"BertConfig"),cke.forEach(t),oto=r(WL," (BERT model)"),WL.forEach(t),rto=i(L),Rm=n(L,"LI",{});var UL=s(Rm);dde=n(UL,"STRONG",{});var fke=s(dde);tto=r(fke,"bert-generation"),fke.forEach(t),ato=r(UL," \u2014 "),BB=n(UL,"A",{href:!0});var mke=s(BB);nto=r(mke,"BertGenerationConfig"),mke.forEach(t),sto=r(UL," (Bert Generation model)"),UL.forEach(t),lto=i(L),Pm=n(L,"LI",{});var HL=s(Pm);cde=n(HL,"STRONG",{});var gke=s(cde);ito=r(gke,"big_bird"),gke.forEach(t),dto=r(HL," \u2014 "),IB=n(HL,"A",{href:!0});var hke=s(IB);cto=r(hke,"BigBirdConfig"),hke.forEach(t),fto=r(HL," (BigBird model)"),HL.forEach(t),mto=i(L),Bm=n(L,"LI",{});var JL=s(Bm);fde=n(JL,"STRONG",{});var uke=s(fde);gto=r(uke,"bigbird_pegasus"),uke.forEach(t),hto=r(JL," \u2014 "),NB=n(JL,"A",{href:!0});var pke=s(NB);uto=r(pke,"BigBirdPegasusConfig"),pke.forEach(t),pto=r(JL," (BigBird-Pegasus model)"),JL.forEach(t),_to=i(L),Im=n(L,"LI",{});var YL=s(Im);mde=n(YL,"STRONG",{});var _ke=s(mde);vto=r(_ke,"blenderbot"),_ke.forEach(t),bto=r(YL," \u2014 "),qB=n(YL,"A",{href:!0});var vke=s(qB);Fto=r(vke,"BlenderbotConfig"),vke.forEach(t),Tto=r(YL," (Blenderbot model)"),YL.forEach(t),Mto=i(L),Nm=n(L,"LI",{});var KL=s(Nm);gde=n(KL,"STRONG",{});var bke=s(gde);Eto=r(bke,"blenderbot-small"),bke.forEach(t),Cto=r(KL," \u2014 "),jB=n(KL,"A",{href:!0});var Fke=s(jB);wto=r(Fke,"BlenderbotSmallConfig"),Fke.forEach(t),Ato=r(KL," (BlenderbotSmall model)"),KL.forEach(t),Lto=i(L),qm=n(L,"LI",{});var ZL=s(qm);hde=n(ZL,"STRONG",{});var Tke=s(hde);yto=r(Tke,"bloom"),Tke.forEach(t),xto=r(ZL," \u2014 "),DB=n(ZL,"A",{href:!0});var Mke=s(DB);$to=r(Mke,"BloomConfig"),Mke.forEach(t),kto=r(ZL," (BLOOM model)"),ZL.forEach(t),Sto=i(L),jm=n(L,"LI",{});var ey=s(jm);ude=n(ey,"STRONG",{});var Eke=s(ude);Rto=r(Eke,"camembert"),Eke.forEach(t),Pto=r(ey," \u2014 "),GB=n(ey,"A",{href:!0});var Cke=s(GB);Bto=r(Cke,"CamembertConfig"),Cke.forEach(t),Ito=r(ey," (CamemBERT model)"),ey.forEach(t),Nto=i(L),Dm=n(L,"LI",{});var oy=s(Dm);pde=n(oy,"STRONG",{});var wke=s(pde);qto=r(wke,"canine"),wke.forEach(t),jto=r(oy," \u2014 "),OB=n(oy,"A",{href:!0});var Ake=s(OB);Dto=r(Ake,"CanineConfig"),Ake.forEach(t),Gto=r(oy," (CANINE model)"),oy.forEach(t),Oto=i(L),Gm=n(L,"LI",{});var ry=s(Gm);_de=n(ry,"STRONG",{});var Lke=s(_de);Vto=r(Lke,"clip"),Lke.forEach(t),Xto=r(ry," \u2014 "),VB=n(ry,"A",{href:!0});var yke=s(VB);zto=r(yke,"CLIPConfig"),yke.forEach(t),Qto=r(ry," (CLIP model)"),ry.forEach(t),Wto=i(L),Om=n(L,"LI",{});var ty=s(Om);vde=n(ty,"STRONG",{});var xke=s(vde);Uto=r(xke,"codegen"),xke.forEach(t),Hto=r(ty," \u2014 "),XB=n(ty,"A",{href:!0});var $ke=s(XB);Jto=r($ke,"CodeGenConfig"),$ke.forEach(t),Yto=r(ty," (CodeGen model)"),ty.forEach(t),Kto=i(L),Vm=n(L,"LI",{});var ay=s(Vm);bde=n(ay,"STRONG",{});var kke=s(bde);Zto=r(kke,"convbert"),kke.forEach(t),eao=r(ay," \u2014 "),zB=n(ay,"A",{href:!0});var Ske=s(zB);oao=r(Ske,"ConvBertConfig"),Ske.forEach(t),rao=r(ay," (ConvBERT model)"),ay.forEach(t),tao=i(L),Xm=n(L,"LI",{});var ny=s(Xm);Fde=n(ny,"STRONG",{});var Rke=s(Fde);aao=r(Rke,"convnext"),Rke.forEach(t),nao=r(ny," \u2014 "),QB=n(ny,"A",{href:!0});var Pke=s(QB);sao=r(Pke,"ConvNextConfig"),Pke.forEach(t),lao=r(ny," (ConvNeXT model)"),ny.forEach(t),iao=i(L),zm=n(L,"LI",{});var sy=s(zm);Tde=n(sy,"STRONG",{});var Bke=s(Tde);dao=r(Bke,"ctrl"),Bke.forEach(t),cao=r(sy," \u2014 "),WB=n(sy,"A",{href:!0});var Ike=s(WB);fao=r(Ike,"CTRLConfig"),Ike.forEach(t),mao=r(sy," (CTRL model)"),sy.forEach(t),gao=i(L),Qm=n(L,"LI",{});var ly=s(Qm);Mde=n(ly,"STRONG",{});var Nke=s(Mde);hao=r(Nke,"cvt"),Nke.forEach(t),uao=r(ly," \u2014 "),UB=n(ly,"A",{href:!0});var qke=s(UB);pao=r(qke,"CvtConfig"),qke.forEach(t),_ao=r(ly," (CvT model)"),ly.forEach(t),vao=i(L),Wm=n(L,"LI",{});var iy=s(Wm);Ede=n(iy,"STRONG",{});var jke=s(Ede);bao=r(jke,"data2vec-audio"),jke.forEach(t),Fao=r(iy," \u2014 "),HB=n(iy,"A",{href:!0});var Dke=s(HB);Tao=r(Dke,"Data2VecAudioConfig"),Dke.forEach(t),Mao=r(iy," (Data2VecAudio model)"),iy.forEach(t),Eao=i(L),Um=n(L,"LI",{});var dy=s(Um);Cde=n(dy,"STRONG",{});var Gke=s(Cde);Cao=r(Gke,"data2vec-text"),Gke.forEach(t),wao=r(dy," \u2014 "),JB=n(dy,"A",{href:!0});var Oke=s(JB);Aao=r(Oke,"Data2VecTextConfig"),Oke.forEach(t),Lao=r(dy," (Data2VecText model)"),dy.forEach(t),yao=i(L),Hm=n(L,"LI",{});var cy=s(Hm);wde=n(cy,"STRONG",{});var Vke=s(wde);xao=r(Vke,"data2vec-vision"),Vke.forEach(t),$ao=r(cy," \u2014 "),YB=n(cy,"A",{href:!0});var Xke=s(YB);kao=r(Xke,"Data2VecVisionConfig"),Xke.forEach(t),Sao=r(cy," (Data2VecVision model)"),cy.forEach(t),Rao=i(L),Jm=n(L,"LI",{});var fy=s(Jm);Ade=n(fy,"STRONG",{});var zke=s(Ade);Pao=r(zke,"deberta"),zke.forEach(t),Bao=r(fy," \u2014 "),KB=n(fy,"A",{href:!0});var Qke=s(KB);Iao=r(Qke,"DebertaConfig"),Qke.forEach(t),Nao=r(fy," (DeBERTa model)"),fy.forEach(t),qao=i(L),Ym=n(L,"LI",{});var my=s(Ym);Lde=n(my,"STRONG",{});var Wke=s(Lde);jao=r(Wke,"deberta-v2"),Wke.forEach(t),Dao=r(my," \u2014 "),ZB=n(my,"A",{href:!0});var Uke=s(ZB);Gao=r(Uke,"DebertaV2Config"),Uke.forEach(t),Oao=r(my," (DeBERTa-v2 model)"),my.forEach(t),Vao=i(L),Km=n(L,"LI",{});var gy=s(Km);yde=n(gy,"STRONG",{});var Hke=s(yde);Xao=r(Hke,"decision_transformer"),Hke.forEach(t),zao=r(gy," \u2014 "),eI=n(gy,"A",{href:!0});var Jke=s(eI);Qao=r(Jke,"DecisionTransformerConfig"),Jke.forEach(t),Wao=r(gy," (Decision Transformer model)"),gy.forEach(t),Uao=i(L),Zm=n(L,"LI",{});var hy=s(Zm);xde=n(hy,"STRONG",{});var Yke=s(xde);Hao=r(Yke,"deit"),Yke.forEach(t),Jao=r(hy," \u2014 "),oI=n(hy,"A",{href:!0});var Kke=s(oI);Yao=r(Kke,"DeiTConfig"),Kke.forEach(t),Kao=r(hy," (DeiT model)"),hy.forEach(t),Zao=i(L),eg=n(L,"LI",{});var uy=s(eg);$de=n(uy,"STRONG",{});var Zke=s($de);eno=r(Zke,"detr"),Zke.forEach(t),ono=r(uy," \u2014 "),rI=n(uy,"A",{href:!0});var eSe=s(rI);rno=r(eSe,"DetrConfig"),eSe.forEach(t),tno=r(uy," (DETR model)"),uy.forEach(t),ano=i(L),og=n(L,"LI",{});var oSe=s(og);kde=n(oSe,"STRONG",{});var Gvt=s(kde);nno=r(Gvt,"distilbert"),Gvt.forEach(t),sno=r(oSe," \u2014 "),tI=n(oSe,"A",{href:!0});var Ovt=s(tI);lno=r(Ovt,"DistilBertConfig"),Ovt.forEach(t),ino=r(oSe," (DistilBERT model)"),oSe.forEach(t),dno=i(L),rg=n(L,"LI",{});var rSe=s(rg);Sde=n(rSe,"STRONG",{});var Vvt=s(Sde);cno=r(Vvt,"donut-swin"),Vvt.forEach(t),fno=r(rSe," \u2014 "),aI=n(rSe,"A",{href:!0});var Xvt=s(aI);mno=r(Xvt,"DonutSwinConfig"),Xvt.forEach(t),gno=r(rSe," (DonutSwin model)"),rSe.forEach(t),hno=i(L),tg=n(L,"LI",{});var tSe=s(tg);Rde=n(tSe,"STRONG",{});var zvt=s(Rde);uno=r(zvt,"dpr"),zvt.forEach(t),pno=r(tSe," \u2014 "),nI=n(tSe,"A",{href:!0});var Qvt=s(nI);_no=r(Qvt,"DPRConfig"),Qvt.forEach(t),vno=r(tSe," (DPR model)"),tSe.forEach(t),bno=i(L),ag=n(L,"LI",{});var aSe=s(ag);Pde=n(aSe,"STRONG",{});var Wvt=s(Pde);Fno=r(Wvt,"dpt"),Wvt.forEach(t),Tno=r(aSe," \u2014 "),sI=n(aSe,"A",{href:!0});var Uvt=s(sI);Mno=r(Uvt,"DPTConfig"),Uvt.forEach(t),Eno=r(aSe," (DPT model)"),aSe.forEach(t),Cno=i(L),ng=n(L,"LI",{});var nSe=s(ng);Bde=n(nSe,"STRONG",{});var Hvt=s(Bde);wno=r(Hvt,"electra"),Hvt.forEach(t),Ano=r(nSe," \u2014 "),lI=n(nSe,"A",{href:!0});var Jvt=s(lI);Lno=r(Jvt,"ElectraConfig"),Jvt.forEach(t),yno=r(nSe," (ELECTRA model)"),nSe.forEach(t),xno=i(L),sg=n(L,"LI",{});var sSe=s(sg);Ide=n(sSe,"STRONG",{});var Yvt=s(Ide);$no=r(Yvt,"encoder-decoder"),Yvt.forEach(t),kno=r(sSe," \u2014 "),iI=n(sSe,"A",{href:!0});var Kvt=s(iI);Sno=r(Kvt,"EncoderDecoderConfig"),Kvt.forEach(t),Rno=r(sSe," (Encoder decoder model)"),sSe.forEach(t),Pno=i(L),lg=n(L,"LI",{});var lSe=s(lg);Nde=n(lSe,"STRONG",{});var Zvt=s(Nde);Bno=r(Zvt,"ernie"),Zvt.forEach(t),Ino=r(lSe," \u2014 "),dI=n(lSe,"A",{href:!0});var e4t=s(dI);Nno=r(e4t,"ErnieConfig"),e4t.forEach(t),qno=r(lSe," (ERNIE model)"),lSe.forEach(t),jno=i(L),ig=n(L,"LI",{});var iSe=s(ig);qde=n(iSe,"STRONG",{});var o4t=s(qde);Dno=r(o4t,"flaubert"),o4t.forEach(t),Gno=r(iSe," \u2014 "),cI=n(iSe,"A",{href:!0});var r4t=s(cI);Ono=r(r4t,"FlaubertConfig"),r4t.forEach(t),Vno=r(iSe," (FlauBERT model)"),iSe.forEach(t),Xno=i(L),dg=n(L,"LI",{});var dSe=s(dg);jde=n(dSe,"STRONG",{});var t4t=s(jde);zno=r(t4t,"flava"),t4t.forEach(t),Qno=r(dSe," \u2014 "),fI=n(dSe,"A",{href:!0});var a4t=s(fI);Wno=r(a4t,"FlavaConfig"),a4t.forEach(t),Uno=r(dSe," (FLAVA model)"),dSe.forEach(t),Hno=i(L),cg=n(L,"LI",{});var cSe=s(cg);Dde=n(cSe,"STRONG",{});var n4t=s(Dde);Jno=r(n4t,"fnet"),n4t.forEach(t),Yno=r(cSe," \u2014 "),mI=n(cSe,"A",{href:!0});var s4t=s(mI);Kno=r(s4t,"FNetConfig"),s4t.forEach(t),Zno=r(cSe," (FNet model)"),cSe.forEach(t),eso=i(L),fg=n(L,"LI",{});var fSe=s(fg);Gde=n(fSe,"STRONG",{});var l4t=s(Gde);oso=r(l4t,"fsmt"),l4t.forEach(t),rso=r(fSe," \u2014 "),gI=n(fSe,"A",{href:!0});var i4t=s(gI);tso=r(i4t,"FSMTConfig"),i4t.forEach(t),aso=r(fSe," (FairSeq Machine-Translation model)"),fSe.forEach(t),nso=i(L),mg=n(L,"LI",{});var mSe=s(mg);Ode=n(mSe,"STRONG",{});var d4t=s(Ode);sso=r(d4t,"funnel"),d4t.forEach(t),lso=r(mSe," \u2014 "),hI=n(mSe,"A",{href:!0});var c4t=s(hI);iso=r(c4t,"FunnelConfig"),c4t.forEach(t),dso=r(mSe," (Funnel Transformer model)"),mSe.forEach(t),cso=i(L),gg=n(L,"LI",{});var gSe=s(gg);Vde=n(gSe,"STRONG",{});var f4t=s(Vde);fso=r(f4t,"glpn"),f4t.forEach(t),mso=r(gSe," \u2014 "),uI=n(gSe,"A",{href:!0});var m4t=s(uI);gso=r(m4t,"GLPNConfig"),m4t.forEach(t),hso=r(gSe," (GLPN model)"),gSe.forEach(t),uso=i(L),hg=n(L,"LI",{});var hSe=s(hg);Xde=n(hSe,"STRONG",{});var g4t=s(Xde);pso=r(g4t,"gpt2"),g4t.forEach(t),_so=r(hSe," \u2014 "),pI=n(hSe,"A",{href:!0});var h4t=s(pI);vso=r(h4t,"GPT2Config"),h4t.forEach(t),bso=r(hSe," (OpenAI GPT-2 model)"),hSe.forEach(t),Fso=i(L),ug=n(L,"LI",{});var uSe=s(ug);zde=n(uSe,"STRONG",{});var u4t=s(zde);Tso=r(u4t,"gpt_neo"),u4t.forEach(t),Mso=r(uSe," \u2014 "),_I=n(uSe,"A",{href:!0});var p4t=s(_I);Eso=r(p4t,"GPTNeoConfig"),p4t.forEach(t),Cso=r(uSe," (GPT Neo model)"),uSe.forEach(t),wso=i(L),pg=n(L,"LI",{});var pSe=s(pg);Qde=n(pSe,"STRONG",{});var _4t=s(Qde);Aso=r(_4t,"gpt_neox"),_4t.forEach(t),Lso=r(pSe," \u2014 "),vI=n(pSe,"A",{href:!0});var v4t=s(vI);yso=r(v4t,"GPTNeoXConfig"),v4t.forEach(t),xso=r(pSe," (GPT NeoX model)"),pSe.forEach(t),$so=i(L),_g=n(L,"LI",{});var _Se=s(_g);Wde=n(_Se,"STRONG",{});var b4t=s(Wde);kso=r(b4t,"gptj"),b4t.forEach(t),Sso=r(_Se," \u2014 "),bI=n(_Se,"A",{href:!0});var F4t=s(bI);Rso=r(F4t,"GPTJConfig"),F4t.forEach(t),Pso=r(_Se," (GPT-J model)"),_Se.forEach(t),Bso=i(L),vg=n(L,"LI",{});var vSe=s(vg);Ude=n(vSe,"STRONG",{});var T4t=s(Ude);Iso=r(T4t,"groupvit"),T4t.forEach(t),Nso=r(vSe," \u2014 "),FI=n(vSe,"A",{href:!0});var M4t=s(FI);qso=r(M4t,"GroupViTConfig"),M4t.forEach(t),jso=r(vSe," (GroupViT model)"),vSe.forEach(t),Dso=i(L),bg=n(L,"LI",{});var bSe=s(bg);Hde=n(bSe,"STRONG",{});var E4t=s(Hde);Gso=r(E4t,"hubert"),E4t.forEach(t),Oso=r(bSe," \u2014 "),TI=n(bSe,"A",{href:!0});var C4t=s(TI);Vso=r(C4t,"HubertConfig"),C4t.forEach(t),Xso=r(bSe," (Hubert model)"),bSe.forEach(t),zso=i(L),Fg=n(L,"LI",{});var FSe=s(Fg);Jde=n(FSe,"STRONG",{});var w4t=s(Jde);Qso=r(w4t,"ibert"),w4t.forEach(t),Wso=r(FSe," \u2014 "),MI=n(FSe,"A",{href:!0});var A4t=s(MI);Uso=r(A4t,"IBertConfig"),A4t.forEach(t),Hso=r(FSe," (I-BERT model)"),FSe.forEach(t),Jso=i(L),Tg=n(L,"LI",{});var TSe=s(Tg);Yde=n(TSe,"STRONG",{});var L4t=s(Yde);Yso=r(L4t,"imagegpt"),L4t.forEach(t),Kso=r(TSe," \u2014 "),EI=n(TSe,"A",{href:!0});var y4t=s(EI);Zso=r(y4t,"ImageGPTConfig"),y4t.forEach(t),elo=r(TSe," (ImageGPT model)"),TSe.forEach(t),olo=i(L),Mg=n(L,"LI",{});var MSe=s(Mg);Kde=n(MSe,"STRONG",{});var x4t=s(Kde);rlo=r(x4t,"layoutlm"),x4t.forEach(t),tlo=r(MSe," \u2014 "),CI=n(MSe,"A",{href:!0});var $4t=s(CI);alo=r($4t,"LayoutLMConfig"),$4t.forEach(t),nlo=r(MSe," (LayoutLM model)"),MSe.forEach(t),slo=i(L),Eg=n(L,"LI",{});var ESe=s(Eg);Zde=n(ESe,"STRONG",{});var k4t=s(Zde);llo=r(k4t,"layoutlmv2"),k4t.forEach(t),ilo=r(ESe," \u2014 "),wI=n(ESe,"A",{href:!0});var S4t=s(wI);dlo=r(S4t,"LayoutLMv2Config"),S4t.forEach(t),clo=r(ESe," (LayoutLMv2 model)"),ESe.forEach(t),flo=i(L),Cg=n(L,"LI",{});var CSe=s(Cg);ece=n(CSe,"STRONG",{});var R4t=s(ece);mlo=r(R4t,"layoutlmv3"),R4t.forEach(t),glo=r(CSe," \u2014 "),AI=n(CSe,"A",{href:!0});var P4t=s(AI);hlo=r(P4t,"LayoutLMv3Config"),P4t.forEach(t),ulo=r(CSe," (LayoutLMv3 model)"),CSe.forEach(t),plo=i(L),wg=n(L,"LI",{});var wSe=s(wg);oce=n(wSe,"STRONG",{});var B4t=s(oce);_lo=r(B4t,"led"),B4t.forEach(t),vlo=r(wSe," \u2014 "),LI=n(wSe,"A",{href:!0});var I4t=s(LI);blo=r(I4t,"LEDConfig"),I4t.forEach(t),Flo=r(wSe," (LED model)"),wSe.forEach(t),Tlo=i(L),Ag=n(L,"LI",{});var ASe=s(Ag);rce=n(ASe,"STRONG",{});var N4t=s(rce);Mlo=r(N4t,"levit"),N4t.forEach(t),Elo=r(ASe," \u2014 "),yI=n(ASe,"A",{href:!0});var q4t=s(yI);Clo=r(q4t,"LevitConfig"),q4t.forEach(t),wlo=r(ASe," (LeViT model)"),ASe.forEach(t),Alo=i(L),Lg=n(L,"LI",{});var LSe=s(Lg);tce=n(LSe,"STRONG",{});var j4t=s(tce);Llo=r(j4t,"longformer"),j4t.forEach(t),ylo=r(LSe," \u2014 "),xI=n(LSe,"A",{href:!0});var D4t=s(xI);xlo=r(D4t,"LongformerConfig"),D4t.forEach(t),$lo=r(LSe," (Longformer model)"),LSe.forEach(t),klo=i(L),yg=n(L,"LI",{});var ySe=s(yg);ace=n(ySe,"STRONG",{});var G4t=s(ace);Slo=r(G4t,"longt5"),G4t.forEach(t),Rlo=r(ySe," \u2014 "),$I=n(ySe,"A",{href:!0});var O4t=s($I);Plo=r(O4t,"LongT5Config"),O4t.forEach(t),Blo=r(ySe," (LongT5 model)"),ySe.forEach(t),Ilo=i(L),xg=n(L,"LI",{});var xSe=s(xg);nce=n(xSe,"STRONG",{});var V4t=s(nce);Nlo=r(V4t,"luke"),V4t.forEach(t),qlo=r(xSe," \u2014 "),kI=n(xSe,"A",{href:!0});var X4t=s(kI);jlo=r(X4t,"LukeConfig"),X4t.forEach(t),Dlo=r(xSe," (LUKE model)"),xSe.forEach(t),Glo=i(L),$g=n(L,"LI",{});var $Se=s($g);sce=n($Se,"STRONG",{});var z4t=s(sce);Olo=r(z4t,"lxmert"),z4t.forEach(t),Vlo=r($Se," \u2014 "),SI=n($Se,"A",{href:!0});var Q4t=s(SI);Xlo=r(Q4t,"LxmertConfig"),Q4t.forEach(t),zlo=r($Se," (LXMERT model)"),$Se.forEach(t),Qlo=i(L),kg=n(L,"LI",{});var kSe=s(kg);lce=n(kSe,"STRONG",{});var W4t=s(lce);Wlo=r(W4t,"m2m_100"),W4t.forEach(t),Ulo=r(kSe," \u2014 "),RI=n(kSe,"A",{href:!0});var U4t=s(RI);Hlo=r(U4t,"M2M100Config"),U4t.forEach(t),Jlo=r(kSe," (M2M100 model)"),kSe.forEach(t),Ylo=i(L),Sg=n(L,"LI",{});var SSe=s(Sg);ice=n(SSe,"STRONG",{});var H4t=s(ice);Klo=r(H4t,"marian"),H4t.forEach(t),Zlo=r(SSe," \u2014 "),PI=n(SSe,"A",{href:!0});var J4t=s(PI);eio=r(J4t,"MarianConfig"),J4t.forEach(t),oio=r(SSe," (Marian model)"),SSe.forEach(t),rio=i(L),Rg=n(L,"LI",{});var RSe=s(Rg);dce=n(RSe,"STRONG",{});var Y4t=s(dce);tio=r(Y4t,"maskformer"),Y4t.forEach(t),aio=r(RSe," \u2014 "),BI=n(RSe,"A",{href:!0});var K4t=s(BI);nio=r(K4t,"MaskFormerConfig"),K4t.forEach(t),sio=r(RSe," (MaskFormer model)"),RSe.forEach(t),lio=i(L),Pg=n(L,"LI",{});var PSe=s(Pg);cce=n(PSe,"STRONG",{});var Z4t=s(cce);iio=r(Z4t,"mbart"),Z4t.forEach(t),dio=r(PSe," \u2014 "),II=n(PSe,"A",{href:!0});var ebt=s(II);cio=r(ebt,"MBartConfig"),ebt.forEach(t),fio=r(PSe," (mBART model)"),PSe.forEach(t),mio=i(L),Bg=n(L,"LI",{});var BSe=s(Bg);fce=n(BSe,"STRONG",{});var obt=s(fce);gio=r(obt,"mctct"),obt.forEach(t),hio=r(BSe," \u2014 "),NI=n(BSe,"A",{href:!0});var rbt=s(NI);uio=r(rbt,"MCTCTConfig"),rbt.forEach(t),pio=r(BSe," (M-CTC-T model)"),BSe.forEach(t),_io=i(L),Ig=n(L,"LI",{});var ISe=s(Ig);mce=n(ISe,"STRONG",{});var tbt=s(mce);vio=r(tbt,"megatron-bert"),tbt.forEach(t),bio=r(ISe," \u2014 "),qI=n(ISe,"A",{href:!0});var abt=s(qI);Fio=r(abt,"MegatronBertConfig"),abt.forEach(t),Tio=r(ISe," (Megatron-BERT model)"),ISe.forEach(t),Mio=i(L),Ng=n(L,"LI",{});var NSe=s(Ng);gce=n(NSe,"STRONG",{});var nbt=s(gce);Eio=r(nbt,"mobilebert"),nbt.forEach(t),Cio=r(NSe," \u2014 "),jI=n(NSe,"A",{href:!0});var sbt=s(jI);wio=r(sbt,"MobileBertConfig"),sbt.forEach(t),Aio=r(NSe," (MobileBERT model)"),NSe.forEach(t),Lio=i(L),qg=n(L,"LI",{});var qSe=s(qg);hce=n(qSe,"STRONG",{});var lbt=s(hce);yio=r(lbt,"mobilevit"),lbt.forEach(t),xio=r(qSe," \u2014 "),DI=n(qSe,"A",{href:!0});var ibt=s(DI);$io=r(ibt,"MobileViTConfig"),ibt.forEach(t),kio=r(qSe," (MobileViT model)"),qSe.forEach(t),Sio=i(L),jg=n(L,"LI",{});var jSe=s(jg);uce=n(jSe,"STRONG",{});var dbt=s(uce);Rio=r(dbt,"mpnet"),dbt.forEach(t),Pio=r(jSe," \u2014 "),GI=n(jSe,"A",{href:!0});var cbt=s(GI);Bio=r(cbt,"MPNetConfig"),cbt.forEach(t),Iio=r(jSe," (MPNet model)"),jSe.forEach(t),Nio=i(L),Dg=n(L,"LI",{});var DSe=s(Dg);pce=n(DSe,"STRONG",{});var fbt=s(pce);qio=r(fbt,"mt5"),fbt.forEach(t),jio=r(DSe," \u2014 "),OI=n(DSe,"A",{href:!0});var mbt=s(OI);Dio=r(mbt,"MT5Config"),mbt.forEach(t),Gio=r(DSe," (MT5 model)"),DSe.forEach(t),Oio=i(L),Gg=n(L,"LI",{});var GSe=s(Gg);_ce=n(GSe,"STRONG",{});var gbt=s(_ce);Vio=r(gbt,"mvp"),gbt.forEach(t),Xio=r(GSe," \u2014 "),VI=n(GSe,"A",{href:!0});var hbt=s(VI);zio=r(hbt,"MvpConfig"),hbt.forEach(t),Qio=r(GSe," (MVP model)"),GSe.forEach(t),Wio=i(L),Og=n(L,"LI",{});var OSe=s(Og);vce=n(OSe,"STRONG",{});var ubt=s(vce);Uio=r(ubt,"nezha"),ubt.forEach(t),Hio=r(OSe," \u2014 "),XI=n(OSe,"A",{href:!0});var pbt=s(XI);Jio=r(pbt,"NezhaConfig"),pbt.forEach(t),Yio=r(OSe," (Nezha model)"),OSe.forEach(t),Kio=i(L),Vg=n(L,"LI",{});var VSe=s(Vg);bce=n(VSe,"STRONG",{});var _bt=s(bce);Zio=r(_bt,"nystromformer"),_bt.forEach(t),edo=r(VSe," \u2014 "),zI=n(VSe,"A",{href:!0});var vbt=s(zI);odo=r(vbt,"NystromformerConfig"),vbt.forEach(t),rdo=r(VSe," (Nystr\xF6mformer model)"),VSe.forEach(t),tdo=i(L),Xg=n(L,"LI",{});var XSe=s(Xg);Fce=n(XSe,"STRONG",{});var bbt=s(Fce);ado=r(bbt,"openai-gpt"),bbt.forEach(t),ndo=r(XSe," \u2014 "),QI=n(XSe,"A",{href:!0});var Fbt=s(QI);sdo=r(Fbt,"OpenAIGPTConfig"),Fbt.forEach(t),ldo=r(XSe," (OpenAI GPT model)"),XSe.forEach(t),ido=i(L),zg=n(L,"LI",{});var zSe=s(zg);Tce=n(zSe,"STRONG",{});var Tbt=s(Tce);ddo=r(Tbt,"opt"),Tbt.forEach(t),cdo=r(zSe," \u2014 "),WI=n(zSe,"A",{href:!0});var Mbt=s(WI);fdo=r(Mbt,"OPTConfig"),Mbt.forEach(t),mdo=r(zSe," (OPT model)"),zSe.forEach(t),gdo=i(L),Qg=n(L,"LI",{});var QSe=s(Qg);Mce=n(QSe,"STRONG",{});var Ebt=s(Mce);hdo=r(Ebt,"owlvit"),Ebt.forEach(t),udo=r(QSe," \u2014 "),UI=n(QSe,"A",{href:!0});var Cbt=s(UI);pdo=r(Cbt,"OwlViTConfig"),Cbt.forEach(t),_do=r(QSe," (OWL-ViT model)"),QSe.forEach(t),vdo=i(L),Wg=n(L,"LI",{});var WSe=s(Wg);Ece=n(WSe,"STRONG",{});var wbt=s(Ece);bdo=r(wbt,"pegasus"),wbt.forEach(t),Fdo=r(WSe," \u2014 "),HI=n(WSe,"A",{href:!0});var Abt=s(HI);Tdo=r(Abt,"PegasusConfig"),Abt.forEach(t),Mdo=r(WSe," (Pegasus model)"),WSe.forEach(t),Edo=i(L),Ug=n(L,"LI",{});var USe=s(Ug);Cce=n(USe,"STRONG",{});var Lbt=s(Cce);Cdo=r(Lbt,"pegasus_x"),Lbt.forEach(t),wdo=r(USe," \u2014 "),JI=n(USe,"A",{href:!0});var ybt=s(JI);Ado=r(ybt,"PegasusXConfig"),ybt.forEach(t),Ldo=r(USe," (PEGASUS-X model)"),USe.forEach(t),ydo=i(L),Hg=n(L,"LI",{});var HSe=s(Hg);wce=n(HSe,"STRONG",{});var xbt=s(wce);xdo=r(xbt,"perceiver"),xbt.forEach(t),$do=r(HSe," \u2014 "),YI=n(HSe,"A",{href:!0});var $bt=s(YI);kdo=r($bt,"PerceiverConfig"),$bt.forEach(t),Sdo=r(HSe," (Perceiver model)"),HSe.forEach(t),Rdo=i(L),Jg=n(L,"LI",{});var JSe=s(Jg);Ace=n(JSe,"STRONG",{});var kbt=s(Ace);Pdo=r(kbt,"plbart"),kbt.forEach(t),Bdo=r(JSe," \u2014 "),KI=n(JSe,"A",{href:!0});var Sbt=s(KI);Ido=r(Sbt,"PLBartConfig"),Sbt.forEach(t),Ndo=r(JSe," (PLBart model)"),JSe.forEach(t),qdo=i(L),Yg=n(L,"LI",{});var YSe=s(Yg);Lce=n(YSe,"STRONG",{});var Rbt=s(Lce);jdo=r(Rbt,"poolformer"),Rbt.forEach(t),Ddo=r(YSe," \u2014 "),ZI=n(YSe,"A",{href:!0});var Pbt=s(ZI);Gdo=r(Pbt,"PoolFormerConfig"),Pbt.forEach(t),Odo=r(YSe," (PoolFormer model)"),YSe.forEach(t),Vdo=i(L),Kg=n(L,"LI",{});var KSe=s(Kg);yce=n(KSe,"STRONG",{});var Bbt=s(yce);Xdo=r(Bbt,"prophetnet"),Bbt.forEach(t),zdo=r(KSe," \u2014 "),eN=n(KSe,"A",{href:!0});var Ibt=s(eN);Qdo=r(Ibt,"ProphetNetConfig"),Ibt.forEach(t),Wdo=r(KSe," (ProphetNet model)"),KSe.forEach(t),Udo=i(L),Zg=n(L,"LI",{});var ZSe=s(Zg);xce=n(ZSe,"STRONG",{});var Nbt=s(xce);Hdo=r(Nbt,"qdqbert"),Nbt.forEach(t),Jdo=r(ZSe," \u2014 "),oN=n(ZSe,"A",{href:!0});var qbt=s(oN);Ydo=r(qbt,"QDQBertConfig"),qbt.forEach(t),Kdo=r(ZSe," (QDQBert model)"),ZSe.forEach(t),Zdo=i(L),eh=n(L,"LI",{});var eRe=s(eh);$ce=n(eRe,"STRONG",{});var jbt=s($ce);eco=r(jbt,"rag"),jbt.forEach(t),oco=r(eRe," \u2014 "),rN=n(eRe,"A",{href:!0});var Dbt=s(rN);rco=r(Dbt,"RagConfig"),Dbt.forEach(t),tco=r(eRe," (RAG model)"),eRe.forEach(t),aco=i(L),oh=n(L,"LI",{});var oRe=s(oh);kce=n(oRe,"STRONG",{});var Gbt=s(kce);nco=r(Gbt,"realm"),Gbt.forEach(t),sco=r(oRe," \u2014 "),tN=n(oRe,"A",{href:!0});var Obt=s(tN);lco=r(Obt,"RealmConfig"),Obt.forEach(t),ico=r(oRe," (REALM model)"),oRe.forEach(t),dco=i(L),rh=n(L,"LI",{});var rRe=s(rh);Sce=n(rRe,"STRONG",{});var Vbt=s(Sce);cco=r(Vbt,"reformer"),Vbt.forEach(t),fco=r(rRe," \u2014 "),aN=n(rRe,"A",{href:!0});var Xbt=s(aN);mco=r(Xbt,"ReformerConfig"),Xbt.forEach(t),gco=r(rRe," (Reformer model)"),rRe.forEach(t),hco=i(L),th=n(L,"LI",{});var tRe=s(th);Rce=n(tRe,"STRONG",{});var zbt=s(Rce);uco=r(zbt,"regnet"),zbt.forEach(t),pco=r(tRe," \u2014 "),nN=n(tRe,"A",{href:!0});var Qbt=s(nN);_co=r(Qbt,"RegNetConfig"),Qbt.forEach(t),vco=r(tRe," (RegNet model)"),tRe.forEach(t),bco=i(L),ah=n(L,"LI",{});var aRe=s(ah);Pce=n(aRe,"STRONG",{});var Wbt=s(Pce);Fco=r(Wbt,"rembert"),Wbt.forEach(t),Tco=r(aRe," \u2014 "),sN=n(aRe,"A",{href:!0});var Ubt=s(sN);Mco=r(Ubt,"RemBertConfig"),Ubt.forEach(t),Eco=r(aRe," (RemBERT model)"),aRe.forEach(t),Cco=i(L),nh=n(L,"LI",{});var nRe=s(nh);Bce=n(nRe,"STRONG",{});var Hbt=s(Bce);wco=r(Hbt,"resnet"),Hbt.forEach(t),Aco=r(nRe," \u2014 "),lN=n(nRe,"A",{href:!0});var Jbt=s(lN);Lco=r(Jbt,"ResNetConfig"),Jbt.forEach(t),yco=r(nRe," (ResNet model)"),nRe.forEach(t),xco=i(L),sh=n(L,"LI",{});var sRe=s(sh);Ice=n(sRe,"STRONG",{});var Ybt=s(Ice);$co=r(Ybt,"retribert"),Ybt.forEach(t),kco=r(sRe," \u2014 "),iN=n(sRe,"A",{href:!0});var Kbt=s(iN);Sco=r(Kbt,"RetriBertConfig"),Kbt.forEach(t),Rco=r(sRe," (RetriBERT model)"),sRe.forEach(t),Pco=i(L),lh=n(L,"LI",{});var lRe=s(lh);Nce=n(lRe,"STRONG",{});var Zbt=s(Nce);Bco=r(Zbt,"roberta"),Zbt.forEach(t),Ico=r(lRe," \u2014 "),dN=n(lRe,"A",{href:!0});var e1t=s(dN);Nco=r(e1t,"RobertaConfig"),e1t.forEach(t),qco=r(lRe," (RoBERTa model)"),lRe.forEach(t),jco=i(L),ih=n(L,"LI",{});var iRe=s(ih);qce=n(iRe,"STRONG",{});var o1t=s(qce);Dco=r(o1t,"roformer"),o1t.forEach(t),Gco=r(iRe," \u2014 "),cN=n(iRe,"A",{href:!0});var r1t=s(cN);Oco=r(r1t,"RoFormerConfig"),r1t.forEach(t),Vco=r(iRe," (RoFormer model)"),iRe.forEach(t),Xco=i(L),dh=n(L,"LI",{});var dRe=s(dh);jce=n(dRe,"STRONG",{});var t1t=s(jce);zco=r(t1t,"segformer"),t1t.forEach(t),Qco=r(dRe," \u2014 "),fN=n(dRe,"A",{href:!0});var a1t=s(fN);Wco=r(a1t,"SegformerConfig"),a1t.forEach(t),Uco=r(dRe," (SegFormer model)"),dRe.forEach(t),Hco=i(L),ch=n(L,"LI",{});var cRe=s(ch);Dce=n(cRe,"STRONG",{});var n1t=s(Dce);Jco=r(n1t,"sew"),n1t.forEach(t),Yco=r(cRe," \u2014 "),mN=n(cRe,"A",{href:!0});var s1t=s(mN);Kco=r(s1t,"SEWConfig"),s1t.forEach(t),Zco=r(cRe," (SEW model)"),cRe.forEach(t),efo=i(L),fh=n(L,"LI",{});var fRe=s(fh);Gce=n(fRe,"STRONG",{});var l1t=s(Gce);ofo=r(l1t,"sew-d"),l1t.forEach(t),rfo=r(fRe," \u2014 "),gN=n(fRe,"A",{href:!0});var i1t=s(gN);tfo=r(i1t,"SEWDConfig"),i1t.forEach(t),afo=r(fRe," (SEW-D model)"),fRe.forEach(t),nfo=i(L),mh=n(L,"LI",{});var mRe=s(mh);Oce=n(mRe,"STRONG",{});var d1t=s(Oce);sfo=r(d1t,"speech-encoder-decoder"),d1t.forEach(t),lfo=r(mRe," \u2014 "),hN=n(mRe,"A",{href:!0});var c1t=s(hN);ifo=r(c1t,"SpeechEncoderDecoderConfig"),c1t.forEach(t),dfo=r(mRe," (Speech Encoder decoder model)"),mRe.forEach(t),cfo=i(L),gh=n(L,"LI",{});var gRe=s(gh);Vce=n(gRe,"STRONG",{});var f1t=s(Vce);ffo=r(f1t,"speech_to_text"),f1t.forEach(t),mfo=r(gRe," \u2014 "),uN=n(gRe,"A",{href:!0});var m1t=s(uN);gfo=r(m1t,"Speech2TextConfig"),m1t.forEach(t),hfo=r(gRe," (Speech2Text model)"),gRe.forEach(t),ufo=i(L),hh=n(L,"LI",{});var hRe=s(hh);Xce=n(hRe,"STRONG",{});var g1t=s(Xce);pfo=r(g1t,"speech_to_text_2"),g1t.forEach(t),_fo=r(hRe," \u2014 "),pN=n(hRe,"A",{href:!0});var h1t=s(pN);vfo=r(h1t,"Speech2Text2Config"),h1t.forEach(t),bfo=r(hRe," (Speech2Text2 model)"),hRe.forEach(t),Ffo=i(L),uh=n(L,"LI",{});var uRe=s(uh);zce=n(uRe,"STRONG",{});var u1t=s(zce);Tfo=r(u1t,"splinter"),u1t.forEach(t),Mfo=r(uRe," \u2014 "),_N=n(uRe,"A",{href:!0});var p1t=s(_N);Efo=r(p1t,"SplinterConfig"),p1t.forEach(t),Cfo=r(uRe," (Splinter model)"),uRe.forEach(t),wfo=i(L),ph=n(L,"LI",{});var pRe=s(ph);Qce=n(pRe,"STRONG",{});var _1t=s(Qce);Afo=r(_1t,"squeezebert"),_1t.forEach(t),Lfo=r(pRe," \u2014 "),vN=n(pRe,"A",{href:!0});var v1t=s(vN);yfo=r(v1t,"SqueezeBertConfig"),v1t.forEach(t),xfo=r(pRe," (SqueezeBERT model)"),pRe.forEach(t),$fo=i(L),_h=n(L,"LI",{});var _Re=s(_h);Wce=n(_Re,"STRONG",{});var b1t=s(Wce);kfo=r(b1t,"swin"),b1t.forEach(t),Sfo=r(_Re," \u2014 "),bN=n(_Re,"A",{href:!0});var F1t=s(bN);Rfo=r(F1t,"SwinConfig"),F1t.forEach(t),Pfo=r(_Re," (Swin Transformer model)"),_Re.forEach(t),Bfo=i(L),vh=n(L,"LI",{});var vRe=s(vh);Uce=n(vRe,"STRONG",{});var T1t=s(Uce);Ifo=r(T1t,"swinv2"),T1t.forEach(t),Nfo=r(vRe," \u2014 "),FN=n(vRe,"A",{href:!0});var M1t=s(FN);qfo=r(M1t,"Swinv2Config"),M1t.forEach(t),jfo=r(vRe," (Swin Transformer V2 model)"),vRe.forEach(t),Dfo=i(L),bh=n(L,"LI",{});var bRe=s(bh);Hce=n(bRe,"STRONG",{});var E1t=s(Hce);Gfo=r(E1t,"t5"),E1t.forEach(t),Ofo=r(bRe," \u2014 "),TN=n(bRe,"A",{href:!0});var C1t=s(TN);Vfo=r(C1t,"T5Config"),C1t.forEach(t),Xfo=r(bRe," (T5 model)"),bRe.forEach(t),zfo=i(L),Fh=n(L,"LI",{});var FRe=s(Fh);Jce=n(FRe,"STRONG",{});var w1t=s(Jce);Qfo=r(w1t,"tapas"),w1t.forEach(t),Wfo=r(FRe," \u2014 "),MN=n(FRe,"A",{href:!0});var A1t=s(MN);Ufo=r(A1t,"TapasConfig"),A1t.forEach(t),Hfo=r(FRe," (TAPAS model)"),FRe.forEach(t),Jfo=i(L),Th=n(L,"LI",{});var TRe=s(Th);Yce=n(TRe,"STRONG",{});var L1t=s(Yce);Yfo=r(L1t,"trajectory_transformer"),L1t.forEach(t),Kfo=r(TRe," \u2014 "),EN=n(TRe,"A",{href:!0});var y1t=s(EN);Zfo=r(y1t,"TrajectoryTransformerConfig"),y1t.forEach(t),emo=r(TRe," (Trajectory Transformer model)"),TRe.forEach(t),omo=i(L),Mh=n(L,"LI",{});var MRe=s(Mh);Kce=n(MRe,"STRONG",{});var x1t=s(Kce);rmo=r(x1t,"transfo-xl"),x1t.forEach(t),tmo=r(MRe," \u2014 "),CN=n(MRe,"A",{href:!0});var $1t=s(CN);amo=r($1t,"TransfoXLConfig"),$1t.forEach(t),nmo=r(MRe," (Transformer-XL model)"),MRe.forEach(t),smo=i(L),Eh=n(L,"LI",{});var ERe=s(Eh);Zce=n(ERe,"STRONG",{});var k1t=s(Zce);lmo=r(k1t,"trocr"),k1t.forEach(t),imo=r(ERe," \u2014 "),wN=n(ERe,"A",{href:!0});var S1t=s(wN);dmo=r(S1t,"TrOCRConfig"),S1t.forEach(t),cmo=r(ERe," (TrOCR model)"),ERe.forEach(t),fmo=i(L),Ch=n(L,"LI",{});var CRe=s(Ch);efe=n(CRe,"STRONG",{});var R1t=s(efe);mmo=r(R1t,"unispeech"),R1t.forEach(t),gmo=r(CRe," \u2014 "),AN=n(CRe,"A",{href:!0});var P1t=s(AN);hmo=r(P1t,"UniSpeechConfig"),P1t.forEach(t),umo=r(CRe," (UniSpeech model)"),CRe.forEach(t),pmo=i(L),wh=n(L,"LI",{});var wRe=s(wh);ofe=n(wRe,"STRONG",{});var B1t=s(ofe);_mo=r(B1t,"unispeech-sat"),B1t.forEach(t),vmo=r(wRe," \u2014 "),LN=n(wRe,"A",{href:!0});var I1t=s(LN);bmo=r(I1t,"UniSpeechSatConfig"),I1t.forEach(t),Fmo=r(wRe," (UniSpeechSat model)"),wRe.forEach(t),Tmo=i(L),Ah=n(L,"LI",{});var ARe=s(Ah);rfe=n(ARe,"STRONG",{});var N1t=s(rfe);Mmo=r(N1t,"van"),N1t.forEach(t),Emo=r(ARe," \u2014 "),yN=n(ARe,"A",{href:!0});var q1t=s(yN);Cmo=r(q1t,"VanConfig"),q1t.forEach(t),wmo=r(ARe," (VAN model)"),ARe.forEach(t),Amo=i(L),Lh=n(L,"LI",{});var LRe=s(Lh);tfe=n(LRe,"STRONG",{});var j1t=s(tfe);Lmo=r(j1t,"videomae"),j1t.forEach(t),ymo=r(LRe," \u2014 "),xN=n(LRe,"A",{href:!0});var D1t=s(xN);xmo=r(D1t,"VideoMAEConfig"),D1t.forEach(t),$mo=r(LRe," (VideoMAE model)"),LRe.forEach(t),kmo=i(L),yh=n(L,"LI",{});var yRe=s(yh);afe=n(yRe,"STRONG",{});var G1t=s(afe);Smo=r(G1t,"vilt"),G1t.forEach(t),Rmo=r(yRe," \u2014 "),$N=n(yRe,"A",{href:!0});var O1t=s($N);Pmo=r(O1t,"ViltConfig"),O1t.forEach(t),Bmo=r(yRe," (ViLT model)"),yRe.forEach(t),Imo=i(L),xh=n(L,"LI",{});var xRe=s(xh);nfe=n(xRe,"STRONG",{});var V1t=s(nfe);Nmo=r(V1t,"vision-encoder-decoder"),V1t.forEach(t),qmo=r(xRe," \u2014 "),kN=n(xRe,"A",{href:!0});var X1t=s(kN);jmo=r(X1t,"VisionEncoderDecoderConfig"),X1t.forEach(t),Dmo=r(xRe," (Vision Encoder decoder model)"),xRe.forEach(t),Gmo=i(L),$h=n(L,"LI",{});var $Re=s($h);sfe=n($Re,"STRONG",{});var z1t=s(sfe);Omo=r(z1t,"vision-text-dual-encoder"),z1t.forEach(t),Vmo=r($Re," \u2014 "),SN=n($Re,"A",{href:!0});var Q1t=s(SN);Xmo=r(Q1t,"VisionTextDualEncoderConfig"),Q1t.forEach(t),zmo=r($Re," (VisionTextDualEncoder model)"),$Re.forEach(t),Qmo=i(L),kh=n(L,"LI",{});var kRe=s(kh);lfe=n(kRe,"STRONG",{});var W1t=s(lfe);Wmo=r(W1t,"visual_bert"),W1t.forEach(t),Umo=r(kRe," \u2014 "),RN=n(kRe,"A",{href:!0});var U1t=s(RN);Hmo=r(U1t,"VisualBertConfig"),U1t.forEach(t),Jmo=r(kRe," (VisualBERT model)"),kRe.forEach(t),Ymo=i(L),Sh=n(L,"LI",{});var SRe=s(Sh);ife=n(SRe,"STRONG",{});var H1t=s(ife);Kmo=r(H1t,"vit"),H1t.forEach(t),Zmo=r(SRe," \u2014 "),PN=n(SRe,"A",{href:!0});var J1t=s(PN);ego=r(J1t,"ViTConfig"),J1t.forEach(t),ogo=r(SRe," (ViT model)"),SRe.forEach(t),rgo=i(L),Rh=n(L,"LI",{});var RRe=s(Rh);dfe=n(RRe,"STRONG",{});var Y1t=s(dfe);tgo=r(Y1t,"vit_mae"),Y1t.forEach(t),ago=r(RRe," \u2014 "),BN=n(RRe,"A",{href:!0});var K1t=s(BN);ngo=r(K1t,"ViTMAEConfig"),K1t.forEach(t),sgo=r(RRe," (ViTMAE model)"),RRe.forEach(t),lgo=i(L),Ph=n(L,"LI",{});var PRe=s(Ph);cfe=n(PRe,"STRONG",{});var Z1t=s(cfe);igo=r(Z1t,"wav2vec2"),Z1t.forEach(t),dgo=r(PRe," \u2014 "),IN=n(PRe,"A",{href:!0});var e0t=s(IN);cgo=r(e0t,"Wav2Vec2Config"),e0t.forEach(t),fgo=r(PRe," (Wav2Vec2 model)"),PRe.forEach(t),mgo=i(L),Bh=n(L,"LI",{});var BRe=s(Bh);ffe=n(BRe,"STRONG",{});var o0t=s(ffe);ggo=r(o0t,"wav2vec2-conformer"),o0t.forEach(t),hgo=r(BRe," \u2014 "),NN=n(BRe,"A",{href:!0});var r0t=s(NN);ugo=r(r0t,"Wav2Vec2ConformerConfig"),r0t.forEach(t),pgo=r(BRe," (Wav2Vec2-Conformer model)"),BRe.forEach(t),_go=i(L),Ih=n(L,"LI",{});var IRe=s(Ih);mfe=n(IRe,"STRONG",{});var t0t=s(mfe);vgo=r(t0t,"wavlm"),t0t.forEach(t),bgo=r(IRe," \u2014 "),qN=n(IRe,"A",{href:!0});var a0t=s(qN);Fgo=r(a0t,"WavLMConfig"),a0t.forEach(t),Tgo=r(IRe," (WavLM model)"),IRe.forEach(t),Mgo=i(L),Nh=n(L,"LI",{});var NRe=s(Nh);gfe=n(NRe,"STRONG",{});var n0t=s(gfe);Ego=r(n0t,"xclip"),n0t.forEach(t),Cgo=r(NRe," \u2014 "),jN=n(NRe,"A",{href:!0});var s0t=s(jN);wgo=r(s0t,"XCLIPConfig"),s0t.forEach(t),Ago=r(NRe," (X-CLIP model)"),NRe.forEach(t),Lgo=i(L),qh=n(L,"LI",{});var qRe=s(qh);hfe=n(qRe,"STRONG",{});var l0t=s(hfe);ygo=r(l0t,"xglm"),l0t.forEach(t),xgo=r(qRe," \u2014 "),DN=n(qRe,"A",{href:!0});var i0t=s(DN);$go=r(i0t,"XGLMConfig"),i0t.forEach(t),kgo=r(qRe," (XGLM model)"),qRe.forEach(t),Sgo=i(L),jh=n(L,"LI",{});var jRe=s(jh);ufe=n(jRe,"STRONG",{});var d0t=s(ufe);Rgo=r(d0t,"xlm"),d0t.forEach(t),Pgo=r(jRe," \u2014 "),GN=n(jRe,"A",{href:!0});var c0t=s(GN);Bgo=r(c0t,"XLMConfig"),c0t.forEach(t),Igo=r(jRe," (XLM model)"),jRe.forEach(t),Ngo=i(L),Dh=n(L,"LI",{});var DRe=s(Dh);pfe=n(DRe,"STRONG",{});var f0t=s(pfe);qgo=r(f0t,"xlm-prophetnet"),f0t.forEach(t),jgo=r(DRe," \u2014 "),ON=n(DRe,"A",{href:!0});var m0t=s(ON);Dgo=r(m0t,"XLMProphetNetConfig"),m0t.forEach(t),Ggo=r(DRe," (XLM-ProphetNet model)"),DRe.forEach(t),Ogo=i(L),Gh=n(L,"LI",{});var GRe=s(Gh);_fe=n(GRe,"STRONG",{});var g0t=s(_fe);Vgo=r(g0t,"xlm-roberta"),g0t.forEach(t),Xgo=r(GRe," \u2014 "),VN=n(GRe,"A",{href:!0});var h0t=s(VN);zgo=r(h0t,"XLMRobertaConfig"),h0t.forEach(t),Qgo=r(GRe," (XLM-RoBERTa model)"),GRe.forEach(t),Wgo=i(L),Oh=n(L,"LI",{});var ORe=s(Oh);vfe=n(ORe,"STRONG",{});var u0t=s(vfe);Ugo=r(u0t,"xlm-roberta-xl"),u0t.forEach(t),Hgo=r(ORe," \u2014 "),XN=n(ORe,"A",{href:!0});var p0t=s(XN);Jgo=r(p0t,"XLMRobertaXLConfig"),p0t.forEach(t),Ygo=r(ORe," (XLM-RoBERTa-XL model)"),ORe.forEach(t),Kgo=i(L),Vh=n(L,"LI",{});var VRe=s(Vh);bfe=n(VRe,"STRONG",{});var _0t=s(bfe);Zgo=r(_0t,"xlnet"),_0t.forEach(t),eho=r(VRe," \u2014 "),zN=n(VRe,"A",{href:!0});var v0t=s(zN);oho=r(v0t,"XLNetConfig"),v0t.forEach(t),rho=r(VRe," (XLNet model)"),VRe.forEach(t),tho=i(L),Xh=n(L,"LI",{});var XRe=s(Xh);Ffe=n(XRe,"STRONG",{});var b0t=s(Ffe);aho=r(b0t,"yolos"),b0t.forEach(t),nho=r(XRe," \u2014 "),QN=n(XRe,"A",{href:!0});var F0t=s(QN);sho=r(F0t,"YolosConfig"),F0t.forEach(t),lho=r(XRe," (YOLOS model)"),XRe.forEach(t),iho=i(L),zh=n(L,"LI",{});var zRe=s(zh);Tfe=n(zRe,"STRONG",{});var T0t=s(Tfe);dho=r(T0t,"yoso"),T0t.forEach(t),cho=r(zRe," \u2014 "),WN=n(zRe,"A",{href:!0});var M0t=s(WN);fho=r(M0t,"YosoConfig"),M0t.forEach(t),mho=r(zRe," (YOSO model)"),zRe.forEach(t),L.forEach(t),gho=i(ut),T(Qh.$$.fragment,ut),ut.forEach(t),hho=i(ht),Wh=n(ht,"DIV",{class:!0});var zZe=s(Wh);T($9.$$.fragment,zZe),uho=i(zZe),Mfe=n(zZe,"P",{});var E0t=s(Mfe);pho=r(E0t,"Register a new configuration for this class."),E0t.forEach(t),zZe.forEach(t),ht.forEach(t),qYe=i(f),md=n(f,"H2",{class:!0});var QZe=s(md);Uh=n(QZe,"A",{id:!0,class:!0,href:!0});var C0t=s(Uh);Efe=n(C0t,"SPAN",{});var w0t=s(Efe);T(k9.$$.fragment,w0t),w0t.forEach(t),C0t.forEach(t),_ho=i(QZe),Cfe=n(QZe,"SPAN",{});var A0t=s(Cfe);vho=r(A0t,"AutoTokenizer"),A0t.forEach(t),QZe.forEach(t),jYe=i(f),ko=n(f,"DIV",{class:!0});var Tl=s(ko);T(S9.$$.fragment,Tl),bho=i(Tl),R9=n(Tl,"P",{});var WZe=s(R9);Fho=r(WZe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),UN=n(WZe,"A",{href:!0});var L0t=s(UN);Tho=r(L0t,"AutoTokenizer.from_pretrained()"),L0t.forEach(t),Mho=r(WZe," class method."),WZe.forEach(t),Eho=i(Tl),P9=n(Tl,"P",{});var UZe=s(P9);Cho=r(UZe,"This class cannot be instantiated directly using "),wfe=n(UZe,"CODE",{});var y0t=s(wfe);who=r(y0t,"__init__()"),y0t.forEach(t),Aho=r(UZe," (throws an error)."),UZe.forEach(t),Lho=i(Tl),Br=n(Tl,"DIV",{class:!0});var Ml=s(Br);T(B9.$$.fragment,Ml),yho=i(Ml),Afe=n(Ml,"P",{});var x0t=s(Afe);xho=r(x0t,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),x0t.forEach(t),$ho=i(Ml),Ua=n(Ml,"P",{});var py=s(Ua);kho=r(py,"The tokenizer class to instantiate is selected based on the "),Lfe=n(py,"CODE",{});var $0t=s(Lfe);Sho=r($0t,"model_type"),$0t.forEach(t),Rho=r(py,` property of the config object (either
passed as an argument or loaded from `),yfe=n(py,"CODE",{});var k0t=s(yfe);Pho=r(k0t,"pretrained_model_name_or_path"),k0t.forEach(t),Bho=r(py,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xfe=n(py,"CODE",{});var S0t=s(xfe);Iho=r(S0t,"pretrained_model_name_or_path"),S0t.forEach(t),Nho=r(py,":"),py.forEach(t),qho=i(Ml),k=n(Ml,"UL",{});var S=s(k);as=n(S,"LI",{});var lP=s(as);$fe=n(lP,"STRONG",{});var R0t=s($fe);jho=r(R0t,"albert"),R0t.forEach(t),Dho=r(lP," \u2014 "),HN=n(lP,"A",{href:!0});var P0t=s(HN);Gho=r(P0t,"AlbertTokenizer"),P0t.forEach(t),Oho=r(lP," or "),JN=n(lP,"A",{href:!0});var B0t=s(JN);Vho=r(B0t,"AlbertTokenizerFast"),B0t.forEach(t),Xho=r(lP," (ALBERT model)"),lP.forEach(t),zho=i(S),ns=n(S,"LI",{});var iP=s(ns);kfe=n(iP,"STRONG",{});var I0t=s(kfe);Qho=r(I0t,"bart"),I0t.forEach(t),Who=r(iP," \u2014 "),YN=n(iP,"A",{href:!0});var N0t=s(YN);Uho=r(N0t,"BartTokenizer"),N0t.forEach(t),Hho=r(iP," or "),KN=n(iP,"A",{href:!0});var q0t=s(KN);Jho=r(q0t,"BartTokenizerFast"),q0t.forEach(t),Yho=r(iP," (BART model)"),iP.forEach(t),Kho=i(S),ss=n(S,"LI",{});var dP=s(ss);Sfe=n(dP,"STRONG",{});var j0t=s(Sfe);Zho=r(j0t,"barthez"),j0t.forEach(t),euo=r(dP," \u2014 "),ZN=n(dP,"A",{href:!0});var D0t=s(ZN);ouo=r(D0t,"BarthezTokenizer"),D0t.forEach(t),ruo=r(dP," or "),eq=n(dP,"A",{href:!0});var G0t=s(eq);tuo=r(G0t,"BarthezTokenizerFast"),G0t.forEach(t),auo=r(dP," (BARThez model)"),dP.forEach(t),nuo=i(S),Hh=n(S,"LI",{});var QRe=s(Hh);Rfe=n(QRe,"STRONG",{});var O0t=s(Rfe);suo=r(O0t,"bartpho"),O0t.forEach(t),luo=r(QRe," \u2014 "),oq=n(QRe,"A",{href:!0});var V0t=s(oq);iuo=r(V0t,"BartphoTokenizer"),V0t.forEach(t),duo=r(QRe," (BARTpho model)"),QRe.forEach(t),cuo=i(S),ls=n(S,"LI",{});var cP=s(ls);Pfe=n(cP,"STRONG",{});var X0t=s(Pfe);fuo=r(X0t,"bert"),X0t.forEach(t),muo=r(cP," \u2014 "),rq=n(cP,"A",{href:!0});var z0t=s(rq);guo=r(z0t,"BertTokenizer"),z0t.forEach(t),huo=r(cP," or "),tq=n(cP,"A",{href:!0});var Q0t=s(tq);uuo=r(Q0t,"BertTokenizerFast"),Q0t.forEach(t),puo=r(cP," (BERT model)"),cP.forEach(t),_uo=i(S),Jh=n(S,"LI",{});var WRe=s(Jh);Bfe=n(WRe,"STRONG",{});var W0t=s(Bfe);vuo=r(W0t,"bert-generation"),W0t.forEach(t),buo=r(WRe," \u2014 "),aq=n(WRe,"A",{href:!0});var U0t=s(aq);Fuo=r(U0t,"BertGenerationTokenizer"),U0t.forEach(t),Tuo=r(WRe," (Bert Generation model)"),WRe.forEach(t),Muo=i(S),Yh=n(S,"LI",{});var URe=s(Yh);Ife=n(URe,"STRONG",{});var H0t=s(Ife);Euo=r(H0t,"bert-japanese"),H0t.forEach(t),Cuo=r(URe," \u2014 "),nq=n(URe,"A",{href:!0});var J0t=s(nq);wuo=r(J0t,"BertJapaneseTokenizer"),J0t.forEach(t),Auo=r(URe," (BertJapanese model)"),URe.forEach(t),Luo=i(S),Kh=n(S,"LI",{});var HRe=s(Kh);Nfe=n(HRe,"STRONG",{});var Y0t=s(Nfe);yuo=r(Y0t,"bertweet"),Y0t.forEach(t),xuo=r(HRe," \u2014 "),sq=n(HRe,"A",{href:!0});var K0t=s(sq);$uo=r(K0t,"BertweetTokenizer"),K0t.forEach(t),kuo=r(HRe," (BERTweet model)"),HRe.forEach(t),Suo=i(S),is=n(S,"LI",{});var fP=s(is);qfe=n(fP,"STRONG",{});var Z0t=s(qfe);Ruo=r(Z0t,"big_bird"),Z0t.forEach(t),Puo=r(fP," \u2014 "),lq=n(fP,"A",{href:!0});var eFt=s(lq);Buo=r(eFt,"BigBirdTokenizer"),eFt.forEach(t),Iuo=r(fP," or "),iq=n(fP,"A",{href:!0});var oFt=s(iq);Nuo=r(oFt,"BigBirdTokenizerFast"),oFt.forEach(t),quo=r(fP," (BigBird model)"),fP.forEach(t),juo=i(S),ds=n(S,"LI",{});var mP=s(ds);jfe=n(mP,"STRONG",{});var rFt=s(jfe);Duo=r(rFt,"bigbird_pegasus"),rFt.forEach(t),Guo=r(mP," \u2014 "),dq=n(mP,"A",{href:!0});var tFt=s(dq);Ouo=r(tFt,"PegasusTokenizer"),tFt.forEach(t),Vuo=r(mP," or "),cq=n(mP,"A",{href:!0});var aFt=s(cq);Xuo=r(aFt,"PegasusTokenizerFast"),aFt.forEach(t),zuo=r(mP," (BigBird-Pegasus model)"),mP.forEach(t),Quo=i(S),cs=n(S,"LI",{});var gP=s(cs);Dfe=n(gP,"STRONG",{});var nFt=s(Dfe);Wuo=r(nFt,"blenderbot"),nFt.forEach(t),Uuo=r(gP," \u2014 "),fq=n(gP,"A",{href:!0});var sFt=s(fq);Huo=r(sFt,"BlenderbotTokenizer"),sFt.forEach(t),Juo=r(gP," or "),mq=n(gP,"A",{href:!0});var lFt=s(mq);Yuo=r(lFt,"BlenderbotTokenizerFast"),lFt.forEach(t),Kuo=r(gP," (Blenderbot model)"),gP.forEach(t),Zuo=i(S),Zh=n(S,"LI",{});var JRe=s(Zh);Gfe=n(JRe,"STRONG",{});var iFt=s(Gfe);epo=r(iFt,"blenderbot-small"),iFt.forEach(t),opo=r(JRe," \u2014 "),gq=n(JRe,"A",{href:!0});var dFt=s(gq);rpo=r(dFt,"BlenderbotSmallTokenizer"),dFt.forEach(t),tpo=r(JRe," (BlenderbotSmall model)"),JRe.forEach(t),apo=i(S),eu=n(S,"LI",{});var YRe=s(eu);Ofe=n(YRe,"STRONG",{});var cFt=s(Ofe);npo=r(cFt,"bloom"),cFt.forEach(t),spo=r(YRe," \u2014 "),hq=n(YRe,"A",{href:!0});var fFt=s(hq);lpo=r(fFt,"BloomTokenizerFast"),fFt.forEach(t),ipo=r(YRe," (BLOOM model)"),YRe.forEach(t),dpo=i(S),ou=n(S,"LI",{});var KRe=s(ou);Vfe=n(KRe,"STRONG",{});var mFt=s(Vfe);cpo=r(mFt,"byt5"),mFt.forEach(t),fpo=r(KRe," \u2014 "),uq=n(KRe,"A",{href:!0});var gFt=s(uq);mpo=r(gFt,"ByT5Tokenizer"),gFt.forEach(t),gpo=r(KRe," (ByT5 model)"),KRe.forEach(t),hpo=i(S),fs=n(S,"LI",{});var hP=s(fs);Xfe=n(hP,"STRONG",{});var hFt=s(Xfe);upo=r(hFt,"camembert"),hFt.forEach(t),ppo=r(hP," \u2014 "),pq=n(hP,"A",{href:!0});var uFt=s(pq);_po=r(uFt,"CamembertTokenizer"),uFt.forEach(t),vpo=r(hP," or "),_q=n(hP,"A",{href:!0});var pFt=s(_q);bpo=r(pFt,"CamembertTokenizerFast"),pFt.forEach(t),Fpo=r(hP," (CamemBERT model)"),hP.forEach(t),Tpo=i(S),ru=n(S,"LI",{});var ZRe=s(ru);zfe=n(ZRe,"STRONG",{});var _Ft=s(zfe);Mpo=r(_Ft,"canine"),_Ft.forEach(t),Epo=r(ZRe," \u2014 "),vq=n(ZRe,"A",{href:!0});var vFt=s(vq);Cpo=r(vFt,"CanineTokenizer"),vFt.forEach(t),wpo=r(ZRe," (CANINE model)"),ZRe.forEach(t),Apo=i(S),ms=n(S,"LI",{});var uP=s(ms);Qfe=n(uP,"STRONG",{});var bFt=s(Qfe);Lpo=r(bFt,"clip"),bFt.forEach(t),ypo=r(uP," \u2014 "),bq=n(uP,"A",{href:!0});var FFt=s(bq);xpo=r(FFt,"CLIPTokenizer"),FFt.forEach(t),$po=r(uP," or "),Fq=n(uP,"A",{href:!0});var TFt=s(Fq);kpo=r(TFt,"CLIPTokenizerFast"),TFt.forEach(t),Spo=r(uP," (CLIP model)"),uP.forEach(t),Rpo=i(S),gs=n(S,"LI",{});var pP=s(gs);Wfe=n(pP,"STRONG",{});var MFt=s(Wfe);Ppo=r(MFt,"codegen"),MFt.forEach(t),Bpo=r(pP," \u2014 "),Tq=n(pP,"A",{href:!0});var EFt=s(Tq);Ipo=r(EFt,"CodeGenTokenizer"),EFt.forEach(t),Npo=r(pP," or "),Mq=n(pP,"A",{href:!0});var CFt=s(Mq);qpo=r(CFt,"CodeGenTokenizerFast"),CFt.forEach(t),jpo=r(pP," (CodeGen model)"),pP.forEach(t),Dpo=i(S),hs=n(S,"LI",{});var _P=s(hs);Ufe=n(_P,"STRONG",{});var wFt=s(Ufe);Gpo=r(wFt,"convbert"),wFt.forEach(t),Opo=r(_P," \u2014 "),Eq=n(_P,"A",{href:!0});var AFt=s(Eq);Vpo=r(AFt,"ConvBertTokenizer"),AFt.forEach(t),Xpo=r(_P," or "),Cq=n(_P,"A",{href:!0});var LFt=s(Cq);zpo=r(LFt,"ConvBertTokenizerFast"),LFt.forEach(t),Qpo=r(_P," (ConvBERT model)"),_P.forEach(t),Wpo=i(S),us=n(S,"LI",{});var vP=s(us);Hfe=n(vP,"STRONG",{});var yFt=s(Hfe);Upo=r(yFt,"cpm"),yFt.forEach(t),Hpo=r(vP," \u2014 "),wq=n(vP,"A",{href:!0});var xFt=s(wq);Jpo=r(xFt,"CpmTokenizer"),xFt.forEach(t),Ypo=r(vP," or "),Aq=n(vP,"A",{href:!0});var $Ft=s(Aq);Kpo=r($Ft,"CpmTokenizerFast"),$Ft.forEach(t),Zpo=r(vP," (CPM model)"),vP.forEach(t),e_o=i(S),tu=n(S,"LI",{});var ePe=s(tu);Jfe=n(ePe,"STRONG",{});var kFt=s(Jfe);o_o=r(kFt,"ctrl"),kFt.forEach(t),r_o=r(ePe," \u2014 "),Lq=n(ePe,"A",{href:!0});var SFt=s(Lq);t_o=r(SFt,"CTRLTokenizer"),SFt.forEach(t),a_o=r(ePe," (CTRL model)"),ePe.forEach(t),n_o=i(S),ps=n(S,"LI",{});var bP=s(ps);Yfe=n(bP,"STRONG",{});var RFt=s(Yfe);s_o=r(RFt,"data2vec-text"),RFt.forEach(t),l_o=r(bP," \u2014 "),yq=n(bP,"A",{href:!0});var PFt=s(yq);i_o=r(PFt,"RobertaTokenizer"),PFt.forEach(t),d_o=r(bP," or "),xq=n(bP,"A",{href:!0});var BFt=s(xq);c_o=r(BFt,"RobertaTokenizerFast"),BFt.forEach(t),f_o=r(bP," (Data2VecText model)"),bP.forEach(t),m_o=i(S),_s=n(S,"LI",{});var FP=s(_s);Kfe=n(FP,"STRONG",{});var IFt=s(Kfe);g_o=r(IFt,"deberta"),IFt.forEach(t),h_o=r(FP," \u2014 "),$q=n(FP,"A",{href:!0});var NFt=s($q);u_o=r(NFt,"DebertaTokenizer"),NFt.forEach(t),p_o=r(FP," or "),kq=n(FP,"A",{href:!0});var qFt=s(kq);__o=r(qFt,"DebertaTokenizerFast"),qFt.forEach(t),v_o=r(FP," (DeBERTa model)"),FP.forEach(t),b_o=i(S),vs=n(S,"LI",{});var TP=s(vs);Zfe=n(TP,"STRONG",{});var jFt=s(Zfe);F_o=r(jFt,"deberta-v2"),jFt.forEach(t),T_o=r(TP," \u2014 "),Sq=n(TP,"A",{href:!0});var DFt=s(Sq);M_o=r(DFt,"DebertaV2Tokenizer"),DFt.forEach(t),E_o=r(TP," or "),Rq=n(TP,"A",{href:!0});var GFt=s(Rq);C_o=r(GFt,"DebertaV2TokenizerFast"),GFt.forEach(t),w_o=r(TP," (DeBERTa-v2 model)"),TP.forEach(t),A_o=i(S),bs=n(S,"LI",{});var MP=s(bs);eme=n(MP,"STRONG",{});var OFt=s(eme);L_o=r(OFt,"distilbert"),OFt.forEach(t),y_o=r(MP," \u2014 "),Pq=n(MP,"A",{href:!0});var VFt=s(Pq);x_o=r(VFt,"DistilBertTokenizer"),VFt.forEach(t),$_o=r(MP," or "),Bq=n(MP,"A",{href:!0});var XFt=s(Bq);k_o=r(XFt,"DistilBertTokenizerFast"),XFt.forEach(t),S_o=r(MP," (DistilBERT model)"),MP.forEach(t),R_o=i(S),Fs=n(S,"LI",{});var EP=s(Fs);ome=n(EP,"STRONG",{});var zFt=s(ome);P_o=r(zFt,"dpr"),zFt.forEach(t),B_o=r(EP," \u2014 "),Iq=n(EP,"A",{href:!0});var QFt=s(Iq);I_o=r(QFt,"DPRQuestionEncoderTokenizer"),QFt.forEach(t),N_o=r(EP," or "),Nq=n(EP,"A",{href:!0});var WFt=s(Nq);q_o=r(WFt,"DPRQuestionEncoderTokenizerFast"),WFt.forEach(t),j_o=r(EP," (DPR model)"),EP.forEach(t),D_o=i(S),Ts=n(S,"LI",{});var CP=s(Ts);rme=n(CP,"STRONG",{});var UFt=s(rme);G_o=r(UFt,"electra"),UFt.forEach(t),O_o=r(CP," \u2014 "),qq=n(CP,"A",{href:!0});var HFt=s(qq);V_o=r(HFt,"ElectraTokenizer"),HFt.forEach(t),X_o=r(CP," or "),jq=n(CP,"A",{href:!0});var JFt=s(jq);z_o=r(JFt,"ElectraTokenizerFast"),JFt.forEach(t),Q_o=r(CP," (ELECTRA model)"),CP.forEach(t),W_o=i(S),Ms=n(S,"LI",{});var wP=s(Ms);tme=n(wP,"STRONG",{});var YFt=s(tme);U_o=r(YFt,"ernie"),YFt.forEach(t),H_o=r(wP," \u2014 "),Dq=n(wP,"A",{href:!0});var KFt=s(Dq);J_o=r(KFt,"BertTokenizer"),KFt.forEach(t),Y_o=r(wP," or "),Gq=n(wP,"A",{href:!0});var ZFt=s(Gq);K_o=r(ZFt,"BertTokenizerFast"),ZFt.forEach(t),Z_o=r(wP," (ERNIE model)"),wP.forEach(t),e2o=i(S),au=n(S,"LI",{});var oPe=s(au);ame=n(oPe,"STRONG",{});var eTt=s(ame);o2o=r(eTt,"flaubert"),eTt.forEach(t),r2o=r(oPe," \u2014 "),Oq=n(oPe,"A",{href:!0});var oTt=s(Oq);t2o=r(oTt,"FlaubertTokenizer"),oTt.forEach(t),a2o=r(oPe," (FlauBERT model)"),oPe.forEach(t),n2o=i(S),Es=n(S,"LI",{});var AP=s(Es);nme=n(AP,"STRONG",{});var rTt=s(nme);s2o=r(rTt,"fnet"),rTt.forEach(t),l2o=r(AP," \u2014 "),Vq=n(AP,"A",{href:!0});var tTt=s(Vq);i2o=r(tTt,"FNetTokenizer"),tTt.forEach(t),d2o=r(AP," or "),Xq=n(AP,"A",{href:!0});var aTt=s(Xq);c2o=r(aTt,"FNetTokenizerFast"),aTt.forEach(t),f2o=r(AP," (FNet model)"),AP.forEach(t),m2o=i(S),nu=n(S,"LI",{});var rPe=s(nu);sme=n(rPe,"STRONG",{});var nTt=s(sme);g2o=r(nTt,"fsmt"),nTt.forEach(t),h2o=r(rPe," \u2014 "),zq=n(rPe,"A",{href:!0});var sTt=s(zq);u2o=r(sTt,"FSMTTokenizer"),sTt.forEach(t),p2o=r(rPe," (FairSeq Machine-Translation model)"),rPe.forEach(t),_2o=i(S),Cs=n(S,"LI",{});var LP=s(Cs);lme=n(LP,"STRONG",{});var lTt=s(lme);v2o=r(lTt,"funnel"),lTt.forEach(t),b2o=r(LP," \u2014 "),Qq=n(LP,"A",{href:!0});var iTt=s(Qq);F2o=r(iTt,"FunnelTokenizer"),iTt.forEach(t),T2o=r(LP," or "),Wq=n(LP,"A",{href:!0});var dTt=s(Wq);M2o=r(dTt,"FunnelTokenizerFast"),dTt.forEach(t),E2o=r(LP," (Funnel Transformer model)"),LP.forEach(t),C2o=i(S),ws=n(S,"LI",{});var yP=s(ws);ime=n(yP,"STRONG",{});var cTt=s(ime);w2o=r(cTt,"gpt2"),cTt.forEach(t),A2o=r(yP," \u2014 "),Uq=n(yP,"A",{href:!0});var fTt=s(Uq);L2o=r(fTt,"GPT2Tokenizer"),fTt.forEach(t),y2o=r(yP," or "),Hq=n(yP,"A",{href:!0});var mTt=s(Hq);x2o=r(mTt,"GPT2TokenizerFast"),mTt.forEach(t),$2o=r(yP," (OpenAI GPT-2 model)"),yP.forEach(t),k2o=i(S),As=n(S,"LI",{});var xP=s(As);dme=n(xP,"STRONG",{});var gTt=s(dme);S2o=r(gTt,"gpt_neo"),gTt.forEach(t),R2o=r(xP," \u2014 "),Jq=n(xP,"A",{href:!0});var hTt=s(Jq);P2o=r(hTt,"GPT2Tokenizer"),hTt.forEach(t),B2o=r(xP," or "),Yq=n(xP,"A",{href:!0});var uTt=s(Yq);I2o=r(uTt,"GPT2TokenizerFast"),uTt.forEach(t),N2o=r(xP," (GPT Neo model)"),xP.forEach(t),q2o=i(S),su=n(S,"LI",{});var tPe=s(su);cme=n(tPe,"STRONG",{});var pTt=s(cme);j2o=r(pTt,"gpt_neox"),pTt.forEach(t),D2o=r(tPe," \u2014 "),Kq=n(tPe,"A",{href:!0});var _Tt=s(Kq);G2o=r(_Tt,"GPTNeoXTokenizerFast"),_Tt.forEach(t),O2o=r(tPe," (GPT NeoX model)"),tPe.forEach(t),V2o=i(S),Ls=n(S,"LI",{});var $P=s(Ls);fme=n($P,"STRONG",{});var vTt=s(fme);X2o=r(vTt,"gptj"),vTt.forEach(t),z2o=r($P," \u2014 "),Zq=n($P,"A",{href:!0});var bTt=s(Zq);Q2o=r(bTt,"GPT2Tokenizer"),bTt.forEach(t),W2o=r($P," or "),ej=n($P,"A",{href:!0});var FTt=s(ej);U2o=r(FTt,"GPT2TokenizerFast"),FTt.forEach(t),H2o=r($P," (GPT-J model)"),$P.forEach(t),J2o=i(S),ys=n(S,"LI",{});var kP=s(ys);mme=n(kP,"STRONG",{});var TTt=s(mme);Y2o=r(TTt,"groupvit"),TTt.forEach(t),K2o=r(kP," \u2014 "),oj=n(kP,"A",{href:!0});var MTt=s(oj);Z2o=r(MTt,"CLIPTokenizer"),MTt.forEach(t),evo=r(kP," or "),rj=n(kP,"A",{href:!0});var ETt=s(rj);ovo=r(ETt,"CLIPTokenizerFast"),ETt.forEach(t),rvo=r(kP," (GroupViT model)"),kP.forEach(t),tvo=i(S),xs=n(S,"LI",{});var SP=s(xs);gme=n(SP,"STRONG",{});var CTt=s(gme);avo=r(CTt,"herbert"),CTt.forEach(t),nvo=r(SP," \u2014 "),tj=n(SP,"A",{href:!0});var wTt=s(tj);svo=r(wTt,"HerbertTokenizer"),wTt.forEach(t),lvo=r(SP," or "),aj=n(SP,"A",{href:!0});var ATt=s(aj);ivo=r(ATt,"HerbertTokenizerFast"),ATt.forEach(t),dvo=r(SP," (HerBERT model)"),SP.forEach(t),cvo=i(S),lu=n(S,"LI",{});var aPe=s(lu);hme=n(aPe,"STRONG",{});var LTt=s(hme);fvo=r(LTt,"hubert"),LTt.forEach(t),mvo=r(aPe," \u2014 "),nj=n(aPe,"A",{href:!0});var yTt=s(nj);gvo=r(yTt,"Wav2Vec2CTCTokenizer"),yTt.forEach(t),hvo=r(aPe," (Hubert model)"),aPe.forEach(t),uvo=i(S),$s=n(S,"LI",{});var RP=s($s);ume=n(RP,"STRONG",{});var xTt=s(ume);pvo=r(xTt,"ibert"),xTt.forEach(t),_vo=r(RP," \u2014 "),sj=n(RP,"A",{href:!0});var $Tt=s(sj);vvo=r($Tt,"RobertaTokenizer"),$Tt.forEach(t),bvo=r(RP," or "),lj=n(RP,"A",{href:!0});var kTt=s(lj);Fvo=r(kTt,"RobertaTokenizerFast"),kTt.forEach(t),Tvo=r(RP," (I-BERT model)"),RP.forEach(t),Mvo=i(S),ks=n(S,"LI",{});var PP=s(ks);pme=n(PP,"STRONG",{});var STt=s(pme);Evo=r(STt,"layoutlm"),STt.forEach(t),Cvo=r(PP," \u2014 "),ij=n(PP,"A",{href:!0});var RTt=s(ij);wvo=r(RTt,"LayoutLMTokenizer"),RTt.forEach(t),Avo=r(PP," or "),dj=n(PP,"A",{href:!0});var PTt=s(dj);Lvo=r(PTt,"LayoutLMTokenizerFast"),PTt.forEach(t),yvo=r(PP," (LayoutLM model)"),PP.forEach(t),xvo=i(S),Ss=n(S,"LI",{});var BP=s(Ss);_me=n(BP,"STRONG",{});var BTt=s(_me);$vo=r(BTt,"layoutlmv2"),BTt.forEach(t),kvo=r(BP," \u2014 "),cj=n(BP,"A",{href:!0});var ITt=s(cj);Svo=r(ITt,"LayoutLMv2Tokenizer"),ITt.forEach(t),Rvo=r(BP," or "),fj=n(BP,"A",{href:!0});var NTt=s(fj);Pvo=r(NTt,"LayoutLMv2TokenizerFast"),NTt.forEach(t),Bvo=r(BP," (LayoutLMv2 model)"),BP.forEach(t),Ivo=i(S),Rs=n(S,"LI",{});var IP=s(Rs);vme=n(IP,"STRONG",{});var qTt=s(vme);Nvo=r(qTt,"layoutlmv3"),qTt.forEach(t),qvo=r(IP," \u2014 "),mj=n(IP,"A",{href:!0});var jTt=s(mj);jvo=r(jTt,"LayoutLMv3Tokenizer"),jTt.forEach(t),Dvo=r(IP," or "),gj=n(IP,"A",{href:!0});var DTt=s(gj);Gvo=r(DTt,"LayoutLMv3TokenizerFast"),DTt.forEach(t),Ovo=r(IP," (LayoutLMv3 model)"),IP.forEach(t),Vvo=i(S),Ps=n(S,"LI",{});var NP=s(Ps);bme=n(NP,"STRONG",{});var GTt=s(bme);Xvo=r(GTt,"layoutxlm"),GTt.forEach(t),zvo=r(NP," \u2014 "),hj=n(NP,"A",{href:!0});var OTt=s(hj);Qvo=r(OTt,"LayoutXLMTokenizer"),OTt.forEach(t),Wvo=r(NP," or "),uj=n(NP,"A",{href:!0});var VTt=s(uj);Uvo=r(VTt,"LayoutXLMTokenizerFast"),VTt.forEach(t),Hvo=r(NP," (LayoutXLM model)"),NP.forEach(t),Jvo=i(S),Bs=n(S,"LI",{});var qP=s(Bs);Fme=n(qP,"STRONG",{});var XTt=s(Fme);Yvo=r(XTt,"led"),XTt.forEach(t),Kvo=r(qP," \u2014 "),pj=n(qP,"A",{href:!0});var zTt=s(pj);Zvo=r(zTt,"LEDTokenizer"),zTt.forEach(t),e4o=r(qP," or "),_j=n(qP,"A",{href:!0});var QTt=s(_j);o4o=r(QTt,"LEDTokenizerFast"),QTt.forEach(t),r4o=r(qP," (LED model)"),qP.forEach(t),t4o=i(S),Is=n(S,"LI",{});var jP=s(Is);Tme=n(jP,"STRONG",{});var WTt=s(Tme);a4o=r(WTt,"longformer"),WTt.forEach(t),n4o=r(jP," \u2014 "),vj=n(jP,"A",{href:!0});var UTt=s(vj);s4o=r(UTt,"LongformerTokenizer"),UTt.forEach(t),l4o=r(jP," or "),bj=n(jP,"A",{href:!0});var HTt=s(bj);i4o=r(HTt,"LongformerTokenizerFast"),HTt.forEach(t),d4o=r(jP," (Longformer model)"),jP.forEach(t),c4o=i(S),Ns=n(S,"LI",{});var DP=s(Ns);Mme=n(DP,"STRONG",{});var JTt=s(Mme);f4o=r(JTt,"longt5"),JTt.forEach(t),m4o=r(DP," \u2014 "),Fj=n(DP,"A",{href:!0});var YTt=s(Fj);g4o=r(YTt,"T5Tokenizer"),YTt.forEach(t),h4o=r(DP," or "),Tj=n(DP,"A",{href:!0});var KTt=s(Tj);u4o=r(KTt,"T5TokenizerFast"),KTt.forEach(t),p4o=r(DP," (LongT5 model)"),DP.forEach(t),_4o=i(S),iu=n(S,"LI",{});var nPe=s(iu);Eme=n(nPe,"STRONG",{});var ZTt=s(Eme);v4o=r(ZTt,"luke"),ZTt.forEach(t),b4o=r(nPe," \u2014 "),Mj=n(nPe,"A",{href:!0});var eMt=s(Mj);F4o=r(eMt,"LukeTokenizer"),eMt.forEach(t),T4o=r(nPe," (LUKE model)"),nPe.forEach(t),M4o=i(S),qs=n(S,"LI",{});var GP=s(qs);Cme=n(GP,"STRONG",{});var oMt=s(Cme);E4o=r(oMt,"lxmert"),oMt.forEach(t),C4o=r(GP," \u2014 "),Ej=n(GP,"A",{href:!0});var rMt=s(Ej);w4o=r(rMt,"LxmertTokenizer"),rMt.forEach(t),A4o=r(GP," or "),Cj=n(GP,"A",{href:!0});var tMt=s(Cj);L4o=r(tMt,"LxmertTokenizerFast"),tMt.forEach(t),y4o=r(GP," (LXMERT model)"),GP.forEach(t),x4o=i(S),du=n(S,"LI",{});var sPe=s(du);wme=n(sPe,"STRONG",{});var aMt=s(wme);$4o=r(aMt,"m2m_100"),aMt.forEach(t),k4o=r(sPe," \u2014 "),wj=n(sPe,"A",{href:!0});var nMt=s(wj);S4o=r(nMt,"M2M100Tokenizer"),nMt.forEach(t),R4o=r(sPe," (M2M100 model)"),sPe.forEach(t),P4o=i(S),cu=n(S,"LI",{});var lPe=s(cu);Ame=n(lPe,"STRONG",{});var sMt=s(Ame);B4o=r(sMt,"marian"),sMt.forEach(t),I4o=r(lPe," \u2014 "),Aj=n(lPe,"A",{href:!0});var lMt=s(Aj);N4o=r(lMt,"MarianTokenizer"),lMt.forEach(t),q4o=r(lPe," (Marian model)"),lPe.forEach(t),j4o=i(S),js=n(S,"LI",{});var OP=s(js);Lme=n(OP,"STRONG",{});var iMt=s(Lme);D4o=r(iMt,"mbart"),iMt.forEach(t),G4o=r(OP," \u2014 "),Lj=n(OP,"A",{href:!0});var dMt=s(Lj);O4o=r(dMt,"MBartTokenizer"),dMt.forEach(t),V4o=r(OP," or "),yj=n(OP,"A",{href:!0});var cMt=s(yj);X4o=r(cMt,"MBartTokenizerFast"),cMt.forEach(t),z4o=r(OP," (mBART model)"),OP.forEach(t),Q4o=i(S),Ds=n(S,"LI",{});var VP=s(Ds);yme=n(VP,"STRONG",{});var fMt=s(yme);W4o=r(fMt,"mbart50"),fMt.forEach(t),U4o=r(VP," \u2014 "),xj=n(VP,"A",{href:!0});var mMt=s(xj);H4o=r(mMt,"MBart50Tokenizer"),mMt.forEach(t),J4o=r(VP," or "),$j=n(VP,"A",{href:!0});var gMt=s($j);Y4o=r(gMt,"MBart50TokenizerFast"),gMt.forEach(t),K4o=r(VP," (mBART-50 model)"),VP.forEach(t),Z4o=i(S),Gs=n(S,"LI",{});var XP=s(Gs);xme=n(XP,"STRONG",{});var hMt=s(xme);ebo=r(hMt,"megatron-bert"),hMt.forEach(t),obo=r(XP," \u2014 "),kj=n(XP,"A",{href:!0});var uMt=s(kj);rbo=r(uMt,"BertTokenizer"),uMt.forEach(t),tbo=r(XP," or "),Sj=n(XP,"A",{href:!0});var pMt=s(Sj);abo=r(pMt,"BertTokenizerFast"),pMt.forEach(t),nbo=r(XP," (Megatron-BERT model)"),XP.forEach(t),sbo=i(S),fu=n(S,"LI",{});var iPe=s(fu);$me=n(iPe,"STRONG",{});var _Mt=s($me);lbo=r(_Mt,"mluke"),_Mt.forEach(t),ibo=r(iPe," \u2014 "),Rj=n(iPe,"A",{href:!0});var vMt=s(Rj);dbo=r(vMt,"MLukeTokenizer"),vMt.forEach(t),cbo=r(iPe," (mLUKE model)"),iPe.forEach(t),fbo=i(S),Os=n(S,"LI",{});var zP=s(Os);kme=n(zP,"STRONG",{});var bMt=s(kme);mbo=r(bMt,"mobilebert"),bMt.forEach(t),gbo=r(zP," \u2014 "),Pj=n(zP,"A",{href:!0});var FMt=s(Pj);hbo=r(FMt,"MobileBertTokenizer"),FMt.forEach(t),ubo=r(zP," or "),Bj=n(zP,"A",{href:!0});var TMt=s(Bj);pbo=r(TMt,"MobileBertTokenizerFast"),TMt.forEach(t),_bo=r(zP," (MobileBERT model)"),zP.forEach(t),vbo=i(S),Vs=n(S,"LI",{});var QP=s(Vs);Sme=n(QP,"STRONG",{});var MMt=s(Sme);bbo=r(MMt,"mpnet"),MMt.forEach(t),Fbo=r(QP," \u2014 "),Ij=n(QP,"A",{href:!0});var EMt=s(Ij);Tbo=r(EMt,"MPNetTokenizer"),EMt.forEach(t),Mbo=r(QP," or "),Nj=n(QP,"A",{href:!0});var CMt=s(Nj);Ebo=r(CMt,"MPNetTokenizerFast"),CMt.forEach(t),Cbo=r(QP," (MPNet model)"),QP.forEach(t),wbo=i(S),Xs=n(S,"LI",{});var WP=s(Xs);Rme=n(WP,"STRONG",{});var wMt=s(Rme);Abo=r(wMt,"mt5"),wMt.forEach(t),Lbo=r(WP," \u2014 "),qj=n(WP,"A",{href:!0});var AMt=s(qj);ybo=r(AMt,"MT5Tokenizer"),AMt.forEach(t),xbo=r(WP," or "),jj=n(WP,"A",{href:!0});var LMt=s(jj);$bo=r(LMt,"MT5TokenizerFast"),LMt.forEach(t),kbo=r(WP," (MT5 model)"),WP.forEach(t),Sbo=i(S),zs=n(S,"LI",{});var UP=s(zs);Pme=n(UP,"STRONG",{});var yMt=s(Pme);Rbo=r(yMt,"mvp"),yMt.forEach(t),Pbo=r(UP," \u2014 "),Dj=n(UP,"A",{href:!0});var xMt=s(Dj);Bbo=r(xMt,"MvpTokenizer"),xMt.forEach(t),Ibo=r(UP," or "),Gj=n(UP,"A",{href:!0});var $Mt=s(Gj);Nbo=r($Mt,"MvpTokenizerFast"),$Mt.forEach(t),qbo=r(UP," (MVP model)"),UP.forEach(t),jbo=i(S),Qs=n(S,"LI",{});var HP=s(Qs);Bme=n(HP,"STRONG",{});var kMt=s(Bme);Dbo=r(kMt,"nezha"),kMt.forEach(t),Gbo=r(HP," \u2014 "),Oj=n(HP,"A",{href:!0});var SMt=s(Oj);Obo=r(SMt,"BertTokenizer"),SMt.forEach(t),Vbo=r(HP," or "),Vj=n(HP,"A",{href:!0});var RMt=s(Vj);Xbo=r(RMt,"BertTokenizerFast"),RMt.forEach(t),zbo=r(HP," (Nezha model)"),HP.forEach(t),Qbo=i(S),Ws=n(S,"LI",{});var JP=s(Ws);Ime=n(JP,"STRONG",{});var PMt=s(Ime);Wbo=r(PMt,"nllb"),PMt.forEach(t),Ubo=r(JP," \u2014 "),Xj=n(JP,"A",{href:!0});var BMt=s(Xj);Hbo=r(BMt,"NllbTokenizer"),BMt.forEach(t),Jbo=r(JP," or "),zj=n(JP,"A",{href:!0});var IMt=s(zj);Ybo=r(IMt,"NllbTokenizerFast"),IMt.forEach(t),Kbo=r(JP," (NLLB model)"),JP.forEach(t),Zbo=i(S),Us=n(S,"LI",{});var YP=s(Us);Nme=n(YP,"STRONG",{});var NMt=s(Nme);e1o=r(NMt,"nystromformer"),NMt.forEach(t),o1o=r(YP," \u2014 "),Qj=n(YP,"A",{href:!0});var qMt=s(Qj);r1o=r(qMt,"AlbertTokenizer"),qMt.forEach(t),t1o=r(YP," or "),Wj=n(YP,"A",{href:!0});var jMt=s(Wj);a1o=r(jMt,"AlbertTokenizerFast"),jMt.forEach(t),n1o=r(YP," (Nystr\xF6mformer model)"),YP.forEach(t),s1o=i(S),Hs=n(S,"LI",{});var KP=s(Hs);qme=n(KP,"STRONG",{});var DMt=s(qme);l1o=r(DMt,"openai-gpt"),DMt.forEach(t),i1o=r(KP," \u2014 "),Uj=n(KP,"A",{href:!0});var GMt=s(Uj);d1o=r(GMt,"OpenAIGPTTokenizer"),GMt.forEach(t),c1o=r(KP," or "),Hj=n(KP,"A",{href:!0});var OMt=s(Hj);f1o=r(OMt,"OpenAIGPTTokenizerFast"),OMt.forEach(t),m1o=r(KP," (OpenAI GPT model)"),KP.forEach(t),g1o=i(S),mu=n(S,"LI",{});var dPe=s(mu);jme=n(dPe,"STRONG",{});var VMt=s(jme);h1o=r(VMt,"opt"),VMt.forEach(t),u1o=r(dPe," \u2014 "),Jj=n(dPe,"A",{href:!0});var XMt=s(Jj);p1o=r(XMt,"GPT2Tokenizer"),XMt.forEach(t),_1o=r(dPe," (OPT model)"),dPe.forEach(t),v1o=i(S),Js=n(S,"LI",{});var ZP=s(Js);Dme=n(ZP,"STRONG",{});var zMt=s(Dme);b1o=r(zMt,"owlvit"),zMt.forEach(t),F1o=r(ZP," \u2014 "),Yj=n(ZP,"A",{href:!0});var QMt=s(Yj);T1o=r(QMt,"CLIPTokenizer"),QMt.forEach(t),M1o=r(ZP," or "),Kj=n(ZP,"A",{href:!0});var WMt=s(Kj);E1o=r(WMt,"CLIPTokenizerFast"),WMt.forEach(t),C1o=r(ZP," (OWL-ViT model)"),ZP.forEach(t),w1o=i(S),Ys=n(S,"LI",{});var eB=s(Ys);Gme=n(eB,"STRONG",{});var UMt=s(Gme);A1o=r(UMt,"pegasus"),UMt.forEach(t),L1o=r(eB," \u2014 "),Zj=n(eB,"A",{href:!0});var HMt=s(Zj);y1o=r(HMt,"PegasusTokenizer"),HMt.forEach(t),x1o=r(eB," or "),eD=n(eB,"A",{href:!0});var JMt=s(eD);$1o=r(JMt,"PegasusTokenizerFast"),JMt.forEach(t),k1o=r(eB," (Pegasus model)"),eB.forEach(t),S1o=i(S),gu=n(S,"LI",{});var cPe=s(gu);Ome=n(cPe,"STRONG",{});var YMt=s(Ome);R1o=r(YMt,"perceiver"),YMt.forEach(t),P1o=r(cPe," \u2014 "),oD=n(cPe,"A",{href:!0});var KMt=s(oD);B1o=r(KMt,"PerceiverTokenizer"),KMt.forEach(t),I1o=r(cPe," (Perceiver model)"),cPe.forEach(t),N1o=i(S),hu=n(S,"LI",{});var fPe=s(hu);Vme=n(fPe,"STRONG",{});var ZMt=s(Vme);q1o=r(ZMt,"phobert"),ZMt.forEach(t),j1o=r(fPe," \u2014 "),rD=n(fPe,"A",{href:!0});var eEt=s(rD);D1o=r(eEt,"PhobertTokenizer"),eEt.forEach(t),G1o=r(fPe," (PhoBERT model)"),fPe.forEach(t),O1o=i(S),uu=n(S,"LI",{});var mPe=s(uu);Xme=n(mPe,"STRONG",{});var oEt=s(Xme);V1o=r(oEt,"plbart"),oEt.forEach(t),X1o=r(mPe," \u2014 "),tD=n(mPe,"A",{href:!0});var rEt=s(tD);z1o=r(rEt,"PLBartTokenizer"),rEt.forEach(t),Q1o=r(mPe," (PLBart model)"),mPe.forEach(t),W1o=i(S),pu=n(S,"LI",{});var gPe=s(pu);zme=n(gPe,"STRONG",{});var tEt=s(zme);U1o=r(tEt,"prophetnet"),tEt.forEach(t),H1o=r(gPe," \u2014 "),aD=n(gPe,"A",{href:!0});var aEt=s(aD);J1o=r(aEt,"ProphetNetTokenizer"),aEt.forEach(t),Y1o=r(gPe," (ProphetNet model)"),gPe.forEach(t),K1o=i(S),Ks=n(S,"LI",{});var oB=s(Ks);Qme=n(oB,"STRONG",{});var nEt=s(Qme);Z1o=r(nEt,"qdqbert"),nEt.forEach(t),e0o=r(oB," \u2014 "),nD=n(oB,"A",{href:!0});var sEt=s(nD);o0o=r(sEt,"BertTokenizer"),sEt.forEach(t),r0o=r(oB," or "),sD=n(oB,"A",{href:!0});var lEt=s(sD);t0o=r(lEt,"BertTokenizerFast"),lEt.forEach(t),a0o=r(oB," (QDQBert model)"),oB.forEach(t),n0o=i(S),_u=n(S,"LI",{});var hPe=s(_u);Wme=n(hPe,"STRONG",{});var iEt=s(Wme);s0o=r(iEt,"rag"),iEt.forEach(t),l0o=r(hPe," \u2014 "),lD=n(hPe,"A",{href:!0});var dEt=s(lD);i0o=r(dEt,"RagTokenizer"),dEt.forEach(t),d0o=r(hPe," (RAG model)"),hPe.forEach(t),c0o=i(S),Zs=n(S,"LI",{});var rB=s(Zs);Ume=n(rB,"STRONG",{});var cEt=s(Ume);f0o=r(cEt,"realm"),cEt.forEach(t),m0o=r(rB," \u2014 "),iD=n(rB,"A",{href:!0});var fEt=s(iD);g0o=r(fEt,"RealmTokenizer"),fEt.forEach(t),h0o=r(rB," or "),dD=n(rB,"A",{href:!0});var mEt=s(dD);u0o=r(mEt,"RealmTokenizerFast"),mEt.forEach(t),p0o=r(rB," (REALM model)"),rB.forEach(t),_0o=i(S),el=n(S,"LI",{});var tB=s(el);Hme=n(tB,"STRONG",{});var gEt=s(Hme);v0o=r(gEt,"reformer"),gEt.forEach(t),b0o=r(tB," \u2014 "),cD=n(tB,"A",{href:!0});var hEt=s(cD);F0o=r(hEt,"ReformerTokenizer"),hEt.forEach(t),T0o=r(tB," or "),fD=n(tB,"A",{href:!0});var uEt=s(fD);M0o=r(uEt,"ReformerTokenizerFast"),uEt.forEach(t),E0o=r(tB," (Reformer model)"),tB.forEach(t),C0o=i(S),ol=n(S,"LI",{});var aB=s(ol);Jme=n(aB,"STRONG",{});var pEt=s(Jme);w0o=r(pEt,"rembert"),pEt.forEach(t),A0o=r(aB," \u2014 "),mD=n(aB,"A",{href:!0});var _Et=s(mD);L0o=r(_Et,"RemBertTokenizer"),_Et.forEach(t),y0o=r(aB," or "),gD=n(aB,"A",{href:!0});var vEt=s(gD);x0o=r(vEt,"RemBertTokenizerFast"),vEt.forEach(t),$0o=r(aB," (RemBERT model)"),aB.forEach(t),k0o=i(S),rl=n(S,"LI",{});var nB=s(rl);Yme=n(nB,"STRONG",{});var bEt=s(Yme);S0o=r(bEt,"retribert"),bEt.forEach(t),R0o=r(nB," \u2014 "),hD=n(nB,"A",{href:!0});var FEt=s(hD);P0o=r(FEt,"RetriBertTokenizer"),FEt.forEach(t),B0o=r(nB," or "),uD=n(nB,"A",{href:!0});var TEt=s(uD);I0o=r(TEt,"RetriBertTokenizerFast"),TEt.forEach(t),N0o=r(nB," (RetriBERT model)"),nB.forEach(t),q0o=i(S),tl=n(S,"LI",{});var sB=s(tl);Kme=n(sB,"STRONG",{});var MEt=s(Kme);j0o=r(MEt,"roberta"),MEt.forEach(t),D0o=r(sB," \u2014 "),pD=n(sB,"A",{href:!0});var EEt=s(pD);G0o=r(EEt,"RobertaTokenizer"),EEt.forEach(t),O0o=r(sB," or "),_D=n(sB,"A",{href:!0});var CEt=s(_D);V0o=r(CEt,"RobertaTokenizerFast"),CEt.forEach(t),X0o=r(sB," (RoBERTa model)"),sB.forEach(t),z0o=i(S),al=n(S,"LI",{});var lB=s(al);Zme=n(lB,"STRONG",{});var wEt=s(Zme);Q0o=r(wEt,"roformer"),wEt.forEach(t),W0o=r(lB," \u2014 "),vD=n(lB,"A",{href:!0});var AEt=s(vD);U0o=r(AEt,"RoFormerTokenizer"),AEt.forEach(t),H0o=r(lB," or "),bD=n(lB,"A",{href:!0});var LEt=s(bD);J0o=r(LEt,"RoFormerTokenizerFast"),LEt.forEach(t),Y0o=r(lB," (RoFormer model)"),lB.forEach(t),K0o=i(S),vu=n(S,"LI",{});var uPe=s(vu);ege=n(uPe,"STRONG",{});var yEt=s(ege);Z0o=r(yEt,"speech_to_text"),yEt.forEach(t),eFo=r(uPe," \u2014 "),FD=n(uPe,"A",{href:!0});var xEt=s(FD);oFo=r(xEt,"Speech2TextTokenizer"),xEt.forEach(t),rFo=r(uPe," (Speech2Text model)"),uPe.forEach(t),tFo=i(S),bu=n(S,"LI",{});var pPe=s(bu);oge=n(pPe,"STRONG",{});var $Et=s(oge);aFo=r($Et,"speech_to_text_2"),$Et.forEach(t),nFo=r(pPe," \u2014 "),TD=n(pPe,"A",{href:!0});var kEt=s(TD);sFo=r(kEt,"Speech2Text2Tokenizer"),kEt.forEach(t),lFo=r(pPe," (Speech2Text2 model)"),pPe.forEach(t),iFo=i(S),nl=n(S,"LI",{});var iB=s(nl);rge=n(iB,"STRONG",{});var SEt=s(rge);dFo=r(SEt,"splinter"),SEt.forEach(t),cFo=r(iB," \u2014 "),MD=n(iB,"A",{href:!0});var REt=s(MD);fFo=r(REt,"SplinterTokenizer"),REt.forEach(t),mFo=r(iB," or "),ED=n(iB,"A",{href:!0});var PEt=s(ED);gFo=r(PEt,"SplinterTokenizerFast"),PEt.forEach(t),hFo=r(iB," (Splinter model)"),iB.forEach(t),uFo=i(S),sl=n(S,"LI",{});var dB=s(sl);tge=n(dB,"STRONG",{});var BEt=s(tge);pFo=r(BEt,"squeezebert"),BEt.forEach(t),_Fo=r(dB," \u2014 "),CD=n(dB,"A",{href:!0});var IEt=s(CD);vFo=r(IEt,"SqueezeBertTokenizer"),IEt.forEach(t),bFo=r(dB," or "),wD=n(dB,"A",{href:!0});var NEt=s(wD);FFo=r(NEt,"SqueezeBertTokenizerFast"),NEt.forEach(t),TFo=r(dB," (SqueezeBERT model)"),dB.forEach(t),MFo=i(S),ll=n(S,"LI",{});var cB=s(ll);age=n(cB,"STRONG",{});var qEt=s(age);EFo=r(qEt,"t5"),qEt.forEach(t),CFo=r(cB," \u2014 "),AD=n(cB,"A",{href:!0});var jEt=s(AD);wFo=r(jEt,"T5Tokenizer"),jEt.forEach(t),AFo=r(cB," or "),LD=n(cB,"A",{href:!0});var DEt=s(LD);LFo=r(DEt,"T5TokenizerFast"),DEt.forEach(t),yFo=r(cB," (T5 model)"),cB.forEach(t),xFo=i(S),Fu=n(S,"LI",{});var _Pe=s(Fu);nge=n(_Pe,"STRONG",{});var GEt=s(nge);$Fo=r(GEt,"tapas"),GEt.forEach(t),kFo=r(_Pe," \u2014 "),yD=n(_Pe,"A",{href:!0});var OEt=s(yD);SFo=r(OEt,"TapasTokenizer"),OEt.forEach(t),RFo=r(_Pe," (TAPAS model)"),_Pe.forEach(t),PFo=i(S),Tu=n(S,"LI",{});var vPe=s(Tu);sge=n(vPe,"STRONG",{});var VEt=s(sge);BFo=r(VEt,"tapex"),VEt.forEach(t),IFo=r(vPe," \u2014 "),xD=n(vPe,"A",{href:!0});var XEt=s(xD);NFo=r(XEt,"TapexTokenizer"),XEt.forEach(t),qFo=r(vPe," (TAPEX model)"),vPe.forEach(t),jFo=i(S),Mu=n(S,"LI",{});var bPe=s(Mu);lge=n(bPe,"STRONG",{});var zEt=s(lge);DFo=r(zEt,"transfo-xl"),zEt.forEach(t),GFo=r(bPe," \u2014 "),$D=n(bPe,"A",{href:!0});var QEt=s($D);OFo=r(QEt,"TransfoXLTokenizer"),QEt.forEach(t),VFo=r(bPe," (Transformer-XL model)"),bPe.forEach(t),XFo=i(S),il=n(S,"LI",{});var fB=s(il);ige=n(fB,"STRONG",{});var WEt=s(ige);zFo=r(WEt,"vilt"),WEt.forEach(t),QFo=r(fB," \u2014 "),kD=n(fB,"A",{href:!0});var UEt=s(kD);WFo=r(UEt,"BertTokenizer"),UEt.forEach(t),UFo=r(fB," or "),SD=n(fB,"A",{href:!0});var HEt=s(SD);HFo=r(HEt,"BertTokenizerFast"),HEt.forEach(t),JFo=r(fB," (ViLT model)"),fB.forEach(t),YFo=i(S),dl=n(S,"LI",{});var mB=s(dl);dge=n(mB,"STRONG",{});var JEt=s(dge);KFo=r(JEt,"visual_bert"),JEt.forEach(t),ZFo=r(mB," \u2014 "),RD=n(mB,"A",{href:!0});var YEt=s(RD);eTo=r(YEt,"BertTokenizer"),YEt.forEach(t),oTo=r(mB," or "),PD=n(mB,"A",{href:!0});var KEt=s(PD);rTo=r(KEt,"BertTokenizerFast"),KEt.forEach(t),tTo=r(mB," (VisualBERT model)"),mB.forEach(t),aTo=i(S),Eu=n(S,"LI",{});var FPe=s(Eu);cge=n(FPe,"STRONG",{});var ZEt=s(cge);nTo=r(ZEt,"wav2vec2"),ZEt.forEach(t),sTo=r(FPe," \u2014 "),BD=n(FPe,"A",{href:!0});var eCt=s(BD);lTo=r(eCt,"Wav2Vec2CTCTokenizer"),eCt.forEach(t),iTo=r(FPe," (Wav2Vec2 model)"),FPe.forEach(t),dTo=i(S),Cu=n(S,"LI",{});var TPe=s(Cu);fge=n(TPe,"STRONG",{});var oCt=s(fge);cTo=r(oCt,"wav2vec2-conformer"),oCt.forEach(t),fTo=r(TPe," \u2014 "),ID=n(TPe,"A",{href:!0});var rCt=s(ID);mTo=r(rCt,"Wav2Vec2CTCTokenizer"),rCt.forEach(t),gTo=r(TPe," (Wav2Vec2-Conformer model)"),TPe.forEach(t),hTo=i(S),wu=n(S,"LI",{});var MPe=s(wu);mge=n(MPe,"STRONG",{});var tCt=s(mge);uTo=r(tCt,"wav2vec2_phoneme"),tCt.forEach(t),pTo=r(MPe," \u2014 "),ND=n(MPe,"A",{href:!0});var aCt=s(ND);_To=r(aCt,"Wav2Vec2PhonemeCTCTokenizer"),aCt.forEach(t),vTo=r(MPe," (Wav2Vec2Phoneme model)"),MPe.forEach(t),bTo=i(S),cl=n(S,"LI",{});var gB=s(cl);gge=n(gB,"STRONG",{});var nCt=s(gge);FTo=r(nCt,"xclip"),nCt.forEach(t),TTo=r(gB," \u2014 "),qD=n(gB,"A",{href:!0});var sCt=s(qD);MTo=r(sCt,"CLIPTokenizer"),sCt.forEach(t),ETo=r(gB," or "),jD=n(gB,"A",{href:!0});var lCt=s(jD);CTo=r(lCt,"CLIPTokenizerFast"),lCt.forEach(t),wTo=r(gB," (X-CLIP model)"),gB.forEach(t),ATo=i(S),fl=n(S,"LI",{});var hB=s(fl);hge=n(hB,"STRONG",{});var iCt=s(hge);LTo=r(iCt,"xglm"),iCt.forEach(t),yTo=r(hB," \u2014 "),DD=n(hB,"A",{href:!0});var dCt=s(DD);xTo=r(dCt,"XGLMTokenizer"),dCt.forEach(t),$To=r(hB," or "),GD=n(hB,"A",{href:!0});var cCt=s(GD);kTo=r(cCt,"XGLMTokenizerFast"),cCt.forEach(t),STo=r(hB," (XGLM model)"),hB.forEach(t),RTo=i(S),Au=n(S,"LI",{});var EPe=s(Au);uge=n(EPe,"STRONG",{});var fCt=s(uge);PTo=r(fCt,"xlm"),fCt.forEach(t),BTo=r(EPe," \u2014 "),OD=n(EPe,"A",{href:!0});var mCt=s(OD);ITo=r(mCt,"XLMTokenizer"),mCt.forEach(t),NTo=r(EPe," (XLM model)"),EPe.forEach(t),qTo=i(S),Lu=n(S,"LI",{});var CPe=s(Lu);pge=n(CPe,"STRONG",{});var gCt=s(pge);jTo=r(gCt,"xlm-prophetnet"),gCt.forEach(t),DTo=r(CPe," \u2014 "),VD=n(CPe,"A",{href:!0});var hCt=s(VD);GTo=r(hCt,"XLMProphetNetTokenizer"),hCt.forEach(t),OTo=r(CPe," (XLM-ProphetNet model)"),CPe.forEach(t),VTo=i(S),ml=n(S,"LI",{});var uB=s(ml);_ge=n(uB,"STRONG",{});var uCt=s(_ge);XTo=r(uCt,"xlm-roberta"),uCt.forEach(t),zTo=r(uB," \u2014 "),XD=n(uB,"A",{href:!0});var pCt=s(XD);QTo=r(pCt,"XLMRobertaTokenizer"),pCt.forEach(t),WTo=r(uB," or "),zD=n(uB,"A",{href:!0});var _Ct=s(zD);UTo=r(_Ct,"XLMRobertaTokenizerFast"),_Ct.forEach(t),HTo=r(uB," (XLM-RoBERTa model)"),uB.forEach(t),JTo=i(S),gl=n(S,"LI",{});var pB=s(gl);vge=n(pB,"STRONG",{});var vCt=s(vge);YTo=r(vCt,"xlm-roberta-xl"),vCt.forEach(t),KTo=r(pB," \u2014 "),QD=n(pB,"A",{href:!0});var bCt=s(QD);ZTo=r(bCt,"XLMRobertaTokenizer"),bCt.forEach(t),eMo=r(pB," or "),WD=n(pB,"A",{href:!0});var FCt=s(WD);oMo=r(FCt,"XLMRobertaTokenizerFast"),FCt.forEach(t),rMo=r(pB," (XLM-RoBERTa-XL model)"),pB.forEach(t),tMo=i(S),hl=n(S,"LI",{});var _B=s(hl);bge=n(_B,"STRONG",{});var TCt=s(bge);aMo=r(TCt,"xlnet"),TCt.forEach(t),nMo=r(_B," \u2014 "),UD=n(_B,"A",{href:!0});var MCt=s(UD);sMo=r(MCt,"XLNetTokenizer"),MCt.forEach(t),lMo=r(_B," or "),HD=n(_B,"A",{href:!0});var ECt=s(HD);iMo=r(ECt,"XLNetTokenizerFast"),ECt.forEach(t),dMo=r(_B," (XLNet model)"),_B.forEach(t),cMo=i(S),ul=n(S,"LI",{});var vB=s(ul);Fge=n(vB,"STRONG",{});var CCt=s(Fge);fMo=r(CCt,"yoso"),CCt.forEach(t),mMo=r(vB," \u2014 "),JD=n(vB,"A",{href:!0});var wCt=s(JD);gMo=r(wCt,"AlbertTokenizer"),wCt.forEach(t),hMo=r(vB," or "),YD=n(vB,"A",{href:!0});var ACt=s(YD);uMo=r(ACt,"AlbertTokenizerFast"),ACt.forEach(t),pMo=r(vB," (YOSO model)"),vB.forEach(t),S.forEach(t),_Mo=i(Ml),T(yu.$$.fragment,Ml),Ml.forEach(t),vMo=i(Tl),xu=n(Tl,"DIV",{class:!0});var HZe=s(xu);T(I9.$$.fragment,HZe),bMo=i(HZe),Tge=n(HZe,"P",{});var LCt=s(Tge);FMo=r(LCt,"Register a new tokenizer in this mapping."),LCt.forEach(t),HZe.forEach(t),Tl.forEach(t),DYe=i(f),gd=n(f,"H2",{class:!0});var JZe=s(gd);$u=n(JZe,"A",{id:!0,class:!0,href:!0});var yCt=s($u);Mge=n(yCt,"SPAN",{});var xCt=s(Mge);T(N9.$$.fragment,xCt),xCt.forEach(t),yCt.forEach(t),TMo=i(JZe),Ege=n(JZe,"SPAN",{});var $Ct=s(Ege);MMo=r($Ct,"AutoFeatureExtractor"),$Ct.forEach(t),JZe.forEach(t),GYe=i(f),So=n(f,"DIV",{class:!0});var El=s(So);T(q9.$$.fragment,El),EMo=i(El),j9=n(El,"P",{});var YZe=s(j9);CMo=r(YZe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),KD=n(YZe,"A",{href:!0});var kCt=s(KD);wMo=r(kCt,"AutoFeatureExtractor.from_pretrained()"),kCt.forEach(t),AMo=r(YZe," class method."),YZe.forEach(t),LMo=i(El),D9=n(El,"P",{});var KZe=s(D9);yMo=r(KZe,"This class cannot be instantiated directly using "),Cge=n(KZe,"CODE",{});var SCt=s(Cge);xMo=r(SCt,"__init__()"),SCt.forEach(t),$Mo=r(KZe," (throws an error)."),KZe.forEach(t),kMo=i(El),Ye=n(El,"DIV",{class:!0});var va=s(Ye);T(G9.$$.fragment,va),SMo=i(va),wge=n(va,"P",{});var RCt=s(wge);RMo=r(RCt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),RCt.forEach(t),PMo=i(va),Ha=n(va,"P",{});var _y=s(Ha);BMo=r(_y,"The feature extractor class to instantiate is selected based on the "),Age=n(_y,"CODE",{});var PCt=s(Age);IMo=r(PCt,"model_type"),PCt.forEach(t),NMo=r(_y,` property of the config object
(either passed as an argument or loaded from `),Lge=n(_y,"CODE",{});var BCt=s(Lge);qMo=r(BCt,"pretrained_model_name_or_path"),BCt.forEach(t),jMo=r(_y,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),yge=n(_y,"CODE",{});var ICt=s(yge);DMo=r(ICt,"pretrained_model_name_or_path"),ICt.forEach(t),GMo=r(_y,":"),_y.forEach(t),OMo=i(va),W=n(va,"UL",{});var J=s(W);ku=n(J,"LI",{});var wPe=s(ku);xge=n(wPe,"STRONG",{});var NCt=s(xge);VMo=r(NCt,"beit"),NCt.forEach(t),XMo=r(wPe," \u2014 "),ZD=n(wPe,"A",{href:!0});var qCt=s(ZD);zMo=r(qCt,"BeitFeatureExtractor"),qCt.forEach(t),QMo=r(wPe," (BEiT model)"),wPe.forEach(t),WMo=i(J),Su=n(J,"LI",{});var APe=s(Su);$ge=n(APe,"STRONG",{});var jCt=s($ge);UMo=r(jCt,"clip"),jCt.forEach(t),HMo=r(APe," \u2014 "),eG=n(APe,"A",{href:!0});var DCt=s(eG);JMo=r(DCt,"CLIPFeatureExtractor"),DCt.forEach(t),YMo=r(APe," (CLIP model)"),APe.forEach(t),KMo=i(J),Ru=n(J,"LI",{});var LPe=s(Ru);kge=n(LPe,"STRONG",{});var GCt=s(kge);ZMo=r(GCt,"convnext"),GCt.forEach(t),eEo=r(LPe," \u2014 "),oG=n(LPe,"A",{href:!0});var OCt=s(oG);oEo=r(OCt,"ConvNextFeatureExtractor"),OCt.forEach(t),rEo=r(LPe," (ConvNeXT model)"),LPe.forEach(t),tEo=i(J),Pu=n(J,"LI",{});var yPe=s(Pu);Sge=n(yPe,"STRONG",{});var VCt=s(Sge);aEo=r(VCt,"cvt"),VCt.forEach(t),nEo=r(yPe," \u2014 "),rG=n(yPe,"A",{href:!0});var XCt=s(rG);sEo=r(XCt,"ConvNextFeatureExtractor"),XCt.forEach(t),lEo=r(yPe," (CvT model)"),yPe.forEach(t),iEo=i(J),Bu=n(J,"LI",{});var xPe=s(Bu);Rge=n(xPe,"STRONG",{});var zCt=s(Rge);dEo=r(zCt,"data2vec-audio"),zCt.forEach(t),cEo=r(xPe," \u2014 "),tG=n(xPe,"A",{href:!0});var QCt=s(tG);fEo=r(QCt,"Wav2Vec2FeatureExtractor"),QCt.forEach(t),mEo=r(xPe," (Data2VecAudio model)"),xPe.forEach(t),gEo=i(J),Iu=n(J,"LI",{});var $Pe=s(Iu);Pge=n($Pe,"STRONG",{});var WCt=s(Pge);hEo=r(WCt,"data2vec-vision"),WCt.forEach(t),uEo=r($Pe," \u2014 "),aG=n($Pe,"A",{href:!0});var UCt=s(aG);pEo=r(UCt,"BeitFeatureExtractor"),UCt.forEach(t),_Eo=r($Pe," (Data2VecVision model)"),$Pe.forEach(t),vEo=i(J),Nu=n(J,"LI",{});var kPe=s(Nu);Bge=n(kPe,"STRONG",{});var HCt=s(Bge);bEo=r(HCt,"deit"),HCt.forEach(t),FEo=r(kPe," \u2014 "),nG=n(kPe,"A",{href:!0});var JCt=s(nG);TEo=r(JCt,"DeiTFeatureExtractor"),JCt.forEach(t),MEo=r(kPe," (DeiT model)"),kPe.forEach(t),EEo=i(J),qu=n(J,"LI",{});var SPe=s(qu);Ige=n(SPe,"STRONG",{});var YCt=s(Ige);CEo=r(YCt,"detr"),YCt.forEach(t),wEo=r(SPe," \u2014 "),sG=n(SPe,"A",{href:!0});var KCt=s(sG);AEo=r(KCt,"DetrFeatureExtractor"),KCt.forEach(t),LEo=r(SPe," (DETR model)"),SPe.forEach(t),yEo=i(J),ju=n(J,"LI",{});var RPe=s(ju);Nge=n(RPe,"STRONG",{});var ZCt=s(Nge);xEo=r(ZCt,"donut"),ZCt.forEach(t),$Eo=r(RPe," \u2014 "),lG=n(RPe,"A",{href:!0});var e3t=s(lG);kEo=r(e3t,"DonutFeatureExtractor"),e3t.forEach(t),SEo=r(RPe," (Donut model)"),RPe.forEach(t),REo=i(J),Du=n(J,"LI",{});var PPe=s(Du);qge=n(PPe,"STRONG",{});var o3t=s(qge);PEo=r(o3t,"dpt"),o3t.forEach(t),BEo=r(PPe," \u2014 "),iG=n(PPe,"A",{href:!0});var r3t=s(iG);IEo=r(r3t,"DPTFeatureExtractor"),r3t.forEach(t),NEo=r(PPe," (DPT model)"),PPe.forEach(t),qEo=i(J),Gu=n(J,"LI",{});var BPe=s(Gu);jge=n(BPe,"STRONG",{});var t3t=s(jge);jEo=r(t3t,"flava"),t3t.forEach(t),DEo=r(BPe," \u2014 "),dG=n(BPe,"A",{href:!0});var a3t=s(dG);GEo=r(a3t,"FlavaFeatureExtractor"),a3t.forEach(t),OEo=r(BPe," (FLAVA model)"),BPe.forEach(t),VEo=i(J),Ou=n(J,"LI",{});var IPe=s(Ou);Dge=n(IPe,"STRONG",{});var n3t=s(Dge);XEo=r(n3t,"glpn"),n3t.forEach(t),zEo=r(IPe," \u2014 "),cG=n(IPe,"A",{href:!0});var s3t=s(cG);QEo=r(s3t,"GLPNFeatureExtractor"),s3t.forEach(t),WEo=r(IPe," (GLPN model)"),IPe.forEach(t),UEo=i(J),Vu=n(J,"LI",{});var NPe=s(Vu);Gge=n(NPe,"STRONG",{});var l3t=s(Gge);HEo=r(l3t,"groupvit"),l3t.forEach(t),JEo=r(NPe," \u2014 "),fG=n(NPe,"A",{href:!0});var i3t=s(fG);YEo=r(i3t,"CLIPFeatureExtractor"),i3t.forEach(t),KEo=r(NPe," (GroupViT model)"),NPe.forEach(t),ZEo=i(J),Xu=n(J,"LI",{});var qPe=s(Xu);Oge=n(qPe,"STRONG",{});var d3t=s(Oge);eCo=r(d3t,"hubert"),d3t.forEach(t),oCo=r(qPe," \u2014 "),mG=n(qPe,"A",{href:!0});var c3t=s(mG);rCo=r(c3t,"Wav2Vec2FeatureExtractor"),c3t.forEach(t),tCo=r(qPe," (Hubert model)"),qPe.forEach(t),aCo=i(J),zu=n(J,"LI",{});var jPe=s(zu);Vge=n(jPe,"STRONG",{});var f3t=s(Vge);nCo=r(f3t,"imagegpt"),f3t.forEach(t),sCo=r(jPe," \u2014 "),gG=n(jPe,"A",{href:!0});var m3t=s(gG);lCo=r(m3t,"ImageGPTFeatureExtractor"),m3t.forEach(t),iCo=r(jPe," (ImageGPT model)"),jPe.forEach(t),dCo=i(J),Qu=n(J,"LI",{});var DPe=s(Qu);Xge=n(DPe,"STRONG",{});var g3t=s(Xge);cCo=r(g3t,"layoutlmv2"),g3t.forEach(t),fCo=r(DPe," \u2014 "),hG=n(DPe,"A",{href:!0});var h3t=s(hG);mCo=r(h3t,"LayoutLMv2FeatureExtractor"),h3t.forEach(t),gCo=r(DPe," (LayoutLMv2 model)"),DPe.forEach(t),hCo=i(J),Wu=n(J,"LI",{});var GPe=s(Wu);zge=n(GPe,"STRONG",{});var u3t=s(zge);uCo=r(u3t,"layoutlmv3"),u3t.forEach(t),pCo=r(GPe," \u2014 "),uG=n(GPe,"A",{href:!0});var p3t=s(uG);_Co=r(p3t,"LayoutLMv3FeatureExtractor"),p3t.forEach(t),vCo=r(GPe," (LayoutLMv3 model)"),GPe.forEach(t),bCo=i(J),Uu=n(J,"LI",{});var OPe=s(Uu);Qge=n(OPe,"STRONG",{});var _3t=s(Qge);FCo=r(_3t,"levit"),_3t.forEach(t),TCo=r(OPe," \u2014 "),pG=n(OPe,"A",{href:!0});var v3t=s(pG);MCo=r(v3t,"LevitFeatureExtractor"),v3t.forEach(t),ECo=r(OPe," (LeViT model)"),OPe.forEach(t),CCo=i(J),Hu=n(J,"LI",{});var VPe=s(Hu);Wge=n(VPe,"STRONG",{});var b3t=s(Wge);wCo=r(b3t,"maskformer"),b3t.forEach(t),ACo=r(VPe," \u2014 "),_G=n(VPe,"A",{href:!0});var F3t=s(_G);LCo=r(F3t,"MaskFormerFeatureExtractor"),F3t.forEach(t),yCo=r(VPe," (MaskFormer model)"),VPe.forEach(t),xCo=i(J),Ju=n(J,"LI",{});var XPe=s(Ju);Uge=n(XPe,"STRONG",{});var T3t=s(Uge);$Co=r(T3t,"mctct"),T3t.forEach(t),kCo=r(XPe," \u2014 "),vG=n(XPe,"A",{href:!0});var M3t=s(vG);SCo=r(M3t,"MCTCTFeatureExtractor"),M3t.forEach(t),RCo=r(XPe," (M-CTC-T model)"),XPe.forEach(t),PCo=i(J),Yu=n(J,"LI",{});var zPe=s(Yu);Hge=n(zPe,"STRONG",{});var E3t=s(Hge);BCo=r(E3t,"mobilevit"),E3t.forEach(t),ICo=r(zPe," \u2014 "),bG=n(zPe,"A",{href:!0});var C3t=s(bG);NCo=r(C3t,"MobileViTFeatureExtractor"),C3t.forEach(t),qCo=r(zPe," (MobileViT model)"),zPe.forEach(t),jCo=i(J),Ku=n(J,"LI",{});var QPe=s(Ku);Jge=n(QPe,"STRONG",{});var w3t=s(Jge);DCo=r(w3t,"owlvit"),w3t.forEach(t),GCo=r(QPe," \u2014 "),FG=n(QPe,"A",{href:!0});var A3t=s(FG);OCo=r(A3t,"OwlViTFeatureExtractor"),A3t.forEach(t),VCo=r(QPe," (OWL-ViT model)"),QPe.forEach(t),XCo=i(J),Zu=n(J,"LI",{});var WPe=s(Zu);Yge=n(WPe,"STRONG",{});var L3t=s(Yge);zCo=r(L3t,"perceiver"),L3t.forEach(t),QCo=r(WPe," \u2014 "),TG=n(WPe,"A",{href:!0});var y3t=s(TG);WCo=r(y3t,"PerceiverFeatureExtractor"),y3t.forEach(t),UCo=r(WPe," (Perceiver model)"),WPe.forEach(t),HCo=i(J),ep=n(J,"LI",{});var UPe=s(ep);Kge=n(UPe,"STRONG",{});var x3t=s(Kge);JCo=r(x3t,"poolformer"),x3t.forEach(t),YCo=r(UPe," \u2014 "),MG=n(UPe,"A",{href:!0});var $3t=s(MG);KCo=r($3t,"PoolFormerFeatureExtractor"),$3t.forEach(t),ZCo=r(UPe," (PoolFormer model)"),UPe.forEach(t),e3o=i(J),op=n(J,"LI",{});var HPe=s(op);Zge=n(HPe,"STRONG",{});var k3t=s(Zge);o3o=r(k3t,"regnet"),k3t.forEach(t),r3o=r(HPe," \u2014 "),EG=n(HPe,"A",{href:!0});var S3t=s(EG);t3o=r(S3t,"ConvNextFeatureExtractor"),S3t.forEach(t),a3o=r(HPe," (RegNet model)"),HPe.forEach(t),n3o=i(J),rp=n(J,"LI",{});var JPe=s(rp);ehe=n(JPe,"STRONG",{});var R3t=s(ehe);s3o=r(R3t,"resnet"),R3t.forEach(t),l3o=r(JPe," \u2014 "),CG=n(JPe,"A",{href:!0});var P3t=s(CG);i3o=r(P3t,"ConvNextFeatureExtractor"),P3t.forEach(t),d3o=r(JPe," (ResNet model)"),JPe.forEach(t),c3o=i(J),tp=n(J,"LI",{});var YPe=s(tp);ohe=n(YPe,"STRONG",{});var B3t=s(ohe);f3o=r(B3t,"segformer"),B3t.forEach(t),m3o=r(YPe," \u2014 "),wG=n(YPe,"A",{href:!0});var I3t=s(wG);g3o=r(I3t,"SegformerFeatureExtractor"),I3t.forEach(t),h3o=r(YPe," (SegFormer model)"),YPe.forEach(t),u3o=i(J),ap=n(J,"LI",{});var KPe=s(ap);rhe=n(KPe,"STRONG",{});var N3t=s(rhe);p3o=r(N3t,"speech_to_text"),N3t.forEach(t),_3o=r(KPe," \u2014 "),AG=n(KPe,"A",{href:!0});var q3t=s(AG);v3o=r(q3t,"Speech2TextFeatureExtractor"),q3t.forEach(t),b3o=r(KPe," (Speech2Text model)"),KPe.forEach(t),F3o=i(J),np=n(J,"LI",{});var ZPe=s(np);the=n(ZPe,"STRONG",{});var j3t=s(the);T3o=r(j3t,"swin"),j3t.forEach(t),M3o=r(ZPe," \u2014 "),LG=n(ZPe,"A",{href:!0});var D3t=s(LG);E3o=r(D3t,"ViTFeatureExtractor"),D3t.forEach(t),C3o=r(ZPe," (Swin Transformer model)"),ZPe.forEach(t),w3o=i(J),sp=n(J,"LI",{});var eBe=s(sp);ahe=n(eBe,"STRONG",{});var G3t=s(ahe);A3o=r(G3t,"swinv2"),G3t.forEach(t),L3o=r(eBe," \u2014 "),yG=n(eBe,"A",{href:!0});var O3t=s(yG);y3o=r(O3t,"ViTFeatureExtractor"),O3t.forEach(t),x3o=r(eBe," (Swin Transformer V2 model)"),eBe.forEach(t),$3o=i(J),lp=n(J,"LI",{});var oBe=s(lp);nhe=n(oBe,"STRONG",{});var V3t=s(nhe);k3o=r(V3t,"van"),V3t.forEach(t),S3o=r(oBe," \u2014 "),xG=n(oBe,"A",{href:!0});var X3t=s(xG);R3o=r(X3t,"ConvNextFeatureExtractor"),X3t.forEach(t),P3o=r(oBe," (VAN model)"),oBe.forEach(t),B3o=i(J),ip=n(J,"LI",{});var rBe=s(ip);she=n(rBe,"STRONG",{});var z3t=s(she);I3o=r(z3t,"videomae"),z3t.forEach(t),N3o=r(rBe," \u2014 "),$G=n(rBe,"A",{href:!0});var Q3t=s($G);q3o=r(Q3t,"VideoMAEFeatureExtractor"),Q3t.forEach(t),j3o=r(rBe," (VideoMAE model)"),rBe.forEach(t),D3o=i(J),dp=n(J,"LI",{});var tBe=s(dp);lhe=n(tBe,"STRONG",{});var W3t=s(lhe);G3o=r(W3t,"vilt"),W3t.forEach(t),O3o=r(tBe," \u2014 "),kG=n(tBe,"A",{href:!0});var U3t=s(kG);V3o=r(U3t,"ViltFeatureExtractor"),U3t.forEach(t),X3o=r(tBe," (ViLT model)"),tBe.forEach(t),z3o=i(J),cp=n(J,"LI",{});var aBe=s(cp);ihe=n(aBe,"STRONG",{});var H3t=s(ihe);Q3o=r(H3t,"vit"),H3t.forEach(t),W3o=r(aBe," \u2014 "),SG=n(aBe,"A",{href:!0});var J3t=s(SG);U3o=r(J3t,"ViTFeatureExtractor"),J3t.forEach(t),H3o=r(aBe," (ViT model)"),aBe.forEach(t),J3o=i(J),fp=n(J,"LI",{});var nBe=s(fp);dhe=n(nBe,"STRONG",{});var Y3t=s(dhe);Y3o=r(Y3t,"vit_mae"),Y3t.forEach(t),K3o=r(nBe," \u2014 "),RG=n(nBe,"A",{href:!0});var K3t=s(RG);Z3o=r(K3t,"ViTFeatureExtractor"),K3t.forEach(t),e5o=r(nBe," (ViTMAE model)"),nBe.forEach(t),o5o=i(J),mp=n(J,"LI",{});var sBe=s(mp);che=n(sBe,"STRONG",{});var Z3t=s(che);r5o=r(Z3t,"wav2vec2"),Z3t.forEach(t),t5o=r(sBe," \u2014 "),PG=n(sBe,"A",{href:!0});var e5t=s(PG);a5o=r(e5t,"Wav2Vec2FeatureExtractor"),e5t.forEach(t),n5o=r(sBe," (Wav2Vec2 model)"),sBe.forEach(t),s5o=i(J),gp=n(J,"LI",{});var lBe=s(gp);fhe=n(lBe,"STRONG",{});var o5t=s(fhe);l5o=r(o5t,"wav2vec2-conformer"),o5t.forEach(t),i5o=r(lBe," \u2014 "),BG=n(lBe,"A",{href:!0});var r5t=s(BG);d5o=r(r5t,"Wav2Vec2FeatureExtractor"),r5t.forEach(t),c5o=r(lBe," (Wav2Vec2-Conformer model)"),lBe.forEach(t),f5o=i(J),hp=n(J,"LI",{});var iBe=s(hp);mhe=n(iBe,"STRONG",{});var t5t=s(mhe);m5o=r(t5t,"xclip"),t5t.forEach(t),g5o=r(iBe," \u2014 "),IG=n(iBe,"A",{href:!0});var a5t=s(IG);h5o=r(a5t,"CLIPFeatureExtractor"),a5t.forEach(t),u5o=r(iBe," (X-CLIP model)"),iBe.forEach(t),p5o=i(J),up=n(J,"LI",{});var dBe=s(up);ghe=n(dBe,"STRONG",{});var n5t=s(ghe);_5o=r(n5t,"yolos"),n5t.forEach(t),v5o=r(dBe," \u2014 "),NG=n(dBe,"A",{href:!0});var s5t=s(NG);b5o=r(s5t,"YolosFeatureExtractor"),s5t.forEach(t),F5o=r(dBe," (YOLOS model)"),dBe.forEach(t),J.forEach(t),T5o=i(va),T(pp.$$.fragment,va),M5o=i(va),T(_p.$$.fragment,va),va.forEach(t),E5o=i(El),vp=n(El,"DIV",{class:!0});var ZZe=s(vp);T(O9.$$.fragment,ZZe),C5o=i(ZZe),hhe=n(ZZe,"P",{});var l5t=s(hhe);w5o=r(l5t,"Register a new feature extractor for this class."),l5t.forEach(t),ZZe.forEach(t),El.forEach(t),OYe=i(f),hd=n(f,"H2",{class:!0});var eeo=s(hd);bp=n(eeo,"A",{id:!0,class:!0,href:!0});var i5t=s(bp);uhe=n(i5t,"SPAN",{});var d5t=s(uhe);T(V9.$$.fragment,d5t),d5t.forEach(t),i5t.forEach(t),A5o=i(eeo),phe=n(eeo,"SPAN",{});var c5t=s(phe);L5o=r(c5t,"AutoProcessor"),c5t.forEach(t),eeo.forEach(t),VYe=i(f),Ro=n(f,"DIV",{class:!0});var Cl=s(Ro);T(X9.$$.fragment,Cl),y5o=i(Cl),z9=n(Cl,"P",{});var oeo=s(z9);x5o=r(oeo,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),qG=n(oeo,"A",{href:!0});var f5t=s(qG);$5o=r(f5t,"AutoProcessor.from_pretrained()"),f5t.forEach(t),k5o=r(oeo," class method."),oeo.forEach(t),S5o=i(Cl),Q9=n(Cl,"P",{});var reo=s(Q9);R5o=r(reo,"This class cannot be instantiated directly using "),_he=n(reo,"CODE",{});var m5t=s(_he);P5o=r(m5t,"__init__()"),m5t.forEach(t),B5o=r(reo," (throws an error)."),reo.forEach(t),I5o=i(Cl),Ke=n(Cl,"DIV",{class:!0});var ba=s(Ke);T(W9.$$.fragment,ba),N5o=i(ba),vhe=n(ba,"P",{});var g5t=s(vhe);q5o=r(g5t,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),g5t.forEach(t),j5o=i(ba),ud=n(ba,"P",{});var Qse=s(ud);D5o=r(Qse,"The processor class to instantiate is selected based on the "),bhe=n(Qse,"CODE",{});var h5t=s(bhe);G5o=r(h5t,"model_type"),h5t.forEach(t),O5o=r(Qse,` property of the config object (either
passed as an argument or loaded from `),Fhe=n(Qse,"CODE",{});var u5t=s(Fhe);V5o=r(u5t,"pretrained_model_name_or_path"),u5t.forEach(t),X5o=r(Qse," if possible):"),Qse.forEach(t),z5o=i(ba),ie=n(ba,"UL",{});var ge=s(ie);Fp=n(ge,"LI",{});var cBe=s(Fp);The=n(cBe,"STRONG",{});var p5t=s(The);Q5o=r(p5t,"clip"),p5t.forEach(t),W5o=r(cBe," \u2014 "),jG=n(cBe,"A",{href:!0});var _5t=s(jG);U5o=r(_5t,"CLIPProcessor"),_5t.forEach(t),H5o=r(cBe," (CLIP model)"),cBe.forEach(t),J5o=i(ge),Tp=n(ge,"LI",{});var fBe=s(Tp);Mhe=n(fBe,"STRONG",{});var v5t=s(Mhe);Y5o=r(v5t,"donut"),v5t.forEach(t),K5o=r(fBe," \u2014 "),DG=n(fBe,"A",{href:!0});var b5t=s(DG);Z5o=r(b5t,"DonutProcessor"),b5t.forEach(t),ewo=r(fBe," (Donut model)"),fBe.forEach(t),owo=i(ge),Mp=n(ge,"LI",{});var mBe=s(Mp);Ehe=n(mBe,"STRONG",{});var F5t=s(Ehe);rwo=r(F5t,"flava"),F5t.forEach(t),two=r(mBe," \u2014 "),GG=n(mBe,"A",{href:!0});var T5t=s(GG);awo=r(T5t,"FlavaProcessor"),T5t.forEach(t),nwo=r(mBe," (FLAVA model)"),mBe.forEach(t),swo=i(ge),Ep=n(ge,"LI",{});var gBe=s(Ep);Che=n(gBe,"STRONG",{});var M5t=s(Che);lwo=r(M5t,"groupvit"),M5t.forEach(t),iwo=r(gBe," \u2014 "),OG=n(gBe,"A",{href:!0});var E5t=s(OG);dwo=r(E5t,"CLIPProcessor"),E5t.forEach(t),cwo=r(gBe," (GroupViT model)"),gBe.forEach(t),fwo=i(ge),Cp=n(ge,"LI",{});var hBe=s(Cp);whe=n(hBe,"STRONG",{});var C5t=s(whe);mwo=r(C5t,"layoutlmv2"),C5t.forEach(t),gwo=r(hBe," \u2014 "),VG=n(hBe,"A",{href:!0});var w5t=s(VG);hwo=r(w5t,"LayoutLMv2Processor"),w5t.forEach(t),uwo=r(hBe," (LayoutLMv2 model)"),hBe.forEach(t),pwo=i(ge),wp=n(ge,"LI",{});var uBe=s(wp);Ahe=n(uBe,"STRONG",{});var A5t=s(Ahe);_wo=r(A5t,"layoutlmv3"),A5t.forEach(t),vwo=r(uBe," \u2014 "),XG=n(uBe,"A",{href:!0});var L5t=s(XG);bwo=r(L5t,"LayoutLMv3Processor"),L5t.forEach(t),Fwo=r(uBe," (LayoutLMv3 model)"),uBe.forEach(t),Two=i(ge),Ap=n(ge,"LI",{});var pBe=s(Ap);Lhe=n(pBe,"STRONG",{});var y5t=s(Lhe);Mwo=r(y5t,"layoutxlm"),y5t.forEach(t),Ewo=r(pBe," \u2014 "),zG=n(pBe,"A",{href:!0});var x5t=s(zG);Cwo=r(x5t,"LayoutXLMProcessor"),x5t.forEach(t),wwo=r(pBe," (LayoutXLM model)"),pBe.forEach(t),Awo=i(ge),Lp=n(ge,"LI",{});var _Be=s(Lp);yhe=n(_Be,"STRONG",{});var $5t=s(yhe);Lwo=r($5t,"owlvit"),$5t.forEach(t),ywo=r(_Be," \u2014 "),QG=n(_Be,"A",{href:!0});var k5t=s(QG);xwo=r(k5t,"OwlViTProcessor"),k5t.forEach(t),$wo=r(_Be," (OWL-ViT model)"),_Be.forEach(t),kwo=i(ge),yp=n(ge,"LI",{});var vBe=s(yp);xhe=n(vBe,"STRONG",{});var S5t=s(xhe);Swo=r(S5t,"sew"),S5t.forEach(t),Rwo=r(vBe," \u2014 "),WG=n(vBe,"A",{href:!0});var R5t=s(WG);Pwo=r(R5t,"Wav2Vec2Processor"),R5t.forEach(t),Bwo=r(vBe," (SEW model)"),vBe.forEach(t),Iwo=i(ge),xp=n(ge,"LI",{});var bBe=s(xp);$he=n(bBe,"STRONG",{});var P5t=s($he);Nwo=r(P5t,"sew-d"),P5t.forEach(t),qwo=r(bBe," \u2014 "),UG=n(bBe,"A",{href:!0});var B5t=s(UG);jwo=r(B5t,"Wav2Vec2Processor"),B5t.forEach(t),Dwo=r(bBe," (SEW-D model)"),bBe.forEach(t),Gwo=i(ge),$p=n(ge,"LI",{});var FBe=s($p);khe=n(FBe,"STRONG",{});var I5t=s(khe);Owo=r(I5t,"speech_to_text"),I5t.forEach(t),Vwo=r(FBe," \u2014 "),HG=n(FBe,"A",{href:!0});var N5t=s(HG);Xwo=r(N5t,"Speech2TextProcessor"),N5t.forEach(t),zwo=r(FBe," (Speech2Text model)"),FBe.forEach(t),Qwo=i(ge),kp=n(ge,"LI",{});var TBe=s(kp);She=n(TBe,"STRONG",{});var q5t=s(She);Wwo=r(q5t,"speech_to_text_2"),q5t.forEach(t),Uwo=r(TBe," \u2014 "),JG=n(TBe,"A",{href:!0});var j5t=s(JG);Hwo=r(j5t,"Speech2Text2Processor"),j5t.forEach(t),Jwo=r(TBe," (Speech2Text2 model)"),TBe.forEach(t),Ywo=i(ge),Sp=n(ge,"LI",{});var MBe=s(Sp);Rhe=n(MBe,"STRONG",{});var D5t=s(Rhe);Kwo=r(D5t,"trocr"),D5t.forEach(t),Zwo=r(MBe," \u2014 "),YG=n(MBe,"A",{href:!0});var G5t=s(YG);eAo=r(G5t,"TrOCRProcessor"),G5t.forEach(t),oAo=r(MBe," (TrOCR model)"),MBe.forEach(t),rAo=i(ge),Rp=n(ge,"LI",{});var EBe=s(Rp);Phe=n(EBe,"STRONG",{});var O5t=s(Phe);tAo=r(O5t,"unispeech"),O5t.forEach(t),aAo=r(EBe," \u2014 "),KG=n(EBe,"A",{href:!0});var V5t=s(KG);nAo=r(V5t,"Wav2Vec2Processor"),V5t.forEach(t),sAo=r(EBe," (UniSpeech model)"),EBe.forEach(t),lAo=i(ge),Pp=n(ge,"LI",{});var CBe=s(Pp);Bhe=n(CBe,"STRONG",{});var X5t=s(Bhe);iAo=r(X5t,"unispeech-sat"),X5t.forEach(t),dAo=r(CBe," \u2014 "),ZG=n(CBe,"A",{href:!0});var z5t=s(ZG);cAo=r(z5t,"Wav2Vec2Processor"),z5t.forEach(t),fAo=r(CBe," (UniSpeechSat model)"),CBe.forEach(t),mAo=i(ge),Bp=n(ge,"LI",{});var wBe=s(Bp);Ihe=n(wBe,"STRONG",{});var Q5t=s(Ihe);gAo=r(Q5t,"vilt"),Q5t.forEach(t),hAo=r(wBe," \u2014 "),eO=n(wBe,"A",{href:!0});var W5t=s(eO);uAo=r(W5t,"ViltProcessor"),W5t.forEach(t),pAo=r(wBe," (ViLT model)"),wBe.forEach(t),_Ao=i(ge),Ip=n(ge,"LI",{});var ABe=s(Ip);Nhe=n(ABe,"STRONG",{});var U5t=s(Nhe);vAo=r(U5t,"vision-text-dual-encoder"),U5t.forEach(t),bAo=r(ABe," \u2014 "),oO=n(ABe,"A",{href:!0});var H5t=s(oO);FAo=r(H5t,"VisionTextDualEncoderProcessor"),H5t.forEach(t),TAo=r(ABe," (VisionTextDualEncoder model)"),ABe.forEach(t),MAo=i(ge),Np=n(ge,"LI",{});var LBe=s(Np);qhe=n(LBe,"STRONG",{});var J5t=s(qhe);EAo=r(J5t,"wav2vec2"),J5t.forEach(t),CAo=r(LBe," \u2014 "),rO=n(LBe,"A",{href:!0});var Y5t=s(rO);wAo=r(Y5t,"Wav2Vec2Processor"),Y5t.forEach(t),AAo=r(LBe," (Wav2Vec2 model)"),LBe.forEach(t),LAo=i(ge),qp=n(ge,"LI",{});var yBe=s(qp);jhe=n(yBe,"STRONG",{});var K5t=s(jhe);yAo=r(K5t,"wav2vec2-conformer"),K5t.forEach(t),xAo=r(yBe," \u2014 "),tO=n(yBe,"A",{href:!0});var Z5t=s(tO);$Ao=r(Z5t,"Wav2Vec2Processor"),Z5t.forEach(t),kAo=r(yBe," (Wav2Vec2-Conformer model)"),yBe.forEach(t),SAo=i(ge),jp=n(ge,"LI",{});var xBe=s(jp);Dhe=n(xBe,"STRONG",{});var ewt=s(Dhe);RAo=r(ewt,"wavlm"),ewt.forEach(t),PAo=r(xBe," \u2014 "),aO=n(xBe,"A",{href:!0});var owt=s(aO);BAo=r(owt,"Wav2Vec2Processor"),owt.forEach(t),IAo=r(xBe," (WavLM model)"),xBe.forEach(t),NAo=i(ge),Dp=n(ge,"LI",{});var $Be=s(Dp);Ghe=n($Be,"STRONG",{});var rwt=s(Ghe);qAo=r(rwt,"xclip"),rwt.forEach(t),jAo=r($Be," \u2014 "),nO=n($Be,"A",{href:!0});var twt=s(nO);DAo=r(twt,"CLIPProcessor"),twt.forEach(t),GAo=r($Be," (X-CLIP model)"),$Be.forEach(t),ge.forEach(t),OAo=i(ba),T(Gp.$$.fragment,ba),VAo=i(ba),T(Op.$$.fragment,ba),ba.forEach(t),XAo=i(Cl),Vp=n(Cl,"DIV",{class:!0});var teo=s(Vp);T(U9.$$.fragment,teo),zAo=i(teo),Ohe=n(teo,"P",{});var awt=s(Ohe);QAo=r(awt,"Register a new processor for this class."),awt.forEach(t),teo.forEach(t),Cl.forEach(t),XYe=i(f),pd=n(f,"H2",{class:!0});var aeo=s(pd);Xp=n(aeo,"A",{id:!0,class:!0,href:!0});var nwt=s(Xp);Vhe=n(nwt,"SPAN",{});var swt=s(Vhe);T(H9.$$.fragment,swt),swt.forEach(t),nwt.forEach(t),WAo=i(aeo),Xhe=n(aeo,"SPAN",{});var lwt=s(Xhe);UAo=r(lwt,"AutoModel"),lwt.forEach(t),aeo.forEach(t),zYe=i(f),Po=n(f,"DIV",{class:!0});var wl=s(Po);T(J9.$$.fragment,wl),HAo=i(wl),_d=n(wl,"P",{});var Wse=s(_d);JAo=r(Wse,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),sO=n(Wse,"A",{href:!0});var iwt=s(sO);YAo=r(iwt,"from_pretrained()"),iwt.forEach(t),KAo=r(Wse," class method or the "),lO=n(Wse,"A",{href:!0});var dwt=s(lO);ZAo=r(dwt,"from_config()"),dwt.forEach(t),e6o=r(Wse,` class
method.`),Wse.forEach(t),o6o=i(wl),Y9=n(wl,"P",{});var neo=s(Y9);r6o=r(neo,"This class cannot be instantiated directly using "),zhe=n(neo,"CODE",{});var cwt=s(zhe);t6o=r(cwt,"__init__()"),cwt.forEach(t),a6o=r(neo," (throws an error)."),neo.forEach(t),n6o=i(wl),_t=n(wl,"DIV",{class:!0});var vy=s(_t);T(K9.$$.fragment,vy),s6o=i(vy),Qhe=n(vy,"P",{});var fwt=s(Qhe);l6o=r(fwt,"Instantiates one of the base model classes of the library from a configuration."),fwt.forEach(t),i6o=i(vy),vd=n(vy,"P",{});var Use=s(vd);d6o=r(Use,`Note:
Loading a model from its configuration file does `),Whe=n(Use,"STRONG",{});var mwt=s(Whe);c6o=r(mwt,"not"),mwt.forEach(t),f6o=r(Use,` load the model weights. It only affects the
model\u2019s configuration. Use `),iO=n(Use,"A",{href:!0});var gwt=s(iO);m6o=r(gwt,"from_pretrained()"),gwt.forEach(t),g6o=r(Use," to load the model weights."),Use.forEach(t),h6o=i(vy),T(zp.$$.fragment,vy),vy.forEach(t),u6o=i(wl),Ze=n(wl,"DIV",{class:!0});var Fa=s(Ze);T(Z9.$$.fragment,Fa),p6o=i(Fa),Uhe=n(Fa,"P",{});var hwt=s(Uhe);_6o=r(hwt,"Instantiate one of the base model classes of the library from a pretrained model."),hwt.forEach(t),v6o=i(Fa),Ja=n(Fa,"P",{});var by=s(Ja);b6o=r(by,"The model class to instantiate is selected based on the "),Hhe=n(by,"CODE",{});var uwt=s(Hhe);F6o=r(uwt,"model_type"),uwt.forEach(t),T6o=r(by,` property of the config object (either
passed as an argument or loaded from `),Jhe=n(by,"CODE",{});var pwt=s(Jhe);M6o=r(pwt,"pretrained_model_name_or_path"),pwt.forEach(t),E6o=r(by,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yhe=n(by,"CODE",{});var _wt=s(Yhe);C6o=r(_wt,"pretrained_model_name_or_path"),_wt.forEach(t),w6o=r(by,":"),by.forEach(t),A6o=i(Fa),y=n(Fa,"UL",{});var x=s(y);Qp=n(x,"LI",{});var kBe=s(Qp);Khe=n(kBe,"STRONG",{});var vwt=s(Khe);L6o=r(vwt,"albert"),vwt.forEach(t),y6o=r(kBe," \u2014 "),dO=n(kBe,"A",{href:!0});var bwt=s(dO);x6o=r(bwt,"AlbertModel"),bwt.forEach(t),$6o=r(kBe," (ALBERT model)"),kBe.forEach(t),k6o=i(x),Wp=n(x,"LI",{});var SBe=s(Wp);Zhe=n(SBe,"STRONG",{});var Fwt=s(Zhe);S6o=r(Fwt,"bart"),Fwt.forEach(t),R6o=r(SBe," \u2014 "),cO=n(SBe,"A",{href:!0});var Twt=s(cO);P6o=r(Twt,"BartModel"),Twt.forEach(t),B6o=r(SBe," (BART model)"),SBe.forEach(t),I6o=i(x),Up=n(x,"LI",{});var RBe=s(Up);eue=n(RBe,"STRONG",{});var Mwt=s(eue);N6o=r(Mwt,"beit"),Mwt.forEach(t),q6o=r(RBe," \u2014 "),fO=n(RBe,"A",{href:!0});var Ewt=s(fO);j6o=r(Ewt,"BeitModel"),Ewt.forEach(t),D6o=r(RBe," (BEiT model)"),RBe.forEach(t),G6o=i(x),Hp=n(x,"LI",{});var PBe=s(Hp);oue=n(PBe,"STRONG",{});var Cwt=s(oue);O6o=r(Cwt,"bert"),Cwt.forEach(t),V6o=r(PBe," \u2014 "),mO=n(PBe,"A",{href:!0});var wwt=s(mO);X6o=r(wwt,"BertModel"),wwt.forEach(t),z6o=r(PBe," (BERT model)"),PBe.forEach(t),Q6o=i(x),Jp=n(x,"LI",{});var BBe=s(Jp);rue=n(BBe,"STRONG",{});var Awt=s(rue);W6o=r(Awt,"bert-generation"),Awt.forEach(t),U6o=r(BBe," \u2014 "),gO=n(BBe,"A",{href:!0});var Lwt=s(gO);H6o=r(Lwt,"BertGenerationEncoder"),Lwt.forEach(t),J6o=r(BBe," (Bert Generation model)"),BBe.forEach(t),Y6o=i(x),Yp=n(x,"LI",{});var IBe=s(Yp);tue=n(IBe,"STRONG",{});var ywt=s(tue);K6o=r(ywt,"big_bird"),ywt.forEach(t),Z6o=r(IBe," \u2014 "),hO=n(IBe,"A",{href:!0});var xwt=s(hO);e7o=r(xwt,"BigBirdModel"),xwt.forEach(t),o7o=r(IBe," (BigBird model)"),IBe.forEach(t),r7o=i(x),Kp=n(x,"LI",{});var NBe=s(Kp);aue=n(NBe,"STRONG",{});var $wt=s(aue);t7o=r($wt,"bigbird_pegasus"),$wt.forEach(t),a7o=r(NBe," \u2014 "),uO=n(NBe,"A",{href:!0});var kwt=s(uO);n7o=r(kwt,"BigBirdPegasusModel"),kwt.forEach(t),s7o=r(NBe," (BigBird-Pegasus model)"),NBe.forEach(t),l7o=i(x),Zp=n(x,"LI",{});var qBe=s(Zp);nue=n(qBe,"STRONG",{});var Swt=s(nue);i7o=r(Swt,"blenderbot"),Swt.forEach(t),d7o=r(qBe," \u2014 "),pO=n(qBe,"A",{href:!0});var Rwt=s(pO);c7o=r(Rwt,"BlenderbotModel"),Rwt.forEach(t),f7o=r(qBe," (Blenderbot model)"),qBe.forEach(t),m7o=i(x),e_=n(x,"LI",{});var jBe=s(e_);sue=n(jBe,"STRONG",{});var Pwt=s(sue);g7o=r(Pwt,"blenderbot-small"),Pwt.forEach(t),h7o=r(jBe," \u2014 "),_O=n(jBe,"A",{href:!0});var Bwt=s(_O);u7o=r(Bwt,"BlenderbotSmallModel"),Bwt.forEach(t),p7o=r(jBe," (BlenderbotSmall model)"),jBe.forEach(t),_7o=i(x),o_=n(x,"LI",{});var DBe=s(o_);lue=n(DBe,"STRONG",{});var Iwt=s(lue);v7o=r(Iwt,"bloom"),Iwt.forEach(t),b7o=r(DBe," \u2014 "),vO=n(DBe,"A",{href:!0});var Nwt=s(vO);F7o=r(Nwt,"BloomModel"),Nwt.forEach(t),T7o=r(DBe," (BLOOM model)"),DBe.forEach(t),M7o=i(x),r_=n(x,"LI",{});var GBe=s(r_);iue=n(GBe,"STRONG",{});var qwt=s(iue);E7o=r(qwt,"camembert"),qwt.forEach(t),C7o=r(GBe," \u2014 "),bO=n(GBe,"A",{href:!0});var jwt=s(bO);w7o=r(jwt,"CamembertModel"),jwt.forEach(t),A7o=r(GBe," (CamemBERT model)"),GBe.forEach(t),L7o=i(x),t_=n(x,"LI",{});var OBe=s(t_);due=n(OBe,"STRONG",{});var Dwt=s(due);y7o=r(Dwt,"canine"),Dwt.forEach(t),x7o=r(OBe," \u2014 "),FO=n(OBe,"A",{href:!0});var Gwt=s(FO);$7o=r(Gwt,"CanineModel"),Gwt.forEach(t),k7o=r(OBe," (CANINE model)"),OBe.forEach(t),S7o=i(x),a_=n(x,"LI",{});var VBe=s(a_);cue=n(VBe,"STRONG",{});var Owt=s(cue);R7o=r(Owt,"clip"),Owt.forEach(t),P7o=r(VBe," \u2014 "),TO=n(VBe,"A",{href:!0});var Vwt=s(TO);B7o=r(Vwt,"CLIPModel"),Vwt.forEach(t),I7o=r(VBe," (CLIP model)"),VBe.forEach(t),N7o=i(x),n_=n(x,"LI",{});var XBe=s(n_);fue=n(XBe,"STRONG",{});var Xwt=s(fue);q7o=r(Xwt,"codegen"),Xwt.forEach(t),j7o=r(XBe," \u2014 "),MO=n(XBe,"A",{href:!0});var zwt=s(MO);D7o=r(zwt,"CodeGenModel"),zwt.forEach(t),G7o=r(XBe," (CodeGen model)"),XBe.forEach(t),O7o=i(x),s_=n(x,"LI",{});var zBe=s(s_);mue=n(zBe,"STRONG",{});var Qwt=s(mue);V7o=r(Qwt,"convbert"),Qwt.forEach(t),X7o=r(zBe," \u2014 "),EO=n(zBe,"A",{href:!0});var Wwt=s(EO);z7o=r(Wwt,"ConvBertModel"),Wwt.forEach(t),Q7o=r(zBe," (ConvBERT model)"),zBe.forEach(t),W7o=i(x),l_=n(x,"LI",{});var QBe=s(l_);gue=n(QBe,"STRONG",{});var Uwt=s(gue);U7o=r(Uwt,"convnext"),Uwt.forEach(t),H7o=r(QBe," \u2014 "),CO=n(QBe,"A",{href:!0});var Hwt=s(CO);J7o=r(Hwt,"ConvNextModel"),Hwt.forEach(t),Y7o=r(QBe," (ConvNeXT model)"),QBe.forEach(t),K7o=i(x),i_=n(x,"LI",{});var WBe=s(i_);hue=n(WBe,"STRONG",{});var Jwt=s(hue);Z7o=r(Jwt,"ctrl"),Jwt.forEach(t),eLo=r(WBe," \u2014 "),wO=n(WBe,"A",{href:!0});var Ywt=s(wO);oLo=r(Ywt,"CTRLModel"),Ywt.forEach(t),rLo=r(WBe," (CTRL model)"),WBe.forEach(t),tLo=i(x),d_=n(x,"LI",{});var UBe=s(d_);uue=n(UBe,"STRONG",{});var Kwt=s(uue);aLo=r(Kwt,"cvt"),Kwt.forEach(t),nLo=r(UBe," \u2014 "),AO=n(UBe,"A",{href:!0});var Zwt=s(AO);sLo=r(Zwt,"CvtModel"),Zwt.forEach(t),lLo=r(UBe," (CvT model)"),UBe.forEach(t),iLo=i(x),c_=n(x,"LI",{});var HBe=s(c_);pue=n(HBe,"STRONG",{});var eAt=s(pue);dLo=r(eAt,"data2vec-audio"),eAt.forEach(t),cLo=r(HBe," \u2014 "),LO=n(HBe,"A",{href:!0});var oAt=s(LO);fLo=r(oAt,"Data2VecAudioModel"),oAt.forEach(t),mLo=r(HBe," (Data2VecAudio model)"),HBe.forEach(t),gLo=i(x),f_=n(x,"LI",{});var JBe=s(f_);_ue=n(JBe,"STRONG",{});var rAt=s(_ue);hLo=r(rAt,"data2vec-text"),rAt.forEach(t),uLo=r(JBe," \u2014 "),yO=n(JBe,"A",{href:!0});var tAt=s(yO);pLo=r(tAt,"Data2VecTextModel"),tAt.forEach(t),_Lo=r(JBe," (Data2VecText model)"),JBe.forEach(t),vLo=i(x),m_=n(x,"LI",{});var YBe=s(m_);vue=n(YBe,"STRONG",{});var aAt=s(vue);bLo=r(aAt,"data2vec-vision"),aAt.forEach(t),FLo=r(YBe," \u2014 "),xO=n(YBe,"A",{href:!0});var nAt=s(xO);TLo=r(nAt,"Data2VecVisionModel"),nAt.forEach(t),MLo=r(YBe," (Data2VecVision model)"),YBe.forEach(t),ELo=i(x),g_=n(x,"LI",{});var KBe=s(g_);bue=n(KBe,"STRONG",{});var sAt=s(bue);CLo=r(sAt,"deberta"),sAt.forEach(t),wLo=r(KBe," \u2014 "),$O=n(KBe,"A",{href:!0});var lAt=s($O);ALo=r(lAt,"DebertaModel"),lAt.forEach(t),LLo=r(KBe," (DeBERTa model)"),KBe.forEach(t),yLo=i(x),h_=n(x,"LI",{});var ZBe=s(h_);Fue=n(ZBe,"STRONG",{});var iAt=s(Fue);xLo=r(iAt,"deberta-v2"),iAt.forEach(t),$Lo=r(ZBe," \u2014 "),kO=n(ZBe,"A",{href:!0});var dAt=s(kO);kLo=r(dAt,"DebertaV2Model"),dAt.forEach(t),SLo=r(ZBe," (DeBERTa-v2 model)"),ZBe.forEach(t),RLo=i(x),u_=n(x,"LI",{});var eIe=s(u_);Tue=n(eIe,"STRONG",{});var cAt=s(Tue);PLo=r(cAt,"decision_transformer"),cAt.forEach(t),BLo=r(eIe," \u2014 "),SO=n(eIe,"A",{href:!0});var fAt=s(SO);ILo=r(fAt,"DecisionTransformerModel"),fAt.forEach(t),NLo=r(eIe," (Decision Transformer model)"),eIe.forEach(t),qLo=i(x),p_=n(x,"LI",{});var oIe=s(p_);Mue=n(oIe,"STRONG",{});var mAt=s(Mue);jLo=r(mAt,"deit"),mAt.forEach(t),DLo=r(oIe," \u2014 "),RO=n(oIe,"A",{href:!0});var gAt=s(RO);GLo=r(gAt,"DeiTModel"),gAt.forEach(t),OLo=r(oIe," (DeiT model)"),oIe.forEach(t),VLo=i(x),__=n(x,"LI",{});var rIe=s(__);Eue=n(rIe,"STRONG",{});var hAt=s(Eue);XLo=r(hAt,"detr"),hAt.forEach(t),zLo=r(rIe," \u2014 "),PO=n(rIe,"A",{href:!0});var uAt=s(PO);QLo=r(uAt,"DetrModel"),uAt.forEach(t),WLo=r(rIe," (DETR model)"),rIe.forEach(t),ULo=i(x),v_=n(x,"LI",{});var tIe=s(v_);Cue=n(tIe,"STRONG",{});var pAt=s(Cue);HLo=r(pAt,"distilbert"),pAt.forEach(t),JLo=r(tIe," \u2014 "),BO=n(tIe,"A",{href:!0});var _At=s(BO);YLo=r(_At,"DistilBertModel"),_At.forEach(t),KLo=r(tIe," (DistilBERT model)"),tIe.forEach(t),ZLo=i(x),b_=n(x,"LI",{});var aIe=s(b_);wue=n(aIe,"STRONG",{});var vAt=s(wue);eyo=r(vAt,"donut-swin"),vAt.forEach(t),oyo=r(aIe," \u2014 "),IO=n(aIe,"A",{href:!0});var bAt=s(IO);ryo=r(bAt,"DonutSwinModel"),bAt.forEach(t),tyo=r(aIe," (DonutSwin model)"),aIe.forEach(t),ayo=i(x),F_=n(x,"LI",{});var nIe=s(F_);Aue=n(nIe,"STRONG",{});var FAt=s(Aue);nyo=r(FAt,"dpr"),FAt.forEach(t),syo=r(nIe," \u2014 "),NO=n(nIe,"A",{href:!0});var TAt=s(NO);lyo=r(TAt,"DPRQuestionEncoder"),TAt.forEach(t),iyo=r(nIe," (DPR model)"),nIe.forEach(t),dyo=i(x),T_=n(x,"LI",{});var sIe=s(T_);Lue=n(sIe,"STRONG",{});var MAt=s(Lue);cyo=r(MAt,"dpt"),MAt.forEach(t),fyo=r(sIe," \u2014 "),qO=n(sIe,"A",{href:!0});var EAt=s(qO);myo=r(EAt,"DPTModel"),EAt.forEach(t),gyo=r(sIe," (DPT model)"),sIe.forEach(t),hyo=i(x),M_=n(x,"LI",{});var lIe=s(M_);yue=n(lIe,"STRONG",{});var CAt=s(yue);uyo=r(CAt,"electra"),CAt.forEach(t),pyo=r(lIe," \u2014 "),jO=n(lIe,"A",{href:!0});var wAt=s(jO);_yo=r(wAt,"ElectraModel"),wAt.forEach(t),vyo=r(lIe," (ELECTRA model)"),lIe.forEach(t),byo=i(x),E_=n(x,"LI",{});var iIe=s(E_);xue=n(iIe,"STRONG",{});var AAt=s(xue);Fyo=r(AAt,"ernie"),AAt.forEach(t),Tyo=r(iIe," \u2014 "),DO=n(iIe,"A",{href:!0});var LAt=s(DO);Myo=r(LAt,"ErnieModel"),LAt.forEach(t),Eyo=r(iIe," (ERNIE model)"),iIe.forEach(t),Cyo=i(x),C_=n(x,"LI",{});var dIe=s(C_);$ue=n(dIe,"STRONG",{});var yAt=s($ue);wyo=r(yAt,"flaubert"),yAt.forEach(t),Ayo=r(dIe," \u2014 "),GO=n(dIe,"A",{href:!0});var xAt=s(GO);Lyo=r(xAt,"FlaubertModel"),xAt.forEach(t),yyo=r(dIe," (FlauBERT model)"),dIe.forEach(t),xyo=i(x),w_=n(x,"LI",{});var cIe=s(w_);kue=n(cIe,"STRONG",{});var $At=s(kue);$yo=r($At,"flava"),$At.forEach(t),kyo=r(cIe," \u2014 "),OO=n(cIe,"A",{href:!0});var kAt=s(OO);Syo=r(kAt,"FlavaModel"),kAt.forEach(t),Ryo=r(cIe," (FLAVA model)"),cIe.forEach(t),Pyo=i(x),A_=n(x,"LI",{});var fIe=s(A_);Sue=n(fIe,"STRONG",{});var SAt=s(Sue);Byo=r(SAt,"fnet"),SAt.forEach(t),Iyo=r(fIe," \u2014 "),VO=n(fIe,"A",{href:!0});var RAt=s(VO);Nyo=r(RAt,"FNetModel"),RAt.forEach(t),qyo=r(fIe," (FNet model)"),fIe.forEach(t),jyo=i(x),L_=n(x,"LI",{});var mIe=s(L_);Rue=n(mIe,"STRONG",{});var PAt=s(Rue);Dyo=r(PAt,"fsmt"),PAt.forEach(t),Gyo=r(mIe," \u2014 "),XO=n(mIe,"A",{href:!0});var BAt=s(XO);Oyo=r(BAt,"FSMTModel"),BAt.forEach(t),Vyo=r(mIe," (FairSeq Machine-Translation model)"),mIe.forEach(t),Xyo=i(x),pl=n(x,"LI",{});var bB=s(pl);Pue=n(bB,"STRONG",{});var IAt=s(Pue);zyo=r(IAt,"funnel"),IAt.forEach(t),Qyo=r(bB," \u2014 "),zO=n(bB,"A",{href:!0});var NAt=s(zO);Wyo=r(NAt,"FunnelModel"),NAt.forEach(t),Uyo=r(bB," or "),QO=n(bB,"A",{href:!0});var qAt=s(QO);Hyo=r(qAt,"FunnelBaseModel"),qAt.forEach(t),Jyo=r(bB," (Funnel Transformer model)"),bB.forEach(t),Yyo=i(x),y_=n(x,"LI",{});var gIe=s(y_);Bue=n(gIe,"STRONG",{});var jAt=s(Bue);Kyo=r(jAt,"glpn"),jAt.forEach(t),Zyo=r(gIe," \u2014 "),WO=n(gIe,"A",{href:!0});var DAt=s(WO);e8o=r(DAt,"GLPNModel"),DAt.forEach(t),o8o=r(gIe," (GLPN model)"),gIe.forEach(t),r8o=i(x),x_=n(x,"LI",{});var hIe=s(x_);Iue=n(hIe,"STRONG",{});var GAt=s(Iue);t8o=r(GAt,"gpt2"),GAt.forEach(t),a8o=r(hIe," \u2014 "),UO=n(hIe,"A",{href:!0});var OAt=s(UO);n8o=r(OAt,"GPT2Model"),OAt.forEach(t),s8o=r(hIe," (OpenAI GPT-2 model)"),hIe.forEach(t),l8o=i(x),$_=n(x,"LI",{});var uIe=s($_);Nue=n(uIe,"STRONG",{});var VAt=s(Nue);i8o=r(VAt,"gpt_neo"),VAt.forEach(t),d8o=r(uIe," \u2014 "),HO=n(uIe,"A",{href:!0});var XAt=s(HO);c8o=r(XAt,"GPTNeoModel"),XAt.forEach(t),f8o=r(uIe," (GPT Neo model)"),uIe.forEach(t),m8o=i(x),k_=n(x,"LI",{});var pIe=s(k_);que=n(pIe,"STRONG",{});var zAt=s(que);g8o=r(zAt,"gpt_neox"),zAt.forEach(t),h8o=r(pIe," \u2014 "),JO=n(pIe,"A",{href:!0});var QAt=s(JO);u8o=r(QAt,"GPTNeoXModel"),QAt.forEach(t),p8o=r(pIe," (GPT NeoX model)"),pIe.forEach(t),_8o=i(x),S_=n(x,"LI",{});var _Ie=s(S_);jue=n(_Ie,"STRONG",{});var WAt=s(jue);v8o=r(WAt,"gptj"),WAt.forEach(t),b8o=r(_Ie," \u2014 "),YO=n(_Ie,"A",{href:!0});var UAt=s(YO);F8o=r(UAt,"GPTJModel"),UAt.forEach(t),T8o=r(_Ie," (GPT-J model)"),_Ie.forEach(t),M8o=i(x),R_=n(x,"LI",{});var vIe=s(R_);Due=n(vIe,"STRONG",{});var HAt=s(Due);E8o=r(HAt,"groupvit"),HAt.forEach(t),C8o=r(vIe," \u2014 "),KO=n(vIe,"A",{href:!0});var JAt=s(KO);w8o=r(JAt,"GroupViTModel"),JAt.forEach(t),A8o=r(vIe," (GroupViT model)"),vIe.forEach(t),L8o=i(x),P_=n(x,"LI",{});var bIe=s(P_);Gue=n(bIe,"STRONG",{});var YAt=s(Gue);y8o=r(YAt,"hubert"),YAt.forEach(t),x8o=r(bIe," \u2014 "),ZO=n(bIe,"A",{href:!0});var KAt=s(ZO);$8o=r(KAt,"HubertModel"),KAt.forEach(t),k8o=r(bIe," (Hubert model)"),bIe.forEach(t),S8o=i(x),B_=n(x,"LI",{});var FIe=s(B_);Oue=n(FIe,"STRONG",{});var ZAt=s(Oue);R8o=r(ZAt,"ibert"),ZAt.forEach(t),P8o=r(FIe," \u2014 "),eV=n(FIe,"A",{href:!0});var e6t=s(eV);B8o=r(e6t,"IBertModel"),e6t.forEach(t),I8o=r(FIe," (I-BERT model)"),FIe.forEach(t),N8o=i(x),I_=n(x,"LI",{});var TIe=s(I_);Vue=n(TIe,"STRONG",{});var o6t=s(Vue);q8o=r(o6t,"imagegpt"),o6t.forEach(t),j8o=r(TIe," \u2014 "),oV=n(TIe,"A",{href:!0});var r6t=s(oV);D8o=r(r6t,"ImageGPTModel"),r6t.forEach(t),G8o=r(TIe," (ImageGPT model)"),TIe.forEach(t),O8o=i(x),N_=n(x,"LI",{});var MIe=s(N_);Xue=n(MIe,"STRONG",{});var t6t=s(Xue);V8o=r(t6t,"layoutlm"),t6t.forEach(t),X8o=r(MIe," \u2014 "),rV=n(MIe,"A",{href:!0});var a6t=s(rV);z8o=r(a6t,"LayoutLMModel"),a6t.forEach(t),Q8o=r(MIe," (LayoutLM model)"),MIe.forEach(t),W8o=i(x),q_=n(x,"LI",{});var EIe=s(q_);zue=n(EIe,"STRONG",{});var n6t=s(zue);U8o=r(n6t,"layoutlmv2"),n6t.forEach(t),H8o=r(EIe," \u2014 "),tV=n(EIe,"A",{href:!0});var s6t=s(tV);J8o=r(s6t,"LayoutLMv2Model"),s6t.forEach(t),Y8o=r(EIe," (LayoutLMv2 model)"),EIe.forEach(t),K8o=i(x),j_=n(x,"LI",{});var CIe=s(j_);Que=n(CIe,"STRONG",{});var l6t=s(Que);Z8o=r(l6t,"layoutlmv3"),l6t.forEach(t),e9o=r(CIe," \u2014 "),aV=n(CIe,"A",{href:!0});var i6t=s(aV);o9o=r(i6t,"LayoutLMv3Model"),i6t.forEach(t),r9o=r(CIe," (LayoutLMv3 model)"),CIe.forEach(t),t9o=i(x),D_=n(x,"LI",{});var wIe=s(D_);Wue=n(wIe,"STRONG",{});var d6t=s(Wue);a9o=r(d6t,"led"),d6t.forEach(t),n9o=r(wIe," \u2014 "),nV=n(wIe,"A",{href:!0});var c6t=s(nV);s9o=r(c6t,"LEDModel"),c6t.forEach(t),l9o=r(wIe," (LED model)"),wIe.forEach(t),i9o=i(x),G_=n(x,"LI",{});var AIe=s(G_);Uue=n(AIe,"STRONG",{});var f6t=s(Uue);d9o=r(f6t,"levit"),f6t.forEach(t),c9o=r(AIe," \u2014 "),sV=n(AIe,"A",{href:!0});var m6t=s(sV);f9o=r(m6t,"LevitModel"),m6t.forEach(t),m9o=r(AIe," (LeViT model)"),AIe.forEach(t),g9o=i(x),O_=n(x,"LI",{});var LIe=s(O_);Hue=n(LIe,"STRONG",{});var g6t=s(Hue);h9o=r(g6t,"longformer"),g6t.forEach(t),u9o=r(LIe," \u2014 "),lV=n(LIe,"A",{href:!0});var h6t=s(lV);p9o=r(h6t,"LongformerModel"),h6t.forEach(t),_9o=r(LIe," (Longformer model)"),LIe.forEach(t),v9o=i(x),V_=n(x,"LI",{});var yIe=s(V_);Jue=n(yIe,"STRONG",{});var u6t=s(Jue);b9o=r(u6t,"longt5"),u6t.forEach(t),F9o=r(yIe," \u2014 "),iV=n(yIe,"A",{href:!0});var p6t=s(iV);T9o=r(p6t,"LongT5Model"),p6t.forEach(t),M9o=r(yIe," (LongT5 model)"),yIe.forEach(t),E9o=i(x),X_=n(x,"LI",{});var xIe=s(X_);Yue=n(xIe,"STRONG",{});var _6t=s(Yue);C9o=r(_6t,"luke"),_6t.forEach(t),w9o=r(xIe," \u2014 "),dV=n(xIe,"A",{href:!0});var v6t=s(dV);A9o=r(v6t,"LukeModel"),v6t.forEach(t),L9o=r(xIe," (LUKE model)"),xIe.forEach(t),y9o=i(x),z_=n(x,"LI",{});var $Ie=s(z_);Kue=n($Ie,"STRONG",{});var b6t=s(Kue);x9o=r(b6t,"lxmert"),b6t.forEach(t),$9o=r($Ie," \u2014 "),cV=n($Ie,"A",{href:!0});var F6t=s(cV);k9o=r(F6t,"LxmertModel"),F6t.forEach(t),S9o=r($Ie," (LXMERT model)"),$Ie.forEach(t),R9o=i(x),Q_=n(x,"LI",{});var kIe=s(Q_);Zue=n(kIe,"STRONG",{});var T6t=s(Zue);P9o=r(T6t,"m2m_100"),T6t.forEach(t),B9o=r(kIe," \u2014 "),fV=n(kIe,"A",{href:!0});var M6t=s(fV);I9o=r(M6t,"M2M100Model"),M6t.forEach(t),N9o=r(kIe," (M2M100 model)"),kIe.forEach(t),q9o=i(x),W_=n(x,"LI",{});var SIe=s(W_);epe=n(SIe,"STRONG",{});var E6t=s(epe);j9o=r(E6t,"marian"),E6t.forEach(t),D9o=r(SIe," \u2014 "),mV=n(SIe,"A",{href:!0});var C6t=s(mV);G9o=r(C6t,"MarianModel"),C6t.forEach(t),O9o=r(SIe," (Marian model)"),SIe.forEach(t),V9o=i(x),U_=n(x,"LI",{});var RIe=s(U_);ope=n(RIe,"STRONG",{});var w6t=s(ope);X9o=r(w6t,"maskformer"),w6t.forEach(t),z9o=r(RIe," \u2014 "),gV=n(RIe,"A",{href:!0});var A6t=s(gV);Q9o=r(A6t,"MaskFormerModel"),A6t.forEach(t),W9o=r(RIe," (MaskFormer model)"),RIe.forEach(t),U9o=i(x),H_=n(x,"LI",{});var PIe=s(H_);rpe=n(PIe,"STRONG",{});var L6t=s(rpe);H9o=r(L6t,"mbart"),L6t.forEach(t),J9o=r(PIe," \u2014 "),hV=n(PIe,"A",{href:!0});var y6t=s(hV);Y9o=r(y6t,"MBartModel"),y6t.forEach(t),K9o=r(PIe," (mBART model)"),PIe.forEach(t),Z9o=i(x),J_=n(x,"LI",{});var BIe=s(J_);tpe=n(BIe,"STRONG",{});var x6t=s(tpe);exo=r(x6t,"mctct"),x6t.forEach(t),oxo=r(BIe," \u2014 "),uV=n(BIe,"A",{href:!0});var $6t=s(uV);rxo=r($6t,"MCTCTModel"),$6t.forEach(t),txo=r(BIe," (M-CTC-T model)"),BIe.forEach(t),axo=i(x),Y_=n(x,"LI",{});var IIe=s(Y_);ape=n(IIe,"STRONG",{});var k6t=s(ape);nxo=r(k6t,"megatron-bert"),k6t.forEach(t),sxo=r(IIe," \u2014 "),pV=n(IIe,"A",{href:!0});var S6t=s(pV);lxo=r(S6t,"MegatronBertModel"),S6t.forEach(t),ixo=r(IIe," (Megatron-BERT model)"),IIe.forEach(t),dxo=i(x),K_=n(x,"LI",{});var NIe=s(K_);npe=n(NIe,"STRONG",{});var R6t=s(npe);cxo=r(R6t,"mobilebert"),R6t.forEach(t),fxo=r(NIe," \u2014 "),_V=n(NIe,"A",{href:!0});var P6t=s(_V);mxo=r(P6t,"MobileBertModel"),P6t.forEach(t),gxo=r(NIe," (MobileBERT model)"),NIe.forEach(t),hxo=i(x),Z_=n(x,"LI",{});var qIe=s(Z_);spe=n(qIe,"STRONG",{});var B6t=s(spe);uxo=r(B6t,"mobilevit"),B6t.forEach(t),pxo=r(qIe," \u2014 "),vV=n(qIe,"A",{href:!0});var I6t=s(vV);_xo=r(I6t,"MobileViTModel"),I6t.forEach(t),vxo=r(qIe," (MobileViT model)"),qIe.forEach(t),bxo=i(x),e2=n(x,"LI",{});var jIe=s(e2);lpe=n(jIe,"STRONG",{});var N6t=s(lpe);Fxo=r(N6t,"mpnet"),N6t.forEach(t),Txo=r(jIe," \u2014 "),bV=n(jIe,"A",{href:!0});var q6t=s(bV);Mxo=r(q6t,"MPNetModel"),q6t.forEach(t),Exo=r(jIe," (MPNet model)"),jIe.forEach(t),Cxo=i(x),o2=n(x,"LI",{});var DIe=s(o2);ipe=n(DIe,"STRONG",{});var j6t=s(ipe);wxo=r(j6t,"mt5"),j6t.forEach(t),Axo=r(DIe," \u2014 "),FV=n(DIe,"A",{href:!0});var D6t=s(FV);Lxo=r(D6t,"MT5Model"),D6t.forEach(t),yxo=r(DIe," (MT5 model)"),DIe.forEach(t),xxo=i(x),r2=n(x,"LI",{});var GIe=s(r2);dpe=n(GIe,"STRONG",{});var G6t=s(dpe);$xo=r(G6t,"mvp"),G6t.forEach(t),kxo=r(GIe," \u2014 "),TV=n(GIe,"A",{href:!0});var O6t=s(TV);Sxo=r(O6t,"MvpModel"),O6t.forEach(t),Rxo=r(GIe," (MVP model)"),GIe.forEach(t),Pxo=i(x),t2=n(x,"LI",{});var OIe=s(t2);cpe=n(OIe,"STRONG",{});var V6t=s(cpe);Bxo=r(V6t,"nezha"),V6t.forEach(t),Ixo=r(OIe," \u2014 "),MV=n(OIe,"A",{href:!0});var X6t=s(MV);Nxo=r(X6t,"NezhaModel"),X6t.forEach(t),qxo=r(OIe," (Nezha model)"),OIe.forEach(t),jxo=i(x),a2=n(x,"LI",{});var VIe=s(a2);fpe=n(VIe,"STRONG",{});var z6t=s(fpe);Dxo=r(z6t,"nllb"),z6t.forEach(t),Gxo=r(VIe," \u2014 "),EV=n(VIe,"A",{href:!0});var Q6t=s(EV);Oxo=r(Q6t,"M2M100Model"),Q6t.forEach(t),Vxo=r(VIe," (NLLB model)"),VIe.forEach(t),Xxo=i(x),n2=n(x,"LI",{});var XIe=s(n2);mpe=n(XIe,"STRONG",{});var W6t=s(mpe);zxo=r(W6t,"nystromformer"),W6t.forEach(t),Qxo=r(XIe," \u2014 "),CV=n(XIe,"A",{href:!0});var U6t=s(CV);Wxo=r(U6t,"NystromformerModel"),U6t.forEach(t),Uxo=r(XIe," (Nystr\xF6mformer model)"),XIe.forEach(t),Hxo=i(x),s2=n(x,"LI",{});var zIe=s(s2);gpe=n(zIe,"STRONG",{});var H6t=s(gpe);Jxo=r(H6t,"openai-gpt"),H6t.forEach(t),Yxo=r(zIe," \u2014 "),wV=n(zIe,"A",{href:!0});var J6t=s(wV);Kxo=r(J6t,"OpenAIGPTModel"),J6t.forEach(t),Zxo=r(zIe," (OpenAI GPT model)"),zIe.forEach(t),e$o=i(x),l2=n(x,"LI",{});var QIe=s(l2);hpe=n(QIe,"STRONG",{});var Y6t=s(hpe);o$o=r(Y6t,"opt"),Y6t.forEach(t),r$o=r(QIe," \u2014 "),AV=n(QIe,"A",{href:!0});var K6t=s(AV);t$o=r(K6t,"OPTModel"),K6t.forEach(t),a$o=r(QIe," (OPT model)"),QIe.forEach(t),n$o=i(x),i2=n(x,"LI",{});var WIe=s(i2);upe=n(WIe,"STRONG",{});var Z6t=s(upe);s$o=r(Z6t,"owlvit"),Z6t.forEach(t),l$o=r(WIe," \u2014 "),LV=n(WIe,"A",{href:!0});var e7t=s(LV);i$o=r(e7t,"OwlViTModel"),e7t.forEach(t),d$o=r(WIe," (OWL-ViT model)"),WIe.forEach(t),c$o=i(x),d2=n(x,"LI",{});var UIe=s(d2);ppe=n(UIe,"STRONG",{});var o7t=s(ppe);f$o=r(o7t,"pegasus"),o7t.forEach(t),m$o=r(UIe," \u2014 "),yV=n(UIe,"A",{href:!0});var r7t=s(yV);g$o=r(r7t,"PegasusModel"),r7t.forEach(t),h$o=r(UIe," (Pegasus model)"),UIe.forEach(t),u$o=i(x),c2=n(x,"LI",{});var HIe=s(c2);_pe=n(HIe,"STRONG",{});var t7t=s(_pe);p$o=r(t7t,"pegasus_x"),t7t.forEach(t),_$o=r(HIe," \u2014 "),xV=n(HIe,"A",{href:!0});var a7t=s(xV);v$o=r(a7t,"PegasusXModel"),a7t.forEach(t),b$o=r(HIe," (PEGASUS-X model)"),HIe.forEach(t),F$o=i(x),f2=n(x,"LI",{});var JIe=s(f2);vpe=n(JIe,"STRONG",{});var n7t=s(vpe);T$o=r(n7t,"perceiver"),n7t.forEach(t),M$o=r(JIe," \u2014 "),$V=n(JIe,"A",{href:!0});var s7t=s($V);E$o=r(s7t,"PerceiverModel"),s7t.forEach(t),C$o=r(JIe," (Perceiver model)"),JIe.forEach(t),w$o=i(x),m2=n(x,"LI",{});var YIe=s(m2);bpe=n(YIe,"STRONG",{});var l7t=s(bpe);A$o=r(l7t,"plbart"),l7t.forEach(t),L$o=r(YIe," \u2014 "),kV=n(YIe,"A",{href:!0});var i7t=s(kV);y$o=r(i7t,"PLBartModel"),i7t.forEach(t),x$o=r(YIe," (PLBart model)"),YIe.forEach(t),$$o=i(x),g2=n(x,"LI",{});var KIe=s(g2);Fpe=n(KIe,"STRONG",{});var d7t=s(Fpe);k$o=r(d7t,"poolformer"),d7t.forEach(t),S$o=r(KIe," \u2014 "),SV=n(KIe,"A",{href:!0});var c7t=s(SV);R$o=r(c7t,"PoolFormerModel"),c7t.forEach(t),P$o=r(KIe," (PoolFormer model)"),KIe.forEach(t),B$o=i(x),h2=n(x,"LI",{});var ZIe=s(h2);Tpe=n(ZIe,"STRONG",{});var f7t=s(Tpe);I$o=r(f7t,"prophetnet"),f7t.forEach(t),N$o=r(ZIe," \u2014 "),RV=n(ZIe,"A",{href:!0});var m7t=s(RV);q$o=r(m7t,"ProphetNetModel"),m7t.forEach(t),j$o=r(ZIe," (ProphetNet model)"),ZIe.forEach(t),D$o=i(x),u2=n(x,"LI",{});var eNe=s(u2);Mpe=n(eNe,"STRONG",{});var g7t=s(Mpe);G$o=r(g7t,"qdqbert"),g7t.forEach(t),O$o=r(eNe," \u2014 "),PV=n(eNe,"A",{href:!0});var h7t=s(PV);V$o=r(h7t,"QDQBertModel"),h7t.forEach(t),X$o=r(eNe," (QDQBert model)"),eNe.forEach(t),z$o=i(x),p2=n(x,"LI",{});var oNe=s(p2);Epe=n(oNe,"STRONG",{});var u7t=s(Epe);Q$o=r(u7t,"reformer"),u7t.forEach(t),W$o=r(oNe," \u2014 "),BV=n(oNe,"A",{href:!0});var p7t=s(BV);U$o=r(p7t,"ReformerModel"),p7t.forEach(t),H$o=r(oNe," (Reformer model)"),oNe.forEach(t),J$o=i(x),_2=n(x,"LI",{});var rNe=s(_2);Cpe=n(rNe,"STRONG",{});var _7t=s(Cpe);Y$o=r(_7t,"regnet"),_7t.forEach(t),K$o=r(rNe," \u2014 "),IV=n(rNe,"A",{href:!0});var v7t=s(IV);Z$o=r(v7t,"RegNetModel"),v7t.forEach(t),eko=r(rNe," (RegNet model)"),rNe.forEach(t),oko=i(x),v2=n(x,"LI",{});var tNe=s(v2);wpe=n(tNe,"STRONG",{});var b7t=s(wpe);rko=r(b7t,"rembert"),b7t.forEach(t),tko=r(tNe," \u2014 "),NV=n(tNe,"A",{href:!0});var F7t=s(NV);ako=r(F7t,"RemBertModel"),F7t.forEach(t),nko=r(tNe," (RemBERT model)"),tNe.forEach(t),sko=i(x),b2=n(x,"LI",{});var aNe=s(b2);Ape=n(aNe,"STRONG",{});var T7t=s(Ape);lko=r(T7t,"resnet"),T7t.forEach(t),iko=r(aNe," \u2014 "),qV=n(aNe,"A",{href:!0});var M7t=s(qV);dko=r(M7t,"ResNetModel"),M7t.forEach(t),cko=r(aNe," (ResNet model)"),aNe.forEach(t),fko=i(x),F2=n(x,"LI",{});var nNe=s(F2);Lpe=n(nNe,"STRONG",{});var E7t=s(Lpe);mko=r(E7t,"retribert"),E7t.forEach(t),gko=r(nNe," \u2014 "),jV=n(nNe,"A",{href:!0});var C7t=s(jV);hko=r(C7t,"RetriBertModel"),C7t.forEach(t),uko=r(nNe," (RetriBERT model)"),nNe.forEach(t),pko=i(x),T2=n(x,"LI",{});var sNe=s(T2);ype=n(sNe,"STRONG",{});var w7t=s(ype);_ko=r(w7t,"roberta"),w7t.forEach(t),vko=r(sNe," \u2014 "),DV=n(sNe,"A",{href:!0});var A7t=s(DV);bko=r(A7t,"RobertaModel"),A7t.forEach(t),Fko=r(sNe," (RoBERTa model)"),sNe.forEach(t),Tko=i(x),M2=n(x,"LI",{});var lNe=s(M2);xpe=n(lNe,"STRONG",{});var L7t=s(xpe);Mko=r(L7t,"roformer"),L7t.forEach(t),Eko=r(lNe," \u2014 "),GV=n(lNe,"A",{href:!0});var y7t=s(GV);Cko=r(y7t,"RoFormerModel"),y7t.forEach(t),wko=r(lNe," (RoFormer model)"),lNe.forEach(t),Ako=i(x),E2=n(x,"LI",{});var iNe=s(E2);$pe=n(iNe,"STRONG",{});var x7t=s($pe);Lko=r(x7t,"segformer"),x7t.forEach(t),yko=r(iNe," \u2014 "),OV=n(iNe,"A",{href:!0});var $7t=s(OV);xko=r($7t,"SegformerModel"),$7t.forEach(t),$ko=r(iNe," (SegFormer model)"),iNe.forEach(t),kko=i(x),C2=n(x,"LI",{});var dNe=s(C2);kpe=n(dNe,"STRONG",{});var k7t=s(kpe);Sko=r(k7t,"sew"),k7t.forEach(t),Rko=r(dNe," \u2014 "),VV=n(dNe,"A",{href:!0});var S7t=s(VV);Pko=r(S7t,"SEWModel"),S7t.forEach(t),Bko=r(dNe," (SEW model)"),dNe.forEach(t),Iko=i(x),w2=n(x,"LI",{});var cNe=s(w2);Spe=n(cNe,"STRONG",{});var R7t=s(Spe);Nko=r(R7t,"sew-d"),R7t.forEach(t),qko=r(cNe," \u2014 "),XV=n(cNe,"A",{href:!0});var P7t=s(XV);jko=r(P7t,"SEWDModel"),P7t.forEach(t),Dko=r(cNe," (SEW-D model)"),cNe.forEach(t),Gko=i(x),A2=n(x,"LI",{});var fNe=s(A2);Rpe=n(fNe,"STRONG",{});var B7t=s(Rpe);Oko=r(B7t,"speech_to_text"),B7t.forEach(t),Vko=r(fNe," \u2014 "),zV=n(fNe,"A",{href:!0});var I7t=s(zV);Xko=r(I7t,"Speech2TextModel"),I7t.forEach(t),zko=r(fNe," (Speech2Text model)"),fNe.forEach(t),Qko=i(x),L2=n(x,"LI",{});var mNe=s(L2);Ppe=n(mNe,"STRONG",{});var N7t=s(Ppe);Wko=r(N7t,"splinter"),N7t.forEach(t),Uko=r(mNe," \u2014 "),QV=n(mNe,"A",{href:!0});var q7t=s(QV);Hko=r(q7t,"SplinterModel"),q7t.forEach(t),Jko=r(mNe," (Splinter model)"),mNe.forEach(t),Yko=i(x),y2=n(x,"LI",{});var gNe=s(y2);Bpe=n(gNe,"STRONG",{});var j7t=s(Bpe);Kko=r(j7t,"squeezebert"),j7t.forEach(t),Zko=r(gNe," \u2014 "),WV=n(gNe,"A",{href:!0});var D7t=s(WV);eSo=r(D7t,"SqueezeBertModel"),D7t.forEach(t),oSo=r(gNe," (SqueezeBERT model)"),gNe.forEach(t),rSo=i(x),x2=n(x,"LI",{});var hNe=s(x2);Ipe=n(hNe,"STRONG",{});var G7t=s(Ipe);tSo=r(G7t,"swin"),G7t.forEach(t),aSo=r(hNe," \u2014 "),UV=n(hNe,"A",{href:!0});var O7t=s(UV);nSo=r(O7t,"SwinModel"),O7t.forEach(t),sSo=r(hNe," (Swin Transformer model)"),hNe.forEach(t),lSo=i(x),$2=n(x,"LI",{});var uNe=s($2);Npe=n(uNe,"STRONG",{});var V7t=s(Npe);iSo=r(V7t,"swinv2"),V7t.forEach(t),dSo=r(uNe," \u2014 "),HV=n(uNe,"A",{href:!0});var X7t=s(HV);cSo=r(X7t,"Swinv2Model"),X7t.forEach(t),fSo=r(uNe," (Swin Transformer V2 model)"),uNe.forEach(t),mSo=i(x),k2=n(x,"LI",{});var pNe=s(k2);qpe=n(pNe,"STRONG",{});var z7t=s(qpe);gSo=r(z7t,"t5"),z7t.forEach(t),hSo=r(pNe," \u2014 "),JV=n(pNe,"A",{href:!0});var Q7t=s(JV);uSo=r(Q7t,"T5Model"),Q7t.forEach(t),pSo=r(pNe," (T5 model)"),pNe.forEach(t),_So=i(x),S2=n(x,"LI",{});var _Ne=s(S2);jpe=n(_Ne,"STRONG",{});var W7t=s(jpe);vSo=r(W7t,"tapas"),W7t.forEach(t),bSo=r(_Ne," \u2014 "),YV=n(_Ne,"A",{href:!0});var U7t=s(YV);FSo=r(U7t,"TapasModel"),U7t.forEach(t),TSo=r(_Ne," (TAPAS model)"),_Ne.forEach(t),MSo=i(x),R2=n(x,"LI",{});var vNe=s(R2);Dpe=n(vNe,"STRONG",{});var H7t=s(Dpe);ESo=r(H7t,"trajectory_transformer"),H7t.forEach(t),CSo=r(vNe," \u2014 "),KV=n(vNe,"A",{href:!0});var J7t=s(KV);wSo=r(J7t,"TrajectoryTransformerModel"),J7t.forEach(t),ASo=r(vNe," (Trajectory Transformer model)"),vNe.forEach(t),LSo=i(x),P2=n(x,"LI",{});var bNe=s(P2);Gpe=n(bNe,"STRONG",{});var Y7t=s(Gpe);ySo=r(Y7t,"transfo-xl"),Y7t.forEach(t),xSo=r(bNe," \u2014 "),ZV=n(bNe,"A",{href:!0});var K7t=s(ZV);$So=r(K7t,"TransfoXLModel"),K7t.forEach(t),kSo=r(bNe," (Transformer-XL model)"),bNe.forEach(t),SSo=i(x),B2=n(x,"LI",{});var FNe=s(B2);Ope=n(FNe,"STRONG",{});var Z7t=s(Ope);RSo=r(Z7t,"unispeech"),Z7t.forEach(t),PSo=r(FNe," \u2014 "),eX=n(FNe,"A",{href:!0});var eLt=s(eX);BSo=r(eLt,"UniSpeechModel"),eLt.forEach(t),ISo=r(FNe," (UniSpeech model)"),FNe.forEach(t),NSo=i(x),I2=n(x,"LI",{});var TNe=s(I2);Vpe=n(TNe,"STRONG",{});var oLt=s(Vpe);qSo=r(oLt,"unispeech-sat"),oLt.forEach(t),jSo=r(TNe," \u2014 "),oX=n(TNe,"A",{href:!0});var rLt=s(oX);DSo=r(rLt,"UniSpeechSatModel"),rLt.forEach(t),GSo=r(TNe," (UniSpeechSat model)"),TNe.forEach(t),OSo=i(x),N2=n(x,"LI",{});var MNe=s(N2);Xpe=n(MNe,"STRONG",{});var tLt=s(Xpe);VSo=r(tLt,"van"),tLt.forEach(t),XSo=r(MNe," \u2014 "),rX=n(MNe,"A",{href:!0});var aLt=s(rX);zSo=r(aLt,"VanModel"),aLt.forEach(t),QSo=r(MNe," (VAN model)"),MNe.forEach(t),WSo=i(x),q2=n(x,"LI",{});var ENe=s(q2);zpe=n(ENe,"STRONG",{});var nLt=s(zpe);USo=r(nLt,"videomae"),nLt.forEach(t),HSo=r(ENe," \u2014 "),tX=n(ENe,"A",{href:!0});var sLt=s(tX);JSo=r(sLt,"VideoMAEModel"),sLt.forEach(t),YSo=r(ENe," (VideoMAE model)"),ENe.forEach(t),KSo=i(x),j2=n(x,"LI",{});var CNe=s(j2);Qpe=n(CNe,"STRONG",{});var lLt=s(Qpe);ZSo=r(lLt,"vilt"),lLt.forEach(t),eRo=r(CNe," \u2014 "),aX=n(CNe,"A",{href:!0});var iLt=s(aX);oRo=r(iLt,"ViltModel"),iLt.forEach(t),rRo=r(CNe," (ViLT model)"),CNe.forEach(t),tRo=i(x),D2=n(x,"LI",{});var wNe=s(D2);Wpe=n(wNe,"STRONG",{});var dLt=s(Wpe);aRo=r(dLt,"vision-text-dual-encoder"),dLt.forEach(t),nRo=r(wNe," \u2014 "),nX=n(wNe,"A",{href:!0});var cLt=s(nX);sRo=r(cLt,"VisionTextDualEncoderModel"),cLt.forEach(t),lRo=r(wNe," (VisionTextDualEncoder model)"),wNe.forEach(t),iRo=i(x),G2=n(x,"LI",{});var ANe=s(G2);Upe=n(ANe,"STRONG",{});var fLt=s(Upe);dRo=r(fLt,"visual_bert"),fLt.forEach(t),cRo=r(ANe," \u2014 "),sX=n(ANe,"A",{href:!0});var mLt=s(sX);fRo=r(mLt,"VisualBertModel"),mLt.forEach(t),mRo=r(ANe," (VisualBERT model)"),ANe.forEach(t),gRo=i(x),O2=n(x,"LI",{});var LNe=s(O2);Hpe=n(LNe,"STRONG",{});var gLt=s(Hpe);hRo=r(gLt,"vit"),gLt.forEach(t),uRo=r(LNe," \u2014 "),lX=n(LNe,"A",{href:!0});var hLt=s(lX);pRo=r(hLt,"ViTModel"),hLt.forEach(t),_Ro=r(LNe," (ViT model)"),LNe.forEach(t),vRo=i(x),V2=n(x,"LI",{});var yNe=s(V2);Jpe=n(yNe,"STRONG",{});var uLt=s(Jpe);bRo=r(uLt,"vit_mae"),uLt.forEach(t),FRo=r(yNe," \u2014 "),iX=n(yNe,"A",{href:!0});var pLt=s(iX);TRo=r(pLt,"ViTMAEModel"),pLt.forEach(t),MRo=r(yNe," (ViTMAE model)"),yNe.forEach(t),ERo=i(x),X2=n(x,"LI",{});var xNe=s(X2);Ype=n(xNe,"STRONG",{});var _Lt=s(Ype);CRo=r(_Lt,"wav2vec2"),_Lt.forEach(t),wRo=r(xNe," \u2014 "),dX=n(xNe,"A",{href:!0});var vLt=s(dX);ARo=r(vLt,"Wav2Vec2Model"),vLt.forEach(t),LRo=r(xNe," (Wav2Vec2 model)"),xNe.forEach(t),yRo=i(x),z2=n(x,"LI",{});var $Ne=s(z2);Kpe=n($Ne,"STRONG",{});var bLt=s(Kpe);xRo=r(bLt,"wav2vec2-conformer"),bLt.forEach(t),$Ro=r($Ne," \u2014 "),cX=n($Ne,"A",{href:!0});var FLt=s(cX);kRo=r(FLt,"Wav2Vec2ConformerModel"),FLt.forEach(t),SRo=r($Ne," (Wav2Vec2-Conformer model)"),$Ne.forEach(t),RRo=i(x),Q2=n(x,"LI",{});var kNe=s(Q2);Zpe=n(kNe,"STRONG",{});var TLt=s(Zpe);PRo=r(TLt,"wavlm"),TLt.forEach(t),BRo=r(kNe," \u2014 "),fX=n(kNe,"A",{href:!0});var MLt=s(fX);IRo=r(MLt,"WavLMModel"),MLt.forEach(t),NRo=r(kNe," (WavLM model)"),kNe.forEach(t),qRo=i(x),W2=n(x,"LI",{});var SNe=s(W2);e_e=n(SNe,"STRONG",{});var ELt=s(e_e);jRo=r(ELt,"xclip"),ELt.forEach(t),DRo=r(SNe," \u2014 "),mX=n(SNe,"A",{href:!0});var CLt=s(mX);GRo=r(CLt,"XCLIPModel"),CLt.forEach(t),ORo=r(SNe," (X-CLIP model)"),SNe.forEach(t),VRo=i(x),U2=n(x,"LI",{});var RNe=s(U2);o_e=n(RNe,"STRONG",{});var wLt=s(o_e);XRo=r(wLt,"xglm"),wLt.forEach(t),zRo=r(RNe," \u2014 "),gX=n(RNe,"A",{href:!0});var ALt=s(gX);QRo=r(ALt,"XGLMModel"),ALt.forEach(t),WRo=r(RNe," (XGLM model)"),RNe.forEach(t),URo=i(x),H2=n(x,"LI",{});var PNe=s(H2);r_e=n(PNe,"STRONG",{});var LLt=s(r_e);HRo=r(LLt,"xlm"),LLt.forEach(t),JRo=r(PNe," \u2014 "),hX=n(PNe,"A",{href:!0});var yLt=s(hX);YRo=r(yLt,"XLMModel"),yLt.forEach(t),KRo=r(PNe," (XLM model)"),PNe.forEach(t),ZRo=i(x),J2=n(x,"LI",{});var BNe=s(J2);t_e=n(BNe,"STRONG",{});var xLt=s(t_e);ePo=r(xLt,"xlm-prophetnet"),xLt.forEach(t),oPo=r(BNe," \u2014 "),uX=n(BNe,"A",{href:!0});var $Lt=s(uX);rPo=r($Lt,"XLMProphetNetModel"),$Lt.forEach(t),tPo=r(BNe," (XLM-ProphetNet model)"),BNe.forEach(t),aPo=i(x),Y2=n(x,"LI",{});var INe=s(Y2);a_e=n(INe,"STRONG",{});var kLt=s(a_e);nPo=r(kLt,"xlm-roberta"),kLt.forEach(t),sPo=r(INe," \u2014 "),pX=n(INe,"A",{href:!0});var SLt=s(pX);lPo=r(SLt,"XLMRobertaModel"),SLt.forEach(t),iPo=r(INe," (XLM-RoBERTa model)"),INe.forEach(t),dPo=i(x),K2=n(x,"LI",{});var NNe=s(K2);n_e=n(NNe,"STRONG",{});var RLt=s(n_e);cPo=r(RLt,"xlm-roberta-xl"),RLt.forEach(t),fPo=r(NNe," \u2014 "),_X=n(NNe,"A",{href:!0});var PLt=s(_X);mPo=r(PLt,"XLMRobertaXLModel"),PLt.forEach(t),gPo=r(NNe," (XLM-RoBERTa-XL model)"),NNe.forEach(t),hPo=i(x),Z2=n(x,"LI",{});var qNe=s(Z2);s_e=n(qNe,"STRONG",{});var BLt=s(s_e);uPo=r(BLt,"xlnet"),BLt.forEach(t),pPo=r(qNe," \u2014 "),vX=n(qNe,"A",{href:!0});var ILt=s(vX);_Po=r(ILt,"XLNetModel"),ILt.forEach(t),vPo=r(qNe," (XLNet model)"),qNe.forEach(t),bPo=i(x),ev=n(x,"LI",{});var jNe=s(ev);l_e=n(jNe,"STRONG",{});var NLt=s(l_e);FPo=r(NLt,"yolos"),NLt.forEach(t),TPo=r(jNe," \u2014 "),bX=n(jNe,"A",{href:!0});var qLt=s(bX);MPo=r(qLt,"YolosModel"),qLt.forEach(t),EPo=r(jNe," (YOLOS model)"),jNe.forEach(t),CPo=i(x),ov=n(x,"LI",{});var DNe=s(ov);i_e=n(DNe,"STRONG",{});var jLt=s(i_e);wPo=r(jLt,"yoso"),jLt.forEach(t),APo=r(DNe," \u2014 "),FX=n(DNe,"A",{href:!0});var DLt=s(FX);LPo=r(DLt,"YosoModel"),DLt.forEach(t),yPo=r(DNe," (YOSO model)"),DNe.forEach(t),x.forEach(t),xPo=i(Fa),rv=n(Fa,"P",{});var GNe=s(rv);$Po=r(GNe,"The model is set in evaluation mode by default using "),d_e=n(GNe,"CODE",{});var GLt=s(d_e);kPo=r(GLt,"model.eval()"),GLt.forEach(t),SPo=r(GNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c_e=n(GNe,"CODE",{});var OLt=s(c_e);RPo=r(OLt,"model.train()"),OLt.forEach(t),GNe.forEach(t),PPo=i(Fa),T(tv.$$.fragment,Fa),Fa.forEach(t),wl.forEach(t),QYe=i(f),bd=n(f,"H2",{class:!0});var seo=s(bd);av=n(seo,"A",{id:!0,class:!0,href:!0});var VLt=s(av);f_e=n(VLt,"SPAN",{});var XLt=s(f_e);T(ex.$$.fragment,XLt),XLt.forEach(t),VLt.forEach(t),BPo=i(seo),m_e=n(seo,"SPAN",{});var zLt=s(m_e);IPo=r(zLt,"AutoModelForPreTraining"),zLt.forEach(t),seo.forEach(t),WYe=i(f),Bo=n(f,"DIV",{class:!0});var Al=s(Bo);T(ox.$$.fragment,Al),NPo=i(Al),Fd=n(Al,"P",{});var Hse=s(Fd);qPo=r(Hse,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),TX=n(Hse,"A",{href:!0});var QLt=s(TX);jPo=r(QLt,"from_pretrained()"),QLt.forEach(t),DPo=r(Hse," class method or the "),MX=n(Hse,"A",{href:!0});var WLt=s(MX);GPo=r(WLt,"from_config()"),WLt.forEach(t),OPo=r(Hse,` class
method.`),Hse.forEach(t),VPo=i(Al),rx=n(Al,"P",{});var leo=s(rx);XPo=r(leo,"This class cannot be instantiated directly using "),g_e=n(leo,"CODE",{});var ULt=s(g_e);zPo=r(ULt,"__init__()"),ULt.forEach(t),QPo=r(leo," (throws an error)."),leo.forEach(t),WPo=i(Al),vt=n(Al,"DIV",{class:!0});var Fy=s(vt);T(tx.$$.fragment,Fy),UPo=i(Fy),h_e=n(Fy,"P",{});var HLt=s(h_e);HPo=r(HLt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),HLt.forEach(t),JPo=i(Fy),Td=n(Fy,"P",{});var Jse=s(Td);YPo=r(Jse,`Note:
Loading a model from its configuration file does `),u_e=n(Jse,"STRONG",{});var JLt=s(u_e);KPo=r(JLt,"not"),JLt.forEach(t),ZPo=r(Jse,` load the model weights. It only affects the
model\u2019s configuration. Use `),EX=n(Jse,"A",{href:!0});var YLt=s(EX);eBo=r(YLt,"from_pretrained()"),YLt.forEach(t),oBo=r(Jse," to load the model weights."),Jse.forEach(t),rBo=i(Fy),T(nv.$$.fragment,Fy),Fy.forEach(t),tBo=i(Al),eo=n(Al,"DIV",{class:!0});var Ta=s(eo);T(ax.$$.fragment,Ta),aBo=i(Ta),p_e=n(Ta,"P",{});var KLt=s(p_e);nBo=r(KLt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),KLt.forEach(t),sBo=i(Ta),Ya=n(Ta,"P",{});var Ty=s(Ya);lBo=r(Ty,"The model class to instantiate is selected based on the "),__e=n(Ty,"CODE",{});var ZLt=s(__e);iBo=r(ZLt,"model_type"),ZLt.forEach(t),dBo=r(Ty,` property of the config object (either
passed as an argument or loaded from `),v_e=n(Ty,"CODE",{});var eyt=s(v_e);cBo=r(eyt,"pretrained_model_name_or_path"),eyt.forEach(t),fBo=r(Ty,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b_e=n(Ty,"CODE",{});var oyt=s(b_e);mBo=r(oyt,"pretrained_model_name_or_path"),oyt.forEach(t),gBo=r(Ty,":"),Ty.forEach(t),hBo=i(Ta),G=n(Ta,"UL",{});var O=s(G);sv=n(O,"LI",{});var ONe=s(sv);F_e=n(ONe,"STRONG",{});var ryt=s(F_e);uBo=r(ryt,"albert"),ryt.forEach(t),pBo=r(ONe," \u2014 "),CX=n(ONe,"A",{href:!0});var tyt=s(CX);_Bo=r(tyt,"AlbertForPreTraining"),tyt.forEach(t),vBo=r(ONe," (ALBERT model)"),ONe.forEach(t),bBo=i(O),lv=n(O,"LI",{});var VNe=s(lv);T_e=n(VNe,"STRONG",{});var ayt=s(T_e);FBo=r(ayt,"bart"),ayt.forEach(t),TBo=r(VNe," \u2014 "),wX=n(VNe,"A",{href:!0});var nyt=s(wX);MBo=r(nyt,"BartForConditionalGeneration"),nyt.forEach(t),EBo=r(VNe," (BART model)"),VNe.forEach(t),CBo=i(O),iv=n(O,"LI",{});var XNe=s(iv);M_e=n(XNe,"STRONG",{});var syt=s(M_e);wBo=r(syt,"bert"),syt.forEach(t),ABo=r(XNe," \u2014 "),AX=n(XNe,"A",{href:!0});var lyt=s(AX);LBo=r(lyt,"BertForPreTraining"),lyt.forEach(t),yBo=r(XNe," (BERT model)"),XNe.forEach(t),xBo=i(O),dv=n(O,"LI",{});var zNe=s(dv);E_e=n(zNe,"STRONG",{});var iyt=s(E_e);$Bo=r(iyt,"big_bird"),iyt.forEach(t),kBo=r(zNe," \u2014 "),LX=n(zNe,"A",{href:!0});var dyt=s(LX);SBo=r(dyt,"BigBirdForPreTraining"),dyt.forEach(t),RBo=r(zNe," (BigBird model)"),zNe.forEach(t),PBo=i(O),cv=n(O,"LI",{});var QNe=s(cv);C_e=n(QNe,"STRONG",{});var cyt=s(C_e);BBo=r(cyt,"bloom"),cyt.forEach(t),IBo=r(QNe," \u2014 "),yX=n(QNe,"A",{href:!0});var fyt=s(yX);NBo=r(fyt,"BloomForCausalLM"),fyt.forEach(t),qBo=r(QNe," (BLOOM model)"),QNe.forEach(t),jBo=i(O),fv=n(O,"LI",{});var WNe=s(fv);w_e=n(WNe,"STRONG",{});var myt=s(w_e);DBo=r(myt,"camembert"),myt.forEach(t),GBo=r(WNe," \u2014 "),xX=n(WNe,"A",{href:!0});var gyt=s(xX);OBo=r(gyt,"CamembertForMaskedLM"),gyt.forEach(t),VBo=r(WNe," (CamemBERT model)"),WNe.forEach(t),XBo=i(O),mv=n(O,"LI",{});var UNe=s(mv);A_e=n(UNe,"STRONG",{});var hyt=s(A_e);zBo=r(hyt,"ctrl"),hyt.forEach(t),QBo=r(UNe," \u2014 "),$X=n(UNe,"A",{href:!0});var uyt=s($X);WBo=r(uyt,"CTRLLMHeadModel"),uyt.forEach(t),UBo=r(UNe," (CTRL model)"),UNe.forEach(t),HBo=i(O),gv=n(O,"LI",{});var HNe=s(gv);L_e=n(HNe,"STRONG",{});var pyt=s(L_e);JBo=r(pyt,"data2vec-text"),pyt.forEach(t),YBo=r(HNe," \u2014 "),kX=n(HNe,"A",{href:!0});var _yt=s(kX);KBo=r(_yt,"Data2VecTextForMaskedLM"),_yt.forEach(t),ZBo=r(HNe," (Data2VecText model)"),HNe.forEach(t),eIo=i(O),hv=n(O,"LI",{});var JNe=s(hv);y_e=n(JNe,"STRONG",{});var vyt=s(y_e);oIo=r(vyt,"deberta"),vyt.forEach(t),rIo=r(JNe," \u2014 "),SX=n(JNe,"A",{href:!0});var byt=s(SX);tIo=r(byt,"DebertaForMaskedLM"),byt.forEach(t),aIo=r(JNe," (DeBERTa model)"),JNe.forEach(t),nIo=i(O),uv=n(O,"LI",{});var YNe=s(uv);x_e=n(YNe,"STRONG",{});var Fyt=s(x_e);sIo=r(Fyt,"deberta-v2"),Fyt.forEach(t),lIo=r(YNe," \u2014 "),RX=n(YNe,"A",{href:!0});var Tyt=s(RX);iIo=r(Tyt,"DebertaV2ForMaskedLM"),Tyt.forEach(t),dIo=r(YNe," (DeBERTa-v2 model)"),YNe.forEach(t),cIo=i(O),pv=n(O,"LI",{});var KNe=s(pv);$_e=n(KNe,"STRONG",{});var Myt=s($_e);fIo=r(Myt,"distilbert"),Myt.forEach(t),mIo=r(KNe," \u2014 "),PX=n(KNe,"A",{href:!0});var Eyt=s(PX);gIo=r(Eyt,"DistilBertForMaskedLM"),Eyt.forEach(t),hIo=r(KNe," (DistilBERT model)"),KNe.forEach(t),uIo=i(O),_v=n(O,"LI",{});var ZNe=s(_v);k_e=n(ZNe,"STRONG",{});var Cyt=s(k_e);pIo=r(Cyt,"electra"),Cyt.forEach(t),_Io=r(ZNe," \u2014 "),BX=n(ZNe,"A",{href:!0});var wyt=s(BX);vIo=r(wyt,"ElectraForPreTraining"),wyt.forEach(t),bIo=r(ZNe," (ELECTRA model)"),ZNe.forEach(t),FIo=i(O),vv=n(O,"LI",{});var eqe=s(vv);S_e=n(eqe,"STRONG",{});var Ayt=s(S_e);TIo=r(Ayt,"ernie"),Ayt.forEach(t),MIo=r(eqe," \u2014 "),IX=n(eqe,"A",{href:!0});var Lyt=s(IX);EIo=r(Lyt,"ErnieForPreTraining"),Lyt.forEach(t),CIo=r(eqe," (ERNIE model)"),eqe.forEach(t),wIo=i(O),bv=n(O,"LI",{});var oqe=s(bv);R_e=n(oqe,"STRONG",{});var yyt=s(R_e);AIo=r(yyt,"flaubert"),yyt.forEach(t),LIo=r(oqe," \u2014 "),NX=n(oqe,"A",{href:!0});var xyt=s(NX);yIo=r(xyt,"FlaubertWithLMHeadModel"),xyt.forEach(t),xIo=r(oqe," (FlauBERT model)"),oqe.forEach(t),$Io=i(O),Fv=n(O,"LI",{});var rqe=s(Fv);P_e=n(rqe,"STRONG",{});var $yt=s(P_e);kIo=r($yt,"flava"),$yt.forEach(t),SIo=r(rqe," \u2014 "),qX=n(rqe,"A",{href:!0});var kyt=s(qX);RIo=r(kyt,"FlavaForPreTraining"),kyt.forEach(t),PIo=r(rqe," (FLAVA model)"),rqe.forEach(t),BIo=i(O),Tv=n(O,"LI",{});var tqe=s(Tv);B_e=n(tqe,"STRONG",{});var Syt=s(B_e);IIo=r(Syt,"fnet"),Syt.forEach(t),NIo=r(tqe," \u2014 "),jX=n(tqe,"A",{href:!0});var Ryt=s(jX);qIo=r(Ryt,"FNetForPreTraining"),Ryt.forEach(t),jIo=r(tqe," (FNet model)"),tqe.forEach(t),DIo=i(O),Mv=n(O,"LI",{});var aqe=s(Mv);I_e=n(aqe,"STRONG",{});var Pyt=s(I_e);GIo=r(Pyt,"fsmt"),Pyt.forEach(t),OIo=r(aqe," \u2014 "),DX=n(aqe,"A",{href:!0});var Byt=s(DX);VIo=r(Byt,"FSMTForConditionalGeneration"),Byt.forEach(t),XIo=r(aqe," (FairSeq Machine-Translation model)"),aqe.forEach(t),zIo=i(O),Ev=n(O,"LI",{});var nqe=s(Ev);N_e=n(nqe,"STRONG",{});var Iyt=s(N_e);QIo=r(Iyt,"funnel"),Iyt.forEach(t),WIo=r(nqe," \u2014 "),GX=n(nqe,"A",{href:!0});var Nyt=s(GX);UIo=r(Nyt,"FunnelForPreTraining"),Nyt.forEach(t),HIo=r(nqe," (Funnel Transformer model)"),nqe.forEach(t),JIo=i(O),Cv=n(O,"LI",{});var sqe=s(Cv);q_e=n(sqe,"STRONG",{});var qyt=s(q_e);YIo=r(qyt,"gpt2"),qyt.forEach(t),KIo=r(sqe," \u2014 "),OX=n(sqe,"A",{href:!0});var jyt=s(OX);ZIo=r(jyt,"GPT2LMHeadModel"),jyt.forEach(t),eNo=r(sqe," (OpenAI GPT-2 model)"),sqe.forEach(t),oNo=i(O),wv=n(O,"LI",{});var lqe=s(wv);j_e=n(lqe,"STRONG",{});var Dyt=s(j_e);rNo=r(Dyt,"ibert"),Dyt.forEach(t),tNo=r(lqe," \u2014 "),VX=n(lqe,"A",{href:!0});var Gyt=s(VX);aNo=r(Gyt,"IBertForMaskedLM"),Gyt.forEach(t),nNo=r(lqe," (I-BERT model)"),lqe.forEach(t),sNo=i(O),Av=n(O,"LI",{});var iqe=s(Av);D_e=n(iqe,"STRONG",{});var Oyt=s(D_e);lNo=r(Oyt,"layoutlm"),Oyt.forEach(t),iNo=r(iqe," \u2014 "),XX=n(iqe,"A",{href:!0});var Vyt=s(XX);dNo=r(Vyt,"LayoutLMForMaskedLM"),Vyt.forEach(t),cNo=r(iqe," (LayoutLM model)"),iqe.forEach(t),fNo=i(O),Lv=n(O,"LI",{});var dqe=s(Lv);G_e=n(dqe,"STRONG",{});var Xyt=s(G_e);mNo=r(Xyt,"longformer"),Xyt.forEach(t),gNo=r(dqe," \u2014 "),zX=n(dqe,"A",{href:!0});var zyt=s(zX);hNo=r(zyt,"LongformerForMaskedLM"),zyt.forEach(t),uNo=r(dqe," (Longformer model)"),dqe.forEach(t),pNo=i(O),yv=n(O,"LI",{});var cqe=s(yv);O_e=n(cqe,"STRONG",{});var Qyt=s(O_e);_No=r(Qyt,"luke"),Qyt.forEach(t),vNo=r(cqe," \u2014 "),QX=n(cqe,"A",{href:!0});var Wyt=s(QX);bNo=r(Wyt,"LukeForMaskedLM"),Wyt.forEach(t),FNo=r(cqe," (LUKE model)"),cqe.forEach(t),TNo=i(O),xv=n(O,"LI",{});var fqe=s(xv);V_e=n(fqe,"STRONG",{});var Uyt=s(V_e);MNo=r(Uyt,"lxmert"),Uyt.forEach(t),ENo=r(fqe," \u2014 "),WX=n(fqe,"A",{href:!0});var Hyt=s(WX);CNo=r(Hyt,"LxmertForPreTraining"),Hyt.forEach(t),wNo=r(fqe," (LXMERT model)"),fqe.forEach(t),ANo=i(O),$v=n(O,"LI",{});var mqe=s($v);X_e=n(mqe,"STRONG",{});var Jyt=s(X_e);LNo=r(Jyt,"megatron-bert"),Jyt.forEach(t),yNo=r(mqe," \u2014 "),UX=n(mqe,"A",{href:!0});var Yyt=s(UX);xNo=r(Yyt,"MegatronBertForPreTraining"),Yyt.forEach(t),$No=r(mqe," (Megatron-BERT model)"),mqe.forEach(t),kNo=i(O),kv=n(O,"LI",{});var gqe=s(kv);z_e=n(gqe,"STRONG",{});var Kyt=s(z_e);SNo=r(Kyt,"mobilebert"),Kyt.forEach(t),RNo=r(gqe," \u2014 "),HX=n(gqe,"A",{href:!0});var Zyt=s(HX);PNo=r(Zyt,"MobileBertForPreTraining"),Zyt.forEach(t),BNo=r(gqe," (MobileBERT model)"),gqe.forEach(t),INo=i(O),Sv=n(O,"LI",{});var hqe=s(Sv);Q_e=n(hqe,"STRONG",{});var e8t=s(Q_e);NNo=r(e8t,"mpnet"),e8t.forEach(t),qNo=r(hqe," \u2014 "),JX=n(hqe,"A",{href:!0});var o8t=s(JX);jNo=r(o8t,"MPNetForMaskedLM"),o8t.forEach(t),DNo=r(hqe," (MPNet model)"),hqe.forEach(t),GNo=i(O),Rv=n(O,"LI",{});var uqe=s(Rv);W_e=n(uqe,"STRONG",{});var r8t=s(W_e);ONo=r(r8t,"mvp"),r8t.forEach(t),VNo=r(uqe," \u2014 "),YX=n(uqe,"A",{href:!0});var t8t=s(YX);XNo=r(t8t,"MvpForConditionalGeneration"),t8t.forEach(t),zNo=r(uqe," (MVP model)"),uqe.forEach(t),QNo=i(O),Pv=n(O,"LI",{});var pqe=s(Pv);U_e=n(pqe,"STRONG",{});var a8t=s(U_e);WNo=r(a8t,"nezha"),a8t.forEach(t),UNo=r(pqe," \u2014 "),KX=n(pqe,"A",{href:!0});var n8t=s(KX);HNo=r(n8t,"NezhaForPreTraining"),n8t.forEach(t),JNo=r(pqe," (Nezha model)"),pqe.forEach(t),YNo=i(O),Bv=n(O,"LI",{});var _qe=s(Bv);H_e=n(_qe,"STRONG",{});var s8t=s(H_e);KNo=r(s8t,"openai-gpt"),s8t.forEach(t),ZNo=r(_qe," \u2014 "),ZX=n(_qe,"A",{href:!0});var l8t=s(ZX);eqo=r(l8t,"OpenAIGPTLMHeadModel"),l8t.forEach(t),oqo=r(_qe," (OpenAI GPT model)"),_qe.forEach(t),rqo=i(O),Iv=n(O,"LI",{});var vqe=s(Iv);J_e=n(vqe,"STRONG",{});var i8t=s(J_e);tqo=r(i8t,"retribert"),i8t.forEach(t),aqo=r(vqe," \u2014 "),ez=n(vqe,"A",{href:!0});var d8t=s(ez);nqo=r(d8t,"RetriBertModel"),d8t.forEach(t),sqo=r(vqe," (RetriBERT model)"),vqe.forEach(t),lqo=i(O),Nv=n(O,"LI",{});var bqe=s(Nv);Y_e=n(bqe,"STRONG",{});var c8t=s(Y_e);iqo=r(c8t,"roberta"),c8t.forEach(t),dqo=r(bqe," \u2014 "),oz=n(bqe,"A",{href:!0});var f8t=s(oz);cqo=r(f8t,"RobertaForMaskedLM"),f8t.forEach(t),fqo=r(bqe," (RoBERTa model)"),bqe.forEach(t),mqo=i(O),qv=n(O,"LI",{});var Fqe=s(qv);K_e=n(Fqe,"STRONG",{});var m8t=s(K_e);gqo=r(m8t,"splinter"),m8t.forEach(t),hqo=r(Fqe," \u2014 "),rz=n(Fqe,"A",{href:!0});var g8t=s(rz);uqo=r(g8t,"SplinterForPreTraining"),g8t.forEach(t),pqo=r(Fqe," (Splinter model)"),Fqe.forEach(t),_qo=i(O),jv=n(O,"LI",{});var Tqe=s(jv);Z_e=n(Tqe,"STRONG",{});var h8t=s(Z_e);vqo=r(h8t,"squeezebert"),h8t.forEach(t),bqo=r(Tqe," \u2014 "),tz=n(Tqe,"A",{href:!0});var u8t=s(tz);Fqo=r(u8t,"SqueezeBertForMaskedLM"),u8t.forEach(t),Tqo=r(Tqe," (SqueezeBERT model)"),Tqe.forEach(t),Mqo=i(O),Dv=n(O,"LI",{});var Mqe=s(Dv);e2e=n(Mqe,"STRONG",{});var p8t=s(e2e);Eqo=r(p8t,"t5"),p8t.forEach(t),Cqo=r(Mqe," \u2014 "),az=n(Mqe,"A",{href:!0});var _8t=s(az);wqo=r(_8t,"T5ForConditionalGeneration"),_8t.forEach(t),Aqo=r(Mqe," (T5 model)"),Mqe.forEach(t),Lqo=i(O),Gv=n(O,"LI",{});var Eqe=s(Gv);o2e=n(Eqe,"STRONG",{});var v8t=s(o2e);yqo=r(v8t,"tapas"),v8t.forEach(t),xqo=r(Eqe," \u2014 "),nz=n(Eqe,"A",{href:!0});var b8t=s(nz);$qo=r(b8t,"TapasForMaskedLM"),b8t.forEach(t),kqo=r(Eqe," (TAPAS model)"),Eqe.forEach(t),Sqo=i(O),Ov=n(O,"LI",{});var Cqe=s(Ov);r2e=n(Cqe,"STRONG",{});var F8t=s(r2e);Rqo=r(F8t,"transfo-xl"),F8t.forEach(t),Pqo=r(Cqe," \u2014 "),sz=n(Cqe,"A",{href:!0});var T8t=s(sz);Bqo=r(T8t,"TransfoXLLMHeadModel"),T8t.forEach(t),Iqo=r(Cqe," (Transformer-XL model)"),Cqe.forEach(t),Nqo=i(O),Vv=n(O,"LI",{});var wqe=s(Vv);t2e=n(wqe,"STRONG",{});var M8t=s(t2e);qqo=r(M8t,"unispeech"),M8t.forEach(t),jqo=r(wqe," \u2014 "),lz=n(wqe,"A",{href:!0});var E8t=s(lz);Dqo=r(E8t,"UniSpeechForPreTraining"),E8t.forEach(t),Gqo=r(wqe," (UniSpeech model)"),wqe.forEach(t),Oqo=i(O),Xv=n(O,"LI",{});var Aqe=s(Xv);a2e=n(Aqe,"STRONG",{});var C8t=s(a2e);Vqo=r(C8t,"unispeech-sat"),C8t.forEach(t),Xqo=r(Aqe," \u2014 "),iz=n(Aqe,"A",{href:!0});var w8t=s(iz);zqo=r(w8t,"UniSpeechSatForPreTraining"),w8t.forEach(t),Qqo=r(Aqe," (UniSpeechSat model)"),Aqe.forEach(t),Wqo=i(O),zv=n(O,"LI",{});var Lqe=s(zv);n2e=n(Lqe,"STRONG",{});var A8t=s(n2e);Uqo=r(A8t,"videomae"),A8t.forEach(t),Hqo=r(Lqe," \u2014 "),dz=n(Lqe,"A",{href:!0});var L8t=s(dz);Jqo=r(L8t,"VideoMAEForPreTraining"),L8t.forEach(t),Yqo=r(Lqe," (VideoMAE model)"),Lqe.forEach(t),Kqo=i(O),Qv=n(O,"LI",{});var yqe=s(Qv);s2e=n(yqe,"STRONG",{});var y8t=s(s2e);Zqo=r(y8t,"visual_bert"),y8t.forEach(t),ejo=r(yqe," \u2014 "),cz=n(yqe,"A",{href:!0});var x8t=s(cz);ojo=r(x8t,"VisualBertForPreTraining"),x8t.forEach(t),rjo=r(yqe," (VisualBERT model)"),yqe.forEach(t),tjo=i(O),Wv=n(O,"LI",{});var xqe=s(Wv);l2e=n(xqe,"STRONG",{});var $8t=s(l2e);ajo=r($8t,"vit_mae"),$8t.forEach(t),njo=r(xqe," \u2014 "),fz=n(xqe,"A",{href:!0});var k8t=s(fz);sjo=r(k8t,"ViTMAEForPreTraining"),k8t.forEach(t),ljo=r(xqe," (ViTMAE model)"),xqe.forEach(t),ijo=i(O),Uv=n(O,"LI",{});var $qe=s(Uv);i2e=n($qe,"STRONG",{});var S8t=s(i2e);djo=r(S8t,"wav2vec2"),S8t.forEach(t),cjo=r($qe," \u2014 "),mz=n($qe,"A",{href:!0});var R8t=s(mz);fjo=r(R8t,"Wav2Vec2ForPreTraining"),R8t.forEach(t),mjo=r($qe," (Wav2Vec2 model)"),$qe.forEach(t),gjo=i(O),Hv=n(O,"LI",{});var kqe=s(Hv);d2e=n(kqe,"STRONG",{});var P8t=s(d2e);hjo=r(P8t,"wav2vec2-conformer"),P8t.forEach(t),ujo=r(kqe," \u2014 "),gz=n(kqe,"A",{href:!0});var B8t=s(gz);pjo=r(B8t,"Wav2Vec2ConformerForPreTraining"),B8t.forEach(t),_jo=r(kqe," (Wav2Vec2-Conformer model)"),kqe.forEach(t),vjo=i(O),Jv=n(O,"LI",{});var Sqe=s(Jv);c2e=n(Sqe,"STRONG",{});var I8t=s(c2e);bjo=r(I8t,"xlm"),I8t.forEach(t),Fjo=r(Sqe," \u2014 "),hz=n(Sqe,"A",{href:!0});var N8t=s(hz);Tjo=r(N8t,"XLMWithLMHeadModel"),N8t.forEach(t),Mjo=r(Sqe," (XLM model)"),Sqe.forEach(t),Ejo=i(O),Yv=n(O,"LI",{});var Rqe=s(Yv);f2e=n(Rqe,"STRONG",{});var q8t=s(f2e);Cjo=r(q8t,"xlm-roberta"),q8t.forEach(t),wjo=r(Rqe," \u2014 "),uz=n(Rqe,"A",{href:!0});var j8t=s(uz);Ajo=r(j8t,"XLMRobertaForMaskedLM"),j8t.forEach(t),Ljo=r(Rqe," (XLM-RoBERTa model)"),Rqe.forEach(t),yjo=i(O),Kv=n(O,"LI",{});var Pqe=s(Kv);m2e=n(Pqe,"STRONG",{});var D8t=s(m2e);xjo=r(D8t,"xlm-roberta-xl"),D8t.forEach(t),$jo=r(Pqe," \u2014 "),pz=n(Pqe,"A",{href:!0});var G8t=s(pz);kjo=r(G8t,"XLMRobertaXLForMaskedLM"),G8t.forEach(t),Sjo=r(Pqe," (XLM-RoBERTa-XL model)"),Pqe.forEach(t),Rjo=i(O),Zv=n(O,"LI",{});var Bqe=s(Zv);g2e=n(Bqe,"STRONG",{});var O8t=s(g2e);Pjo=r(O8t,"xlnet"),O8t.forEach(t),Bjo=r(Bqe," \u2014 "),_z=n(Bqe,"A",{href:!0});var V8t=s(_z);Ijo=r(V8t,"XLNetLMHeadModel"),V8t.forEach(t),Njo=r(Bqe," (XLNet model)"),Bqe.forEach(t),O.forEach(t),qjo=i(Ta),e4=n(Ta,"P",{});var Iqe=s(e4);jjo=r(Iqe,"The model is set in evaluation mode by default using "),h2e=n(Iqe,"CODE",{});var X8t=s(h2e);Djo=r(X8t,"model.eval()"),X8t.forEach(t),Gjo=r(Iqe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u2e=n(Iqe,"CODE",{});var z8t=s(u2e);Ojo=r(z8t,"model.train()"),z8t.forEach(t),Iqe.forEach(t),Vjo=i(Ta),T(o4.$$.fragment,Ta),Ta.forEach(t),Al.forEach(t),UYe=i(f),Md=n(f,"H2",{class:!0});var ieo=s(Md);r4=n(ieo,"A",{id:!0,class:!0,href:!0});var Q8t=s(r4);p2e=n(Q8t,"SPAN",{});var W8t=s(p2e);T(nx.$$.fragment,W8t),W8t.forEach(t),Q8t.forEach(t),Xjo=i(ieo),_2e=n(ieo,"SPAN",{});var U8t=s(_2e);zjo=r(U8t,"AutoModelForCausalLM"),U8t.forEach(t),ieo.forEach(t),HYe=i(f),Io=n(f,"DIV",{class:!0});var Ll=s(Io);T(sx.$$.fragment,Ll),Qjo=i(Ll),Ed=n(Ll,"P",{});var Yse=s(Ed);Wjo=r(Yse,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),vz=n(Yse,"A",{href:!0});var H8t=s(vz);Ujo=r(H8t,"from_pretrained()"),H8t.forEach(t),Hjo=r(Yse," class method or the "),bz=n(Yse,"A",{href:!0});var J8t=s(bz);Jjo=r(J8t,"from_config()"),J8t.forEach(t),Yjo=r(Yse,` class
method.`),Yse.forEach(t),Kjo=i(Ll),lx=n(Ll,"P",{});var deo=s(lx);Zjo=r(deo,"This class cannot be instantiated directly using "),v2e=n(deo,"CODE",{});var Y8t=s(v2e);eDo=r(Y8t,"__init__()"),Y8t.forEach(t),oDo=r(deo," (throws an error)."),deo.forEach(t),rDo=i(Ll),bt=n(Ll,"DIV",{class:!0});var My=s(bt);T(ix.$$.fragment,My),tDo=i(My),b2e=n(My,"P",{});var K8t=s(b2e);aDo=r(K8t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),K8t.forEach(t),nDo=i(My),Cd=n(My,"P",{});var Kse=s(Cd);sDo=r(Kse,`Note:
Loading a model from its configuration file does `),F2e=n(Kse,"STRONG",{});var Z8t=s(F2e);lDo=r(Z8t,"not"),Z8t.forEach(t),iDo=r(Kse,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=n(Kse,"A",{href:!0});var e9t=s(Fz);dDo=r(e9t,"from_pretrained()"),e9t.forEach(t),cDo=r(Kse," to load the model weights."),Kse.forEach(t),fDo=i(My),T(t4.$$.fragment,My),My.forEach(t),mDo=i(Ll),oo=n(Ll,"DIV",{class:!0});var Ma=s(oo);T(dx.$$.fragment,Ma),gDo=i(Ma),T2e=n(Ma,"P",{});var o9t=s(T2e);hDo=r(o9t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),o9t.forEach(t),uDo=i(Ma),Ka=n(Ma,"P",{});var Ey=s(Ka);pDo=r(Ey,"The model class to instantiate is selected based on the "),M2e=n(Ey,"CODE",{});var r9t=s(M2e);_Do=r(r9t,"model_type"),r9t.forEach(t),vDo=r(Ey,` property of the config object (either
passed as an argument or loaded from `),E2e=n(Ey,"CODE",{});var t9t=s(E2e);bDo=r(t9t,"pretrained_model_name_or_path"),t9t.forEach(t),FDo=r(Ey,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C2e=n(Ey,"CODE",{});var a9t=s(C2e);TDo=r(a9t,"pretrained_model_name_or_path"),a9t.forEach(t),MDo=r(Ey,":"),Ey.forEach(t),EDo=i(Ma),z=n(Ma,"UL",{});var Q=s(z);a4=n(Q,"LI",{});var Nqe=s(a4);w2e=n(Nqe,"STRONG",{});var n9t=s(w2e);CDo=r(n9t,"bart"),n9t.forEach(t),wDo=r(Nqe," \u2014 "),Tz=n(Nqe,"A",{href:!0});var s9t=s(Tz);ADo=r(s9t,"BartForCausalLM"),s9t.forEach(t),LDo=r(Nqe," (BART model)"),Nqe.forEach(t),yDo=i(Q),n4=n(Q,"LI",{});var qqe=s(n4);A2e=n(qqe,"STRONG",{});var l9t=s(A2e);xDo=r(l9t,"bert"),l9t.forEach(t),$Do=r(qqe," \u2014 "),Mz=n(qqe,"A",{href:!0});var i9t=s(Mz);kDo=r(i9t,"BertLMHeadModel"),i9t.forEach(t),SDo=r(qqe," (BERT model)"),qqe.forEach(t),RDo=i(Q),s4=n(Q,"LI",{});var jqe=s(s4);L2e=n(jqe,"STRONG",{});var d9t=s(L2e);PDo=r(d9t,"bert-generation"),d9t.forEach(t),BDo=r(jqe," \u2014 "),Ez=n(jqe,"A",{href:!0});var c9t=s(Ez);IDo=r(c9t,"BertGenerationDecoder"),c9t.forEach(t),NDo=r(jqe," (Bert Generation model)"),jqe.forEach(t),qDo=i(Q),l4=n(Q,"LI",{});var Dqe=s(l4);y2e=n(Dqe,"STRONG",{});var f9t=s(y2e);jDo=r(f9t,"big_bird"),f9t.forEach(t),DDo=r(Dqe," \u2014 "),Cz=n(Dqe,"A",{href:!0});var m9t=s(Cz);GDo=r(m9t,"BigBirdForCausalLM"),m9t.forEach(t),ODo=r(Dqe," (BigBird model)"),Dqe.forEach(t),VDo=i(Q),i4=n(Q,"LI",{});var Gqe=s(i4);x2e=n(Gqe,"STRONG",{});var g9t=s(x2e);XDo=r(g9t,"bigbird_pegasus"),g9t.forEach(t),zDo=r(Gqe," \u2014 "),wz=n(Gqe,"A",{href:!0});var h9t=s(wz);QDo=r(h9t,"BigBirdPegasusForCausalLM"),h9t.forEach(t),WDo=r(Gqe," (BigBird-Pegasus model)"),Gqe.forEach(t),UDo=i(Q),d4=n(Q,"LI",{});var Oqe=s(d4);$2e=n(Oqe,"STRONG",{});var u9t=s($2e);HDo=r(u9t,"blenderbot"),u9t.forEach(t),JDo=r(Oqe," \u2014 "),Az=n(Oqe,"A",{href:!0});var p9t=s(Az);YDo=r(p9t,"BlenderbotForCausalLM"),p9t.forEach(t),KDo=r(Oqe," (Blenderbot model)"),Oqe.forEach(t),ZDo=i(Q),c4=n(Q,"LI",{});var Vqe=s(c4);k2e=n(Vqe,"STRONG",{});var _9t=s(k2e);eGo=r(_9t,"blenderbot-small"),_9t.forEach(t),oGo=r(Vqe," \u2014 "),Lz=n(Vqe,"A",{href:!0});var v9t=s(Lz);rGo=r(v9t,"BlenderbotSmallForCausalLM"),v9t.forEach(t),tGo=r(Vqe," (BlenderbotSmall model)"),Vqe.forEach(t),aGo=i(Q),f4=n(Q,"LI",{});var Xqe=s(f4);S2e=n(Xqe,"STRONG",{});var b9t=s(S2e);nGo=r(b9t,"bloom"),b9t.forEach(t),sGo=r(Xqe," \u2014 "),yz=n(Xqe,"A",{href:!0});var F9t=s(yz);lGo=r(F9t,"BloomForCausalLM"),F9t.forEach(t),iGo=r(Xqe," (BLOOM model)"),Xqe.forEach(t),dGo=i(Q),m4=n(Q,"LI",{});var zqe=s(m4);R2e=n(zqe,"STRONG",{});var T9t=s(R2e);cGo=r(T9t,"camembert"),T9t.forEach(t),fGo=r(zqe," \u2014 "),xz=n(zqe,"A",{href:!0});var M9t=s(xz);mGo=r(M9t,"CamembertForCausalLM"),M9t.forEach(t),gGo=r(zqe," (CamemBERT model)"),zqe.forEach(t),hGo=i(Q),g4=n(Q,"LI",{});var Qqe=s(g4);P2e=n(Qqe,"STRONG",{});var E9t=s(P2e);uGo=r(E9t,"codegen"),E9t.forEach(t),pGo=r(Qqe," \u2014 "),$z=n(Qqe,"A",{href:!0});var C9t=s($z);_Go=r(C9t,"CodeGenForCausalLM"),C9t.forEach(t),vGo=r(Qqe," (CodeGen model)"),Qqe.forEach(t),bGo=i(Q),h4=n(Q,"LI",{});var Wqe=s(h4);B2e=n(Wqe,"STRONG",{});var w9t=s(B2e);FGo=r(w9t,"ctrl"),w9t.forEach(t),TGo=r(Wqe," \u2014 "),kz=n(Wqe,"A",{href:!0});var A9t=s(kz);MGo=r(A9t,"CTRLLMHeadModel"),A9t.forEach(t),EGo=r(Wqe," (CTRL model)"),Wqe.forEach(t),CGo=i(Q),u4=n(Q,"LI",{});var Uqe=s(u4);I2e=n(Uqe,"STRONG",{});var L9t=s(I2e);wGo=r(L9t,"data2vec-text"),L9t.forEach(t),AGo=r(Uqe," \u2014 "),Sz=n(Uqe,"A",{href:!0});var y9t=s(Sz);LGo=r(y9t,"Data2VecTextForCausalLM"),y9t.forEach(t),yGo=r(Uqe," (Data2VecText model)"),Uqe.forEach(t),xGo=i(Q),p4=n(Q,"LI",{});var Hqe=s(p4);N2e=n(Hqe,"STRONG",{});var x9t=s(N2e);$Go=r(x9t,"electra"),x9t.forEach(t),kGo=r(Hqe," \u2014 "),Rz=n(Hqe,"A",{href:!0});var $9t=s(Rz);SGo=r($9t,"ElectraForCausalLM"),$9t.forEach(t),RGo=r(Hqe," (ELECTRA model)"),Hqe.forEach(t),PGo=i(Q),_4=n(Q,"LI",{});var Jqe=s(_4);q2e=n(Jqe,"STRONG",{});var k9t=s(q2e);BGo=r(k9t,"ernie"),k9t.forEach(t),IGo=r(Jqe," \u2014 "),Pz=n(Jqe,"A",{href:!0});var S9t=s(Pz);NGo=r(S9t,"ErnieForCausalLM"),S9t.forEach(t),qGo=r(Jqe," (ERNIE model)"),Jqe.forEach(t),jGo=i(Q),v4=n(Q,"LI",{});var Yqe=s(v4);j2e=n(Yqe,"STRONG",{});var R9t=s(j2e);DGo=r(R9t,"gpt2"),R9t.forEach(t),GGo=r(Yqe," \u2014 "),Bz=n(Yqe,"A",{href:!0});var P9t=s(Bz);OGo=r(P9t,"GPT2LMHeadModel"),P9t.forEach(t),VGo=r(Yqe," (OpenAI GPT-2 model)"),Yqe.forEach(t),XGo=i(Q),b4=n(Q,"LI",{});var Kqe=s(b4);D2e=n(Kqe,"STRONG",{});var B9t=s(D2e);zGo=r(B9t,"gpt_neo"),B9t.forEach(t),QGo=r(Kqe," \u2014 "),Iz=n(Kqe,"A",{href:!0});var I9t=s(Iz);WGo=r(I9t,"GPTNeoForCausalLM"),I9t.forEach(t),UGo=r(Kqe," (GPT Neo model)"),Kqe.forEach(t),HGo=i(Q),F4=n(Q,"LI",{});var Zqe=s(F4);G2e=n(Zqe,"STRONG",{});var N9t=s(G2e);JGo=r(N9t,"gpt_neox"),N9t.forEach(t),YGo=r(Zqe," \u2014 "),Nz=n(Zqe,"A",{href:!0});var q9t=s(Nz);KGo=r(q9t,"GPTNeoXForCausalLM"),q9t.forEach(t),ZGo=r(Zqe," (GPT NeoX model)"),Zqe.forEach(t),eOo=i(Q),T4=n(Q,"LI",{});var eje=s(T4);O2e=n(eje,"STRONG",{});var j9t=s(O2e);oOo=r(j9t,"gptj"),j9t.forEach(t),rOo=r(eje," \u2014 "),qz=n(eje,"A",{href:!0});var D9t=s(qz);tOo=r(D9t,"GPTJForCausalLM"),D9t.forEach(t),aOo=r(eje," (GPT-J model)"),eje.forEach(t),nOo=i(Q),M4=n(Q,"LI",{});var oje=s(M4);V2e=n(oje,"STRONG",{});var G9t=s(V2e);sOo=r(G9t,"marian"),G9t.forEach(t),lOo=r(oje," \u2014 "),jz=n(oje,"A",{href:!0});var O9t=s(jz);iOo=r(O9t,"MarianForCausalLM"),O9t.forEach(t),dOo=r(oje," (Marian model)"),oje.forEach(t),cOo=i(Q),E4=n(Q,"LI",{});var rje=s(E4);X2e=n(rje,"STRONG",{});var V9t=s(X2e);fOo=r(V9t,"mbart"),V9t.forEach(t),mOo=r(rje," \u2014 "),Dz=n(rje,"A",{href:!0});var X9t=s(Dz);gOo=r(X9t,"MBartForCausalLM"),X9t.forEach(t),hOo=r(rje," (mBART model)"),rje.forEach(t),uOo=i(Q),C4=n(Q,"LI",{});var tje=s(C4);z2e=n(tje,"STRONG",{});var z9t=s(z2e);pOo=r(z9t,"megatron-bert"),z9t.forEach(t),_Oo=r(tje," \u2014 "),Gz=n(tje,"A",{href:!0});var Q9t=s(Gz);vOo=r(Q9t,"MegatronBertForCausalLM"),Q9t.forEach(t),bOo=r(tje," (Megatron-BERT model)"),tje.forEach(t),FOo=i(Q),w4=n(Q,"LI",{});var aje=s(w4);Q2e=n(aje,"STRONG",{});var W9t=s(Q2e);TOo=r(W9t,"mvp"),W9t.forEach(t),MOo=r(aje," \u2014 "),Oz=n(aje,"A",{href:!0});var U9t=s(Oz);EOo=r(U9t,"MvpForCausalLM"),U9t.forEach(t),COo=r(aje," (MVP model)"),aje.forEach(t),wOo=i(Q),A4=n(Q,"LI",{});var nje=s(A4);W2e=n(nje,"STRONG",{});var H9t=s(W2e);AOo=r(H9t,"openai-gpt"),H9t.forEach(t),LOo=r(nje," \u2014 "),Vz=n(nje,"A",{href:!0});var J9t=s(Vz);yOo=r(J9t,"OpenAIGPTLMHeadModel"),J9t.forEach(t),xOo=r(nje," (OpenAI GPT model)"),nje.forEach(t),$Oo=i(Q),L4=n(Q,"LI",{});var sje=s(L4);U2e=n(sje,"STRONG",{});var Y9t=s(U2e);kOo=r(Y9t,"opt"),Y9t.forEach(t),SOo=r(sje," \u2014 "),Xz=n(sje,"A",{href:!0});var K9t=s(Xz);ROo=r(K9t,"OPTForCausalLM"),K9t.forEach(t),POo=r(sje," (OPT model)"),sje.forEach(t),BOo=i(Q),y4=n(Q,"LI",{});var lje=s(y4);H2e=n(lje,"STRONG",{});var Z9t=s(H2e);IOo=r(Z9t,"pegasus"),Z9t.forEach(t),NOo=r(lje," \u2014 "),zz=n(lje,"A",{href:!0});var ext=s(zz);qOo=r(ext,"PegasusForCausalLM"),ext.forEach(t),jOo=r(lje," (Pegasus model)"),lje.forEach(t),DOo=i(Q),x4=n(Q,"LI",{});var ije=s(x4);J2e=n(ije,"STRONG",{});var oxt=s(J2e);GOo=r(oxt,"plbart"),oxt.forEach(t),OOo=r(ije," \u2014 "),Qz=n(ije,"A",{href:!0});var rxt=s(Qz);VOo=r(rxt,"PLBartForCausalLM"),rxt.forEach(t),XOo=r(ije," (PLBart model)"),ije.forEach(t),zOo=i(Q),$4=n(Q,"LI",{});var dje=s($4);Y2e=n(dje,"STRONG",{});var txt=s(Y2e);QOo=r(txt,"prophetnet"),txt.forEach(t),WOo=r(dje," \u2014 "),Wz=n(dje,"A",{href:!0});var axt=s(Wz);UOo=r(axt,"ProphetNetForCausalLM"),axt.forEach(t),HOo=r(dje," (ProphetNet model)"),dje.forEach(t),JOo=i(Q),k4=n(Q,"LI",{});var cje=s(k4);K2e=n(cje,"STRONG",{});var nxt=s(K2e);YOo=r(nxt,"qdqbert"),nxt.forEach(t),KOo=r(cje," \u2014 "),Uz=n(cje,"A",{href:!0});var sxt=s(Uz);ZOo=r(sxt,"QDQBertLMHeadModel"),sxt.forEach(t),eVo=r(cje," (QDQBert model)"),cje.forEach(t),oVo=i(Q),S4=n(Q,"LI",{});var fje=s(S4);Z2e=n(fje,"STRONG",{});var lxt=s(Z2e);rVo=r(lxt,"reformer"),lxt.forEach(t),tVo=r(fje," \u2014 "),Hz=n(fje,"A",{href:!0});var ixt=s(Hz);aVo=r(ixt,"ReformerModelWithLMHead"),ixt.forEach(t),nVo=r(fje," (Reformer model)"),fje.forEach(t),sVo=i(Q),R4=n(Q,"LI",{});var mje=s(R4);eve=n(mje,"STRONG",{});var dxt=s(eve);lVo=r(dxt,"rembert"),dxt.forEach(t),iVo=r(mje," \u2014 "),Jz=n(mje,"A",{href:!0});var cxt=s(Jz);dVo=r(cxt,"RemBertForCausalLM"),cxt.forEach(t),cVo=r(mje," (RemBERT model)"),mje.forEach(t),fVo=i(Q),P4=n(Q,"LI",{});var gje=s(P4);ove=n(gje,"STRONG",{});var fxt=s(ove);mVo=r(fxt,"roberta"),fxt.forEach(t),gVo=r(gje," \u2014 "),Yz=n(gje,"A",{href:!0});var mxt=s(Yz);hVo=r(mxt,"RobertaForCausalLM"),mxt.forEach(t),uVo=r(gje," (RoBERTa model)"),gje.forEach(t),pVo=i(Q),B4=n(Q,"LI",{});var hje=s(B4);rve=n(hje,"STRONG",{});var gxt=s(rve);_Vo=r(gxt,"roformer"),gxt.forEach(t),vVo=r(hje," \u2014 "),Kz=n(hje,"A",{href:!0});var hxt=s(Kz);bVo=r(hxt,"RoFormerForCausalLM"),hxt.forEach(t),FVo=r(hje," (RoFormer model)"),hje.forEach(t),TVo=i(Q),I4=n(Q,"LI",{});var uje=s(I4);tve=n(uje,"STRONG",{});var uxt=s(tve);MVo=r(uxt,"speech_to_text_2"),uxt.forEach(t),EVo=r(uje," \u2014 "),Zz=n(uje,"A",{href:!0});var pxt=s(Zz);CVo=r(pxt,"Speech2Text2ForCausalLM"),pxt.forEach(t),wVo=r(uje," (Speech2Text2 model)"),uje.forEach(t),AVo=i(Q),N4=n(Q,"LI",{});var pje=s(N4);ave=n(pje,"STRONG",{});var _xt=s(ave);LVo=r(_xt,"transfo-xl"),_xt.forEach(t),yVo=r(pje," \u2014 "),eQ=n(pje,"A",{href:!0});var vxt=s(eQ);xVo=r(vxt,"TransfoXLLMHeadModel"),vxt.forEach(t),$Vo=r(pje," (Transformer-XL model)"),pje.forEach(t),kVo=i(Q),q4=n(Q,"LI",{});var _je=s(q4);nve=n(_je,"STRONG",{});var bxt=s(nve);SVo=r(bxt,"trocr"),bxt.forEach(t),RVo=r(_je," \u2014 "),oQ=n(_je,"A",{href:!0});var Fxt=s(oQ);PVo=r(Fxt,"TrOCRForCausalLM"),Fxt.forEach(t),BVo=r(_je," (TrOCR model)"),_je.forEach(t),IVo=i(Q),j4=n(Q,"LI",{});var vje=s(j4);sve=n(vje,"STRONG",{});var Txt=s(sve);NVo=r(Txt,"xglm"),Txt.forEach(t),qVo=r(vje," \u2014 "),rQ=n(vje,"A",{href:!0});var Mxt=s(rQ);jVo=r(Mxt,"XGLMForCausalLM"),Mxt.forEach(t),DVo=r(vje," (XGLM model)"),vje.forEach(t),GVo=i(Q),D4=n(Q,"LI",{});var bje=s(D4);lve=n(bje,"STRONG",{});var Ext=s(lve);OVo=r(Ext,"xlm"),Ext.forEach(t),VVo=r(bje," \u2014 "),tQ=n(bje,"A",{href:!0});var Cxt=s(tQ);XVo=r(Cxt,"XLMWithLMHeadModel"),Cxt.forEach(t),zVo=r(bje," (XLM model)"),bje.forEach(t),QVo=i(Q),G4=n(Q,"LI",{});var Fje=s(G4);ive=n(Fje,"STRONG",{});var wxt=s(ive);WVo=r(wxt,"xlm-prophetnet"),wxt.forEach(t),UVo=r(Fje," \u2014 "),aQ=n(Fje,"A",{href:!0});var Axt=s(aQ);HVo=r(Axt,"XLMProphetNetForCausalLM"),Axt.forEach(t),JVo=r(Fje," (XLM-ProphetNet model)"),Fje.forEach(t),YVo=i(Q),O4=n(Q,"LI",{});var Tje=s(O4);dve=n(Tje,"STRONG",{});var Lxt=s(dve);KVo=r(Lxt,"xlm-roberta"),Lxt.forEach(t),ZVo=r(Tje," \u2014 "),nQ=n(Tje,"A",{href:!0});var yxt=s(nQ);eXo=r(yxt,"XLMRobertaForCausalLM"),yxt.forEach(t),oXo=r(Tje," (XLM-RoBERTa model)"),Tje.forEach(t),rXo=i(Q),V4=n(Q,"LI",{});var Mje=s(V4);cve=n(Mje,"STRONG",{});var xxt=s(cve);tXo=r(xxt,"xlm-roberta-xl"),xxt.forEach(t),aXo=r(Mje," \u2014 "),sQ=n(Mje,"A",{href:!0});var $xt=s(sQ);nXo=r($xt,"XLMRobertaXLForCausalLM"),$xt.forEach(t),sXo=r(Mje," (XLM-RoBERTa-XL model)"),Mje.forEach(t),lXo=i(Q),X4=n(Q,"LI",{});var Eje=s(X4);fve=n(Eje,"STRONG",{});var kxt=s(fve);iXo=r(kxt,"xlnet"),kxt.forEach(t),dXo=r(Eje," \u2014 "),lQ=n(Eje,"A",{href:!0});var Sxt=s(lQ);cXo=r(Sxt,"XLNetLMHeadModel"),Sxt.forEach(t),fXo=r(Eje," (XLNet model)"),Eje.forEach(t),Q.forEach(t),mXo=i(Ma),z4=n(Ma,"P",{});var Cje=s(z4);gXo=r(Cje,"The model is set in evaluation mode by default using "),mve=n(Cje,"CODE",{});var Rxt=s(mve);hXo=r(Rxt,"model.eval()"),Rxt.forEach(t),uXo=r(Cje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gve=n(Cje,"CODE",{});var Pxt=s(gve);pXo=r(Pxt,"model.train()"),Pxt.forEach(t),Cje.forEach(t),_Xo=i(Ma),T(Q4.$$.fragment,Ma),Ma.forEach(t),Ll.forEach(t),JYe=i(f),wd=n(f,"H2",{class:!0});var ceo=s(wd);W4=n(ceo,"A",{id:!0,class:!0,href:!0});var Bxt=s(W4);hve=n(Bxt,"SPAN",{});var Ixt=s(hve);T(cx.$$.fragment,Ixt),Ixt.forEach(t),Bxt.forEach(t),vXo=i(ceo),uve=n(ceo,"SPAN",{});var Nxt=s(uve);bXo=r(Nxt,"AutoModelForMaskedLM"),Nxt.forEach(t),ceo.forEach(t),YYe=i(f),No=n(f,"DIV",{class:!0});var yl=s(No);T(fx.$$.fragment,yl),FXo=i(yl),Ad=n(yl,"P",{});var Zse=s(Ad);TXo=r(Zse,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),iQ=n(Zse,"A",{href:!0});var qxt=s(iQ);MXo=r(qxt,"from_pretrained()"),qxt.forEach(t),EXo=r(Zse," class method or the "),dQ=n(Zse,"A",{href:!0});var jxt=s(dQ);CXo=r(jxt,"from_config()"),jxt.forEach(t),wXo=r(Zse,` class
method.`),Zse.forEach(t),AXo=i(yl),mx=n(yl,"P",{});var feo=s(mx);LXo=r(feo,"This class cannot be instantiated directly using "),pve=n(feo,"CODE",{});var Dxt=s(pve);yXo=r(Dxt,"__init__()"),Dxt.forEach(t),xXo=r(feo," (throws an error)."),feo.forEach(t),$Xo=i(yl),Ft=n(yl,"DIV",{class:!0});var Cy=s(Ft);T(gx.$$.fragment,Cy),kXo=i(Cy),_ve=n(Cy,"P",{});var Gxt=s(_ve);SXo=r(Gxt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Gxt.forEach(t),RXo=i(Cy),Ld=n(Cy,"P",{});var ele=s(Ld);PXo=r(ele,`Note:
Loading a model from its configuration file does `),vve=n(ele,"STRONG",{});var Oxt=s(vve);BXo=r(Oxt,"not"),Oxt.forEach(t),IXo=r(ele,` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=n(ele,"A",{href:!0});var Vxt=s(cQ);NXo=r(Vxt,"from_pretrained()"),Vxt.forEach(t),qXo=r(ele," to load the model weights."),ele.forEach(t),jXo=i(Cy),T(U4.$$.fragment,Cy),Cy.forEach(t),DXo=i(yl),ro=n(yl,"DIV",{class:!0});var Ea=s(ro);T(hx.$$.fragment,Ea),GXo=i(Ea),bve=n(Ea,"P",{});var Xxt=s(bve);OXo=r(Xxt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Xxt.forEach(t),VXo=i(Ea),Za=n(Ea,"P",{});var wy=s(Za);XXo=r(wy,"The model class to instantiate is selected based on the "),Fve=n(wy,"CODE",{});var zxt=s(Fve);zXo=r(zxt,"model_type"),zxt.forEach(t),QXo=r(wy,` property of the config object (either
passed as an argument or loaded from `),Tve=n(wy,"CODE",{});var Qxt=s(Tve);WXo=r(Qxt,"pretrained_model_name_or_path"),Qxt.forEach(t),UXo=r(wy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mve=n(wy,"CODE",{});var Wxt=s(Mve);HXo=r(Wxt,"pretrained_model_name_or_path"),Wxt.forEach(t),JXo=r(wy,":"),wy.forEach(t),YXo=i(Ea),U=n(Ea,"UL",{});var Y=s(U);H4=n(Y,"LI",{});var wje=s(H4);Eve=n(wje,"STRONG",{});var Uxt=s(Eve);KXo=r(Uxt,"albert"),Uxt.forEach(t),ZXo=r(wje," \u2014 "),fQ=n(wje,"A",{href:!0});var Hxt=s(fQ);ezo=r(Hxt,"AlbertForMaskedLM"),Hxt.forEach(t),ozo=r(wje," (ALBERT model)"),wje.forEach(t),rzo=i(Y),J4=n(Y,"LI",{});var Aje=s(J4);Cve=n(Aje,"STRONG",{});var Jxt=s(Cve);tzo=r(Jxt,"bart"),Jxt.forEach(t),azo=r(Aje," \u2014 "),mQ=n(Aje,"A",{href:!0});var Yxt=s(mQ);nzo=r(Yxt,"BartForConditionalGeneration"),Yxt.forEach(t),szo=r(Aje," (BART model)"),Aje.forEach(t),lzo=i(Y),Y4=n(Y,"LI",{});var Lje=s(Y4);wve=n(Lje,"STRONG",{});var Kxt=s(wve);izo=r(Kxt,"bert"),Kxt.forEach(t),dzo=r(Lje," \u2014 "),gQ=n(Lje,"A",{href:!0});var Zxt=s(gQ);czo=r(Zxt,"BertForMaskedLM"),Zxt.forEach(t),fzo=r(Lje," (BERT model)"),Lje.forEach(t),mzo=i(Y),K4=n(Y,"LI",{});var yje=s(K4);Ave=n(yje,"STRONG",{});var e$t=s(Ave);gzo=r(e$t,"big_bird"),e$t.forEach(t),hzo=r(yje," \u2014 "),hQ=n(yje,"A",{href:!0});var o$t=s(hQ);uzo=r(o$t,"BigBirdForMaskedLM"),o$t.forEach(t),pzo=r(yje," (BigBird model)"),yje.forEach(t),_zo=i(Y),Z4=n(Y,"LI",{});var xje=s(Z4);Lve=n(xje,"STRONG",{});var r$t=s(Lve);vzo=r(r$t,"camembert"),r$t.forEach(t),bzo=r(xje," \u2014 "),uQ=n(xje,"A",{href:!0});var t$t=s(uQ);Fzo=r(t$t,"CamembertForMaskedLM"),t$t.forEach(t),Tzo=r(xje," (CamemBERT model)"),xje.forEach(t),Mzo=i(Y),eb=n(Y,"LI",{});var $je=s(eb);yve=n($je,"STRONG",{});var a$t=s(yve);Ezo=r(a$t,"convbert"),a$t.forEach(t),Czo=r($je," \u2014 "),pQ=n($je,"A",{href:!0});var n$t=s(pQ);wzo=r(n$t,"ConvBertForMaskedLM"),n$t.forEach(t),Azo=r($je," (ConvBERT model)"),$je.forEach(t),Lzo=i(Y),ob=n(Y,"LI",{});var kje=s(ob);xve=n(kje,"STRONG",{});var s$t=s(xve);yzo=r(s$t,"data2vec-text"),s$t.forEach(t),xzo=r(kje," \u2014 "),_Q=n(kje,"A",{href:!0});var l$t=s(_Q);$zo=r(l$t,"Data2VecTextForMaskedLM"),l$t.forEach(t),kzo=r(kje," (Data2VecText model)"),kje.forEach(t),Szo=i(Y),rb=n(Y,"LI",{});var Sje=s(rb);$ve=n(Sje,"STRONG",{});var i$t=s($ve);Rzo=r(i$t,"deberta"),i$t.forEach(t),Pzo=r(Sje," \u2014 "),vQ=n(Sje,"A",{href:!0});var d$t=s(vQ);Bzo=r(d$t,"DebertaForMaskedLM"),d$t.forEach(t),Izo=r(Sje," (DeBERTa model)"),Sje.forEach(t),Nzo=i(Y),tb=n(Y,"LI",{});var Rje=s(tb);kve=n(Rje,"STRONG",{});var c$t=s(kve);qzo=r(c$t,"deberta-v2"),c$t.forEach(t),jzo=r(Rje," \u2014 "),bQ=n(Rje,"A",{href:!0});var f$t=s(bQ);Dzo=r(f$t,"DebertaV2ForMaskedLM"),f$t.forEach(t),Gzo=r(Rje," (DeBERTa-v2 model)"),Rje.forEach(t),Ozo=i(Y),ab=n(Y,"LI",{});var Pje=s(ab);Sve=n(Pje,"STRONG",{});var m$t=s(Sve);Vzo=r(m$t,"distilbert"),m$t.forEach(t),Xzo=r(Pje," \u2014 "),FQ=n(Pje,"A",{href:!0});var g$t=s(FQ);zzo=r(g$t,"DistilBertForMaskedLM"),g$t.forEach(t),Qzo=r(Pje," (DistilBERT model)"),Pje.forEach(t),Wzo=i(Y),nb=n(Y,"LI",{});var Bje=s(nb);Rve=n(Bje,"STRONG",{});var h$t=s(Rve);Uzo=r(h$t,"electra"),h$t.forEach(t),Hzo=r(Bje," \u2014 "),TQ=n(Bje,"A",{href:!0});var u$t=s(TQ);Jzo=r(u$t,"ElectraForMaskedLM"),u$t.forEach(t),Yzo=r(Bje," (ELECTRA model)"),Bje.forEach(t),Kzo=i(Y),sb=n(Y,"LI",{});var Ije=s(sb);Pve=n(Ije,"STRONG",{});var p$t=s(Pve);Zzo=r(p$t,"ernie"),p$t.forEach(t),eQo=r(Ije," \u2014 "),MQ=n(Ije,"A",{href:!0});var _$t=s(MQ);oQo=r(_$t,"ErnieForMaskedLM"),_$t.forEach(t),rQo=r(Ije," (ERNIE model)"),Ije.forEach(t),tQo=i(Y),lb=n(Y,"LI",{});var Nje=s(lb);Bve=n(Nje,"STRONG",{});var v$t=s(Bve);aQo=r(v$t,"flaubert"),v$t.forEach(t),nQo=r(Nje," \u2014 "),EQ=n(Nje,"A",{href:!0});var b$t=s(EQ);sQo=r(b$t,"FlaubertWithLMHeadModel"),b$t.forEach(t),lQo=r(Nje," (FlauBERT model)"),Nje.forEach(t),iQo=i(Y),ib=n(Y,"LI",{});var qje=s(ib);Ive=n(qje,"STRONG",{});var F$t=s(Ive);dQo=r(F$t,"fnet"),F$t.forEach(t),cQo=r(qje," \u2014 "),CQ=n(qje,"A",{href:!0});var T$t=s(CQ);fQo=r(T$t,"FNetForMaskedLM"),T$t.forEach(t),mQo=r(qje," (FNet model)"),qje.forEach(t),gQo=i(Y),db=n(Y,"LI",{});var jje=s(db);Nve=n(jje,"STRONG",{});var M$t=s(Nve);hQo=r(M$t,"funnel"),M$t.forEach(t),uQo=r(jje," \u2014 "),wQ=n(jje,"A",{href:!0});var E$t=s(wQ);pQo=r(E$t,"FunnelForMaskedLM"),E$t.forEach(t),_Qo=r(jje," (Funnel Transformer model)"),jje.forEach(t),vQo=i(Y),cb=n(Y,"LI",{});var Dje=s(cb);qve=n(Dje,"STRONG",{});var C$t=s(qve);bQo=r(C$t,"ibert"),C$t.forEach(t),FQo=r(Dje," \u2014 "),AQ=n(Dje,"A",{href:!0});var w$t=s(AQ);TQo=r(w$t,"IBertForMaskedLM"),w$t.forEach(t),MQo=r(Dje," (I-BERT model)"),Dje.forEach(t),EQo=i(Y),fb=n(Y,"LI",{});var Gje=s(fb);jve=n(Gje,"STRONG",{});var A$t=s(jve);CQo=r(A$t,"layoutlm"),A$t.forEach(t),wQo=r(Gje," \u2014 "),LQ=n(Gje,"A",{href:!0});var L$t=s(LQ);AQo=r(L$t,"LayoutLMForMaskedLM"),L$t.forEach(t),LQo=r(Gje," (LayoutLM model)"),Gje.forEach(t),yQo=i(Y),mb=n(Y,"LI",{});var Oje=s(mb);Dve=n(Oje,"STRONG",{});var y$t=s(Dve);xQo=r(y$t,"longformer"),y$t.forEach(t),$Qo=r(Oje," \u2014 "),yQ=n(Oje,"A",{href:!0});var x$t=s(yQ);kQo=r(x$t,"LongformerForMaskedLM"),x$t.forEach(t),SQo=r(Oje," (Longformer model)"),Oje.forEach(t),RQo=i(Y),gb=n(Y,"LI",{});var Vje=s(gb);Gve=n(Vje,"STRONG",{});var $$t=s(Gve);PQo=r($$t,"luke"),$$t.forEach(t),BQo=r(Vje," \u2014 "),xQ=n(Vje,"A",{href:!0});var k$t=s(xQ);IQo=r(k$t,"LukeForMaskedLM"),k$t.forEach(t),NQo=r(Vje," (LUKE model)"),Vje.forEach(t),qQo=i(Y),hb=n(Y,"LI",{});var Xje=s(hb);Ove=n(Xje,"STRONG",{});var S$t=s(Ove);jQo=r(S$t,"mbart"),S$t.forEach(t),DQo=r(Xje," \u2014 "),$Q=n(Xje,"A",{href:!0});var R$t=s($Q);GQo=r(R$t,"MBartForConditionalGeneration"),R$t.forEach(t),OQo=r(Xje," (mBART model)"),Xje.forEach(t),VQo=i(Y),ub=n(Y,"LI",{});var zje=s(ub);Vve=n(zje,"STRONG",{});var P$t=s(Vve);XQo=r(P$t,"megatron-bert"),P$t.forEach(t),zQo=r(zje," \u2014 "),kQ=n(zje,"A",{href:!0});var B$t=s(kQ);QQo=r(B$t,"MegatronBertForMaskedLM"),B$t.forEach(t),WQo=r(zje," (Megatron-BERT model)"),zje.forEach(t),UQo=i(Y),pb=n(Y,"LI",{});var Qje=s(pb);Xve=n(Qje,"STRONG",{});var I$t=s(Xve);HQo=r(I$t,"mobilebert"),I$t.forEach(t),JQo=r(Qje," \u2014 "),SQ=n(Qje,"A",{href:!0});var N$t=s(SQ);YQo=r(N$t,"MobileBertForMaskedLM"),N$t.forEach(t),KQo=r(Qje," (MobileBERT model)"),Qje.forEach(t),ZQo=i(Y),_b=n(Y,"LI",{});var Wje=s(_b);zve=n(Wje,"STRONG",{});var q$t=s(zve);eWo=r(q$t,"mpnet"),q$t.forEach(t),oWo=r(Wje," \u2014 "),RQ=n(Wje,"A",{href:!0});var j$t=s(RQ);rWo=r(j$t,"MPNetForMaskedLM"),j$t.forEach(t),tWo=r(Wje," (MPNet model)"),Wje.forEach(t),aWo=i(Y),vb=n(Y,"LI",{});var Uje=s(vb);Qve=n(Uje,"STRONG",{});var D$t=s(Qve);nWo=r(D$t,"mvp"),D$t.forEach(t),sWo=r(Uje," \u2014 "),PQ=n(Uje,"A",{href:!0});var G$t=s(PQ);lWo=r(G$t,"MvpForConditionalGeneration"),G$t.forEach(t),iWo=r(Uje," (MVP model)"),Uje.forEach(t),dWo=i(Y),bb=n(Y,"LI",{});var Hje=s(bb);Wve=n(Hje,"STRONG",{});var O$t=s(Wve);cWo=r(O$t,"nezha"),O$t.forEach(t),fWo=r(Hje," \u2014 "),BQ=n(Hje,"A",{href:!0});var V$t=s(BQ);mWo=r(V$t,"NezhaForMaskedLM"),V$t.forEach(t),gWo=r(Hje," (Nezha model)"),Hje.forEach(t),hWo=i(Y),Fb=n(Y,"LI",{});var Jje=s(Fb);Uve=n(Jje,"STRONG",{});var X$t=s(Uve);uWo=r(X$t,"nystromformer"),X$t.forEach(t),pWo=r(Jje," \u2014 "),IQ=n(Jje,"A",{href:!0});var z$t=s(IQ);_Wo=r(z$t,"NystromformerForMaskedLM"),z$t.forEach(t),vWo=r(Jje," (Nystr\xF6mformer model)"),Jje.forEach(t),bWo=i(Y),Tb=n(Y,"LI",{});var Yje=s(Tb);Hve=n(Yje,"STRONG",{});var Q$t=s(Hve);FWo=r(Q$t,"perceiver"),Q$t.forEach(t),TWo=r(Yje," \u2014 "),NQ=n(Yje,"A",{href:!0});var W$t=s(NQ);MWo=r(W$t,"PerceiverForMaskedLM"),W$t.forEach(t),EWo=r(Yje," (Perceiver model)"),Yje.forEach(t),CWo=i(Y),Mb=n(Y,"LI",{});var Kje=s(Mb);Jve=n(Kje,"STRONG",{});var U$t=s(Jve);wWo=r(U$t,"qdqbert"),U$t.forEach(t),AWo=r(Kje," \u2014 "),qQ=n(Kje,"A",{href:!0});var H$t=s(qQ);LWo=r(H$t,"QDQBertForMaskedLM"),H$t.forEach(t),yWo=r(Kje," (QDQBert model)"),Kje.forEach(t),xWo=i(Y),Eb=n(Y,"LI",{});var Zje=s(Eb);Yve=n(Zje,"STRONG",{});var J$t=s(Yve);$Wo=r(J$t,"reformer"),J$t.forEach(t),kWo=r(Zje," \u2014 "),jQ=n(Zje,"A",{href:!0});var Y$t=s(jQ);SWo=r(Y$t,"ReformerForMaskedLM"),Y$t.forEach(t),RWo=r(Zje," (Reformer model)"),Zje.forEach(t),PWo=i(Y),Cb=n(Y,"LI",{});var eDe=s(Cb);Kve=n(eDe,"STRONG",{});var K$t=s(Kve);BWo=r(K$t,"rembert"),K$t.forEach(t),IWo=r(eDe," \u2014 "),DQ=n(eDe,"A",{href:!0});var Z$t=s(DQ);NWo=r(Z$t,"RemBertForMaskedLM"),Z$t.forEach(t),qWo=r(eDe," (RemBERT model)"),eDe.forEach(t),jWo=i(Y),wb=n(Y,"LI",{});var oDe=s(wb);Zve=n(oDe,"STRONG",{});var ekt=s(Zve);DWo=r(ekt,"roberta"),ekt.forEach(t),GWo=r(oDe," \u2014 "),GQ=n(oDe,"A",{href:!0});var okt=s(GQ);OWo=r(okt,"RobertaForMaskedLM"),okt.forEach(t),VWo=r(oDe," (RoBERTa model)"),oDe.forEach(t),XWo=i(Y),Ab=n(Y,"LI",{});var rDe=s(Ab);e4e=n(rDe,"STRONG",{});var rkt=s(e4e);zWo=r(rkt,"roformer"),rkt.forEach(t),QWo=r(rDe," \u2014 "),OQ=n(rDe,"A",{href:!0});var tkt=s(OQ);WWo=r(tkt,"RoFormerForMaskedLM"),tkt.forEach(t),UWo=r(rDe," (RoFormer model)"),rDe.forEach(t),HWo=i(Y),Lb=n(Y,"LI",{});var tDe=s(Lb);o4e=n(tDe,"STRONG",{});var akt=s(o4e);JWo=r(akt,"squeezebert"),akt.forEach(t),YWo=r(tDe," \u2014 "),VQ=n(tDe,"A",{href:!0});var nkt=s(VQ);KWo=r(nkt,"SqueezeBertForMaskedLM"),nkt.forEach(t),ZWo=r(tDe," (SqueezeBERT model)"),tDe.forEach(t),eUo=i(Y),yb=n(Y,"LI",{});var aDe=s(yb);r4e=n(aDe,"STRONG",{});var skt=s(r4e);oUo=r(skt,"tapas"),skt.forEach(t),rUo=r(aDe," \u2014 "),XQ=n(aDe,"A",{href:!0});var lkt=s(XQ);tUo=r(lkt,"TapasForMaskedLM"),lkt.forEach(t),aUo=r(aDe," (TAPAS model)"),aDe.forEach(t),nUo=i(Y),xb=n(Y,"LI",{});var nDe=s(xb);t4e=n(nDe,"STRONG",{});var ikt=s(t4e);sUo=r(ikt,"wav2vec2"),ikt.forEach(t),lUo=r(nDe," \u2014 "),a4e=n(nDe,"CODE",{});var dkt=s(a4e);iUo=r(dkt,"Wav2Vec2ForMaskedLM"),dkt.forEach(t),dUo=r(nDe," (Wav2Vec2 model)"),nDe.forEach(t),cUo=i(Y),$b=n(Y,"LI",{});var sDe=s($b);n4e=n(sDe,"STRONG",{});var ckt=s(n4e);fUo=r(ckt,"xlm"),ckt.forEach(t),mUo=r(sDe," \u2014 "),zQ=n(sDe,"A",{href:!0});var fkt=s(zQ);gUo=r(fkt,"XLMWithLMHeadModel"),fkt.forEach(t),hUo=r(sDe," (XLM model)"),sDe.forEach(t),uUo=i(Y),kb=n(Y,"LI",{});var lDe=s(kb);s4e=n(lDe,"STRONG",{});var mkt=s(s4e);pUo=r(mkt,"xlm-roberta"),mkt.forEach(t),_Uo=r(lDe," \u2014 "),QQ=n(lDe,"A",{href:!0});var gkt=s(QQ);vUo=r(gkt,"XLMRobertaForMaskedLM"),gkt.forEach(t),bUo=r(lDe," (XLM-RoBERTa model)"),lDe.forEach(t),FUo=i(Y),Sb=n(Y,"LI",{});var iDe=s(Sb);l4e=n(iDe,"STRONG",{});var hkt=s(l4e);TUo=r(hkt,"xlm-roberta-xl"),hkt.forEach(t),MUo=r(iDe," \u2014 "),WQ=n(iDe,"A",{href:!0});var ukt=s(WQ);EUo=r(ukt,"XLMRobertaXLForMaskedLM"),ukt.forEach(t),CUo=r(iDe," (XLM-RoBERTa-XL model)"),iDe.forEach(t),wUo=i(Y),Rb=n(Y,"LI",{});var dDe=s(Rb);i4e=n(dDe,"STRONG",{});var pkt=s(i4e);AUo=r(pkt,"yoso"),pkt.forEach(t),LUo=r(dDe," \u2014 "),UQ=n(dDe,"A",{href:!0});var _kt=s(UQ);yUo=r(_kt,"YosoForMaskedLM"),_kt.forEach(t),xUo=r(dDe," (YOSO model)"),dDe.forEach(t),Y.forEach(t),$Uo=i(Ea),Pb=n(Ea,"P",{});var cDe=s(Pb);kUo=r(cDe,"The model is set in evaluation mode by default using "),d4e=n(cDe,"CODE",{});var vkt=s(d4e);SUo=r(vkt,"model.eval()"),vkt.forEach(t),RUo=r(cDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c4e=n(cDe,"CODE",{});var bkt=s(c4e);PUo=r(bkt,"model.train()"),bkt.forEach(t),cDe.forEach(t),BUo=i(Ea),T(Bb.$$.fragment,Ea),Ea.forEach(t),yl.forEach(t),KYe=i(f),yd=n(f,"H2",{class:!0});var meo=s(yd);Ib=n(meo,"A",{id:!0,class:!0,href:!0});var Fkt=s(Ib);f4e=n(Fkt,"SPAN",{});var Tkt=s(f4e);T(ux.$$.fragment,Tkt),Tkt.forEach(t),Fkt.forEach(t),IUo=i(meo),m4e=n(meo,"SPAN",{});var Mkt=s(m4e);NUo=r(Mkt,"AutoModelForSeq2SeqLM"),Mkt.forEach(t),meo.forEach(t),ZYe=i(f),qo=n(f,"DIV",{class:!0});var xl=s(qo);T(px.$$.fragment,xl),qUo=i(xl),xd=n(xl,"P",{});var ole=s(xd);jUo=r(ole,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),HQ=n(ole,"A",{href:!0});var Ekt=s(HQ);DUo=r(Ekt,"from_pretrained()"),Ekt.forEach(t),GUo=r(ole," class method or the "),JQ=n(ole,"A",{href:!0});var Ckt=s(JQ);OUo=r(Ckt,"from_config()"),Ckt.forEach(t),VUo=r(ole,` class
method.`),ole.forEach(t),XUo=i(xl),_x=n(xl,"P",{});var geo=s(_x);zUo=r(geo,"This class cannot be instantiated directly using "),g4e=n(geo,"CODE",{});var wkt=s(g4e);QUo=r(wkt,"__init__()"),wkt.forEach(t),WUo=r(geo," (throws an error)."),geo.forEach(t),UUo=i(xl),Tt=n(xl,"DIV",{class:!0});var Ay=s(Tt);T(vx.$$.fragment,Ay),HUo=i(Ay),h4e=n(Ay,"P",{});var Akt=s(h4e);JUo=r(Akt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Akt.forEach(t),YUo=i(Ay),$d=n(Ay,"P",{});var rle=s($d);KUo=r(rle,`Note:
Loading a model from its configuration file does `),u4e=n(rle,"STRONG",{});var Lkt=s(u4e);ZUo=r(Lkt,"not"),Lkt.forEach(t),eHo=r(rle,` load the model weights. It only affects the
model\u2019s configuration. Use `),YQ=n(rle,"A",{href:!0});var ykt=s(YQ);oHo=r(ykt,"from_pretrained()"),ykt.forEach(t),rHo=r(rle," to load the model weights."),rle.forEach(t),tHo=i(Ay),T(Nb.$$.fragment,Ay),Ay.forEach(t),aHo=i(xl),to=n(xl,"DIV",{class:!0});var Ca=s(to);T(bx.$$.fragment,Ca),nHo=i(Ca),p4e=n(Ca,"P",{});var xkt=s(p4e);sHo=r(xkt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),xkt.forEach(t),lHo=i(Ca),en=n(Ca,"P",{});var Ly=s(en);iHo=r(Ly,"The model class to instantiate is selected based on the "),_4e=n(Ly,"CODE",{});var $kt=s(_4e);dHo=r($kt,"model_type"),$kt.forEach(t),cHo=r(Ly,` property of the config object (either
passed as an argument or loaded from `),v4e=n(Ly,"CODE",{});var kkt=s(v4e);fHo=r(kkt,"pretrained_model_name_or_path"),kkt.forEach(t),mHo=r(Ly,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b4e=n(Ly,"CODE",{});var Skt=s(b4e);gHo=r(Skt,"pretrained_model_name_or_path"),Skt.forEach(t),hHo=r(Ly,":"),Ly.forEach(t),uHo=i(Ca),fe=n(Ca,"UL",{});var pe=s(fe);qb=n(pe,"LI",{});var fDe=s(qb);F4e=n(fDe,"STRONG",{});var Rkt=s(F4e);pHo=r(Rkt,"bart"),Rkt.forEach(t),_Ho=r(fDe," \u2014 "),KQ=n(fDe,"A",{href:!0});var Pkt=s(KQ);vHo=r(Pkt,"BartForConditionalGeneration"),Pkt.forEach(t),bHo=r(fDe," (BART model)"),fDe.forEach(t),FHo=i(pe),jb=n(pe,"LI",{});var mDe=s(jb);T4e=n(mDe,"STRONG",{});var Bkt=s(T4e);THo=r(Bkt,"bigbird_pegasus"),Bkt.forEach(t),MHo=r(mDe," \u2014 "),ZQ=n(mDe,"A",{href:!0});var Ikt=s(ZQ);EHo=r(Ikt,"BigBirdPegasusForConditionalGeneration"),Ikt.forEach(t),CHo=r(mDe," (BigBird-Pegasus model)"),mDe.forEach(t),wHo=i(pe),Db=n(pe,"LI",{});var gDe=s(Db);M4e=n(gDe,"STRONG",{});var Nkt=s(M4e);AHo=r(Nkt,"blenderbot"),Nkt.forEach(t),LHo=r(gDe," \u2014 "),eW=n(gDe,"A",{href:!0});var qkt=s(eW);yHo=r(qkt,"BlenderbotForConditionalGeneration"),qkt.forEach(t),xHo=r(gDe," (Blenderbot model)"),gDe.forEach(t),$Ho=i(pe),Gb=n(pe,"LI",{});var hDe=s(Gb);E4e=n(hDe,"STRONG",{});var jkt=s(E4e);kHo=r(jkt,"blenderbot-small"),jkt.forEach(t),SHo=r(hDe," \u2014 "),oW=n(hDe,"A",{href:!0});var Dkt=s(oW);RHo=r(Dkt,"BlenderbotSmallForConditionalGeneration"),Dkt.forEach(t),PHo=r(hDe," (BlenderbotSmall model)"),hDe.forEach(t),BHo=i(pe),Ob=n(pe,"LI",{});var uDe=s(Ob);C4e=n(uDe,"STRONG",{});var Gkt=s(C4e);IHo=r(Gkt,"encoder-decoder"),Gkt.forEach(t),NHo=r(uDe," \u2014 "),rW=n(uDe,"A",{href:!0});var Okt=s(rW);qHo=r(Okt,"EncoderDecoderModel"),Okt.forEach(t),jHo=r(uDe," (Encoder decoder model)"),uDe.forEach(t),DHo=i(pe),Vb=n(pe,"LI",{});var pDe=s(Vb);w4e=n(pDe,"STRONG",{});var Vkt=s(w4e);GHo=r(Vkt,"fsmt"),Vkt.forEach(t),OHo=r(pDe," \u2014 "),tW=n(pDe,"A",{href:!0});var Xkt=s(tW);VHo=r(Xkt,"FSMTForConditionalGeneration"),Xkt.forEach(t),XHo=r(pDe," (FairSeq Machine-Translation model)"),pDe.forEach(t),zHo=i(pe),Xb=n(pe,"LI",{});var _De=s(Xb);A4e=n(_De,"STRONG",{});var zkt=s(A4e);QHo=r(zkt,"led"),zkt.forEach(t),WHo=r(_De," \u2014 "),aW=n(_De,"A",{href:!0});var Qkt=s(aW);UHo=r(Qkt,"LEDForConditionalGeneration"),Qkt.forEach(t),HHo=r(_De," (LED model)"),_De.forEach(t),JHo=i(pe),zb=n(pe,"LI",{});var vDe=s(zb);L4e=n(vDe,"STRONG",{});var Wkt=s(L4e);YHo=r(Wkt,"longt5"),Wkt.forEach(t),KHo=r(vDe," \u2014 "),nW=n(vDe,"A",{href:!0});var Ukt=s(nW);ZHo=r(Ukt,"LongT5ForConditionalGeneration"),Ukt.forEach(t),eJo=r(vDe," (LongT5 model)"),vDe.forEach(t),oJo=i(pe),Qb=n(pe,"LI",{});var bDe=s(Qb);y4e=n(bDe,"STRONG",{});var Hkt=s(y4e);rJo=r(Hkt,"m2m_100"),Hkt.forEach(t),tJo=r(bDe," \u2014 "),sW=n(bDe,"A",{href:!0});var Jkt=s(sW);aJo=r(Jkt,"M2M100ForConditionalGeneration"),Jkt.forEach(t),nJo=r(bDe," (M2M100 model)"),bDe.forEach(t),sJo=i(pe),Wb=n(pe,"LI",{});var FDe=s(Wb);x4e=n(FDe,"STRONG",{});var Ykt=s(x4e);lJo=r(Ykt,"marian"),Ykt.forEach(t),iJo=r(FDe," \u2014 "),lW=n(FDe,"A",{href:!0});var Kkt=s(lW);dJo=r(Kkt,"MarianMTModel"),Kkt.forEach(t),cJo=r(FDe," (Marian model)"),FDe.forEach(t),fJo=i(pe),Ub=n(pe,"LI",{});var TDe=s(Ub);$4e=n(TDe,"STRONG",{});var Zkt=s($4e);mJo=r(Zkt,"mbart"),Zkt.forEach(t),gJo=r(TDe," \u2014 "),iW=n(TDe,"A",{href:!0});var eSt=s(iW);hJo=r(eSt,"MBartForConditionalGeneration"),eSt.forEach(t),uJo=r(TDe," (mBART model)"),TDe.forEach(t),pJo=i(pe),Hb=n(pe,"LI",{});var MDe=s(Hb);k4e=n(MDe,"STRONG",{});var oSt=s(k4e);_Jo=r(oSt,"mt5"),oSt.forEach(t),vJo=r(MDe," \u2014 "),dW=n(MDe,"A",{href:!0});var rSt=s(dW);bJo=r(rSt,"MT5ForConditionalGeneration"),rSt.forEach(t),FJo=r(MDe," (MT5 model)"),MDe.forEach(t),TJo=i(pe),Jb=n(pe,"LI",{});var EDe=s(Jb);S4e=n(EDe,"STRONG",{});var tSt=s(S4e);MJo=r(tSt,"mvp"),tSt.forEach(t),EJo=r(EDe," \u2014 "),cW=n(EDe,"A",{href:!0});var aSt=s(cW);CJo=r(aSt,"MvpForConditionalGeneration"),aSt.forEach(t),wJo=r(EDe," (MVP model)"),EDe.forEach(t),AJo=i(pe),Yb=n(pe,"LI",{});var CDe=s(Yb);R4e=n(CDe,"STRONG",{});var nSt=s(R4e);LJo=r(nSt,"nllb"),nSt.forEach(t),yJo=r(CDe," \u2014 "),fW=n(CDe,"A",{href:!0});var sSt=s(fW);xJo=r(sSt,"M2M100ForConditionalGeneration"),sSt.forEach(t),$Jo=r(CDe," (NLLB model)"),CDe.forEach(t),kJo=i(pe),Kb=n(pe,"LI",{});var wDe=s(Kb);P4e=n(wDe,"STRONG",{});var lSt=s(P4e);SJo=r(lSt,"pegasus"),lSt.forEach(t),RJo=r(wDe," \u2014 "),mW=n(wDe,"A",{href:!0});var iSt=s(mW);PJo=r(iSt,"PegasusForConditionalGeneration"),iSt.forEach(t),BJo=r(wDe," (Pegasus model)"),wDe.forEach(t),IJo=i(pe),Zb=n(pe,"LI",{});var ADe=s(Zb);B4e=n(ADe,"STRONG",{});var dSt=s(B4e);NJo=r(dSt,"pegasus_x"),dSt.forEach(t),qJo=r(ADe," \u2014 "),gW=n(ADe,"A",{href:!0});var cSt=s(gW);jJo=r(cSt,"PegasusXForConditionalGeneration"),cSt.forEach(t),DJo=r(ADe," (PEGASUS-X model)"),ADe.forEach(t),GJo=i(pe),e1=n(pe,"LI",{});var LDe=s(e1);I4e=n(LDe,"STRONG",{});var fSt=s(I4e);OJo=r(fSt,"plbart"),fSt.forEach(t),VJo=r(LDe," \u2014 "),hW=n(LDe,"A",{href:!0});var mSt=s(hW);XJo=r(mSt,"PLBartForConditionalGeneration"),mSt.forEach(t),zJo=r(LDe," (PLBart model)"),LDe.forEach(t),QJo=i(pe),o1=n(pe,"LI",{});var yDe=s(o1);N4e=n(yDe,"STRONG",{});var gSt=s(N4e);WJo=r(gSt,"prophetnet"),gSt.forEach(t),UJo=r(yDe," \u2014 "),uW=n(yDe,"A",{href:!0});var hSt=s(uW);HJo=r(hSt,"ProphetNetForConditionalGeneration"),hSt.forEach(t),JJo=r(yDe," (ProphetNet model)"),yDe.forEach(t),YJo=i(pe),r1=n(pe,"LI",{});var xDe=s(r1);q4e=n(xDe,"STRONG",{});var uSt=s(q4e);KJo=r(uSt,"t5"),uSt.forEach(t),ZJo=r(xDe," \u2014 "),pW=n(xDe,"A",{href:!0});var pSt=s(pW);eYo=r(pSt,"T5ForConditionalGeneration"),pSt.forEach(t),oYo=r(xDe," (T5 model)"),xDe.forEach(t),rYo=i(pe),t1=n(pe,"LI",{});var $De=s(t1);j4e=n($De,"STRONG",{});var _St=s(j4e);tYo=r(_St,"xlm-prophetnet"),_St.forEach(t),aYo=r($De," \u2014 "),_W=n($De,"A",{href:!0});var vSt=s(_W);nYo=r(vSt,"XLMProphetNetForConditionalGeneration"),vSt.forEach(t),sYo=r($De," (XLM-ProphetNet model)"),$De.forEach(t),pe.forEach(t),lYo=i(Ca),a1=n(Ca,"P",{});var kDe=s(a1);iYo=r(kDe,"The model is set in evaluation mode by default using "),D4e=n(kDe,"CODE",{});var bSt=s(D4e);dYo=r(bSt,"model.eval()"),bSt.forEach(t),cYo=r(kDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),G4e=n(kDe,"CODE",{});var FSt=s(G4e);fYo=r(FSt,"model.train()"),FSt.forEach(t),kDe.forEach(t),mYo=i(Ca),T(n1.$$.fragment,Ca),Ca.forEach(t),xl.forEach(t),eKe=i(f),kd=n(f,"H2",{class:!0});var heo=s(kd);s1=n(heo,"A",{id:!0,class:!0,href:!0});var TSt=s(s1);O4e=n(TSt,"SPAN",{});var MSt=s(O4e);T(Fx.$$.fragment,MSt),MSt.forEach(t),TSt.forEach(t),gYo=i(heo),V4e=n(heo,"SPAN",{});var ESt=s(V4e);hYo=r(ESt,"AutoModelForSequenceClassification"),ESt.forEach(t),heo.forEach(t),oKe=i(f),jo=n(f,"DIV",{class:!0});var $l=s(jo);T(Tx.$$.fragment,$l),uYo=i($l),Sd=n($l,"P",{});var tle=s(Sd);pYo=r(tle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),vW=n(tle,"A",{href:!0});var CSt=s(vW);_Yo=r(CSt,"from_pretrained()"),CSt.forEach(t),vYo=r(tle," class method or the "),bW=n(tle,"A",{href:!0});var wSt=s(bW);bYo=r(wSt,"from_config()"),wSt.forEach(t),FYo=r(tle,` class
method.`),tle.forEach(t),TYo=i($l),Mx=n($l,"P",{});var ueo=s(Mx);MYo=r(ueo,"This class cannot be instantiated directly using "),X4e=n(ueo,"CODE",{});var ASt=s(X4e);EYo=r(ASt,"__init__()"),ASt.forEach(t),CYo=r(ueo," (throws an error)."),ueo.forEach(t),wYo=i($l),Mt=n($l,"DIV",{class:!0});var yy=s(Mt);T(Ex.$$.fragment,yy),AYo=i(yy),z4e=n(yy,"P",{});var LSt=s(z4e);LYo=r(LSt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),LSt.forEach(t),yYo=i(yy),Rd=n(yy,"P",{});var ale=s(Rd);xYo=r(ale,`Note:
Loading a model from its configuration file does `),Q4e=n(ale,"STRONG",{});var ySt=s(Q4e);$Yo=r(ySt,"not"),ySt.forEach(t),kYo=r(ale,` load the model weights. It only affects the
model\u2019s configuration. Use `),FW=n(ale,"A",{href:!0});var xSt=s(FW);SYo=r(xSt,"from_pretrained()"),xSt.forEach(t),RYo=r(ale," to load the model weights."),ale.forEach(t),PYo=i(yy),T(l1.$$.fragment,yy),yy.forEach(t),BYo=i($l),ao=n($l,"DIV",{class:!0});var wa=s(ao);T(Cx.$$.fragment,wa),IYo=i(wa),W4e=n(wa,"P",{});var $St=s(W4e);NYo=r($St,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),$St.forEach(t),qYo=i(wa),on=n(wa,"P",{});var xy=s(on);jYo=r(xy,"The model class to instantiate is selected based on the "),U4e=n(xy,"CODE",{});var kSt=s(U4e);DYo=r(kSt,"model_type"),kSt.forEach(t),GYo=r(xy,` property of the config object (either
passed as an argument or loaded from `),H4e=n(xy,"CODE",{});var SSt=s(H4e);OYo=r(SSt,"pretrained_model_name_or_path"),SSt.forEach(t),VYo=r(xy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J4e=n(xy,"CODE",{});var RSt=s(J4e);XYo=r(RSt,"pretrained_model_name_or_path"),RSt.forEach(t),zYo=r(xy,":"),xy.forEach(t),QYo=i(wa),q=n(wa,"UL",{});var D=s(q);i1=n(D,"LI",{});var SDe=s(i1);Y4e=n(SDe,"STRONG",{});var PSt=s(Y4e);WYo=r(PSt,"albert"),PSt.forEach(t),UYo=r(SDe," \u2014 "),TW=n(SDe,"A",{href:!0});var BSt=s(TW);HYo=r(BSt,"AlbertForSequenceClassification"),BSt.forEach(t),JYo=r(SDe," (ALBERT model)"),SDe.forEach(t),YYo=i(D),d1=n(D,"LI",{});var RDe=s(d1);K4e=n(RDe,"STRONG",{});var ISt=s(K4e);KYo=r(ISt,"bart"),ISt.forEach(t),ZYo=r(RDe," \u2014 "),MW=n(RDe,"A",{href:!0});var NSt=s(MW);eKo=r(NSt,"BartForSequenceClassification"),NSt.forEach(t),oKo=r(RDe," (BART model)"),RDe.forEach(t),rKo=i(D),c1=n(D,"LI",{});var PDe=s(c1);Z4e=n(PDe,"STRONG",{});var qSt=s(Z4e);tKo=r(qSt,"bert"),qSt.forEach(t),aKo=r(PDe," \u2014 "),EW=n(PDe,"A",{href:!0});var jSt=s(EW);nKo=r(jSt,"BertForSequenceClassification"),jSt.forEach(t),sKo=r(PDe," (BERT model)"),PDe.forEach(t),lKo=i(D),f1=n(D,"LI",{});var BDe=s(f1);ebe=n(BDe,"STRONG",{});var DSt=s(ebe);iKo=r(DSt,"big_bird"),DSt.forEach(t),dKo=r(BDe," \u2014 "),CW=n(BDe,"A",{href:!0});var GSt=s(CW);cKo=r(GSt,"BigBirdForSequenceClassification"),GSt.forEach(t),fKo=r(BDe," (BigBird model)"),BDe.forEach(t),mKo=i(D),m1=n(D,"LI",{});var IDe=s(m1);obe=n(IDe,"STRONG",{});var OSt=s(obe);gKo=r(OSt,"bigbird_pegasus"),OSt.forEach(t),hKo=r(IDe," \u2014 "),wW=n(IDe,"A",{href:!0});var VSt=s(wW);uKo=r(VSt,"BigBirdPegasusForSequenceClassification"),VSt.forEach(t),pKo=r(IDe," (BigBird-Pegasus model)"),IDe.forEach(t),_Ko=i(D),g1=n(D,"LI",{});var NDe=s(g1);rbe=n(NDe,"STRONG",{});var XSt=s(rbe);vKo=r(XSt,"bloom"),XSt.forEach(t),bKo=r(NDe," \u2014 "),AW=n(NDe,"A",{href:!0});var zSt=s(AW);FKo=r(zSt,"BloomForSequenceClassification"),zSt.forEach(t),TKo=r(NDe," (BLOOM model)"),NDe.forEach(t),MKo=i(D),h1=n(D,"LI",{});var qDe=s(h1);tbe=n(qDe,"STRONG",{});var QSt=s(tbe);EKo=r(QSt,"camembert"),QSt.forEach(t),CKo=r(qDe," \u2014 "),LW=n(qDe,"A",{href:!0});var WSt=s(LW);wKo=r(WSt,"CamembertForSequenceClassification"),WSt.forEach(t),AKo=r(qDe," (CamemBERT model)"),qDe.forEach(t),LKo=i(D),u1=n(D,"LI",{});var jDe=s(u1);abe=n(jDe,"STRONG",{});var USt=s(abe);yKo=r(USt,"canine"),USt.forEach(t),xKo=r(jDe," \u2014 "),yW=n(jDe,"A",{href:!0});var HSt=s(yW);$Ko=r(HSt,"CanineForSequenceClassification"),HSt.forEach(t),kKo=r(jDe," (CANINE model)"),jDe.forEach(t),SKo=i(D),p1=n(D,"LI",{});var DDe=s(p1);nbe=n(DDe,"STRONG",{});var JSt=s(nbe);RKo=r(JSt,"convbert"),JSt.forEach(t),PKo=r(DDe," \u2014 "),xW=n(DDe,"A",{href:!0});var YSt=s(xW);BKo=r(YSt,"ConvBertForSequenceClassification"),YSt.forEach(t),IKo=r(DDe," (ConvBERT model)"),DDe.forEach(t),NKo=i(D),_1=n(D,"LI",{});var GDe=s(_1);sbe=n(GDe,"STRONG",{});var KSt=s(sbe);qKo=r(KSt,"ctrl"),KSt.forEach(t),jKo=r(GDe," \u2014 "),$W=n(GDe,"A",{href:!0});var ZSt=s($W);DKo=r(ZSt,"CTRLForSequenceClassification"),ZSt.forEach(t),GKo=r(GDe," (CTRL model)"),GDe.forEach(t),OKo=i(D),v1=n(D,"LI",{});var ODe=s(v1);lbe=n(ODe,"STRONG",{});var eRt=s(lbe);VKo=r(eRt,"data2vec-text"),eRt.forEach(t),XKo=r(ODe," \u2014 "),kW=n(ODe,"A",{href:!0});var oRt=s(kW);zKo=r(oRt,"Data2VecTextForSequenceClassification"),oRt.forEach(t),QKo=r(ODe," (Data2VecText model)"),ODe.forEach(t),WKo=i(D),b1=n(D,"LI",{});var VDe=s(b1);ibe=n(VDe,"STRONG",{});var rRt=s(ibe);UKo=r(rRt,"deberta"),rRt.forEach(t),HKo=r(VDe," \u2014 "),SW=n(VDe,"A",{href:!0});var tRt=s(SW);JKo=r(tRt,"DebertaForSequenceClassification"),tRt.forEach(t),YKo=r(VDe," (DeBERTa model)"),VDe.forEach(t),KKo=i(D),F1=n(D,"LI",{});var XDe=s(F1);dbe=n(XDe,"STRONG",{});var aRt=s(dbe);ZKo=r(aRt,"deberta-v2"),aRt.forEach(t),eZo=r(XDe," \u2014 "),RW=n(XDe,"A",{href:!0});var nRt=s(RW);oZo=r(nRt,"DebertaV2ForSequenceClassification"),nRt.forEach(t),rZo=r(XDe," (DeBERTa-v2 model)"),XDe.forEach(t),tZo=i(D),T1=n(D,"LI",{});var zDe=s(T1);cbe=n(zDe,"STRONG",{});var sRt=s(cbe);aZo=r(sRt,"distilbert"),sRt.forEach(t),nZo=r(zDe," \u2014 "),PW=n(zDe,"A",{href:!0});var lRt=s(PW);sZo=r(lRt,"DistilBertForSequenceClassification"),lRt.forEach(t),lZo=r(zDe," (DistilBERT model)"),zDe.forEach(t),iZo=i(D),M1=n(D,"LI",{});var QDe=s(M1);fbe=n(QDe,"STRONG",{});var iRt=s(fbe);dZo=r(iRt,"electra"),iRt.forEach(t),cZo=r(QDe," \u2014 "),BW=n(QDe,"A",{href:!0});var dRt=s(BW);fZo=r(dRt,"ElectraForSequenceClassification"),dRt.forEach(t),mZo=r(QDe," (ELECTRA model)"),QDe.forEach(t),gZo=i(D),E1=n(D,"LI",{});var WDe=s(E1);mbe=n(WDe,"STRONG",{});var cRt=s(mbe);hZo=r(cRt,"ernie"),cRt.forEach(t),uZo=r(WDe," \u2014 "),IW=n(WDe,"A",{href:!0});var fRt=s(IW);pZo=r(fRt,"ErnieForSequenceClassification"),fRt.forEach(t),_Zo=r(WDe," (ERNIE model)"),WDe.forEach(t),vZo=i(D),C1=n(D,"LI",{});var UDe=s(C1);gbe=n(UDe,"STRONG",{});var mRt=s(gbe);bZo=r(mRt,"flaubert"),mRt.forEach(t),FZo=r(UDe," \u2014 "),NW=n(UDe,"A",{href:!0});var gRt=s(NW);TZo=r(gRt,"FlaubertForSequenceClassification"),gRt.forEach(t),MZo=r(UDe," (FlauBERT model)"),UDe.forEach(t),EZo=i(D),w1=n(D,"LI",{});var HDe=s(w1);hbe=n(HDe,"STRONG",{});var hRt=s(hbe);CZo=r(hRt,"fnet"),hRt.forEach(t),wZo=r(HDe," \u2014 "),qW=n(HDe,"A",{href:!0});var uRt=s(qW);AZo=r(uRt,"FNetForSequenceClassification"),uRt.forEach(t),LZo=r(HDe," (FNet model)"),HDe.forEach(t),yZo=i(D),A1=n(D,"LI",{});var JDe=s(A1);ube=n(JDe,"STRONG",{});var pRt=s(ube);xZo=r(pRt,"funnel"),pRt.forEach(t),$Zo=r(JDe," \u2014 "),jW=n(JDe,"A",{href:!0});var _Rt=s(jW);kZo=r(_Rt,"FunnelForSequenceClassification"),_Rt.forEach(t),SZo=r(JDe," (Funnel Transformer model)"),JDe.forEach(t),RZo=i(D),L1=n(D,"LI",{});var YDe=s(L1);pbe=n(YDe,"STRONG",{});var vRt=s(pbe);PZo=r(vRt,"gpt2"),vRt.forEach(t),BZo=r(YDe," \u2014 "),DW=n(YDe,"A",{href:!0});var bRt=s(DW);IZo=r(bRt,"GPT2ForSequenceClassification"),bRt.forEach(t),NZo=r(YDe," (OpenAI GPT-2 model)"),YDe.forEach(t),qZo=i(D),y1=n(D,"LI",{});var KDe=s(y1);_be=n(KDe,"STRONG",{});var FRt=s(_be);jZo=r(FRt,"gpt_neo"),FRt.forEach(t),DZo=r(KDe," \u2014 "),GW=n(KDe,"A",{href:!0});var TRt=s(GW);GZo=r(TRt,"GPTNeoForSequenceClassification"),TRt.forEach(t),OZo=r(KDe," (GPT Neo model)"),KDe.forEach(t),VZo=i(D),x1=n(D,"LI",{});var ZDe=s(x1);vbe=n(ZDe,"STRONG",{});var MRt=s(vbe);XZo=r(MRt,"gptj"),MRt.forEach(t),zZo=r(ZDe," \u2014 "),OW=n(ZDe,"A",{href:!0});var ERt=s(OW);QZo=r(ERt,"GPTJForSequenceClassification"),ERt.forEach(t),WZo=r(ZDe," (GPT-J model)"),ZDe.forEach(t),UZo=i(D),$1=n(D,"LI",{});var eGe=s($1);bbe=n(eGe,"STRONG",{});var CRt=s(bbe);HZo=r(CRt,"ibert"),CRt.forEach(t),JZo=r(eGe," \u2014 "),VW=n(eGe,"A",{href:!0});var wRt=s(VW);YZo=r(wRt,"IBertForSequenceClassification"),wRt.forEach(t),KZo=r(eGe," (I-BERT model)"),eGe.forEach(t),ZZo=i(D),k1=n(D,"LI",{});var oGe=s(k1);Fbe=n(oGe,"STRONG",{});var ARt=s(Fbe);eer=r(ARt,"layoutlm"),ARt.forEach(t),oer=r(oGe," \u2014 "),XW=n(oGe,"A",{href:!0});var LRt=s(XW);rer=r(LRt,"LayoutLMForSequenceClassification"),LRt.forEach(t),ter=r(oGe," (LayoutLM model)"),oGe.forEach(t),aer=i(D),S1=n(D,"LI",{});var rGe=s(S1);Tbe=n(rGe,"STRONG",{});var yRt=s(Tbe);ner=r(yRt,"layoutlmv2"),yRt.forEach(t),ser=r(rGe," \u2014 "),zW=n(rGe,"A",{href:!0});var xRt=s(zW);ler=r(xRt,"LayoutLMv2ForSequenceClassification"),xRt.forEach(t),ier=r(rGe," (LayoutLMv2 model)"),rGe.forEach(t),der=i(D),R1=n(D,"LI",{});var tGe=s(R1);Mbe=n(tGe,"STRONG",{});var $Rt=s(Mbe);cer=r($Rt,"layoutlmv3"),$Rt.forEach(t),fer=r(tGe," \u2014 "),QW=n(tGe,"A",{href:!0});var kRt=s(QW);mer=r(kRt,"LayoutLMv3ForSequenceClassification"),kRt.forEach(t),ger=r(tGe," (LayoutLMv3 model)"),tGe.forEach(t),her=i(D),P1=n(D,"LI",{});var aGe=s(P1);Ebe=n(aGe,"STRONG",{});var SRt=s(Ebe);uer=r(SRt,"led"),SRt.forEach(t),per=r(aGe," \u2014 "),WW=n(aGe,"A",{href:!0});var RRt=s(WW);_er=r(RRt,"LEDForSequenceClassification"),RRt.forEach(t),ver=r(aGe," (LED model)"),aGe.forEach(t),ber=i(D),B1=n(D,"LI",{});var nGe=s(B1);Cbe=n(nGe,"STRONG",{});var PRt=s(Cbe);Fer=r(PRt,"longformer"),PRt.forEach(t),Ter=r(nGe," \u2014 "),UW=n(nGe,"A",{href:!0});var BRt=s(UW);Mer=r(BRt,"LongformerForSequenceClassification"),BRt.forEach(t),Eer=r(nGe," (Longformer model)"),nGe.forEach(t),Cer=i(D),I1=n(D,"LI",{});var sGe=s(I1);wbe=n(sGe,"STRONG",{});var IRt=s(wbe);wer=r(IRt,"luke"),IRt.forEach(t),Aer=r(sGe," \u2014 "),HW=n(sGe,"A",{href:!0});var NRt=s(HW);Ler=r(NRt,"LukeForSequenceClassification"),NRt.forEach(t),yer=r(sGe," (LUKE model)"),sGe.forEach(t),xer=i(D),N1=n(D,"LI",{});var lGe=s(N1);Abe=n(lGe,"STRONG",{});var qRt=s(Abe);$er=r(qRt,"mbart"),qRt.forEach(t),ker=r(lGe," \u2014 "),JW=n(lGe,"A",{href:!0});var jRt=s(JW);Ser=r(jRt,"MBartForSequenceClassification"),jRt.forEach(t),Rer=r(lGe," (mBART model)"),lGe.forEach(t),Per=i(D),q1=n(D,"LI",{});var iGe=s(q1);Lbe=n(iGe,"STRONG",{});var DRt=s(Lbe);Ber=r(DRt,"megatron-bert"),DRt.forEach(t),Ier=r(iGe," \u2014 "),YW=n(iGe,"A",{href:!0});var GRt=s(YW);Ner=r(GRt,"MegatronBertForSequenceClassification"),GRt.forEach(t),qer=r(iGe," (Megatron-BERT model)"),iGe.forEach(t),jer=i(D),j1=n(D,"LI",{});var dGe=s(j1);ybe=n(dGe,"STRONG",{});var ORt=s(ybe);Der=r(ORt,"mobilebert"),ORt.forEach(t),Ger=r(dGe," \u2014 "),KW=n(dGe,"A",{href:!0});var VRt=s(KW);Oer=r(VRt,"MobileBertForSequenceClassification"),VRt.forEach(t),Ver=r(dGe," (MobileBERT model)"),dGe.forEach(t),Xer=i(D),D1=n(D,"LI",{});var cGe=s(D1);xbe=n(cGe,"STRONG",{});var XRt=s(xbe);zer=r(XRt,"mpnet"),XRt.forEach(t),Qer=r(cGe," \u2014 "),ZW=n(cGe,"A",{href:!0});var zRt=s(ZW);Wer=r(zRt,"MPNetForSequenceClassification"),zRt.forEach(t),Uer=r(cGe," (MPNet model)"),cGe.forEach(t),Her=i(D),G1=n(D,"LI",{});var fGe=s(G1);$be=n(fGe,"STRONG",{});var QRt=s($be);Jer=r(QRt,"mvp"),QRt.forEach(t),Yer=r(fGe," \u2014 "),eU=n(fGe,"A",{href:!0});var WRt=s(eU);Ker=r(WRt,"MvpForSequenceClassification"),WRt.forEach(t),Zer=r(fGe," (MVP model)"),fGe.forEach(t),eor=i(D),O1=n(D,"LI",{});var mGe=s(O1);kbe=n(mGe,"STRONG",{});var URt=s(kbe);oor=r(URt,"nezha"),URt.forEach(t),ror=r(mGe," \u2014 "),oU=n(mGe,"A",{href:!0});var HRt=s(oU);tor=r(HRt,"NezhaForSequenceClassification"),HRt.forEach(t),aor=r(mGe," (Nezha model)"),mGe.forEach(t),nor=i(D),V1=n(D,"LI",{});var gGe=s(V1);Sbe=n(gGe,"STRONG",{});var JRt=s(Sbe);sor=r(JRt,"nystromformer"),JRt.forEach(t),lor=r(gGe," \u2014 "),rU=n(gGe,"A",{href:!0});var YRt=s(rU);ior=r(YRt,"NystromformerForSequenceClassification"),YRt.forEach(t),dor=r(gGe," (Nystr\xF6mformer model)"),gGe.forEach(t),cor=i(D),X1=n(D,"LI",{});var hGe=s(X1);Rbe=n(hGe,"STRONG",{});var KRt=s(Rbe);mor=r(KRt,"openai-gpt"),KRt.forEach(t),gor=r(hGe," \u2014 "),tU=n(hGe,"A",{href:!0});var ZRt=s(tU);hor=r(ZRt,"OpenAIGPTForSequenceClassification"),ZRt.forEach(t),uor=r(hGe," (OpenAI GPT model)"),hGe.forEach(t),por=i(D),z1=n(D,"LI",{});var uGe=s(z1);Pbe=n(uGe,"STRONG",{});var ePt=s(Pbe);_or=r(ePt,"opt"),ePt.forEach(t),vor=r(uGe," \u2014 "),aU=n(uGe,"A",{href:!0});var oPt=s(aU);bor=r(oPt,"OPTForSequenceClassification"),oPt.forEach(t),For=r(uGe," (OPT model)"),uGe.forEach(t),Tor=i(D),Q1=n(D,"LI",{});var pGe=s(Q1);Bbe=n(pGe,"STRONG",{});var rPt=s(Bbe);Mor=r(rPt,"perceiver"),rPt.forEach(t),Eor=r(pGe," \u2014 "),nU=n(pGe,"A",{href:!0});var tPt=s(nU);Cor=r(tPt,"PerceiverForSequenceClassification"),tPt.forEach(t),wor=r(pGe," (Perceiver model)"),pGe.forEach(t),Aor=i(D),W1=n(D,"LI",{});var _Ge=s(W1);Ibe=n(_Ge,"STRONG",{});var aPt=s(Ibe);Lor=r(aPt,"plbart"),aPt.forEach(t),yor=r(_Ge," \u2014 "),sU=n(_Ge,"A",{href:!0});var nPt=s(sU);xor=r(nPt,"PLBartForSequenceClassification"),nPt.forEach(t),$or=r(_Ge," (PLBart model)"),_Ge.forEach(t),kor=i(D),U1=n(D,"LI",{});var vGe=s(U1);Nbe=n(vGe,"STRONG",{});var sPt=s(Nbe);Sor=r(sPt,"qdqbert"),sPt.forEach(t),Ror=r(vGe," \u2014 "),lU=n(vGe,"A",{href:!0});var lPt=s(lU);Por=r(lPt,"QDQBertForSequenceClassification"),lPt.forEach(t),Bor=r(vGe," (QDQBert model)"),vGe.forEach(t),Ior=i(D),H1=n(D,"LI",{});var bGe=s(H1);qbe=n(bGe,"STRONG",{});var iPt=s(qbe);Nor=r(iPt,"reformer"),iPt.forEach(t),qor=r(bGe," \u2014 "),iU=n(bGe,"A",{href:!0});var dPt=s(iU);jor=r(dPt,"ReformerForSequenceClassification"),dPt.forEach(t),Dor=r(bGe," (Reformer model)"),bGe.forEach(t),Gor=i(D),J1=n(D,"LI",{});var FGe=s(J1);jbe=n(FGe,"STRONG",{});var cPt=s(jbe);Oor=r(cPt,"rembert"),cPt.forEach(t),Vor=r(FGe," \u2014 "),dU=n(FGe,"A",{href:!0});var fPt=s(dU);Xor=r(fPt,"RemBertForSequenceClassification"),fPt.forEach(t),zor=r(FGe," (RemBERT model)"),FGe.forEach(t),Qor=i(D),Y1=n(D,"LI",{});var TGe=s(Y1);Dbe=n(TGe,"STRONG",{});var mPt=s(Dbe);Wor=r(mPt,"roberta"),mPt.forEach(t),Uor=r(TGe," \u2014 "),cU=n(TGe,"A",{href:!0});var gPt=s(cU);Hor=r(gPt,"RobertaForSequenceClassification"),gPt.forEach(t),Jor=r(TGe," (RoBERTa model)"),TGe.forEach(t),Yor=i(D),K1=n(D,"LI",{});var MGe=s(K1);Gbe=n(MGe,"STRONG",{});var hPt=s(Gbe);Kor=r(hPt,"roformer"),hPt.forEach(t),Zor=r(MGe," \u2014 "),fU=n(MGe,"A",{href:!0});var uPt=s(fU);err=r(uPt,"RoFormerForSequenceClassification"),uPt.forEach(t),orr=r(MGe," (RoFormer model)"),MGe.forEach(t),rrr=i(D),Z1=n(D,"LI",{});var EGe=s(Z1);Obe=n(EGe,"STRONG",{});var pPt=s(Obe);trr=r(pPt,"squeezebert"),pPt.forEach(t),arr=r(EGe," \u2014 "),mU=n(EGe,"A",{href:!0});var _Pt=s(mU);nrr=r(_Pt,"SqueezeBertForSequenceClassification"),_Pt.forEach(t),srr=r(EGe," (SqueezeBERT model)"),EGe.forEach(t),lrr=i(D),e0=n(D,"LI",{});var CGe=s(e0);Vbe=n(CGe,"STRONG",{});var vPt=s(Vbe);irr=r(vPt,"tapas"),vPt.forEach(t),drr=r(CGe," \u2014 "),gU=n(CGe,"A",{href:!0});var bPt=s(gU);crr=r(bPt,"TapasForSequenceClassification"),bPt.forEach(t),frr=r(CGe," (TAPAS model)"),CGe.forEach(t),mrr=i(D),o0=n(D,"LI",{});var wGe=s(o0);Xbe=n(wGe,"STRONG",{});var FPt=s(Xbe);grr=r(FPt,"transfo-xl"),FPt.forEach(t),hrr=r(wGe," \u2014 "),hU=n(wGe,"A",{href:!0});var TPt=s(hU);urr=r(TPt,"TransfoXLForSequenceClassification"),TPt.forEach(t),prr=r(wGe," (Transformer-XL model)"),wGe.forEach(t),_rr=i(D),r0=n(D,"LI",{});var AGe=s(r0);zbe=n(AGe,"STRONG",{});var MPt=s(zbe);vrr=r(MPt,"xlm"),MPt.forEach(t),brr=r(AGe," \u2014 "),uU=n(AGe,"A",{href:!0});var EPt=s(uU);Frr=r(EPt,"XLMForSequenceClassification"),EPt.forEach(t),Trr=r(AGe," (XLM model)"),AGe.forEach(t),Mrr=i(D),t0=n(D,"LI",{});var LGe=s(t0);Qbe=n(LGe,"STRONG",{});var CPt=s(Qbe);Err=r(CPt,"xlm-roberta"),CPt.forEach(t),Crr=r(LGe," \u2014 "),pU=n(LGe,"A",{href:!0});var wPt=s(pU);wrr=r(wPt,"XLMRobertaForSequenceClassification"),wPt.forEach(t),Arr=r(LGe," (XLM-RoBERTa model)"),LGe.forEach(t),Lrr=i(D),a0=n(D,"LI",{});var yGe=s(a0);Wbe=n(yGe,"STRONG",{});var APt=s(Wbe);yrr=r(APt,"xlm-roberta-xl"),APt.forEach(t),xrr=r(yGe," \u2014 "),_U=n(yGe,"A",{href:!0});var LPt=s(_U);$rr=r(LPt,"XLMRobertaXLForSequenceClassification"),LPt.forEach(t),krr=r(yGe," (XLM-RoBERTa-XL model)"),yGe.forEach(t),Srr=i(D),n0=n(D,"LI",{});var xGe=s(n0);Ube=n(xGe,"STRONG",{});var yPt=s(Ube);Rrr=r(yPt,"xlnet"),yPt.forEach(t),Prr=r(xGe," \u2014 "),vU=n(xGe,"A",{href:!0});var xPt=s(vU);Brr=r(xPt,"XLNetForSequenceClassification"),xPt.forEach(t),Irr=r(xGe," (XLNet model)"),xGe.forEach(t),Nrr=i(D),s0=n(D,"LI",{});var $Ge=s(s0);Hbe=n($Ge,"STRONG",{});var $Pt=s(Hbe);qrr=r($Pt,"yoso"),$Pt.forEach(t),jrr=r($Ge," \u2014 "),bU=n($Ge,"A",{href:!0});var kPt=s(bU);Drr=r(kPt,"YosoForSequenceClassification"),kPt.forEach(t),Grr=r($Ge," (YOSO model)"),$Ge.forEach(t),D.forEach(t),Orr=i(wa),l0=n(wa,"P",{});var kGe=s(l0);Vrr=r(kGe,"The model is set in evaluation mode by default using "),Jbe=n(kGe,"CODE",{});var SPt=s(Jbe);Xrr=r(SPt,"model.eval()"),SPt.forEach(t),zrr=r(kGe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ybe=n(kGe,"CODE",{});var RPt=s(Ybe);Qrr=r(RPt,"model.train()"),RPt.forEach(t),kGe.forEach(t),Wrr=i(wa),T(i0.$$.fragment,wa),wa.forEach(t),$l.forEach(t),rKe=i(f),Pd=n(f,"H2",{class:!0});var peo=s(Pd);d0=n(peo,"A",{id:!0,class:!0,href:!0});var PPt=s(d0);Kbe=n(PPt,"SPAN",{});var BPt=s(Kbe);T(wx.$$.fragment,BPt),BPt.forEach(t),PPt.forEach(t),Urr=i(peo),Zbe=n(peo,"SPAN",{});var IPt=s(Zbe);Hrr=r(IPt,"AutoModelForMultipleChoice"),IPt.forEach(t),peo.forEach(t),tKe=i(f),Do=n(f,"DIV",{class:!0});var kl=s(Do);T(Ax.$$.fragment,kl),Jrr=i(kl),Bd=n(kl,"P",{});var nle=s(Bd);Yrr=r(nle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),FU=n(nle,"A",{href:!0});var NPt=s(FU);Krr=r(NPt,"from_pretrained()"),NPt.forEach(t),Zrr=r(nle," class method or the "),TU=n(nle,"A",{href:!0});var qPt=s(TU);etr=r(qPt,"from_config()"),qPt.forEach(t),otr=r(nle,` class
method.`),nle.forEach(t),rtr=i(kl),Lx=n(kl,"P",{});var _eo=s(Lx);ttr=r(_eo,"This class cannot be instantiated directly using "),e1e=n(_eo,"CODE",{});var jPt=s(e1e);atr=r(jPt,"__init__()"),jPt.forEach(t),ntr=r(_eo," (throws an error)."),_eo.forEach(t),str=i(kl),Et=n(kl,"DIV",{class:!0});var $y=s(Et);T(yx.$$.fragment,$y),ltr=i($y),o1e=n($y,"P",{});var DPt=s(o1e);itr=r(DPt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),DPt.forEach(t),dtr=i($y),Id=n($y,"P",{});var sle=s(Id);ctr=r(sle,`Note:
Loading a model from its configuration file does `),r1e=n(sle,"STRONG",{});var GPt=s(r1e);ftr=r(GPt,"not"),GPt.forEach(t),mtr=r(sle,` load the model weights. It only affects the
model\u2019s configuration. Use `),MU=n(sle,"A",{href:!0});var OPt=s(MU);gtr=r(OPt,"from_pretrained()"),OPt.forEach(t),htr=r(sle," to load the model weights."),sle.forEach(t),utr=i($y),T(c0.$$.fragment,$y),$y.forEach(t),ptr=i(kl),no=n(kl,"DIV",{class:!0});var Aa=s(no);T(xx.$$.fragment,Aa),_tr=i(Aa),t1e=n(Aa,"P",{});var VPt=s(t1e);vtr=r(VPt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),VPt.forEach(t),btr=i(Aa),rn=n(Aa,"P",{});var ky=s(rn);Ftr=r(ky,"The model class to instantiate is selected based on the "),a1e=n(ky,"CODE",{});var XPt=s(a1e);Ttr=r(XPt,"model_type"),XPt.forEach(t),Mtr=r(ky,` property of the config object (either
passed as an argument or loaded from `),n1e=n(ky,"CODE",{});var zPt=s(n1e);Etr=r(zPt,"pretrained_model_name_or_path"),zPt.forEach(t),Ctr=r(ky,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s1e=n(ky,"CODE",{});var QPt=s(s1e);wtr=r(QPt,"pretrained_model_name_or_path"),QPt.forEach(t),Atr=r(ky,":"),ky.forEach(t),Ltr=i(Aa),Z=n(Aa,"UL",{});var ee=s(Z);f0=n(ee,"LI",{});var SGe=s(f0);l1e=n(SGe,"STRONG",{});var WPt=s(l1e);ytr=r(WPt,"albert"),WPt.forEach(t),xtr=r(SGe," \u2014 "),EU=n(SGe,"A",{href:!0});var UPt=s(EU);$tr=r(UPt,"AlbertForMultipleChoice"),UPt.forEach(t),ktr=r(SGe," (ALBERT model)"),SGe.forEach(t),Str=i(ee),m0=n(ee,"LI",{});var RGe=s(m0);i1e=n(RGe,"STRONG",{});var HPt=s(i1e);Rtr=r(HPt,"bert"),HPt.forEach(t),Ptr=r(RGe," \u2014 "),CU=n(RGe,"A",{href:!0});var JPt=s(CU);Btr=r(JPt,"BertForMultipleChoice"),JPt.forEach(t),Itr=r(RGe," (BERT model)"),RGe.forEach(t),Ntr=i(ee),g0=n(ee,"LI",{});var PGe=s(g0);d1e=n(PGe,"STRONG",{});var YPt=s(d1e);qtr=r(YPt,"big_bird"),YPt.forEach(t),jtr=r(PGe," \u2014 "),wU=n(PGe,"A",{href:!0});var KPt=s(wU);Dtr=r(KPt,"BigBirdForMultipleChoice"),KPt.forEach(t),Gtr=r(PGe," (BigBird model)"),PGe.forEach(t),Otr=i(ee),h0=n(ee,"LI",{});var BGe=s(h0);c1e=n(BGe,"STRONG",{});var ZPt=s(c1e);Vtr=r(ZPt,"camembert"),ZPt.forEach(t),Xtr=r(BGe," \u2014 "),AU=n(BGe,"A",{href:!0});var eBt=s(AU);ztr=r(eBt,"CamembertForMultipleChoice"),eBt.forEach(t),Qtr=r(BGe," (CamemBERT model)"),BGe.forEach(t),Wtr=i(ee),u0=n(ee,"LI",{});var IGe=s(u0);f1e=n(IGe,"STRONG",{});var oBt=s(f1e);Utr=r(oBt,"canine"),oBt.forEach(t),Htr=r(IGe," \u2014 "),LU=n(IGe,"A",{href:!0});var rBt=s(LU);Jtr=r(rBt,"CanineForMultipleChoice"),rBt.forEach(t),Ytr=r(IGe," (CANINE model)"),IGe.forEach(t),Ktr=i(ee),p0=n(ee,"LI",{});var NGe=s(p0);m1e=n(NGe,"STRONG",{});var tBt=s(m1e);Ztr=r(tBt,"convbert"),tBt.forEach(t),ear=r(NGe," \u2014 "),yU=n(NGe,"A",{href:!0});var aBt=s(yU);oar=r(aBt,"ConvBertForMultipleChoice"),aBt.forEach(t),rar=r(NGe," (ConvBERT model)"),NGe.forEach(t),tar=i(ee),_0=n(ee,"LI",{});var qGe=s(_0);g1e=n(qGe,"STRONG",{});var nBt=s(g1e);aar=r(nBt,"data2vec-text"),nBt.forEach(t),nar=r(qGe," \u2014 "),xU=n(qGe,"A",{href:!0});var sBt=s(xU);sar=r(sBt,"Data2VecTextForMultipleChoice"),sBt.forEach(t),lar=r(qGe," (Data2VecText model)"),qGe.forEach(t),iar=i(ee),v0=n(ee,"LI",{});var jGe=s(v0);h1e=n(jGe,"STRONG",{});var lBt=s(h1e);dar=r(lBt,"deberta-v2"),lBt.forEach(t),car=r(jGe," \u2014 "),$U=n(jGe,"A",{href:!0});var iBt=s($U);far=r(iBt,"DebertaV2ForMultipleChoice"),iBt.forEach(t),mar=r(jGe," (DeBERTa-v2 model)"),jGe.forEach(t),gar=i(ee),b0=n(ee,"LI",{});var DGe=s(b0);u1e=n(DGe,"STRONG",{});var dBt=s(u1e);har=r(dBt,"distilbert"),dBt.forEach(t),uar=r(DGe," \u2014 "),kU=n(DGe,"A",{href:!0});var cBt=s(kU);par=r(cBt,"DistilBertForMultipleChoice"),cBt.forEach(t),_ar=r(DGe," (DistilBERT model)"),DGe.forEach(t),bar=i(ee),F0=n(ee,"LI",{});var GGe=s(F0);p1e=n(GGe,"STRONG",{});var fBt=s(p1e);Far=r(fBt,"electra"),fBt.forEach(t),Tar=r(GGe," \u2014 "),SU=n(GGe,"A",{href:!0});var mBt=s(SU);Mar=r(mBt,"ElectraForMultipleChoice"),mBt.forEach(t),Ear=r(GGe," (ELECTRA model)"),GGe.forEach(t),Car=i(ee),T0=n(ee,"LI",{});var OGe=s(T0);_1e=n(OGe,"STRONG",{});var gBt=s(_1e);war=r(gBt,"ernie"),gBt.forEach(t),Aar=r(OGe," \u2014 "),RU=n(OGe,"A",{href:!0});var hBt=s(RU);Lar=r(hBt,"ErnieForMultipleChoice"),hBt.forEach(t),yar=r(OGe," (ERNIE model)"),OGe.forEach(t),xar=i(ee),M0=n(ee,"LI",{});var VGe=s(M0);v1e=n(VGe,"STRONG",{});var uBt=s(v1e);$ar=r(uBt,"flaubert"),uBt.forEach(t),kar=r(VGe," \u2014 "),PU=n(VGe,"A",{href:!0});var pBt=s(PU);Sar=r(pBt,"FlaubertForMultipleChoice"),pBt.forEach(t),Rar=r(VGe," (FlauBERT model)"),VGe.forEach(t),Par=i(ee),E0=n(ee,"LI",{});var XGe=s(E0);b1e=n(XGe,"STRONG",{});var _Bt=s(b1e);Bar=r(_Bt,"fnet"),_Bt.forEach(t),Iar=r(XGe," \u2014 "),BU=n(XGe,"A",{href:!0});var vBt=s(BU);Nar=r(vBt,"FNetForMultipleChoice"),vBt.forEach(t),qar=r(XGe," (FNet model)"),XGe.forEach(t),jar=i(ee),C0=n(ee,"LI",{});var zGe=s(C0);F1e=n(zGe,"STRONG",{});var bBt=s(F1e);Dar=r(bBt,"funnel"),bBt.forEach(t),Gar=r(zGe," \u2014 "),IU=n(zGe,"A",{href:!0});var FBt=s(IU);Oar=r(FBt,"FunnelForMultipleChoice"),FBt.forEach(t),Var=r(zGe," (Funnel Transformer model)"),zGe.forEach(t),Xar=i(ee),w0=n(ee,"LI",{});var QGe=s(w0);T1e=n(QGe,"STRONG",{});var TBt=s(T1e);zar=r(TBt,"ibert"),TBt.forEach(t),Qar=r(QGe," \u2014 "),NU=n(QGe,"A",{href:!0});var MBt=s(NU);War=r(MBt,"IBertForMultipleChoice"),MBt.forEach(t),Uar=r(QGe," (I-BERT model)"),QGe.forEach(t),Har=i(ee),A0=n(ee,"LI",{});var WGe=s(A0);M1e=n(WGe,"STRONG",{});var EBt=s(M1e);Jar=r(EBt,"longformer"),EBt.forEach(t),Yar=r(WGe," \u2014 "),qU=n(WGe,"A",{href:!0});var CBt=s(qU);Kar=r(CBt,"LongformerForMultipleChoice"),CBt.forEach(t),Zar=r(WGe," (Longformer model)"),WGe.forEach(t),enr=i(ee),L0=n(ee,"LI",{});var UGe=s(L0);E1e=n(UGe,"STRONG",{});var wBt=s(E1e);onr=r(wBt,"luke"),wBt.forEach(t),rnr=r(UGe," \u2014 "),jU=n(UGe,"A",{href:!0});var ABt=s(jU);tnr=r(ABt,"LukeForMultipleChoice"),ABt.forEach(t),anr=r(UGe," (LUKE model)"),UGe.forEach(t),nnr=i(ee),y0=n(ee,"LI",{});var HGe=s(y0);C1e=n(HGe,"STRONG",{});var LBt=s(C1e);snr=r(LBt,"megatron-bert"),LBt.forEach(t),lnr=r(HGe," \u2014 "),DU=n(HGe,"A",{href:!0});var yBt=s(DU);inr=r(yBt,"MegatronBertForMultipleChoice"),yBt.forEach(t),dnr=r(HGe," (Megatron-BERT model)"),HGe.forEach(t),cnr=i(ee),x0=n(ee,"LI",{});var JGe=s(x0);w1e=n(JGe,"STRONG",{});var xBt=s(w1e);fnr=r(xBt,"mobilebert"),xBt.forEach(t),mnr=r(JGe," \u2014 "),GU=n(JGe,"A",{href:!0});var $Bt=s(GU);gnr=r($Bt,"MobileBertForMultipleChoice"),$Bt.forEach(t),hnr=r(JGe," (MobileBERT model)"),JGe.forEach(t),unr=i(ee),$0=n(ee,"LI",{});var YGe=s($0);A1e=n(YGe,"STRONG",{});var kBt=s(A1e);pnr=r(kBt,"mpnet"),kBt.forEach(t),_nr=r(YGe," \u2014 "),OU=n(YGe,"A",{href:!0});var SBt=s(OU);vnr=r(SBt,"MPNetForMultipleChoice"),SBt.forEach(t),bnr=r(YGe," (MPNet model)"),YGe.forEach(t),Fnr=i(ee),k0=n(ee,"LI",{});var KGe=s(k0);L1e=n(KGe,"STRONG",{});var RBt=s(L1e);Tnr=r(RBt,"nezha"),RBt.forEach(t),Mnr=r(KGe," \u2014 "),VU=n(KGe,"A",{href:!0});var PBt=s(VU);Enr=r(PBt,"NezhaForMultipleChoice"),PBt.forEach(t),Cnr=r(KGe," (Nezha model)"),KGe.forEach(t),wnr=i(ee),S0=n(ee,"LI",{});var ZGe=s(S0);y1e=n(ZGe,"STRONG",{});var BBt=s(y1e);Anr=r(BBt,"nystromformer"),BBt.forEach(t),Lnr=r(ZGe," \u2014 "),XU=n(ZGe,"A",{href:!0});var IBt=s(XU);ynr=r(IBt,"NystromformerForMultipleChoice"),IBt.forEach(t),xnr=r(ZGe," (Nystr\xF6mformer model)"),ZGe.forEach(t),$nr=i(ee),R0=n(ee,"LI",{});var eOe=s(R0);x1e=n(eOe,"STRONG",{});var NBt=s(x1e);knr=r(NBt,"qdqbert"),NBt.forEach(t),Snr=r(eOe," \u2014 "),zU=n(eOe,"A",{href:!0});var qBt=s(zU);Rnr=r(qBt,"QDQBertForMultipleChoice"),qBt.forEach(t),Pnr=r(eOe," (QDQBert model)"),eOe.forEach(t),Bnr=i(ee),P0=n(ee,"LI",{});var oOe=s(P0);$1e=n(oOe,"STRONG",{});var jBt=s($1e);Inr=r(jBt,"rembert"),jBt.forEach(t),Nnr=r(oOe," \u2014 "),QU=n(oOe,"A",{href:!0});var DBt=s(QU);qnr=r(DBt,"RemBertForMultipleChoice"),DBt.forEach(t),jnr=r(oOe," (RemBERT model)"),oOe.forEach(t),Dnr=i(ee),B0=n(ee,"LI",{});var rOe=s(B0);k1e=n(rOe,"STRONG",{});var GBt=s(k1e);Gnr=r(GBt,"roberta"),GBt.forEach(t),Onr=r(rOe," \u2014 "),WU=n(rOe,"A",{href:!0});var OBt=s(WU);Vnr=r(OBt,"RobertaForMultipleChoice"),OBt.forEach(t),Xnr=r(rOe," (RoBERTa model)"),rOe.forEach(t),znr=i(ee),I0=n(ee,"LI",{});var tOe=s(I0);S1e=n(tOe,"STRONG",{});var VBt=s(S1e);Qnr=r(VBt,"roformer"),VBt.forEach(t),Wnr=r(tOe," \u2014 "),UU=n(tOe,"A",{href:!0});var XBt=s(UU);Unr=r(XBt,"RoFormerForMultipleChoice"),XBt.forEach(t),Hnr=r(tOe," (RoFormer model)"),tOe.forEach(t),Jnr=i(ee),N0=n(ee,"LI",{});var aOe=s(N0);R1e=n(aOe,"STRONG",{});var zBt=s(R1e);Ynr=r(zBt,"squeezebert"),zBt.forEach(t),Knr=r(aOe," \u2014 "),HU=n(aOe,"A",{href:!0});var QBt=s(HU);Znr=r(QBt,"SqueezeBertForMultipleChoice"),QBt.forEach(t),esr=r(aOe," (SqueezeBERT model)"),aOe.forEach(t),osr=i(ee),q0=n(ee,"LI",{});var nOe=s(q0);P1e=n(nOe,"STRONG",{});var WBt=s(P1e);rsr=r(WBt,"xlm"),WBt.forEach(t),tsr=r(nOe," \u2014 "),JU=n(nOe,"A",{href:!0});var UBt=s(JU);asr=r(UBt,"XLMForMultipleChoice"),UBt.forEach(t),nsr=r(nOe," (XLM model)"),nOe.forEach(t),ssr=i(ee),j0=n(ee,"LI",{});var sOe=s(j0);B1e=n(sOe,"STRONG",{});var HBt=s(B1e);lsr=r(HBt,"xlm-roberta"),HBt.forEach(t),isr=r(sOe," \u2014 "),YU=n(sOe,"A",{href:!0});var JBt=s(YU);dsr=r(JBt,"XLMRobertaForMultipleChoice"),JBt.forEach(t),csr=r(sOe," (XLM-RoBERTa model)"),sOe.forEach(t),fsr=i(ee),D0=n(ee,"LI",{});var lOe=s(D0);I1e=n(lOe,"STRONG",{});var YBt=s(I1e);msr=r(YBt,"xlm-roberta-xl"),YBt.forEach(t),gsr=r(lOe," \u2014 "),KU=n(lOe,"A",{href:!0});var KBt=s(KU);hsr=r(KBt,"XLMRobertaXLForMultipleChoice"),KBt.forEach(t),usr=r(lOe," (XLM-RoBERTa-XL model)"),lOe.forEach(t),psr=i(ee),G0=n(ee,"LI",{});var iOe=s(G0);N1e=n(iOe,"STRONG",{});var ZBt=s(N1e);_sr=r(ZBt,"xlnet"),ZBt.forEach(t),vsr=r(iOe," \u2014 "),ZU=n(iOe,"A",{href:!0});var eIt=s(ZU);bsr=r(eIt,"XLNetForMultipleChoice"),eIt.forEach(t),Fsr=r(iOe," (XLNet model)"),iOe.forEach(t),Tsr=i(ee),O0=n(ee,"LI",{});var dOe=s(O0);q1e=n(dOe,"STRONG",{});var oIt=s(q1e);Msr=r(oIt,"yoso"),oIt.forEach(t),Esr=r(dOe," \u2014 "),eH=n(dOe,"A",{href:!0});var rIt=s(eH);Csr=r(rIt,"YosoForMultipleChoice"),rIt.forEach(t),wsr=r(dOe," (YOSO model)"),dOe.forEach(t),ee.forEach(t),Asr=i(Aa),V0=n(Aa,"P",{});var cOe=s(V0);Lsr=r(cOe,"The model is set in evaluation mode by default using "),j1e=n(cOe,"CODE",{});var tIt=s(j1e);ysr=r(tIt,"model.eval()"),tIt.forEach(t),xsr=r(cOe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D1e=n(cOe,"CODE",{});var aIt=s(D1e);$sr=r(aIt,"model.train()"),aIt.forEach(t),cOe.forEach(t),ksr=i(Aa),T(X0.$$.fragment,Aa),Aa.forEach(t),kl.forEach(t),aKe=i(f),Nd=n(f,"H2",{class:!0});var veo=s(Nd);z0=n(veo,"A",{id:!0,class:!0,href:!0});var nIt=s(z0);G1e=n(nIt,"SPAN",{});var sIt=s(G1e);T($x.$$.fragment,sIt),sIt.forEach(t),nIt.forEach(t),Ssr=i(veo),O1e=n(veo,"SPAN",{});var lIt=s(O1e);Rsr=r(lIt,"AutoModelForNextSentencePrediction"),lIt.forEach(t),veo.forEach(t),nKe=i(f),Go=n(f,"DIV",{class:!0});var Sl=s(Go);T(kx.$$.fragment,Sl),Psr=i(Sl),qd=n(Sl,"P",{});var lle=s(qd);Bsr=r(lle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),oH=n(lle,"A",{href:!0});var iIt=s(oH);Isr=r(iIt,"from_pretrained()"),iIt.forEach(t),Nsr=r(lle," class method or the "),rH=n(lle,"A",{href:!0});var dIt=s(rH);qsr=r(dIt,"from_config()"),dIt.forEach(t),jsr=r(lle,` class
method.`),lle.forEach(t),Dsr=i(Sl),Sx=n(Sl,"P",{});var beo=s(Sx);Gsr=r(beo,"This class cannot be instantiated directly using "),V1e=n(beo,"CODE",{});var cIt=s(V1e);Osr=r(cIt,"__init__()"),cIt.forEach(t),Vsr=r(beo," (throws an error)."),beo.forEach(t),Xsr=i(Sl),Ct=n(Sl,"DIV",{class:!0});var Sy=s(Ct);T(Rx.$$.fragment,Sy),zsr=i(Sy),X1e=n(Sy,"P",{});var fIt=s(X1e);Qsr=r(fIt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),fIt.forEach(t),Wsr=i(Sy),jd=n(Sy,"P",{});var ile=s(jd);Usr=r(ile,`Note:
Loading a model from its configuration file does `),z1e=n(ile,"STRONG",{});var mIt=s(z1e);Hsr=r(mIt,"not"),mIt.forEach(t),Jsr=r(ile,` load the model weights. It only affects the
model\u2019s configuration. Use `),tH=n(ile,"A",{href:!0});var gIt=s(tH);Ysr=r(gIt,"from_pretrained()"),gIt.forEach(t),Ksr=r(ile," to load the model weights."),ile.forEach(t),Zsr=i(Sy),T(Q0.$$.fragment,Sy),Sy.forEach(t),elr=i(Sl),so=n(Sl,"DIV",{class:!0});var La=s(so);T(Px.$$.fragment,La),olr=i(La),Q1e=n(La,"P",{});var hIt=s(Q1e);rlr=r(hIt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),hIt.forEach(t),tlr=i(La),tn=n(La,"P",{});var Ry=s(tn);alr=r(Ry,"The model class to instantiate is selected based on the "),W1e=n(Ry,"CODE",{});var uIt=s(W1e);nlr=r(uIt,"model_type"),uIt.forEach(t),slr=r(Ry,` property of the config object (either
passed as an argument or loaded from `),U1e=n(Ry,"CODE",{});var pIt=s(U1e);llr=r(pIt,"pretrained_model_name_or_path"),pIt.forEach(t),ilr=r(Ry,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H1e=n(Ry,"CODE",{});var _It=s(H1e);dlr=r(_It,"pretrained_model_name_or_path"),_It.forEach(t),clr=r(Ry,":"),Ry.forEach(t),flr=i(La),Ue=n(La,"UL",{});var ct=s(Ue);W0=n(ct,"LI",{});var fOe=s(W0);J1e=n(fOe,"STRONG",{});var vIt=s(J1e);mlr=r(vIt,"bert"),vIt.forEach(t),glr=r(fOe," \u2014 "),aH=n(fOe,"A",{href:!0});var bIt=s(aH);hlr=r(bIt,"BertForNextSentencePrediction"),bIt.forEach(t),ulr=r(fOe," (BERT model)"),fOe.forEach(t),plr=i(ct),U0=n(ct,"LI",{});var mOe=s(U0);Y1e=n(mOe,"STRONG",{});var FIt=s(Y1e);_lr=r(FIt,"ernie"),FIt.forEach(t),vlr=r(mOe," \u2014 "),nH=n(mOe,"A",{href:!0});var TIt=s(nH);blr=r(TIt,"ErnieForNextSentencePrediction"),TIt.forEach(t),Flr=r(mOe," (ERNIE model)"),mOe.forEach(t),Tlr=i(ct),H0=n(ct,"LI",{});var gOe=s(H0);K1e=n(gOe,"STRONG",{});var MIt=s(K1e);Mlr=r(MIt,"fnet"),MIt.forEach(t),Elr=r(gOe," \u2014 "),sH=n(gOe,"A",{href:!0});var EIt=s(sH);Clr=r(EIt,"FNetForNextSentencePrediction"),EIt.forEach(t),wlr=r(gOe," (FNet model)"),gOe.forEach(t),Alr=i(ct),J0=n(ct,"LI",{});var hOe=s(J0);Z1e=n(hOe,"STRONG",{});var CIt=s(Z1e);Llr=r(CIt,"megatron-bert"),CIt.forEach(t),ylr=r(hOe," \u2014 "),lH=n(hOe,"A",{href:!0});var wIt=s(lH);xlr=r(wIt,"MegatronBertForNextSentencePrediction"),wIt.forEach(t),$lr=r(hOe," (Megatron-BERT model)"),hOe.forEach(t),klr=i(ct),Y0=n(ct,"LI",{});var uOe=s(Y0);e0e=n(uOe,"STRONG",{});var AIt=s(e0e);Slr=r(AIt,"mobilebert"),AIt.forEach(t),Rlr=r(uOe," \u2014 "),iH=n(uOe,"A",{href:!0});var LIt=s(iH);Plr=r(LIt,"MobileBertForNextSentencePrediction"),LIt.forEach(t),Blr=r(uOe," (MobileBERT model)"),uOe.forEach(t),Ilr=i(ct),K0=n(ct,"LI",{});var pOe=s(K0);o0e=n(pOe,"STRONG",{});var yIt=s(o0e);Nlr=r(yIt,"nezha"),yIt.forEach(t),qlr=r(pOe," \u2014 "),dH=n(pOe,"A",{href:!0});var xIt=s(dH);jlr=r(xIt,"NezhaForNextSentencePrediction"),xIt.forEach(t),Dlr=r(pOe," (Nezha model)"),pOe.forEach(t),Glr=i(ct),Z0=n(ct,"LI",{});var _Oe=s(Z0);r0e=n(_Oe,"STRONG",{});var $It=s(r0e);Olr=r($It,"qdqbert"),$It.forEach(t),Vlr=r(_Oe," \u2014 "),cH=n(_Oe,"A",{href:!0});var kIt=s(cH);Xlr=r(kIt,"QDQBertForNextSentencePrediction"),kIt.forEach(t),zlr=r(_Oe," (QDQBert model)"),_Oe.forEach(t),ct.forEach(t),Qlr=i(La),eF=n(La,"P",{});var vOe=s(eF);Wlr=r(vOe,"The model is set in evaluation mode by default using "),t0e=n(vOe,"CODE",{});var SIt=s(t0e);Ulr=r(SIt,"model.eval()"),SIt.forEach(t),Hlr=r(vOe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a0e=n(vOe,"CODE",{});var RIt=s(a0e);Jlr=r(RIt,"model.train()"),RIt.forEach(t),vOe.forEach(t),Ylr=i(La),T(oF.$$.fragment,La),La.forEach(t),Sl.forEach(t),sKe=i(f),Dd=n(f,"H2",{class:!0});var Feo=s(Dd);rF=n(Feo,"A",{id:!0,class:!0,href:!0});var PIt=s(rF);n0e=n(PIt,"SPAN",{});var BIt=s(n0e);T(Bx.$$.fragment,BIt),BIt.forEach(t),PIt.forEach(t),Klr=i(Feo),s0e=n(Feo,"SPAN",{});var IIt=s(s0e);Zlr=r(IIt,"AutoModelForTokenClassification"),IIt.forEach(t),Feo.forEach(t),lKe=i(f),Oo=n(f,"DIV",{class:!0});var Rl=s(Oo);T(Ix.$$.fragment,Rl),eir=i(Rl),Gd=n(Rl,"P",{});var dle=s(Gd);oir=r(dle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),fH=n(dle,"A",{href:!0});var NIt=s(fH);rir=r(NIt,"from_pretrained()"),NIt.forEach(t),tir=r(dle," class method or the "),mH=n(dle,"A",{href:!0});var qIt=s(mH);air=r(qIt,"from_config()"),qIt.forEach(t),nir=r(dle,` class
method.`),dle.forEach(t),sir=i(Rl),Nx=n(Rl,"P",{});var Teo=s(Nx);lir=r(Teo,"This class cannot be instantiated directly using "),l0e=n(Teo,"CODE",{});var jIt=s(l0e);iir=r(jIt,"__init__()"),jIt.forEach(t),dir=r(Teo," (throws an error)."),Teo.forEach(t),cir=i(Rl),wt=n(Rl,"DIV",{class:!0});var Py=s(wt);T(qx.$$.fragment,Py),fir=i(Py),i0e=n(Py,"P",{});var DIt=s(i0e);mir=r(DIt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),DIt.forEach(t),gir=i(Py),Od=n(Py,"P",{});var cle=s(Od);hir=r(cle,`Note:
Loading a model from its configuration file does `),d0e=n(cle,"STRONG",{});var GIt=s(d0e);uir=r(GIt,"not"),GIt.forEach(t),pir=r(cle,` load the model weights. It only affects the
model\u2019s configuration. Use `),gH=n(cle,"A",{href:!0});var OIt=s(gH);_ir=r(OIt,"from_pretrained()"),OIt.forEach(t),vir=r(cle," to load the model weights."),cle.forEach(t),bir=i(Py),T(tF.$$.fragment,Py),Py.forEach(t),Fir=i(Rl),lo=n(Rl,"DIV",{class:!0});var ya=s(lo);T(jx.$$.fragment,ya),Tir=i(ya),c0e=n(ya,"P",{});var VIt=s(c0e);Mir=r(VIt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),VIt.forEach(t),Eir=i(ya),an=n(ya,"P",{});var By=s(an);Cir=r(By,"The model class to instantiate is selected based on the "),f0e=n(By,"CODE",{});var XIt=s(f0e);wir=r(XIt,"model_type"),XIt.forEach(t),Air=r(By,` property of the config object (either
passed as an argument or loaded from `),m0e=n(By,"CODE",{});var zIt=s(m0e);Lir=r(zIt,"pretrained_model_name_or_path"),zIt.forEach(t),yir=r(By,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g0e=n(By,"CODE",{});var QIt=s(g0e);xir=r(QIt,"pretrained_model_name_or_path"),QIt.forEach(t),$ir=r(By,":"),By.forEach(t),kir=i(ya),H=n(ya,"UL",{});var K=s(H);aF=n(K,"LI",{});var bOe=s(aF);h0e=n(bOe,"STRONG",{});var WIt=s(h0e);Sir=r(WIt,"albert"),WIt.forEach(t),Rir=r(bOe," \u2014 "),hH=n(bOe,"A",{href:!0});var UIt=s(hH);Pir=r(UIt,"AlbertForTokenClassification"),UIt.forEach(t),Bir=r(bOe," (ALBERT model)"),bOe.forEach(t),Iir=i(K),nF=n(K,"LI",{});var FOe=s(nF);u0e=n(FOe,"STRONG",{});var HIt=s(u0e);Nir=r(HIt,"bert"),HIt.forEach(t),qir=r(FOe," \u2014 "),uH=n(FOe,"A",{href:!0});var JIt=s(uH);jir=r(JIt,"BertForTokenClassification"),JIt.forEach(t),Dir=r(FOe," (BERT model)"),FOe.forEach(t),Gir=i(K),sF=n(K,"LI",{});var TOe=s(sF);p0e=n(TOe,"STRONG",{});var YIt=s(p0e);Oir=r(YIt,"big_bird"),YIt.forEach(t),Vir=r(TOe," \u2014 "),pH=n(TOe,"A",{href:!0});var KIt=s(pH);Xir=r(KIt,"BigBirdForTokenClassification"),KIt.forEach(t),zir=r(TOe," (BigBird model)"),TOe.forEach(t),Qir=i(K),lF=n(K,"LI",{});var MOe=s(lF);_0e=n(MOe,"STRONG",{});var ZIt=s(_0e);Wir=r(ZIt,"bloom"),ZIt.forEach(t),Uir=r(MOe," \u2014 "),_H=n(MOe,"A",{href:!0});var eNt=s(_H);Hir=r(eNt,"BloomForTokenClassification"),eNt.forEach(t),Jir=r(MOe," (BLOOM model)"),MOe.forEach(t),Yir=i(K),iF=n(K,"LI",{});var EOe=s(iF);v0e=n(EOe,"STRONG",{});var oNt=s(v0e);Kir=r(oNt,"camembert"),oNt.forEach(t),Zir=r(EOe," \u2014 "),vH=n(EOe,"A",{href:!0});var rNt=s(vH);edr=r(rNt,"CamembertForTokenClassification"),rNt.forEach(t),odr=r(EOe," (CamemBERT model)"),EOe.forEach(t),rdr=i(K),dF=n(K,"LI",{});var COe=s(dF);b0e=n(COe,"STRONG",{});var tNt=s(b0e);tdr=r(tNt,"canine"),tNt.forEach(t),adr=r(COe," \u2014 "),bH=n(COe,"A",{href:!0});var aNt=s(bH);ndr=r(aNt,"CanineForTokenClassification"),aNt.forEach(t),sdr=r(COe," (CANINE model)"),COe.forEach(t),ldr=i(K),cF=n(K,"LI",{});var wOe=s(cF);F0e=n(wOe,"STRONG",{});var nNt=s(F0e);idr=r(nNt,"convbert"),nNt.forEach(t),ddr=r(wOe," \u2014 "),FH=n(wOe,"A",{href:!0});var sNt=s(FH);cdr=r(sNt,"ConvBertForTokenClassification"),sNt.forEach(t),fdr=r(wOe," (ConvBERT model)"),wOe.forEach(t),mdr=i(K),fF=n(K,"LI",{});var AOe=s(fF);T0e=n(AOe,"STRONG",{});var lNt=s(T0e);gdr=r(lNt,"data2vec-text"),lNt.forEach(t),hdr=r(AOe," \u2014 "),TH=n(AOe,"A",{href:!0});var iNt=s(TH);udr=r(iNt,"Data2VecTextForTokenClassification"),iNt.forEach(t),pdr=r(AOe," (Data2VecText model)"),AOe.forEach(t),_dr=i(K),mF=n(K,"LI",{});var LOe=s(mF);M0e=n(LOe,"STRONG",{});var dNt=s(M0e);vdr=r(dNt,"deberta"),dNt.forEach(t),bdr=r(LOe," \u2014 "),MH=n(LOe,"A",{href:!0});var cNt=s(MH);Fdr=r(cNt,"DebertaForTokenClassification"),cNt.forEach(t),Tdr=r(LOe," (DeBERTa model)"),LOe.forEach(t),Mdr=i(K),gF=n(K,"LI",{});var yOe=s(gF);E0e=n(yOe,"STRONG",{});var fNt=s(E0e);Edr=r(fNt,"deberta-v2"),fNt.forEach(t),Cdr=r(yOe," \u2014 "),EH=n(yOe,"A",{href:!0});var mNt=s(EH);wdr=r(mNt,"DebertaV2ForTokenClassification"),mNt.forEach(t),Adr=r(yOe," (DeBERTa-v2 model)"),yOe.forEach(t),Ldr=i(K),hF=n(K,"LI",{});var xOe=s(hF);C0e=n(xOe,"STRONG",{});var gNt=s(C0e);ydr=r(gNt,"distilbert"),gNt.forEach(t),xdr=r(xOe," \u2014 "),CH=n(xOe,"A",{href:!0});var hNt=s(CH);$dr=r(hNt,"DistilBertForTokenClassification"),hNt.forEach(t),kdr=r(xOe," (DistilBERT model)"),xOe.forEach(t),Sdr=i(K),uF=n(K,"LI",{});var $Oe=s(uF);w0e=n($Oe,"STRONG",{});var uNt=s(w0e);Rdr=r(uNt,"electra"),uNt.forEach(t),Pdr=r($Oe," \u2014 "),wH=n($Oe,"A",{href:!0});var pNt=s(wH);Bdr=r(pNt,"ElectraForTokenClassification"),pNt.forEach(t),Idr=r($Oe," (ELECTRA model)"),$Oe.forEach(t),Ndr=i(K),pF=n(K,"LI",{});var kOe=s(pF);A0e=n(kOe,"STRONG",{});var _Nt=s(A0e);qdr=r(_Nt,"ernie"),_Nt.forEach(t),jdr=r(kOe," \u2014 "),AH=n(kOe,"A",{href:!0});var vNt=s(AH);Ddr=r(vNt,"ErnieForTokenClassification"),vNt.forEach(t),Gdr=r(kOe," (ERNIE model)"),kOe.forEach(t),Odr=i(K),_F=n(K,"LI",{});var SOe=s(_F);L0e=n(SOe,"STRONG",{});var bNt=s(L0e);Vdr=r(bNt,"flaubert"),bNt.forEach(t),Xdr=r(SOe," \u2014 "),LH=n(SOe,"A",{href:!0});var FNt=s(LH);zdr=r(FNt,"FlaubertForTokenClassification"),FNt.forEach(t),Qdr=r(SOe," (FlauBERT model)"),SOe.forEach(t),Wdr=i(K),vF=n(K,"LI",{});var ROe=s(vF);y0e=n(ROe,"STRONG",{});var TNt=s(y0e);Udr=r(TNt,"fnet"),TNt.forEach(t),Hdr=r(ROe," \u2014 "),yH=n(ROe,"A",{href:!0});var MNt=s(yH);Jdr=r(MNt,"FNetForTokenClassification"),MNt.forEach(t),Ydr=r(ROe," (FNet model)"),ROe.forEach(t),Kdr=i(K),bF=n(K,"LI",{});var POe=s(bF);x0e=n(POe,"STRONG",{});var ENt=s(x0e);Zdr=r(ENt,"funnel"),ENt.forEach(t),ecr=r(POe," \u2014 "),xH=n(POe,"A",{href:!0});var CNt=s(xH);ocr=r(CNt,"FunnelForTokenClassification"),CNt.forEach(t),rcr=r(POe," (Funnel Transformer model)"),POe.forEach(t),tcr=i(K),FF=n(K,"LI",{});var BOe=s(FF);$0e=n(BOe,"STRONG",{});var wNt=s($0e);acr=r(wNt,"gpt2"),wNt.forEach(t),ncr=r(BOe," \u2014 "),$H=n(BOe,"A",{href:!0});var ANt=s($H);scr=r(ANt,"GPT2ForTokenClassification"),ANt.forEach(t),lcr=r(BOe," (OpenAI GPT-2 model)"),BOe.forEach(t),icr=i(K),TF=n(K,"LI",{});var IOe=s(TF);k0e=n(IOe,"STRONG",{});var LNt=s(k0e);dcr=r(LNt,"ibert"),LNt.forEach(t),ccr=r(IOe," \u2014 "),kH=n(IOe,"A",{href:!0});var yNt=s(kH);fcr=r(yNt,"IBertForTokenClassification"),yNt.forEach(t),mcr=r(IOe," (I-BERT model)"),IOe.forEach(t),gcr=i(K),MF=n(K,"LI",{});var NOe=s(MF);S0e=n(NOe,"STRONG",{});var xNt=s(S0e);hcr=r(xNt,"layoutlm"),xNt.forEach(t),ucr=r(NOe," \u2014 "),SH=n(NOe,"A",{href:!0});var $Nt=s(SH);pcr=r($Nt,"LayoutLMForTokenClassification"),$Nt.forEach(t),_cr=r(NOe," (LayoutLM model)"),NOe.forEach(t),vcr=i(K),EF=n(K,"LI",{});var qOe=s(EF);R0e=n(qOe,"STRONG",{});var kNt=s(R0e);bcr=r(kNt,"layoutlmv2"),kNt.forEach(t),Fcr=r(qOe," \u2014 "),RH=n(qOe,"A",{href:!0});var SNt=s(RH);Tcr=r(SNt,"LayoutLMv2ForTokenClassification"),SNt.forEach(t),Mcr=r(qOe," (LayoutLMv2 model)"),qOe.forEach(t),Ecr=i(K),CF=n(K,"LI",{});var jOe=s(CF);P0e=n(jOe,"STRONG",{});var RNt=s(P0e);Ccr=r(RNt,"layoutlmv3"),RNt.forEach(t),wcr=r(jOe," \u2014 "),PH=n(jOe,"A",{href:!0});var PNt=s(PH);Acr=r(PNt,"LayoutLMv3ForTokenClassification"),PNt.forEach(t),Lcr=r(jOe," (LayoutLMv3 model)"),jOe.forEach(t),ycr=i(K),wF=n(K,"LI",{});var DOe=s(wF);B0e=n(DOe,"STRONG",{});var BNt=s(B0e);xcr=r(BNt,"longformer"),BNt.forEach(t),$cr=r(DOe," \u2014 "),BH=n(DOe,"A",{href:!0});var INt=s(BH);kcr=r(INt,"LongformerForTokenClassification"),INt.forEach(t),Scr=r(DOe," (Longformer model)"),DOe.forEach(t),Rcr=i(K),AF=n(K,"LI",{});var GOe=s(AF);I0e=n(GOe,"STRONG",{});var NNt=s(I0e);Pcr=r(NNt,"luke"),NNt.forEach(t),Bcr=r(GOe," \u2014 "),IH=n(GOe,"A",{href:!0});var qNt=s(IH);Icr=r(qNt,"LukeForTokenClassification"),qNt.forEach(t),Ncr=r(GOe," (LUKE model)"),GOe.forEach(t),qcr=i(K),LF=n(K,"LI",{});var OOe=s(LF);N0e=n(OOe,"STRONG",{});var jNt=s(N0e);jcr=r(jNt,"megatron-bert"),jNt.forEach(t),Dcr=r(OOe," \u2014 "),NH=n(OOe,"A",{href:!0});var DNt=s(NH);Gcr=r(DNt,"MegatronBertForTokenClassification"),DNt.forEach(t),Ocr=r(OOe," (Megatron-BERT model)"),OOe.forEach(t),Vcr=i(K),yF=n(K,"LI",{});var VOe=s(yF);q0e=n(VOe,"STRONG",{});var GNt=s(q0e);Xcr=r(GNt,"mobilebert"),GNt.forEach(t),zcr=r(VOe," \u2014 "),qH=n(VOe,"A",{href:!0});var ONt=s(qH);Qcr=r(ONt,"MobileBertForTokenClassification"),ONt.forEach(t),Wcr=r(VOe," (MobileBERT model)"),VOe.forEach(t),Ucr=i(K),xF=n(K,"LI",{});var XOe=s(xF);j0e=n(XOe,"STRONG",{});var VNt=s(j0e);Hcr=r(VNt,"mpnet"),VNt.forEach(t),Jcr=r(XOe," \u2014 "),jH=n(XOe,"A",{href:!0});var XNt=s(jH);Ycr=r(XNt,"MPNetForTokenClassification"),XNt.forEach(t),Kcr=r(XOe," (MPNet model)"),XOe.forEach(t),Zcr=i(K),$F=n(K,"LI",{});var zOe=s($F);D0e=n(zOe,"STRONG",{});var zNt=s(D0e);efr=r(zNt,"nezha"),zNt.forEach(t),ofr=r(zOe," \u2014 "),DH=n(zOe,"A",{href:!0});var QNt=s(DH);rfr=r(QNt,"NezhaForTokenClassification"),QNt.forEach(t),tfr=r(zOe," (Nezha model)"),zOe.forEach(t),afr=i(K),kF=n(K,"LI",{});var QOe=s(kF);G0e=n(QOe,"STRONG",{});var WNt=s(G0e);nfr=r(WNt,"nystromformer"),WNt.forEach(t),sfr=r(QOe," \u2014 "),GH=n(QOe,"A",{href:!0});var UNt=s(GH);lfr=r(UNt,"NystromformerForTokenClassification"),UNt.forEach(t),ifr=r(QOe," (Nystr\xF6mformer model)"),QOe.forEach(t),dfr=i(K),SF=n(K,"LI",{});var WOe=s(SF);O0e=n(WOe,"STRONG",{});var HNt=s(O0e);cfr=r(HNt,"qdqbert"),HNt.forEach(t),ffr=r(WOe," \u2014 "),OH=n(WOe,"A",{href:!0});var JNt=s(OH);mfr=r(JNt,"QDQBertForTokenClassification"),JNt.forEach(t),gfr=r(WOe," (QDQBert model)"),WOe.forEach(t),hfr=i(K),RF=n(K,"LI",{});var UOe=s(RF);V0e=n(UOe,"STRONG",{});var YNt=s(V0e);ufr=r(YNt,"rembert"),YNt.forEach(t),pfr=r(UOe," \u2014 "),VH=n(UOe,"A",{href:!0});var KNt=s(VH);_fr=r(KNt,"RemBertForTokenClassification"),KNt.forEach(t),vfr=r(UOe," (RemBERT model)"),UOe.forEach(t),bfr=i(K),PF=n(K,"LI",{});var HOe=s(PF);X0e=n(HOe,"STRONG",{});var ZNt=s(X0e);Ffr=r(ZNt,"roberta"),ZNt.forEach(t),Tfr=r(HOe," \u2014 "),XH=n(HOe,"A",{href:!0});var eqt=s(XH);Mfr=r(eqt,"RobertaForTokenClassification"),eqt.forEach(t),Efr=r(HOe," (RoBERTa model)"),HOe.forEach(t),Cfr=i(K),BF=n(K,"LI",{});var JOe=s(BF);z0e=n(JOe,"STRONG",{});var oqt=s(z0e);wfr=r(oqt,"roformer"),oqt.forEach(t),Afr=r(JOe," \u2014 "),zH=n(JOe,"A",{href:!0});var rqt=s(zH);Lfr=r(rqt,"RoFormerForTokenClassification"),rqt.forEach(t),yfr=r(JOe," (RoFormer model)"),JOe.forEach(t),xfr=i(K),IF=n(K,"LI",{});var YOe=s(IF);Q0e=n(YOe,"STRONG",{});var tqt=s(Q0e);$fr=r(tqt,"squeezebert"),tqt.forEach(t),kfr=r(YOe," \u2014 "),QH=n(YOe,"A",{href:!0});var aqt=s(QH);Sfr=r(aqt,"SqueezeBertForTokenClassification"),aqt.forEach(t),Rfr=r(YOe," (SqueezeBERT model)"),YOe.forEach(t),Pfr=i(K),NF=n(K,"LI",{});var KOe=s(NF);W0e=n(KOe,"STRONG",{});var nqt=s(W0e);Bfr=r(nqt,"xlm"),nqt.forEach(t),Ifr=r(KOe," \u2014 "),WH=n(KOe,"A",{href:!0});var sqt=s(WH);Nfr=r(sqt,"XLMForTokenClassification"),sqt.forEach(t),qfr=r(KOe," (XLM model)"),KOe.forEach(t),jfr=i(K),qF=n(K,"LI",{});var ZOe=s(qF);U0e=n(ZOe,"STRONG",{});var lqt=s(U0e);Dfr=r(lqt,"xlm-roberta"),lqt.forEach(t),Gfr=r(ZOe," \u2014 "),UH=n(ZOe,"A",{href:!0});var iqt=s(UH);Ofr=r(iqt,"XLMRobertaForTokenClassification"),iqt.forEach(t),Vfr=r(ZOe," (XLM-RoBERTa model)"),ZOe.forEach(t),Xfr=i(K),jF=n(K,"LI",{});var eVe=s(jF);H0e=n(eVe,"STRONG",{});var dqt=s(H0e);zfr=r(dqt,"xlm-roberta-xl"),dqt.forEach(t),Qfr=r(eVe," \u2014 "),HH=n(eVe,"A",{href:!0});var cqt=s(HH);Wfr=r(cqt,"XLMRobertaXLForTokenClassification"),cqt.forEach(t),Ufr=r(eVe," (XLM-RoBERTa-XL model)"),eVe.forEach(t),Hfr=i(K),DF=n(K,"LI",{});var oVe=s(DF);J0e=n(oVe,"STRONG",{});var fqt=s(J0e);Jfr=r(fqt,"xlnet"),fqt.forEach(t),Yfr=r(oVe," \u2014 "),JH=n(oVe,"A",{href:!0});var mqt=s(JH);Kfr=r(mqt,"XLNetForTokenClassification"),mqt.forEach(t),Zfr=r(oVe," (XLNet model)"),oVe.forEach(t),emr=i(K),GF=n(K,"LI",{});var rVe=s(GF);Y0e=n(rVe,"STRONG",{});var gqt=s(Y0e);omr=r(gqt,"yoso"),gqt.forEach(t),rmr=r(rVe," \u2014 "),YH=n(rVe,"A",{href:!0});var hqt=s(YH);tmr=r(hqt,"YosoForTokenClassification"),hqt.forEach(t),amr=r(rVe," (YOSO model)"),rVe.forEach(t),K.forEach(t),nmr=i(ya),OF=n(ya,"P",{});var tVe=s(OF);smr=r(tVe,"The model is set in evaluation mode by default using "),K0e=n(tVe,"CODE",{});var uqt=s(K0e);lmr=r(uqt,"model.eval()"),uqt.forEach(t),imr=r(tVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z0e=n(tVe,"CODE",{});var pqt=s(Z0e);dmr=r(pqt,"model.train()"),pqt.forEach(t),tVe.forEach(t),cmr=i(ya),T(VF.$$.fragment,ya),ya.forEach(t),Rl.forEach(t),iKe=i(f),Vd=n(f,"H2",{class:!0});var Meo=s(Vd);XF=n(Meo,"A",{id:!0,class:!0,href:!0});var _qt=s(XF);eFe=n(_qt,"SPAN",{});var vqt=s(eFe);T(Dx.$$.fragment,vqt),vqt.forEach(t),_qt.forEach(t),fmr=i(Meo),oFe=n(Meo,"SPAN",{});var bqt=s(oFe);mmr=r(bqt,"AutoModelForQuestionAnswering"),bqt.forEach(t),Meo.forEach(t),dKe=i(f),Vo=n(f,"DIV",{class:!0});var Pl=s(Vo);T(Gx.$$.fragment,Pl),gmr=i(Pl),Xd=n(Pl,"P",{});var fle=s(Xd);hmr=r(fle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),KH=n(fle,"A",{href:!0});var Fqt=s(KH);umr=r(Fqt,"from_pretrained()"),Fqt.forEach(t),pmr=r(fle," class method or the "),ZH=n(fle,"A",{href:!0});var Tqt=s(ZH);_mr=r(Tqt,"from_config()"),Tqt.forEach(t),vmr=r(fle,` class
method.`),fle.forEach(t),bmr=i(Pl),Ox=n(Pl,"P",{});var Eeo=s(Ox);Fmr=r(Eeo,"This class cannot be instantiated directly using "),rFe=n(Eeo,"CODE",{});var Mqt=s(rFe);Tmr=r(Mqt,"__init__()"),Mqt.forEach(t),Mmr=r(Eeo," (throws an error)."),Eeo.forEach(t),Emr=i(Pl),At=n(Pl,"DIV",{class:!0});var Iy=s(At);T(Vx.$$.fragment,Iy),Cmr=i(Iy),tFe=n(Iy,"P",{});var Eqt=s(tFe);wmr=r(Eqt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Eqt.forEach(t),Amr=i(Iy),zd=n(Iy,"P",{});var mle=s(zd);Lmr=r(mle,`Note:
Loading a model from its configuration file does `),aFe=n(mle,"STRONG",{});var Cqt=s(aFe);ymr=r(Cqt,"not"),Cqt.forEach(t),xmr=r(mle,` load the model weights. It only affects the
model\u2019s configuration. Use `),eJ=n(mle,"A",{href:!0});var wqt=s(eJ);$mr=r(wqt,"from_pretrained()"),wqt.forEach(t),kmr=r(mle," to load the model weights."),mle.forEach(t),Smr=i(Iy),T(zF.$$.fragment,Iy),Iy.forEach(t),Rmr=i(Pl),io=n(Pl,"DIV",{class:!0});var xa=s(io);T(Xx.$$.fragment,xa),Pmr=i(xa),nFe=n(xa,"P",{});var Aqt=s(nFe);Bmr=r(Aqt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Aqt.forEach(t),Imr=i(xa),nn=n(xa,"P",{});var Ny=s(nn);Nmr=r(Ny,"The model class to instantiate is selected based on the "),sFe=n(Ny,"CODE",{});var Lqt=s(sFe);qmr=r(Lqt,"model_type"),Lqt.forEach(t),jmr=r(Ny,` property of the config object (either
passed as an argument or loaded from `),lFe=n(Ny,"CODE",{});var yqt=s(lFe);Dmr=r(yqt,"pretrained_model_name_or_path"),yqt.forEach(t),Gmr=r(Ny,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iFe=n(Ny,"CODE",{});var xqt=s(iFe);Omr=r(xqt,"pretrained_model_name_or_path"),xqt.forEach(t),Vmr=r(Ny,":"),Ny.forEach(t),Xmr=i(xa),V=n(xa,"UL",{});var X=s(V);QF=n(X,"LI",{});var aVe=s(QF);dFe=n(aVe,"STRONG",{});var $qt=s(dFe);zmr=r($qt,"albert"),$qt.forEach(t),Qmr=r(aVe," \u2014 "),oJ=n(aVe,"A",{href:!0});var kqt=s(oJ);Wmr=r(kqt,"AlbertForQuestionAnswering"),kqt.forEach(t),Umr=r(aVe," (ALBERT model)"),aVe.forEach(t),Hmr=i(X),WF=n(X,"LI",{});var nVe=s(WF);cFe=n(nVe,"STRONG",{});var Sqt=s(cFe);Jmr=r(Sqt,"bart"),Sqt.forEach(t),Ymr=r(nVe," \u2014 "),rJ=n(nVe,"A",{href:!0});var Rqt=s(rJ);Kmr=r(Rqt,"BartForQuestionAnswering"),Rqt.forEach(t),Zmr=r(nVe," (BART model)"),nVe.forEach(t),egr=i(X),UF=n(X,"LI",{});var sVe=s(UF);fFe=n(sVe,"STRONG",{});var Pqt=s(fFe);ogr=r(Pqt,"bert"),Pqt.forEach(t),rgr=r(sVe," \u2014 "),tJ=n(sVe,"A",{href:!0});var Bqt=s(tJ);tgr=r(Bqt,"BertForQuestionAnswering"),Bqt.forEach(t),agr=r(sVe," (BERT model)"),sVe.forEach(t),ngr=i(X),HF=n(X,"LI",{});var lVe=s(HF);mFe=n(lVe,"STRONG",{});var Iqt=s(mFe);sgr=r(Iqt,"big_bird"),Iqt.forEach(t),lgr=r(lVe," \u2014 "),aJ=n(lVe,"A",{href:!0});var Nqt=s(aJ);igr=r(Nqt,"BigBirdForQuestionAnswering"),Nqt.forEach(t),dgr=r(lVe," (BigBird model)"),lVe.forEach(t),cgr=i(X),JF=n(X,"LI",{});var iVe=s(JF);gFe=n(iVe,"STRONG",{});var qqt=s(gFe);fgr=r(qqt,"bigbird_pegasus"),qqt.forEach(t),mgr=r(iVe," \u2014 "),nJ=n(iVe,"A",{href:!0});var jqt=s(nJ);ggr=r(jqt,"BigBirdPegasusForQuestionAnswering"),jqt.forEach(t),hgr=r(iVe," (BigBird-Pegasus model)"),iVe.forEach(t),ugr=i(X),YF=n(X,"LI",{});var dVe=s(YF);hFe=n(dVe,"STRONG",{});var Dqt=s(hFe);pgr=r(Dqt,"camembert"),Dqt.forEach(t),_gr=r(dVe," \u2014 "),sJ=n(dVe,"A",{href:!0});var Gqt=s(sJ);vgr=r(Gqt,"CamembertForQuestionAnswering"),Gqt.forEach(t),bgr=r(dVe," (CamemBERT model)"),dVe.forEach(t),Fgr=i(X),KF=n(X,"LI",{});var cVe=s(KF);uFe=n(cVe,"STRONG",{});var Oqt=s(uFe);Tgr=r(Oqt,"canine"),Oqt.forEach(t),Mgr=r(cVe," \u2014 "),lJ=n(cVe,"A",{href:!0});var Vqt=s(lJ);Egr=r(Vqt,"CanineForQuestionAnswering"),Vqt.forEach(t),Cgr=r(cVe," (CANINE model)"),cVe.forEach(t),wgr=i(X),ZF=n(X,"LI",{});var fVe=s(ZF);pFe=n(fVe,"STRONG",{});var Xqt=s(pFe);Agr=r(Xqt,"convbert"),Xqt.forEach(t),Lgr=r(fVe," \u2014 "),iJ=n(fVe,"A",{href:!0});var zqt=s(iJ);ygr=r(zqt,"ConvBertForQuestionAnswering"),zqt.forEach(t),xgr=r(fVe," (ConvBERT model)"),fVe.forEach(t),$gr=i(X),eT=n(X,"LI",{});var mVe=s(eT);_Fe=n(mVe,"STRONG",{});var Qqt=s(_Fe);kgr=r(Qqt,"data2vec-text"),Qqt.forEach(t),Sgr=r(mVe," \u2014 "),dJ=n(mVe,"A",{href:!0});var Wqt=s(dJ);Rgr=r(Wqt,"Data2VecTextForQuestionAnswering"),Wqt.forEach(t),Pgr=r(mVe," (Data2VecText model)"),mVe.forEach(t),Bgr=i(X),oT=n(X,"LI",{});var gVe=s(oT);vFe=n(gVe,"STRONG",{});var Uqt=s(vFe);Igr=r(Uqt,"deberta"),Uqt.forEach(t),Ngr=r(gVe," \u2014 "),cJ=n(gVe,"A",{href:!0});var Hqt=s(cJ);qgr=r(Hqt,"DebertaForQuestionAnswering"),Hqt.forEach(t),jgr=r(gVe," (DeBERTa model)"),gVe.forEach(t),Dgr=i(X),rT=n(X,"LI",{});var hVe=s(rT);bFe=n(hVe,"STRONG",{});var Jqt=s(bFe);Ggr=r(Jqt,"deberta-v2"),Jqt.forEach(t),Ogr=r(hVe," \u2014 "),fJ=n(hVe,"A",{href:!0});var Yqt=s(fJ);Vgr=r(Yqt,"DebertaV2ForQuestionAnswering"),Yqt.forEach(t),Xgr=r(hVe," (DeBERTa-v2 model)"),hVe.forEach(t),zgr=i(X),tT=n(X,"LI",{});var uVe=s(tT);FFe=n(uVe,"STRONG",{});var Kqt=s(FFe);Qgr=r(Kqt,"distilbert"),Kqt.forEach(t),Wgr=r(uVe," \u2014 "),mJ=n(uVe,"A",{href:!0});var Zqt=s(mJ);Ugr=r(Zqt,"DistilBertForQuestionAnswering"),Zqt.forEach(t),Hgr=r(uVe," (DistilBERT model)"),uVe.forEach(t),Jgr=i(X),aT=n(X,"LI",{});var pVe=s(aT);TFe=n(pVe,"STRONG",{});var ejt=s(TFe);Ygr=r(ejt,"electra"),ejt.forEach(t),Kgr=r(pVe," \u2014 "),gJ=n(pVe,"A",{href:!0});var ojt=s(gJ);Zgr=r(ojt,"ElectraForQuestionAnswering"),ojt.forEach(t),ehr=r(pVe," (ELECTRA model)"),pVe.forEach(t),ohr=i(X),nT=n(X,"LI",{});var _Ve=s(nT);MFe=n(_Ve,"STRONG",{});var rjt=s(MFe);rhr=r(rjt,"ernie"),rjt.forEach(t),thr=r(_Ve," \u2014 "),hJ=n(_Ve,"A",{href:!0});var tjt=s(hJ);ahr=r(tjt,"ErnieForQuestionAnswering"),tjt.forEach(t),nhr=r(_Ve," (ERNIE model)"),_Ve.forEach(t),shr=i(X),sT=n(X,"LI",{});var vVe=s(sT);EFe=n(vVe,"STRONG",{});var ajt=s(EFe);lhr=r(ajt,"flaubert"),ajt.forEach(t),ihr=r(vVe," \u2014 "),uJ=n(vVe,"A",{href:!0});var njt=s(uJ);dhr=r(njt,"FlaubertForQuestionAnsweringSimple"),njt.forEach(t),chr=r(vVe," (FlauBERT model)"),vVe.forEach(t),fhr=i(X),lT=n(X,"LI",{});var bVe=s(lT);CFe=n(bVe,"STRONG",{});var sjt=s(CFe);mhr=r(sjt,"fnet"),sjt.forEach(t),ghr=r(bVe," \u2014 "),pJ=n(bVe,"A",{href:!0});var ljt=s(pJ);hhr=r(ljt,"FNetForQuestionAnswering"),ljt.forEach(t),uhr=r(bVe," (FNet model)"),bVe.forEach(t),phr=i(X),iT=n(X,"LI",{});var FVe=s(iT);wFe=n(FVe,"STRONG",{});var ijt=s(wFe);_hr=r(ijt,"funnel"),ijt.forEach(t),vhr=r(FVe," \u2014 "),_J=n(FVe,"A",{href:!0});var djt=s(_J);bhr=r(djt,"FunnelForQuestionAnswering"),djt.forEach(t),Fhr=r(FVe," (Funnel Transformer model)"),FVe.forEach(t),Thr=i(X),dT=n(X,"LI",{});var TVe=s(dT);AFe=n(TVe,"STRONG",{});var cjt=s(AFe);Mhr=r(cjt,"gptj"),cjt.forEach(t),Ehr=r(TVe," \u2014 "),vJ=n(TVe,"A",{href:!0});var fjt=s(vJ);Chr=r(fjt,"GPTJForQuestionAnswering"),fjt.forEach(t),whr=r(TVe," (GPT-J model)"),TVe.forEach(t),Ahr=i(X),cT=n(X,"LI",{});var MVe=s(cT);LFe=n(MVe,"STRONG",{});var mjt=s(LFe);Lhr=r(mjt,"ibert"),mjt.forEach(t),yhr=r(MVe," \u2014 "),bJ=n(MVe,"A",{href:!0});var gjt=s(bJ);xhr=r(gjt,"IBertForQuestionAnswering"),gjt.forEach(t),$hr=r(MVe," (I-BERT model)"),MVe.forEach(t),khr=i(X),fT=n(X,"LI",{});var EVe=s(fT);yFe=n(EVe,"STRONG",{});var hjt=s(yFe);Shr=r(hjt,"layoutlmv2"),hjt.forEach(t),Rhr=r(EVe," \u2014 "),FJ=n(EVe,"A",{href:!0});var ujt=s(FJ);Phr=r(ujt,"LayoutLMv2ForQuestionAnswering"),ujt.forEach(t),Bhr=r(EVe," (LayoutLMv2 model)"),EVe.forEach(t),Ihr=i(X),mT=n(X,"LI",{});var CVe=s(mT);xFe=n(CVe,"STRONG",{});var pjt=s(xFe);Nhr=r(pjt,"layoutlmv3"),pjt.forEach(t),qhr=r(CVe," \u2014 "),TJ=n(CVe,"A",{href:!0});var _jt=s(TJ);jhr=r(_jt,"LayoutLMv3ForQuestionAnswering"),_jt.forEach(t),Dhr=r(CVe," (LayoutLMv3 model)"),CVe.forEach(t),Ghr=i(X),gT=n(X,"LI",{});var wVe=s(gT);$Fe=n(wVe,"STRONG",{});var vjt=s($Fe);Ohr=r(vjt,"led"),vjt.forEach(t),Vhr=r(wVe," \u2014 "),MJ=n(wVe,"A",{href:!0});var bjt=s(MJ);Xhr=r(bjt,"LEDForQuestionAnswering"),bjt.forEach(t),zhr=r(wVe," (LED model)"),wVe.forEach(t),Qhr=i(X),hT=n(X,"LI",{});var AVe=s(hT);kFe=n(AVe,"STRONG",{});var Fjt=s(kFe);Whr=r(Fjt,"longformer"),Fjt.forEach(t),Uhr=r(AVe," \u2014 "),EJ=n(AVe,"A",{href:!0});var Tjt=s(EJ);Hhr=r(Tjt,"LongformerForQuestionAnswering"),Tjt.forEach(t),Jhr=r(AVe," (Longformer model)"),AVe.forEach(t),Yhr=i(X),uT=n(X,"LI",{});var LVe=s(uT);SFe=n(LVe,"STRONG",{});var Mjt=s(SFe);Khr=r(Mjt,"luke"),Mjt.forEach(t),Zhr=r(LVe," \u2014 "),CJ=n(LVe,"A",{href:!0});var Ejt=s(CJ);eur=r(Ejt,"LukeForQuestionAnswering"),Ejt.forEach(t),our=r(LVe," (LUKE model)"),LVe.forEach(t),rur=i(X),pT=n(X,"LI",{});var yVe=s(pT);RFe=n(yVe,"STRONG",{});var Cjt=s(RFe);tur=r(Cjt,"lxmert"),Cjt.forEach(t),aur=r(yVe," \u2014 "),wJ=n(yVe,"A",{href:!0});var wjt=s(wJ);nur=r(wjt,"LxmertForQuestionAnswering"),wjt.forEach(t),sur=r(yVe," (LXMERT model)"),yVe.forEach(t),lur=i(X),_T=n(X,"LI",{});var xVe=s(_T);PFe=n(xVe,"STRONG",{});var Ajt=s(PFe);iur=r(Ajt,"mbart"),Ajt.forEach(t),dur=r(xVe," \u2014 "),AJ=n(xVe,"A",{href:!0});var Ljt=s(AJ);cur=r(Ljt,"MBartForQuestionAnswering"),Ljt.forEach(t),fur=r(xVe," (mBART model)"),xVe.forEach(t),mur=i(X),vT=n(X,"LI",{});var $Ve=s(vT);BFe=n($Ve,"STRONG",{});var yjt=s(BFe);gur=r(yjt,"megatron-bert"),yjt.forEach(t),hur=r($Ve," \u2014 "),LJ=n($Ve,"A",{href:!0});var xjt=s(LJ);uur=r(xjt,"MegatronBertForQuestionAnswering"),xjt.forEach(t),pur=r($Ve," (Megatron-BERT model)"),$Ve.forEach(t),_ur=i(X),bT=n(X,"LI",{});var kVe=s(bT);IFe=n(kVe,"STRONG",{});var $jt=s(IFe);vur=r($jt,"mobilebert"),$jt.forEach(t),bur=r(kVe," \u2014 "),yJ=n(kVe,"A",{href:!0});var kjt=s(yJ);Fur=r(kjt,"MobileBertForQuestionAnswering"),kjt.forEach(t),Tur=r(kVe," (MobileBERT model)"),kVe.forEach(t),Mur=i(X),FT=n(X,"LI",{});var SVe=s(FT);NFe=n(SVe,"STRONG",{});var Sjt=s(NFe);Eur=r(Sjt,"mpnet"),Sjt.forEach(t),Cur=r(SVe," \u2014 "),xJ=n(SVe,"A",{href:!0});var Rjt=s(xJ);wur=r(Rjt,"MPNetForQuestionAnswering"),Rjt.forEach(t),Aur=r(SVe," (MPNet model)"),SVe.forEach(t),Lur=i(X),TT=n(X,"LI",{});var RVe=s(TT);qFe=n(RVe,"STRONG",{});var Pjt=s(qFe);yur=r(Pjt,"mvp"),Pjt.forEach(t),xur=r(RVe," \u2014 "),$J=n(RVe,"A",{href:!0});var Bjt=s($J);$ur=r(Bjt,"MvpForQuestionAnswering"),Bjt.forEach(t),kur=r(RVe," (MVP model)"),RVe.forEach(t),Sur=i(X),MT=n(X,"LI",{});var PVe=s(MT);jFe=n(PVe,"STRONG",{});var Ijt=s(jFe);Rur=r(Ijt,"nezha"),Ijt.forEach(t),Pur=r(PVe," \u2014 "),kJ=n(PVe,"A",{href:!0});var Njt=s(kJ);Bur=r(Njt,"NezhaForQuestionAnswering"),Njt.forEach(t),Iur=r(PVe," (Nezha model)"),PVe.forEach(t),Nur=i(X),ET=n(X,"LI",{});var BVe=s(ET);DFe=n(BVe,"STRONG",{});var qjt=s(DFe);qur=r(qjt,"nystromformer"),qjt.forEach(t),jur=r(BVe," \u2014 "),SJ=n(BVe,"A",{href:!0});var jjt=s(SJ);Dur=r(jjt,"NystromformerForQuestionAnswering"),jjt.forEach(t),Gur=r(BVe," (Nystr\xF6mformer model)"),BVe.forEach(t),Our=i(X),CT=n(X,"LI",{});var IVe=s(CT);GFe=n(IVe,"STRONG",{});var Djt=s(GFe);Vur=r(Djt,"qdqbert"),Djt.forEach(t),Xur=r(IVe," \u2014 "),RJ=n(IVe,"A",{href:!0});var Gjt=s(RJ);zur=r(Gjt,"QDQBertForQuestionAnswering"),Gjt.forEach(t),Qur=r(IVe," (QDQBert model)"),IVe.forEach(t),Wur=i(X),wT=n(X,"LI",{});var NVe=s(wT);OFe=n(NVe,"STRONG",{});var Ojt=s(OFe);Uur=r(Ojt,"reformer"),Ojt.forEach(t),Hur=r(NVe," \u2014 "),PJ=n(NVe,"A",{href:!0});var Vjt=s(PJ);Jur=r(Vjt,"ReformerForQuestionAnswering"),Vjt.forEach(t),Yur=r(NVe," (Reformer model)"),NVe.forEach(t),Kur=i(X),AT=n(X,"LI",{});var qVe=s(AT);VFe=n(qVe,"STRONG",{});var Xjt=s(VFe);Zur=r(Xjt,"rembert"),Xjt.forEach(t),epr=r(qVe," \u2014 "),BJ=n(qVe,"A",{href:!0});var zjt=s(BJ);opr=r(zjt,"RemBertForQuestionAnswering"),zjt.forEach(t),rpr=r(qVe," (RemBERT model)"),qVe.forEach(t),tpr=i(X),LT=n(X,"LI",{});var jVe=s(LT);XFe=n(jVe,"STRONG",{});var Qjt=s(XFe);apr=r(Qjt,"roberta"),Qjt.forEach(t),npr=r(jVe," \u2014 "),IJ=n(jVe,"A",{href:!0});var Wjt=s(IJ);spr=r(Wjt,"RobertaForQuestionAnswering"),Wjt.forEach(t),lpr=r(jVe," (RoBERTa model)"),jVe.forEach(t),ipr=i(X),yT=n(X,"LI",{});var DVe=s(yT);zFe=n(DVe,"STRONG",{});var Ujt=s(zFe);dpr=r(Ujt,"roformer"),Ujt.forEach(t),cpr=r(DVe," \u2014 "),NJ=n(DVe,"A",{href:!0});var Hjt=s(NJ);fpr=r(Hjt,"RoFormerForQuestionAnswering"),Hjt.forEach(t),mpr=r(DVe," (RoFormer model)"),DVe.forEach(t),gpr=i(X),xT=n(X,"LI",{});var GVe=s(xT);QFe=n(GVe,"STRONG",{});var Jjt=s(QFe);hpr=r(Jjt,"splinter"),Jjt.forEach(t),upr=r(GVe," \u2014 "),qJ=n(GVe,"A",{href:!0});var Yjt=s(qJ);ppr=r(Yjt,"SplinterForQuestionAnswering"),Yjt.forEach(t),_pr=r(GVe," (Splinter model)"),GVe.forEach(t),vpr=i(X),$T=n(X,"LI",{});var OVe=s($T);WFe=n(OVe,"STRONG",{});var Kjt=s(WFe);bpr=r(Kjt,"squeezebert"),Kjt.forEach(t),Fpr=r(OVe," \u2014 "),jJ=n(OVe,"A",{href:!0});var Zjt=s(jJ);Tpr=r(Zjt,"SqueezeBertForQuestionAnswering"),Zjt.forEach(t),Mpr=r(OVe," (SqueezeBERT model)"),OVe.forEach(t),Epr=i(X),kT=n(X,"LI",{});var VVe=s(kT);UFe=n(VVe,"STRONG",{});var eDt=s(UFe);Cpr=r(eDt,"xlm"),eDt.forEach(t),wpr=r(VVe," \u2014 "),DJ=n(VVe,"A",{href:!0});var oDt=s(DJ);Apr=r(oDt,"XLMForQuestionAnsweringSimple"),oDt.forEach(t),Lpr=r(VVe," (XLM model)"),VVe.forEach(t),ypr=i(X),ST=n(X,"LI",{});var XVe=s(ST);HFe=n(XVe,"STRONG",{});var rDt=s(HFe);xpr=r(rDt,"xlm-roberta"),rDt.forEach(t),$pr=r(XVe," \u2014 "),GJ=n(XVe,"A",{href:!0});var tDt=s(GJ);kpr=r(tDt,"XLMRobertaForQuestionAnswering"),tDt.forEach(t),Spr=r(XVe," (XLM-RoBERTa model)"),XVe.forEach(t),Rpr=i(X),RT=n(X,"LI",{});var zVe=s(RT);JFe=n(zVe,"STRONG",{});var aDt=s(JFe);Ppr=r(aDt,"xlm-roberta-xl"),aDt.forEach(t),Bpr=r(zVe," \u2014 "),OJ=n(zVe,"A",{href:!0});var nDt=s(OJ);Ipr=r(nDt,"XLMRobertaXLForQuestionAnswering"),nDt.forEach(t),Npr=r(zVe," (XLM-RoBERTa-XL model)"),zVe.forEach(t),qpr=i(X),PT=n(X,"LI",{});var QVe=s(PT);YFe=n(QVe,"STRONG",{});var sDt=s(YFe);jpr=r(sDt,"xlnet"),sDt.forEach(t),Dpr=r(QVe," \u2014 "),VJ=n(QVe,"A",{href:!0});var lDt=s(VJ);Gpr=r(lDt,"XLNetForQuestionAnsweringSimple"),lDt.forEach(t),Opr=r(QVe," (XLNet model)"),QVe.forEach(t),Vpr=i(X),BT=n(X,"LI",{});var WVe=s(BT);KFe=n(WVe,"STRONG",{});var iDt=s(KFe);Xpr=r(iDt,"yoso"),iDt.forEach(t),zpr=r(WVe," \u2014 "),XJ=n(WVe,"A",{href:!0});var dDt=s(XJ);Qpr=r(dDt,"YosoForQuestionAnswering"),dDt.forEach(t),Wpr=r(WVe," (YOSO model)"),WVe.forEach(t),X.forEach(t),Upr=i(xa),IT=n(xa,"P",{});var UVe=s(IT);Hpr=r(UVe,"The model is set in evaluation mode by default using "),ZFe=n(UVe,"CODE",{});var cDt=s(ZFe);Jpr=r(cDt,"model.eval()"),cDt.forEach(t),Ypr=r(UVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),eTe=n(UVe,"CODE",{});var fDt=s(eTe);Kpr=r(fDt,"model.train()"),fDt.forEach(t),UVe.forEach(t),Zpr=i(xa),T(NT.$$.fragment,xa),xa.forEach(t),Pl.forEach(t),cKe=i(f),Qd=n(f,"H2",{class:!0});var Ceo=s(Qd);qT=n(Ceo,"A",{id:!0,class:!0,href:!0});var mDt=s(qT);oTe=n(mDt,"SPAN",{});var gDt=s(oTe);T(zx.$$.fragment,gDt),gDt.forEach(t),mDt.forEach(t),e_r=i(Ceo),rTe=n(Ceo,"SPAN",{});var hDt=s(rTe);o_r=r(hDt,"AutoModelForTableQuestionAnswering"),hDt.forEach(t),Ceo.forEach(t),fKe=i(f),Xo=n(f,"DIV",{class:!0});var Bl=s(Xo);T(Qx.$$.fragment,Bl),r_r=i(Bl),Wd=n(Bl,"P",{});var gle=s(Wd);t_r=r(gle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),zJ=n(gle,"A",{href:!0});var uDt=s(zJ);a_r=r(uDt,"from_pretrained()"),uDt.forEach(t),n_r=r(gle," class method or the "),QJ=n(gle,"A",{href:!0});var pDt=s(QJ);s_r=r(pDt,"from_config()"),pDt.forEach(t),l_r=r(gle,` class
method.`),gle.forEach(t),i_r=i(Bl),Wx=n(Bl,"P",{});var weo=s(Wx);d_r=r(weo,"This class cannot be instantiated directly using "),tTe=n(weo,"CODE",{});var _Dt=s(tTe);c_r=r(_Dt,"__init__()"),_Dt.forEach(t),f_r=r(weo," (throws an error)."),weo.forEach(t),m_r=i(Bl),Lt=n(Bl,"DIV",{class:!0});var qy=s(Lt);T(Ux.$$.fragment,qy),g_r=i(qy),aTe=n(qy,"P",{});var vDt=s(aTe);h_r=r(vDt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),vDt.forEach(t),u_r=i(qy),Ud=n(qy,"P",{});var hle=s(Ud);p_r=r(hle,`Note:
Loading a model from its configuration file does `),nTe=n(hle,"STRONG",{});var bDt=s(nTe);__r=r(bDt,"not"),bDt.forEach(t),v_r=r(hle,` load the model weights. It only affects the
model\u2019s configuration. Use `),WJ=n(hle,"A",{href:!0});var FDt=s(WJ);b_r=r(FDt,"from_pretrained()"),FDt.forEach(t),F_r=r(hle," to load the model weights."),hle.forEach(t),T_r=i(qy),T(jT.$$.fragment,qy),qy.forEach(t),M_r=i(Bl),co=n(Bl,"DIV",{class:!0});var $a=s(co);T(Hx.$$.fragment,$a),E_r=i($a),sTe=n($a,"P",{});var TDt=s(sTe);C_r=r(TDt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),TDt.forEach(t),w_r=i($a),sn=n($a,"P",{});var jy=s(sn);A_r=r(jy,"The model class to instantiate is selected based on the "),lTe=n(jy,"CODE",{});var MDt=s(lTe);L_r=r(MDt,"model_type"),MDt.forEach(t),y_r=r(jy,` property of the config object (either
passed as an argument or loaded from `),iTe=n(jy,"CODE",{});var EDt=s(iTe);x_r=r(EDt,"pretrained_model_name_or_path"),EDt.forEach(t),$_r=r(jy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dTe=n(jy,"CODE",{});var CDt=s(dTe);k_r=r(CDt,"pretrained_model_name_or_path"),CDt.forEach(t),S_r=r(jy,":"),jy.forEach(t),R_r=i($a),cTe=n($a,"UL",{});var wDt=s(cTe);DT=n(wDt,"LI",{});var HVe=s(DT);fTe=n(HVe,"STRONG",{});var ADt=s(fTe);P_r=r(ADt,"tapas"),ADt.forEach(t),B_r=r(HVe," \u2014 "),UJ=n(HVe,"A",{href:!0});var LDt=s(UJ);I_r=r(LDt,"TapasForQuestionAnswering"),LDt.forEach(t),N_r=r(HVe," (TAPAS model)"),HVe.forEach(t),wDt.forEach(t),q_r=i($a),GT=n($a,"P",{});var JVe=s(GT);j_r=r(JVe,"The model is set in evaluation mode by default using "),mTe=n(JVe,"CODE",{});var yDt=s(mTe);D_r=r(yDt,"model.eval()"),yDt.forEach(t),G_r=r(JVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gTe=n(JVe,"CODE",{});var xDt=s(gTe);O_r=r(xDt,"model.train()"),xDt.forEach(t),JVe.forEach(t),V_r=i($a),T(OT.$$.fragment,$a),$a.forEach(t),Bl.forEach(t),mKe=i(f),Hd=n(f,"H2",{class:!0});var Aeo=s(Hd);VT=n(Aeo,"A",{id:!0,class:!0,href:!0});var $Dt=s(VT);hTe=n($Dt,"SPAN",{});var kDt=s(hTe);T(Jx.$$.fragment,kDt),kDt.forEach(t),$Dt.forEach(t),X_r=i(Aeo),uTe=n(Aeo,"SPAN",{});var SDt=s(uTe);z_r=r(SDt,"AutoModelForDocumentQuestionAnswering"),SDt.forEach(t),Aeo.forEach(t),gKe=i(f),zo=n(f,"DIV",{class:!0});var Il=s(zo);T(Yx.$$.fragment,Il),Q_r=i(Il),Jd=n(Il,"P",{});var ule=s(Jd);W_r=r(ule,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),HJ=n(ule,"A",{href:!0});var RDt=s(HJ);U_r=r(RDt,"from_pretrained()"),RDt.forEach(t),H_r=r(ule," class method or the "),JJ=n(ule,"A",{href:!0});var PDt=s(JJ);J_r=r(PDt,"from_config()"),PDt.forEach(t),Y_r=r(ule,` class
method.`),ule.forEach(t),K_r=i(Il),Kx=n(Il,"P",{});var Leo=s(Kx);Z_r=r(Leo,"This class cannot be instantiated directly using "),pTe=n(Leo,"CODE",{});var BDt=s(pTe);e2r=r(BDt,"__init__()"),BDt.forEach(t),o2r=r(Leo," (throws an error)."),Leo.forEach(t),r2r=i(Il),yt=n(Il,"DIV",{class:!0});var Dy=s(yt);T(Zx.$$.fragment,Dy),t2r=i(Dy),_Te=n(Dy,"P",{});var IDt=s(_Te);a2r=r(IDt,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),IDt.forEach(t),n2r=i(Dy),Yd=n(Dy,"P",{});var ple=s(Yd);s2r=r(ple,`Note:
Loading a model from its configuration file does `),vTe=n(ple,"STRONG",{});var NDt=s(vTe);l2r=r(NDt,"not"),NDt.forEach(t),i2r=r(ple,` load the model weights. It only affects the
model\u2019s configuration. Use `),YJ=n(ple,"A",{href:!0});var qDt=s(YJ);d2r=r(qDt,"from_pretrained()"),qDt.forEach(t),c2r=r(ple," to load the model weights."),ple.forEach(t),f2r=i(Dy),T(XT.$$.fragment,Dy),Dy.forEach(t),m2r=i(Il),fo=n(Il,"DIV",{class:!0});var ka=s(fo);T(e$.$$.fragment,ka),g2r=i(ka),bTe=n(ka,"P",{});var jDt=s(bTe);h2r=r(jDt,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),jDt.forEach(t),u2r=i(ka),ln=n(ka,"P",{});var Gy=s(ln);p2r=r(Gy,"The model class to instantiate is selected based on the "),FTe=n(Gy,"CODE",{});var DDt=s(FTe);_2r=r(DDt,"model_type"),DDt.forEach(t),v2r=r(Gy,` property of the config object (either
passed as an argument or loaded from `),TTe=n(Gy,"CODE",{});var GDt=s(TTe);b2r=r(GDt,"pretrained_model_name_or_path"),GDt.forEach(t),F2r=r(Gy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MTe=n(Gy,"CODE",{});var ODt=s(MTe);T2r=r(ODt,"pretrained_model_name_or_path"),ODt.forEach(t),M2r=r(Gy,":"),Gy.forEach(t),E2r=i(ka),Kd=n(ka,"UL",{});var _le=s(Kd);zT=n(_le,"LI",{});var YVe=s(zT);ETe=n(YVe,"STRONG",{});var VDt=s(ETe);C2r=r(VDt,"layoutlm"),VDt.forEach(t),w2r=r(YVe," \u2014 "),KJ=n(YVe,"A",{href:!0});var XDt=s(KJ);A2r=r(XDt,"LayoutLMForQuestionAnswering"),XDt.forEach(t),L2r=r(YVe," (LayoutLM model)"),YVe.forEach(t),y2r=i(_le),QT=n(_le,"LI",{});var KVe=s(QT);CTe=n(KVe,"STRONG",{});var zDt=s(CTe);x2r=r(zDt,"layoutlmv2"),zDt.forEach(t),$2r=r(KVe," \u2014 "),ZJ=n(KVe,"A",{href:!0});var QDt=s(ZJ);k2r=r(QDt,"LayoutLMv2ForQuestionAnswering"),QDt.forEach(t),S2r=r(KVe," (LayoutLMv2 model)"),KVe.forEach(t),R2r=i(_le),WT=n(_le,"LI",{});var ZVe=s(WT);wTe=n(ZVe,"STRONG",{});var WDt=s(wTe);P2r=r(WDt,"layoutlmv3"),WDt.forEach(t),B2r=r(ZVe," \u2014 "),eY=n(ZVe,"A",{href:!0});var UDt=s(eY);I2r=r(UDt,"LayoutLMv3ForQuestionAnswering"),UDt.forEach(t),N2r=r(ZVe," (LayoutLMv3 model)"),ZVe.forEach(t),_le.forEach(t),q2r=i(ka),UT=n(ka,"P",{});var eXe=s(UT);j2r=r(eXe,"The model is set in evaluation mode by default using "),ATe=n(eXe,"CODE",{});var HDt=s(ATe);D2r=r(HDt,"model.eval()"),HDt.forEach(t),G2r=r(eXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LTe=n(eXe,"CODE",{});var JDt=s(LTe);O2r=r(JDt,"model.train()"),JDt.forEach(t),eXe.forEach(t),V2r=i(ka),T(HT.$$.fragment,ka),ka.forEach(t),Il.forEach(t),hKe=i(f),Zd=n(f,"H2",{class:!0});var yeo=s(Zd);JT=n(yeo,"A",{id:!0,class:!0,href:!0});var YDt=s(JT);yTe=n(YDt,"SPAN",{});var KDt=s(yTe);T(o$.$$.fragment,KDt),KDt.forEach(t),YDt.forEach(t),X2r=i(yeo),xTe=n(yeo,"SPAN",{});var ZDt=s(xTe);z2r=r(ZDt,"AutoModelForImageClassification"),ZDt.forEach(t),yeo.forEach(t),uKe=i(f),Qo=n(f,"DIV",{class:!0});var Nl=s(Qo);T(r$.$$.fragment,Nl),Q2r=i(Nl),ec=n(Nl,"P",{});var vle=s(ec);W2r=r(vle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),oY=n(vle,"A",{href:!0});var eGt=s(oY);U2r=r(eGt,"from_pretrained()"),eGt.forEach(t),H2r=r(vle," class method or the "),rY=n(vle,"A",{href:!0});var oGt=s(rY);J2r=r(oGt,"from_config()"),oGt.forEach(t),Y2r=r(vle,` class
method.`),vle.forEach(t),K2r=i(Nl),t$=n(Nl,"P",{});var xeo=s(t$);Z2r=r(xeo,"This class cannot be instantiated directly using "),$Te=n(xeo,"CODE",{});var rGt=s($Te);evr=r(rGt,"__init__()"),rGt.forEach(t),ovr=r(xeo," (throws an error)."),xeo.forEach(t),rvr=i(Nl),xt=n(Nl,"DIV",{class:!0});var Oy=s(xt);T(a$.$$.fragment,Oy),tvr=i(Oy),kTe=n(Oy,"P",{});var tGt=s(kTe);avr=r(tGt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),tGt.forEach(t),nvr=i(Oy),oc=n(Oy,"P",{});var ble=s(oc);svr=r(ble,`Note:
Loading a model from its configuration file does `),STe=n(ble,"STRONG",{});var aGt=s(STe);lvr=r(aGt,"not"),aGt.forEach(t),ivr=r(ble,` load the model weights. It only affects the
model\u2019s configuration. Use `),tY=n(ble,"A",{href:!0});var nGt=s(tY);dvr=r(nGt,"from_pretrained()"),nGt.forEach(t),cvr=r(ble," to load the model weights."),ble.forEach(t),fvr=i(Oy),T(YT.$$.fragment,Oy),Oy.forEach(t),mvr=i(Nl),mo=n(Nl,"DIV",{class:!0});var Sa=s(mo);T(n$.$$.fragment,Sa),gvr=i(Sa),RTe=n(Sa,"P",{});var sGt=s(RTe);hvr=r(sGt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),sGt.forEach(t),uvr=i(Sa),dn=n(Sa,"P",{});var Vy=s(dn);pvr=r(Vy,"The model class to instantiate is selected based on the "),PTe=n(Vy,"CODE",{});var lGt=s(PTe);_vr=r(lGt,"model_type"),lGt.forEach(t),vvr=r(Vy,` property of the config object (either
passed as an argument or loaded from `),BTe=n(Vy,"CODE",{});var iGt=s(BTe);bvr=r(iGt,"pretrained_model_name_or_path"),iGt.forEach(t),Fvr=r(Vy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ITe=n(Vy,"CODE",{});var dGt=s(ITe);Tvr=r(dGt,"pretrained_model_name_or_path"),dGt.forEach(t),Mvr=r(Vy,":"),Vy.forEach(t),Evr=i(Sa),ve=n(Sa,"UL",{});var Fe=s(ve);KT=n(Fe,"LI",{});var oXe=s(KT);NTe=n(oXe,"STRONG",{});var cGt=s(NTe);Cvr=r(cGt,"beit"),cGt.forEach(t),wvr=r(oXe," \u2014 "),aY=n(oXe,"A",{href:!0});var fGt=s(aY);Avr=r(fGt,"BeitForImageClassification"),fGt.forEach(t),Lvr=r(oXe," (BEiT model)"),oXe.forEach(t),yvr=i(Fe),ZT=n(Fe,"LI",{});var rXe=s(ZT);qTe=n(rXe,"STRONG",{});var mGt=s(qTe);xvr=r(mGt,"convnext"),mGt.forEach(t),$vr=r(rXe," \u2014 "),nY=n(rXe,"A",{href:!0});var gGt=s(nY);kvr=r(gGt,"ConvNextForImageClassification"),gGt.forEach(t),Svr=r(rXe," (ConvNeXT model)"),rXe.forEach(t),Rvr=i(Fe),eM=n(Fe,"LI",{});var tXe=s(eM);jTe=n(tXe,"STRONG",{});var hGt=s(jTe);Pvr=r(hGt,"cvt"),hGt.forEach(t),Bvr=r(tXe," \u2014 "),sY=n(tXe,"A",{href:!0});var uGt=s(sY);Ivr=r(uGt,"CvtForImageClassification"),uGt.forEach(t),Nvr=r(tXe," (CvT model)"),tXe.forEach(t),qvr=i(Fe),oM=n(Fe,"LI",{});var aXe=s(oM);DTe=n(aXe,"STRONG",{});var pGt=s(DTe);jvr=r(pGt,"data2vec-vision"),pGt.forEach(t),Dvr=r(aXe," \u2014 "),lY=n(aXe,"A",{href:!0});var _Gt=s(lY);Gvr=r(_Gt,"Data2VecVisionForImageClassification"),_Gt.forEach(t),Ovr=r(aXe," (Data2VecVision model)"),aXe.forEach(t),Vvr=i(Fe),_l=n(Fe,"LI",{});var FB=s(_l);GTe=n(FB,"STRONG",{});var vGt=s(GTe);Xvr=r(vGt,"deit"),vGt.forEach(t),zvr=r(FB," \u2014 "),iY=n(FB,"A",{href:!0});var bGt=s(iY);Qvr=r(bGt,"DeiTForImageClassification"),bGt.forEach(t),Wvr=r(FB," or "),dY=n(FB,"A",{href:!0});var FGt=s(dY);Uvr=r(FGt,"DeiTForImageClassificationWithTeacher"),FGt.forEach(t),Hvr=r(FB," (DeiT model)"),FB.forEach(t),Jvr=i(Fe),rM=n(Fe,"LI",{});var nXe=s(rM);OTe=n(nXe,"STRONG",{});var TGt=s(OTe);Yvr=r(TGt,"imagegpt"),TGt.forEach(t),Kvr=r(nXe," \u2014 "),cY=n(nXe,"A",{href:!0});var MGt=s(cY);Zvr=r(MGt,"ImageGPTForImageClassification"),MGt.forEach(t),e4r=r(nXe," (ImageGPT model)"),nXe.forEach(t),o4r=i(Fe),vl=n(Fe,"LI",{});var TB=s(vl);VTe=n(TB,"STRONG",{});var EGt=s(VTe);r4r=r(EGt,"levit"),EGt.forEach(t),t4r=r(TB," \u2014 "),fY=n(TB,"A",{href:!0});var CGt=s(fY);a4r=r(CGt,"LevitForImageClassification"),CGt.forEach(t),n4r=r(TB," or "),mY=n(TB,"A",{href:!0});var wGt=s(mY);s4r=r(wGt,"LevitForImageClassificationWithTeacher"),wGt.forEach(t),l4r=r(TB," (LeViT model)"),TB.forEach(t),i4r=i(Fe),tM=n(Fe,"LI",{});var sXe=s(tM);XTe=n(sXe,"STRONG",{});var AGt=s(XTe);d4r=r(AGt,"mobilevit"),AGt.forEach(t),c4r=r(sXe," \u2014 "),gY=n(sXe,"A",{href:!0});var LGt=s(gY);f4r=r(LGt,"MobileViTForImageClassification"),LGt.forEach(t),m4r=r(sXe," (MobileViT model)"),sXe.forEach(t),g4r=i(Fe),$t=n(Fe,"LI",{});var Tm=s($t);zTe=n(Tm,"STRONG",{});var yGt=s(zTe);h4r=r(yGt,"perceiver"),yGt.forEach(t),u4r=r(Tm," \u2014 "),hY=n(Tm,"A",{href:!0});var xGt=s(hY);p4r=r(xGt,"PerceiverForImageClassificationLearned"),xGt.forEach(t),_4r=r(Tm," or "),uY=n(Tm,"A",{href:!0});var $Gt=s(uY);v4r=r($Gt,"PerceiverForImageClassificationFourier"),$Gt.forEach(t),b4r=r(Tm," or "),pY=n(Tm,"A",{href:!0});var kGt=s(pY);F4r=r(kGt,"PerceiverForImageClassificationConvProcessing"),kGt.forEach(t),T4r=r(Tm," (Perceiver model)"),Tm.forEach(t),M4r=i(Fe),aM=n(Fe,"LI",{});var lXe=s(aM);QTe=n(lXe,"STRONG",{});var SGt=s(QTe);E4r=r(SGt,"poolformer"),SGt.forEach(t),C4r=r(lXe," \u2014 "),_Y=n(lXe,"A",{href:!0});var RGt=s(_Y);w4r=r(RGt,"PoolFormerForImageClassification"),RGt.forEach(t),A4r=r(lXe," (PoolFormer model)"),lXe.forEach(t),L4r=i(Fe),nM=n(Fe,"LI",{});var iXe=s(nM);WTe=n(iXe,"STRONG",{});var PGt=s(WTe);y4r=r(PGt,"regnet"),PGt.forEach(t),x4r=r(iXe," \u2014 "),vY=n(iXe,"A",{href:!0});var BGt=s(vY);$4r=r(BGt,"RegNetForImageClassification"),BGt.forEach(t),k4r=r(iXe," (RegNet model)"),iXe.forEach(t),S4r=i(Fe),sM=n(Fe,"LI",{});var dXe=s(sM);UTe=n(dXe,"STRONG",{});var IGt=s(UTe);R4r=r(IGt,"resnet"),IGt.forEach(t),P4r=r(dXe," \u2014 "),bY=n(dXe,"A",{href:!0});var NGt=s(bY);B4r=r(NGt,"ResNetForImageClassification"),NGt.forEach(t),I4r=r(dXe," (ResNet model)"),dXe.forEach(t),N4r=i(Fe),lM=n(Fe,"LI",{});var cXe=s(lM);HTe=n(cXe,"STRONG",{});var qGt=s(HTe);q4r=r(qGt,"segformer"),qGt.forEach(t),j4r=r(cXe," \u2014 "),FY=n(cXe,"A",{href:!0});var jGt=s(FY);D4r=r(jGt,"SegformerForImageClassification"),jGt.forEach(t),G4r=r(cXe," (SegFormer model)"),cXe.forEach(t),O4r=i(Fe),iM=n(Fe,"LI",{});var fXe=s(iM);JTe=n(fXe,"STRONG",{});var DGt=s(JTe);V4r=r(DGt,"swin"),DGt.forEach(t),X4r=r(fXe," \u2014 "),TY=n(fXe,"A",{href:!0});var GGt=s(TY);z4r=r(GGt,"SwinForImageClassification"),GGt.forEach(t),Q4r=r(fXe," (Swin Transformer model)"),fXe.forEach(t),W4r=i(Fe),dM=n(Fe,"LI",{});var mXe=s(dM);YTe=n(mXe,"STRONG",{});var OGt=s(YTe);U4r=r(OGt,"swinv2"),OGt.forEach(t),H4r=r(mXe," \u2014 "),MY=n(mXe,"A",{href:!0});var VGt=s(MY);J4r=r(VGt,"Swinv2ForImageClassification"),VGt.forEach(t),Y4r=r(mXe," (Swin Transformer V2 model)"),mXe.forEach(t),K4r=i(Fe),cM=n(Fe,"LI",{});var gXe=s(cM);KTe=n(gXe,"STRONG",{});var XGt=s(KTe);Z4r=r(XGt,"van"),XGt.forEach(t),ebr=r(gXe," \u2014 "),EY=n(gXe,"A",{href:!0});var zGt=s(EY);obr=r(zGt,"VanForImageClassification"),zGt.forEach(t),rbr=r(gXe," (VAN model)"),gXe.forEach(t),tbr=i(Fe),fM=n(Fe,"LI",{});var hXe=s(fM);ZTe=n(hXe,"STRONG",{});var QGt=s(ZTe);abr=r(QGt,"vit"),QGt.forEach(t),nbr=r(hXe," \u2014 "),CY=n(hXe,"A",{href:!0});var WGt=s(CY);sbr=r(WGt,"ViTForImageClassification"),WGt.forEach(t),lbr=r(hXe," (ViT model)"),hXe.forEach(t),Fe.forEach(t),ibr=i(Sa),mM=n(Sa,"P",{});var uXe=s(mM);dbr=r(uXe,"The model is set in evaluation mode by default using "),eMe=n(uXe,"CODE",{});var UGt=s(eMe);cbr=r(UGt,"model.eval()"),UGt.forEach(t),fbr=r(uXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),oMe=n(uXe,"CODE",{});var HGt=s(oMe);mbr=r(HGt,"model.train()"),HGt.forEach(t),uXe.forEach(t),gbr=i(Sa),T(gM.$$.fragment,Sa),Sa.forEach(t),Nl.forEach(t),pKe=i(f),rc=n(f,"H2",{class:!0});var $eo=s(rc);hM=n($eo,"A",{id:!0,class:!0,href:!0});var JGt=s(hM);rMe=n(JGt,"SPAN",{});var YGt=s(rMe);T(s$.$$.fragment,YGt),YGt.forEach(t),JGt.forEach(t),hbr=i($eo),tMe=n($eo,"SPAN",{});var KGt=s(tMe);ubr=r(KGt,"AutoModelForVideoClassification"),KGt.forEach(t),$eo.forEach(t),_Ke=i(f),Wo=n(f,"DIV",{class:!0});var ql=s(Wo);T(l$.$$.fragment,ql),pbr=i(ql),tc=n(ql,"P",{});var Fle=s(tc);_br=r(Fle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),wY=n(Fle,"A",{href:!0});var ZGt=s(wY);vbr=r(ZGt,"from_pretrained()"),ZGt.forEach(t),bbr=r(Fle," class method or the "),AY=n(Fle,"A",{href:!0});var eOt=s(AY);Fbr=r(eOt,"from_config()"),eOt.forEach(t),Tbr=r(Fle,` class
method.`),Fle.forEach(t),Mbr=i(ql),i$=n(ql,"P",{});var keo=s(i$);Ebr=r(keo,"This class cannot be instantiated directly using "),aMe=n(keo,"CODE",{});var oOt=s(aMe);Cbr=r(oOt,"__init__()"),oOt.forEach(t),wbr=r(keo," (throws an error)."),keo.forEach(t),Abr=i(ql),kt=n(ql,"DIV",{class:!0});var Xy=s(kt);T(d$.$$.fragment,Xy),Lbr=i(Xy),nMe=n(Xy,"P",{});var rOt=s(nMe);ybr=r(rOt,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),rOt.forEach(t),xbr=i(Xy),ac=n(Xy,"P",{});var Tle=s(ac);$br=r(Tle,`Note:
Loading a model from its configuration file does `),sMe=n(Tle,"STRONG",{});var tOt=s(sMe);kbr=r(tOt,"not"),tOt.forEach(t),Sbr=r(Tle,` load the model weights. It only affects the
model\u2019s configuration. Use `),LY=n(Tle,"A",{href:!0});var aOt=s(LY);Rbr=r(aOt,"from_pretrained()"),aOt.forEach(t),Pbr=r(Tle," to load the model weights."),Tle.forEach(t),Bbr=i(Xy),T(uM.$$.fragment,Xy),Xy.forEach(t),Ibr=i(ql),go=n(ql,"DIV",{class:!0});var Ra=s(go);T(c$.$$.fragment,Ra),Nbr=i(Ra),lMe=n(Ra,"P",{});var nOt=s(lMe);qbr=r(nOt,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),nOt.forEach(t),jbr=i(Ra),cn=n(Ra,"P",{});var zy=s(cn);Dbr=r(zy,"The model class to instantiate is selected based on the "),iMe=n(zy,"CODE",{});var sOt=s(iMe);Gbr=r(sOt,"model_type"),sOt.forEach(t),Obr=r(zy,` property of the config object (either
passed as an argument or loaded from `),dMe=n(zy,"CODE",{});var lOt=s(dMe);Vbr=r(lOt,"pretrained_model_name_or_path"),lOt.forEach(t),Xbr=r(zy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cMe=n(zy,"CODE",{});var iOt=s(cMe);zbr=r(iOt,"pretrained_model_name_or_path"),iOt.forEach(t),Qbr=r(zy,":"),zy.forEach(t),Wbr=i(Ra),fMe=n(Ra,"UL",{});var dOt=s(fMe);pM=n(dOt,"LI",{});var pXe=s(pM);mMe=n(pXe,"STRONG",{});var cOt=s(mMe);Ubr=r(cOt,"videomae"),cOt.forEach(t),Hbr=r(pXe," \u2014 "),yY=n(pXe,"A",{href:!0});var fOt=s(yY);Jbr=r(fOt,"VideoMAEForVideoClassification"),fOt.forEach(t),Ybr=r(pXe," (VideoMAE model)"),pXe.forEach(t),dOt.forEach(t),Kbr=i(Ra),_M=n(Ra,"P",{});var _Xe=s(_M);Zbr=r(_Xe,"The model is set in evaluation mode by default using "),gMe=n(_Xe,"CODE",{});var mOt=s(gMe);e1r=r(mOt,"model.eval()"),mOt.forEach(t),o1r=r(_Xe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hMe=n(_Xe,"CODE",{});var gOt=s(hMe);r1r=r(gOt,"model.train()"),gOt.forEach(t),_Xe.forEach(t),t1r=i(Ra),T(vM.$$.fragment,Ra),Ra.forEach(t),ql.forEach(t),vKe=i(f),nc=n(f,"H2",{class:!0});var Seo=s(nc);bM=n(Seo,"A",{id:!0,class:!0,href:!0});var hOt=s(bM);uMe=n(hOt,"SPAN",{});var uOt=s(uMe);T(f$.$$.fragment,uOt),uOt.forEach(t),hOt.forEach(t),a1r=i(Seo),pMe=n(Seo,"SPAN",{});var pOt=s(pMe);n1r=r(pOt,"AutoModelForVision2Seq"),pOt.forEach(t),Seo.forEach(t),bKe=i(f),Uo=n(f,"DIV",{class:!0});var jl=s(Uo);T(m$.$$.fragment,jl),s1r=i(jl),sc=n(jl,"P",{});var Mle=s(sc);l1r=r(Mle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),xY=n(Mle,"A",{href:!0});var _Ot=s(xY);i1r=r(_Ot,"from_pretrained()"),_Ot.forEach(t),d1r=r(Mle," class method or the "),$Y=n(Mle,"A",{href:!0});var vOt=s($Y);c1r=r(vOt,"from_config()"),vOt.forEach(t),f1r=r(Mle,` class
method.`),Mle.forEach(t),m1r=i(jl),g$=n(jl,"P",{});var Reo=s(g$);g1r=r(Reo,"This class cannot be instantiated directly using "),_Me=n(Reo,"CODE",{});var bOt=s(_Me);h1r=r(bOt,"__init__()"),bOt.forEach(t),u1r=r(Reo," (throws an error)."),Reo.forEach(t),p1r=i(jl),St=n(jl,"DIV",{class:!0});var Qy=s(St);T(h$.$$.fragment,Qy),_1r=i(Qy),vMe=n(Qy,"P",{});var FOt=s(vMe);v1r=r(FOt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),FOt.forEach(t),b1r=i(Qy),lc=n(Qy,"P",{});var Ele=s(lc);F1r=r(Ele,`Note:
Loading a model from its configuration file does `),bMe=n(Ele,"STRONG",{});var TOt=s(bMe);T1r=r(TOt,"not"),TOt.forEach(t),M1r=r(Ele,` load the model weights. It only affects the
model\u2019s configuration. Use `),kY=n(Ele,"A",{href:!0});var MOt=s(kY);E1r=r(MOt,"from_pretrained()"),MOt.forEach(t),C1r=r(Ele," to load the model weights."),Ele.forEach(t),w1r=i(Qy),T(FM.$$.fragment,Qy),Qy.forEach(t),A1r=i(jl),ho=n(jl,"DIV",{class:!0});var Pa=s(ho);T(u$.$$.fragment,Pa),L1r=i(Pa),FMe=n(Pa,"P",{});var EOt=s(FMe);y1r=r(EOt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),EOt.forEach(t),x1r=i(Pa),fn=n(Pa,"P",{});var Wy=s(fn);$1r=r(Wy,"The model class to instantiate is selected based on the "),TMe=n(Wy,"CODE",{});var COt=s(TMe);k1r=r(COt,"model_type"),COt.forEach(t),S1r=r(Wy,` property of the config object (either
passed as an argument or loaded from `),MMe=n(Wy,"CODE",{});var wOt=s(MMe);R1r=r(wOt,"pretrained_model_name_or_path"),wOt.forEach(t),P1r=r(Wy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EMe=n(Wy,"CODE",{});var AOt=s(EMe);B1r=r(AOt,"pretrained_model_name_or_path"),AOt.forEach(t),I1r=r(Wy,":"),Wy.forEach(t),N1r=i(Pa),CMe=n(Pa,"UL",{});var LOt=s(CMe);TM=n(LOt,"LI",{});var vXe=s(TM);wMe=n(vXe,"STRONG",{});var yOt=s(wMe);q1r=r(yOt,"vision-encoder-decoder"),yOt.forEach(t),j1r=r(vXe," \u2014 "),SY=n(vXe,"A",{href:!0});var xOt=s(SY);D1r=r(xOt,"VisionEncoderDecoderModel"),xOt.forEach(t),G1r=r(vXe," (Vision Encoder decoder model)"),vXe.forEach(t),LOt.forEach(t),O1r=i(Pa),MM=n(Pa,"P",{});var bXe=s(MM);V1r=r(bXe,"The model is set in evaluation mode by default using "),AMe=n(bXe,"CODE",{});var $Ot=s(AMe);X1r=r($Ot,"model.eval()"),$Ot.forEach(t),z1r=r(bXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LMe=n(bXe,"CODE",{});var kOt=s(LMe);Q1r=r(kOt,"model.train()"),kOt.forEach(t),bXe.forEach(t),W1r=i(Pa),T(EM.$$.fragment,Pa),Pa.forEach(t),jl.forEach(t),FKe=i(f),ic=n(f,"H2",{class:!0});var Peo=s(ic);CM=n(Peo,"A",{id:!0,class:!0,href:!0});var SOt=s(CM);yMe=n(SOt,"SPAN",{});var ROt=s(yMe);T(p$.$$.fragment,ROt),ROt.forEach(t),SOt.forEach(t),U1r=i(Peo),xMe=n(Peo,"SPAN",{});var POt=s(xMe);H1r=r(POt,"AutoModelForVisualQuestionAnswering"),POt.forEach(t),Peo.forEach(t),TKe=i(f),Ho=n(f,"DIV",{class:!0});var Dl=s(Ho);T(_$.$$.fragment,Dl),J1r=i(Dl),dc=n(Dl,"P",{});var Cle=s(dc);Y1r=r(Cle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),RY=n(Cle,"A",{href:!0});var BOt=s(RY);K1r=r(BOt,"from_pretrained()"),BOt.forEach(t),Z1r=r(Cle," class method or the "),PY=n(Cle,"A",{href:!0});var IOt=s(PY);e0r=r(IOt,"from_config()"),IOt.forEach(t),o0r=r(Cle,` class
method.`),Cle.forEach(t),r0r=i(Dl),v$=n(Dl,"P",{});var Beo=s(v$);t0r=r(Beo,"This class cannot be instantiated directly using "),$Me=n(Beo,"CODE",{});var NOt=s($Me);a0r=r(NOt,"__init__()"),NOt.forEach(t),n0r=r(Beo," (throws an error)."),Beo.forEach(t),s0r=i(Dl),Rt=n(Dl,"DIV",{class:!0});var Uy=s(Rt);T(b$.$$.fragment,Uy),l0r=i(Uy),kMe=n(Uy,"P",{});var qOt=s(kMe);i0r=r(qOt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),qOt.forEach(t),d0r=i(Uy),cc=n(Uy,"P",{});var wle=s(cc);c0r=r(wle,`Note:
Loading a model from its configuration file does `),SMe=n(wle,"STRONG",{});var jOt=s(SMe);f0r=r(jOt,"not"),jOt.forEach(t),m0r=r(wle,` load the model weights. It only affects the
model\u2019s configuration. Use `),BY=n(wle,"A",{href:!0});var DOt=s(BY);g0r=r(DOt,"from_pretrained()"),DOt.forEach(t),h0r=r(wle," to load the model weights."),wle.forEach(t),u0r=i(Uy),T(wM.$$.fragment,Uy),Uy.forEach(t),p0r=i(Dl),uo=n(Dl,"DIV",{class:!0});var Ba=s(uo);T(F$.$$.fragment,Ba),_0r=i(Ba),RMe=n(Ba,"P",{});var GOt=s(RMe);v0r=r(GOt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),GOt.forEach(t),b0r=i(Ba),mn=n(Ba,"P",{});var Hy=s(mn);F0r=r(Hy,"The model class to instantiate is selected based on the "),PMe=n(Hy,"CODE",{});var OOt=s(PMe);T0r=r(OOt,"model_type"),OOt.forEach(t),M0r=r(Hy,` property of the config object (either
passed as an argument or loaded from `),BMe=n(Hy,"CODE",{});var VOt=s(BMe);E0r=r(VOt,"pretrained_model_name_or_path"),VOt.forEach(t),C0r=r(Hy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IMe=n(Hy,"CODE",{});var XOt=s(IMe);w0r=r(XOt,"pretrained_model_name_or_path"),XOt.forEach(t),A0r=r(Hy,":"),Hy.forEach(t),L0r=i(Ba),NMe=n(Ba,"UL",{});var zOt=s(NMe);AM=n(zOt,"LI",{});var FXe=s(AM);qMe=n(FXe,"STRONG",{});var QOt=s(qMe);y0r=r(QOt,"vilt"),QOt.forEach(t),x0r=r(FXe," \u2014 "),IY=n(FXe,"A",{href:!0});var WOt=s(IY);$0r=r(WOt,"ViltForQuestionAnswering"),WOt.forEach(t),k0r=r(FXe," (ViLT model)"),FXe.forEach(t),zOt.forEach(t),S0r=i(Ba),LM=n(Ba,"P",{});var TXe=s(LM);R0r=r(TXe,"The model is set in evaluation mode by default using "),jMe=n(TXe,"CODE",{});var UOt=s(jMe);P0r=r(UOt,"model.eval()"),UOt.forEach(t),B0r=r(TXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),DMe=n(TXe,"CODE",{});var HOt=s(DMe);I0r=r(HOt,"model.train()"),HOt.forEach(t),TXe.forEach(t),N0r=i(Ba),T(yM.$$.fragment,Ba),Ba.forEach(t),Dl.forEach(t),MKe=i(f),fc=n(f,"H2",{class:!0});var Ieo=s(fc);xM=n(Ieo,"A",{id:!0,class:!0,href:!0});var JOt=s(xM);GMe=n(JOt,"SPAN",{});var YOt=s(GMe);T(T$.$$.fragment,YOt),YOt.forEach(t),JOt.forEach(t),q0r=i(Ieo),OMe=n(Ieo,"SPAN",{});var KOt=s(OMe);j0r=r(KOt,"AutoModelForAudioClassification"),KOt.forEach(t),Ieo.forEach(t),EKe=i(f),Jo=n(f,"DIV",{class:!0});var Gl=s(Jo);T(M$.$$.fragment,Gl),D0r=i(Gl),mc=n(Gl,"P",{});var Ale=s(mc);G0r=r(Ale,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),NY=n(Ale,"A",{href:!0});var ZOt=s(NY);O0r=r(ZOt,"from_pretrained()"),ZOt.forEach(t),V0r=r(Ale," class method or the "),qY=n(Ale,"A",{href:!0});var eVt=s(qY);X0r=r(eVt,"from_config()"),eVt.forEach(t),z0r=r(Ale,` class
method.`),Ale.forEach(t),Q0r=i(Gl),E$=n(Gl,"P",{});var Neo=s(E$);W0r=r(Neo,"This class cannot be instantiated directly using "),VMe=n(Neo,"CODE",{});var oVt=s(VMe);U0r=r(oVt,"__init__()"),oVt.forEach(t),H0r=r(Neo," (throws an error)."),Neo.forEach(t),J0r=i(Gl),Pt=n(Gl,"DIV",{class:!0});var Jy=s(Pt);T(C$.$$.fragment,Jy),Y0r=i(Jy),XMe=n(Jy,"P",{});var rVt=s(XMe);K0r=r(rVt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),rVt.forEach(t),Z0r=i(Jy),gc=n(Jy,"P",{});var Lle=s(gc);eFr=r(Lle,`Note:
Loading a model from its configuration file does `),zMe=n(Lle,"STRONG",{});var tVt=s(zMe);oFr=r(tVt,"not"),tVt.forEach(t),rFr=r(Lle,` load the model weights. It only affects the
model\u2019s configuration. Use `),jY=n(Lle,"A",{href:!0});var aVt=s(jY);tFr=r(aVt,"from_pretrained()"),aVt.forEach(t),aFr=r(Lle," to load the model weights."),Lle.forEach(t),nFr=i(Jy),T($M.$$.fragment,Jy),Jy.forEach(t),sFr=i(Gl),po=n(Gl,"DIV",{class:!0});var Ia=s(po);T(w$.$$.fragment,Ia),lFr=i(Ia),QMe=n(Ia,"P",{});var nVt=s(QMe);iFr=r(nVt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),nVt.forEach(t),dFr=i(Ia),gn=n(Ia,"P",{});var Yy=s(gn);cFr=r(Yy,"The model class to instantiate is selected based on the "),WMe=n(Yy,"CODE",{});var sVt=s(WMe);fFr=r(sVt,"model_type"),sVt.forEach(t),mFr=r(Yy,` property of the config object (either
passed as an argument or loaded from `),UMe=n(Yy,"CODE",{});var lVt=s(UMe);gFr=r(lVt,"pretrained_model_name_or_path"),lVt.forEach(t),hFr=r(Yy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HMe=n(Yy,"CODE",{});var iVt=s(HMe);uFr=r(iVt,"pretrained_model_name_or_path"),iVt.forEach(t),pFr=r(Yy,":"),Yy.forEach(t),_Fr=i(Ia),Pe=n(Ia,"UL",{});var Qe=s(Pe);kM=n(Qe,"LI",{});var MXe=s(kM);JMe=n(MXe,"STRONG",{});var dVt=s(JMe);vFr=r(dVt,"data2vec-audio"),dVt.forEach(t),bFr=r(MXe," \u2014 "),DY=n(MXe,"A",{href:!0});var cVt=s(DY);FFr=r(cVt,"Data2VecAudioForSequenceClassification"),cVt.forEach(t),TFr=r(MXe," (Data2VecAudio model)"),MXe.forEach(t),MFr=i(Qe),SM=n(Qe,"LI",{});var EXe=s(SM);YMe=n(EXe,"STRONG",{});var fVt=s(YMe);EFr=r(fVt,"hubert"),fVt.forEach(t),CFr=r(EXe," \u2014 "),GY=n(EXe,"A",{href:!0});var mVt=s(GY);wFr=r(mVt,"HubertForSequenceClassification"),mVt.forEach(t),AFr=r(EXe," (Hubert model)"),EXe.forEach(t),LFr=i(Qe),RM=n(Qe,"LI",{});var CXe=s(RM);KMe=n(CXe,"STRONG",{});var gVt=s(KMe);yFr=r(gVt,"sew"),gVt.forEach(t),xFr=r(CXe," \u2014 "),OY=n(CXe,"A",{href:!0});var hVt=s(OY);$Fr=r(hVt,"SEWForSequenceClassification"),hVt.forEach(t),kFr=r(CXe," (SEW model)"),CXe.forEach(t),SFr=i(Qe),PM=n(Qe,"LI",{});var wXe=s(PM);ZMe=n(wXe,"STRONG",{});var uVt=s(ZMe);RFr=r(uVt,"sew-d"),uVt.forEach(t),PFr=r(wXe," \u2014 "),VY=n(wXe,"A",{href:!0});var pVt=s(VY);BFr=r(pVt,"SEWDForSequenceClassification"),pVt.forEach(t),IFr=r(wXe," (SEW-D model)"),wXe.forEach(t),NFr=i(Qe),BM=n(Qe,"LI",{});var AXe=s(BM);eEe=n(AXe,"STRONG",{});var _Vt=s(eEe);qFr=r(_Vt,"unispeech"),_Vt.forEach(t),jFr=r(AXe," \u2014 "),XY=n(AXe,"A",{href:!0});var vVt=s(XY);DFr=r(vVt,"UniSpeechForSequenceClassification"),vVt.forEach(t),GFr=r(AXe," (UniSpeech model)"),AXe.forEach(t),OFr=i(Qe),IM=n(Qe,"LI",{});var LXe=s(IM);oEe=n(LXe,"STRONG",{});var bVt=s(oEe);VFr=r(bVt,"unispeech-sat"),bVt.forEach(t),XFr=r(LXe," \u2014 "),zY=n(LXe,"A",{href:!0});var FVt=s(zY);zFr=r(FVt,"UniSpeechSatForSequenceClassification"),FVt.forEach(t),QFr=r(LXe," (UniSpeechSat model)"),LXe.forEach(t),WFr=i(Qe),NM=n(Qe,"LI",{});var yXe=s(NM);rEe=n(yXe,"STRONG",{});var TVt=s(rEe);UFr=r(TVt,"wav2vec2"),TVt.forEach(t),HFr=r(yXe," \u2014 "),QY=n(yXe,"A",{href:!0});var MVt=s(QY);JFr=r(MVt,"Wav2Vec2ForSequenceClassification"),MVt.forEach(t),YFr=r(yXe," (Wav2Vec2 model)"),yXe.forEach(t),KFr=i(Qe),qM=n(Qe,"LI",{});var xXe=s(qM);tEe=n(xXe,"STRONG",{});var EVt=s(tEe);ZFr=r(EVt,"wav2vec2-conformer"),EVt.forEach(t),eTr=r(xXe," \u2014 "),WY=n(xXe,"A",{href:!0});var CVt=s(WY);oTr=r(CVt,"Wav2Vec2ConformerForSequenceClassification"),CVt.forEach(t),rTr=r(xXe," (Wav2Vec2-Conformer model)"),xXe.forEach(t),tTr=i(Qe),jM=n(Qe,"LI",{});var $Xe=s(jM);aEe=n($Xe,"STRONG",{});var wVt=s(aEe);aTr=r(wVt,"wavlm"),wVt.forEach(t),nTr=r($Xe," \u2014 "),UY=n($Xe,"A",{href:!0});var AVt=s(UY);sTr=r(AVt,"WavLMForSequenceClassification"),AVt.forEach(t),lTr=r($Xe," (WavLM model)"),$Xe.forEach(t),Qe.forEach(t),iTr=i(Ia),DM=n(Ia,"P",{});var kXe=s(DM);dTr=r(kXe,"The model is set in evaluation mode by default using "),nEe=n(kXe,"CODE",{});var LVt=s(nEe);cTr=r(LVt,"model.eval()"),LVt.forEach(t),fTr=r(kXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sEe=n(kXe,"CODE",{});var yVt=s(sEe);mTr=r(yVt,"model.train()"),yVt.forEach(t),kXe.forEach(t),gTr=i(Ia),T(GM.$$.fragment,Ia),Ia.forEach(t),Gl.forEach(t),CKe=i(f),hc=n(f,"H2",{class:!0});var qeo=s(hc);OM=n(qeo,"A",{id:!0,class:!0,href:!0});var xVt=s(OM);lEe=n(xVt,"SPAN",{});var $Vt=s(lEe);T(A$.$$.fragment,$Vt),$Vt.forEach(t),xVt.forEach(t),hTr=i(qeo),iEe=n(qeo,"SPAN",{});var kVt=s(iEe);uTr=r(kVt,"AutoModelForAudioFrameClassification"),kVt.forEach(t),qeo.forEach(t),wKe=i(f),Yo=n(f,"DIV",{class:!0});var Ol=s(Yo);T(L$.$$.fragment,Ol),pTr=i(Ol),uc=n(Ol,"P",{});var yle=s(uc);_Tr=r(yle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),HY=n(yle,"A",{href:!0});var SVt=s(HY);vTr=r(SVt,"from_pretrained()"),SVt.forEach(t),bTr=r(yle," class method or the "),JY=n(yle,"A",{href:!0});var RVt=s(JY);FTr=r(RVt,"from_config()"),RVt.forEach(t),TTr=r(yle,` class
method.`),yle.forEach(t),MTr=i(Ol),y$=n(Ol,"P",{});var jeo=s(y$);ETr=r(jeo,"This class cannot be instantiated directly using "),dEe=n(jeo,"CODE",{});var PVt=s(dEe);CTr=r(PVt,"__init__()"),PVt.forEach(t),wTr=r(jeo," (throws an error)."),jeo.forEach(t),ATr=i(Ol),Bt=n(Ol,"DIV",{class:!0});var Ky=s(Bt);T(x$.$$.fragment,Ky),LTr=i(Ky),cEe=n(Ky,"P",{});var BVt=s(cEe);yTr=r(BVt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),BVt.forEach(t),xTr=i(Ky),pc=n(Ky,"P",{});var xle=s(pc);$Tr=r(xle,`Note:
Loading a model from its configuration file does `),fEe=n(xle,"STRONG",{});var IVt=s(fEe);kTr=r(IVt,"not"),IVt.forEach(t),STr=r(xle,` load the model weights. It only affects the
model\u2019s configuration. Use `),YY=n(xle,"A",{href:!0});var NVt=s(YY);RTr=r(NVt,"from_pretrained()"),NVt.forEach(t),PTr=r(xle," to load the model weights."),xle.forEach(t),BTr=i(Ky),T(VM.$$.fragment,Ky),Ky.forEach(t),ITr=i(Ol),_o=n(Ol,"DIV",{class:!0});var Na=s(_o);T($$.$$.fragment,Na),NTr=i(Na),mEe=n(Na,"P",{});var qVt=s(mEe);qTr=r(qVt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),qVt.forEach(t),jTr=i(Na),hn=n(Na,"P",{});var Zy=s(hn);DTr=r(Zy,"The model class to instantiate is selected based on the "),gEe=n(Zy,"CODE",{});var jVt=s(gEe);GTr=r(jVt,"model_type"),jVt.forEach(t),OTr=r(Zy,` property of the config object (either
passed as an argument or loaded from `),hEe=n(Zy,"CODE",{});var DVt=s(hEe);VTr=r(DVt,"pretrained_model_name_or_path"),DVt.forEach(t),XTr=r(Zy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uEe=n(Zy,"CODE",{});var GVt=s(uEe);zTr=r(GVt,"pretrained_model_name_or_path"),GVt.forEach(t),QTr=r(Zy,":"),Zy.forEach(t),WTr=i(Na),ft=n(Na,"UL",{});var Vl=s(ft);XM=n(Vl,"LI",{});var SXe=s(XM);pEe=n(SXe,"STRONG",{});var OVt=s(pEe);UTr=r(OVt,"data2vec-audio"),OVt.forEach(t),HTr=r(SXe," \u2014 "),KY=n(SXe,"A",{href:!0});var VVt=s(KY);JTr=r(VVt,"Data2VecAudioForAudioFrameClassification"),VVt.forEach(t),YTr=r(SXe," (Data2VecAudio model)"),SXe.forEach(t),KTr=i(Vl),zM=n(Vl,"LI",{});var RXe=s(zM);_Ee=n(RXe,"STRONG",{});var XVt=s(_Ee);ZTr=r(XVt,"unispeech-sat"),XVt.forEach(t),eMr=r(RXe," \u2014 "),ZY=n(RXe,"A",{href:!0});var zVt=s(ZY);oMr=r(zVt,"UniSpeechSatForAudioFrameClassification"),zVt.forEach(t),rMr=r(RXe," (UniSpeechSat model)"),RXe.forEach(t),tMr=i(Vl),QM=n(Vl,"LI",{});var PXe=s(QM);vEe=n(PXe,"STRONG",{});var QVt=s(vEe);aMr=r(QVt,"wav2vec2"),QVt.forEach(t),nMr=r(PXe," \u2014 "),eK=n(PXe,"A",{href:!0});var WVt=s(eK);sMr=r(WVt,"Wav2Vec2ForAudioFrameClassification"),WVt.forEach(t),lMr=r(PXe," (Wav2Vec2 model)"),PXe.forEach(t),iMr=i(Vl),WM=n(Vl,"LI",{});var BXe=s(WM);bEe=n(BXe,"STRONG",{});var UVt=s(bEe);dMr=r(UVt,"wav2vec2-conformer"),UVt.forEach(t),cMr=r(BXe," \u2014 "),oK=n(BXe,"A",{href:!0});var HVt=s(oK);fMr=r(HVt,"Wav2Vec2ConformerForAudioFrameClassification"),HVt.forEach(t),mMr=r(BXe," (Wav2Vec2-Conformer model)"),BXe.forEach(t),gMr=i(Vl),UM=n(Vl,"LI",{});var IXe=s(UM);FEe=n(IXe,"STRONG",{});var JVt=s(FEe);hMr=r(JVt,"wavlm"),JVt.forEach(t),uMr=r(IXe," \u2014 "),rK=n(IXe,"A",{href:!0});var YVt=s(rK);pMr=r(YVt,"WavLMForAudioFrameClassification"),YVt.forEach(t),_Mr=r(IXe," (WavLM model)"),IXe.forEach(t),Vl.forEach(t),vMr=i(Na),HM=n(Na,"P",{});var NXe=s(HM);bMr=r(NXe,"The model is set in evaluation mode by default using "),TEe=n(NXe,"CODE",{});var KVt=s(TEe);FMr=r(KVt,"model.eval()"),KVt.forEach(t),TMr=r(NXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),MEe=n(NXe,"CODE",{});var ZVt=s(MEe);MMr=r(ZVt,"model.train()"),ZVt.forEach(t),NXe.forEach(t),EMr=i(Na),T(JM.$$.fragment,Na),Na.forEach(t),Ol.forEach(t),AKe=i(f),_c=n(f,"H2",{class:!0});var Deo=s(_c);YM=n(Deo,"A",{id:!0,class:!0,href:!0});var eXt=s(YM);EEe=n(eXt,"SPAN",{});var oXt=s(EEe);T(k$.$$.fragment,oXt),oXt.forEach(t),eXt.forEach(t),CMr=i(Deo),CEe=n(Deo,"SPAN",{});var rXt=s(CEe);wMr=r(rXt,"AutoModelForCTC"),rXt.forEach(t),Deo.forEach(t),LKe=i(f),Ko=n(f,"DIV",{class:!0});var Xl=s(Ko);T(S$.$$.fragment,Xl),AMr=i(Xl),vc=n(Xl,"P",{});var $le=s(vc);LMr=r($le,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),tK=n($le,"A",{href:!0});var tXt=s(tK);yMr=r(tXt,"from_pretrained()"),tXt.forEach(t),xMr=r($le," class method or the "),aK=n($le,"A",{href:!0});var aXt=s(aK);$Mr=r(aXt,"from_config()"),aXt.forEach(t),kMr=r($le,` class
method.`),$le.forEach(t),SMr=i(Xl),R$=n(Xl,"P",{});var Geo=s(R$);RMr=r(Geo,"This class cannot be instantiated directly using "),wEe=n(Geo,"CODE",{});var nXt=s(wEe);PMr=r(nXt,"__init__()"),nXt.forEach(t),BMr=r(Geo," (throws an error)."),Geo.forEach(t),IMr=i(Xl),It=n(Xl,"DIV",{class:!0});var e8=s(It);T(P$.$$.fragment,e8),NMr=i(e8),AEe=n(e8,"P",{});var sXt=s(AEe);qMr=r(sXt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),sXt.forEach(t),jMr=i(e8),bc=n(e8,"P",{});var kle=s(bc);DMr=r(kle,`Note:
Loading a model from its configuration file does `),LEe=n(kle,"STRONG",{});var lXt=s(LEe);GMr=r(lXt,"not"),lXt.forEach(t),OMr=r(kle,` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=n(kle,"A",{href:!0});var iXt=s(nK);VMr=r(iXt,"from_pretrained()"),iXt.forEach(t),XMr=r(kle," to load the model weights."),kle.forEach(t),zMr=i(e8),T(KM.$$.fragment,e8),e8.forEach(t),QMr=i(Xl),vo=n(Xl,"DIV",{class:!0});var qa=s(vo);T(B$.$$.fragment,qa),WMr=i(qa),yEe=n(qa,"P",{});var dXt=s(yEe);UMr=r(dXt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),dXt.forEach(t),HMr=i(qa),un=n(qa,"P",{});var o8=s(un);JMr=r(o8,"The model class to instantiate is selected based on the "),xEe=n(o8,"CODE",{});var cXt=s(xEe);YMr=r(cXt,"model_type"),cXt.forEach(t),KMr=r(o8,` property of the config object (either
passed as an argument or loaded from `),$Ee=n(o8,"CODE",{});var fXt=s($Ee);ZMr=r(fXt,"pretrained_model_name_or_path"),fXt.forEach(t),eEr=r(o8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kEe=n(o8,"CODE",{});var mXt=s(kEe);oEr=r(mXt,"pretrained_model_name_or_path"),mXt.forEach(t),rEr=r(o8,":"),o8.forEach(t),tEr=i(qa),Le=n(qa,"UL",{});var Ie=s(Le);ZM=n(Ie,"LI",{});var qXe=s(ZM);SEe=n(qXe,"STRONG",{});var gXt=s(SEe);aEr=r(gXt,"data2vec-audio"),gXt.forEach(t),nEr=r(qXe," \u2014 "),sK=n(qXe,"A",{href:!0});var hXt=s(sK);sEr=r(hXt,"Data2VecAudioForCTC"),hXt.forEach(t),lEr=r(qXe," (Data2VecAudio model)"),qXe.forEach(t),iEr=i(Ie),eE=n(Ie,"LI",{});var jXe=s(eE);REe=n(jXe,"STRONG",{});var uXt=s(REe);dEr=r(uXt,"hubert"),uXt.forEach(t),cEr=r(jXe," \u2014 "),lK=n(jXe,"A",{href:!0});var pXt=s(lK);fEr=r(pXt,"HubertForCTC"),pXt.forEach(t),mEr=r(jXe," (Hubert model)"),jXe.forEach(t),gEr=i(Ie),oE=n(Ie,"LI",{});var DXe=s(oE);PEe=n(DXe,"STRONG",{});var _Xt=s(PEe);hEr=r(_Xt,"mctct"),_Xt.forEach(t),uEr=r(DXe," \u2014 "),iK=n(DXe,"A",{href:!0});var vXt=s(iK);pEr=r(vXt,"MCTCTForCTC"),vXt.forEach(t),_Er=r(DXe," (M-CTC-T model)"),DXe.forEach(t),vEr=i(Ie),rE=n(Ie,"LI",{});var GXe=s(rE);BEe=n(GXe,"STRONG",{});var bXt=s(BEe);bEr=r(bXt,"sew"),bXt.forEach(t),FEr=r(GXe," \u2014 "),dK=n(GXe,"A",{href:!0});var FXt=s(dK);TEr=r(FXt,"SEWForCTC"),FXt.forEach(t),MEr=r(GXe," (SEW model)"),GXe.forEach(t),EEr=i(Ie),tE=n(Ie,"LI",{});var OXe=s(tE);IEe=n(OXe,"STRONG",{});var TXt=s(IEe);CEr=r(TXt,"sew-d"),TXt.forEach(t),wEr=r(OXe," \u2014 "),cK=n(OXe,"A",{href:!0});var MXt=s(cK);AEr=r(MXt,"SEWDForCTC"),MXt.forEach(t),LEr=r(OXe," (SEW-D model)"),OXe.forEach(t),yEr=i(Ie),aE=n(Ie,"LI",{});var VXe=s(aE);NEe=n(VXe,"STRONG",{});var EXt=s(NEe);xEr=r(EXt,"unispeech"),EXt.forEach(t),$Er=r(VXe," \u2014 "),fK=n(VXe,"A",{href:!0});var CXt=s(fK);kEr=r(CXt,"UniSpeechForCTC"),CXt.forEach(t),SEr=r(VXe," (UniSpeech model)"),VXe.forEach(t),REr=i(Ie),nE=n(Ie,"LI",{});var XXe=s(nE);qEe=n(XXe,"STRONG",{});var wXt=s(qEe);PEr=r(wXt,"unispeech-sat"),wXt.forEach(t),BEr=r(XXe," \u2014 "),mK=n(XXe,"A",{href:!0});var AXt=s(mK);IEr=r(AXt,"UniSpeechSatForCTC"),AXt.forEach(t),NEr=r(XXe," (UniSpeechSat model)"),XXe.forEach(t),qEr=i(Ie),sE=n(Ie,"LI",{});var zXe=s(sE);jEe=n(zXe,"STRONG",{});var LXt=s(jEe);jEr=r(LXt,"wav2vec2"),LXt.forEach(t),DEr=r(zXe," \u2014 "),gK=n(zXe,"A",{href:!0});var yXt=s(gK);GEr=r(yXt,"Wav2Vec2ForCTC"),yXt.forEach(t),OEr=r(zXe," (Wav2Vec2 model)"),zXe.forEach(t),VEr=i(Ie),lE=n(Ie,"LI",{});var QXe=s(lE);DEe=n(QXe,"STRONG",{});var xXt=s(DEe);XEr=r(xXt,"wav2vec2-conformer"),xXt.forEach(t),zEr=r(QXe," \u2014 "),hK=n(QXe,"A",{href:!0});var $Xt=s(hK);QEr=r($Xt,"Wav2Vec2ConformerForCTC"),$Xt.forEach(t),WEr=r(QXe," (Wav2Vec2-Conformer model)"),QXe.forEach(t),UEr=i(Ie),iE=n(Ie,"LI",{});var WXe=s(iE);GEe=n(WXe,"STRONG",{});var kXt=s(GEe);HEr=r(kXt,"wavlm"),kXt.forEach(t),JEr=r(WXe," \u2014 "),uK=n(WXe,"A",{href:!0});var SXt=s(uK);YEr=r(SXt,"WavLMForCTC"),SXt.forEach(t),KEr=r(WXe," (WavLM model)"),WXe.forEach(t),Ie.forEach(t),ZEr=i(qa),dE=n(qa,"P",{});var UXe=s(dE);eCr=r(UXe,"The model is set in evaluation mode by default using "),OEe=n(UXe,"CODE",{});var RXt=s(OEe);oCr=r(RXt,"model.eval()"),RXt.forEach(t),rCr=r(UXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),VEe=n(UXe,"CODE",{});var PXt=s(VEe);tCr=r(PXt,"model.train()"),PXt.forEach(t),UXe.forEach(t),aCr=i(qa),T(cE.$$.fragment,qa),qa.forEach(t),Xl.forEach(t),yKe=i(f),Fc=n(f,"H2",{class:!0});var Oeo=s(Fc);fE=n(Oeo,"A",{id:!0,class:!0,href:!0});var BXt=s(fE);XEe=n(BXt,"SPAN",{});var IXt=s(XEe);T(I$.$$.fragment,IXt),IXt.forEach(t),BXt.forEach(t),nCr=i(Oeo),zEe=n(Oeo,"SPAN",{});var NXt=s(zEe);sCr=r(NXt,"AutoModelForSpeechSeq2Seq"),NXt.forEach(t),Oeo.forEach(t),xKe=i(f),Zo=n(f,"DIV",{class:!0});var zl=s(Zo);T(N$.$$.fragment,zl),lCr=i(zl),Tc=n(zl,"P",{});var Sle=s(Tc);iCr=r(Sle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),pK=n(Sle,"A",{href:!0});var qXt=s(pK);dCr=r(qXt,"from_pretrained()"),qXt.forEach(t),cCr=r(Sle," class method or the "),_K=n(Sle,"A",{href:!0});var jXt=s(_K);fCr=r(jXt,"from_config()"),jXt.forEach(t),mCr=r(Sle,` class
method.`),Sle.forEach(t),gCr=i(zl),q$=n(zl,"P",{});var Veo=s(q$);hCr=r(Veo,"This class cannot be instantiated directly using "),QEe=n(Veo,"CODE",{});var DXt=s(QEe);uCr=r(DXt,"__init__()"),DXt.forEach(t),pCr=r(Veo," (throws an error)."),Veo.forEach(t),_Cr=i(zl),Nt=n(zl,"DIV",{class:!0});var r8=s(Nt);T(j$.$$.fragment,r8),vCr=i(r8),WEe=n(r8,"P",{});var GXt=s(WEe);bCr=r(GXt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),GXt.forEach(t),FCr=i(r8),Mc=n(r8,"P",{});var Rle=s(Mc);TCr=r(Rle,`Note:
Loading a model from its configuration file does `),UEe=n(Rle,"STRONG",{});var OXt=s(UEe);MCr=r(OXt,"not"),OXt.forEach(t),ECr=r(Rle,` load the model weights. It only affects the
model\u2019s configuration. Use `),vK=n(Rle,"A",{href:!0});var VXt=s(vK);CCr=r(VXt,"from_pretrained()"),VXt.forEach(t),wCr=r(Rle," to load the model weights."),Rle.forEach(t),ACr=i(r8),T(mE.$$.fragment,r8),r8.forEach(t),LCr=i(zl),bo=n(zl,"DIV",{class:!0});var ja=s(bo);T(D$.$$.fragment,ja),yCr=i(ja),HEe=n(ja,"P",{});var XXt=s(HEe);xCr=r(XXt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),XXt.forEach(t),$Cr=i(ja),pn=n(ja,"P",{});var t8=s(pn);kCr=r(t8,"The model class to instantiate is selected based on the "),JEe=n(t8,"CODE",{});var zXt=s(JEe);SCr=r(zXt,"model_type"),zXt.forEach(t),RCr=r(t8,` property of the config object (either
passed as an argument or loaded from `),YEe=n(t8,"CODE",{});var QXt=s(YEe);PCr=r(QXt,"pretrained_model_name_or_path"),QXt.forEach(t),BCr=r(t8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KEe=n(t8,"CODE",{});var WXt=s(KEe);ICr=r(WXt,"pretrained_model_name_or_path"),WXt.forEach(t),NCr=r(t8,":"),t8.forEach(t),qCr=i(ja),G$=n(ja,"UL",{});var Xeo=s(G$);gE=n(Xeo,"LI",{});var HXe=s(gE);ZEe=n(HXe,"STRONG",{});var UXt=s(ZEe);jCr=r(UXt,"speech-encoder-decoder"),UXt.forEach(t),DCr=r(HXe," \u2014 "),bK=n(HXe,"A",{href:!0});var HXt=s(bK);GCr=r(HXt,"SpeechEncoderDecoderModel"),HXt.forEach(t),OCr=r(HXe," (Speech Encoder decoder model)"),HXe.forEach(t),VCr=i(Xeo),hE=n(Xeo,"LI",{});var JXe=s(hE);eCe=n(JXe,"STRONG",{});var JXt=s(eCe);XCr=r(JXt,"speech_to_text"),JXt.forEach(t),zCr=r(JXe," \u2014 "),FK=n(JXe,"A",{href:!0});var YXt=s(FK);QCr=r(YXt,"Speech2TextForConditionalGeneration"),YXt.forEach(t),WCr=r(JXe," (Speech2Text model)"),JXe.forEach(t),Xeo.forEach(t),UCr=i(ja),uE=n(ja,"P",{});var YXe=s(uE);HCr=r(YXe,"The model is set in evaluation mode by default using "),oCe=n(YXe,"CODE",{});var KXt=s(oCe);JCr=r(KXt,"model.eval()"),KXt.forEach(t),YCr=r(YXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rCe=n(YXe,"CODE",{});var ZXt=s(rCe);KCr=r(ZXt,"model.train()"),ZXt.forEach(t),YXe.forEach(t),ZCr=i(ja),T(pE.$$.fragment,ja),ja.forEach(t),zl.forEach(t),$Ke=i(f),Ec=n(f,"H2",{class:!0});var zeo=s(Ec);_E=n(zeo,"A",{id:!0,class:!0,href:!0});var ezt=s(_E);tCe=n(ezt,"SPAN",{});var ozt=s(tCe);T(O$.$$.fragment,ozt),ozt.forEach(t),ezt.forEach(t),e3r=i(zeo),aCe=n(zeo,"SPAN",{});var rzt=s(aCe);o3r=r(rzt,"AutoModelForAudioXVector"),rzt.forEach(t),zeo.forEach(t),kKe=i(f),er=n(f,"DIV",{class:!0});var Ql=s(er);T(V$.$$.fragment,Ql),r3r=i(Ql),Cc=n(Ql,"P",{});var Ple=s(Cc);t3r=r(Ple,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),TK=n(Ple,"A",{href:!0});var tzt=s(TK);a3r=r(tzt,"from_pretrained()"),tzt.forEach(t),n3r=r(Ple," class method or the "),MK=n(Ple,"A",{href:!0});var azt=s(MK);s3r=r(azt,"from_config()"),azt.forEach(t),l3r=r(Ple,` class
method.`),Ple.forEach(t),i3r=i(Ql),X$=n(Ql,"P",{});var Qeo=s(X$);d3r=r(Qeo,"This class cannot be instantiated directly using "),nCe=n(Qeo,"CODE",{});var nzt=s(nCe);c3r=r(nzt,"__init__()"),nzt.forEach(t),f3r=r(Qeo," (throws an error)."),Qeo.forEach(t),m3r=i(Ql),qt=n(Ql,"DIV",{class:!0});var a8=s(qt);T(z$.$$.fragment,a8),g3r=i(a8),sCe=n(a8,"P",{});var szt=s(sCe);h3r=r(szt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),szt.forEach(t),u3r=i(a8),wc=n(a8,"P",{});var Ble=s(wc);p3r=r(Ble,`Note:
Loading a model from its configuration file does `),lCe=n(Ble,"STRONG",{});var lzt=s(lCe);_3r=r(lzt,"not"),lzt.forEach(t),v3r=r(Ble,` load the model weights. It only affects the
model\u2019s configuration. Use `),EK=n(Ble,"A",{href:!0});var izt=s(EK);b3r=r(izt,"from_pretrained()"),izt.forEach(t),F3r=r(Ble," to load the model weights."),Ble.forEach(t),T3r=i(a8),T(vE.$$.fragment,a8),a8.forEach(t),M3r=i(Ql),Fo=n(Ql,"DIV",{class:!0});var Da=s(Fo);T(Q$.$$.fragment,Da),E3r=i(Da),iCe=n(Da,"P",{});var dzt=s(iCe);C3r=r(dzt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),dzt.forEach(t),w3r=i(Da),_n=n(Da,"P",{});var n8=s(_n);A3r=r(n8,"The model class to instantiate is selected based on the "),dCe=n(n8,"CODE",{});var czt=s(dCe);L3r=r(czt,"model_type"),czt.forEach(t),y3r=r(n8,` property of the config object (either
passed as an argument or loaded from `),cCe=n(n8,"CODE",{});var fzt=s(cCe);x3r=r(fzt,"pretrained_model_name_or_path"),fzt.forEach(t),$3r=r(n8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fCe=n(n8,"CODE",{});var mzt=s(fCe);k3r=r(mzt,"pretrained_model_name_or_path"),mzt.forEach(t),S3r=r(n8,":"),n8.forEach(t),R3r=i(Da),mt=n(Da,"UL",{});var Wl=s(mt);bE=n(Wl,"LI",{});var KXe=s(bE);mCe=n(KXe,"STRONG",{});var gzt=s(mCe);P3r=r(gzt,"data2vec-audio"),gzt.forEach(t),B3r=r(KXe," \u2014 "),CK=n(KXe,"A",{href:!0});var hzt=s(CK);I3r=r(hzt,"Data2VecAudioForXVector"),hzt.forEach(t),N3r=r(KXe," (Data2VecAudio model)"),KXe.forEach(t),q3r=i(Wl),FE=n(Wl,"LI",{});var ZXe=s(FE);gCe=n(ZXe,"STRONG",{});var uzt=s(gCe);j3r=r(uzt,"unispeech-sat"),uzt.forEach(t),D3r=r(ZXe," \u2014 "),wK=n(ZXe,"A",{href:!0});var pzt=s(wK);G3r=r(pzt,"UniSpeechSatForXVector"),pzt.forEach(t),O3r=r(ZXe," (UniSpeechSat model)"),ZXe.forEach(t),V3r=i(Wl),TE=n(Wl,"LI",{});var eze=s(TE);hCe=n(eze,"STRONG",{});var _zt=s(hCe);X3r=r(_zt,"wav2vec2"),_zt.forEach(t),z3r=r(eze," \u2014 "),AK=n(eze,"A",{href:!0});var vzt=s(AK);Q3r=r(vzt,"Wav2Vec2ForXVector"),vzt.forEach(t),W3r=r(eze," (Wav2Vec2 model)"),eze.forEach(t),U3r=i(Wl),ME=n(Wl,"LI",{});var oze=s(ME);uCe=n(oze,"STRONG",{});var bzt=s(uCe);H3r=r(bzt,"wav2vec2-conformer"),bzt.forEach(t),J3r=r(oze," \u2014 "),LK=n(oze,"A",{href:!0});var Fzt=s(LK);Y3r=r(Fzt,"Wav2Vec2ConformerForXVector"),Fzt.forEach(t),K3r=r(oze," (Wav2Vec2-Conformer model)"),oze.forEach(t),Z3r=i(Wl),EE=n(Wl,"LI",{});var rze=s(EE);pCe=n(rze,"STRONG",{});var Tzt=s(pCe);e5r=r(Tzt,"wavlm"),Tzt.forEach(t),o5r=r(rze," \u2014 "),yK=n(rze,"A",{href:!0});var Mzt=s(yK);r5r=r(Mzt,"WavLMForXVector"),Mzt.forEach(t),t5r=r(rze," (WavLM model)"),rze.forEach(t),Wl.forEach(t),a5r=i(Da),CE=n(Da,"P",{});var tze=s(CE);n5r=r(tze,"The model is set in evaluation mode by default using "),_Ce=n(tze,"CODE",{});var Ezt=s(_Ce);s5r=r(Ezt,"model.eval()"),Ezt.forEach(t),l5r=r(tze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vCe=n(tze,"CODE",{});var Czt=s(vCe);i5r=r(Czt,"model.train()"),Czt.forEach(t),tze.forEach(t),d5r=i(Da),T(wE.$$.fragment,Da),Da.forEach(t),Ql.forEach(t),SKe=i(f),Ac=n(f,"H2",{class:!0});var Weo=s(Ac);AE=n(Weo,"A",{id:!0,class:!0,href:!0});var wzt=s(AE);bCe=n(wzt,"SPAN",{});var Azt=s(bCe);T(W$.$$.fragment,Azt),Azt.forEach(t),wzt.forEach(t),c5r=i(Weo),FCe=n(Weo,"SPAN",{});var Lzt=s(FCe);f5r=r(Lzt,"AutoModelForMaskedImageModeling"),Lzt.forEach(t),Weo.forEach(t),RKe=i(f),or=n(f,"DIV",{class:!0});var Ul=s(or);T(U$.$$.fragment,Ul),m5r=i(Ul),Lc=n(Ul,"P",{});var Ile=s(Lc);g5r=r(Ile,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),xK=n(Ile,"A",{href:!0});var yzt=s(xK);h5r=r(yzt,"from_pretrained()"),yzt.forEach(t),u5r=r(Ile," class method or the "),$K=n(Ile,"A",{href:!0});var xzt=s($K);p5r=r(xzt,"from_config()"),xzt.forEach(t),_5r=r(Ile,` class
method.`),Ile.forEach(t),v5r=i(Ul),H$=n(Ul,"P",{});var Ueo=s(H$);b5r=r(Ueo,"This class cannot be instantiated directly using "),TCe=n(Ueo,"CODE",{});var $zt=s(TCe);F5r=r($zt,"__init__()"),$zt.forEach(t),T5r=r(Ueo," (throws an error)."),Ueo.forEach(t),M5r=i(Ul),jt=n(Ul,"DIV",{class:!0});var s8=s(jt);T(J$.$$.fragment,s8),E5r=i(s8),MCe=n(s8,"P",{});var kzt=s(MCe);C5r=r(kzt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),kzt.forEach(t),w5r=i(s8),yc=n(s8,"P",{});var Nle=s(yc);A5r=r(Nle,`Note:
Loading a model from its configuration file does `),ECe=n(Nle,"STRONG",{});var Szt=s(ECe);L5r=r(Szt,"not"),Szt.forEach(t),y5r=r(Nle,` load the model weights. It only affects the
model\u2019s configuration. Use `),kK=n(Nle,"A",{href:!0});var Rzt=s(kK);x5r=r(Rzt,"from_pretrained()"),Rzt.forEach(t),$5r=r(Nle," to load the model weights."),Nle.forEach(t),k5r=i(s8),T(LE.$$.fragment,s8),s8.forEach(t),S5r=i(Ul),To=n(Ul,"DIV",{class:!0});var Ga=s(To);T(Y$.$$.fragment,Ga),R5r=i(Ga),CCe=n(Ga,"P",{});var Pzt=s(CCe);P5r=r(Pzt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Pzt.forEach(t),B5r=i(Ga),vn=n(Ga,"P",{});var l8=s(vn);I5r=r(l8,"The model class to instantiate is selected based on the "),wCe=n(l8,"CODE",{});var Bzt=s(wCe);N5r=r(Bzt,"model_type"),Bzt.forEach(t),q5r=r(l8,` property of the config object (either
passed as an argument or loaded from `),ACe=n(l8,"CODE",{});var Izt=s(ACe);j5r=r(Izt,"pretrained_model_name_or_path"),Izt.forEach(t),D5r=r(l8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LCe=n(l8,"CODE",{});var Nzt=s(LCe);G5r=r(Nzt,"pretrained_model_name_or_path"),Nzt.forEach(t),O5r=r(l8,":"),l8.forEach(t),V5r=i(Ga),bn=n(Ga,"UL",{});var i8=s(bn);yE=n(i8,"LI",{});var aze=s(yE);yCe=n(aze,"STRONG",{});var qzt=s(yCe);X5r=r(qzt,"deit"),qzt.forEach(t),z5r=r(aze," \u2014 "),SK=n(aze,"A",{href:!0});var jzt=s(SK);Q5r=r(jzt,"DeiTForMaskedImageModeling"),jzt.forEach(t),W5r=r(aze," (DeiT model)"),aze.forEach(t),U5r=i(i8),xE=n(i8,"LI",{});var nze=s(xE);xCe=n(nze,"STRONG",{});var Dzt=s(xCe);H5r=r(Dzt,"swin"),Dzt.forEach(t),J5r=r(nze," \u2014 "),RK=n(nze,"A",{href:!0});var Gzt=s(RK);Y5r=r(Gzt,"SwinForMaskedImageModeling"),Gzt.forEach(t),K5r=r(nze," (Swin Transformer model)"),nze.forEach(t),Z5r=i(i8),$E=n(i8,"LI",{});var sze=s($E);$Ce=n(sze,"STRONG",{});var Ozt=s($Ce);ewr=r(Ozt,"swinv2"),Ozt.forEach(t),owr=r(sze," \u2014 "),PK=n(sze,"A",{href:!0});var Vzt=s(PK);rwr=r(Vzt,"Swinv2ForMaskedImageModeling"),Vzt.forEach(t),twr=r(sze," (Swin Transformer V2 model)"),sze.forEach(t),awr=i(i8),kE=n(i8,"LI",{});var lze=s(kE);kCe=n(lze,"STRONG",{});var Xzt=s(kCe);nwr=r(Xzt,"vit"),Xzt.forEach(t),swr=r(lze," \u2014 "),BK=n(lze,"A",{href:!0});var zzt=s(BK);lwr=r(zzt,"ViTForMaskedImageModeling"),zzt.forEach(t),iwr=r(lze," (ViT model)"),lze.forEach(t),i8.forEach(t),dwr=i(Ga),SE=n(Ga,"P",{});var ize=s(SE);cwr=r(ize,"The model is set in evaluation mode by default using "),SCe=n(ize,"CODE",{});var Qzt=s(SCe);fwr=r(Qzt,"model.eval()"),Qzt.forEach(t),mwr=r(ize,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),RCe=n(ize,"CODE",{});var Wzt=s(RCe);gwr=r(Wzt,"model.train()"),Wzt.forEach(t),ize.forEach(t),hwr=i(Ga),T(RE.$$.fragment,Ga),Ga.forEach(t),Ul.forEach(t),PKe=i(f),xc=n(f,"H2",{class:!0});var Heo=s(xc);PE=n(Heo,"A",{id:!0,class:!0,href:!0});var Uzt=s(PE);PCe=n(Uzt,"SPAN",{});var Hzt=s(PCe);T(K$.$$.fragment,Hzt),Hzt.forEach(t),Uzt.forEach(t),uwr=i(Heo),BCe=n(Heo,"SPAN",{});var Jzt=s(BCe);pwr=r(Jzt,"AutoModelForObjectDetection"),Jzt.forEach(t),Heo.forEach(t),BKe=i(f),rr=n(f,"DIV",{class:!0});var Hl=s(rr);T(Z$.$$.fragment,Hl),_wr=i(Hl),$c=n(Hl,"P",{});var qle=s($c);vwr=r(qle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),IK=n(qle,"A",{href:!0});var Yzt=s(IK);bwr=r(Yzt,"from_pretrained()"),Yzt.forEach(t),Fwr=r(qle," class method or the "),NK=n(qle,"A",{href:!0});var Kzt=s(NK);Twr=r(Kzt,"from_config()"),Kzt.forEach(t),Mwr=r(qle,` class
method.`),qle.forEach(t),Ewr=i(Hl),ek=n(Hl,"P",{});var Jeo=s(ek);Cwr=r(Jeo,"This class cannot be instantiated directly using "),ICe=n(Jeo,"CODE",{});var Zzt=s(ICe);wwr=r(Zzt,"__init__()"),Zzt.forEach(t),Awr=r(Jeo," (throws an error)."),Jeo.forEach(t),Lwr=i(Hl),Dt=n(Hl,"DIV",{class:!0});var d8=s(Dt);T(ok.$$.fragment,d8),ywr=i(d8),NCe=n(d8,"P",{});var eQt=s(NCe);xwr=r(eQt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),eQt.forEach(t),$wr=i(d8),kc=n(d8,"P",{});var jle=s(kc);kwr=r(jle,`Note:
Loading a model from its configuration file does `),qCe=n(jle,"STRONG",{});var oQt=s(qCe);Swr=r(oQt,"not"),oQt.forEach(t),Rwr=r(jle,` load the model weights. It only affects the
model\u2019s configuration. Use `),qK=n(jle,"A",{href:!0});var rQt=s(qK);Pwr=r(rQt,"from_pretrained()"),rQt.forEach(t),Bwr=r(jle," to load the model weights."),jle.forEach(t),Iwr=i(d8),T(BE.$$.fragment,d8),d8.forEach(t),Nwr=i(Hl),Mo=n(Hl,"DIV",{class:!0});var Oa=s(Mo);T(rk.$$.fragment,Oa),qwr=i(Oa),jCe=n(Oa,"P",{});var tQt=s(jCe);jwr=r(tQt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),tQt.forEach(t),Dwr=i(Oa),Fn=n(Oa,"P",{});var c8=s(Fn);Gwr=r(c8,"The model class to instantiate is selected based on the "),DCe=n(c8,"CODE",{});var aQt=s(DCe);Owr=r(aQt,"model_type"),aQt.forEach(t),Vwr=r(c8,` property of the config object (either
passed as an argument or loaded from `),GCe=n(c8,"CODE",{});var nQt=s(GCe);Xwr=r(nQt,"pretrained_model_name_or_path"),nQt.forEach(t),zwr=r(c8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),OCe=n(c8,"CODE",{});var sQt=s(OCe);Qwr=r(sQt,"pretrained_model_name_or_path"),sQt.forEach(t),Wwr=r(c8,":"),c8.forEach(t),Uwr=i(Oa),tk=n(Oa,"UL",{});var Yeo=s(tk);IE=n(Yeo,"LI",{});var dze=s(IE);VCe=n(dze,"STRONG",{});var lQt=s(VCe);Hwr=r(lQt,"detr"),lQt.forEach(t),Jwr=r(dze," \u2014 "),jK=n(dze,"A",{href:!0});var iQt=s(jK);Ywr=r(iQt,"DetrForObjectDetection"),iQt.forEach(t),Kwr=r(dze," (DETR model)"),dze.forEach(t),Zwr=i(Yeo),NE=n(Yeo,"LI",{});var cze=s(NE);XCe=n(cze,"STRONG",{});var dQt=s(XCe);eAr=r(dQt,"yolos"),dQt.forEach(t),oAr=r(cze," \u2014 "),DK=n(cze,"A",{href:!0});var cQt=s(DK);rAr=r(cQt,"YolosForObjectDetection"),cQt.forEach(t),tAr=r(cze," (YOLOS model)"),cze.forEach(t),Yeo.forEach(t),aAr=i(Oa),qE=n(Oa,"P",{});var fze=s(qE);nAr=r(fze,"The model is set in evaluation mode by default using "),zCe=n(fze,"CODE",{});var fQt=s(zCe);sAr=r(fQt,"model.eval()"),fQt.forEach(t),lAr=r(fze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),QCe=n(fze,"CODE",{});var mQt=s(QCe);iAr=r(mQt,"model.train()"),mQt.forEach(t),fze.forEach(t),dAr=i(Oa),T(jE.$$.fragment,Oa),Oa.forEach(t),Hl.forEach(t),IKe=i(f),Sc=n(f,"H2",{class:!0});var Keo=s(Sc);DE=n(Keo,"A",{id:!0,class:!0,href:!0});var gQt=s(DE);WCe=n(gQt,"SPAN",{});var hQt=s(WCe);T(ak.$$.fragment,hQt),hQt.forEach(t),gQt.forEach(t),cAr=i(Keo),UCe=n(Keo,"SPAN",{});var uQt=s(UCe);fAr=r(uQt,"AutoModelForImageSegmentation"),uQt.forEach(t),Keo.forEach(t),NKe=i(f),tr=n(f,"DIV",{class:!0});var Jl=s(tr);T(nk.$$.fragment,Jl),mAr=i(Jl),Rc=n(Jl,"P",{});var Dle=s(Rc);gAr=r(Dle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),GK=n(Dle,"A",{href:!0});var pQt=s(GK);hAr=r(pQt,"from_pretrained()"),pQt.forEach(t),uAr=r(Dle," class method or the "),OK=n(Dle,"A",{href:!0});var _Qt=s(OK);pAr=r(_Qt,"from_config()"),_Qt.forEach(t),_Ar=r(Dle,` class
method.`),Dle.forEach(t),vAr=i(Jl),sk=n(Jl,"P",{});var Zeo=s(sk);bAr=r(Zeo,"This class cannot be instantiated directly using "),HCe=n(Zeo,"CODE",{});var vQt=s(HCe);FAr=r(vQt,"__init__()"),vQt.forEach(t),TAr=r(Zeo," (throws an error)."),Zeo.forEach(t),MAr=i(Jl),Gt=n(Jl,"DIV",{class:!0});var f8=s(Gt);T(lk.$$.fragment,f8),EAr=i(f8),JCe=n(f8,"P",{});var bQt=s(JCe);CAr=r(bQt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),bQt.forEach(t),wAr=i(f8),Pc=n(f8,"P",{});var Gle=s(Pc);AAr=r(Gle,`Note:
Loading a model from its configuration file does `),YCe=n(Gle,"STRONG",{});var FQt=s(YCe);LAr=r(FQt,"not"),FQt.forEach(t),yAr=r(Gle,` load the model weights. It only affects the
model\u2019s configuration. Use `),VK=n(Gle,"A",{href:!0});var TQt=s(VK);xAr=r(TQt,"from_pretrained()"),TQt.forEach(t),$Ar=r(Gle," to load the model weights."),Gle.forEach(t),kAr=i(f8),T(GE.$$.fragment,f8),f8.forEach(t),SAr=i(Jl),Eo=n(Jl,"DIV",{class:!0});var Va=s(Eo);T(ik.$$.fragment,Va),RAr=i(Va),KCe=n(Va,"P",{});var MQt=s(KCe);PAr=r(MQt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),MQt.forEach(t),BAr=i(Va),Tn=n(Va,"P",{});var m8=s(Tn);IAr=r(m8,"The model class to instantiate is selected based on the "),ZCe=n(m8,"CODE",{});var EQt=s(ZCe);NAr=r(EQt,"model_type"),EQt.forEach(t),qAr=r(m8,` property of the config object (either
passed as an argument or loaded from `),e3e=n(m8,"CODE",{});var CQt=s(e3e);jAr=r(CQt,"pretrained_model_name_or_path"),CQt.forEach(t),DAr=r(m8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o3e=n(m8,"CODE",{});var wQt=s(o3e);GAr=r(wQt,"pretrained_model_name_or_path"),wQt.forEach(t),OAr=r(m8,":"),m8.forEach(t),VAr=i(Va),r3e=n(Va,"UL",{});var AQt=s(r3e);OE=n(AQt,"LI",{});var mze=s(OE);t3e=n(mze,"STRONG",{});var LQt=s(t3e);XAr=r(LQt,"detr"),LQt.forEach(t),zAr=r(mze," \u2014 "),XK=n(mze,"A",{href:!0});var yQt=s(XK);QAr=r(yQt,"DetrForSegmentation"),yQt.forEach(t),WAr=r(mze," (DETR model)"),mze.forEach(t),AQt.forEach(t),UAr=i(Va),VE=n(Va,"P",{});var gze=s(VE);HAr=r(gze,"The model is set in evaluation mode by default using "),a3e=n(gze,"CODE",{});var xQt=s(a3e);JAr=r(xQt,"model.eval()"),xQt.forEach(t),YAr=r(gze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n3e=n(gze,"CODE",{});var $Qt=s(n3e);KAr=r($Qt,"model.train()"),$Qt.forEach(t),gze.forEach(t),ZAr=i(Va),T(XE.$$.fragment,Va),Va.forEach(t),Jl.forEach(t),qKe=i(f),Bc=n(f,"H2",{class:!0});var eoo=s(Bc);zE=n(eoo,"A",{id:!0,class:!0,href:!0});var kQt=s(zE);s3e=n(kQt,"SPAN",{});var SQt=s(s3e);T(dk.$$.fragment,SQt),SQt.forEach(t),kQt.forEach(t),e6r=i(eoo),l3e=n(eoo,"SPAN",{});var RQt=s(l3e);o6r=r(RQt,"AutoModelForSemanticSegmentation"),RQt.forEach(t),eoo.forEach(t),jKe=i(f),ar=n(f,"DIV",{class:!0});var Yl=s(ar);T(ck.$$.fragment,Yl),r6r=i(Yl),Ic=n(Yl,"P",{});var Ole=s(Ic);t6r=r(Ole,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zK=n(Ole,"A",{href:!0});var PQt=s(zK);a6r=r(PQt,"from_pretrained()"),PQt.forEach(t),n6r=r(Ole," class method or the "),QK=n(Ole,"A",{href:!0});var BQt=s(QK);s6r=r(BQt,"from_config()"),BQt.forEach(t),l6r=r(Ole,` class
method.`),Ole.forEach(t),i6r=i(Yl),fk=n(Yl,"P",{});var ooo=s(fk);d6r=r(ooo,"This class cannot be instantiated directly using "),i3e=n(ooo,"CODE",{});var IQt=s(i3e);c6r=r(IQt,"__init__()"),IQt.forEach(t),f6r=r(ooo," (throws an error)."),ooo.forEach(t),m6r=i(Yl),Ot=n(Yl,"DIV",{class:!0});var g8=s(Ot);T(mk.$$.fragment,g8),g6r=i(g8),d3e=n(g8,"P",{});var NQt=s(d3e);h6r=r(NQt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),NQt.forEach(t),u6r=i(g8),Nc=n(g8,"P",{});var Vle=s(Nc);p6r=r(Vle,`Note:
Loading a model from its configuration file does `),c3e=n(Vle,"STRONG",{});var qQt=s(c3e);_6r=r(qQt,"not"),qQt.forEach(t),v6r=r(Vle,` load the model weights. It only affects the
model\u2019s configuration. Use `),WK=n(Vle,"A",{href:!0});var jQt=s(WK);b6r=r(jQt,"from_pretrained()"),jQt.forEach(t),F6r=r(Vle," to load the model weights."),Vle.forEach(t),T6r=i(g8),T(QE.$$.fragment,g8),g8.forEach(t),M6r=i(Yl),Co=n(Yl,"DIV",{class:!0});var Xa=s(Co);T(gk.$$.fragment,Xa),E6r=i(Xa),f3e=n(Xa,"P",{});var DQt=s(f3e);C6r=r(DQt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),DQt.forEach(t),w6r=i(Xa),Mn=n(Xa,"P",{});var h8=s(Mn);A6r=r(h8,"The model class to instantiate is selected based on the "),m3e=n(h8,"CODE",{});var GQt=s(m3e);L6r=r(GQt,"model_type"),GQt.forEach(t),y6r=r(h8,` property of the config object (either
passed as an argument or loaded from `),g3e=n(h8,"CODE",{});var OQt=s(g3e);x6r=r(OQt,"pretrained_model_name_or_path"),OQt.forEach(t),$6r=r(h8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h3e=n(h8,"CODE",{});var VQt=s(h3e);k6r=r(VQt,"pretrained_model_name_or_path"),VQt.forEach(t),S6r=r(h8,":"),h8.forEach(t),R6r=i(Xa),gt=n(Xa,"UL",{});var Kl=s(gt);WE=n(Kl,"LI",{});var hze=s(WE);u3e=n(hze,"STRONG",{});var XQt=s(u3e);P6r=r(XQt,"beit"),XQt.forEach(t),B6r=r(hze," \u2014 "),UK=n(hze,"A",{href:!0});var zQt=s(UK);I6r=r(zQt,"BeitForSemanticSegmentation"),zQt.forEach(t),N6r=r(hze," (BEiT model)"),hze.forEach(t),q6r=i(Kl),UE=n(Kl,"LI",{});var uze=s(UE);p3e=n(uze,"STRONG",{});var QQt=s(p3e);j6r=r(QQt,"data2vec-vision"),QQt.forEach(t),D6r=r(uze," \u2014 "),HK=n(uze,"A",{href:!0});var WQt=s(HK);G6r=r(WQt,"Data2VecVisionForSemanticSegmentation"),WQt.forEach(t),O6r=r(uze," (Data2VecVision model)"),uze.forEach(t),V6r=i(Kl),HE=n(Kl,"LI",{});var pze=s(HE);_3e=n(pze,"STRONG",{});var UQt=s(_3e);X6r=r(UQt,"dpt"),UQt.forEach(t),z6r=r(pze," \u2014 "),JK=n(pze,"A",{href:!0});var HQt=s(JK);Q6r=r(HQt,"DPTForSemanticSegmentation"),HQt.forEach(t),W6r=r(pze," (DPT model)"),pze.forEach(t),U6r=i(Kl),JE=n(Kl,"LI",{});var _ze=s(JE);v3e=n(_ze,"STRONG",{});var JQt=s(v3e);H6r=r(JQt,"mobilevit"),JQt.forEach(t),J6r=r(_ze," \u2014 "),YK=n(_ze,"A",{href:!0});var YQt=s(YK);Y6r=r(YQt,"MobileViTForSemanticSegmentation"),YQt.forEach(t),K6r=r(_ze," (MobileViT model)"),_ze.forEach(t),Z6r=i(Kl),YE=n(Kl,"LI",{});var vze=s(YE);b3e=n(vze,"STRONG",{});var KQt=s(b3e);e7r=r(KQt,"segformer"),KQt.forEach(t),o7r=r(vze," \u2014 "),KK=n(vze,"A",{href:!0});var ZQt=s(KK);r7r=r(ZQt,"SegformerForSemanticSegmentation"),ZQt.forEach(t),t7r=r(vze," (SegFormer model)"),vze.forEach(t),Kl.forEach(t),a7r=i(Xa),KE=n(Xa,"P",{});var bze=s(KE);n7r=r(bze,"The model is set in evaluation mode by default using "),F3e=n(bze,"CODE",{});var eWt=s(F3e);s7r=r(eWt,"model.eval()"),eWt.forEach(t),l7r=r(bze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T3e=n(bze,"CODE",{});var oWt=s(T3e);i7r=r(oWt,"model.train()"),oWt.forEach(t),bze.forEach(t),d7r=i(Xa),T(ZE.$$.fragment,Xa),Xa.forEach(t),Yl.forEach(t),DKe=i(f),qc=n(f,"H2",{class:!0});var roo=s(qc);eC=n(roo,"A",{id:!0,class:!0,href:!0});var rWt=s(eC);M3e=n(rWt,"SPAN",{});var tWt=s(M3e);T(hk.$$.fragment,tWt),tWt.forEach(t),rWt.forEach(t),c7r=i(roo),E3e=n(roo,"SPAN",{});var aWt=s(E3e);f7r=r(aWt,"AutoModelForInstanceSegmentation"),aWt.forEach(t),roo.forEach(t),GKe=i(f),nr=n(f,"DIV",{class:!0});var Zl=s(nr);T(uk.$$.fragment,Zl),m7r=i(Zl),jc=n(Zl,"P",{});var Xle=s(jc);g7r=r(Xle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),ZK=n(Xle,"A",{href:!0});var nWt=s(ZK);h7r=r(nWt,"from_pretrained()"),nWt.forEach(t),u7r=r(Xle," class method or the "),eZ=n(Xle,"A",{href:!0});var sWt=s(eZ);p7r=r(sWt,"from_config()"),sWt.forEach(t),_7r=r(Xle,` class
method.`),Xle.forEach(t),v7r=i(Zl),pk=n(Zl,"P",{});var too=s(pk);b7r=r(too,"This class cannot be instantiated directly using "),C3e=n(too,"CODE",{});var lWt=s(C3e);F7r=r(lWt,"__init__()"),lWt.forEach(t),T7r=r(too," (throws an error)."),too.forEach(t),M7r=i(Zl),Vt=n(Zl,"DIV",{class:!0});var u8=s(Vt);T(_k.$$.fragment,u8),E7r=i(u8),w3e=n(u8,"P",{});var iWt=s(w3e);C7r=r(iWt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),iWt.forEach(t),w7r=i(u8),Dc=n(u8,"P",{});var zle=s(Dc);A7r=r(zle,`Note:
Loading a model from its configuration file does `),A3e=n(zle,"STRONG",{});var dWt=s(A3e);L7r=r(dWt,"not"),dWt.forEach(t),y7r=r(zle,` load the model weights. It only affects the
model\u2019s configuration. Use `),oZ=n(zle,"A",{href:!0});var cWt=s(oZ);x7r=r(cWt,"from_pretrained()"),cWt.forEach(t),$7r=r(zle," to load the model weights."),zle.forEach(t),k7r=i(u8),T(oC.$$.fragment,u8),u8.forEach(t),S7r=i(Zl),wo=n(Zl,"DIV",{class:!0});var za=s(wo);T(vk.$$.fragment,za),R7r=i(za),L3e=n(za,"P",{});var fWt=s(L3e);P7r=r(fWt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),fWt.forEach(t),B7r=i(za),En=n(za,"P",{});var p8=s(En);I7r=r(p8,"The model class to instantiate is selected based on the "),y3e=n(p8,"CODE",{});var mWt=s(y3e);N7r=r(mWt,"model_type"),mWt.forEach(t),q7r=r(p8,` property of the config object (either
passed as an argument or loaded from `),x3e=n(p8,"CODE",{});var gWt=s(x3e);j7r=r(gWt,"pretrained_model_name_or_path"),gWt.forEach(t),D7r=r(p8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$3e=n(p8,"CODE",{});var hWt=s($3e);G7r=r(hWt,"pretrained_model_name_or_path"),hWt.forEach(t),O7r=r(p8,":"),p8.forEach(t),V7r=i(za),k3e=n(za,"UL",{});var uWt=s(k3e);rC=n(uWt,"LI",{});var Fze=s(rC);S3e=n(Fze,"STRONG",{});var pWt=s(S3e);X7r=r(pWt,"maskformer"),pWt.forEach(t),z7r=r(Fze," \u2014 "),rZ=n(Fze,"A",{href:!0});var _Wt=s(rZ);Q7r=r(_Wt,"MaskFormerForInstanceSegmentation"),_Wt.forEach(t),W7r=r(Fze," (MaskFormer model)"),Fze.forEach(t),uWt.forEach(t),U7r=i(za),tC=n(za,"P",{});var Tze=s(tC);H7r=r(Tze,"The model is set in evaluation mode by default using "),R3e=n(Tze,"CODE",{});var vWt=s(R3e);J7r=r(vWt,"model.eval()"),vWt.forEach(t),Y7r=r(Tze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P3e=n(Tze,"CODE",{});var bWt=s(P3e);K7r=r(bWt,"model.train()"),bWt.forEach(t),Tze.forEach(t),Z7r=i(za),T(aC.$$.fragment,za),za.forEach(t),Zl.forEach(t),OKe=i(f),Gc=n(f,"H2",{class:!0});var aoo=s(Gc);nC=n(aoo,"A",{id:!0,class:!0,href:!0});var FWt=s(nC);B3e=n(FWt,"SPAN",{});var TWt=s(B3e);T(bk.$$.fragment,TWt),TWt.forEach(t),FWt.forEach(t),eLr=i(aoo),I3e=n(aoo,"SPAN",{});var MWt=s(I3e);oLr=r(MWt,"TFAutoModel"),MWt.forEach(t),aoo.forEach(t),VKe=i(f),sr=n(f,"DIV",{class:!0});var ei=s(sr);T(Fk.$$.fragment,ei),rLr=i(ei),Oc=n(ei,"P",{});var Qle=s(Oc);tLr=r(Qle,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),tZ=n(Qle,"A",{href:!0});var EWt=s(tZ);aLr=r(EWt,"from_pretrained()"),EWt.forEach(t),nLr=r(Qle," class method or the "),aZ=n(Qle,"A",{href:!0});var CWt=s(aZ);sLr=r(CWt,"from_config()"),CWt.forEach(t),lLr=r(Qle,` class
method.`),Qle.forEach(t),iLr=i(ei),Tk=n(ei,"P",{});var noo=s(Tk);dLr=r(noo,"This class cannot be instantiated directly using "),N3e=n(noo,"CODE",{});var wWt=s(N3e);cLr=r(wWt,"__init__()"),wWt.forEach(t),fLr=r(noo," (throws an error)."),noo.forEach(t),mLr=i(ei),Xt=n(ei,"DIV",{class:!0});var _8=s(Xt);T(Mk.$$.fragment,_8),gLr=i(_8),q3e=n(_8,"P",{});var AWt=s(q3e);hLr=r(AWt,"Instantiates one of the base model classes of the library from a configuration."),AWt.forEach(t),uLr=i(_8),Vc=n(_8,"P",{});var Wle=s(Vc);pLr=r(Wle,`Note:
Loading a model from its configuration file does `),j3e=n(Wle,"STRONG",{});var LWt=s(j3e);_Lr=r(LWt,"not"),LWt.forEach(t),vLr=r(Wle,` load the model weights. It only affects the
model\u2019s configuration. Use `),nZ=n(Wle,"A",{href:!0});var yWt=s(nZ);bLr=r(yWt,"from_pretrained()"),yWt.forEach(t),FLr=r(Wle," to load the model weights."),Wle.forEach(t),TLr=i(_8),T(sC.$$.fragment,_8),_8.forEach(t),MLr=i(ei),Ir=n(ei,"DIV",{class:!0});var oi=s(Ir);T(Ek.$$.fragment,oi),ELr=i(oi),D3e=n(oi,"P",{});var xWt=s(D3e);CLr=r(xWt,"Instantiate one of the base model classes of the library from a pretrained model."),xWt.forEach(t),wLr=i(oi),Cn=n(oi,"P",{});var v8=s(Cn);ALr=r(v8,"The model class to instantiate is selected based on the "),G3e=n(v8,"CODE",{});var $Wt=s(G3e);LLr=r($Wt,"model_type"),$Wt.forEach(t),yLr=r(v8,` property of the config object (either
passed as an argument or loaded from `),O3e=n(v8,"CODE",{});var kWt=s(O3e);xLr=r(kWt,"pretrained_model_name_or_path"),kWt.forEach(t),$Lr=r(v8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V3e=n(v8,"CODE",{});var SWt=s(V3e);kLr=r(SWt,"pretrained_model_name_or_path"),SWt.forEach(t),SLr=r(v8,":"),v8.forEach(t),RLr=i(oi),N=n(oi,"UL",{});var j=s(N);lC=n(j,"LI",{});var Mze=s(lC);X3e=n(Mze,"STRONG",{});var RWt=s(X3e);PLr=r(RWt,"albert"),RWt.forEach(t),BLr=r(Mze," \u2014 "),sZ=n(Mze,"A",{href:!0});var PWt=s(sZ);ILr=r(PWt,"TFAlbertModel"),PWt.forEach(t),NLr=r(Mze," (ALBERT model)"),Mze.forEach(t),qLr=i(j),iC=n(j,"LI",{});var Eze=s(iC);z3e=n(Eze,"STRONG",{});var BWt=s(z3e);jLr=r(BWt,"bart"),BWt.forEach(t),DLr=r(Eze," \u2014 "),lZ=n(Eze,"A",{href:!0});var IWt=s(lZ);GLr=r(IWt,"TFBartModel"),IWt.forEach(t),OLr=r(Eze," (BART model)"),Eze.forEach(t),VLr=i(j),dC=n(j,"LI",{});var Cze=s(dC);Q3e=n(Cze,"STRONG",{});var NWt=s(Q3e);XLr=r(NWt,"bert"),NWt.forEach(t),zLr=r(Cze," \u2014 "),iZ=n(Cze,"A",{href:!0});var qWt=s(iZ);QLr=r(qWt,"TFBertModel"),qWt.forEach(t),WLr=r(Cze," (BERT model)"),Cze.forEach(t),ULr=i(j),cC=n(j,"LI",{});var wze=s(cC);W3e=n(wze,"STRONG",{});var jWt=s(W3e);HLr=r(jWt,"blenderbot"),jWt.forEach(t),JLr=r(wze," \u2014 "),dZ=n(wze,"A",{href:!0});var DWt=s(dZ);YLr=r(DWt,"TFBlenderbotModel"),DWt.forEach(t),KLr=r(wze," (Blenderbot model)"),wze.forEach(t),ZLr=i(j),fC=n(j,"LI",{});var Aze=s(fC);U3e=n(Aze,"STRONG",{});var GWt=s(U3e);eyr=r(GWt,"blenderbot-small"),GWt.forEach(t),oyr=r(Aze," \u2014 "),cZ=n(Aze,"A",{href:!0});var OWt=s(cZ);ryr=r(OWt,"TFBlenderbotSmallModel"),OWt.forEach(t),tyr=r(Aze," (BlenderbotSmall model)"),Aze.forEach(t),ayr=i(j),mC=n(j,"LI",{});var Lze=s(mC);H3e=n(Lze,"STRONG",{});var VWt=s(H3e);nyr=r(VWt,"camembert"),VWt.forEach(t),syr=r(Lze," \u2014 "),fZ=n(Lze,"A",{href:!0});var XWt=s(fZ);lyr=r(XWt,"TFCamembertModel"),XWt.forEach(t),iyr=r(Lze," (CamemBERT model)"),Lze.forEach(t),dyr=i(j),gC=n(j,"LI",{});var yze=s(gC);J3e=n(yze,"STRONG",{});var zWt=s(J3e);cyr=r(zWt,"clip"),zWt.forEach(t),fyr=r(yze," \u2014 "),mZ=n(yze,"A",{href:!0});var QWt=s(mZ);myr=r(QWt,"TFCLIPModel"),QWt.forEach(t),gyr=r(yze," (CLIP model)"),yze.forEach(t),hyr=i(j),hC=n(j,"LI",{});var xze=s(hC);Y3e=n(xze,"STRONG",{});var WWt=s(Y3e);uyr=r(WWt,"convbert"),WWt.forEach(t),pyr=r(xze," \u2014 "),gZ=n(xze,"A",{href:!0});var UWt=s(gZ);_yr=r(UWt,"TFConvBertModel"),UWt.forEach(t),vyr=r(xze," (ConvBERT model)"),xze.forEach(t),byr=i(j),uC=n(j,"LI",{});var $ze=s(uC);K3e=n($ze,"STRONG",{});var HWt=s(K3e);Fyr=r(HWt,"convnext"),HWt.forEach(t),Tyr=r($ze," \u2014 "),hZ=n($ze,"A",{href:!0});var JWt=s(hZ);Myr=r(JWt,"TFConvNextModel"),JWt.forEach(t),Eyr=r($ze," (ConvNeXT model)"),$ze.forEach(t),Cyr=i(j),pC=n(j,"LI",{});var kze=s(pC);Z3e=n(kze,"STRONG",{});var YWt=s(Z3e);wyr=r(YWt,"ctrl"),YWt.forEach(t),Ayr=r(kze," \u2014 "),uZ=n(kze,"A",{href:!0});var KWt=s(uZ);Lyr=r(KWt,"TFCTRLModel"),KWt.forEach(t),yyr=r(kze," (CTRL model)"),kze.forEach(t),xyr=i(j),_C=n(j,"LI",{});var Sze=s(_C);e5e=n(Sze,"STRONG",{});var ZWt=s(e5e);$yr=r(ZWt,"data2vec-vision"),ZWt.forEach(t),kyr=r(Sze," \u2014 "),pZ=n(Sze,"A",{href:!0});var eUt=s(pZ);Syr=r(eUt,"TFData2VecVisionModel"),eUt.forEach(t),Ryr=r(Sze," (Data2VecVision model)"),Sze.forEach(t),Pyr=i(j),vC=n(j,"LI",{});var Rze=s(vC);o5e=n(Rze,"STRONG",{});var oUt=s(o5e);Byr=r(oUt,"deberta"),oUt.forEach(t),Iyr=r(Rze," \u2014 "),_Z=n(Rze,"A",{href:!0});var rUt=s(_Z);Nyr=r(rUt,"TFDebertaModel"),rUt.forEach(t),qyr=r(Rze," (DeBERTa model)"),Rze.forEach(t),jyr=i(j),bC=n(j,"LI",{});var Pze=s(bC);r5e=n(Pze,"STRONG",{});var tUt=s(r5e);Dyr=r(tUt,"deberta-v2"),tUt.forEach(t),Gyr=r(Pze," \u2014 "),vZ=n(Pze,"A",{href:!0});var aUt=s(vZ);Oyr=r(aUt,"TFDebertaV2Model"),aUt.forEach(t),Vyr=r(Pze," (DeBERTa-v2 model)"),Pze.forEach(t),Xyr=i(j),FC=n(j,"LI",{});var Bze=s(FC);t5e=n(Bze,"STRONG",{});var nUt=s(t5e);zyr=r(nUt,"deit"),nUt.forEach(t),Qyr=r(Bze," \u2014 "),bZ=n(Bze,"A",{href:!0});var sUt=s(bZ);Wyr=r(sUt,"TFDeiTModel"),sUt.forEach(t),Uyr=r(Bze," (DeiT model)"),Bze.forEach(t),Hyr=i(j),TC=n(j,"LI",{});var Ize=s(TC);a5e=n(Ize,"STRONG",{});var lUt=s(a5e);Jyr=r(lUt,"distilbert"),lUt.forEach(t),Yyr=r(Ize," \u2014 "),FZ=n(Ize,"A",{href:!0});var iUt=s(FZ);Kyr=r(iUt,"TFDistilBertModel"),iUt.forEach(t),Zyr=r(Ize," (DistilBERT model)"),Ize.forEach(t),e8r=i(j),MC=n(j,"LI",{});var Nze=s(MC);n5e=n(Nze,"STRONG",{});var dUt=s(n5e);o8r=r(dUt,"dpr"),dUt.forEach(t),r8r=r(Nze," \u2014 "),TZ=n(Nze,"A",{href:!0});var cUt=s(TZ);t8r=r(cUt,"TFDPRQuestionEncoder"),cUt.forEach(t),a8r=r(Nze," (DPR model)"),Nze.forEach(t),n8r=i(j),EC=n(j,"LI",{});var qze=s(EC);s5e=n(qze,"STRONG",{});var fUt=s(s5e);s8r=r(fUt,"electra"),fUt.forEach(t),l8r=r(qze," \u2014 "),MZ=n(qze,"A",{href:!0});var mUt=s(MZ);i8r=r(mUt,"TFElectraModel"),mUt.forEach(t),d8r=r(qze," (ELECTRA model)"),qze.forEach(t),c8r=i(j),CC=n(j,"LI",{});var jze=s(CC);l5e=n(jze,"STRONG",{});var gUt=s(l5e);f8r=r(gUt,"flaubert"),gUt.forEach(t),m8r=r(jze," \u2014 "),EZ=n(jze,"A",{href:!0});var hUt=s(EZ);g8r=r(hUt,"TFFlaubertModel"),hUt.forEach(t),h8r=r(jze," (FlauBERT model)"),jze.forEach(t),u8r=i(j),bl=n(j,"LI",{});var MB=s(bl);i5e=n(MB,"STRONG",{});var uUt=s(i5e);p8r=r(uUt,"funnel"),uUt.forEach(t),_8r=r(MB," \u2014 "),CZ=n(MB,"A",{href:!0});var pUt=s(CZ);v8r=r(pUt,"TFFunnelModel"),pUt.forEach(t),b8r=r(MB," or "),wZ=n(MB,"A",{href:!0});var _Ut=s(wZ);F8r=r(_Ut,"TFFunnelBaseModel"),_Ut.forEach(t),T8r=r(MB," (Funnel Transformer model)"),MB.forEach(t),M8r=i(j),wC=n(j,"LI",{});var Dze=s(wC);d5e=n(Dze,"STRONG",{});var vUt=s(d5e);E8r=r(vUt,"gpt2"),vUt.forEach(t),C8r=r(Dze," \u2014 "),AZ=n(Dze,"A",{href:!0});var bUt=s(AZ);w8r=r(bUt,"TFGPT2Model"),bUt.forEach(t),A8r=r(Dze," (OpenAI GPT-2 model)"),Dze.forEach(t),L8r=i(j),AC=n(j,"LI",{});var Gze=s(AC);c5e=n(Gze,"STRONG",{});var FUt=s(c5e);y8r=r(FUt,"gptj"),FUt.forEach(t),x8r=r(Gze," \u2014 "),LZ=n(Gze,"A",{href:!0});var TUt=s(LZ);$8r=r(TUt,"TFGPTJModel"),TUt.forEach(t),k8r=r(Gze," (GPT-J model)"),Gze.forEach(t),S8r=i(j),LC=n(j,"LI",{});var Oze=s(LC);f5e=n(Oze,"STRONG",{});var MUt=s(f5e);R8r=r(MUt,"hubert"),MUt.forEach(t),P8r=r(Oze," \u2014 "),yZ=n(Oze,"A",{href:!0});var EUt=s(yZ);B8r=r(EUt,"TFHubertModel"),EUt.forEach(t),I8r=r(Oze," (Hubert model)"),Oze.forEach(t),N8r=i(j),yC=n(j,"LI",{});var Vze=s(yC);m5e=n(Vze,"STRONG",{});var CUt=s(m5e);q8r=r(CUt,"layoutlm"),CUt.forEach(t),j8r=r(Vze," \u2014 "),xZ=n(Vze,"A",{href:!0});var wUt=s(xZ);D8r=r(wUt,"TFLayoutLMModel"),wUt.forEach(t),G8r=r(Vze," (LayoutLM model)"),Vze.forEach(t),O8r=i(j),xC=n(j,"LI",{});var Xze=s(xC);g5e=n(Xze,"STRONG",{});var AUt=s(g5e);V8r=r(AUt,"layoutlmv3"),AUt.forEach(t),X8r=r(Xze," \u2014 "),$Z=n(Xze,"A",{href:!0});var LUt=s($Z);z8r=r(LUt,"TFLayoutLMv3Model"),LUt.forEach(t),Q8r=r(Xze," (LayoutLMv3 model)"),Xze.forEach(t),W8r=i(j),$C=n(j,"LI",{});var zze=s($C);h5e=n(zze,"STRONG",{});var yUt=s(h5e);U8r=r(yUt,"led"),yUt.forEach(t),H8r=r(zze," \u2014 "),kZ=n(zze,"A",{href:!0});var xUt=s(kZ);J8r=r(xUt,"TFLEDModel"),xUt.forEach(t),Y8r=r(zze," (LED model)"),zze.forEach(t),K8r=i(j),kC=n(j,"LI",{});var Qze=s(kC);u5e=n(Qze,"STRONG",{});var $Ut=s(u5e);Z8r=r($Ut,"longformer"),$Ut.forEach(t),e9r=r(Qze," \u2014 "),SZ=n(Qze,"A",{href:!0});var kUt=s(SZ);o9r=r(kUt,"TFLongformerModel"),kUt.forEach(t),r9r=r(Qze," (Longformer model)"),Qze.forEach(t),t9r=i(j),SC=n(j,"LI",{});var Wze=s(SC);p5e=n(Wze,"STRONG",{});var SUt=s(p5e);a9r=r(SUt,"lxmert"),SUt.forEach(t),n9r=r(Wze," \u2014 "),RZ=n(Wze,"A",{href:!0});var RUt=s(RZ);s9r=r(RUt,"TFLxmertModel"),RUt.forEach(t),l9r=r(Wze," (LXMERT model)"),Wze.forEach(t),i9r=i(j),RC=n(j,"LI",{});var Uze=s(RC);_5e=n(Uze,"STRONG",{});var PUt=s(_5e);d9r=r(PUt,"marian"),PUt.forEach(t),c9r=r(Uze," \u2014 "),PZ=n(Uze,"A",{href:!0});var BUt=s(PZ);f9r=r(BUt,"TFMarianModel"),BUt.forEach(t),m9r=r(Uze," (Marian model)"),Uze.forEach(t),g9r=i(j),PC=n(j,"LI",{});var Hze=s(PC);v5e=n(Hze,"STRONG",{});var IUt=s(v5e);h9r=r(IUt,"mbart"),IUt.forEach(t),u9r=r(Hze," \u2014 "),BZ=n(Hze,"A",{href:!0});var NUt=s(BZ);p9r=r(NUt,"TFMBartModel"),NUt.forEach(t),_9r=r(Hze," (mBART model)"),Hze.forEach(t),v9r=i(j),BC=n(j,"LI",{});var Jze=s(BC);b5e=n(Jze,"STRONG",{});var qUt=s(b5e);b9r=r(qUt,"mobilebert"),qUt.forEach(t),F9r=r(Jze," \u2014 "),IZ=n(Jze,"A",{href:!0});var jUt=s(IZ);T9r=r(jUt,"TFMobileBertModel"),jUt.forEach(t),M9r=r(Jze," (MobileBERT model)"),Jze.forEach(t),E9r=i(j),IC=n(j,"LI",{});var Yze=s(IC);F5e=n(Yze,"STRONG",{});var DUt=s(F5e);C9r=r(DUt,"mobilevit"),DUt.forEach(t),w9r=r(Yze," \u2014 "),NZ=n(Yze,"A",{href:!0});var GUt=s(NZ);A9r=r(GUt,"TFMobileViTModel"),GUt.forEach(t),L9r=r(Yze," (MobileViT model)"),Yze.forEach(t),y9r=i(j),NC=n(j,"LI",{});var Kze=s(NC);T5e=n(Kze,"STRONG",{});var OUt=s(T5e);x9r=r(OUt,"mpnet"),OUt.forEach(t),$9r=r(Kze," \u2014 "),qZ=n(Kze,"A",{href:!0});var VUt=s(qZ);k9r=r(VUt,"TFMPNetModel"),VUt.forEach(t),S9r=r(Kze," (MPNet model)"),Kze.forEach(t),R9r=i(j),qC=n(j,"LI",{});var Zze=s(qC);M5e=n(Zze,"STRONG",{});var XUt=s(M5e);P9r=r(XUt,"mt5"),XUt.forEach(t),B9r=r(Zze," \u2014 "),jZ=n(Zze,"A",{href:!0});var zUt=s(jZ);I9r=r(zUt,"TFMT5Model"),zUt.forEach(t),N9r=r(Zze," (MT5 model)"),Zze.forEach(t),q9r=i(j),jC=n(j,"LI",{});var eQe=s(jC);E5e=n(eQe,"STRONG",{});var QUt=s(E5e);j9r=r(QUt,"openai-gpt"),QUt.forEach(t),D9r=r(eQe," \u2014 "),DZ=n(eQe,"A",{href:!0});var WUt=s(DZ);G9r=r(WUt,"TFOpenAIGPTModel"),WUt.forEach(t),O9r=r(eQe," (OpenAI GPT model)"),eQe.forEach(t),V9r=i(j),DC=n(j,"LI",{});var oQe=s(DC);C5e=n(oQe,"STRONG",{});var UUt=s(C5e);X9r=r(UUt,"opt"),UUt.forEach(t),z9r=r(oQe," \u2014 "),GZ=n(oQe,"A",{href:!0});var HUt=s(GZ);Q9r=r(HUt,"TFOPTModel"),HUt.forEach(t),W9r=r(oQe," (OPT model)"),oQe.forEach(t),U9r=i(j),GC=n(j,"LI",{});var rQe=s(GC);w5e=n(rQe,"STRONG",{});var JUt=s(w5e);H9r=r(JUt,"pegasus"),JUt.forEach(t),J9r=r(rQe," \u2014 "),OZ=n(rQe,"A",{href:!0});var YUt=s(OZ);Y9r=r(YUt,"TFPegasusModel"),YUt.forEach(t),K9r=r(rQe," (Pegasus model)"),rQe.forEach(t),Z9r=i(j),OC=n(j,"LI",{});var tQe=s(OC);A5e=n(tQe,"STRONG",{});var KUt=s(A5e);exr=r(KUt,"regnet"),KUt.forEach(t),oxr=r(tQe," \u2014 "),VZ=n(tQe,"A",{href:!0});var ZUt=s(VZ);rxr=r(ZUt,"TFRegNetModel"),ZUt.forEach(t),txr=r(tQe," (RegNet model)"),tQe.forEach(t),axr=i(j),VC=n(j,"LI",{});var aQe=s(VC);L5e=n(aQe,"STRONG",{});var eHt=s(L5e);nxr=r(eHt,"rembert"),eHt.forEach(t),sxr=r(aQe," \u2014 "),XZ=n(aQe,"A",{href:!0});var oHt=s(XZ);lxr=r(oHt,"TFRemBertModel"),oHt.forEach(t),ixr=r(aQe," (RemBERT model)"),aQe.forEach(t),dxr=i(j),XC=n(j,"LI",{});var nQe=s(XC);y5e=n(nQe,"STRONG",{});var rHt=s(y5e);cxr=r(rHt,"resnet"),rHt.forEach(t),fxr=r(nQe," \u2014 "),zZ=n(nQe,"A",{href:!0});var tHt=s(zZ);mxr=r(tHt,"TFResNetModel"),tHt.forEach(t),gxr=r(nQe," (ResNet model)"),nQe.forEach(t),hxr=i(j),zC=n(j,"LI",{});var sQe=s(zC);x5e=n(sQe,"STRONG",{});var aHt=s(x5e);uxr=r(aHt,"roberta"),aHt.forEach(t),pxr=r(sQe," \u2014 "),QZ=n(sQe,"A",{href:!0});var nHt=s(QZ);_xr=r(nHt,"TFRobertaModel"),nHt.forEach(t),vxr=r(sQe," (RoBERTa model)"),sQe.forEach(t),bxr=i(j),QC=n(j,"LI",{});var lQe=s(QC);$5e=n(lQe,"STRONG",{});var sHt=s($5e);Fxr=r(sHt,"roformer"),sHt.forEach(t),Txr=r(lQe," \u2014 "),WZ=n(lQe,"A",{href:!0});var lHt=s(WZ);Mxr=r(lHt,"TFRoFormerModel"),lHt.forEach(t),Exr=r(lQe," (RoFormer model)"),lQe.forEach(t),Cxr=i(j),WC=n(j,"LI",{});var iQe=s(WC);k5e=n(iQe,"STRONG",{});var iHt=s(k5e);wxr=r(iHt,"segformer"),iHt.forEach(t),Axr=r(iQe," \u2014 "),UZ=n(iQe,"A",{href:!0});var dHt=s(UZ);Lxr=r(dHt,"TFSegformerModel"),dHt.forEach(t),yxr=r(iQe," (SegFormer model)"),iQe.forEach(t),xxr=i(j),UC=n(j,"LI",{});var dQe=s(UC);S5e=n(dQe,"STRONG",{});var cHt=s(S5e);$xr=r(cHt,"speech_to_text"),cHt.forEach(t),kxr=r(dQe," \u2014 "),HZ=n(dQe,"A",{href:!0});var fHt=s(HZ);Sxr=r(fHt,"TFSpeech2TextModel"),fHt.forEach(t),Rxr=r(dQe," (Speech2Text model)"),dQe.forEach(t),Pxr=i(j),HC=n(j,"LI",{});var cQe=s(HC);R5e=n(cQe,"STRONG",{});var mHt=s(R5e);Bxr=r(mHt,"swin"),mHt.forEach(t),Ixr=r(cQe," \u2014 "),JZ=n(cQe,"A",{href:!0});var gHt=s(JZ);Nxr=r(gHt,"TFSwinModel"),gHt.forEach(t),qxr=r(cQe," (Swin Transformer model)"),cQe.forEach(t),jxr=i(j),JC=n(j,"LI",{});var fQe=s(JC);P5e=n(fQe,"STRONG",{});var hHt=s(P5e);Dxr=r(hHt,"t5"),hHt.forEach(t),Gxr=r(fQe," \u2014 "),YZ=n(fQe,"A",{href:!0});var uHt=s(YZ);Oxr=r(uHt,"TFT5Model"),uHt.forEach(t),Vxr=r(fQe," (T5 model)"),fQe.forEach(t),Xxr=i(j),YC=n(j,"LI",{});var mQe=s(YC);B5e=n(mQe,"STRONG",{});var pHt=s(B5e);zxr=r(pHt,"tapas"),pHt.forEach(t),Qxr=r(mQe," \u2014 "),KZ=n(mQe,"A",{href:!0});var _Ht=s(KZ);Wxr=r(_Ht,"TFTapasModel"),_Ht.forEach(t),Uxr=r(mQe," (TAPAS model)"),mQe.forEach(t),Hxr=i(j),KC=n(j,"LI",{});var gQe=s(KC);I5e=n(gQe,"STRONG",{});var vHt=s(I5e);Jxr=r(vHt,"transfo-xl"),vHt.forEach(t),Yxr=r(gQe," \u2014 "),ZZ=n(gQe,"A",{href:!0});var bHt=s(ZZ);Kxr=r(bHt,"TFTransfoXLModel"),bHt.forEach(t),Zxr=r(gQe," (Transformer-XL model)"),gQe.forEach(t),e$r=i(j),ZC=n(j,"LI",{});var hQe=s(ZC);N5e=n(hQe,"STRONG",{});var FHt=s(N5e);o$r=r(FHt,"vit"),FHt.forEach(t),r$r=r(hQe," \u2014 "),eee=n(hQe,"A",{href:!0});var THt=s(eee);t$r=r(THt,"TFViTModel"),THt.forEach(t),a$r=r(hQe," (ViT model)"),hQe.forEach(t),n$r=i(j),e3=n(j,"LI",{});var uQe=s(e3);q5e=n(uQe,"STRONG",{});var MHt=s(q5e);s$r=r(MHt,"vit_mae"),MHt.forEach(t),l$r=r(uQe," \u2014 "),oee=n(uQe,"A",{href:!0});var EHt=s(oee);i$r=r(EHt,"TFViTMAEModel"),EHt.forEach(t),d$r=r(uQe," (ViTMAE model)"),uQe.forEach(t),c$r=i(j),o3=n(j,"LI",{});var pQe=s(o3);j5e=n(pQe,"STRONG",{});var CHt=s(j5e);f$r=r(CHt,"wav2vec2"),CHt.forEach(t),m$r=r(pQe," \u2014 "),ree=n(pQe,"A",{href:!0});var wHt=s(ree);g$r=r(wHt,"TFWav2Vec2Model"),wHt.forEach(t),h$r=r(pQe," (Wav2Vec2 model)"),pQe.forEach(t),u$r=i(j),r3=n(j,"LI",{});var _Qe=s(r3);D5e=n(_Qe,"STRONG",{});var AHt=s(D5e);p$r=r(AHt,"xglm"),AHt.forEach(t),_$r=r(_Qe," \u2014 "),tee=n(_Qe,"A",{href:!0});var LHt=s(tee);v$r=r(LHt,"TFXGLMModel"),LHt.forEach(t),b$r=r(_Qe," (XGLM model)"),_Qe.forEach(t),F$r=i(j),t3=n(j,"LI",{});var vQe=s(t3);G5e=n(vQe,"STRONG",{});var yHt=s(G5e);T$r=r(yHt,"xlm"),yHt.forEach(t),M$r=r(vQe," \u2014 "),aee=n(vQe,"A",{href:!0});var xHt=s(aee);E$r=r(xHt,"TFXLMModel"),xHt.forEach(t),C$r=r(vQe," (XLM model)"),vQe.forEach(t),w$r=i(j),a3=n(j,"LI",{});var bQe=s(a3);O5e=n(bQe,"STRONG",{});var $Ht=s(O5e);A$r=r($Ht,"xlm-roberta"),$Ht.forEach(t),L$r=r(bQe," \u2014 "),nee=n(bQe,"A",{href:!0});var kHt=s(nee);y$r=r(kHt,"TFXLMRobertaModel"),kHt.forEach(t),x$r=r(bQe," (XLM-RoBERTa model)"),bQe.forEach(t),$$r=i(j),n3=n(j,"LI",{});var FQe=s(n3);V5e=n(FQe,"STRONG",{});var SHt=s(V5e);k$r=r(SHt,"xlnet"),SHt.forEach(t),S$r=r(FQe," \u2014 "),see=n(FQe,"A",{href:!0});var RHt=s(see);R$r=r(RHt,"TFXLNetModel"),RHt.forEach(t),P$r=r(FQe," (XLNet model)"),FQe.forEach(t),j.forEach(t),B$r=i(oi),T(s3.$$.fragment,oi),oi.forEach(t),ei.forEach(t),XKe=i(f),Xc=n(f,"H2",{class:!0});var soo=s(Xc);l3=n(soo,"A",{id:!0,class:!0,href:!0});var PHt=s(l3);X5e=n(PHt,"SPAN",{});var BHt=s(X5e);T(Ck.$$.fragment,BHt),BHt.forEach(t),PHt.forEach(t),I$r=i(soo),z5e=n(soo,"SPAN",{});var IHt=s(z5e);N$r=r(IHt,"TFAutoModelForPreTraining"),IHt.forEach(t),soo.forEach(t),zKe=i(f),lr=n(f,"DIV",{class:!0});var ri=s(lr);T(wk.$$.fragment,ri),q$r=i(ri),zc=n(ri,"P",{});var Ule=s(zc);j$r=r(Ule,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),lee=n(Ule,"A",{href:!0});var NHt=s(lee);D$r=r(NHt,"from_pretrained()"),NHt.forEach(t),G$r=r(Ule," class method or the "),iee=n(Ule,"A",{href:!0});var qHt=s(iee);O$r=r(qHt,"from_config()"),qHt.forEach(t),V$r=r(Ule,` class
method.`),Ule.forEach(t),X$r=i(ri),Ak=n(ri,"P",{});var loo=s(Ak);z$r=r(loo,"This class cannot be instantiated directly using "),Q5e=n(loo,"CODE",{});var jHt=s(Q5e);Q$r=r(jHt,"__init__()"),jHt.forEach(t),W$r=r(loo," (throws an error)."),loo.forEach(t),U$r=i(ri),zt=n(ri,"DIV",{class:!0});var b8=s(zt);T(Lk.$$.fragment,b8),H$r=i(b8),W5e=n(b8,"P",{});var DHt=s(W5e);J$r=r(DHt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),DHt.forEach(t),Y$r=i(b8),Qc=n(b8,"P",{});var Hle=s(Qc);K$r=r(Hle,`Note:
Loading a model from its configuration file does `),U5e=n(Hle,"STRONG",{});var GHt=s(U5e);Z$r=r(GHt,"not"),GHt.forEach(t),ekr=r(Hle,` load the model weights. It only affects the
model\u2019s configuration. Use `),dee=n(Hle,"A",{href:!0});var OHt=s(dee);okr=r(OHt,"from_pretrained()"),OHt.forEach(t),rkr=r(Hle," to load the model weights."),Hle.forEach(t),tkr=i(b8),T(i3.$$.fragment,b8),b8.forEach(t),akr=i(ri),Nr=n(ri,"DIV",{class:!0});var ti=s(Nr);T(yk.$$.fragment,ti),nkr=i(ti),H5e=n(ti,"P",{});var VHt=s(H5e);skr=r(VHt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),VHt.forEach(t),lkr=i(ti),wn=n(ti,"P",{});var F8=s(wn);ikr=r(F8,"The model class to instantiate is selected based on the "),J5e=n(F8,"CODE",{});var XHt=s(J5e);dkr=r(XHt,"model_type"),XHt.forEach(t),ckr=r(F8,` property of the config object (either
passed as an argument or loaded from `),Y5e=n(F8,"CODE",{});var zHt=s(Y5e);fkr=r(zHt,"pretrained_model_name_or_path"),zHt.forEach(t),mkr=r(F8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K5e=n(F8,"CODE",{});var QHt=s(K5e);gkr=r(QHt,"pretrained_model_name_or_path"),QHt.forEach(t),hkr=r(F8,":"),F8.forEach(t),ukr=i(ti),se=n(ti,"UL",{});var le=s(se);d3=n(le,"LI",{});var TQe=s(d3);Z5e=n(TQe,"STRONG",{});var WHt=s(Z5e);pkr=r(WHt,"albert"),WHt.forEach(t),_kr=r(TQe," \u2014 "),cee=n(TQe,"A",{href:!0});var UHt=s(cee);vkr=r(UHt,"TFAlbertForPreTraining"),UHt.forEach(t),bkr=r(TQe," (ALBERT model)"),TQe.forEach(t),Fkr=i(le),c3=n(le,"LI",{});var MQe=s(c3);ewe=n(MQe,"STRONG",{});var HHt=s(ewe);Tkr=r(HHt,"bart"),HHt.forEach(t),Mkr=r(MQe," \u2014 "),fee=n(MQe,"A",{href:!0});var JHt=s(fee);Ekr=r(JHt,"TFBartForConditionalGeneration"),JHt.forEach(t),Ckr=r(MQe," (BART model)"),MQe.forEach(t),wkr=i(le),f3=n(le,"LI",{});var EQe=s(f3);owe=n(EQe,"STRONG",{});var YHt=s(owe);Akr=r(YHt,"bert"),YHt.forEach(t),Lkr=r(EQe," \u2014 "),mee=n(EQe,"A",{href:!0});var KHt=s(mee);ykr=r(KHt,"TFBertForPreTraining"),KHt.forEach(t),xkr=r(EQe," (BERT model)"),EQe.forEach(t),$kr=i(le),m3=n(le,"LI",{});var CQe=s(m3);rwe=n(CQe,"STRONG",{});var ZHt=s(rwe);kkr=r(ZHt,"camembert"),ZHt.forEach(t),Skr=r(CQe," \u2014 "),gee=n(CQe,"A",{href:!0});var eJt=s(gee);Rkr=r(eJt,"TFCamembertForMaskedLM"),eJt.forEach(t),Pkr=r(CQe," (CamemBERT model)"),CQe.forEach(t),Bkr=i(le),g3=n(le,"LI",{});var wQe=s(g3);twe=n(wQe,"STRONG",{});var oJt=s(twe);Ikr=r(oJt,"ctrl"),oJt.forEach(t),Nkr=r(wQe," \u2014 "),hee=n(wQe,"A",{href:!0});var rJt=s(hee);qkr=r(rJt,"TFCTRLLMHeadModel"),rJt.forEach(t),jkr=r(wQe," (CTRL model)"),wQe.forEach(t),Dkr=i(le),h3=n(le,"LI",{});var AQe=s(h3);awe=n(AQe,"STRONG",{});var tJt=s(awe);Gkr=r(tJt,"distilbert"),tJt.forEach(t),Okr=r(AQe," \u2014 "),uee=n(AQe,"A",{href:!0});var aJt=s(uee);Vkr=r(aJt,"TFDistilBertForMaskedLM"),aJt.forEach(t),Xkr=r(AQe," (DistilBERT model)"),AQe.forEach(t),zkr=i(le),u3=n(le,"LI",{});var LQe=s(u3);nwe=n(LQe,"STRONG",{});var nJt=s(nwe);Qkr=r(nJt,"electra"),nJt.forEach(t),Wkr=r(LQe," \u2014 "),pee=n(LQe,"A",{href:!0});var sJt=s(pee);Ukr=r(sJt,"TFElectraForPreTraining"),sJt.forEach(t),Hkr=r(LQe," (ELECTRA model)"),LQe.forEach(t),Jkr=i(le),p3=n(le,"LI",{});var yQe=s(p3);swe=n(yQe,"STRONG",{});var lJt=s(swe);Ykr=r(lJt,"flaubert"),lJt.forEach(t),Kkr=r(yQe," \u2014 "),_ee=n(yQe,"A",{href:!0});var iJt=s(_ee);Zkr=r(iJt,"TFFlaubertWithLMHeadModel"),iJt.forEach(t),eSr=r(yQe," (FlauBERT model)"),yQe.forEach(t),oSr=i(le),_3=n(le,"LI",{});var xQe=s(_3);lwe=n(xQe,"STRONG",{});var dJt=s(lwe);rSr=r(dJt,"funnel"),dJt.forEach(t),tSr=r(xQe," \u2014 "),vee=n(xQe,"A",{href:!0});var cJt=s(vee);aSr=r(cJt,"TFFunnelForPreTraining"),cJt.forEach(t),nSr=r(xQe," (Funnel Transformer model)"),xQe.forEach(t),sSr=i(le),v3=n(le,"LI",{});var $Qe=s(v3);iwe=n($Qe,"STRONG",{});var fJt=s(iwe);lSr=r(fJt,"gpt2"),fJt.forEach(t),iSr=r($Qe," \u2014 "),bee=n($Qe,"A",{href:!0});var mJt=s(bee);dSr=r(mJt,"TFGPT2LMHeadModel"),mJt.forEach(t),cSr=r($Qe," (OpenAI GPT-2 model)"),$Qe.forEach(t),fSr=i(le),b3=n(le,"LI",{});var kQe=s(b3);dwe=n(kQe,"STRONG",{});var gJt=s(dwe);mSr=r(gJt,"layoutlm"),gJt.forEach(t),gSr=r(kQe," \u2014 "),Fee=n(kQe,"A",{href:!0});var hJt=s(Fee);hSr=r(hJt,"TFLayoutLMForMaskedLM"),hJt.forEach(t),uSr=r(kQe," (LayoutLM model)"),kQe.forEach(t),pSr=i(le),F3=n(le,"LI",{});var SQe=s(F3);cwe=n(SQe,"STRONG",{});var uJt=s(cwe);_Sr=r(uJt,"lxmert"),uJt.forEach(t),vSr=r(SQe," \u2014 "),Tee=n(SQe,"A",{href:!0});var pJt=s(Tee);bSr=r(pJt,"TFLxmertForPreTraining"),pJt.forEach(t),FSr=r(SQe," (LXMERT model)"),SQe.forEach(t),TSr=i(le),T3=n(le,"LI",{});var RQe=s(T3);fwe=n(RQe,"STRONG",{});var _Jt=s(fwe);MSr=r(_Jt,"mobilebert"),_Jt.forEach(t),ESr=r(RQe," \u2014 "),Mee=n(RQe,"A",{href:!0});var vJt=s(Mee);CSr=r(vJt,"TFMobileBertForPreTraining"),vJt.forEach(t),wSr=r(RQe," (MobileBERT model)"),RQe.forEach(t),ASr=i(le),M3=n(le,"LI",{});var PQe=s(M3);mwe=n(PQe,"STRONG",{});var bJt=s(mwe);LSr=r(bJt,"mpnet"),bJt.forEach(t),ySr=r(PQe," \u2014 "),Eee=n(PQe,"A",{href:!0});var FJt=s(Eee);xSr=r(FJt,"TFMPNetForMaskedLM"),FJt.forEach(t),$Sr=r(PQe," (MPNet model)"),PQe.forEach(t),kSr=i(le),E3=n(le,"LI",{});var BQe=s(E3);gwe=n(BQe,"STRONG",{});var TJt=s(gwe);SSr=r(TJt,"openai-gpt"),TJt.forEach(t),RSr=r(BQe," \u2014 "),Cee=n(BQe,"A",{href:!0});var MJt=s(Cee);PSr=r(MJt,"TFOpenAIGPTLMHeadModel"),MJt.forEach(t),BSr=r(BQe," (OpenAI GPT model)"),BQe.forEach(t),ISr=i(le),C3=n(le,"LI",{});var IQe=s(C3);hwe=n(IQe,"STRONG",{});var EJt=s(hwe);NSr=r(EJt,"roberta"),EJt.forEach(t),qSr=r(IQe," \u2014 "),wee=n(IQe,"A",{href:!0});var CJt=s(wee);jSr=r(CJt,"TFRobertaForMaskedLM"),CJt.forEach(t),DSr=r(IQe," (RoBERTa model)"),IQe.forEach(t),GSr=i(le),w3=n(le,"LI",{});var NQe=s(w3);uwe=n(NQe,"STRONG",{});var wJt=s(uwe);OSr=r(wJt,"t5"),wJt.forEach(t),VSr=r(NQe," \u2014 "),Aee=n(NQe,"A",{href:!0});var AJt=s(Aee);XSr=r(AJt,"TFT5ForConditionalGeneration"),AJt.forEach(t),zSr=r(NQe," (T5 model)"),NQe.forEach(t),QSr=i(le),A3=n(le,"LI",{});var qQe=s(A3);pwe=n(qQe,"STRONG",{});var LJt=s(pwe);WSr=r(LJt,"tapas"),LJt.forEach(t),USr=r(qQe," \u2014 "),Lee=n(qQe,"A",{href:!0});var yJt=s(Lee);HSr=r(yJt,"TFTapasForMaskedLM"),yJt.forEach(t),JSr=r(qQe," (TAPAS model)"),qQe.forEach(t),YSr=i(le),L3=n(le,"LI",{});var jQe=s(L3);_we=n(jQe,"STRONG",{});var xJt=s(_we);KSr=r(xJt,"transfo-xl"),xJt.forEach(t),ZSr=r(jQe," \u2014 "),yee=n(jQe,"A",{href:!0});var $Jt=s(yee);eRr=r($Jt,"TFTransfoXLLMHeadModel"),$Jt.forEach(t),oRr=r(jQe," (Transformer-XL model)"),jQe.forEach(t),rRr=i(le),y3=n(le,"LI",{});var DQe=s(y3);vwe=n(DQe,"STRONG",{});var kJt=s(vwe);tRr=r(kJt,"vit_mae"),kJt.forEach(t),aRr=r(DQe," \u2014 "),xee=n(DQe,"A",{href:!0});var SJt=s(xee);nRr=r(SJt,"TFViTMAEForPreTraining"),SJt.forEach(t),sRr=r(DQe," (ViTMAE model)"),DQe.forEach(t),lRr=i(le),x3=n(le,"LI",{});var GQe=s(x3);bwe=n(GQe,"STRONG",{});var RJt=s(bwe);iRr=r(RJt,"xlm"),RJt.forEach(t),dRr=r(GQe," \u2014 "),$ee=n(GQe,"A",{href:!0});var PJt=s($ee);cRr=r(PJt,"TFXLMWithLMHeadModel"),PJt.forEach(t),fRr=r(GQe," (XLM model)"),GQe.forEach(t),mRr=i(le),$3=n(le,"LI",{});var OQe=s($3);Fwe=n(OQe,"STRONG",{});var BJt=s(Fwe);gRr=r(BJt,"xlm-roberta"),BJt.forEach(t),hRr=r(OQe," \u2014 "),kee=n(OQe,"A",{href:!0});var IJt=s(kee);uRr=r(IJt,"TFXLMRobertaForMaskedLM"),IJt.forEach(t),pRr=r(OQe," (XLM-RoBERTa model)"),OQe.forEach(t),_Rr=i(le),k3=n(le,"LI",{});var VQe=s(k3);Twe=n(VQe,"STRONG",{});var NJt=s(Twe);vRr=r(NJt,"xlnet"),NJt.forEach(t),bRr=r(VQe," \u2014 "),See=n(VQe,"A",{href:!0});var qJt=s(See);FRr=r(qJt,"TFXLNetLMHeadModel"),qJt.forEach(t),TRr=r(VQe," (XLNet model)"),VQe.forEach(t),le.forEach(t),MRr=i(ti),T(S3.$$.fragment,ti),ti.forEach(t),ri.forEach(t),QKe=i(f),Wc=n(f,"H2",{class:!0});var ioo=s(Wc);R3=n(ioo,"A",{id:!0,class:!0,href:!0});var jJt=s(R3);Mwe=n(jJt,"SPAN",{});var DJt=s(Mwe);T(xk.$$.fragment,DJt),DJt.forEach(t),jJt.forEach(t),ERr=i(ioo),Ewe=n(ioo,"SPAN",{});var GJt=s(Ewe);CRr=r(GJt,"TFAutoModelForCausalLM"),GJt.forEach(t),ioo.forEach(t),WKe=i(f),ir=n(f,"DIV",{class:!0});var ai=s(ir);T($k.$$.fragment,ai),wRr=i(ai),Uc=n(ai,"P",{});var Jle=s(Uc);ARr=r(Jle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Ree=n(Jle,"A",{href:!0});var OJt=s(Ree);LRr=r(OJt,"from_pretrained()"),OJt.forEach(t),yRr=r(Jle," class method or the "),Pee=n(Jle,"A",{href:!0});var VJt=s(Pee);xRr=r(VJt,"from_config()"),VJt.forEach(t),$Rr=r(Jle,` class
method.`),Jle.forEach(t),kRr=i(ai),kk=n(ai,"P",{});var doo=s(kk);SRr=r(doo,"This class cannot be instantiated directly using "),Cwe=n(doo,"CODE",{});var XJt=s(Cwe);RRr=r(XJt,"__init__()"),XJt.forEach(t),PRr=r(doo," (throws an error)."),doo.forEach(t),BRr=i(ai),Qt=n(ai,"DIV",{class:!0});var T8=s(Qt);T(Sk.$$.fragment,T8),IRr=i(T8),wwe=n(T8,"P",{});var zJt=s(wwe);NRr=r(zJt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),zJt.forEach(t),qRr=i(T8),Hc=n(T8,"P",{});var Yle=s(Hc);jRr=r(Yle,`Note:
Loading a model from its configuration file does `),Awe=n(Yle,"STRONG",{});var QJt=s(Awe);DRr=r(QJt,"not"),QJt.forEach(t),GRr=r(Yle,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bee=n(Yle,"A",{href:!0});var WJt=s(Bee);ORr=r(WJt,"from_pretrained()"),WJt.forEach(t),VRr=r(Yle," to load the model weights."),Yle.forEach(t),XRr=i(T8),T(P3.$$.fragment,T8),T8.forEach(t),zRr=i(ai),qr=n(ai,"DIV",{class:!0});var ni=s(qr);T(Rk.$$.fragment,ni),QRr=i(ni),Lwe=n(ni,"P",{});var UJt=s(Lwe);WRr=r(UJt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),UJt.forEach(t),URr=i(ni),An=n(ni,"P",{});var M8=s(An);HRr=r(M8,"The model class to instantiate is selected based on the "),ywe=n(M8,"CODE",{});var HJt=s(ywe);JRr=r(HJt,"model_type"),HJt.forEach(t),YRr=r(M8,` property of the config object (either
passed as an argument or loaded from `),xwe=n(M8,"CODE",{});var JJt=s(xwe);KRr=r(JJt,"pretrained_model_name_or_path"),JJt.forEach(t),ZRr=r(M8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$we=n(M8,"CODE",{});var YJt=s($we);ePr=r(YJt,"pretrained_model_name_or_path"),YJt.forEach(t),oPr=r(M8,":"),M8.forEach(t),rPr=i(ni),Me=n(ni,"UL",{});var Ce=s(Me);B3=n(Ce,"LI",{});var XQe=s(B3);kwe=n(XQe,"STRONG",{});var KJt=s(kwe);tPr=r(KJt,"bert"),KJt.forEach(t),aPr=r(XQe," \u2014 "),Iee=n(XQe,"A",{href:!0});var ZJt=s(Iee);nPr=r(ZJt,"TFBertLMHeadModel"),ZJt.forEach(t),sPr=r(XQe," (BERT model)"),XQe.forEach(t),lPr=i(Ce),I3=n(Ce,"LI",{});var zQe=s(I3);Swe=n(zQe,"STRONG",{});var eYt=s(Swe);iPr=r(eYt,"camembert"),eYt.forEach(t),dPr=r(zQe," \u2014 "),Nee=n(zQe,"A",{href:!0});var oYt=s(Nee);cPr=r(oYt,"TFCamembertForCausalLM"),oYt.forEach(t),fPr=r(zQe," (CamemBERT model)"),zQe.forEach(t),mPr=i(Ce),N3=n(Ce,"LI",{});var QQe=s(N3);Rwe=n(QQe,"STRONG",{});var rYt=s(Rwe);gPr=r(rYt,"ctrl"),rYt.forEach(t),hPr=r(QQe," \u2014 "),qee=n(QQe,"A",{href:!0});var tYt=s(qee);uPr=r(tYt,"TFCTRLLMHeadModel"),tYt.forEach(t),pPr=r(QQe," (CTRL model)"),QQe.forEach(t),_Pr=i(Ce),q3=n(Ce,"LI",{});var WQe=s(q3);Pwe=n(WQe,"STRONG",{});var aYt=s(Pwe);vPr=r(aYt,"gpt2"),aYt.forEach(t),bPr=r(WQe," \u2014 "),jee=n(WQe,"A",{href:!0});var nYt=s(jee);FPr=r(nYt,"TFGPT2LMHeadModel"),nYt.forEach(t),TPr=r(WQe," (OpenAI GPT-2 model)"),WQe.forEach(t),MPr=i(Ce),j3=n(Ce,"LI",{});var UQe=s(j3);Bwe=n(UQe,"STRONG",{});var sYt=s(Bwe);EPr=r(sYt,"gptj"),sYt.forEach(t),CPr=r(UQe," \u2014 "),Dee=n(UQe,"A",{href:!0});var lYt=s(Dee);wPr=r(lYt,"TFGPTJForCausalLM"),lYt.forEach(t),APr=r(UQe," (GPT-J model)"),UQe.forEach(t),LPr=i(Ce),D3=n(Ce,"LI",{});var HQe=s(D3);Iwe=n(HQe,"STRONG",{});var iYt=s(Iwe);yPr=r(iYt,"openai-gpt"),iYt.forEach(t),xPr=r(HQe," \u2014 "),Gee=n(HQe,"A",{href:!0});var dYt=s(Gee);$Pr=r(dYt,"TFOpenAIGPTLMHeadModel"),dYt.forEach(t),kPr=r(HQe," (OpenAI GPT model)"),HQe.forEach(t),SPr=i(Ce),G3=n(Ce,"LI",{});var JQe=s(G3);Nwe=n(JQe,"STRONG",{});var cYt=s(Nwe);RPr=r(cYt,"opt"),cYt.forEach(t),PPr=r(JQe," \u2014 "),Oee=n(JQe,"A",{href:!0});var fYt=s(Oee);BPr=r(fYt,"TFOPTForCausalLM"),fYt.forEach(t),IPr=r(JQe," (OPT model)"),JQe.forEach(t),NPr=i(Ce),O3=n(Ce,"LI",{});var YQe=s(O3);qwe=n(YQe,"STRONG",{});var mYt=s(qwe);qPr=r(mYt,"rembert"),mYt.forEach(t),jPr=r(YQe," \u2014 "),Vee=n(YQe,"A",{href:!0});var gYt=s(Vee);DPr=r(gYt,"TFRemBertForCausalLM"),gYt.forEach(t),GPr=r(YQe," (RemBERT model)"),YQe.forEach(t),OPr=i(Ce),V3=n(Ce,"LI",{});var KQe=s(V3);jwe=n(KQe,"STRONG",{});var hYt=s(jwe);VPr=r(hYt,"roberta"),hYt.forEach(t),XPr=r(KQe," \u2014 "),Xee=n(KQe,"A",{href:!0});var uYt=s(Xee);zPr=r(uYt,"TFRobertaForCausalLM"),uYt.forEach(t),QPr=r(KQe," (RoBERTa model)"),KQe.forEach(t),WPr=i(Ce),X3=n(Ce,"LI",{});var ZQe=s(X3);Dwe=n(ZQe,"STRONG",{});var pYt=s(Dwe);UPr=r(pYt,"roformer"),pYt.forEach(t),HPr=r(ZQe," \u2014 "),zee=n(ZQe,"A",{href:!0});var _Yt=s(zee);JPr=r(_Yt,"TFRoFormerForCausalLM"),_Yt.forEach(t),YPr=r(ZQe," (RoFormer model)"),ZQe.forEach(t),KPr=i(Ce),z3=n(Ce,"LI",{});var eWe=s(z3);Gwe=n(eWe,"STRONG",{});var vYt=s(Gwe);ZPr=r(vYt,"transfo-xl"),vYt.forEach(t),eBr=r(eWe," \u2014 "),Qee=n(eWe,"A",{href:!0});var bYt=s(Qee);oBr=r(bYt,"TFTransfoXLLMHeadModel"),bYt.forEach(t),rBr=r(eWe," (Transformer-XL model)"),eWe.forEach(t),tBr=i(Ce),Q3=n(Ce,"LI",{});var oWe=s(Q3);Owe=n(oWe,"STRONG",{});var FYt=s(Owe);aBr=r(FYt,"xglm"),FYt.forEach(t),nBr=r(oWe," \u2014 "),Wee=n(oWe,"A",{href:!0});var TYt=s(Wee);sBr=r(TYt,"TFXGLMForCausalLM"),TYt.forEach(t),lBr=r(oWe," (XGLM model)"),oWe.forEach(t),iBr=i(Ce),W3=n(Ce,"LI",{});var rWe=s(W3);Vwe=n(rWe,"STRONG",{});var MYt=s(Vwe);dBr=r(MYt,"xlm"),MYt.forEach(t),cBr=r(rWe," \u2014 "),Uee=n(rWe,"A",{href:!0});var EYt=s(Uee);fBr=r(EYt,"TFXLMWithLMHeadModel"),EYt.forEach(t),mBr=r(rWe," (XLM model)"),rWe.forEach(t),gBr=i(Ce),U3=n(Ce,"LI",{});var tWe=s(U3);Xwe=n(tWe,"STRONG",{});var CYt=s(Xwe);hBr=r(CYt,"xlnet"),CYt.forEach(t),uBr=r(tWe," \u2014 "),Hee=n(tWe,"A",{href:!0});var wYt=s(Hee);pBr=r(wYt,"TFXLNetLMHeadModel"),wYt.forEach(t),_Br=r(tWe," (XLNet model)"),tWe.forEach(t),Ce.forEach(t),vBr=i(ni),T(H3.$$.fragment,ni),ni.forEach(t),ai.forEach(t),UKe=i(f),Jc=n(f,"H2",{class:!0});var coo=s(Jc);J3=n(coo,"A",{id:!0,class:!0,href:!0});var AYt=s(J3);zwe=n(AYt,"SPAN",{});var LYt=s(zwe);T(Pk.$$.fragment,LYt),LYt.forEach(t),AYt.forEach(t),bBr=i(coo),Qwe=n(coo,"SPAN",{});var yYt=s(Qwe);FBr=r(yYt,"TFAutoModelForImageClassification"),yYt.forEach(t),coo.forEach(t),HKe=i(f),dr=n(f,"DIV",{class:!0});var si=s(dr);T(Bk.$$.fragment,si),TBr=i(si),Yc=n(si,"P",{});var Kle=s(Yc);MBr=r(Kle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Jee=n(Kle,"A",{href:!0});var xYt=s(Jee);EBr=r(xYt,"from_pretrained()"),xYt.forEach(t),CBr=r(Kle," class method or the "),Yee=n(Kle,"A",{href:!0});var $Yt=s(Yee);wBr=r($Yt,"from_config()"),$Yt.forEach(t),ABr=r(Kle,` class
method.`),Kle.forEach(t),LBr=i(si),Ik=n(si,"P",{});var foo=s(Ik);yBr=r(foo,"This class cannot be instantiated directly using "),Wwe=n(foo,"CODE",{});var kYt=s(Wwe);xBr=r(kYt,"__init__()"),kYt.forEach(t),$Br=r(foo," (throws an error)."),foo.forEach(t),kBr=i(si),Wt=n(si,"DIV",{class:!0});var E8=s(Wt);T(Nk.$$.fragment,E8),SBr=i(E8),Uwe=n(E8,"P",{});var SYt=s(Uwe);RBr=r(SYt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),SYt.forEach(t),PBr=i(E8),Kc=n(E8,"P",{});var Zle=s(Kc);BBr=r(Zle,`Note:
Loading a model from its configuration file does `),Hwe=n(Zle,"STRONG",{});var RYt=s(Hwe);IBr=r(RYt,"not"),RYt.forEach(t),NBr=r(Zle,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kee=n(Zle,"A",{href:!0});var PYt=s(Kee);qBr=r(PYt,"from_pretrained()"),PYt.forEach(t),jBr=r(Zle," to load the model weights."),Zle.forEach(t),DBr=i(E8),T(Y3.$$.fragment,E8),E8.forEach(t),GBr=i(si),jr=n(si,"DIV",{class:!0});var li=s(jr);T(qk.$$.fragment,li),OBr=i(li),Jwe=n(li,"P",{});var BYt=s(Jwe);VBr=r(BYt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),BYt.forEach(t),XBr=i(li),Ln=n(li,"P",{});var C8=s(Ln);zBr=r(C8,"The model class to instantiate is selected based on the "),Ywe=n(C8,"CODE",{});var IYt=s(Ywe);QBr=r(IYt,"model_type"),IYt.forEach(t),WBr=r(C8,` property of the config object (either
passed as an argument or loaded from `),Kwe=n(C8,"CODE",{});var NYt=s(Kwe);UBr=r(NYt,"pretrained_model_name_or_path"),NYt.forEach(t),HBr=r(C8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zwe=n(C8,"CODE",{});var qYt=s(Zwe);JBr=r(qYt,"pretrained_model_name_or_path"),qYt.forEach(t),YBr=r(C8,":"),C8.forEach(t),KBr=i(li),Be=n(li,"UL",{});var We=s(Be);K3=n(We,"LI",{});var aWe=s(K3);eAe=n(aWe,"STRONG",{});var jYt=s(eAe);ZBr=r(jYt,"convnext"),jYt.forEach(t),eIr=r(aWe," \u2014 "),Zee=n(aWe,"A",{href:!0});var DYt=s(Zee);oIr=r(DYt,"TFConvNextForImageClassification"),DYt.forEach(t),rIr=r(aWe," (ConvNeXT model)"),aWe.forEach(t),tIr=i(We),Z3=n(We,"LI",{});var nWe=s(Z3);oAe=n(nWe,"STRONG",{});var GYt=s(oAe);aIr=r(GYt,"data2vec-vision"),GYt.forEach(t),nIr=r(nWe," \u2014 "),eoe=n(nWe,"A",{href:!0});var OYt=s(eoe);sIr=r(OYt,"TFData2VecVisionForImageClassification"),OYt.forEach(t),lIr=r(nWe," (Data2VecVision model)"),nWe.forEach(t),iIr=i(We),Fl=n(We,"LI",{});var EB=s(Fl);rAe=n(EB,"STRONG",{});var VYt=s(rAe);dIr=r(VYt,"deit"),VYt.forEach(t),cIr=r(EB," \u2014 "),ooe=n(EB,"A",{href:!0});var XYt=s(ooe);fIr=r(XYt,"TFDeiTForImageClassification"),XYt.forEach(t),mIr=r(EB," or "),roe=n(EB,"A",{href:!0});var zYt=s(roe);gIr=r(zYt,"TFDeiTForImageClassificationWithTeacher"),zYt.forEach(t),hIr=r(EB," (DeiT model)"),EB.forEach(t),uIr=i(We),e5=n(We,"LI",{});var sWe=s(e5);tAe=n(sWe,"STRONG",{});var QYt=s(tAe);pIr=r(QYt,"mobilevit"),QYt.forEach(t),_Ir=r(sWe," \u2014 "),toe=n(sWe,"A",{href:!0});var WYt=s(toe);vIr=r(WYt,"TFMobileViTForImageClassification"),WYt.forEach(t),bIr=r(sWe," (MobileViT model)"),sWe.forEach(t),FIr=i(We),o5=n(We,"LI",{});var lWe=s(o5);aAe=n(lWe,"STRONG",{});var UYt=s(aAe);TIr=r(UYt,"regnet"),UYt.forEach(t),MIr=r(lWe," \u2014 "),aoe=n(lWe,"A",{href:!0});var HYt=s(aoe);EIr=r(HYt,"TFRegNetForImageClassification"),HYt.forEach(t),CIr=r(lWe," (RegNet model)"),lWe.forEach(t),wIr=i(We),r5=n(We,"LI",{});var iWe=s(r5);nAe=n(iWe,"STRONG",{});var JYt=s(nAe);AIr=r(JYt,"resnet"),JYt.forEach(t),LIr=r(iWe," \u2014 "),noe=n(iWe,"A",{href:!0});var YYt=s(noe);yIr=r(YYt,"TFResNetForImageClassification"),YYt.forEach(t),xIr=r(iWe," (ResNet model)"),iWe.forEach(t),$Ir=i(We),t5=n(We,"LI",{});var dWe=s(t5);sAe=n(dWe,"STRONG",{});var KYt=s(sAe);kIr=r(KYt,"segformer"),KYt.forEach(t),SIr=r(dWe," \u2014 "),soe=n(dWe,"A",{href:!0});var ZYt=s(soe);RIr=r(ZYt,"TFSegformerForImageClassification"),ZYt.forEach(t),PIr=r(dWe," (SegFormer model)"),dWe.forEach(t),BIr=i(We),a5=n(We,"LI",{});var cWe=s(a5);lAe=n(cWe,"STRONG",{});var eKt=s(lAe);IIr=r(eKt,"swin"),eKt.forEach(t),NIr=r(cWe," \u2014 "),loe=n(cWe,"A",{href:!0});var oKt=s(loe);qIr=r(oKt,"TFSwinForImageClassification"),oKt.forEach(t),jIr=r(cWe," (Swin Transformer model)"),cWe.forEach(t),DIr=i(We),n5=n(We,"LI",{});var fWe=s(n5);iAe=n(fWe,"STRONG",{});var rKt=s(iAe);GIr=r(rKt,"vit"),rKt.forEach(t),OIr=r(fWe," \u2014 "),ioe=n(fWe,"A",{href:!0});var tKt=s(ioe);VIr=r(tKt,"TFViTForImageClassification"),tKt.forEach(t),XIr=r(fWe," (ViT model)"),fWe.forEach(t),We.forEach(t),zIr=i(li),T(s5.$$.fragment,li),li.forEach(t),si.forEach(t),JKe=i(f),Zc=n(f,"H2",{class:!0});var moo=s(Zc);l5=n(moo,"A",{id:!0,class:!0,href:!0});var aKt=s(l5);dAe=n(aKt,"SPAN",{});var nKt=s(dAe);T(jk.$$.fragment,nKt),nKt.forEach(t),aKt.forEach(t),QIr=i(moo),cAe=n(moo,"SPAN",{});var sKt=s(cAe);WIr=r(sKt,"TFAutoModelForSemanticSegmentation"),sKt.forEach(t),moo.forEach(t),YKe=i(f),cr=n(f,"DIV",{class:!0});var ii=s(cr);T(Dk.$$.fragment,ii),UIr=i(ii),ef=n(ii,"P",{});var eie=s(ef);HIr=r(eie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),doe=n(eie,"A",{href:!0});var lKt=s(doe);JIr=r(lKt,"from_pretrained()"),lKt.forEach(t),YIr=r(eie," class method or the "),coe=n(eie,"A",{href:!0});var iKt=s(coe);KIr=r(iKt,"from_config()"),iKt.forEach(t),ZIr=r(eie,` class
method.`),eie.forEach(t),eNr=i(ii),Gk=n(ii,"P",{});var goo=s(Gk);oNr=r(goo,"This class cannot be instantiated directly using "),fAe=n(goo,"CODE",{});var dKt=s(fAe);rNr=r(dKt,"__init__()"),dKt.forEach(t),tNr=r(goo," (throws an error)."),goo.forEach(t),aNr=i(ii),Ut=n(ii,"DIV",{class:!0});var w8=s(Ut);T(Ok.$$.fragment,w8),nNr=i(w8),mAe=n(w8,"P",{});var cKt=s(mAe);sNr=r(cKt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),cKt.forEach(t),lNr=i(w8),of=n(w8,"P",{});var oie=s(of);iNr=r(oie,`Note:
Loading a model from its configuration file does `),gAe=n(oie,"STRONG",{});var fKt=s(gAe);dNr=r(fKt,"not"),fKt.forEach(t),cNr=r(oie,` load the model weights. It only affects the
model\u2019s configuration. Use `),foe=n(oie,"A",{href:!0});var mKt=s(foe);fNr=r(mKt,"from_pretrained()"),mKt.forEach(t),mNr=r(oie," to load the model weights."),oie.forEach(t),gNr=i(w8),T(i5.$$.fragment,w8),w8.forEach(t),hNr=i(ii),Dr=n(ii,"DIV",{class:!0});var di=s(Dr);T(Vk.$$.fragment,di),uNr=i(di),hAe=n(di,"P",{});var gKt=s(hAe);pNr=r(gKt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),gKt.forEach(t),_Nr=i(di),yn=n(di,"P",{});var A8=s(yn);vNr=r(A8,"The model class to instantiate is selected based on the "),uAe=n(A8,"CODE",{});var hKt=s(uAe);bNr=r(hKt,"model_type"),hKt.forEach(t),FNr=r(A8,` property of the config object (either
passed as an argument or loaded from `),pAe=n(A8,"CODE",{});var uKt=s(pAe);TNr=r(uKt,"pretrained_model_name_or_path"),uKt.forEach(t),MNr=r(A8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Ae=n(A8,"CODE",{});var pKt=s(_Ae);ENr=r(pKt,"pretrained_model_name_or_path"),pKt.forEach(t),CNr=r(A8,":"),A8.forEach(t),wNr=i(di),rf=n(di,"UL",{});var rie=s(rf);d5=n(rie,"LI",{});var mWe=s(d5);vAe=n(mWe,"STRONG",{});var _Kt=s(vAe);ANr=r(_Kt,"data2vec-vision"),_Kt.forEach(t),LNr=r(mWe," \u2014 "),moe=n(mWe,"A",{href:!0});var vKt=s(moe);yNr=r(vKt,"TFData2VecVisionForSemanticSegmentation"),vKt.forEach(t),xNr=r(mWe," (Data2VecVision model)"),mWe.forEach(t),$Nr=i(rie),c5=n(rie,"LI",{});var gWe=s(c5);bAe=n(gWe,"STRONG",{});var bKt=s(bAe);kNr=r(bKt,"mobilevit"),bKt.forEach(t),SNr=r(gWe," \u2014 "),goe=n(gWe,"A",{href:!0});var FKt=s(goe);RNr=r(FKt,"TFMobileViTForSemanticSegmentation"),FKt.forEach(t),PNr=r(gWe," (MobileViT model)"),gWe.forEach(t),BNr=i(rie),f5=n(rie,"LI",{});var hWe=s(f5);FAe=n(hWe,"STRONG",{});var TKt=s(FAe);INr=r(TKt,"segformer"),TKt.forEach(t),NNr=r(hWe," \u2014 "),hoe=n(hWe,"A",{href:!0});var MKt=s(hoe);qNr=r(MKt,"TFSegformerForSemanticSegmentation"),MKt.forEach(t),jNr=r(hWe," (SegFormer model)"),hWe.forEach(t),rie.forEach(t),DNr=i(di),T(m5.$$.fragment,di),di.forEach(t),ii.forEach(t),KKe=i(f),tf=n(f,"H2",{class:!0});var hoo=s(tf);g5=n(hoo,"A",{id:!0,class:!0,href:!0});var EKt=s(g5);TAe=n(EKt,"SPAN",{});var CKt=s(TAe);T(Xk.$$.fragment,CKt),CKt.forEach(t),EKt.forEach(t),GNr=i(hoo),MAe=n(hoo,"SPAN",{});var wKt=s(MAe);ONr=r(wKt,"TFAutoModelForMaskedLM"),wKt.forEach(t),hoo.forEach(t),ZKe=i(f),fr=n(f,"DIV",{class:!0});var ci=s(fr);T(zk.$$.fragment,ci),VNr=i(ci),af=n(ci,"P",{});var tie=s(af);XNr=r(tie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),uoe=n(tie,"A",{href:!0});var AKt=s(uoe);zNr=r(AKt,"from_pretrained()"),AKt.forEach(t),QNr=r(tie," class method or the "),poe=n(tie,"A",{href:!0});var LKt=s(poe);WNr=r(LKt,"from_config()"),LKt.forEach(t),UNr=r(tie,` class
method.`),tie.forEach(t),HNr=i(ci),Qk=n(ci,"P",{});var uoo=s(Qk);JNr=r(uoo,"This class cannot be instantiated directly using "),EAe=n(uoo,"CODE",{});var yKt=s(EAe);YNr=r(yKt,"__init__()"),yKt.forEach(t),KNr=r(uoo," (throws an error)."),uoo.forEach(t),ZNr=i(ci),Ht=n(ci,"DIV",{class:!0});var L8=s(Ht);T(Wk.$$.fragment,L8),eqr=i(L8),CAe=n(L8,"P",{});var xKt=s(CAe);oqr=r(xKt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),xKt.forEach(t),rqr=i(L8),nf=n(L8,"P",{});var aie=s(nf);tqr=r(aie,`Note:
Loading a model from its configuration file does `),wAe=n(aie,"STRONG",{});var $Kt=s(wAe);aqr=r($Kt,"not"),$Kt.forEach(t),nqr=r(aie,` load the model weights. It only affects the
model\u2019s configuration. Use `),_oe=n(aie,"A",{href:!0});var kKt=s(_oe);sqr=r(kKt,"from_pretrained()"),kKt.forEach(t),lqr=r(aie," to load the model weights."),aie.forEach(t),iqr=i(L8),T(h5.$$.fragment,L8),L8.forEach(t),dqr=i(ci),Gr=n(ci,"DIV",{class:!0});var fi=s(Gr);T(Uk.$$.fragment,fi),cqr=i(fi),AAe=n(fi,"P",{});var SKt=s(AAe);fqr=r(SKt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),SKt.forEach(t),mqr=i(fi),xn=n(fi,"P",{});var y8=s(xn);gqr=r(y8,"The model class to instantiate is selected based on the "),LAe=n(y8,"CODE",{});var RKt=s(LAe);hqr=r(RKt,"model_type"),RKt.forEach(t),uqr=r(y8,` property of the config object (either
passed as an argument or loaded from `),yAe=n(y8,"CODE",{});var PKt=s(yAe);pqr=r(PKt,"pretrained_model_name_or_path"),PKt.forEach(t),_qr=r(y8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xAe=n(y8,"CODE",{});var BKt=s(xAe);vqr=r(BKt,"pretrained_model_name_or_path"),BKt.forEach(t),bqr=r(y8,":"),y8.forEach(t),Fqr=i(fi),me=n(fi,"UL",{});var _e=s(me);u5=n(_e,"LI",{});var uWe=s(u5);$Ae=n(uWe,"STRONG",{});var IKt=s($Ae);Tqr=r(IKt,"albert"),IKt.forEach(t),Mqr=r(uWe," \u2014 "),voe=n(uWe,"A",{href:!0});var NKt=s(voe);Eqr=r(NKt,"TFAlbertForMaskedLM"),NKt.forEach(t),Cqr=r(uWe," (ALBERT model)"),uWe.forEach(t),wqr=i(_e),p5=n(_e,"LI",{});var pWe=s(p5);kAe=n(pWe,"STRONG",{});var qKt=s(kAe);Aqr=r(qKt,"bert"),qKt.forEach(t),Lqr=r(pWe," \u2014 "),boe=n(pWe,"A",{href:!0});var jKt=s(boe);yqr=r(jKt,"TFBertForMaskedLM"),jKt.forEach(t),xqr=r(pWe," (BERT model)"),pWe.forEach(t),$qr=i(_e),_5=n(_e,"LI",{});var _We=s(_5);SAe=n(_We,"STRONG",{});var DKt=s(SAe);kqr=r(DKt,"camembert"),DKt.forEach(t),Sqr=r(_We," \u2014 "),Foe=n(_We,"A",{href:!0});var GKt=s(Foe);Rqr=r(GKt,"TFCamembertForMaskedLM"),GKt.forEach(t),Pqr=r(_We," (CamemBERT model)"),_We.forEach(t),Bqr=i(_e),v5=n(_e,"LI",{});var vWe=s(v5);RAe=n(vWe,"STRONG",{});var OKt=s(RAe);Iqr=r(OKt,"convbert"),OKt.forEach(t),Nqr=r(vWe," \u2014 "),Toe=n(vWe,"A",{href:!0});var VKt=s(Toe);qqr=r(VKt,"TFConvBertForMaskedLM"),VKt.forEach(t),jqr=r(vWe," (ConvBERT model)"),vWe.forEach(t),Dqr=i(_e),b5=n(_e,"LI",{});var bWe=s(b5);PAe=n(bWe,"STRONG",{});var XKt=s(PAe);Gqr=r(XKt,"deberta"),XKt.forEach(t),Oqr=r(bWe," \u2014 "),Moe=n(bWe,"A",{href:!0});var zKt=s(Moe);Vqr=r(zKt,"TFDebertaForMaskedLM"),zKt.forEach(t),Xqr=r(bWe," (DeBERTa model)"),bWe.forEach(t),zqr=i(_e),F5=n(_e,"LI",{});var FWe=s(F5);BAe=n(FWe,"STRONG",{});var QKt=s(BAe);Qqr=r(QKt,"deberta-v2"),QKt.forEach(t),Wqr=r(FWe," \u2014 "),Eoe=n(FWe,"A",{href:!0});var WKt=s(Eoe);Uqr=r(WKt,"TFDebertaV2ForMaskedLM"),WKt.forEach(t),Hqr=r(FWe," (DeBERTa-v2 model)"),FWe.forEach(t),Jqr=i(_e),T5=n(_e,"LI",{});var TWe=s(T5);IAe=n(TWe,"STRONG",{});var UKt=s(IAe);Yqr=r(UKt,"distilbert"),UKt.forEach(t),Kqr=r(TWe," \u2014 "),Coe=n(TWe,"A",{href:!0});var HKt=s(Coe);Zqr=r(HKt,"TFDistilBertForMaskedLM"),HKt.forEach(t),ejr=r(TWe," (DistilBERT model)"),TWe.forEach(t),ojr=i(_e),M5=n(_e,"LI",{});var MWe=s(M5);NAe=n(MWe,"STRONG",{});var JKt=s(NAe);rjr=r(JKt,"electra"),JKt.forEach(t),tjr=r(MWe," \u2014 "),woe=n(MWe,"A",{href:!0});var YKt=s(woe);ajr=r(YKt,"TFElectraForMaskedLM"),YKt.forEach(t),njr=r(MWe," (ELECTRA model)"),MWe.forEach(t),sjr=i(_e),E5=n(_e,"LI",{});var EWe=s(E5);qAe=n(EWe,"STRONG",{});var KKt=s(qAe);ljr=r(KKt,"flaubert"),KKt.forEach(t),ijr=r(EWe," \u2014 "),Aoe=n(EWe,"A",{href:!0});var ZKt=s(Aoe);djr=r(ZKt,"TFFlaubertWithLMHeadModel"),ZKt.forEach(t),cjr=r(EWe," (FlauBERT model)"),EWe.forEach(t),fjr=i(_e),C5=n(_e,"LI",{});var CWe=s(C5);jAe=n(CWe,"STRONG",{});var eZt=s(jAe);mjr=r(eZt,"funnel"),eZt.forEach(t),gjr=r(CWe," \u2014 "),Loe=n(CWe,"A",{href:!0});var oZt=s(Loe);hjr=r(oZt,"TFFunnelForMaskedLM"),oZt.forEach(t),ujr=r(CWe," (Funnel Transformer model)"),CWe.forEach(t),pjr=i(_e),w5=n(_e,"LI",{});var wWe=s(w5);DAe=n(wWe,"STRONG",{});var rZt=s(DAe);_jr=r(rZt,"layoutlm"),rZt.forEach(t),vjr=r(wWe," \u2014 "),yoe=n(wWe,"A",{href:!0});var tZt=s(yoe);bjr=r(tZt,"TFLayoutLMForMaskedLM"),tZt.forEach(t),Fjr=r(wWe," (LayoutLM model)"),wWe.forEach(t),Tjr=i(_e),A5=n(_e,"LI",{});var AWe=s(A5);GAe=n(AWe,"STRONG",{});var aZt=s(GAe);Mjr=r(aZt,"longformer"),aZt.forEach(t),Ejr=r(AWe," \u2014 "),xoe=n(AWe,"A",{href:!0});var nZt=s(xoe);Cjr=r(nZt,"TFLongformerForMaskedLM"),nZt.forEach(t),wjr=r(AWe," (Longformer model)"),AWe.forEach(t),Ajr=i(_e),L5=n(_e,"LI",{});var LWe=s(L5);OAe=n(LWe,"STRONG",{});var sZt=s(OAe);Ljr=r(sZt,"mobilebert"),sZt.forEach(t),yjr=r(LWe," \u2014 "),$oe=n(LWe,"A",{href:!0});var lZt=s($oe);xjr=r(lZt,"TFMobileBertForMaskedLM"),lZt.forEach(t),$jr=r(LWe," (MobileBERT model)"),LWe.forEach(t),kjr=i(_e),y5=n(_e,"LI",{});var yWe=s(y5);VAe=n(yWe,"STRONG",{});var iZt=s(VAe);Sjr=r(iZt,"mpnet"),iZt.forEach(t),Rjr=r(yWe," \u2014 "),koe=n(yWe,"A",{href:!0});var dZt=s(koe);Pjr=r(dZt,"TFMPNetForMaskedLM"),dZt.forEach(t),Bjr=r(yWe," (MPNet model)"),yWe.forEach(t),Ijr=i(_e),x5=n(_e,"LI",{});var xWe=s(x5);XAe=n(xWe,"STRONG",{});var cZt=s(XAe);Njr=r(cZt,"rembert"),cZt.forEach(t),qjr=r(xWe," \u2014 "),Soe=n(xWe,"A",{href:!0});var fZt=s(Soe);jjr=r(fZt,"TFRemBertForMaskedLM"),fZt.forEach(t),Djr=r(xWe," (RemBERT model)"),xWe.forEach(t),Gjr=i(_e),$5=n(_e,"LI",{});var $We=s($5);zAe=n($We,"STRONG",{});var mZt=s(zAe);Ojr=r(mZt,"roberta"),mZt.forEach(t),Vjr=r($We," \u2014 "),Roe=n($We,"A",{href:!0});var gZt=s(Roe);Xjr=r(gZt,"TFRobertaForMaskedLM"),gZt.forEach(t),zjr=r($We," (RoBERTa model)"),$We.forEach(t),Qjr=i(_e),k5=n(_e,"LI",{});var kWe=s(k5);QAe=n(kWe,"STRONG",{});var hZt=s(QAe);Wjr=r(hZt,"roformer"),hZt.forEach(t),Ujr=r(kWe," \u2014 "),Poe=n(kWe,"A",{href:!0});var uZt=s(Poe);Hjr=r(uZt,"TFRoFormerForMaskedLM"),uZt.forEach(t),Jjr=r(kWe," (RoFormer model)"),kWe.forEach(t),Yjr=i(_e),S5=n(_e,"LI",{});var SWe=s(S5);WAe=n(SWe,"STRONG",{});var pZt=s(WAe);Kjr=r(pZt,"tapas"),pZt.forEach(t),Zjr=r(SWe," \u2014 "),Boe=n(SWe,"A",{href:!0});var _Zt=s(Boe);eDr=r(_Zt,"TFTapasForMaskedLM"),_Zt.forEach(t),oDr=r(SWe," (TAPAS model)"),SWe.forEach(t),rDr=i(_e),R5=n(_e,"LI",{});var RWe=s(R5);UAe=n(RWe,"STRONG",{});var vZt=s(UAe);tDr=r(vZt,"xlm"),vZt.forEach(t),aDr=r(RWe," \u2014 "),Ioe=n(RWe,"A",{href:!0});var bZt=s(Ioe);nDr=r(bZt,"TFXLMWithLMHeadModel"),bZt.forEach(t),sDr=r(RWe," (XLM model)"),RWe.forEach(t),lDr=i(_e),P5=n(_e,"LI",{});var PWe=s(P5);HAe=n(PWe,"STRONG",{});var FZt=s(HAe);iDr=r(FZt,"xlm-roberta"),FZt.forEach(t),dDr=r(PWe," \u2014 "),Noe=n(PWe,"A",{href:!0});var TZt=s(Noe);cDr=r(TZt,"TFXLMRobertaForMaskedLM"),TZt.forEach(t),fDr=r(PWe," (XLM-RoBERTa model)"),PWe.forEach(t),_e.forEach(t),mDr=i(fi),T(B5.$$.fragment,fi),fi.forEach(t),ci.forEach(t),eZe=i(f),sf=n(f,"H2",{class:!0});var poo=s(sf);I5=n(poo,"A",{id:!0,class:!0,href:!0});var MZt=s(I5);JAe=n(MZt,"SPAN",{});var EZt=s(JAe);T(Hk.$$.fragment,EZt),EZt.forEach(t),MZt.forEach(t),gDr=i(poo),YAe=n(poo,"SPAN",{});var CZt=s(YAe);hDr=r(CZt,"TFAutoModelForSeq2SeqLM"),CZt.forEach(t),poo.forEach(t),oZe=i(f),mr=n(f,"DIV",{class:!0});var mi=s(mr);T(Jk.$$.fragment,mi),uDr=i(mi),lf=n(mi,"P",{});var nie=s(lf);pDr=r(nie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),qoe=n(nie,"A",{href:!0});var wZt=s(qoe);_Dr=r(wZt,"from_pretrained()"),wZt.forEach(t),vDr=r(nie," class method or the "),joe=n(nie,"A",{href:!0});var AZt=s(joe);bDr=r(AZt,"from_config()"),AZt.forEach(t),FDr=r(nie,` class
method.`),nie.forEach(t),TDr=i(mi),Yk=n(mi,"P",{});var _oo=s(Yk);MDr=r(_oo,"This class cannot be instantiated directly using "),KAe=n(_oo,"CODE",{});var LZt=s(KAe);EDr=r(LZt,"__init__()"),LZt.forEach(t),CDr=r(_oo," (throws an error)."),_oo.forEach(t),wDr=i(mi),Jt=n(mi,"DIV",{class:!0});var x8=s(Jt);T(Kk.$$.fragment,x8),ADr=i(x8),ZAe=n(x8,"P",{});var yZt=s(ZAe);LDr=r(yZt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),yZt.forEach(t),yDr=i(x8),df=n(x8,"P",{});var sie=s(df);xDr=r(sie,`Note:
Loading a model from its configuration file does `),e6e=n(sie,"STRONG",{});var xZt=s(e6e);$Dr=r(xZt,"not"),xZt.forEach(t),kDr=r(sie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Doe=n(sie,"A",{href:!0});var $Zt=s(Doe);SDr=r($Zt,"from_pretrained()"),$Zt.forEach(t),RDr=r(sie," to load the model weights."),sie.forEach(t),PDr=i(x8),T(N5.$$.fragment,x8),x8.forEach(t),BDr=i(mi),Or=n(mi,"DIV",{class:!0});var gi=s(Or);T(Zk.$$.fragment,gi),IDr=i(gi),o6e=n(gi,"P",{});var kZt=s(o6e);NDr=r(kZt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),kZt.forEach(t),qDr=i(gi),$n=n(gi,"P",{});var $8=s($n);jDr=r($8,"The model class to instantiate is selected based on the "),r6e=n($8,"CODE",{});var SZt=s(r6e);DDr=r(SZt,"model_type"),SZt.forEach(t),GDr=r($8,` property of the config object (either
passed as an argument or loaded from `),t6e=n($8,"CODE",{});var RZt=s(t6e);ODr=r(RZt,"pretrained_model_name_or_path"),RZt.forEach(t),VDr=r($8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a6e=n($8,"CODE",{});var PZt=s(a6e);XDr=r(PZt,"pretrained_model_name_or_path"),PZt.forEach(t),zDr=r($8,":"),$8.forEach(t),QDr=i(gi),ye=n(gi,"UL",{});var Ne=s(ye);q5=n(Ne,"LI",{});var BWe=s(q5);n6e=n(BWe,"STRONG",{});var BZt=s(n6e);WDr=r(BZt,"bart"),BZt.forEach(t),UDr=r(BWe," \u2014 "),Goe=n(BWe,"A",{href:!0});var IZt=s(Goe);HDr=r(IZt,"TFBartForConditionalGeneration"),IZt.forEach(t),JDr=r(BWe," (BART model)"),BWe.forEach(t),YDr=i(Ne),j5=n(Ne,"LI",{});var IWe=s(j5);s6e=n(IWe,"STRONG",{});var NZt=s(s6e);KDr=r(NZt,"blenderbot"),NZt.forEach(t),ZDr=r(IWe," \u2014 "),Ooe=n(IWe,"A",{href:!0});var qZt=s(Ooe);eGr=r(qZt,"TFBlenderbotForConditionalGeneration"),qZt.forEach(t),oGr=r(IWe," (Blenderbot model)"),IWe.forEach(t),rGr=i(Ne),D5=n(Ne,"LI",{});var NWe=s(D5);l6e=n(NWe,"STRONG",{});var jZt=s(l6e);tGr=r(jZt,"blenderbot-small"),jZt.forEach(t),aGr=r(NWe," \u2014 "),Voe=n(NWe,"A",{href:!0});var DZt=s(Voe);nGr=r(DZt,"TFBlenderbotSmallForConditionalGeneration"),DZt.forEach(t),sGr=r(NWe," (BlenderbotSmall model)"),NWe.forEach(t),lGr=i(Ne),G5=n(Ne,"LI",{});var qWe=s(G5);i6e=n(qWe,"STRONG",{});var GZt=s(i6e);iGr=r(GZt,"encoder-decoder"),GZt.forEach(t),dGr=r(qWe," \u2014 "),Xoe=n(qWe,"A",{href:!0});var OZt=s(Xoe);cGr=r(OZt,"TFEncoderDecoderModel"),OZt.forEach(t),fGr=r(qWe," (Encoder decoder model)"),qWe.forEach(t),mGr=i(Ne),O5=n(Ne,"LI",{});var jWe=s(O5);d6e=n(jWe,"STRONG",{});var VZt=s(d6e);gGr=r(VZt,"led"),VZt.forEach(t),hGr=r(jWe," \u2014 "),zoe=n(jWe,"A",{href:!0});var XZt=s(zoe);uGr=r(XZt,"TFLEDForConditionalGeneration"),XZt.forEach(t),pGr=r(jWe," (LED model)"),jWe.forEach(t),_Gr=i(Ne),V5=n(Ne,"LI",{});var DWe=s(V5);c6e=n(DWe,"STRONG",{});var zZt=s(c6e);vGr=r(zZt,"marian"),zZt.forEach(t),bGr=r(DWe," \u2014 "),Qoe=n(DWe,"A",{href:!0});var QZt=s(Qoe);FGr=r(QZt,"TFMarianMTModel"),QZt.forEach(t),TGr=r(DWe," (Marian model)"),DWe.forEach(t),MGr=i(Ne),X5=n(Ne,"LI",{});var GWe=s(X5);f6e=n(GWe,"STRONG",{});var WZt=s(f6e);EGr=r(WZt,"mbart"),WZt.forEach(t),CGr=r(GWe," \u2014 "),Woe=n(GWe,"A",{href:!0});var UZt=s(Woe);wGr=r(UZt,"TFMBartForConditionalGeneration"),UZt.forEach(t),AGr=r(GWe," (mBART model)"),GWe.forEach(t),LGr=i(Ne),z5=n(Ne,"LI",{});var OWe=s(z5);m6e=n(OWe,"STRONG",{});var HZt=s(m6e);yGr=r(HZt,"mt5"),HZt.forEach(t),xGr=r(OWe," \u2014 "),Uoe=n(OWe,"A",{href:!0});var JZt=s(Uoe);$Gr=r(JZt,"TFMT5ForConditionalGeneration"),JZt.forEach(t),kGr=r(OWe," (MT5 model)"),OWe.forEach(t),SGr=i(Ne),Q5=n(Ne,"LI",{});var VWe=s(Q5);g6e=n(VWe,"STRONG",{});var YZt=s(g6e);RGr=r(YZt,"pegasus"),YZt.forEach(t),PGr=r(VWe," \u2014 "),Hoe=n(VWe,"A",{href:!0});var KZt=s(Hoe);BGr=r(KZt,"TFPegasusForConditionalGeneration"),KZt.forEach(t),IGr=r(VWe," (Pegasus model)"),VWe.forEach(t),NGr=i(Ne),W5=n(Ne,"LI",{});var XWe=s(W5);h6e=n(XWe,"STRONG",{});var ZZt=s(h6e);qGr=r(ZZt,"t5"),ZZt.forEach(t),jGr=r(XWe," \u2014 "),Joe=n(XWe,"A",{href:!0});var eea=s(Joe);DGr=r(eea,"TFT5ForConditionalGeneration"),eea.forEach(t),GGr=r(XWe," (T5 model)"),XWe.forEach(t),Ne.forEach(t),OGr=i(gi),T(U5.$$.fragment,gi),gi.forEach(t),mi.forEach(t),rZe=i(f),cf=n(f,"H2",{class:!0});var voo=s(cf);H5=n(voo,"A",{id:!0,class:!0,href:!0});var oea=s(H5);u6e=n(oea,"SPAN",{});var rea=s(u6e);T(eS.$$.fragment,rea),rea.forEach(t),oea.forEach(t),VGr=i(voo),p6e=n(voo,"SPAN",{});var tea=s(p6e);XGr=r(tea,"TFAutoModelForSequenceClassification"),tea.forEach(t),voo.forEach(t),tZe=i(f),gr=n(f,"DIV",{class:!0});var hi=s(gr);T(oS.$$.fragment,hi),zGr=i(hi),ff=n(hi,"P",{});var lie=s(ff);QGr=r(lie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Yoe=n(lie,"A",{href:!0});var aea=s(Yoe);WGr=r(aea,"from_pretrained()"),aea.forEach(t),UGr=r(lie," class method or the "),Koe=n(lie,"A",{href:!0});var nea=s(Koe);HGr=r(nea,"from_config()"),nea.forEach(t),JGr=r(lie,` class
method.`),lie.forEach(t),YGr=i(hi),rS=n(hi,"P",{});var boo=s(rS);KGr=r(boo,"This class cannot be instantiated directly using "),_6e=n(boo,"CODE",{});var sea=s(_6e);ZGr=r(sea,"__init__()"),sea.forEach(t),eOr=r(boo," (throws an error)."),boo.forEach(t),oOr=i(hi),Yt=n(hi,"DIV",{class:!0});var k8=s(Yt);T(tS.$$.fragment,k8),rOr=i(k8),v6e=n(k8,"P",{});var lea=s(v6e);tOr=r(lea,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),lea.forEach(t),aOr=i(k8),mf=n(k8,"P",{});var iie=s(mf);nOr=r(iie,`Note:
Loading a model from its configuration file does `),b6e=n(iie,"STRONG",{});var iea=s(b6e);sOr=r(iea,"not"),iea.forEach(t),lOr=r(iie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zoe=n(iie,"A",{href:!0});var dea=s(Zoe);iOr=r(dea,"from_pretrained()"),dea.forEach(t),dOr=r(iie," to load the model weights."),iie.forEach(t),cOr=i(k8),T(J5.$$.fragment,k8),k8.forEach(t),fOr=i(hi),Vr=n(hi,"DIV",{class:!0});var ui=s(Vr);T(aS.$$.fragment,ui),mOr=i(ui),F6e=n(ui,"P",{});var cea=s(F6e);gOr=r(cea,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),cea.forEach(t),hOr=i(ui),kn=n(ui,"P",{});var S8=s(kn);uOr=r(S8,"The model class to instantiate is selected based on the "),T6e=n(S8,"CODE",{});var fea=s(T6e);pOr=r(fea,"model_type"),fea.forEach(t),_Or=r(S8,` property of the config object (either
passed as an argument or loaded from `),M6e=n(S8,"CODE",{});var mea=s(M6e);vOr=r(mea,"pretrained_model_name_or_path"),mea.forEach(t),bOr=r(S8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E6e=n(S8,"CODE",{});var gea=s(E6e);FOr=r(gea,"pretrained_model_name_or_path"),gea.forEach(t),TOr=r(S8,":"),S8.forEach(t),MOr=i(ui),re=n(ui,"UL",{});var ae=s(re);Y5=n(ae,"LI",{});var zWe=s(Y5);C6e=n(zWe,"STRONG",{});var hea=s(C6e);EOr=r(hea,"albert"),hea.forEach(t),COr=r(zWe," \u2014 "),ere=n(zWe,"A",{href:!0});var uea=s(ere);wOr=r(uea,"TFAlbertForSequenceClassification"),uea.forEach(t),AOr=r(zWe," (ALBERT model)"),zWe.forEach(t),LOr=i(ae),K5=n(ae,"LI",{});var QWe=s(K5);w6e=n(QWe,"STRONG",{});var pea=s(w6e);yOr=r(pea,"bert"),pea.forEach(t),xOr=r(QWe," \u2014 "),ore=n(QWe,"A",{href:!0});var _ea=s(ore);$Or=r(_ea,"TFBertForSequenceClassification"),_ea.forEach(t),kOr=r(QWe," (BERT model)"),QWe.forEach(t),SOr=i(ae),Z5=n(ae,"LI",{});var WWe=s(Z5);A6e=n(WWe,"STRONG",{});var vea=s(A6e);ROr=r(vea,"camembert"),vea.forEach(t),POr=r(WWe," \u2014 "),rre=n(WWe,"A",{href:!0});var bea=s(rre);BOr=r(bea,"TFCamembertForSequenceClassification"),bea.forEach(t),IOr=r(WWe," (CamemBERT model)"),WWe.forEach(t),NOr=i(ae),ew=n(ae,"LI",{});var UWe=s(ew);L6e=n(UWe,"STRONG",{});var Fea=s(L6e);qOr=r(Fea,"convbert"),Fea.forEach(t),jOr=r(UWe," \u2014 "),tre=n(UWe,"A",{href:!0});var Tea=s(tre);DOr=r(Tea,"TFConvBertForSequenceClassification"),Tea.forEach(t),GOr=r(UWe," (ConvBERT model)"),UWe.forEach(t),OOr=i(ae),ow=n(ae,"LI",{});var HWe=s(ow);y6e=n(HWe,"STRONG",{});var Mea=s(y6e);VOr=r(Mea,"ctrl"),Mea.forEach(t),XOr=r(HWe," \u2014 "),are=n(HWe,"A",{href:!0});var Eea=s(are);zOr=r(Eea,"TFCTRLForSequenceClassification"),Eea.forEach(t),QOr=r(HWe," (CTRL model)"),HWe.forEach(t),WOr=i(ae),rw=n(ae,"LI",{});var JWe=s(rw);x6e=n(JWe,"STRONG",{});var Cea=s(x6e);UOr=r(Cea,"deberta"),Cea.forEach(t),HOr=r(JWe," \u2014 "),nre=n(JWe,"A",{href:!0});var wea=s(nre);JOr=r(wea,"TFDebertaForSequenceClassification"),wea.forEach(t),YOr=r(JWe," (DeBERTa model)"),JWe.forEach(t),KOr=i(ae),tw=n(ae,"LI",{});var YWe=s(tw);$6e=n(YWe,"STRONG",{});var Aea=s($6e);ZOr=r(Aea,"deberta-v2"),Aea.forEach(t),eVr=r(YWe," \u2014 "),sre=n(YWe,"A",{href:!0});var Lea=s(sre);oVr=r(Lea,"TFDebertaV2ForSequenceClassification"),Lea.forEach(t),rVr=r(YWe," (DeBERTa-v2 model)"),YWe.forEach(t),tVr=i(ae),aw=n(ae,"LI",{});var KWe=s(aw);k6e=n(KWe,"STRONG",{});var yea=s(k6e);aVr=r(yea,"distilbert"),yea.forEach(t),nVr=r(KWe," \u2014 "),lre=n(KWe,"A",{href:!0});var xea=s(lre);sVr=r(xea,"TFDistilBertForSequenceClassification"),xea.forEach(t),lVr=r(KWe," (DistilBERT model)"),KWe.forEach(t),iVr=i(ae),nw=n(ae,"LI",{});var ZWe=s(nw);S6e=n(ZWe,"STRONG",{});var $ea=s(S6e);dVr=r($ea,"electra"),$ea.forEach(t),cVr=r(ZWe," \u2014 "),ire=n(ZWe,"A",{href:!0});var kea=s(ire);fVr=r(kea,"TFElectraForSequenceClassification"),kea.forEach(t),mVr=r(ZWe," (ELECTRA model)"),ZWe.forEach(t),gVr=i(ae),sw=n(ae,"LI",{});var eUe=s(sw);R6e=n(eUe,"STRONG",{});var Sea=s(R6e);hVr=r(Sea,"flaubert"),Sea.forEach(t),uVr=r(eUe," \u2014 "),dre=n(eUe,"A",{href:!0});var Rea=s(dre);pVr=r(Rea,"TFFlaubertForSequenceClassification"),Rea.forEach(t),_Vr=r(eUe," (FlauBERT model)"),eUe.forEach(t),vVr=i(ae),lw=n(ae,"LI",{});var oUe=s(lw);P6e=n(oUe,"STRONG",{});var Pea=s(P6e);bVr=r(Pea,"funnel"),Pea.forEach(t),FVr=r(oUe," \u2014 "),cre=n(oUe,"A",{href:!0});var Bea=s(cre);TVr=r(Bea,"TFFunnelForSequenceClassification"),Bea.forEach(t),MVr=r(oUe," (Funnel Transformer model)"),oUe.forEach(t),EVr=i(ae),iw=n(ae,"LI",{});var rUe=s(iw);B6e=n(rUe,"STRONG",{});var Iea=s(B6e);CVr=r(Iea,"gpt2"),Iea.forEach(t),wVr=r(rUe," \u2014 "),fre=n(rUe,"A",{href:!0});var Nea=s(fre);AVr=r(Nea,"TFGPT2ForSequenceClassification"),Nea.forEach(t),LVr=r(rUe," (OpenAI GPT-2 model)"),rUe.forEach(t),yVr=i(ae),dw=n(ae,"LI",{});var tUe=s(dw);I6e=n(tUe,"STRONG",{});var qea=s(I6e);xVr=r(qea,"gptj"),qea.forEach(t),$Vr=r(tUe," \u2014 "),mre=n(tUe,"A",{href:!0});var jea=s(mre);kVr=r(jea,"TFGPTJForSequenceClassification"),jea.forEach(t),SVr=r(tUe," (GPT-J model)"),tUe.forEach(t),RVr=i(ae),cw=n(ae,"LI",{});var aUe=s(cw);N6e=n(aUe,"STRONG",{});var Dea=s(N6e);PVr=r(Dea,"layoutlm"),Dea.forEach(t),BVr=r(aUe," \u2014 "),gre=n(aUe,"A",{href:!0});var Gea=s(gre);IVr=r(Gea,"TFLayoutLMForSequenceClassification"),Gea.forEach(t),NVr=r(aUe," (LayoutLM model)"),aUe.forEach(t),qVr=i(ae),fw=n(ae,"LI",{});var nUe=s(fw);q6e=n(nUe,"STRONG",{});var Oea=s(q6e);jVr=r(Oea,"layoutlmv3"),Oea.forEach(t),DVr=r(nUe," \u2014 "),hre=n(nUe,"A",{href:!0});var Vea=s(hre);GVr=r(Vea,"TFLayoutLMv3ForSequenceClassification"),Vea.forEach(t),OVr=r(nUe," (LayoutLMv3 model)"),nUe.forEach(t),VVr=i(ae),mw=n(ae,"LI",{});var sUe=s(mw);j6e=n(sUe,"STRONG",{});var Xea=s(j6e);XVr=r(Xea,"longformer"),Xea.forEach(t),zVr=r(sUe," \u2014 "),ure=n(sUe,"A",{href:!0});var zea=s(ure);QVr=r(zea,"TFLongformerForSequenceClassification"),zea.forEach(t),WVr=r(sUe," (Longformer model)"),sUe.forEach(t),UVr=i(ae),gw=n(ae,"LI",{});var lUe=s(gw);D6e=n(lUe,"STRONG",{});var Qea=s(D6e);HVr=r(Qea,"mobilebert"),Qea.forEach(t),JVr=r(lUe," \u2014 "),pre=n(lUe,"A",{href:!0});var Wea=s(pre);YVr=r(Wea,"TFMobileBertForSequenceClassification"),Wea.forEach(t),KVr=r(lUe," (MobileBERT model)"),lUe.forEach(t),ZVr=i(ae),hw=n(ae,"LI",{});var iUe=s(hw);G6e=n(iUe,"STRONG",{});var Uea=s(G6e);eXr=r(Uea,"mpnet"),Uea.forEach(t),oXr=r(iUe," \u2014 "),_re=n(iUe,"A",{href:!0});var Hea=s(_re);rXr=r(Hea,"TFMPNetForSequenceClassification"),Hea.forEach(t),tXr=r(iUe," (MPNet model)"),iUe.forEach(t),aXr=i(ae),uw=n(ae,"LI",{});var dUe=s(uw);O6e=n(dUe,"STRONG",{});var Jea=s(O6e);nXr=r(Jea,"openai-gpt"),Jea.forEach(t),sXr=r(dUe," \u2014 "),vre=n(dUe,"A",{href:!0});var Yea=s(vre);lXr=r(Yea,"TFOpenAIGPTForSequenceClassification"),Yea.forEach(t),iXr=r(dUe," (OpenAI GPT model)"),dUe.forEach(t),dXr=i(ae),pw=n(ae,"LI",{});var cUe=s(pw);V6e=n(cUe,"STRONG",{});var Kea=s(V6e);cXr=r(Kea,"rembert"),Kea.forEach(t),fXr=r(cUe," \u2014 "),bre=n(cUe,"A",{href:!0});var Zea=s(bre);mXr=r(Zea,"TFRemBertForSequenceClassification"),Zea.forEach(t),gXr=r(cUe," (RemBERT model)"),cUe.forEach(t),hXr=i(ae),_w=n(ae,"LI",{});var fUe=s(_w);X6e=n(fUe,"STRONG",{});var eoa=s(X6e);uXr=r(eoa,"roberta"),eoa.forEach(t),pXr=r(fUe," \u2014 "),Fre=n(fUe,"A",{href:!0});var ooa=s(Fre);_Xr=r(ooa,"TFRobertaForSequenceClassification"),ooa.forEach(t),vXr=r(fUe," (RoBERTa model)"),fUe.forEach(t),bXr=i(ae),vw=n(ae,"LI",{});var mUe=s(vw);z6e=n(mUe,"STRONG",{});var roa=s(z6e);FXr=r(roa,"roformer"),roa.forEach(t),TXr=r(mUe," \u2014 "),Tre=n(mUe,"A",{href:!0});var toa=s(Tre);MXr=r(toa,"TFRoFormerForSequenceClassification"),toa.forEach(t),EXr=r(mUe," (RoFormer model)"),mUe.forEach(t),CXr=i(ae),bw=n(ae,"LI",{});var gUe=s(bw);Q6e=n(gUe,"STRONG",{});var aoa=s(Q6e);wXr=r(aoa,"tapas"),aoa.forEach(t),AXr=r(gUe," \u2014 "),Mre=n(gUe,"A",{href:!0});var noa=s(Mre);LXr=r(noa,"TFTapasForSequenceClassification"),noa.forEach(t),yXr=r(gUe," (TAPAS model)"),gUe.forEach(t),xXr=i(ae),Fw=n(ae,"LI",{});var hUe=s(Fw);W6e=n(hUe,"STRONG",{});var soa=s(W6e);$Xr=r(soa,"transfo-xl"),soa.forEach(t),kXr=r(hUe," \u2014 "),Ere=n(hUe,"A",{href:!0});var loa=s(Ere);SXr=r(loa,"TFTransfoXLForSequenceClassification"),loa.forEach(t),RXr=r(hUe," (Transformer-XL model)"),hUe.forEach(t),PXr=i(ae),Tw=n(ae,"LI",{});var uUe=s(Tw);U6e=n(uUe,"STRONG",{});var ioa=s(U6e);BXr=r(ioa,"xlm"),ioa.forEach(t),IXr=r(uUe," \u2014 "),Cre=n(uUe,"A",{href:!0});var doa=s(Cre);NXr=r(doa,"TFXLMForSequenceClassification"),doa.forEach(t),qXr=r(uUe," (XLM model)"),uUe.forEach(t),jXr=i(ae),Mw=n(ae,"LI",{});var pUe=s(Mw);H6e=n(pUe,"STRONG",{});var coa=s(H6e);DXr=r(coa,"xlm-roberta"),coa.forEach(t),GXr=r(pUe," \u2014 "),wre=n(pUe,"A",{href:!0});var foa=s(wre);OXr=r(foa,"TFXLMRobertaForSequenceClassification"),foa.forEach(t),VXr=r(pUe," (XLM-RoBERTa model)"),pUe.forEach(t),XXr=i(ae),Ew=n(ae,"LI",{});var _Ue=s(Ew);J6e=n(_Ue,"STRONG",{});var moa=s(J6e);zXr=r(moa,"xlnet"),moa.forEach(t),QXr=r(_Ue," \u2014 "),Are=n(_Ue,"A",{href:!0});var goa=s(Are);WXr=r(goa,"TFXLNetForSequenceClassification"),goa.forEach(t),UXr=r(_Ue," (XLNet model)"),_Ue.forEach(t),ae.forEach(t),HXr=i(ui),T(Cw.$$.fragment,ui),ui.forEach(t),hi.forEach(t),aZe=i(f),gf=n(f,"H2",{class:!0});var Foo=s(gf);ww=n(Foo,"A",{id:!0,class:!0,href:!0});var hoa=s(ww);Y6e=n(hoa,"SPAN",{});var uoa=s(Y6e);T(nS.$$.fragment,uoa),uoa.forEach(t),hoa.forEach(t),JXr=i(Foo),K6e=n(Foo,"SPAN",{});var poa=s(K6e);YXr=r(poa,"TFAutoModelForMultipleChoice"),poa.forEach(t),Foo.forEach(t),nZe=i(f),hr=n(f,"DIV",{class:!0});var pi=s(hr);T(sS.$$.fragment,pi),KXr=i(pi),hf=n(pi,"P",{});var die=s(hf);ZXr=r(die,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Lre=n(die,"A",{href:!0});var _oa=s(Lre);ezr=r(_oa,"from_pretrained()"),_oa.forEach(t),ozr=r(die," class method or the "),yre=n(die,"A",{href:!0});var voa=s(yre);rzr=r(voa,"from_config()"),voa.forEach(t),tzr=r(die,` class
method.`),die.forEach(t),azr=i(pi),lS=n(pi,"P",{});var Too=s(lS);nzr=r(Too,"This class cannot be instantiated directly using "),Z6e=n(Too,"CODE",{});var boa=s(Z6e);szr=r(boa,"__init__()"),boa.forEach(t),lzr=r(Too," (throws an error)."),Too.forEach(t),izr=i(pi),Kt=n(pi,"DIV",{class:!0});var R8=s(Kt);T(iS.$$.fragment,R8),dzr=i(R8),e7e=n(R8,"P",{});var Foa=s(e7e);czr=r(Foa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Foa.forEach(t),fzr=i(R8),uf=n(R8,"P",{});var cie=s(uf);mzr=r(cie,`Note:
Loading a model from its configuration file does `),o7e=n(cie,"STRONG",{});var Toa=s(o7e);gzr=r(Toa,"not"),Toa.forEach(t),hzr=r(cie,` load the model weights. It only affects the
model\u2019s configuration. Use `),xre=n(cie,"A",{href:!0});var Moa=s(xre);uzr=r(Moa,"from_pretrained()"),Moa.forEach(t),pzr=r(cie," to load the model weights."),cie.forEach(t),_zr=i(R8),T(Aw.$$.fragment,R8),R8.forEach(t),vzr=i(pi),Xr=n(pi,"DIV",{class:!0});var _i=s(Xr);T(dS.$$.fragment,_i),bzr=i(_i),r7e=n(_i,"P",{});var Eoa=s(r7e);Fzr=r(Eoa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Eoa.forEach(t),Tzr=i(_i),Sn=n(_i,"P",{});var P8=s(Sn);Mzr=r(P8,"The model class to instantiate is selected based on the "),t7e=n(P8,"CODE",{});var Coa=s(t7e);Ezr=r(Coa,"model_type"),Coa.forEach(t),Czr=r(P8,` property of the config object (either
passed as an argument or loaded from `),a7e=n(P8,"CODE",{});var woa=s(a7e);wzr=r(woa,"pretrained_model_name_or_path"),woa.forEach(t),Azr=r(P8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n7e=n(P8,"CODE",{});var Aoa=s(n7e);Lzr=r(Aoa,"pretrained_model_name_or_path"),Aoa.forEach(t),yzr=r(P8,":"),P8.forEach(t),xzr=i(_i),be=n(_i,"UL",{});var Te=s(be);Lw=n(Te,"LI",{});var vUe=s(Lw);s7e=n(vUe,"STRONG",{});var Loa=s(s7e);$zr=r(Loa,"albert"),Loa.forEach(t),kzr=r(vUe," \u2014 "),$re=n(vUe,"A",{href:!0});var yoa=s($re);Szr=r(yoa,"TFAlbertForMultipleChoice"),yoa.forEach(t),Rzr=r(vUe," (ALBERT model)"),vUe.forEach(t),Pzr=i(Te),yw=n(Te,"LI",{});var bUe=s(yw);l7e=n(bUe,"STRONG",{});var xoa=s(l7e);Bzr=r(xoa,"bert"),xoa.forEach(t),Izr=r(bUe," \u2014 "),kre=n(bUe,"A",{href:!0});var $oa=s(kre);Nzr=r($oa,"TFBertForMultipleChoice"),$oa.forEach(t),qzr=r(bUe," (BERT model)"),bUe.forEach(t),jzr=i(Te),xw=n(Te,"LI",{});var FUe=s(xw);i7e=n(FUe,"STRONG",{});var koa=s(i7e);Dzr=r(koa,"camembert"),koa.forEach(t),Gzr=r(FUe," \u2014 "),Sre=n(FUe,"A",{href:!0});var Soa=s(Sre);Ozr=r(Soa,"TFCamembertForMultipleChoice"),Soa.forEach(t),Vzr=r(FUe," (CamemBERT model)"),FUe.forEach(t),Xzr=i(Te),$w=n(Te,"LI",{});var TUe=s($w);d7e=n(TUe,"STRONG",{});var Roa=s(d7e);zzr=r(Roa,"convbert"),Roa.forEach(t),Qzr=r(TUe," \u2014 "),Rre=n(TUe,"A",{href:!0});var Poa=s(Rre);Wzr=r(Poa,"TFConvBertForMultipleChoice"),Poa.forEach(t),Uzr=r(TUe," (ConvBERT model)"),TUe.forEach(t),Hzr=i(Te),kw=n(Te,"LI",{});var MUe=s(kw);c7e=n(MUe,"STRONG",{});var Boa=s(c7e);Jzr=r(Boa,"distilbert"),Boa.forEach(t),Yzr=r(MUe," \u2014 "),Pre=n(MUe,"A",{href:!0});var Ioa=s(Pre);Kzr=r(Ioa,"TFDistilBertForMultipleChoice"),Ioa.forEach(t),Zzr=r(MUe," (DistilBERT model)"),MUe.forEach(t),eQr=i(Te),Sw=n(Te,"LI",{});var EUe=s(Sw);f7e=n(EUe,"STRONG",{});var Noa=s(f7e);oQr=r(Noa,"electra"),Noa.forEach(t),rQr=r(EUe," \u2014 "),Bre=n(EUe,"A",{href:!0});var qoa=s(Bre);tQr=r(qoa,"TFElectraForMultipleChoice"),qoa.forEach(t),aQr=r(EUe," (ELECTRA model)"),EUe.forEach(t),nQr=i(Te),Rw=n(Te,"LI",{});var CUe=s(Rw);m7e=n(CUe,"STRONG",{});var joa=s(m7e);sQr=r(joa,"flaubert"),joa.forEach(t),lQr=r(CUe," \u2014 "),Ire=n(CUe,"A",{href:!0});var Doa=s(Ire);iQr=r(Doa,"TFFlaubertForMultipleChoice"),Doa.forEach(t),dQr=r(CUe," (FlauBERT model)"),CUe.forEach(t),cQr=i(Te),Pw=n(Te,"LI",{});var wUe=s(Pw);g7e=n(wUe,"STRONG",{});var Goa=s(g7e);fQr=r(Goa,"funnel"),Goa.forEach(t),mQr=r(wUe," \u2014 "),Nre=n(wUe,"A",{href:!0});var Ooa=s(Nre);gQr=r(Ooa,"TFFunnelForMultipleChoice"),Ooa.forEach(t),hQr=r(wUe," (Funnel Transformer model)"),wUe.forEach(t),uQr=i(Te),Bw=n(Te,"LI",{});var AUe=s(Bw);h7e=n(AUe,"STRONG",{});var Voa=s(h7e);pQr=r(Voa,"longformer"),Voa.forEach(t),_Qr=r(AUe," \u2014 "),qre=n(AUe,"A",{href:!0});var Xoa=s(qre);vQr=r(Xoa,"TFLongformerForMultipleChoice"),Xoa.forEach(t),bQr=r(AUe," (Longformer model)"),AUe.forEach(t),FQr=i(Te),Iw=n(Te,"LI",{});var LUe=s(Iw);u7e=n(LUe,"STRONG",{});var zoa=s(u7e);TQr=r(zoa,"mobilebert"),zoa.forEach(t),MQr=r(LUe," \u2014 "),jre=n(LUe,"A",{href:!0});var Qoa=s(jre);EQr=r(Qoa,"TFMobileBertForMultipleChoice"),Qoa.forEach(t),CQr=r(LUe," (MobileBERT model)"),LUe.forEach(t),wQr=i(Te),Nw=n(Te,"LI",{});var yUe=s(Nw);p7e=n(yUe,"STRONG",{});var Woa=s(p7e);AQr=r(Woa,"mpnet"),Woa.forEach(t),LQr=r(yUe," \u2014 "),Dre=n(yUe,"A",{href:!0});var Uoa=s(Dre);yQr=r(Uoa,"TFMPNetForMultipleChoice"),Uoa.forEach(t),xQr=r(yUe," (MPNet model)"),yUe.forEach(t),$Qr=i(Te),qw=n(Te,"LI",{});var xUe=s(qw);_7e=n(xUe,"STRONG",{});var Hoa=s(_7e);kQr=r(Hoa,"rembert"),Hoa.forEach(t),SQr=r(xUe," \u2014 "),Gre=n(xUe,"A",{href:!0});var Joa=s(Gre);RQr=r(Joa,"TFRemBertForMultipleChoice"),Joa.forEach(t),PQr=r(xUe," (RemBERT model)"),xUe.forEach(t),BQr=i(Te),jw=n(Te,"LI",{});var $Ue=s(jw);v7e=n($Ue,"STRONG",{});var Yoa=s(v7e);IQr=r(Yoa,"roberta"),Yoa.forEach(t),NQr=r($Ue," \u2014 "),Ore=n($Ue,"A",{href:!0});var Koa=s(Ore);qQr=r(Koa,"TFRobertaForMultipleChoice"),Koa.forEach(t),jQr=r($Ue," (RoBERTa model)"),$Ue.forEach(t),DQr=i(Te),Dw=n(Te,"LI",{});var kUe=s(Dw);b7e=n(kUe,"STRONG",{});var Zoa=s(b7e);GQr=r(Zoa,"roformer"),Zoa.forEach(t),OQr=r(kUe," \u2014 "),Vre=n(kUe,"A",{href:!0});var era=s(Vre);VQr=r(era,"TFRoFormerForMultipleChoice"),era.forEach(t),XQr=r(kUe," (RoFormer model)"),kUe.forEach(t),zQr=i(Te),Gw=n(Te,"LI",{});var SUe=s(Gw);F7e=n(SUe,"STRONG",{});var ora=s(F7e);QQr=r(ora,"xlm"),ora.forEach(t),WQr=r(SUe," \u2014 "),Xre=n(SUe,"A",{href:!0});var rra=s(Xre);UQr=r(rra,"TFXLMForMultipleChoice"),rra.forEach(t),HQr=r(SUe," (XLM model)"),SUe.forEach(t),JQr=i(Te),Ow=n(Te,"LI",{});var RUe=s(Ow);T7e=n(RUe,"STRONG",{});var tra=s(T7e);YQr=r(tra,"xlm-roberta"),tra.forEach(t),KQr=r(RUe," \u2014 "),zre=n(RUe,"A",{href:!0});var ara=s(zre);ZQr=r(ara,"TFXLMRobertaForMultipleChoice"),ara.forEach(t),eWr=r(RUe," (XLM-RoBERTa model)"),RUe.forEach(t),oWr=i(Te),Vw=n(Te,"LI",{});var PUe=s(Vw);M7e=n(PUe,"STRONG",{});var nra=s(M7e);rWr=r(nra,"xlnet"),nra.forEach(t),tWr=r(PUe," \u2014 "),Qre=n(PUe,"A",{href:!0});var sra=s(Qre);aWr=r(sra,"TFXLNetForMultipleChoice"),sra.forEach(t),nWr=r(PUe," (XLNet model)"),PUe.forEach(t),Te.forEach(t),sWr=i(_i),T(Xw.$$.fragment,_i),_i.forEach(t),pi.forEach(t),sZe=i(f),pf=n(f,"H2",{class:!0});var Moo=s(pf);zw=n(Moo,"A",{id:!0,class:!0,href:!0});var lra=s(zw);E7e=n(lra,"SPAN",{});var ira=s(E7e);T(cS.$$.fragment,ira),ira.forEach(t),lra.forEach(t),lWr=i(Moo),C7e=n(Moo,"SPAN",{});var dra=s(C7e);iWr=r(dra,"TFAutoModelForNextSentencePrediction"),dra.forEach(t),Moo.forEach(t),lZe=i(f),ur=n(f,"DIV",{class:!0});var vi=s(ur);T(fS.$$.fragment,vi),dWr=i(vi),_f=n(vi,"P",{});var fie=s(_f);cWr=r(fie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Wre=n(fie,"A",{href:!0});var cra=s(Wre);fWr=r(cra,"from_pretrained()"),cra.forEach(t),mWr=r(fie," class method or the "),Ure=n(fie,"A",{href:!0});var fra=s(Ure);gWr=r(fra,"from_config()"),fra.forEach(t),hWr=r(fie,` class
method.`),fie.forEach(t),uWr=i(vi),mS=n(vi,"P",{});var Eoo=s(mS);pWr=r(Eoo,"This class cannot be instantiated directly using "),w7e=n(Eoo,"CODE",{});var mra=s(w7e);_Wr=r(mra,"__init__()"),mra.forEach(t),vWr=r(Eoo," (throws an error)."),Eoo.forEach(t),bWr=i(vi),Zt=n(vi,"DIV",{class:!0});var B8=s(Zt);T(gS.$$.fragment,B8),FWr=i(B8),A7e=n(B8,"P",{});var gra=s(A7e);TWr=r(gra,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),gra.forEach(t),MWr=i(B8),vf=n(B8,"P",{});var mie=s(vf);EWr=r(mie,`Note:
Loading a model from its configuration file does `),L7e=n(mie,"STRONG",{});var hra=s(L7e);CWr=r(hra,"not"),hra.forEach(t),wWr=r(mie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Hre=n(mie,"A",{href:!0});var ura=s(Hre);AWr=r(ura,"from_pretrained()"),ura.forEach(t),LWr=r(mie," to load the model weights."),mie.forEach(t),yWr=i(B8),T(Qw.$$.fragment,B8),B8.forEach(t),xWr=i(vi),zr=n(vi,"DIV",{class:!0});var bi=s(zr);T(hS.$$.fragment,bi),$Wr=i(bi),y7e=n(bi,"P",{});var pra=s(y7e);kWr=r(pra,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),pra.forEach(t),SWr=i(bi),Rn=n(bi,"P",{});var I8=s(Rn);RWr=r(I8,"The model class to instantiate is selected based on the "),x7e=n(I8,"CODE",{});var _ra=s(x7e);PWr=r(_ra,"model_type"),_ra.forEach(t),BWr=r(I8,` property of the config object (either
passed as an argument or loaded from `),$7e=n(I8,"CODE",{});var vra=s($7e);IWr=r(vra,"pretrained_model_name_or_path"),vra.forEach(t),NWr=r(I8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k7e=n(I8,"CODE",{});var bra=s(k7e);qWr=r(bra,"pretrained_model_name_or_path"),bra.forEach(t),jWr=r(I8,":"),I8.forEach(t),DWr=i(bi),uS=n(bi,"UL",{});var Coo=s(uS);Ww=n(Coo,"LI",{});var BUe=s(Ww);S7e=n(BUe,"STRONG",{});var Fra=s(S7e);GWr=r(Fra,"bert"),Fra.forEach(t),OWr=r(BUe," \u2014 "),Jre=n(BUe,"A",{href:!0});var Tra=s(Jre);VWr=r(Tra,"TFBertForNextSentencePrediction"),Tra.forEach(t),XWr=r(BUe," (BERT model)"),BUe.forEach(t),zWr=i(Coo),Uw=n(Coo,"LI",{});var IUe=s(Uw);R7e=n(IUe,"STRONG",{});var Mra=s(R7e);QWr=r(Mra,"mobilebert"),Mra.forEach(t),WWr=r(IUe," \u2014 "),Yre=n(IUe,"A",{href:!0});var Era=s(Yre);UWr=r(Era,"TFMobileBertForNextSentencePrediction"),Era.forEach(t),HWr=r(IUe," (MobileBERT model)"),IUe.forEach(t),Coo.forEach(t),JWr=i(bi),T(Hw.$$.fragment,bi),bi.forEach(t),vi.forEach(t),iZe=i(f),bf=n(f,"H2",{class:!0});var woo=s(bf);Jw=n(woo,"A",{id:!0,class:!0,href:!0});var Cra=s(Jw);P7e=n(Cra,"SPAN",{});var wra=s(P7e);T(pS.$$.fragment,wra),wra.forEach(t),Cra.forEach(t),YWr=i(woo),B7e=n(woo,"SPAN",{});var Ara=s(B7e);KWr=r(Ara,"TFAutoModelForTableQuestionAnswering"),Ara.forEach(t),woo.forEach(t),dZe=i(f),pr=n(f,"DIV",{class:!0});var Fi=s(pr);T(_S.$$.fragment,Fi),ZWr=i(Fi),Ff=n(Fi,"P",{});var gie=s(Ff);eUr=r(gie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Kre=n(gie,"A",{href:!0});var Lra=s(Kre);oUr=r(Lra,"from_pretrained()"),Lra.forEach(t),rUr=r(gie," class method or the "),Zre=n(gie,"A",{href:!0});var yra=s(Zre);tUr=r(yra,"from_config()"),yra.forEach(t),aUr=r(gie,` class
method.`),gie.forEach(t),nUr=i(Fi),vS=n(Fi,"P",{});var Aoo=s(vS);sUr=r(Aoo,"This class cannot be instantiated directly using "),I7e=n(Aoo,"CODE",{});var xra=s(I7e);lUr=r(xra,"__init__()"),xra.forEach(t),iUr=r(Aoo," (throws an error)."),Aoo.forEach(t),dUr=i(Fi),ea=n(Fi,"DIV",{class:!0});var N8=s(ea);T(bS.$$.fragment,N8),cUr=i(N8),N7e=n(N8,"P",{});var $ra=s(N7e);fUr=r($ra,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),$ra.forEach(t),mUr=i(N8),Tf=n(N8,"P",{});var hie=s(Tf);gUr=r(hie,`Note:
Loading a model from its configuration file does `),q7e=n(hie,"STRONG",{});var kra=s(q7e);hUr=r(kra,"not"),kra.forEach(t),uUr=r(hie,` load the model weights. It only affects the
model\u2019s configuration. Use `),ete=n(hie,"A",{href:!0});var Sra=s(ete);pUr=r(Sra,"from_pretrained()"),Sra.forEach(t),_Ur=r(hie," to load the model weights."),hie.forEach(t),vUr=i(N8),T(Yw.$$.fragment,N8),N8.forEach(t),bUr=i(Fi),Qr=n(Fi,"DIV",{class:!0});var Ti=s(Qr);T(FS.$$.fragment,Ti),FUr=i(Ti),j7e=n(Ti,"P",{});var Rra=s(j7e);TUr=r(Rra,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Rra.forEach(t),MUr=i(Ti),Pn=n(Ti,"P",{});var q8=s(Pn);EUr=r(q8,"The model class to instantiate is selected based on the "),D7e=n(q8,"CODE",{});var Pra=s(D7e);CUr=r(Pra,"model_type"),Pra.forEach(t),wUr=r(q8,` property of the config object (either
passed as an argument or loaded from `),G7e=n(q8,"CODE",{});var Bra=s(G7e);AUr=r(Bra,"pretrained_model_name_or_path"),Bra.forEach(t),LUr=r(q8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O7e=n(q8,"CODE",{});var Ira=s(O7e);yUr=r(Ira,"pretrained_model_name_or_path"),Ira.forEach(t),xUr=r(q8,":"),q8.forEach(t),$Ur=i(Ti),V7e=n(Ti,"UL",{});var Nra=s(V7e);Kw=n(Nra,"LI",{});var NUe=s(Kw);X7e=n(NUe,"STRONG",{});var qra=s(X7e);kUr=r(qra,"tapas"),qra.forEach(t),SUr=r(NUe," \u2014 "),ote=n(NUe,"A",{href:!0});var jra=s(ote);RUr=r(jra,"TFTapasForQuestionAnswering"),jra.forEach(t),PUr=r(NUe," (TAPAS model)"),NUe.forEach(t),Nra.forEach(t),BUr=i(Ti),T(Zw.$$.fragment,Ti),Ti.forEach(t),Fi.forEach(t),cZe=i(f),Mf=n(f,"H2",{class:!0});var Loo=s(Mf);eA=n(Loo,"A",{id:!0,class:!0,href:!0});var Dra=s(eA);z7e=n(Dra,"SPAN",{});var Gra=s(z7e);T(TS.$$.fragment,Gra),Gra.forEach(t),Dra.forEach(t),IUr=i(Loo),Q7e=n(Loo,"SPAN",{});var Ora=s(Q7e);NUr=r(Ora,"TFAutoModelForDocumentQuestionAnswering"),Ora.forEach(t),Loo.forEach(t),fZe=i(f),_r=n(f,"DIV",{class:!0});var Mi=s(_r);T(MS.$$.fragment,Mi),qUr=i(Mi),Ef=n(Mi,"P",{});var uie=s(Ef);jUr=r(uie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),rte=n(uie,"A",{href:!0});var Vra=s(rte);DUr=r(Vra,"from_pretrained()"),Vra.forEach(t),GUr=r(uie," class method or the "),tte=n(uie,"A",{href:!0});var Xra=s(tte);OUr=r(Xra,"from_config()"),Xra.forEach(t),VUr=r(uie,` class
method.`),uie.forEach(t),XUr=i(Mi),ES=n(Mi,"P",{});var yoo=s(ES);zUr=r(yoo,"This class cannot be instantiated directly using "),W7e=n(yoo,"CODE",{});var zra=s(W7e);QUr=r(zra,"__init__()"),zra.forEach(t),WUr=r(yoo," (throws an error)."),yoo.forEach(t),UUr=i(Mi),oa=n(Mi,"DIV",{class:!0});var j8=s(oa);T(CS.$$.fragment,j8),HUr=i(j8),U7e=n(j8,"P",{});var Qra=s(U7e);JUr=r(Qra,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Qra.forEach(t),YUr=i(j8),Cf=n(j8,"P",{});var pie=s(Cf);KUr=r(pie,`Note:
Loading a model from its configuration file does `),H7e=n(pie,"STRONG",{});var Wra=s(H7e);ZUr=r(Wra,"not"),Wra.forEach(t),eHr=r(pie,` load the model weights. It only affects the
model\u2019s configuration. Use `),ate=n(pie,"A",{href:!0});var Ura=s(ate);oHr=r(Ura,"from_pretrained()"),Ura.forEach(t),rHr=r(pie," to load the model weights."),pie.forEach(t),tHr=i(j8),T(oA.$$.fragment,j8),j8.forEach(t),aHr=i(Mi),Wr=n(Mi,"DIV",{class:!0});var Ei=s(Wr);T(wS.$$.fragment,Ei),nHr=i(Ei),J7e=n(Ei,"P",{});var Hra=s(J7e);sHr=r(Hra,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Hra.forEach(t),lHr=i(Ei),Bn=n(Ei,"P",{});var D8=s(Bn);iHr=r(D8,"The model class to instantiate is selected based on the "),Y7e=n(D8,"CODE",{});var Jra=s(Y7e);dHr=r(Jra,"model_type"),Jra.forEach(t),cHr=r(D8,` property of the config object (either
passed as an argument or loaded from `),K7e=n(D8,"CODE",{});var Yra=s(K7e);fHr=r(Yra,"pretrained_model_name_or_path"),Yra.forEach(t),mHr=r(D8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z7e=n(D8,"CODE",{});var Kra=s(Z7e);gHr=r(Kra,"pretrained_model_name_or_path"),Kra.forEach(t),hHr=r(D8,":"),D8.forEach(t),uHr=i(Ei),eLe=n(Ei,"UL",{});var Zra=s(eLe);rA=n(Zra,"LI",{});var qUe=s(rA);oLe=n(qUe,"STRONG",{});var eta=s(oLe);pHr=r(eta,"layoutlm"),eta.forEach(t),_Hr=r(qUe," \u2014 "),nte=n(qUe,"A",{href:!0});var ota=s(nte);vHr=r(ota,"TFLayoutLMForQuestionAnswering"),ota.forEach(t),bHr=r(qUe," (LayoutLM model)"),qUe.forEach(t),Zra.forEach(t),FHr=i(Ei),T(tA.$$.fragment,Ei),Ei.forEach(t),Mi.forEach(t),mZe=i(f),wf=n(f,"H2",{class:!0});var xoo=s(wf);aA=n(xoo,"A",{id:!0,class:!0,href:!0});var rta=s(aA);rLe=n(rta,"SPAN",{});var tta=s(rLe);T(AS.$$.fragment,tta),tta.forEach(t),rta.forEach(t),THr=i(xoo),tLe=n(xoo,"SPAN",{});var ata=s(tLe);MHr=r(ata,"TFAutoModelForTokenClassification"),ata.forEach(t),xoo.forEach(t),gZe=i(f),vr=n(f,"DIV",{class:!0});var Ci=s(vr);T(LS.$$.fragment,Ci),EHr=i(Ci),Af=n(Ci,"P",{});var _ie=s(Af);CHr=r(_ie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ste=n(_ie,"A",{href:!0});var nta=s(ste);wHr=r(nta,"from_pretrained()"),nta.forEach(t),AHr=r(_ie," class method or the "),lte=n(_ie,"A",{href:!0});var sta=s(lte);LHr=r(sta,"from_config()"),sta.forEach(t),yHr=r(_ie,` class
method.`),_ie.forEach(t),xHr=i(Ci),yS=n(Ci,"P",{});var $oo=s(yS);$Hr=r($oo,"This class cannot be instantiated directly using "),aLe=n($oo,"CODE",{});var lta=s(aLe);kHr=r(lta,"__init__()"),lta.forEach(t),SHr=r($oo," (throws an error)."),$oo.forEach(t),RHr=i(Ci),ra=n(Ci,"DIV",{class:!0});var G8=s(ra);T(xS.$$.fragment,G8),PHr=i(G8),nLe=n(G8,"P",{});var ita=s(nLe);BHr=r(ita,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),ita.forEach(t),IHr=i(G8),Lf=n(G8,"P",{});var vie=s(Lf);NHr=r(vie,`Note:
Loading a model from its configuration file does `),sLe=n(vie,"STRONG",{});var dta=s(sLe);qHr=r(dta,"not"),dta.forEach(t),jHr=r(vie,` load the model weights. It only affects the
model\u2019s configuration. Use `),ite=n(vie,"A",{href:!0});var cta=s(ite);DHr=r(cta,"from_pretrained()"),cta.forEach(t),GHr=r(vie," to load the model weights."),vie.forEach(t),OHr=i(G8),T(nA.$$.fragment,G8),G8.forEach(t),VHr=i(Ci),Ur=n(Ci,"DIV",{class:!0});var wi=s(Ur);T($S.$$.fragment,wi),XHr=i(wi),lLe=n(wi,"P",{});var fta=s(lLe);zHr=r(fta,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),fta.forEach(t),QHr=i(wi),In=n(wi,"P",{});var O8=s(In);WHr=r(O8,"The model class to instantiate is selected based on the "),iLe=n(O8,"CODE",{});var mta=s(iLe);UHr=r(mta,"model_type"),mta.forEach(t),HHr=r(O8,` property of the config object (either
passed as an argument or loaded from `),dLe=n(O8,"CODE",{});var gta=s(dLe);JHr=r(gta,"pretrained_model_name_or_path"),gta.forEach(t),YHr=r(O8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cLe=n(O8,"CODE",{});var hta=s(cLe);KHr=r(hta,"pretrained_model_name_or_path"),hta.forEach(t),ZHr=r(O8,":"),O8.forEach(t),eJr=i(wi),de=n(wi,"UL",{});var he=s(de);sA=n(he,"LI",{});var jUe=s(sA);fLe=n(jUe,"STRONG",{});var uta=s(fLe);oJr=r(uta,"albert"),uta.forEach(t),rJr=r(jUe," \u2014 "),dte=n(jUe,"A",{href:!0});var pta=s(dte);tJr=r(pta,"TFAlbertForTokenClassification"),pta.forEach(t),aJr=r(jUe," (ALBERT model)"),jUe.forEach(t),nJr=i(he),lA=n(he,"LI",{});var DUe=s(lA);mLe=n(DUe,"STRONG",{});var _ta=s(mLe);sJr=r(_ta,"bert"),_ta.forEach(t),lJr=r(DUe," \u2014 "),cte=n(DUe,"A",{href:!0});var vta=s(cte);iJr=r(vta,"TFBertForTokenClassification"),vta.forEach(t),dJr=r(DUe," (BERT model)"),DUe.forEach(t),cJr=i(he),iA=n(he,"LI",{});var GUe=s(iA);gLe=n(GUe,"STRONG",{});var bta=s(gLe);fJr=r(bta,"camembert"),bta.forEach(t),mJr=r(GUe," \u2014 "),fte=n(GUe,"A",{href:!0});var Fta=s(fte);gJr=r(Fta,"TFCamembertForTokenClassification"),Fta.forEach(t),hJr=r(GUe," (CamemBERT model)"),GUe.forEach(t),uJr=i(he),dA=n(he,"LI",{});var OUe=s(dA);hLe=n(OUe,"STRONG",{});var Tta=s(hLe);pJr=r(Tta,"convbert"),Tta.forEach(t),_Jr=r(OUe," \u2014 "),mte=n(OUe,"A",{href:!0});var Mta=s(mte);vJr=r(Mta,"TFConvBertForTokenClassification"),Mta.forEach(t),bJr=r(OUe," (ConvBERT model)"),OUe.forEach(t),FJr=i(he),cA=n(he,"LI",{});var VUe=s(cA);uLe=n(VUe,"STRONG",{});var Eta=s(uLe);TJr=r(Eta,"deberta"),Eta.forEach(t),MJr=r(VUe," \u2014 "),gte=n(VUe,"A",{href:!0});var Cta=s(gte);EJr=r(Cta,"TFDebertaForTokenClassification"),Cta.forEach(t),CJr=r(VUe," (DeBERTa model)"),VUe.forEach(t),wJr=i(he),fA=n(he,"LI",{});var XUe=s(fA);pLe=n(XUe,"STRONG",{});var wta=s(pLe);AJr=r(wta,"deberta-v2"),wta.forEach(t),LJr=r(XUe," \u2014 "),hte=n(XUe,"A",{href:!0});var Ata=s(hte);yJr=r(Ata,"TFDebertaV2ForTokenClassification"),Ata.forEach(t),xJr=r(XUe," (DeBERTa-v2 model)"),XUe.forEach(t),$Jr=i(he),mA=n(he,"LI",{});var zUe=s(mA);_Le=n(zUe,"STRONG",{});var Lta=s(_Le);kJr=r(Lta,"distilbert"),Lta.forEach(t),SJr=r(zUe," \u2014 "),ute=n(zUe,"A",{href:!0});var yta=s(ute);RJr=r(yta,"TFDistilBertForTokenClassification"),yta.forEach(t),PJr=r(zUe," (DistilBERT model)"),zUe.forEach(t),BJr=i(he),gA=n(he,"LI",{});var QUe=s(gA);vLe=n(QUe,"STRONG",{});var xta=s(vLe);IJr=r(xta,"electra"),xta.forEach(t),NJr=r(QUe," \u2014 "),pte=n(QUe,"A",{href:!0});var $ta=s(pte);qJr=r($ta,"TFElectraForTokenClassification"),$ta.forEach(t),jJr=r(QUe," (ELECTRA model)"),QUe.forEach(t),DJr=i(he),hA=n(he,"LI",{});var WUe=s(hA);bLe=n(WUe,"STRONG",{});var kta=s(bLe);GJr=r(kta,"flaubert"),kta.forEach(t),OJr=r(WUe," \u2014 "),_te=n(WUe,"A",{href:!0});var Sta=s(_te);VJr=r(Sta,"TFFlaubertForTokenClassification"),Sta.forEach(t),XJr=r(WUe," (FlauBERT model)"),WUe.forEach(t),zJr=i(he),uA=n(he,"LI",{});var UUe=s(uA);FLe=n(UUe,"STRONG",{});var Rta=s(FLe);QJr=r(Rta,"funnel"),Rta.forEach(t),WJr=r(UUe," \u2014 "),vte=n(UUe,"A",{href:!0});var Pta=s(vte);UJr=r(Pta,"TFFunnelForTokenClassification"),Pta.forEach(t),HJr=r(UUe," (Funnel Transformer model)"),UUe.forEach(t),JJr=i(he),pA=n(he,"LI",{});var HUe=s(pA);TLe=n(HUe,"STRONG",{});var Bta=s(TLe);YJr=r(Bta,"layoutlm"),Bta.forEach(t),KJr=r(HUe," \u2014 "),bte=n(HUe,"A",{href:!0});var Ita=s(bte);ZJr=r(Ita,"TFLayoutLMForTokenClassification"),Ita.forEach(t),eYr=r(HUe," (LayoutLM model)"),HUe.forEach(t),oYr=i(he),_A=n(he,"LI",{});var JUe=s(_A);MLe=n(JUe,"STRONG",{});var Nta=s(MLe);rYr=r(Nta,"layoutlmv3"),Nta.forEach(t),tYr=r(JUe," \u2014 "),Fte=n(JUe,"A",{href:!0});var qta=s(Fte);aYr=r(qta,"TFLayoutLMv3ForTokenClassification"),qta.forEach(t),nYr=r(JUe," (LayoutLMv3 model)"),JUe.forEach(t),sYr=i(he),vA=n(he,"LI",{});var YUe=s(vA);ELe=n(YUe,"STRONG",{});var jta=s(ELe);lYr=r(jta,"longformer"),jta.forEach(t),iYr=r(YUe," \u2014 "),Tte=n(YUe,"A",{href:!0});var Dta=s(Tte);dYr=r(Dta,"TFLongformerForTokenClassification"),Dta.forEach(t),cYr=r(YUe," (Longformer model)"),YUe.forEach(t),fYr=i(he),bA=n(he,"LI",{});var KUe=s(bA);CLe=n(KUe,"STRONG",{});var Gta=s(CLe);mYr=r(Gta,"mobilebert"),Gta.forEach(t),gYr=r(KUe," \u2014 "),Mte=n(KUe,"A",{href:!0});var Ota=s(Mte);hYr=r(Ota,"TFMobileBertForTokenClassification"),Ota.forEach(t),uYr=r(KUe," (MobileBERT model)"),KUe.forEach(t),pYr=i(he),FA=n(he,"LI",{});var ZUe=s(FA);wLe=n(ZUe,"STRONG",{});var Vta=s(wLe);_Yr=r(Vta,"mpnet"),Vta.forEach(t),vYr=r(ZUe," \u2014 "),Ete=n(ZUe,"A",{href:!0});var Xta=s(Ete);bYr=r(Xta,"TFMPNetForTokenClassification"),Xta.forEach(t),FYr=r(ZUe," (MPNet model)"),ZUe.forEach(t),TYr=i(he),TA=n(he,"LI",{});var eHe=s(TA);ALe=n(eHe,"STRONG",{});var zta=s(ALe);MYr=r(zta,"rembert"),zta.forEach(t),EYr=r(eHe," \u2014 "),Cte=n(eHe,"A",{href:!0});var Qta=s(Cte);CYr=r(Qta,"TFRemBertForTokenClassification"),Qta.forEach(t),wYr=r(eHe," (RemBERT model)"),eHe.forEach(t),AYr=i(he),MA=n(he,"LI",{});var oHe=s(MA);LLe=n(oHe,"STRONG",{});var Wta=s(LLe);LYr=r(Wta,"roberta"),Wta.forEach(t),yYr=r(oHe," \u2014 "),wte=n(oHe,"A",{href:!0});var Uta=s(wte);xYr=r(Uta,"TFRobertaForTokenClassification"),Uta.forEach(t),$Yr=r(oHe," (RoBERTa model)"),oHe.forEach(t),kYr=i(he),EA=n(he,"LI",{});var rHe=s(EA);yLe=n(rHe,"STRONG",{});var Hta=s(yLe);SYr=r(Hta,"roformer"),Hta.forEach(t),RYr=r(rHe," \u2014 "),Ate=n(rHe,"A",{href:!0});var Jta=s(Ate);PYr=r(Jta,"TFRoFormerForTokenClassification"),Jta.forEach(t),BYr=r(rHe," (RoFormer model)"),rHe.forEach(t),IYr=i(he),CA=n(he,"LI",{});var tHe=s(CA);xLe=n(tHe,"STRONG",{});var Yta=s(xLe);NYr=r(Yta,"xlm"),Yta.forEach(t),qYr=r(tHe," \u2014 "),Lte=n(tHe,"A",{href:!0});var Kta=s(Lte);jYr=r(Kta,"TFXLMForTokenClassification"),Kta.forEach(t),DYr=r(tHe," (XLM model)"),tHe.forEach(t),GYr=i(he),wA=n(he,"LI",{});var aHe=s(wA);$Le=n(aHe,"STRONG",{});var Zta=s($Le);OYr=r(Zta,"xlm-roberta"),Zta.forEach(t),VYr=r(aHe," \u2014 "),yte=n(aHe,"A",{href:!0});var eaa=s(yte);XYr=r(eaa,"TFXLMRobertaForTokenClassification"),eaa.forEach(t),zYr=r(aHe," (XLM-RoBERTa model)"),aHe.forEach(t),QYr=i(he),AA=n(he,"LI",{});var nHe=s(AA);kLe=n(nHe,"STRONG",{});var oaa=s(kLe);WYr=r(oaa,"xlnet"),oaa.forEach(t),UYr=r(nHe," \u2014 "),xte=n(nHe,"A",{href:!0});var raa=s(xte);HYr=r(raa,"TFXLNetForTokenClassification"),raa.forEach(t),JYr=r(nHe," (XLNet model)"),nHe.forEach(t),he.forEach(t),YYr=i(wi),T(LA.$$.fragment,wi),wi.forEach(t),Ci.forEach(t),hZe=i(f),yf=n(f,"H2",{class:!0});var koo=s(yf);yA=n(koo,"A",{id:!0,class:!0,href:!0});var taa=s(yA);SLe=n(taa,"SPAN",{});var aaa=s(SLe);T(kS.$$.fragment,aaa),aaa.forEach(t),taa.forEach(t),KYr=i(koo),RLe=n(koo,"SPAN",{});var naa=s(RLe);ZYr=r(naa,"TFAutoModelForQuestionAnswering"),naa.forEach(t),koo.forEach(t),uZe=i(f),br=n(f,"DIV",{class:!0});var Ai=s(br);T(SS.$$.fragment,Ai),eKr=i(Ai),xf=n(Ai,"P",{});var bie=s(xf);oKr=r(bie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),$te=n(bie,"A",{href:!0});var saa=s($te);rKr=r(saa,"from_pretrained()"),saa.forEach(t),tKr=r(bie," class method or the "),kte=n(bie,"A",{href:!0});var laa=s(kte);aKr=r(laa,"from_config()"),laa.forEach(t),nKr=r(bie,` class
method.`),bie.forEach(t),sKr=i(Ai),RS=n(Ai,"P",{});var Soo=s(RS);lKr=r(Soo,"This class cannot be instantiated directly using "),PLe=n(Soo,"CODE",{});var iaa=s(PLe);iKr=r(iaa,"__init__()"),iaa.forEach(t),dKr=r(Soo," (throws an error)."),Soo.forEach(t),cKr=i(Ai),ta=n(Ai,"DIV",{class:!0});var V8=s(ta);T(PS.$$.fragment,V8),fKr=i(V8),BLe=n(V8,"P",{});var daa=s(BLe);mKr=r(daa,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),daa.forEach(t),gKr=i(V8),$f=n(V8,"P",{});var Fie=s($f);hKr=r(Fie,`Note:
Loading a model from its configuration file does `),ILe=n(Fie,"STRONG",{});var caa=s(ILe);uKr=r(caa,"not"),caa.forEach(t),pKr=r(Fie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ste=n(Fie,"A",{href:!0});var faa=s(Ste);_Kr=r(faa,"from_pretrained()"),faa.forEach(t),vKr=r(Fie," to load the model weights."),Fie.forEach(t),bKr=i(V8),T(xA.$$.fragment,V8),V8.forEach(t),FKr=i(Ai),Hr=n(Ai,"DIV",{class:!0});var Li=s(Hr);T(BS.$$.fragment,Li),TKr=i(Li),NLe=n(Li,"P",{});var maa=s(NLe);MKr=r(maa,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),maa.forEach(t),EKr=i(Li),Nn=n(Li,"P",{});var X8=s(Nn);CKr=r(X8,"The model class to instantiate is selected based on the "),qLe=n(X8,"CODE",{});var gaa=s(qLe);wKr=r(gaa,"model_type"),gaa.forEach(t),AKr=r(X8,` property of the config object (either
passed as an argument or loaded from `),jLe=n(X8,"CODE",{});var haa=s(jLe);LKr=r(haa,"pretrained_model_name_or_path"),haa.forEach(t),yKr=r(X8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DLe=n(X8,"CODE",{});var uaa=s(DLe);xKr=r(uaa,"pretrained_model_name_or_path"),uaa.forEach(t),$Kr=r(X8,":"),X8.forEach(t),kKr=i(Li),ce=n(Li,"UL",{});var ue=s(ce);$A=n(ue,"LI",{});var sHe=s($A);GLe=n(sHe,"STRONG",{});var paa=s(GLe);SKr=r(paa,"albert"),paa.forEach(t),RKr=r(sHe," \u2014 "),Rte=n(sHe,"A",{href:!0});var _aa=s(Rte);PKr=r(_aa,"TFAlbertForQuestionAnswering"),_aa.forEach(t),BKr=r(sHe," (ALBERT model)"),sHe.forEach(t),IKr=i(ue),kA=n(ue,"LI",{});var lHe=s(kA);OLe=n(lHe,"STRONG",{});var vaa=s(OLe);NKr=r(vaa,"bert"),vaa.forEach(t),qKr=r(lHe," \u2014 "),Pte=n(lHe,"A",{href:!0});var baa=s(Pte);jKr=r(baa,"TFBertForQuestionAnswering"),baa.forEach(t),DKr=r(lHe," (BERT model)"),lHe.forEach(t),GKr=i(ue),SA=n(ue,"LI",{});var iHe=s(SA);VLe=n(iHe,"STRONG",{});var Faa=s(VLe);OKr=r(Faa,"camembert"),Faa.forEach(t),VKr=r(iHe," \u2014 "),Bte=n(iHe,"A",{href:!0});var Taa=s(Bte);XKr=r(Taa,"TFCamembertForQuestionAnswering"),Taa.forEach(t),zKr=r(iHe," (CamemBERT model)"),iHe.forEach(t),QKr=i(ue),RA=n(ue,"LI",{});var dHe=s(RA);XLe=n(dHe,"STRONG",{});var Maa=s(XLe);WKr=r(Maa,"convbert"),Maa.forEach(t),UKr=r(dHe," \u2014 "),Ite=n(dHe,"A",{href:!0});var Eaa=s(Ite);HKr=r(Eaa,"TFConvBertForQuestionAnswering"),Eaa.forEach(t),JKr=r(dHe," (ConvBERT model)"),dHe.forEach(t),YKr=i(ue),PA=n(ue,"LI",{});var cHe=s(PA);zLe=n(cHe,"STRONG",{});var Caa=s(zLe);KKr=r(Caa,"deberta"),Caa.forEach(t),ZKr=r(cHe," \u2014 "),Nte=n(cHe,"A",{href:!0});var waa=s(Nte);eZr=r(waa,"TFDebertaForQuestionAnswering"),waa.forEach(t),oZr=r(cHe," (DeBERTa model)"),cHe.forEach(t),rZr=i(ue),BA=n(ue,"LI",{});var fHe=s(BA);QLe=n(fHe,"STRONG",{});var Aaa=s(QLe);tZr=r(Aaa,"deberta-v2"),Aaa.forEach(t),aZr=r(fHe," \u2014 "),qte=n(fHe,"A",{href:!0});var Laa=s(qte);nZr=r(Laa,"TFDebertaV2ForQuestionAnswering"),Laa.forEach(t),sZr=r(fHe," (DeBERTa-v2 model)"),fHe.forEach(t),lZr=i(ue),IA=n(ue,"LI",{});var mHe=s(IA);WLe=n(mHe,"STRONG",{});var yaa=s(WLe);iZr=r(yaa,"distilbert"),yaa.forEach(t),dZr=r(mHe," \u2014 "),jte=n(mHe,"A",{href:!0});var xaa=s(jte);cZr=r(xaa,"TFDistilBertForQuestionAnswering"),xaa.forEach(t),fZr=r(mHe," (DistilBERT model)"),mHe.forEach(t),mZr=i(ue),NA=n(ue,"LI",{});var gHe=s(NA);ULe=n(gHe,"STRONG",{});var $aa=s(ULe);gZr=r($aa,"electra"),$aa.forEach(t),hZr=r(gHe," \u2014 "),Dte=n(gHe,"A",{href:!0});var kaa=s(Dte);uZr=r(kaa,"TFElectraForQuestionAnswering"),kaa.forEach(t),pZr=r(gHe," (ELECTRA model)"),gHe.forEach(t),_Zr=i(ue),qA=n(ue,"LI",{});var hHe=s(qA);HLe=n(hHe,"STRONG",{});var Saa=s(HLe);vZr=r(Saa,"flaubert"),Saa.forEach(t),bZr=r(hHe," \u2014 "),Gte=n(hHe,"A",{href:!0});var Raa=s(Gte);FZr=r(Raa,"TFFlaubertForQuestionAnsweringSimple"),Raa.forEach(t),TZr=r(hHe," (FlauBERT model)"),hHe.forEach(t),MZr=i(ue),jA=n(ue,"LI",{});var uHe=s(jA);JLe=n(uHe,"STRONG",{});var Paa=s(JLe);EZr=r(Paa,"funnel"),Paa.forEach(t),CZr=r(uHe," \u2014 "),Ote=n(uHe,"A",{href:!0});var Baa=s(Ote);wZr=r(Baa,"TFFunnelForQuestionAnswering"),Baa.forEach(t),AZr=r(uHe," (Funnel Transformer model)"),uHe.forEach(t),LZr=i(ue),DA=n(ue,"LI",{});var pHe=s(DA);YLe=n(pHe,"STRONG",{});var Iaa=s(YLe);yZr=r(Iaa,"gptj"),Iaa.forEach(t),xZr=r(pHe," \u2014 "),Vte=n(pHe,"A",{href:!0});var Naa=s(Vte);$Zr=r(Naa,"TFGPTJForQuestionAnswering"),Naa.forEach(t),kZr=r(pHe," (GPT-J model)"),pHe.forEach(t),SZr=i(ue),GA=n(ue,"LI",{});var _He=s(GA);KLe=n(_He,"STRONG",{});var qaa=s(KLe);RZr=r(qaa,"layoutlmv3"),qaa.forEach(t),PZr=r(_He," \u2014 "),Xte=n(_He,"A",{href:!0});var jaa=s(Xte);BZr=r(jaa,"TFLayoutLMv3ForQuestionAnswering"),jaa.forEach(t),IZr=r(_He," (LayoutLMv3 model)"),_He.forEach(t),NZr=i(ue),OA=n(ue,"LI",{});var vHe=s(OA);ZLe=n(vHe,"STRONG",{});var Daa=s(ZLe);qZr=r(Daa,"longformer"),Daa.forEach(t),jZr=r(vHe," \u2014 "),zte=n(vHe,"A",{href:!0});var Gaa=s(zte);DZr=r(Gaa,"TFLongformerForQuestionAnswering"),Gaa.forEach(t),GZr=r(vHe," (Longformer model)"),vHe.forEach(t),OZr=i(ue),VA=n(ue,"LI",{});var bHe=s(VA);eye=n(bHe,"STRONG",{});var Oaa=s(eye);VZr=r(Oaa,"mobilebert"),Oaa.forEach(t),XZr=r(bHe," \u2014 "),Qte=n(bHe,"A",{href:!0});var Vaa=s(Qte);zZr=r(Vaa,"TFMobileBertForQuestionAnswering"),Vaa.forEach(t),QZr=r(bHe," (MobileBERT model)"),bHe.forEach(t),WZr=i(ue),XA=n(ue,"LI",{});var FHe=s(XA);oye=n(FHe,"STRONG",{});var Xaa=s(oye);UZr=r(Xaa,"mpnet"),Xaa.forEach(t),HZr=r(FHe," \u2014 "),Wte=n(FHe,"A",{href:!0});var zaa=s(Wte);JZr=r(zaa,"TFMPNetForQuestionAnswering"),zaa.forEach(t),YZr=r(FHe," (MPNet model)"),FHe.forEach(t),KZr=i(ue),zA=n(ue,"LI",{});var THe=s(zA);rye=n(THe,"STRONG",{});var Qaa=s(rye);ZZr=r(Qaa,"rembert"),Qaa.forEach(t),eet=r(THe," \u2014 "),Ute=n(THe,"A",{href:!0});var Waa=s(Ute);oet=r(Waa,"TFRemBertForQuestionAnswering"),Waa.forEach(t),ret=r(THe," (RemBERT model)"),THe.forEach(t),tet=i(ue),QA=n(ue,"LI",{});var MHe=s(QA);tye=n(MHe,"STRONG",{});var Uaa=s(tye);aet=r(Uaa,"roberta"),Uaa.forEach(t),net=r(MHe," \u2014 "),Hte=n(MHe,"A",{href:!0});var Haa=s(Hte);set=r(Haa,"TFRobertaForQuestionAnswering"),Haa.forEach(t),iet=r(MHe," (RoBERTa model)"),MHe.forEach(t),det=i(ue),WA=n(ue,"LI",{});var EHe=s(WA);aye=n(EHe,"STRONG",{});var Jaa=s(aye);cet=r(Jaa,"roformer"),Jaa.forEach(t),fet=r(EHe," \u2014 "),Jte=n(EHe,"A",{href:!0});var Yaa=s(Jte);met=r(Yaa,"TFRoFormerForQuestionAnswering"),Yaa.forEach(t),get=r(EHe," (RoFormer model)"),EHe.forEach(t),het=i(ue),UA=n(ue,"LI",{});var CHe=s(UA);nye=n(CHe,"STRONG",{});var Kaa=s(nye);uet=r(Kaa,"xlm"),Kaa.forEach(t),pet=r(CHe," \u2014 "),Yte=n(CHe,"A",{href:!0});var Zaa=s(Yte);_et=r(Zaa,"TFXLMForQuestionAnsweringSimple"),Zaa.forEach(t),vet=r(CHe," (XLM model)"),CHe.forEach(t),bet=i(ue),HA=n(ue,"LI",{});var wHe=s(HA);sye=n(wHe,"STRONG",{});var ena=s(sye);Fet=r(ena,"xlm-roberta"),ena.forEach(t),Tet=r(wHe," \u2014 "),Kte=n(wHe,"A",{href:!0});var ona=s(Kte);Met=r(ona,"TFXLMRobertaForQuestionAnswering"),ona.forEach(t),Eet=r(wHe," (XLM-RoBERTa model)"),wHe.forEach(t),Cet=i(ue),JA=n(ue,"LI",{});var AHe=s(JA);lye=n(AHe,"STRONG",{});var rna=s(lye);wet=r(rna,"xlnet"),rna.forEach(t),Aet=r(AHe," \u2014 "),Zte=n(AHe,"A",{href:!0});var tna=s(Zte);Let=r(tna,"TFXLNetForQuestionAnsweringSimple"),tna.forEach(t),yet=r(AHe," (XLNet model)"),AHe.forEach(t),ue.forEach(t),xet=i(Li),T(YA.$$.fragment,Li),Li.forEach(t),Ai.forEach(t),pZe=i(f),kf=n(f,"H2",{class:!0});var Roo=s(kf);KA=n(Roo,"A",{id:!0,class:!0,href:!0});var ana=s(KA);iye=n(ana,"SPAN",{});var nna=s(iye);T(IS.$$.fragment,nna),nna.forEach(t),ana.forEach(t),$et=i(Roo),dye=n(Roo,"SPAN",{});var sna=s(dye);ket=r(sna,"TFAutoModelForVision2Seq"),sna.forEach(t),Roo.forEach(t),_Ze=i(f),Fr=n(f,"DIV",{class:!0});var yi=s(Fr);T(NS.$$.fragment,yi),Set=i(yi),Sf=n(yi,"P",{});var Tie=s(Sf);Ret=r(Tie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),eae=n(Tie,"A",{href:!0});var lna=s(eae);Pet=r(lna,"from_pretrained()"),lna.forEach(t),Bet=r(Tie," class method or the "),oae=n(Tie,"A",{href:!0});var ina=s(oae);Iet=r(ina,"from_config()"),ina.forEach(t),Net=r(Tie,` class
method.`),Tie.forEach(t),qet=i(yi),qS=n(yi,"P",{});var Poo=s(qS);jet=r(Poo,"This class cannot be instantiated directly using "),cye=n(Poo,"CODE",{});var dna=s(cye);Det=r(dna,"__init__()"),dna.forEach(t),Get=r(Poo," (throws an error)."),Poo.forEach(t),Oet=i(yi),aa=n(yi,"DIV",{class:!0});var z8=s(aa);T(jS.$$.fragment,z8),Vet=i(z8),fye=n(z8,"P",{});var cna=s(fye);Xet=r(cna,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),cna.forEach(t),zet=i(z8),Rf=n(z8,"P",{});var Mie=s(Rf);Qet=r(Mie,`Note:
Loading a model from its configuration file does `),mye=n(Mie,"STRONG",{});var fna=s(mye);Wet=r(fna,"not"),fna.forEach(t),Uet=r(Mie,` load the model weights. It only affects the
model\u2019s configuration. Use `),rae=n(Mie,"A",{href:!0});var mna=s(rae);Het=r(mna,"from_pretrained()"),mna.forEach(t),Jet=r(Mie," to load the model weights."),Mie.forEach(t),Yet=i(z8),T(ZA.$$.fragment,z8),z8.forEach(t),Ket=i(yi),Jr=n(yi,"DIV",{class:!0});var xi=s(Jr);T(DS.$$.fragment,xi),Zet=i(xi),gye=n(xi,"P",{});var gna=s(gye);eot=r(gna,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),gna.forEach(t),oot=i(xi),qn=n(xi,"P",{});var Q8=s(qn);rot=r(Q8,"The model class to instantiate is selected based on the "),hye=n(Q8,"CODE",{});var hna=s(hye);tot=r(hna,"model_type"),hna.forEach(t),aot=r(Q8,` property of the config object (either
passed as an argument or loaded from `),uye=n(Q8,"CODE",{});var una=s(uye);not=r(una,"pretrained_model_name_or_path"),una.forEach(t),sot=r(Q8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pye=n(Q8,"CODE",{});var pna=s(pye);lot=r(pna,"pretrained_model_name_or_path"),pna.forEach(t),iot=r(Q8,":"),Q8.forEach(t),dot=i(xi),_ye=n(xi,"UL",{});var _na=s(_ye);e6=n(_na,"LI",{});var LHe=s(e6);vye=n(LHe,"STRONG",{});var vna=s(vye);cot=r(vna,"vision-encoder-decoder"),vna.forEach(t),fot=r(LHe," \u2014 "),tae=n(LHe,"A",{href:!0});var bna=s(tae);mot=r(bna,"TFVisionEncoderDecoderModel"),bna.forEach(t),got=r(LHe," (Vision Encoder decoder model)"),LHe.forEach(t),_na.forEach(t),hot=i(xi),T(o6.$$.fragment,xi),xi.forEach(t),yi.forEach(t),vZe=i(f),Pf=n(f,"H2",{class:!0});var Boo=s(Pf);r6=n(Boo,"A",{id:!0,class:!0,href:!0});var Fna=s(r6);bye=n(Fna,"SPAN",{});var Tna=s(bye);T(GS.$$.fragment,Tna),Tna.forEach(t),Fna.forEach(t),uot=i(Boo),Fye=n(Boo,"SPAN",{});var Mna=s(Fye);pot=r(Mna,"TFAutoModelForSpeechSeq2Seq"),Mna.forEach(t),Boo.forEach(t),bZe=i(f),Tr=n(f,"DIV",{class:!0});var $i=s(Tr);T(OS.$$.fragment,$i),_ot=i($i),Bf=n($i,"P",{});var Eie=s(Bf);vot=r(Eie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),aae=n(Eie,"A",{href:!0});var Ena=s(aae);bot=r(Ena,"from_pretrained()"),Ena.forEach(t),Fot=r(Eie," class method or the "),nae=n(Eie,"A",{href:!0});var Cna=s(nae);Tot=r(Cna,"from_config()"),Cna.forEach(t),Mot=r(Eie,` class
method.`),Eie.forEach(t),Eot=i($i),VS=n($i,"P",{});var Ioo=s(VS);Cot=r(Ioo,"This class cannot be instantiated directly using "),Tye=n(Ioo,"CODE",{});var wna=s(Tye);wot=r(wna,"__init__()"),wna.forEach(t),Aot=r(Ioo," (throws an error)."),Ioo.forEach(t),Lot=i($i),na=n($i,"DIV",{class:!0});var W8=s(na);T(XS.$$.fragment,W8),yot=i(W8),Mye=n(W8,"P",{});var Ana=s(Mye);xot=r(Ana,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Ana.forEach(t),$ot=i(W8),If=n(W8,"P",{});var Cie=s(If);kot=r(Cie,`Note:
Loading a model from its configuration file does `),Eye=n(Cie,"STRONG",{});var Lna=s(Eye);Sot=r(Lna,"not"),Lna.forEach(t),Rot=r(Cie,` load the model weights. It only affects the
model\u2019s configuration. Use `),sae=n(Cie,"A",{href:!0});var yna=s(sae);Pot=r(yna,"from_pretrained()"),yna.forEach(t),Bot=r(Cie," to load the model weights."),Cie.forEach(t),Iot=i(W8),T(t6.$$.fragment,W8),W8.forEach(t),Not=i($i),Yr=n($i,"DIV",{class:!0});var ki=s(Yr);T(zS.$$.fragment,ki),qot=i(ki),Cye=n(ki,"P",{});var xna=s(Cye);jot=r(xna,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),xna.forEach(t),Dot=i(ki),jn=n(ki,"P",{});var U8=s(jn);Got=r(U8,"The model class to instantiate is selected based on the "),wye=n(U8,"CODE",{});var $na=s(wye);Oot=r($na,"model_type"),$na.forEach(t),Vot=r(U8,` property of the config object (either
passed as an argument or loaded from `),Aye=n(U8,"CODE",{});var kna=s(Aye);Xot=r(kna,"pretrained_model_name_or_path"),kna.forEach(t),zot=r(U8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lye=n(U8,"CODE",{});var Sna=s(Lye);Qot=r(Sna,"pretrained_model_name_or_path"),Sna.forEach(t),Wot=r(U8,":"),U8.forEach(t),Uot=i(ki),yye=n(ki,"UL",{});var Rna=s(yye);a6=n(Rna,"LI",{});var yHe=s(a6);xye=n(yHe,"STRONG",{});var Pna=s(xye);Hot=r(Pna,"speech_to_text"),Pna.forEach(t),Jot=r(yHe," \u2014 "),lae=n(yHe,"A",{href:!0});var Bna=s(lae);Yot=r(Bna,"TFSpeech2TextForConditionalGeneration"),Bna.forEach(t),Kot=r(yHe," (Speech2Text model)"),yHe.forEach(t),Rna.forEach(t),Zot=i(ki),T(n6.$$.fragment,ki),ki.forEach(t),$i.forEach(t),FZe=i(f),Nf=n(f,"H2",{class:!0});var Noo=s(Nf);s6=n(Noo,"A",{id:!0,class:!0,href:!0});var Ina=s(s6);$ye=n(Ina,"SPAN",{});var Nna=s($ye);T(QS.$$.fragment,Nna),Nna.forEach(t),Ina.forEach(t),ert=i(Noo),kye=n(Noo,"SPAN",{});var qna=s(kye);ort=r(qna,"FlaxAutoModel"),qna.forEach(t),Noo.forEach(t),TZe=i(f),Mr=n(f,"DIV",{class:!0});var Si=s(Mr);T(WS.$$.fragment,Si),rrt=i(Si),qf=n(Si,"P",{});var wie=s(qf);trt=r(wie,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),iae=n(wie,"A",{href:!0});var jna=s(iae);art=r(jna,"from_pretrained()"),jna.forEach(t),nrt=r(wie," class method or the "),dae=n(wie,"A",{href:!0});var Dna=s(dae);srt=r(Dna,"from_config()"),Dna.forEach(t),lrt=r(wie,` class
method.`),wie.forEach(t),irt=i(Si),US=n(Si,"P",{});var qoo=s(US);drt=r(qoo,"This class cannot be instantiated directly using "),Sye=n(qoo,"CODE",{});var Gna=s(Sye);crt=r(Gna,"__init__()"),Gna.forEach(t),frt=r(qoo," (throws an error)."),qoo.forEach(t),mrt=i(Si),sa=n(Si,"DIV",{class:!0});var H8=s(sa);T(HS.$$.fragment,H8),grt=i(H8),Rye=n(H8,"P",{});var Ona=s(Rye);hrt=r(Ona,"Instantiates one of the base model classes of the library from a configuration."),Ona.forEach(t),urt=i(H8),jf=n(H8,"P",{});var Aie=s(jf);prt=r(Aie,`Note:
Loading a model from its configuration file does `),Pye=n(Aie,"STRONG",{});var Vna=s(Pye);_rt=r(Vna,"not"),Vna.forEach(t),vrt=r(Aie,` load the model weights. It only affects the
model\u2019s configuration. Use `),cae=n(Aie,"A",{href:!0});var Xna=s(cae);brt=r(Xna,"from_pretrained()"),Xna.forEach(t),Frt=r(Aie," to load the model weights."),Aie.forEach(t),Trt=i(H8),T(l6.$$.fragment,H8),H8.forEach(t),Mrt=i(Si),Kr=n(Si,"DIV",{class:!0});var Ri=s(Kr);T(JS.$$.fragment,Ri),Ert=i(Ri),Bye=n(Ri,"P",{});var zna=s(Bye);Crt=r(zna,"Instantiate one of the base model classes of the library from a pretrained model."),zna.forEach(t),wrt=i(Ri),Dn=n(Ri,"P",{});var J8=s(Dn);Art=r(J8,"The model class to instantiate is selected based on the "),Iye=n(J8,"CODE",{});var Qna=s(Iye);Lrt=r(Qna,"model_type"),Qna.forEach(t),yrt=r(J8,` property of the config object (either
passed as an argument or loaded from `),Nye=n(J8,"CODE",{});var Wna=s(Nye);xrt=r(Wna,"pretrained_model_name_or_path"),Wna.forEach(t),$rt=r(J8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qye=n(J8,"CODE",{});var Una=s(qye);krt=r(Una,"pretrained_model_name_or_path"),Una.forEach(t),Srt=r(J8,":"),J8.forEach(t),Rrt=i(Ri),te=n(Ri,"UL",{});var ne=s(te);i6=n(ne,"LI",{});var xHe=s(i6);jye=n(xHe,"STRONG",{});var Hna=s(jye);Prt=r(Hna,"albert"),Hna.forEach(t),Brt=r(xHe," \u2014 "),fae=n(xHe,"A",{href:!0});var Jna=s(fae);Irt=r(Jna,"FlaxAlbertModel"),Jna.forEach(t),Nrt=r(xHe," (ALBERT model)"),xHe.forEach(t),qrt=i(ne),d6=n(ne,"LI",{});var $He=s(d6);Dye=n($He,"STRONG",{});var Yna=s(Dye);jrt=r(Yna,"bart"),Yna.forEach(t),Drt=r($He," \u2014 "),mae=n($He,"A",{href:!0});var Kna=s(mae);Grt=r(Kna,"FlaxBartModel"),Kna.forEach(t),Ort=r($He," (BART model)"),$He.forEach(t),Vrt=i(ne),c6=n(ne,"LI",{});var kHe=s(c6);Gye=n(kHe,"STRONG",{});var Zna=s(Gye);Xrt=r(Zna,"beit"),Zna.forEach(t),zrt=r(kHe," \u2014 "),gae=n(kHe,"A",{href:!0});var esa=s(gae);Qrt=r(esa,"FlaxBeitModel"),esa.forEach(t),Wrt=r(kHe," (BEiT model)"),kHe.forEach(t),Urt=i(ne),f6=n(ne,"LI",{});var SHe=s(f6);Oye=n(SHe,"STRONG",{});var osa=s(Oye);Hrt=r(osa,"bert"),osa.forEach(t),Jrt=r(SHe," \u2014 "),hae=n(SHe,"A",{href:!0});var rsa=s(hae);Yrt=r(rsa,"FlaxBertModel"),rsa.forEach(t),Krt=r(SHe," (BERT model)"),SHe.forEach(t),Zrt=i(ne),m6=n(ne,"LI",{});var RHe=s(m6);Vye=n(RHe,"STRONG",{});var tsa=s(Vye);ett=r(tsa,"big_bird"),tsa.forEach(t),ott=r(RHe," \u2014 "),uae=n(RHe,"A",{href:!0});var asa=s(uae);rtt=r(asa,"FlaxBigBirdModel"),asa.forEach(t),ttt=r(RHe," (BigBird model)"),RHe.forEach(t),att=i(ne),g6=n(ne,"LI",{});var PHe=s(g6);Xye=n(PHe,"STRONG",{});var nsa=s(Xye);ntt=r(nsa,"blenderbot"),nsa.forEach(t),stt=r(PHe," \u2014 "),pae=n(PHe,"A",{href:!0});var ssa=s(pae);ltt=r(ssa,"FlaxBlenderbotModel"),ssa.forEach(t),itt=r(PHe," (Blenderbot model)"),PHe.forEach(t),dtt=i(ne),h6=n(ne,"LI",{});var BHe=s(h6);zye=n(BHe,"STRONG",{});var lsa=s(zye);ctt=r(lsa,"blenderbot-small"),lsa.forEach(t),ftt=r(BHe," \u2014 "),_ae=n(BHe,"A",{href:!0});var isa=s(_ae);mtt=r(isa,"FlaxBlenderbotSmallModel"),isa.forEach(t),gtt=r(BHe," (BlenderbotSmall model)"),BHe.forEach(t),htt=i(ne),u6=n(ne,"LI",{});var IHe=s(u6);Qye=n(IHe,"STRONG",{});var dsa=s(Qye);utt=r(dsa,"clip"),dsa.forEach(t),ptt=r(IHe," \u2014 "),vae=n(IHe,"A",{href:!0});var csa=s(vae);_tt=r(csa,"FlaxCLIPModel"),csa.forEach(t),vtt=r(IHe," (CLIP model)"),IHe.forEach(t),btt=i(ne),p6=n(ne,"LI",{});var NHe=s(p6);Wye=n(NHe,"STRONG",{});var fsa=s(Wye);Ftt=r(fsa,"distilbert"),fsa.forEach(t),Ttt=r(NHe," \u2014 "),bae=n(NHe,"A",{href:!0});var msa=s(bae);Mtt=r(msa,"FlaxDistilBertModel"),msa.forEach(t),Ett=r(NHe," (DistilBERT model)"),NHe.forEach(t),Ctt=i(ne),_6=n(ne,"LI",{});var qHe=s(_6);Uye=n(qHe,"STRONG",{});var gsa=s(Uye);wtt=r(gsa,"electra"),gsa.forEach(t),Att=r(qHe," \u2014 "),Fae=n(qHe,"A",{href:!0});var hsa=s(Fae);Ltt=r(hsa,"FlaxElectraModel"),hsa.forEach(t),ytt=r(qHe," (ELECTRA model)"),qHe.forEach(t),xtt=i(ne),v6=n(ne,"LI",{});var jHe=s(v6);Hye=n(jHe,"STRONG",{});var usa=s(Hye);$tt=r(usa,"gpt2"),usa.forEach(t),ktt=r(jHe," \u2014 "),Tae=n(jHe,"A",{href:!0});var psa=s(Tae);Stt=r(psa,"FlaxGPT2Model"),psa.forEach(t),Rtt=r(jHe," (OpenAI GPT-2 model)"),jHe.forEach(t),Ptt=i(ne),b6=n(ne,"LI",{});var DHe=s(b6);Jye=n(DHe,"STRONG",{});var _sa=s(Jye);Btt=r(_sa,"gpt_neo"),_sa.forEach(t),Itt=r(DHe," \u2014 "),Mae=n(DHe,"A",{href:!0});var vsa=s(Mae);Ntt=r(vsa,"FlaxGPTNeoModel"),vsa.forEach(t),qtt=r(DHe," (GPT Neo model)"),DHe.forEach(t),jtt=i(ne),F6=n(ne,"LI",{});var GHe=s(F6);Yye=n(GHe,"STRONG",{});var bsa=s(Yye);Dtt=r(bsa,"gptj"),bsa.forEach(t),Gtt=r(GHe," \u2014 "),Eae=n(GHe,"A",{href:!0});var Fsa=s(Eae);Ott=r(Fsa,"FlaxGPTJModel"),Fsa.forEach(t),Vtt=r(GHe," (GPT-J model)"),GHe.forEach(t),Xtt=i(ne),T6=n(ne,"LI",{});var OHe=s(T6);Kye=n(OHe,"STRONG",{});var Tsa=s(Kye);ztt=r(Tsa,"longt5"),Tsa.forEach(t),Qtt=r(OHe," \u2014 "),Cae=n(OHe,"A",{href:!0});var Msa=s(Cae);Wtt=r(Msa,"FlaxLongT5Model"),Msa.forEach(t),Utt=r(OHe," (LongT5 model)"),OHe.forEach(t),Htt=i(ne),M6=n(ne,"LI",{});var VHe=s(M6);Zye=n(VHe,"STRONG",{});var Esa=s(Zye);Jtt=r(Esa,"marian"),Esa.forEach(t),Ytt=r(VHe," \u2014 "),wae=n(VHe,"A",{href:!0});var Csa=s(wae);Ktt=r(Csa,"FlaxMarianModel"),Csa.forEach(t),Ztt=r(VHe," (Marian model)"),VHe.forEach(t),eat=i(ne),E6=n(ne,"LI",{});var XHe=s(E6);e8e=n(XHe,"STRONG",{});var wsa=s(e8e);oat=r(wsa,"mbart"),wsa.forEach(t),rat=r(XHe," \u2014 "),Aae=n(XHe,"A",{href:!0});var Asa=s(Aae);tat=r(Asa,"FlaxMBartModel"),Asa.forEach(t),aat=r(XHe," (mBART model)"),XHe.forEach(t),nat=i(ne),C6=n(ne,"LI",{});var zHe=s(C6);o8e=n(zHe,"STRONG",{});var Lsa=s(o8e);sat=r(Lsa,"mt5"),Lsa.forEach(t),lat=r(zHe," \u2014 "),Lae=n(zHe,"A",{href:!0});var ysa=s(Lae);iat=r(ysa,"FlaxMT5Model"),ysa.forEach(t),dat=r(zHe," (MT5 model)"),zHe.forEach(t),cat=i(ne),w6=n(ne,"LI",{});var QHe=s(w6);r8e=n(QHe,"STRONG",{});var xsa=s(r8e);fat=r(xsa,"opt"),xsa.forEach(t),mat=r(QHe," \u2014 "),yae=n(QHe,"A",{href:!0});var $sa=s(yae);gat=r($sa,"FlaxOPTModel"),$sa.forEach(t),hat=r(QHe," (OPT model)"),QHe.forEach(t),uat=i(ne),A6=n(ne,"LI",{});var WHe=s(A6);t8e=n(WHe,"STRONG",{});var ksa=s(t8e);pat=r(ksa,"pegasus"),ksa.forEach(t),_at=r(WHe," \u2014 "),xae=n(WHe,"A",{href:!0});var Ssa=s(xae);vat=r(Ssa,"FlaxPegasusModel"),Ssa.forEach(t),bat=r(WHe," (Pegasus model)"),WHe.forEach(t),Fat=i(ne),L6=n(ne,"LI",{});var UHe=s(L6);a8e=n(UHe,"STRONG",{});var Rsa=s(a8e);Tat=r(Rsa,"roberta"),Rsa.forEach(t),Mat=r(UHe," \u2014 "),$ae=n(UHe,"A",{href:!0});var Psa=s($ae);Eat=r(Psa,"FlaxRobertaModel"),Psa.forEach(t),Cat=r(UHe," (RoBERTa model)"),UHe.forEach(t),wat=i(ne),y6=n(ne,"LI",{});var HHe=s(y6);n8e=n(HHe,"STRONG",{});var Bsa=s(n8e);Aat=r(Bsa,"roformer"),Bsa.forEach(t),Lat=r(HHe," \u2014 "),kae=n(HHe,"A",{href:!0});var Isa=s(kae);yat=r(Isa,"FlaxRoFormerModel"),Isa.forEach(t),xat=r(HHe," (RoFormer model)"),HHe.forEach(t),$at=i(ne),x6=n(ne,"LI",{});var JHe=s(x6);s8e=n(JHe,"STRONG",{});var Nsa=s(s8e);kat=r(Nsa,"t5"),Nsa.forEach(t),Sat=r(JHe," \u2014 "),Sae=n(JHe,"A",{href:!0});var qsa=s(Sae);Rat=r(qsa,"FlaxT5Model"),qsa.forEach(t),Pat=r(JHe," (T5 model)"),JHe.forEach(t),Bat=i(ne),$6=n(ne,"LI",{});var YHe=s($6);l8e=n(YHe,"STRONG",{});var jsa=s(l8e);Iat=r(jsa,"vision-text-dual-encoder"),jsa.forEach(t),Nat=r(YHe," \u2014 "),Rae=n(YHe,"A",{href:!0});var Dsa=s(Rae);qat=r(Dsa,"FlaxVisionTextDualEncoderModel"),Dsa.forEach(t),jat=r(YHe," (VisionTextDualEncoder model)"),YHe.forEach(t),Dat=i(ne),k6=n(ne,"LI",{});var KHe=s(k6);i8e=n(KHe,"STRONG",{});var Gsa=s(i8e);Gat=r(Gsa,"vit"),Gsa.forEach(t),Oat=r(KHe," \u2014 "),Pae=n(KHe,"A",{href:!0});var Osa=s(Pae);Vat=r(Osa,"FlaxViTModel"),Osa.forEach(t),Xat=r(KHe," (ViT model)"),KHe.forEach(t),zat=i(ne),S6=n(ne,"LI",{});var ZHe=s(S6);d8e=n(ZHe,"STRONG",{});var Vsa=s(d8e);Qat=r(Vsa,"wav2vec2"),Vsa.forEach(t),Wat=r(ZHe," \u2014 "),Bae=n(ZHe,"A",{href:!0});var Xsa=s(Bae);Uat=r(Xsa,"FlaxWav2Vec2Model"),Xsa.forEach(t),Hat=r(ZHe," (Wav2Vec2 model)"),ZHe.forEach(t),Jat=i(ne),R6=n(ne,"LI",{});var eJe=s(R6);c8e=n(eJe,"STRONG",{});var zsa=s(c8e);Yat=r(zsa,"xglm"),zsa.forEach(t),Kat=r(eJe," \u2014 "),Iae=n(eJe,"A",{href:!0});var Qsa=s(Iae);Zat=r(Qsa,"FlaxXGLMModel"),Qsa.forEach(t),ent=r(eJe," (XGLM model)"),eJe.forEach(t),ont=i(ne),P6=n(ne,"LI",{});var oJe=s(P6);f8e=n(oJe,"STRONG",{});var Wsa=s(f8e);rnt=r(Wsa,"xlm-roberta"),Wsa.forEach(t),tnt=r(oJe," \u2014 "),Nae=n(oJe,"A",{href:!0});var Usa=s(Nae);ant=r(Usa,"FlaxXLMRobertaModel"),Usa.forEach(t),nnt=r(oJe," (XLM-RoBERTa model)"),oJe.forEach(t),ne.forEach(t),snt=i(Ri),T(B6.$$.fragment,Ri),Ri.forEach(t),Si.forEach(t),MZe=i(f),Df=n(f,"H2",{class:!0});var joo=s(Df);I6=n(joo,"A",{id:!0,class:!0,href:!0});var Hsa=s(I6);m8e=n(Hsa,"SPAN",{});var Jsa=s(m8e);T(YS.$$.fragment,Jsa),Jsa.forEach(t),Hsa.forEach(t),lnt=i(joo),g8e=n(joo,"SPAN",{});var Ysa=s(g8e);int=r(Ysa,"FlaxAutoModelForCausalLM"),Ysa.forEach(t),joo.forEach(t),EZe=i(f),Er=n(f,"DIV",{class:!0});var Pi=s(Er);T(KS.$$.fragment,Pi),dnt=i(Pi),Gf=n(Pi,"P",{});var Lie=s(Gf);cnt=r(Lie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),qae=n(Lie,"A",{href:!0});var Ksa=s(qae);fnt=r(Ksa,"from_pretrained()"),Ksa.forEach(t),mnt=r(Lie," class method or the "),jae=n(Lie,"A",{href:!0});var Zsa=s(jae);gnt=r(Zsa,"from_config()"),Zsa.forEach(t),hnt=r(Lie,` class
method.`),Lie.forEach(t),unt=i(Pi),ZS=n(Pi,"P",{});var Doo=s(ZS);pnt=r(Doo,"This class cannot be instantiated directly using "),h8e=n(Doo,"CODE",{});var ela=s(h8e);_nt=r(ela,"__init__()"),ela.forEach(t),vnt=r(Doo," (throws an error)."),Doo.forEach(t),bnt=i(Pi),la=n(Pi,"DIV",{class:!0});var Y8=s(la);T(eR.$$.fragment,Y8),Fnt=i(Y8),u8e=n(Y8,"P",{});var ola=s(u8e);Tnt=r(ola,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ola.forEach(t),Mnt=i(Y8),Of=n(Y8,"P",{});var yie=s(Of);Ent=r(yie,`Note:
Loading a model from its configuration file does `),p8e=n(yie,"STRONG",{});var rla=s(p8e);Cnt=r(rla,"not"),rla.forEach(t),wnt=r(yie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Dae=n(yie,"A",{href:!0});var tla=s(Dae);Ant=r(tla,"from_pretrained()"),tla.forEach(t),Lnt=r(yie," to load the model weights."),yie.forEach(t),ynt=i(Y8),T(N6.$$.fragment,Y8),Y8.forEach(t),xnt=i(Pi),Zr=n(Pi,"DIV",{class:!0});var Bi=s(Zr);T(oR.$$.fragment,Bi),$nt=i(Bi),_8e=n(Bi,"P",{});var ala=s(_8e);knt=r(ala,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),ala.forEach(t),Snt=i(Bi),Gn=n(Bi,"P",{});var K8=s(Gn);Rnt=r(K8,"The model class to instantiate is selected based on the "),v8e=n(K8,"CODE",{});var nla=s(v8e);Pnt=r(nla,"model_type"),nla.forEach(t),Bnt=r(K8,` property of the config object (either
passed as an argument or loaded from `),b8e=n(K8,"CODE",{});var sla=s(b8e);Int=r(sla,"pretrained_model_name_or_path"),sla.forEach(t),Nnt=r(K8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F8e=n(K8,"CODE",{});var lla=s(F8e);qnt=r(lla,"pretrained_model_name_or_path"),lla.forEach(t),jnt=r(K8,":"),K8.forEach(t),Dnt=i(Bi),xe=n(Bi,"UL",{});var qe=s(xe);q6=n(qe,"LI",{});var rJe=s(q6);T8e=n(rJe,"STRONG",{});var ila=s(T8e);Gnt=r(ila,"bart"),ila.forEach(t),Ont=r(rJe," \u2014 "),Gae=n(rJe,"A",{href:!0});var dla=s(Gae);Vnt=r(dla,"FlaxBartForCausalLM"),dla.forEach(t),Xnt=r(rJe," (BART model)"),rJe.forEach(t),znt=i(qe),j6=n(qe,"LI",{});var tJe=s(j6);M8e=n(tJe,"STRONG",{});var cla=s(M8e);Qnt=r(cla,"bert"),cla.forEach(t),Wnt=r(tJe," \u2014 "),Oae=n(tJe,"A",{href:!0});var fla=s(Oae);Unt=r(fla,"FlaxBertForCausalLM"),fla.forEach(t),Hnt=r(tJe," (BERT model)"),tJe.forEach(t),Jnt=i(qe),D6=n(qe,"LI",{});var aJe=s(D6);E8e=n(aJe,"STRONG",{});var mla=s(E8e);Ynt=r(mla,"big_bird"),mla.forEach(t),Knt=r(aJe," \u2014 "),Vae=n(aJe,"A",{href:!0});var gla=s(Vae);Znt=r(gla,"FlaxBigBirdForCausalLM"),gla.forEach(t),est=r(aJe," (BigBird model)"),aJe.forEach(t),ost=i(qe),G6=n(qe,"LI",{});var nJe=s(G6);C8e=n(nJe,"STRONG",{});var hla=s(C8e);rst=r(hla,"electra"),hla.forEach(t),tst=r(nJe," \u2014 "),Xae=n(nJe,"A",{href:!0});var ula=s(Xae);ast=r(ula,"FlaxElectraForCausalLM"),ula.forEach(t),nst=r(nJe," (ELECTRA model)"),nJe.forEach(t),sst=i(qe),O6=n(qe,"LI",{});var sJe=s(O6);w8e=n(sJe,"STRONG",{});var pla=s(w8e);lst=r(pla,"gpt2"),pla.forEach(t),ist=r(sJe," \u2014 "),zae=n(sJe,"A",{href:!0});var _la=s(zae);dst=r(_la,"FlaxGPT2LMHeadModel"),_la.forEach(t),cst=r(sJe," (OpenAI GPT-2 model)"),sJe.forEach(t),fst=i(qe),V6=n(qe,"LI",{});var lJe=s(V6);A8e=n(lJe,"STRONG",{});var vla=s(A8e);mst=r(vla,"gpt_neo"),vla.forEach(t),gst=r(lJe," \u2014 "),Qae=n(lJe,"A",{href:!0});var bla=s(Qae);hst=r(bla,"FlaxGPTNeoForCausalLM"),bla.forEach(t),ust=r(lJe," (GPT Neo model)"),lJe.forEach(t),pst=i(qe),X6=n(qe,"LI",{});var iJe=s(X6);L8e=n(iJe,"STRONG",{});var Fla=s(L8e);_st=r(Fla,"gptj"),Fla.forEach(t),vst=r(iJe," \u2014 "),Wae=n(iJe,"A",{href:!0});var Tla=s(Wae);bst=r(Tla,"FlaxGPTJForCausalLM"),Tla.forEach(t),Fst=r(iJe," (GPT-J model)"),iJe.forEach(t),Tst=i(qe),z6=n(qe,"LI",{});var dJe=s(z6);y8e=n(dJe,"STRONG",{});var Mla=s(y8e);Mst=r(Mla,"opt"),Mla.forEach(t),Est=r(dJe," \u2014 "),Uae=n(dJe,"A",{href:!0});var Ela=s(Uae);Cst=r(Ela,"FlaxOPTForCausalLM"),Ela.forEach(t),wst=r(dJe," (OPT model)"),dJe.forEach(t),Ast=i(qe),Q6=n(qe,"LI",{});var cJe=s(Q6);x8e=n(cJe,"STRONG",{});var Cla=s(x8e);Lst=r(Cla,"roberta"),Cla.forEach(t),yst=r(cJe," \u2014 "),Hae=n(cJe,"A",{href:!0});var wla=s(Hae);xst=r(wla,"FlaxRobertaForCausalLM"),wla.forEach(t),$st=r(cJe," (RoBERTa model)"),cJe.forEach(t),kst=i(qe),W6=n(qe,"LI",{});var fJe=s(W6);$8e=n(fJe,"STRONG",{});var Ala=s($8e);Sst=r(Ala,"xglm"),Ala.forEach(t),Rst=r(fJe," \u2014 "),Jae=n(fJe,"A",{href:!0});var Lla=s(Jae);Pst=r(Lla,"FlaxXGLMForCausalLM"),Lla.forEach(t),Bst=r(fJe," (XGLM model)"),fJe.forEach(t),qe.forEach(t),Ist=i(Bi),T(U6.$$.fragment,Bi),Bi.forEach(t),Pi.forEach(t),CZe=i(f),Vf=n(f,"H2",{class:!0});var Goo=s(Vf);H6=n(Goo,"A",{id:!0,class:!0,href:!0});var yla=s(H6);k8e=n(yla,"SPAN",{});var xla=s(k8e);T(rR.$$.fragment,xla),xla.forEach(t),yla.forEach(t),Nst=i(Goo),S8e=n(Goo,"SPAN",{});var $la=s(S8e);qst=r($la,"FlaxAutoModelForPreTraining"),$la.forEach(t),Goo.forEach(t),wZe=i(f),Cr=n(f,"DIV",{class:!0});var Ii=s(Cr);T(tR.$$.fragment,Ii),jst=i(Ii),Xf=n(Ii,"P",{});var xie=s(Xf);Dst=r(xie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Yae=n(xie,"A",{href:!0});var kla=s(Yae);Gst=r(kla,"from_pretrained()"),kla.forEach(t),Ost=r(xie," class method or the "),Kae=n(xie,"A",{href:!0});var Sla=s(Kae);Vst=r(Sla,"from_config()"),Sla.forEach(t),Xst=r(xie,` class
method.`),xie.forEach(t),zst=i(Ii),aR=n(Ii,"P",{});var Ooo=s(aR);Qst=r(Ooo,"This class cannot be instantiated directly using "),R8e=n(Ooo,"CODE",{});var Rla=s(R8e);Wst=r(Rla,"__init__()"),Rla.forEach(t),Ust=r(Ooo," (throws an error)."),Ooo.forEach(t),Hst=i(Ii),ia=n(Ii,"DIV",{class:!0});var Z8=s(ia);T(nR.$$.fragment,Z8),Jst=i(Z8),P8e=n(Z8,"P",{});var Pla=s(P8e);Yst=r(Pla,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Pla.forEach(t),Kst=i(Z8),zf=n(Z8,"P",{});var $ie=s(zf);Zst=r($ie,`Note:
Loading a model from its configuration file does `),B8e=n($ie,"STRONG",{});var Bla=s(B8e);elt=r(Bla,"not"),Bla.forEach(t),olt=r($ie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zae=n($ie,"A",{href:!0});var Ila=s(Zae);rlt=r(Ila,"from_pretrained()"),Ila.forEach(t),tlt=r($ie," to load the model weights."),$ie.forEach(t),alt=i(Z8),T(J6.$$.fragment,Z8),Z8.forEach(t),nlt=i(Ii),et=n(Ii,"DIV",{class:!0});var Ni=s(et);T(sR.$$.fragment,Ni),slt=i(Ni),I8e=n(Ni,"P",{});var Nla=s(I8e);llt=r(Nla,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Nla.forEach(t),ilt=i(Ni),On=n(Ni,"P",{});var e9=s(On);dlt=r(e9,"The model class to instantiate is selected based on the "),N8e=n(e9,"CODE",{});var qla=s(N8e);clt=r(qla,"model_type"),qla.forEach(t),flt=r(e9,` property of the config object (either
passed as an argument or loaded from `),q8e=n(e9,"CODE",{});var jla=s(q8e);mlt=r(jla,"pretrained_model_name_or_path"),jla.forEach(t),glt=r(e9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j8e=n(e9,"CODE",{});var Dla=s(j8e);hlt=r(Dla,"pretrained_model_name_or_path"),Dla.forEach(t),ult=r(e9,":"),e9.forEach(t),plt=i(Ni),Ee=n(Ni,"UL",{});var we=s(Ee);Y6=n(we,"LI",{});var mJe=s(Y6);D8e=n(mJe,"STRONG",{});var Gla=s(D8e);_lt=r(Gla,"albert"),Gla.forEach(t),vlt=r(mJe," \u2014 "),ene=n(mJe,"A",{href:!0});var Ola=s(ene);blt=r(Ola,"FlaxAlbertForPreTraining"),Ola.forEach(t),Flt=r(mJe," (ALBERT model)"),mJe.forEach(t),Tlt=i(we),K6=n(we,"LI",{});var gJe=s(K6);G8e=n(gJe,"STRONG",{});var Vla=s(G8e);Mlt=r(Vla,"bart"),Vla.forEach(t),Elt=r(gJe," \u2014 "),one=n(gJe,"A",{href:!0});var Xla=s(one);Clt=r(Xla,"FlaxBartForConditionalGeneration"),Xla.forEach(t),wlt=r(gJe," (BART model)"),gJe.forEach(t),Alt=i(we),Z6=n(we,"LI",{});var hJe=s(Z6);O8e=n(hJe,"STRONG",{});var zla=s(O8e);Llt=r(zla,"bert"),zla.forEach(t),ylt=r(hJe," \u2014 "),rne=n(hJe,"A",{href:!0});var Qla=s(rne);xlt=r(Qla,"FlaxBertForPreTraining"),Qla.forEach(t),$lt=r(hJe," (BERT model)"),hJe.forEach(t),klt=i(we),e7=n(we,"LI",{});var uJe=s(e7);V8e=n(uJe,"STRONG",{});var Wla=s(V8e);Slt=r(Wla,"big_bird"),Wla.forEach(t),Rlt=r(uJe," \u2014 "),tne=n(uJe,"A",{href:!0});var Ula=s(tne);Plt=r(Ula,"FlaxBigBirdForPreTraining"),Ula.forEach(t),Blt=r(uJe," (BigBird model)"),uJe.forEach(t),Ilt=i(we),o7=n(we,"LI",{});var pJe=s(o7);X8e=n(pJe,"STRONG",{});var Hla=s(X8e);Nlt=r(Hla,"electra"),Hla.forEach(t),qlt=r(pJe," \u2014 "),ane=n(pJe,"A",{href:!0});var Jla=s(ane);jlt=r(Jla,"FlaxElectraForPreTraining"),Jla.forEach(t),Dlt=r(pJe," (ELECTRA model)"),pJe.forEach(t),Glt=i(we),r7=n(we,"LI",{});var _Je=s(r7);z8e=n(_Je,"STRONG",{});var Yla=s(z8e);Olt=r(Yla,"longt5"),Yla.forEach(t),Vlt=r(_Je," \u2014 "),nne=n(_Je,"A",{href:!0});var Kla=s(nne);Xlt=r(Kla,"FlaxLongT5ForConditionalGeneration"),Kla.forEach(t),zlt=r(_Je," (LongT5 model)"),_Je.forEach(t),Qlt=i(we),t7=n(we,"LI",{});var vJe=s(t7);Q8e=n(vJe,"STRONG",{});var Zla=s(Q8e);Wlt=r(Zla,"mbart"),Zla.forEach(t),Ult=r(vJe," \u2014 "),sne=n(vJe,"A",{href:!0});var eia=s(sne);Hlt=r(eia,"FlaxMBartForConditionalGeneration"),eia.forEach(t),Jlt=r(vJe," (mBART model)"),vJe.forEach(t),Ylt=i(we),a7=n(we,"LI",{});var bJe=s(a7);W8e=n(bJe,"STRONG",{});var oia=s(W8e);Klt=r(oia,"mt5"),oia.forEach(t),Zlt=r(bJe," \u2014 "),lne=n(bJe,"A",{href:!0});var ria=s(lne);eit=r(ria,"FlaxMT5ForConditionalGeneration"),ria.forEach(t),oit=r(bJe," (MT5 model)"),bJe.forEach(t),rit=i(we),n7=n(we,"LI",{});var FJe=s(n7);U8e=n(FJe,"STRONG",{});var tia=s(U8e);tit=r(tia,"roberta"),tia.forEach(t),ait=r(FJe," \u2014 "),ine=n(FJe,"A",{href:!0});var aia=s(ine);nit=r(aia,"FlaxRobertaForMaskedLM"),aia.forEach(t),sit=r(FJe," (RoBERTa model)"),FJe.forEach(t),lit=i(we),s7=n(we,"LI",{});var TJe=s(s7);H8e=n(TJe,"STRONG",{});var nia=s(H8e);iit=r(nia,"roformer"),nia.forEach(t),dit=r(TJe," \u2014 "),dne=n(TJe,"A",{href:!0});var sia=s(dne);cit=r(sia,"FlaxRoFormerForMaskedLM"),sia.forEach(t),fit=r(TJe," (RoFormer model)"),TJe.forEach(t),mit=i(we),l7=n(we,"LI",{});var MJe=s(l7);J8e=n(MJe,"STRONG",{});var lia=s(J8e);git=r(lia,"t5"),lia.forEach(t),hit=r(MJe," \u2014 "),cne=n(MJe,"A",{href:!0});var iia=s(cne);uit=r(iia,"FlaxT5ForConditionalGeneration"),iia.forEach(t),pit=r(MJe," (T5 model)"),MJe.forEach(t),_it=i(we),i7=n(we,"LI",{});var EJe=s(i7);Y8e=n(EJe,"STRONG",{});var dia=s(Y8e);vit=r(dia,"wav2vec2"),dia.forEach(t),bit=r(EJe," \u2014 "),fne=n(EJe,"A",{href:!0});var cia=s(fne);Fit=r(cia,"FlaxWav2Vec2ForPreTraining"),cia.forEach(t),Tit=r(EJe," (Wav2Vec2 model)"),EJe.forEach(t),Mit=i(we),d7=n(we,"LI",{});var CJe=s(d7);K8e=n(CJe,"STRONG",{});var fia=s(K8e);Eit=r(fia,"xlm-roberta"),fia.forEach(t),Cit=r(CJe," \u2014 "),mne=n(CJe,"A",{href:!0});var mia=s(mne);wit=r(mia,"FlaxXLMRobertaForMaskedLM"),mia.forEach(t),Ait=r(CJe," (XLM-RoBERTa model)"),CJe.forEach(t),we.forEach(t),Lit=i(Ni),T(c7.$$.fragment,Ni),Ni.forEach(t),Ii.forEach(t),AZe=i(f),Qf=n(f,"H2",{class:!0});var Voo=s(Qf);f7=n(Voo,"A",{id:!0,class:!0,href:!0});var gia=s(f7);Z8e=n(gia,"SPAN",{});var hia=s(Z8e);T(lR.$$.fragment,hia),hia.forEach(t),gia.forEach(t),yit=i(Voo),e9e=n(Voo,"SPAN",{});var uia=s(e9e);xit=r(uia,"FlaxAutoModelForMaskedLM"),uia.forEach(t),Voo.forEach(t),LZe=i(f),wr=n(f,"DIV",{class:!0});var qi=s(wr);T(iR.$$.fragment,qi),$it=i(qi),Wf=n(qi,"P",{});var kie=s(Wf);kit=r(kie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),gne=n(kie,"A",{href:!0});var pia=s(gne);Sit=r(pia,"from_pretrained()"),pia.forEach(t),Rit=r(kie," class method or the "),hne=n(kie,"A",{href:!0});var _ia=s(hne);Pit=r(_ia,"from_config()"),_ia.forEach(t),Bit=r(kie,` class
method.`),kie.forEach(t),Iit=i(qi),dR=n(qi,"P",{});var Xoo=s(dR);Nit=r(Xoo,"This class cannot be instantiated directly using "),o9e=n(Xoo,"CODE",{});var via=s(o9e);qit=r(via,"__init__()"),via.forEach(t),jit=r(Xoo," (throws an error)."),Xoo.forEach(t),Dit=i(qi),da=n(qi,"DIV",{class:!0});var o9=s(da);T(cR.$$.fragment,o9),Git=i(o9),r9e=n(o9,"P",{});var bia=s(r9e);Oit=r(bia,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),bia.forEach(t),Vit=i(o9),Uf=n(o9,"P",{});var Sie=s(Uf);Xit=r(Sie,`Note:
Loading a model from its configuration file does `),t9e=n(Sie,"STRONG",{});var Fia=s(t9e);zit=r(Fia,"not"),Fia.forEach(t),Qit=r(Sie,` load the model weights. It only affects the
model\u2019s configuration. Use `),une=n(Sie,"A",{href:!0});var Tia=s(une);Wit=r(Tia,"from_pretrained()"),Tia.forEach(t),Uit=r(Sie," to load the model weights."),Sie.forEach(t),Hit=i(o9),T(m7.$$.fragment,o9),o9.forEach(t),Jit=i(qi),ot=n(qi,"DIV",{class:!0});var ji=s(ot);T(fR.$$.fragment,ji),Yit=i(ji),a9e=n(ji,"P",{});var Mia=s(a9e);Kit=r(Mia,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Mia.forEach(t),Zit=i(ji),Vn=n(ji,"P",{});var r9=s(Vn);edt=r(r9,"The model class to instantiate is selected based on the "),n9e=n(r9,"CODE",{});var Eia=s(n9e);odt=r(Eia,"model_type"),Eia.forEach(t),rdt=r(r9,` property of the config object (either
passed as an argument or loaded from `),s9e=n(r9,"CODE",{});var Cia=s(s9e);tdt=r(Cia,"pretrained_model_name_or_path"),Cia.forEach(t),adt=r(r9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l9e=n(r9,"CODE",{});var wia=s(l9e);ndt=r(wia,"pretrained_model_name_or_path"),wia.forEach(t),sdt=r(r9,":"),r9.forEach(t),ldt=i(ji),$e=n(ji,"UL",{});var je=s($e);g7=n(je,"LI",{});var wJe=s(g7);i9e=n(wJe,"STRONG",{});var Aia=s(i9e);idt=r(Aia,"albert"),Aia.forEach(t),ddt=r(wJe," \u2014 "),pne=n(wJe,"A",{href:!0});var Lia=s(pne);cdt=r(Lia,"FlaxAlbertForMaskedLM"),Lia.forEach(t),fdt=r(wJe," (ALBERT model)"),wJe.forEach(t),mdt=i(je),h7=n(je,"LI",{});var AJe=s(h7);d9e=n(AJe,"STRONG",{});var yia=s(d9e);gdt=r(yia,"bart"),yia.forEach(t),hdt=r(AJe," \u2014 "),_ne=n(AJe,"A",{href:!0});var xia=s(_ne);udt=r(xia,"FlaxBartForConditionalGeneration"),xia.forEach(t),pdt=r(AJe," (BART model)"),AJe.forEach(t),_dt=i(je),u7=n(je,"LI",{});var LJe=s(u7);c9e=n(LJe,"STRONG",{});var $ia=s(c9e);vdt=r($ia,"bert"),$ia.forEach(t),bdt=r(LJe," \u2014 "),vne=n(LJe,"A",{href:!0});var kia=s(vne);Fdt=r(kia,"FlaxBertForMaskedLM"),kia.forEach(t),Tdt=r(LJe," (BERT model)"),LJe.forEach(t),Mdt=i(je),p7=n(je,"LI",{});var yJe=s(p7);f9e=n(yJe,"STRONG",{});var Sia=s(f9e);Edt=r(Sia,"big_bird"),Sia.forEach(t),Cdt=r(yJe," \u2014 "),bne=n(yJe,"A",{href:!0});var Ria=s(bne);wdt=r(Ria,"FlaxBigBirdForMaskedLM"),Ria.forEach(t),Adt=r(yJe," (BigBird model)"),yJe.forEach(t),Ldt=i(je),_7=n(je,"LI",{});var xJe=s(_7);m9e=n(xJe,"STRONG",{});var Pia=s(m9e);ydt=r(Pia,"distilbert"),Pia.forEach(t),xdt=r(xJe," \u2014 "),Fne=n(xJe,"A",{href:!0});var Bia=s(Fne);$dt=r(Bia,"FlaxDistilBertForMaskedLM"),Bia.forEach(t),kdt=r(xJe," (DistilBERT model)"),xJe.forEach(t),Sdt=i(je),v7=n(je,"LI",{});var $Je=s(v7);g9e=n($Je,"STRONG",{});var Iia=s(g9e);Rdt=r(Iia,"electra"),Iia.forEach(t),Pdt=r($Je," \u2014 "),Tne=n($Je,"A",{href:!0});var Nia=s(Tne);Bdt=r(Nia,"FlaxElectraForMaskedLM"),Nia.forEach(t),Idt=r($Je," (ELECTRA model)"),$Je.forEach(t),Ndt=i(je),b7=n(je,"LI",{});var kJe=s(b7);h9e=n(kJe,"STRONG",{});var qia=s(h9e);qdt=r(qia,"mbart"),qia.forEach(t),jdt=r(kJe," \u2014 "),Mne=n(kJe,"A",{href:!0});var jia=s(Mne);Ddt=r(jia,"FlaxMBartForConditionalGeneration"),jia.forEach(t),Gdt=r(kJe," (mBART model)"),kJe.forEach(t),Odt=i(je),F7=n(je,"LI",{});var SJe=s(F7);u9e=n(SJe,"STRONG",{});var Dia=s(u9e);Vdt=r(Dia,"roberta"),Dia.forEach(t),Xdt=r(SJe," \u2014 "),Ene=n(SJe,"A",{href:!0});var Gia=s(Ene);zdt=r(Gia,"FlaxRobertaForMaskedLM"),Gia.forEach(t),Qdt=r(SJe," (RoBERTa model)"),SJe.forEach(t),Wdt=i(je),T7=n(je,"LI",{});var RJe=s(T7);p9e=n(RJe,"STRONG",{});var Oia=s(p9e);Udt=r(Oia,"roformer"),Oia.forEach(t),Hdt=r(RJe," \u2014 "),Cne=n(RJe,"A",{href:!0});var Via=s(Cne);Jdt=r(Via,"FlaxRoFormerForMaskedLM"),Via.forEach(t),Ydt=r(RJe," (RoFormer model)"),RJe.forEach(t),Kdt=i(je),M7=n(je,"LI",{});var PJe=s(M7);_9e=n(PJe,"STRONG",{});var Xia=s(_9e);Zdt=r(Xia,"xlm-roberta"),Xia.forEach(t),ect=r(PJe," \u2014 "),wne=n(PJe,"A",{href:!0});var zia=s(wne);oct=r(zia,"FlaxXLMRobertaForMaskedLM"),zia.forEach(t),rct=r(PJe," (XLM-RoBERTa model)"),PJe.forEach(t),je.forEach(t),tct=i(ji),T(E7.$$.fragment,ji),ji.forEach(t),qi.forEach(t),yZe=i(f),Hf=n(f,"H2",{class:!0});var zoo=s(Hf);C7=n(zoo,"A",{id:!0,class:!0,href:!0});var Qia=s(C7);v9e=n(Qia,"SPAN",{});var Wia=s(v9e);T(mR.$$.fragment,Wia),Wia.forEach(t),Qia.forEach(t),act=i(zoo),b9e=n(zoo,"SPAN",{});var Uia=s(b9e);nct=r(Uia,"FlaxAutoModelForSeq2SeqLM"),Uia.forEach(t),zoo.forEach(t),xZe=i(f),Ar=n(f,"DIV",{class:!0});var Di=s(Ar);T(gR.$$.fragment,Di),sct=i(Di),Jf=n(Di,"P",{});var Rie=s(Jf);lct=r(Rie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Ane=n(Rie,"A",{href:!0});var Hia=s(Ane);ict=r(Hia,"from_pretrained()"),Hia.forEach(t),dct=r(Rie," class method or the "),Lne=n(Rie,"A",{href:!0});var Jia=s(Lne);cct=r(Jia,"from_config()"),Jia.forEach(t),fct=r(Rie,` class
method.`),Rie.forEach(t),mct=i(Di),hR=n(Di,"P",{});var Qoo=s(hR);gct=r(Qoo,"This class cannot be instantiated directly using "),F9e=n(Qoo,"CODE",{});var Yia=s(F9e);hct=r(Yia,"__init__()"),Yia.forEach(t),uct=r(Qoo," (throws an error)."),Qoo.forEach(t),pct=i(Di),ca=n(Di,"DIV",{class:!0});var t9=s(ca);T(uR.$$.fragment,t9),_ct=i(t9),T9e=n(t9,"P",{});var Kia=s(T9e);vct=r(Kia,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Kia.forEach(t),bct=i(t9),Yf=n(t9,"P",{});var Pie=s(Yf);Fct=r(Pie,`Note:
Loading a model from its configuration file does `),M9e=n(Pie,"STRONG",{});var Zia=s(M9e);Tct=r(Zia,"not"),Zia.forEach(t),Mct=r(Pie,` load the model weights. It only affects the
model\u2019s configuration. Use `),yne=n(Pie,"A",{href:!0});var eda=s(yne);Ect=r(eda,"from_pretrained()"),eda.forEach(t),Cct=r(Pie," to load the model weights."),Pie.forEach(t),wct=i(t9),T(w7.$$.fragment,t9),t9.forEach(t),Act=i(Di),rt=n(Di,"DIV",{class:!0});var Gi=s(rt);T(pR.$$.fragment,Gi),Lct=i(Gi),E9e=n(Gi,"P",{});var oda=s(E9e);yct=r(oda,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),oda.forEach(t),xct=i(Gi),Xn=n(Gi,"P",{});var a9=s(Xn);$ct=r(a9,"The model class to instantiate is selected based on the "),C9e=n(a9,"CODE",{});var rda=s(C9e);kct=r(rda,"model_type"),rda.forEach(t),Sct=r(a9,` property of the config object (either
passed as an argument or loaded from `),w9e=n(a9,"CODE",{});var tda=s(w9e);Rct=r(tda,"pretrained_model_name_or_path"),tda.forEach(t),Pct=r(a9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A9e=n(a9,"CODE",{});var ada=s(A9e);Bct=r(ada,"pretrained_model_name_or_path"),ada.forEach(t),Ict=r(a9,":"),a9.forEach(t),Nct=i(Gi),ke=n(Gi,"UL",{});var De=s(ke);A7=n(De,"LI",{});var BJe=s(A7);L9e=n(BJe,"STRONG",{});var nda=s(L9e);qct=r(nda,"bart"),nda.forEach(t),jct=r(BJe," \u2014 "),xne=n(BJe,"A",{href:!0});var sda=s(xne);Dct=r(sda,"FlaxBartForConditionalGeneration"),sda.forEach(t),Gct=r(BJe," (BART model)"),BJe.forEach(t),Oct=i(De),L7=n(De,"LI",{});var IJe=s(L7);y9e=n(IJe,"STRONG",{});var lda=s(y9e);Vct=r(lda,"blenderbot"),lda.forEach(t),Xct=r(IJe," \u2014 "),$ne=n(IJe,"A",{href:!0});var ida=s($ne);zct=r(ida,"FlaxBlenderbotForConditionalGeneration"),ida.forEach(t),Qct=r(IJe," (Blenderbot model)"),IJe.forEach(t),Wct=i(De),y7=n(De,"LI",{});var NJe=s(y7);x9e=n(NJe,"STRONG",{});var dda=s(x9e);Uct=r(dda,"blenderbot-small"),dda.forEach(t),Hct=r(NJe," \u2014 "),kne=n(NJe,"A",{href:!0});var cda=s(kne);Jct=r(cda,"FlaxBlenderbotSmallForConditionalGeneration"),cda.forEach(t),Yct=r(NJe," (BlenderbotSmall model)"),NJe.forEach(t),Kct=i(De),x7=n(De,"LI",{});var qJe=s(x7);$9e=n(qJe,"STRONG",{});var fda=s($9e);Zct=r(fda,"encoder-decoder"),fda.forEach(t),eft=r(qJe," \u2014 "),Sne=n(qJe,"A",{href:!0});var mda=s(Sne);oft=r(mda,"FlaxEncoderDecoderModel"),mda.forEach(t),rft=r(qJe," (Encoder decoder model)"),qJe.forEach(t),tft=i(De),$7=n(De,"LI",{});var jJe=s($7);k9e=n(jJe,"STRONG",{});var gda=s(k9e);aft=r(gda,"longt5"),gda.forEach(t),nft=r(jJe," \u2014 "),Rne=n(jJe,"A",{href:!0});var hda=s(Rne);sft=r(hda,"FlaxLongT5ForConditionalGeneration"),hda.forEach(t),lft=r(jJe," (LongT5 model)"),jJe.forEach(t),ift=i(De),k7=n(De,"LI",{});var DJe=s(k7);S9e=n(DJe,"STRONG",{});var uda=s(S9e);dft=r(uda,"marian"),uda.forEach(t),cft=r(DJe," \u2014 "),Pne=n(DJe,"A",{href:!0});var pda=s(Pne);fft=r(pda,"FlaxMarianMTModel"),pda.forEach(t),mft=r(DJe," (Marian model)"),DJe.forEach(t),gft=i(De),S7=n(De,"LI",{});var GJe=s(S7);R9e=n(GJe,"STRONG",{});var _da=s(R9e);hft=r(_da,"mbart"),_da.forEach(t),uft=r(GJe," \u2014 "),Bne=n(GJe,"A",{href:!0});var vda=s(Bne);pft=r(vda,"FlaxMBartForConditionalGeneration"),vda.forEach(t),_ft=r(GJe," (mBART model)"),GJe.forEach(t),vft=i(De),R7=n(De,"LI",{});var OJe=s(R7);P9e=n(OJe,"STRONG",{});var bda=s(P9e);bft=r(bda,"mt5"),bda.forEach(t),Fft=r(OJe," \u2014 "),Ine=n(OJe,"A",{href:!0});var Fda=s(Ine);Tft=r(Fda,"FlaxMT5ForConditionalGeneration"),Fda.forEach(t),Mft=r(OJe," (MT5 model)"),OJe.forEach(t),Eft=i(De),P7=n(De,"LI",{});var VJe=s(P7);B9e=n(VJe,"STRONG",{});var Tda=s(B9e);Cft=r(Tda,"pegasus"),Tda.forEach(t),wft=r(VJe," \u2014 "),Nne=n(VJe,"A",{href:!0});var Mda=s(Nne);Aft=r(Mda,"FlaxPegasusForConditionalGeneration"),Mda.forEach(t),Lft=r(VJe," (Pegasus model)"),VJe.forEach(t),yft=i(De),B7=n(De,"LI",{});var XJe=s(B7);I9e=n(XJe,"STRONG",{});var Eda=s(I9e);xft=r(Eda,"t5"),Eda.forEach(t),$ft=r(XJe," \u2014 "),qne=n(XJe,"A",{href:!0});var Cda=s(qne);kft=r(Cda,"FlaxT5ForConditionalGeneration"),Cda.forEach(t),Sft=r(XJe," (T5 model)"),XJe.forEach(t),De.forEach(t),Rft=i(Gi),T(I7.$$.fragment,Gi),Gi.forEach(t),Di.forEach(t),$Ze=i(f),Kf=n(f,"H2",{class:!0});var Woo=s(Kf);N7=n(Woo,"A",{id:!0,class:!0,href:!0});var wda=s(N7);N9e=n(wda,"SPAN",{});var Ada=s(N9e);T(_R.$$.fragment,Ada),Ada.forEach(t),wda.forEach(t),Pft=i(Woo),q9e=n(Woo,"SPAN",{});var Lda=s(q9e);Bft=r(Lda,"FlaxAutoModelForSequenceClassification"),Lda.forEach(t),Woo.forEach(t),kZe=i(f),Lr=n(f,"DIV",{class:!0});var Oi=s(Lr);T(vR.$$.fragment,Oi),Ift=i(Oi),Zf=n(Oi,"P",{});var Bie=s(Zf);Nft=r(Bie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),jne=n(Bie,"A",{href:!0});var yda=s(jne);qft=r(yda,"from_pretrained()"),yda.forEach(t),jft=r(Bie," class method or the "),Dne=n(Bie,"A",{href:!0});var xda=s(Dne);Dft=r(xda,"from_config()"),xda.forEach(t),Gft=r(Bie,` class
method.`),Bie.forEach(t),Oft=i(Oi),bR=n(Oi,"P",{});var Uoo=s(bR);Vft=r(Uoo,"This class cannot be instantiated directly using "),j9e=n(Uoo,"CODE",{});var $da=s(j9e);Xft=r($da,"__init__()"),$da.forEach(t),zft=r(Uoo," (throws an error)."),Uoo.forEach(t),Qft=i(Oi),fa=n(Oi,"DIV",{class:!0});var n9=s(fa);T(FR.$$.fragment,n9),Wft=i(n9),D9e=n(n9,"P",{});var kda=s(D9e);Uft=r(kda,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),kda.forEach(t),Hft=i(n9),em=n(n9,"P",{});var Iie=s(em);Jft=r(Iie,`Note:
Loading a model from its configuration file does `),G9e=n(Iie,"STRONG",{});var Sda=s(G9e);Yft=r(Sda,"not"),Sda.forEach(t),Kft=r(Iie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gne=n(Iie,"A",{href:!0});var Rda=s(Gne);Zft=r(Rda,"from_pretrained()"),Rda.forEach(t),emt=r(Iie," to load the model weights."),Iie.forEach(t),omt=i(n9),T(q7.$$.fragment,n9),n9.forEach(t),rmt=i(Oi),tt=n(Oi,"DIV",{class:!0});var Vi=s(tt);T(TR.$$.fragment,Vi),tmt=i(Vi),O9e=n(Vi,"P",{});var Pda=s(O9e);amt=r(Pda,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Pda.forEach(t),nmt=i(Vi),zn=n(Vi,"P",{});var s9=s(zn);smt=r(s9,"The model class to instantiate is selected based on the "),V9e=n(s9,"CODE",{});var Bda=s(V9e);lmt=r(Bda,"model_type"),Bda.forEach(t),imt=r(s9,` property of the config object (either
passed as an argument or loaded from `),X9e=n(s9,"CODE",{});var Ida=s(X9e);dmt=r(Ida,"pretrained_model_name_or_path"),Ida.forEach(t),cmt=r(s9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z9e=n(s9,"CODE",{});var Nda=s(z9e);fmt=r(Nda,"pretrained_model_name_or_path"),Nda.forEach(t),mmt=r(s9,":"),s9.forEach(t),gmt=i(Vi),Se=n(Vi,"UL",{});var Ge=s(Se);j7=n(Ge,"LI",{});var zJe=s(j7);Q9e=n(zJe,"STRONG",{});var qda=s(Q9e);hmt=r(qda,"albert"),qda.forEach(t),umt=r(zJe," \u2014 "),One=n(zJe,"A",{href:!0});var jda=s(One);pmt=r(jda,"FlaxAlbertForSequenceClassification"),jda.forEach(t),_mt=r(zJe," (ALBERT model)"),zJe.forEach(t),vmt=i(Ge),D7=n(Ge,"LI",{});var QJe=s(D7);W9e=n(QJe,"STRONG",{});var Dda=s(W9e);bmt=r(Dda,"bart"),Dda.forEach(t),Fmt=r(QJe," \u2014 "),Vne=n(QJe,"A",{href:!0});var Gda=s(Vne);Tmt=r(Gda,"FlaxBartForSequenceClassification"),Gda.forEach(t),Mmt=r(QJe," (BART model)"),QJe.forEach(t),Emt=i(Ge),G7=n(Ge,"LI",{});var WJe=s(G7);U9e=n(WJe,"STRONG",{});var Oda=s(U9e);Cmt=r(Oda,"bert"),Oda.forEach(t),wmt=r(WJe," \u2014 "),Xne=n(WJe,"A",{href:!0});var Vda=s(Xne);Amt=r(Vda,"FlaxBertForSequenceClassification"),Vda.forEach(t),Lmt=r(WJe," (BERT model)"),WJe.forEach(t),ymt=i(Ge),O7=n(Ge,"LI",{});var UJe=s(O7);H9e=n(UJe,"STRONG",{});var Xda=s(H9e);xmt=r(Xda,"big_bird"),Xda.forEach(t),$mt=r(UJe," \u2014 "),zne=n(UJe,"A",{href:!0});var zda=s(zne);kmt=r(zda,"FlaxBigBirdForSequenceClassification"),zda.forEach(t),Smt=r(UJe," (BigBird model)"),UJe.forEach(t),Rmt=i(Ge),V7=n(Ge,"LI",{});var HJe=s(V7);J9e=n(HJe,"STRONG",{});var Qda=s(J9e);Pmt=r(Qda,"distilbert"),Qda.forEach(t),Bmt=r(HJe," \u2014 "),Qne=n(HJe,"A",{href:!0});var Wda=s(Qne);Imt=r(Wda,"FlaxDistilBertForSequenceClassification"),Wda.forEach(t),Nmt=r(HJe," (DistilBERT model)"),HJe.forEach(t),qmt=i(Ge),X7=n(Ge,"LI",{});var JJe=s(X7);Y9e=n(JJe,"STRONG",{});var Uda=s(Y9e);jmt=r(Uda,"electra"),Uda.forEach(t),Dmt=r(JJe," \u2014 "),Wne=n(JJe,"A",{href:!0});var Hda=s(Wne);Gmt=r(Hda,"FlaxElectraForSequenceClassification"),Hda.forEach(t),Omt=r(JJe," (ELECTRA model)"),JJe.forEach(t),Vmt=i(Ge),z7=n(Ge,"LI",{});var YJe=s(z7);K9e=n(YJe,"STRONG",{});var Jda=s(K9e);Xmt=r(Jda,"mbart"),Jda.forEach(t),zmt=r(YJe," \u2014 "),Une=n(YJe,"A",{href:!0});var Yda=s(Une);Qmt=r(Yda,"FlaxMBartForSequenceClassification"),Yda.forEach(t),Wmt=r(YJe," (mBART model)"),YJe.forEach(t),Umt=i(Ge),Q7=n(Ge,"LI",{});var KJe=s(Q7);Z9e=n(KJe,"STRONG",{});var Kda=s(Z9e);Hmt=r(Kda,"roberta"),Kda.forEach(t),Jmt=r(KJe," \u2014 "),Hne=n(KJe,"A",{href:!0});var Zda=s(Hne);Ymt=r(Zda,"FlaxRobertaForSequenceClassification"),Zda.forEach(t),Kmt=r(KJe," (RoBERTa model)"),KJe.forEach(t),Zmt=i(Ge),W7=n(Ge,"LI",{});var ZJe=s(W7);exe=n(ZJe,"STRONG",{});var eca=s(exe);egt=r(eca,"roformer"),eca.forEach(t),ogt=r(ZJe," \u2014 "),Jne=n(ZJe,"A",{href:!0});var oca=s(Jne);rgt=r(oca,"FlaxRoFormerForSequenceClassification"),oca.forEach(t),tgt=r(ZJe," (RoFormer model)"),ZJe.forEach(t),agt=i(Ge),U7=n(Ge,"LI",{});var eYe=s(U7);oxe=n(eYe,"STRONG",{});var rca=s(oxe);ngt=r(rca,"xlm-roberta"),rca.forEach(t),sgt=r(eYe," \u2014 "),Yne=n(eYe,"A",{href:!0});var tca=s(Yne);lgt=r(tca,"FlaxXLMRobertaForSequenceClassification"),tca.forEach(t),igt=r(eYe," (XLM-RoBERTa model)"),eYe.forEach(t),Ge.forEach(t),dgt=i(Vi),T(H7.$$.fragment,Vi),Vi.forEach(t),Oi.forEach(t),SZe=i(f),om=n(f,"H2",{class:!0});var Hoo=s(om);J7=n(Hoo,"A",{id:!0,class:!0,href:!0});var aca=s(J7);rxe=n(aca,"SPAN",{});var nca=s(rxe);T(MR.$$.fragment,nca),nca.forEach(t),aca.forEach(t),cgt=i(Hoo),txe=n(Hoo,"SPAN",{});var sca=s(txe);fgt=r(sca,"FlaxAutoModelForQuestionAnswering"),sca.forEach(t),Hoo.forEach(t),RZe=i(f),yr=n(f,"DIV",{class:!0});var Xi=s(yr);T(ER.$$.fragment,Xi),mgt=i(Xi),rm=n(Xi,"P",{});var Nie=s(rm);ggt=r(Nie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Kne=n(Nie,"A",{href:!0});var lca=s(Kne);hgt=r(lca,"from_pretrained()"),lca.forEach(t),ugt=r(Nie," class method or the "),Zne=n(Nie,"A",{href:!0});var ica=s(Zne);pgt=r(ica,"from_config()"),ica.forEach(t),_gt=r(Nie,` class
method.`),Nie.forEach(t),vgt=i(Xi),CR=n(Xi,"P",{});var Joo=s(CR);bgt=r(Joo,"This class cannot be instantiated directly using "),axe=n(Joo,"CODE",{});var dca=s(axe);Fgt=r(dca,"__init__()"),dca.forEach(t),Tgt=r(Joo," (throws an error)."),Joo.forEach(t),Mgt=i(Xi),ma=n(Xi,"DIV",{class:!0});var l9=s(ma);T(wR.$$.fragment,l9),Egt=i(l9),nxe=n(l9,"P",{});var cca=s(nxe);Cgt=r(cca,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),cca.forEach(t),wgt=i(l9),tm=n(l9,"P",{});var qie=s(tm);Agt=r(qie,`Note:
Loading a model from its configuration file does `),sxe=n(qie,"STRONG",{});var fca=s(sxe);Lgt=r(fca,"not"),fca.forEach(t),ygt=r(qie,` load the model weights. It only affects the
model\u2019s configuration. Use `),ese=n(qie,"A",{href:!0});var mca=s(ese);xgt=r(mca,"from_pretrained()"),mca.forEach(t),$gt=r(qie," to load the model weights."),qie.forEach(t),kgt=i(l9),T(Y7.$$.fragment,l9),l9.forEach(t),Sgt=i(Xi),at=n(Xi,"DIV",{class:!0});var zi=s(at);T(AR.$$.fragment,zi),Rgt=i(zi),lxe=n(zi,"P",{});var gca=s(lxe);Pgt=r(gca,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),gca.forEach(t),Bgt=i(zi),Qn=n(zi,"P",{});var i9=s(Qn);Igt=r(i9,"The model class to instantiate is selected based on the "),ixe=n(i9,"CODE",{});var hca=s(ixe);Ngt=r(hca,"model_type"),hca.forEach(t),qgt=r(i9,` property of the config object (either
passed as an argument or loaded from `),dxe=n(i9,"CODE",{});var uca=s(dxe);jgt=r(uca,"pretrained_model_name_or_path"),uca.forEach(t),Dgt=r(i9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cxe=n(i9,"CODE",{});var pca=s(cxe);Ggt=r(pca,"pretrained_model_name_or_path"),pca.forEach(t),Ogt=r(i9,":"),i9.forEach(t),Vgt=i(zi),Re=n(zi,"UL",{});var Oe=s(Re);K7=n(Oe,"LI",{});var oYe=s(K7);fxe=n(oYe,"STRONG",{});var _ca=s(fxe);Xgt=r(_ca,"albert"),_ca.forEach(t),zgt=r(oYe," \u2014 "),ose=n(oYe,"A",{href:!0});var vca=s(ose);Qgt=r(vca,"FlaxAlbertForQuestionAnswering"),vca.forEach(t),Wgt=r(oYe," (ALBERT model)"),oYe.forEach(t),Ugt=i(Oe),Z7=n(Oe,"LI",{});var rYe=s(Z7);mxe=n(rYe,"STRONG",{});var bca=s(mxe);Hgt=r(bca,"bart"),bca.forEach(t),Jgt=r(rYe," \u2014 "),rse=n(rYe,"A",{href:!0});var Fca=s(rse);Ygt=r(Fca,"FlaxBartForQuestionAnswering"),Fca.forEach(t),Kgt=r(rYe," (BART model)"),rYe.forEach(t),Zgt=i(Oe),eL=n(Oe,"LI",{});var tYe=s(eL);gxe=n(tYe,"STRONG",{});var Tca=s(gxe);eht=r(Tca,"bert"),Tca.forEach(t),oht=r(tYe," \u2014 "),tse=n(tYe,"A",{href:!0});var Mca=s(tse);rht=r(Mca,"FlaxBertForQuestionAnswering"),Mca.forEach(t),tht=r(tYe," (BERT model)"),tYe.forEach(t),aht=i(Oe),oL=n(Oe,"LI",{});var aYe=s(oL);hxe=n(aYe,"STRONG",{});var Eca=s(hxe);nht=r(Eca,"big_bird"),Eca.forEach(t),sht=r(aYe," \u2014 "),ase=n(aYe,"A",{href:!0});var Cca=s(ase);lht=r(Cca,"FlaxBigBirdForQuestionAnswering"),Cca.forEach(t),iht=r(aYe," (BigBird model)"),aYe.forEach(t),dht=i(Oe),rL=n(Oe,"LI",{});var nYe=s(rL);uxe=n(nYe,"STRONG",{});var wca=s(uxe);cht=r(wca,"distilbert"),wca.forEach(t),fht=r(nYe," \u2014 "),nse=n(nYe,"A",{href:!0});var Aca=s(nse);mht=r(Aca,"FlaxDistilBertForQuestionAnswering"),Aca.forEach(t),ght=r(nYe," (DistilBERT model)"),nYe.forEach(t),hht=i(Oe),tL=n(Oe,"LI",{});var sYe=s(tL);pxe=n(sYe,"STRONG",{});var Lca=s(pxe);uht=r(Lca,"electra"),Lca.forEach(t),pht=r(sYe," \u2014 "),sse=n(sYe,"A",{href:!0});var yca=s(sse);_ht=r(yca,"FlaxElectraForQuestionAnswering"),yca.forEach(t),vht=r(sYe," (ELECTRA model)"),sYe.forEach(t),bht=i(Oe),aL=n(Oe,"LI",{});var lYe=s(aL);_xe=n(lYe,"STRONG",{});var xca=s(_xe);Fht=r(xca,"mbart"),xca.forEach(t),Tht=r(lYe," \u2014 "),lse=n(lYe,"A",{href:!0});var $ca=s(lse);Mht=r($ca,"FlaxMBartForQuestionAnswering"),$ca.forEach(t),Eht=r(lYe," (mBART model)"),lYe.forEach(t),Cht=i(Oe),nL=n(Oe,"LI",{});var iYe=s(nL);vxe=n(iYe,"STRONG",{});var kca=s(vxe);wht=r(kca,"roberta"),kca.forEach(t),Aht=r(iYe," \u2014 "),ise=n(iYe,"A",{href:!0});var Sca=s(ise);Lht=r(Sca,"FlaxRobertaForQuestionAnswering"),Sca.forEach(t),yht=r(iYe," (RoBERTa model)"),iYe.forEach(t),xht=i(Oe),sL=n(Oe,"LI",{});var dYe=s(sL);bxe=n(dYe,"STRONG",{});var Rca=s(bxe);$ht=r(Rca,"roformer"),Rca.forEach(t),kht=r(dYe," \u2014 "),dse=n(dYe,"A",{href:!0});var Pca=s(dse);Sht=r(Pca,"FlaxRoFormerForQuestionAnswering"),Pca.forEach(t),Rht=r(dYe," (RoFormer model)"),dYe.forEach(t),Pht=i(Oe),lL=n(Oe,"LI",{});var cYe=s(lL);Fxe=n(cYe,"STRONG",{});var Bca=s(Fxe);Bht=r(Bca,"xlm-roberta"),Bca.forEach(t),Iht=r(cYe," \u2014 "),cse=n(cYe,"A",{href:!0});var Ica=s(cse);Nht=r(Ica,"FlaxXLMRobertaForQuestionAnswering"),Ica.forEach(t),qht=r(cYe," (XLM-RoBERTa model)"),cYe.forEach(t),Oe.forEach(t),jht=i(zi),T(iL.$$.fragment,zi),zi.forEach(t),Xi.forEach(t),PZe=i(f),am=n(f,"H2",{class:!0});var Yoo=s(am);dL=n(Yoo,"A",{id:!0,class:!0,href:!0});var Nca=s(dL);Txe=n(Nca,"SPAN",{});var qca=s(Txe);T(LR.$$.fragment,qca),qca.forEach(t),Nca.forEach(t),Dht=i(Yoo),Mxe=n(Yoo,"SPAN",{});var jca=s(Mxe);Ght=r(jca,"FlaxAutoModelForTokenClassification"),jca.forEach(t),Yoo.forEach(t),BZe=i(f),xr=n(f,"DIV",{class:!0});var Qi=s(xr);T(yR.$$.fragment,Qi),Oht=i(Qi),nm=n(Qi,"P",{});var jie=s(nm);Vht=r(jie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),fse=n(jie,"A",{href:!0});var Dca=s(fse);Xht=r(Dca,"from_pretrained()"),Dca.forEach(t),zht=r(jie," class method or the "),mse=n(jie,"A",{href:!0});var Gca=s(mse);Qht=r(Gca,"from_config()"),Gca.forEach(t),Wht=r(jie,` class
method.`),jie.forEach(t),Uht=i(Qi),xR=n(Qi,"P",{});var Koo=s(xR);Hht=r(Koo,"This class cannot be instantiated directly using "),Exe=n(Koo,"CODE",{});var Oca=s(Exe);Jht=r(Oca,"__init__()"),Oca.forEach(t),Yht=r(Koo," (throws an error)."),Koo.forEach(t),Kht=i(Qi),ga=n(Qi,"DIV",{class:!0});var d9=s(ga);T($R.$$.fragment,d9),Zht=i(d9),Cxe=n(d9,"P",{});var Vca=s(Cxe);eut=r(Vca,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Vca.forEach(t),out=i(d9),sm=n(d9,"P",{});var Die=s(sm);rut=r(Die,`Note:
Loading a model from its configuration file does `),wxe=n(Die,"STRONG",{});var Xca=s(wxe);tut=r(Xca,"not"),Xca.forEach(t),aut=r(Die,` load the model weights. It only affects the
model\u2019s configuration. Use `),gse=n(Die,"A",{href:!0});var zca=s(gse);nut=r(zca,"from_pretrained()"),zca.forEach(t),sut=r(Die," to load the model weights."),Die.forEach(t),lut=i(d9),T(cL.$$.fragment,d9),d9.forEach(t),iut=i(Qi),nt=n(Qi,"DIV",{class:!0});var Wi=s(nt);T(kR.$$.fragment,Wi),dut=i(Wi),Axe=n(Wi,"P",{});var Qca=s(Axe);cut=r(Qca,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Qca.forEach(t),fut=i(Wi),Wn=n(Wi,"P",{});var c9=s(Wn);mut=r(c9,"The model class to instantiate is selected based on the "),Lxe=n(c9,"CODE",{});var Wca=s(Lxe);gut=r(Wca,"model_type"),Wca.forEach(t),hut=r(c9,` property of the config object (either
passed as an argument or loaded from `),yxe=n(c9,"CODE",{});var Uca=s(yxe);uut=r(Uca,"pretrained_model_name_or_path"),Uca.forEach(t),put=r(c9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xxe=n(c9,"CODE",{});var Hca=s(xxe);_ut=r(Hca,"pretrained_model_name_or_path"),Hca.forEach(t),vut=r(c9,":"),c9.forEach(t),but=i(Wi),Xe=n(Wi,"UL",{});var Ao=s(Xe);fL=n(Ao,"LI",{});var fYe=s(fL);$xe=n(fYe,"STRONG",{});var Jca=s($xe);Fut=r(Jca,"albert"),Jca.forEach(t),Tut=r(fYe," \u2014 "),hse=n(fYe,"A",{href:!0});var Yca=s(hse);Mut=r(Yca,"FlaxAlbertForTokenClassification"),Yca.forEach(t),Eut=r(fYe," (ALBERT model)"),fYe.forEach(t),Cut=i(Ao),mL=n(Ao,"LI",{});var mYe=s(mL);kxe=n(mYe,"STRONG",{});var Kca=s(kxe);wut=r(Kca,"bert"),Kca.forEach(t),Aut=r(mYe," \u2014 "),use=n(mYe,"A",{href:!0});var Zca=s(use);Lut=r(Zca,"FlaxBertForTokenClassification"),Zca.forEach(t),yut=r(mYe," (BERT model)"),mYe.forEach(t),xut=i(Ao),gL=n(Ao,"LI",{});var gYe=s(gL);Sxe=n(gYe,"STRONG",{});var efa=s(Sxe);$ut=r(efa,"big_bird"),efa.forEach(t),kut=r(gYe," \u2014 "),pse=n(gYe,"A",{href:!0});var ofa=s(pse);Sut=r(ofa,"FlaxBigBirdForTokenClassification"),ofa.forEach(t),Rut=r(gYe," (BigBird model)"),gYe.forEach(t),Put=i(Ao),hL=n(Ao,"LI",{});var hYe=s(hL);Rxe=n(hYe,"STRONG",{});var rfa=s(Rxe);But=r(rfa,"distilbert"),rfa.forEach(t),Iut=r(hYe," \u2014 "),_se=n(hYe,"A",{href:!0});var tfa=s(_se);Nut=r(tfa,"FlaxDistilBertForTokenClassification"),tfa.forEach(t),qut=r(hYe," (DistilBERT model)"),hYe.forEach(t),jut=i(Ao),uL=n(Ao,"LI",{});var uYe=s(uL);Pxe=n(uYe,"STRONG",{});var afa=s(Pxe);Dut=r(afa,"electra"),afa.forEach(t),Gut=r(uYe," \u2014 "),vse=n(uYe,"A",{href:!0});var nfa=s(vse);Out=r(nfa,"FlaxElectraForTokenClassification"),nfa.forEach(t),Vut=r(uYe," (ELECTRA model)"),uYe.forEach(t),Xut=i(Ao),pL=n(Ao,"LI",{});var pYe=s(pL);Bxe=n(pYe,"STRONG",{});var sfa=s(Bxe);zut=r(sfa,"roberta"),sfa.forEach(t),Qut=r(pYe," \u2014 "),bse=n(pYe,"A",{href:!0});var lfa=s(bse);Wut=r(lfa,"FlaxRobertaForTokenClassification"),lfa.forEach(t),Uut=r(pYe," (RoBERTa model)"),pYe.forEach(t),Hut=i(Ao),_L=n(Ao,"LI",{});var _Ye=s(_L);Ixe=n(_Ye,"STRONG",{});var ifa=s(Ixe);Jut=r(ifa,"roformer"),ifa.forEach(t),Yut=r(_Ye," \u2014 "),Fse=n(_Ye,"A",{href:!0});var dfa=s(Fse);Kut=r(dfa,"FlaxRoFormerForTokenClassification"),dfa.forEach(t),Zut=r(_Ye," (RoFormer model)"),_Ye.forEach(t),ept=i(Ao),vL=n(Ao,"LI",{});var vYe=s(vL);Nxe=n(vYe,"STRONG",{});var cfa=s(Nxe);opt=r(cfa,"xlm-roberta"),cfa.forEach(t),rpt=r(vYe," \u2014 "),Tse=n(vYe,"A",{href:!0});var ffa=s(Tse);tpt=r(ffa,"FlaxXLMRobertaForTokenClassification"),ffa.forEach(t),apt=r(vYe," (XLM-RoBERTa model)"),vYe.forEach(t),Ao.forEach(t),npt=i(Wi),T(bL.$$.fragment,Wi),Wi.forEach(t),Qi.forEach(t),IZe=i(f),lm=n(f,"H2",{class:!0});var Zoo=s(lm);FL=n(Zoo,"A",{id:!0,class:!0,href:!0});var mfa=s(FL);qxe=n(mfa,"SPAN",{});var gfa=s(qxe);T(SR.$$.fragment,gfa),gfa.forEach(t),mfa.forEach(t),spt=i(Zoo),jxe=n(Zoo,"SPAN",{});var hfa=s(jxe);lpt=r(hfa,"FlaxAutoModelForMultipleChoice"),hfa.forEach(t),Zoo.forEach(t),NZe=i(f),$r=n(f,"DIV",{class:!0});var Ui=s($r);T(RR.$$.fragment,Ui),ipt=i(Ui),im=n(Ui,"P",{});var Gie=s(im);dpt=r(Gie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Mse=n(Gie,"A",{href:!0});var ufa=s(Mse);cpt=r(ufa,"from_pretrained()"),ufa.forEach(t),fpt=r(Gie," class method or the "),Ese=n(Gie,"A",{href:!0});var pfa=s(Ese);mpt=r(pfa,"from_config()"),pfa.forEach(t),gpt=r(Gie,` class
method.`),Gie.forEach(t),hpt=i(Ui),PR=n(Ui,"P",{});var ero=s(PR);upt=r(ero,"This class cannot be instantiated directly using "),Dxe=n(ero,"CODE",{});var _fa=s(Dxe);ppt=r(_fa,"__init__()"),_fa.forEach(t),_pt=r(ero," (throws an error)."),ero.forEach(t),vpt=i(Ui),ha=n(Ui,"DIV",{class:!0});var f9=s(ha);T(BR.$$.fragment,f9),bpt=i(f9),Gxe=n(f9,"P",{});var vfa=s(Gxe);Fpt=r(vfa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),vfa.forEach(t),Tpt=i(f9),dm=n(f9,"P",{});var Oie=s(dm);Mpt=r(Oie,`Note:
Loading a model from its configuration file does `),Oxe=n(Oie,"STRONG",{});var bfa=s(Oxe);Ept=r(bfa,"not"),bfa.forEach(t),Cpt=r(Oie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cse=n(Oie,"A",{href:!0});var Ffa=s(Cse);wpt=r(Ffa,"from_pretrained()"),Ffa.forEach(t),Apt=r(Oie," to load the model weights."),Oie.forEach(t),Lpt=i(f9),T(TL.$$.fragment,f9),f9.forEach(t),ypt=i(Ui),st=n(Ui,"DIV",{class:!0});var Hi=s(st);T(IR.$$.fragment,Hi),xpt=i(Hi),Vxe=n(Hi,"P",{});var Tfa=s(Vxe);$pt=r(Tfa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Tfa.forEach(t),kpt=i(Hi),Un=n(Hi,"P",{});var m9=s(Un);Spt=r(m9,"The model class to instantiate is selected based on the "),Xxe=n(m9,"CODE",{});var Mfa=s(Xxe);Rpt=r(Mfa,"model_type"),Mfa.forEach(t),Ppt=r(m9,` property of the config object (either
passed as an argument or loaded from `),zxe=n(m9,"CODE",{});var Efa=s(zxe);Bpt=r(Efa,"pretrained_model_name_or_path"),Efa.forEach(t),Ipt=r(m9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qxe=n(m9,"CODE",{});var Cfa=s(Qxe);Npt=r(Cfa,"pretrained_model_name_or_path"),Cfa.forEach(t),qpt=r(m9,":"),m9.forEach(t),jpt=i(Hi),ze=n(Hi,"UL",{});var Lo=s(ze);ML=n(Lo,"LI",{});var bYe=s(ML);Wxe=n(bYe,"STRONG",{});var wfa=s(Wxe);Dpt=r(wfa,"albert"),wfa.forEach(t),Gpt=r(bYe," \u2014 "),wse=n(bYe,"A",{href:!0});var Afa=s(wse);Opt=r(Afa,"FlaxAlbertForMultipleChoice"),Afa.forEach(t),Vpt=r(bYe," (ALBERT model)"),bYe.forEach(t),Xpt=i(Lo),EL=n(Lo,"LI",{});var FYe=s(EL);Uxe=n(FYe,"STRONG",{});var Lfa=s(Uxe);zpt=r(Lfa,"bert"),Lfa.forEach(t),Qpt=r(FYe," \u2014 "),Ase=n(FYe,"A",{href:!0});var yfa=s(Ase);Wpt=r(yfa,"FlaxBertForMultipleChoice"),yfa.forEach(t),Upt=r(FYe," (BERT model)"),FYe.forEach(t),Hpt=i(Lo),CL=n(Lo,"LI",{});var TYe=s(CL);Hxe=n(TYe,"STRONG",{});var xfa=s(Hxe);Jpt=r(xfa,"big_bird"),xfa.forEach(t),Ypt=r(TYe," \u2014 "),Lse=n(TYe,"A",{href:!0});var $fa=s(Lse);Kpt=r($fa,"FlaxBigBirdForMultipleChoice"),$fa.forEach(t),Zpt=r(TYe," (BigBird model)"),TYe.forEach(t),e_t=i(Lo),wL=n(Lo,"LI",{});var MYe=s(wL);Jxe=n(MYe,"STRONG",{});var kfa=s(Jxe);o_t=r(kfa,"distilbert"),kfa.forEach(t),r_t=r(MYe," \u2014 "),yse=n(MYe,"A",{href:!0});var Sfa=s(yse);t_t=r(Sfa,"FlaxDistilBertForMultipleChoice"),Sfa.forEach(t),a_t=r(MYe," (DistilBERT model)"),MYe.forEach(t),n_t=i(Lo),AL=n(Lo,"LI",{});var EYe=s(AL);Yxe=n(EYe,"STRONG",{});var Rfa=s(Yxe);s_t=r(Rfa,"electra"),Rfa.forEach(t),l_t=r(EYe," \u2014 "),xse=n(EYe,"A",{href:!0});var Pfa=s(xse);i_t=r(Pfa,"FlaxElectraForMultipleChoice"),Pfa.forEach(t),d_t=r(EYe," (ELECTRA model)"),EYe.forEach(t),c_t=i(Lo),LL=n(Lo,"LI",{});var CYe=s(LL);Kxe=n(CYe,"STRONG",{});var Bfa=s(Kxe);f_t=r(Bfa,"roberta"),Bfa.forEach(t),m_t=r(CYe," \u2014 "),$se=n(CYe,"A",{href:!0});var Ifa=s($se);g_t=r(Ifa,"FlaxRobertaForMultipleChoice"),Ifa.forEach(t),h_t=r(CYe," (RoBERTa model)"),CYe.forEach(t),u_t=i(Lo),yL=n(Lo,"LI",{});var wYe=s(yL);Zxe=n(wYe,"STRONG",{});var Nfa=s(Zxe);p_t=r(Nfa,"roformer"),Nfa.forEach(t),__t=r(wYe," \u2014 "),kse=n(wYe,"A",{href:!0});var qfa=s(kse);v_t=r(qfa,"FlaxRoFormerForMultipleChoice"),qfa.forEach(t),b_t=r(wYe," (RoFormer model)"),wYe.forEach(t),F_t=i(Lo),xL=n(Lo,"LI",{});var AYe=s(xL);e$e=n(AYe,"STRONG",{});var jfa=s(e$e);T_t=r(jfa,"xlm-roberta"),jfa.forEach(t),M_t=r(AYe," \u2014 "),Sse=n(AYe,"A",{href:!0});var Dfa=s(Sse);E_t=r(Dfa,"FlaxXLMRobertaForMultipleChoice"),Dfa.forEach(t),C_t=r(AYe," (XLM-RoBERTa model)"),AYe.forEach(t),Lo.forEach(t),w_t=i(Hi),T($L.$$.fragment,Hi),Hi.forEach(t),Ui.forEach(t),qZe=i(f),cm=n(f,"H2",{class:!0});var oro=s(cm);kL=n(oro,"A",{id:!0,class:!0,href:!0});var Gfa=s(kL);o$e=n(Gfa,"SPAN",{});var Ofa=s(o$e);T(NR.$$.fragment,Ofa),Ofa.forEach(t),Gfa.forEach(t),A_t=i(oro),r$e=n(oro,"SPAN",{});var Vfa=s(r$e);L_t=r(Vfa,"FlaxAutoModelForNextSentencePrediction"),Vfa.forEach(t),oro.forEach(t),jZe=i(f),kr=n(f,"DIV",{class:!0});var Ji=s(kr);T(qR.$$.fragment,Ji),y_t=i(Ji),fm=n(Ji,"P",{});var Vie=s(fm);x_t=r(Vie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Rse=n(Vie,"A",{href:!0});var Xfa=s(Rse);$_t=r(Xfa,"from_pretrained()"),Xfa.forEach(t),k_t=r(Vie," class method or the "),Pse=n(Vie,"A",{href:!0});var zfa=s(Pse);S_t=r(zfa,"from_config()"),zfa.forEach(t),R_t=r(Vie,` class
method.`),Vie.forEach(t),P_t=i(Ji),jR=n(Ji,"P",{});var rro=s(jR);B_t=r(rro,"This class cannot be instantiated directly using "),t$e=n(rro,"CODE",{});var Qfa=s(t$e);I_t=r(Qfa,"__init__()"),Qfa.forEach(t),N_t=r(rro," (throws an error)."),rro.forEach(t),q_t=i(Ji),ua=n(Ji,"DIV",{class:!0});var g9=s(ua);T(DR.$$.fragment,g9),j_t=i(g9),a$e=n(g9,"P",{});var Wfa=s(a$e);D_t=r(Wfa,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Wfa.forEach(t),G_t=i(g9),mm=n(g9,"P",{});var Xie=s(mm);O_t=r(Xie,`Note:
Loading a model from its configuration file does `),n$e=n(Xie,"STRONG",{});var Ufa=s(n$e);V_t=r(Ufa,"not"),Ufa.forEach(t),X_t=r(Xie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bse=n(Xie,"A",{href:!0});var Hfa=s(Bse);z_t=r(Hfa,"from_pretrained()"),Hfa.forEach(t),Q_t=r(Xie," to load the model weights."),Xie.forEach(t),W_t=i(g9),T(SL.$$.fragment,g9),g9.forEach(t),U_t=i(Ji),lt=n(Ji,"DIV",{class:!0});var Yi=s(lt);T(GR.$$.fragment,Yi),H_t=i(Yi),s$e=n(Yi,"P",{});var Jfa=s(s$e);J_t=r(Jfa,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Jfa.forEach(t),Y_t=i(Yi),Hn=n(Yi,"P",{});var h9=s(Hn);K_t=r(h9,"The model class to instantiate is selected based on the "),l$e=n(h9,"CODE",{});var Yfa=s(l$e);Z_t=r(Yfa,"model_type"),Yfa.forEach(t),e2t=r(h9,` property of the config object (either
passed as an argument or loaded from `),i$e=n(h9,"CODE",{});var Kfa=s(i$e);o2t=r(Kfa,"pretrained_model_name_or_path"),Kfa.forEach(t),r2t=r(h9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d$e=n(h9,"CODE",{});var Zfa=s(d$e);t2t=r(Zfa,"pretrained_model_name_or_path"),Zfa.forEach(t),a2t=r(h9,":"),h9.forEach(t),n2t=i(Yi),c$e=n(Yi,"UL",{});var ema=s(c$e);RL=n(ema,"LI",{});var LYe=s(RL);f$e=n(LYe,"STRONG",{});var oma=s(f$e);s2t=r(oma,"bert"),oma.forEach(t),l2t=r(LYe," \u2014 "),Ise=n(LYe,"A",{href:!0});var rma=s(Ise);i2t=r(rma,"FlaxBertForNextSentencePrediction"),rma.forEach(t),d2t=r(LYe," (BERT model)"),LYe.forEach(t),ema.forEach(t),c2t=i(Yi),T(PL.$$.fragment,Yi),Yi.forEach(t),Ji.forEach(t),DZe=i(f),gm=n(f,"H2",{class:!0});var tro=s(gm);BL=n(tro,"A",{id:!0,class:!0,href:!0});var tma=s(BL);m$e=n(tma,"SPAN",{});var ama=s(m$e);T(OR.$$.fragment,ama),ama.forEach(t),tma.forEach(t),f2t=i(tro),g$e=n(tro,"SPAN",{});var nma=s(g$e);m2t=r(nma,"FlaxAutoModelForImageClassification"),nma.forEach(t),tro.forEach(t),GZe=i(f),Sr=n(f,"DIV",{class:!0});var Ki=s(Sr);T(VR.$$.fragment,Ki),g2t=i(Ki),hm=n(Ki,"P",{});var zie=s(hm);h2t=r(zie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Nse=n(zie,"A",{href:!0});var sma=s(Nse);u2t=r(sma,"from_pretrained()"),sma.forEach(t),p2t=r(zie," class method or the "),qse=n(zie,"A",{href:!0});var lma=s(qse);_2t=r(lma,"from_config()"),lma.forEach(t),v2t=r(zie,` class
method.`),zie.forEach(t),b2t=i(Ki),XR=n(Ki,"P",{});var aro=s(XR);F2t=r(aro,"This class cannot be instantiated directly using "),h$e=n(aro,"CODE",{});var ima=s(h$e);T2t=r(ima,"__init__()"),ima.forEach(t),M2t=r(aro," (throws an error)."),aro.forEach(t),E2t=i(Ki),pa=n(Ki,"DIV",{class:!0});var u9=s(pa);T(zR.$$.fragment,u9),C2t=i(u9),u$e=n(u9,"P",{});var dma=s(u$e);w2t=r(dma,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),dma.forEach(t),A2t=i(u9),um=n(u9,"P",{});var Qie=s(um);L2t=r(Qie,`Note:
Loading a model from its configuration file does `),p$e=n(Qie,"STRONG",{});var cma=s(p$e);y2t=r(cma,"not"),cma.forEach(t),x2t=r(Qie,` load the model weights. It only affects the
model\u2019s configuration. Use `),jse=n(Qie,"A",{href:!0});var fma=s(jse);$2t=r(fma,"from_pretrained()"),fma.forEach(t),k2t=r(Qie," to load the model weights."),Qie.forEach(t),S2t=i(u9),T(IL.$$.fragment,u9),u9.forEach(t),R2t=i(Ki),it=n(Ki,"DIV",{class:!0});var Zi=s(it);T(QR.$$.fragment,Zi),P2t=i(Zi),_$e=n(Zi,"P",{});var mma=s(_$e);B2t=r(mma,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),mma.forEach(t),I2t=i(Zi),Jn=n(Zi,"P",{});var p9=s(Jn);N2t=r(p9,"The model class to instantiate is selected based on the "),v$e=n(p9,"CODE",{});var gma=s(v$e);q2t=r(gma,"model_type"),gma.forEach(t),j2t=r(p9,` property of the config object (either
passed as an argument or loaded from `),b$e=n(p9,"CODE",{});var hma=s(b$e);D2t=r(hma,"pretrained_model_name_or_path"),hma.forEach(t),G2t=r(p9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F$e=n(p9,"CODE",{});var uma=s(F$e);O2t=r(uma,"pretrained_model_name_or_path"),uma.forEach(t),V2t=r(p9,":"),p9.forEach(t),X2t=i(Zi),WR=n(Zi,"UL",{});var nro=s(WR);NL=n(nro,"LI",{});var yYe=s(NL);T$e=n(yYe,"STRONG",{});var pma=s(T$e);z2t=r(pma,"beit"),pma.forEach(t),Q2t=r(yYe," \u2014 "),Dse=n(yYe,"A",{href:!0});var _ma=s(Dse);W2t=r(_ma,"FlaxBeitForImageClassification"),_ma.forEach(t),U2t=r(yYe," (BEiT model)"),yYe.forEach(t),H2t=i(nro),qL=n(nro,"LI",{});var xYe=s(qL);M$e=n(xYe,"STRONG",{});var vma=s(M$e);J2t=r(vma,"vit"),vma.forEach(t),Y2t=r(xYe," \u2014 "),Gse=n(xYe,"A",{href:!0});var bma=s(Gse);K2t=r(bma,"FlaxViTForImageClassification"),bma.forEach(t),Z2t=r(xYe," (ViT model)"),xYe.forEach(t),nro.forEach(t),evt=i(Zi),T(jL.$$.fragment,Zi),Zi.forEach(t),Ki.forEach(t),OZe=i(f),pm=n(f,"H2",{class:!0});var sro=s(pm);DL=n(sro,"A",{id:!0,class:!0,href:!0});var Fma=s(DL);E$e=n(Fma,"SPAN",{});var Tma=s(E$e);T(UR.$$.fragment,Tma),Tma.forEach(t),Fma.forEach(t),ovt=i(sro),C$e=n(sro,"SPAN",{});var Mma=s(C$e);rvt=r(Mma,"FlaxAutoModelForVision2Seq"),Mma.forEach(t),sro.forEach(t),VZe=i(f),Rr=n(f,"DIV",{class:!0});var ed=s(Rr);T(HR.$$.fragment,ed),tvt=i(ed),_m=n(ed,"P",{});var Wie=s(_m);avt=r(Wie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Ose=n(Wie,"A",{href:!0});var Ema=s(Ose);nvt=r(Ema,"from_pretrained()"),Ema.forEach(t),svt=r(Wie," class method or the "),Vse=n(Wie,"A",{href:!0});var Cma=s(Vse);lvt=r(Cma,"from_config()"),Cma.forEach(t),ivt=r(Wie,` class
method.`),Wie.forEach(t),dvt=i(ed),JR=n(ed,"P",{});var lro=s(JR);cvt=r(lro,"This class cannot be instantiated directly using "),w$e=n(lro,"CODE",{});var wma=s(w$e);fvt=r(wma,"__init__()"),wma.forEach(t),mvt=r(lro," (throws an error)."),lro.forEach(t),gvt=i(ed),_a=n(ed,"DIV",{class:!0});var _9=s(_a);T(YR.$$.fragment,_9),hvt=i(_9),A$e=n(_9,"P",{});var Ama=s(A$e);uvt=r(Ama,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Ama.forEach(t),pvt=i(_9),vm=n(_9,"P",{});var Uie=s(vm);_vt=r(Uie,`Note:
Loading a model from its configuration file does `),L$e=n(Uie,"STRONG",{});var Lma=s(L$e);vvt=r(Lma,"not"),Lma.forEach(t),bvt=r(Uie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xse=n(Uie,"A",{href:!0});var yma=s(Xse);Fvt=r(yma,"from_pretrained()"),yma.forEach(t),Tvt=r(Uie," to load the model weights."),Uie.forEach(t),Mvt=i(_9),T(GL.$$.fragment,_9),_9.forEach(t),Evt=i(ed),dt=n(ed,"DIV",{class:!0});var od=s(dt);T(KR.$$.fragment,od),Cvt=i(od),y$e=n(od,"P",{});var xma=s(y$e);wvt=r(xma,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),xma.forEach(t),Avt=i(od),Yn=n(od,"P",{});var v9=s(Yn);Lvt=r(v9,"The model class to instantiate is selected based on the "),x$e=n(v9,"CODE",{});var $ma=s(x$e);yvt=r($ma,"model_type"),$ma.forEach(t),xvt=r(v9,` property of the config object (either
passed as an argument or loaded from `),$$e=n(v9,"CODE",{});var kma=s($$e);$vt=r(kma,"pretrained_model_name_or_path"),kma.forEach(t),kvt=r(v9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k$e=n(v9,"CODE",{});var Sma=s(k$e);Svt=r(Sma,"pretrained_model_name_or_path"),Sma.forEach(t),Rvt=r(v9,":"),v9.forEach(t),Pvt=i(od),S$e=n(od,"UL",{});var Rma=s(S$e);OL=n(Rma,"LI",{});var $Ye=s(OL);R$e=n($Ye,"STRONG",{});var Pma=s(R$e);Bvt=r(Pma,"vision-encoder-decoder"),Pma.forEach(t),Ivt=r($Ye," \u2014 "),zse=n($Ye,"A",{href:!0});var Bma=s(zse);Nvt=r(Bma,"FlaxVisionEncoderDecoderModel"),Bma.forEach(t),qvt=r($Ye," (Vision Encoder decoder model)"),$Ye.forEach(t),Rma.forEach(t),jvt=i(od),T(VL.$$.fragment,od),od.forEach(t),ed.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(Hha)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(u,"class","relative group"),c(Zn,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.AutoConfig"),c(os,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.AutoModel"),c(rs,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.AutoTokenizer"),c(id,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertModel"),c(Am,"id","extending-the-auto-classes"),c(Am,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Am,"href","#extending-the-auto-classes"),c(dd,"class","relative group"),c(ym,"id","transformers.AutoConfig"),c(ym,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ym,"href","#transformers.AutoConfig"),c(cd,"class","relative group"),c($B,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(kB,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertConfig"),c(SB,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartConfig"),c(RB,"href","/docs/transformers/v4.22.0/en/model_doc/beit#transformers.BeitConfig"),c(PB,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertConfig"),c(BB,"href","/docs/transformers/v4.22.0/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(IB,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdConfig"),c(NB,"href","/docs/transformers/v4.22.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(qB,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(jB,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(DB,"href","/docs/transformers/v4.22.0/en/model_doc/bloom#transformers.BloomConfig"),c(GB,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig"),c(OB,"href","/docs/transformers/v4.22.0/en/model_doc/canine#transformers.CanineConfig"),c(VB,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPConfig"),c(XB,"href","/docs/transformers/v4.22.0/en/model_doc/codegen#transformers.CodeGenConfig"),c(zB,"href","/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertConfig"),c(QB,"href","/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.ConvNextConfig"),c(WB,"href","/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLConfig"),c(UB,"href","/docs/transformers/v4.22.0/en/model_doc/cvt#transformers.CvtConfig"),c(HB,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(JB,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(YB,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(KB,"href","/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaConfig"),c(ZB,"href","/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(eI,"href","/docs/transformers/v4.22.0/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(oI,"href","/docs/transformers/v4.22.0/en/model_doc/deit#transformers.DeiTConfig"),c(rI,"href","/docs/transformers/v4.22.0/en/model_doc/detr#transformers.DetrConfig"),c(tI,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertConfig"),c(aI,"href","/docs/transformers/v4.22.0/en/model_doc/donut#transformers.DonutSwinConfig"),c(nI,"href","/docs/transformers/v4.22.0/en/model_doc/dpr#transformers.DPRConfig"),c(sI,"href","/docs/transformers/v4.22.0/en/model_doc/dpt#transformers.DPTConfig"),c(lI,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraConfig"),c(iI,"href","/docs/transformers/v4.22.0/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(dI,"href","/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieConfig"),c(cI,"href","/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertConfig"),c(fI,"href","/docs/transformers/v4.22.0/en/model_doc/flava#transformers.FlavaConfig"),c(mI,"href","/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetConfig"),c(gI,"href","/docs/transformers/v4.22.0/en/model_doc/fsmt#transformers.FSMTConfig"),c(hI,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelConfig"),c(uI,"href","/docs/transformers/v4.22.0/en/model_doc/glpn#transformers.GLPNConfig"),c(pI,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Config"),c(_I,"href","/docs/transformers/v4.22.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(vI,"href","/docs/transformers/v4.22.0/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(bI,"href","/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJConfig"),c(FI,"href","/docs/transformers/v4.22.0/en/model_doc/groupvit#transformers.GroupViTConfig"),c(TI,"href","/docs/transformers/v4.22.0/en/model_doc/hubert#transformers.HubertConfig"),c(MI,"href","/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertConfig"),c(EI,"href","/docs/transformers/v4.22.0/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(CI,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(wI,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(AI,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(LI,"href","/docs/transformers/v4.22.0/en/model_doc/led#transformers.LEDConfig"),c(yI,"href","/docs/transformers/v4.22.0/en/model_doc/levit#transformers.LevitConfig"),c(xI,"href","/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerConfig"),c($I,"href","/docs/transformers/v4.22.0/en/model_doc/longt5#transformers.LongT5Config"),c(kI,"href","/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeConfig"),c(SI,"href","/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.LxmertConfig"),c(RI,"href","/docs/transformers/v4.22.0/en/model_doc/m2m_100#transformers.M2M100Config"),c(PI,"href","/docs/transformers/v4.22.0/en/model_doc/marian#transformers.MarianConfig"),c(BI,"href","/docs/transformers/v4.22.0/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(II,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartConfig"),c(NI,"href","/docs/transformers/v4.22.0/en/model_doc/mctct#transformers.MCTCTConfig"),c(qI,"href","/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(jI,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(DI,"href","/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.MobileViTConfig"),c(GI,"href","/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetConfig"),c(OI,"href","/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.MT5Config"),c(VI,"href","/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpConfig"),c(XI,"href","/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaConfig"),c(zI,"href","/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(QI,"href","/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(WI,"href","/docs/transformers/v4.22.0/en/model_doc/opt#transformers.OPTConfig"),c(UI,"href","/docs/transformers/v4.22.0/en/model_doc/owlvit#transformers.OwlViTConfig"),c(HI,"href","/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusConfig"),c(JI,"href","/docs/transformers/v4.22.0/en/model_doc/pegasus_x#transformers.PegasusXConfig"),c(YI,"href","/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverConfig"),c(KI,"href","/docs/transformers/v4.22.0/en/model_doc/plbart#transformers.PLBartConfig"),c(ZI,"href","/docs/transformers/v4.22.0/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(eN,"href","/docs/transformers/v4.22.0/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(oN,"href","/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(rN,"href","/docs/transformers/v4.22.0/en/model_doc/rag#transformers.RagConfig"),c(tN,"href","/docs/transformers/v4.22.0/en/model_doc/realm#transformers.RealmConfig"),c(aN,"href","/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerConfig"),c(nN,"href","/docs/transformers/v4.22.0/en/model_doc/regnet#transformers.RegNetConfig"),c(sN,"href","/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertConfig"),c(lN,"href","/docs/transformers/v4.22.0/en/model_doc/resnet#transformers.ResNetConfig"),c(iN,"href","/docs/transformers/v4.22.0/en/model_doc/retribert#transformers.RetriBertConfig"),c(dN,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig"),c(cN,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerConfig"),c(fN,"href","/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.SegformerConfig"),c(mN,"href","/docs/transformers/v4.22.0/en/model_doc/sew#transformers.SEWConfig"),c(gN,"href","/docs/transformers/v4.22.0/en/model_doc/sew-d#transformers.SEWDConfig"),c(hN,"href","/docs/transformers/v4.22.0/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(uN,"href","/docs/transformers/v4.22.0/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(pN,"href","/docs/transformers/v4.22.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(_N,"href","/docs/transformers/v4.22.0/en/model_doc/splinter#transformers.SplinterConfig"),c(vN,"href","/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(bN,"href","/docs/transformers/v4.22.0/en/model_doc/swin#transformers.SwinConfig"),c(FN,"href","/docs/transformers/v4.22.0/en/model_doc/swinv2#transformers.Swinv2Config"),c(TN,"href","/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5Config"),c(MN,"href","/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasConfig"),c(EN,"href","/docs/transformers/v4.22.0/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(CN,"href","/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(wN,"href","/docs/transformers/v4.22.0/en/model_doc/trocr#transformers.TrOCRConfig"),c(AN,"href","/docs/transformers/v4.22.0/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(LN,"href","/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(yN,"href","/docs/transformers/v4.22.0/en/model_doc/van#transformers.VanConfig"),c(xN,"href","/docs/transformers/v4.22.0/en/model_doc/videomae#transformers.VideoMAEConfig"),c($N,"href","/docs/transformers/v4.22.0/en/model_doc/vilt#transformers.ViltConfig"),c(kN,"href","/docs/transformers/v4.22.0/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(SN,"href","/docs/transformers/v4.22.0/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(RN,"href","/docs/transformers/v4.22.0/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(PN,"href","/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTConfig"),c(BN,"href","/docs/transformers/v4.22.0/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(IN,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(NN,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(qN,"href","/docs/transformers/v4.22.0/en/model_doc/wavlm#transformers.WavLMConfig"),c(jN,"href","/docs/transformers/v4.22.0/en/model_doc/xclip#transformers.XCLIPConfig"),c(DN,"href","/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.XGLMConfig"),c(GN,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMConfig"),c(ON,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(VN,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(XN,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(zN,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetConfig"),c(QN,"href","/docs/transformers/v4.22.0/en/model_doc/yolos#transformers.YolosConfig"),c(WN,"href","/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoConfig"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uh,"id","transformers.AutoTokenizer"),c(Uh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Uh,"href","#transformers.AutoTokenizer"),c(md,"class","relative group"),c(UN,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(HN,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertTokenizer"),c(JN,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(YN,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartTokenizer"),c(KN,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartTokenizerFast"),c(ZN,"href","/docs/transformers/v4.22.0/en/model_doc/barthez#transformers.BarthezTokenizer"),c(eq,"href","/docs/transformers/v4.22.0/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(oq,"href","/docs/transformers/v4.22.0/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(rq,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertTokenizer"),c(tq,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertTokenizerFast"),c(aq,"href","/docs/transformers/v4.22.0/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(nq,"href","/docs/transformers/v4.22.0/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(sq,"href","/docs/transformers/v4.22.0/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(lq,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(iq,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(dq,"href","/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(cq,"href","/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(fq,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(mq,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(gq,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(hq,"href","/docs/transformers/v4.22.0/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(uq,"href","/docs/transformers/v4.22.0/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(pq,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertTokenizer"),c(_q,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(vq,"href","/docs/transformers/v4.22.0/en/model_doc/canine#transformers.CanineTokenizer"),c(bq,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPTokenizer"),c(Fq,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(Tq,"href","/docs/transformers/v4.22.0/en/model_doc/codegen#transformers.CodeGenTokenizer"),c(Mq,"href","/docs/transformers/v4.22.0/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),c(Eq,"href","/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(Cq,"href","/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(wq,"href","/docs/transformers/v4.22.0/en/model_doc/cpm#transformers.CpmTokenizer"),c(Aq,"href","/docs/transformers/v4.22.0/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(Lq,"href","/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(yq,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaTokenizer"),c(xq,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c($q,"href","/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaTokenizer"),c(kq,"href","/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(Sq,"href","/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(Rq,"href","/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(Pq,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(Bq,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(Iq,"href","/docs/transformers/v4.22.0/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(Nq,"href","/docs/transformers/v4.22.0/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(qq,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraTokenizer"),c(jq,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(Dq,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertTokenizer"),c(Gq,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertTokenizerFast"),c(Oq,"href","/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(Vq,"href","/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetTokenizer"),c(Xq,"href","/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(zq,"href","/docs/transformers/v4.22.0/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(Qq,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelTokenizer"),c(Wq,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(Uq,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(Hq,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(Jq,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(Yq,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(Kq,"href","/docs/transformers/v4.22.0/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(Zq,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(ej,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(oj,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPTokenizer"),c(rj,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(tj,"href","/docs/transformers/v4.22.0/en/model_doc/herbert#transformers.HerbertTokenizer"),c(aj,"href","/docs/transformers/v4.22.0/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(nj,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(sj,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaTokenizer"),c(lj,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(ij,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(dj,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(cj,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(fj,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(mj,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(gj,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(hj,"href","/docs/transformers/v4.22.0/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(uj,"href","/docs/transformers/v4.22.0/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(pj,"href","/docs/transformers/v4.22.0/en/model_doc/led#transformers.LEDTokenizer"),c(_j,"href","/docs/transformers/v4.22.0/en/model_doc/led#transformers.LEDTokenizerFast"),c(vj,"href","/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerTokenizer"),c(bj,"href","/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(Fj,"href","/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5Tokenizer"),c(Tj,"href","/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5TokenizerFast"),c(Mj,"href","/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeTokenizer"),c(Ej,"href","/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(Cj,"href","/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(wj,"href","/docs/transformers/v4.22.0/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(Aj,"href","/docs/transformers/v4.22.0/en/model_doc/marian#transformers.MarianTokenizer"),c(Lj,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartTokenizer"),c(yj,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(xj,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBart50Tokenizer"),c($j,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(kj,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertTokenizer"),c(Sj,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertTokenizerFast"),c(Rj,"href","/docs/transformers/v4.22.0/en/model_doc/mluke#transformers.MLukeTokenizer"),c(Pj,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(Bj,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(Ij,"href","/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(Nj,"href","/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(qj,"href","/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5Tokenizer"),c(jj,"href","/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5TokenizerFast"),c(Dj,"href","/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpTokenizer"),c(Gj,"href","/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpTokenizerFast"),c(Oj,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertTokenizer"),c(Vj,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertTokenizerFast"),c(Xj,"href","/docs/transformers/v4.22.0/en/model_doc/nllb#transformers.NllbTokenizer"),c(zj,"href","/docs/transformers/v4.22.0/en/model_doc/nllb#transformers.NllbTokenizerFast"),c(Qj,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertTokenizer"),c(Wj,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Uj,"href","/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(Hj,"href","/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(Jj,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(Yj,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPTokenizer"),c(Kj,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(Zj,"href","/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(eD,"href","/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(oD,"href","/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(rD,"href","/docs/transformers/v4.22.0/en/model_doc/phobert#transformers.PhobertTokenizer"),c(tD,"href","/docs/transformers/v4.22.0/en/model_doc/plbart#transformers.PLBartTokenizer"),c(aD,"href","/docs/transformers/v4.22.0/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(nD,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertTokenizer"),c(sD,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertTokenizerFast"),c(lD,"href","/docs/transformers/v4.22.0/en/model_doc/rag#transformers.RagTokenizer"),c(iD,"href","/docs/transformers/v4.22.0/en/model_doc/realm#transformers.RealmTokenizer"),c(dD,"href","/docs/transformers/v4.22.0/en/model_doc/realm#transformers.RealmTokenizerFast"),c(cD,"href","/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerTokenizer"),c(fD,"href","/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(mD,"href","/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertTokenizer"),c(gD,"href","/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(hD,"href","/docs/transformers/v4.22.0/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(uD,"href","/docs/transformers/v4.22.0/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(pD,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaTokenizer"),c(_D,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(vD,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(bD,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(FD,"href","/docs/transformers/v4.22.0/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(TD,"href","/docs/transformers/v4.22.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(MD,"href","/docs/transformers/v4.22.0/en/model_doc/splinter#transformers.SplinterTokenizer"),c(ED,"href","/docs/transformers/v4.22.0/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(CD,"href","/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(wD,"href","/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(AD,"href","/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5Tokenizer"),c(LD,"href","/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5TokenizerFast"),c(yD,"href","/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasTokenizer"),c(xD,"href","/docs/transformers/v4.22.0/en/model_doc/tapex#transformers.TapexTokenizer"),c($D,"href","/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(kD,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertTokenizer"),c(SD,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertTokenizerFast"),c(RD,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertTokenizer"),c(PD,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertTokenizerFast"),c(BD,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(ID,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(ND,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(qD,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPTokenizer"),c(jD,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(DD,"href","/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.XGLMTokenizer"),c(GD,"href","/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(OD,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMTokenizer"),c(VD,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(XD,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(zD,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(QD,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(WD,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(UD,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(HD,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(JD,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertTokenizer"),c(YD,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($u,"id","transformers.AutoFeatureExtractor"),c($u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($u,"href","#transformers.AutoFeatureExtractor"),c(gd,"class","relative group"),c(KD,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(ZD,"href","/docs/transformers/v4.22.0/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(eG,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(oG,"href","/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(rG,"href","/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(tG,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(aG,"href","/docs/transformers/v4.22.0/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(nG,"href","/docs/transformers/v4.22.0/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(sG,"href","/docs/transformers/v4.22.0/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(lG,"href","/docs/transformers/v4.22.0/en/model_doc/donut#transformers.DonutFeatureExtractor"),c(iG,"href","/docs/transformers/v4.22.0/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(dG,"href","/docs/transformers/v4.22.0/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(cG,"href","/docs/transformers/v4.22.0/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(fG,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(mG,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(gG,"href","/docs/transformers/v4.22.0/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(hG,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(uG,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(pG,"href","/docs/transformers/v4.22.0/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(_G,"href","/docs/transformers/v4.22.0/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(vG,"href","/docs/transformers/v4.22.0/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(bG,"href","/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),c(FG,"href","/docs/transformers/v4.22.0/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),c(TG,"href","/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(MG,"href","/docs/transformers/v4.22.0/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(EG,"href","/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(CG,"href","/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(wG,"href","/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(AG,"href","/docs/transformers/v4.22.0/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(LG,"href","/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(yG,"href","/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(xG,"href","/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c($G,"href","/docs/transformers/v4.22.0/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor"),c(kG,"href","/docs/transformers/v4.22.0/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(SG,"href","/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(RG,"href","/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(PG,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(BG,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(IG,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(NG,"href","/docs/transformers/v4.22.0/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bp,"id","transformers.AutoProcessor"),c(bp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bp,"href","#transformers.AutoProcessor"),c(hd,"class","relative group"),c(qG,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(jG,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPProcessor"),c(DG,"href","/docs/transformers/v4.22.0/en/model_doc/donut#transformers.DonutProcessor"),c(GG,"href","/docs/transformers/v4.22.0/en/model_doc/flava#transformers.FlavaProcessor"),c(OG,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPProcessor"),c(VG,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(XG,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(zG,"href","/docs/transformers/v4.22.0/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(QG,"href","/docs/transformers/v4.22.0/en/model_doc/owlvit#transformers.OwlViTProcessor"),c(WG,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(UG,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(HG,"href","/docs/transformers/v4.22.0/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(JG,"href","/docs/transformers/v4.22.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(YG,"href","/docs/transformers/v4.22.0/en/model_doc/trocr#transformers.TrOCRProcessor"),c(KG,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(ZG,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(eO,"href","/docs/transformers/v4.22.0/en/model_doc/vilt#transformers.ViltProcessor"),c(oO,"href","/docs/transformers/v4.22.0/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(rO,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(tO,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(aO,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(nO,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPProcessor"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xp,"id","transformers.AutoModel"),c(Xp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Xp,"href","#transformers.AutoModel"),c(pd,"class","relative group"),c(sO,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lO,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iO,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dO,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertModel"),c(cO,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartModel"),c(fO,"href","/docs/transformers/v4.22.0/en/model_doc/beit#transformers.BeitModel"),c(mO,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertModel"),c(gO,"href","/docs/transformers/v4.22.0/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(hO,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdModel"),c(uO,"href","/docs/transformers/v4.22.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(pO,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(_O,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(vO,"href","/docs/transformers/v4.22.0/en/model_doc/bloom#transformers.BloomModel"),c(bO,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertModel"),c(FO,"href","/docs/transformers/v4.22.0/en/model_doc/canine#transformers.CanineModel"),c(TO,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.CLIPModel"),c(MO,"href","/docs/transformers/v4.22.0/en/model_doc/codegen#transformers.CodeGenModel"),c(EO,"href","/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertModel"),c(CO,"href","/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.ConvNextModel"),c(wO,"href","/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLModel"),c(AO,"href","/docs/transformers/v4.22.0/en/model_doc/cvt#transformers.CvtModel"),c(LO,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(yO,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(xO,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c($O,"href","/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaModel"),c(kO,"href","/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(SO,"href","/docs/transformers/v4.22.0/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(RO,"href","/docs/transformers/v4.22.0/en/model_doc/deit#transformers.DeiTModel"),c(PO,"href","/docs/transformers/v4.22.0/en/model_doc/detr#transformers.DetrModel"),c(BO,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertModel"),c(IO,"href","/docs/transformers/v4.22.0/en/model_doc/donut#transformers.DonutSwinModel"),c(NO,"href","/docs/transformers/v4.22.0/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(qO,"href","/docs/transformers/v4.22.0/en/model_doc/dpt#transformers.DPTModel"),c(jO,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraModel"),c(DO,"href","/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieModel"),c(GO,"href","/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertModel"),c(OO,"href","/docs/transformers/v4.22.0/en/model_doc/flava#transformers.FlavaModel"),c(VO,"href","/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetModel"),c(XO,"href","/docs/transformers/v4.22.0/en/model_doc/fsmt#transformers.FSMTModel"),c(zO,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelModel"),c(QO,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelBaseModel"),c(WO,"href","/docs/transformers/v4.22.0/en/model_doc/glpn#transformers.GLPNModel"),c(UO,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2Model"),c(HO,"href","/docs/transformers/v4.22.0/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(JO,"href","/docs/transformers/v4.22.0/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(YO,"href","/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJModel"),c(KO,"href","/docs/transformers/v4.22.0/en/model_doc/groupvit#transformers.GroupViTModel"),c(ZO,"href","/docs/transformers/v4.22.0/en/model_doc/hubert#transformers.HubertModel"),c(eV,"href","/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertModel"),c(oV,"href","/docs/transformers/v4.22.0/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(rV,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(tV,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(aV,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(nV,"href","/docs/transformers/v4.22.0/en/model_doc/led#transformers.LEDModel"),c(sV,"href","/docs/transformers/v4.22.0/en/model_doc/levit#transformers.LevitModel"),c(lV,"href","/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerModel"),c(iV,"href","/docs/transformers/v4.22.0/en/model_doc/longt5#transformers.LongT5Model"),c(dV,"href","/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeModel"),c(cV,"href","/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.LxmertModel"),c(fV,"href","/docs/transformers/v4.22.0/en/model_doc/m2m_100#transformers.M2M100Model"),c(mV,"href","/docs/transformers/v4.22.0/en/model_doc/marian#transformers.MarianModel"),c(gV,"href","/docs/transformers/v4.22.0/en/model_doc/maskformer#transformers.MaskFormerModel"),c(hV,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartModel"),c(uV,"href","/docs/transformers/v4.22.0/en/model_doc/mctct#transformers.MCTCTModel"),c(pV,"href","/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(_V,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertModel"),c(vV,"href","/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.MobileViTModel"),c(bV,"href","/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetModel"),c(FV,"href","/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.MT5Model"),c(TV,"href","/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpModel"),c(MV,"href","/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaModel"),c(EV,"href","/docs/transformers/v4.22.0/en/model_doc/m2m_100#transformers.M2M100Model"),c(CV,"href","/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerModel"),c(wV,"href","/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(AV,"href","/docs/transformers/v4.22.0/en/model_doc/opt#transformers.OPTModel"),c(LV,"href","/docs/transformers/v4.22.0/en/model_doc/owlvit#transformers.OwlViTModel"),c(yV,"href","/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusModel"),c(xV,"href","/docs/transformers/v4.22.0/en/model_doc/pegasus_x#transformers.PegasusXModel"),c($V,"href","/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverModel"),c(kV,"href","/docs/transformers/v4.22.0/en/model_doc/plbart#transformers.PLBartModel"),c(SV,"href","/docs/transformers/v4.22.0/en/model_doc/poolformer#transformers.PoolFormerModel"),c(RV,"href","/docs/transformers/v4.22.0/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(PV,"href","/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertModel"),c(BV,"href","/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerModel"),c(IV,"href","/docs/transformers/v4.22.0/en/model_doc/regnet#transformers.RegNetModel"),c(NV,"href","/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertModel"),c(qV,"href","/docs/transformers/v4.22.0/en/model_doc/resnet#transformers.ResNetModel"),c(jV,"href","/docs/transformers/v4.22.0/en/model_doc/retribert#transformers.RetriBertModel"),c(DV,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaModel"),c(GV,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerModel"),c(OV,"href","/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.SegformerModel"),c(VV,"href","/docs/transformers/v4.22.0/en/model_doc/sew#transformers.SEWModel"),c(XV,"href","/docs/transformers/v4.22.0/en/model_doc/sew-d#transformers.SEWDModel"),c(zV,"href","/docs/transformers/v4.22.0/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(QV,"href","/docs/transformers/v4.22.0/en/model_doc/splinter#transformers.SplinterModel"),c(WV,"href","/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(UV,"href","/docs/transformers/v4.22.0/en/model_doc/swin#transformers.SwinModel"),c(HV,"href","/docs/transformers/v4.22.0/en/model_doc/swinv2#transformers.Swinv2Model"),c(JV,"href","/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5Model"),c(YV,"href","/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasModel"),c(KV,"href","/docs/transformers/v4.22.0/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(ZV,"href","/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(eX,"href","/docs/transformers/v4.22.0/en/model_doc/unispeech#transformers.UniSpeechModel"),c(oX,"href","/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(rX,"href","/docs/transformers/v4.22.0/en/model_doc/van#transformers.VanModel"),c(tX,"href","/docs/transformers/v4.22.0/en/model_doc/videomae#transformers.VideoMAEModel"),c(aX,"href","/docs/transformers/v4.22.0/en/model_doc/vilt#transformers.ViltModel"),c(nX,"href","/docs/transformers/v4.22.0/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(sX,"href","/docs/transformers/v4.22.0/en/model_doc/visual_bert#transformers.VisualBertModel"),c(lX,"href","/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTModel"),c(iX,"href","/docs/transformers/v4.22.0/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(dX,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(cX,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(fX,"href","/docs/transformers/v4.22.0/en/model_doc/wavlm#transformers.WavLMModel"),c(mX,"href","/docs/transformers/v4.22.0/en/model_doc/xclip#transformers.XCLIPModel"),c(gX,"href","/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.XGLMModel"),c(hX,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMModel"),c(uX,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(pX,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(_X,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(vX,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetModel"),c(bX,"href","/docs/transformers/v4.22.0/en/model_doc/yolos#transformers.YolosModel"),c(FX,"href","/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoModel"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(av,"id","transformers.AutoModelForPreTraining"),c(av,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(av,"href","#transformers.AutoModelForPreTraining"),c(bd,"class","relative group"),c(TX,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(MX,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(EX,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CX,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertForPreTraining"),c(wX,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(AX,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertForPreTraining"),c(LX,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(yX,"href","/docs/transformers/v4.22.0/en/model_doc/bloom#transformers.BloomForCausalLM"),c(xX,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c($X,"href","/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(kX,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(SX,"href","/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(RX,"href","/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(PX,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(BX,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraForPreTraining"),c(IX,"href","/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieForPreTraining"),c(NX,"href","/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(qX,"href","/docs/transformers/v4.22.0/en/model_doc/flava#transformers.FlavaForPreTraining"),c(jX,"href","/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetForPreTraining"),c(DX,"href","/docs/transformers/v4.22.0/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(GX,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(OX,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(VX,"href","/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(XX,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(zX,"href","/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(QX,"href","/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeForMaskedLM"),c(WX,"href","/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(UX,"href","/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(HX,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(JX,"href","/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(YX,"href","/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(KX,"href","/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(ZX,"href","/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(ez,"href","/docs/transformers/v4.22.0/en/model_doc/retribert#transformers.RetriBertModel"),c(oz,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(rz,"href","/docs/transformers/v4.22.0/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(tz,"href","/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(az,"href","/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(nz,"href","/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(sz,"href","/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(lz,"href","/docs/transformers/v4.22.0/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(iz,"href","/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(dz,"href","/docs/transformers/v4.22.0/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),c(cz,"href","/docs/transformers/v4.22.0/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(fz,"href","/docs/transformers/v4.22.0/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(mz,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(gz,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(hz,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(uz,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(pz,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(_z,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(r4,"id","transformers.AutoModelForCausalLM"),c(r4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(r4,"href","#transformers.AutoModelForCausalLM"),c(Md,"class","relative group"),c(vz,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bz,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Fz,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tz,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartForCausalLM"),c(Mz,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertLMHeadModel"),c(Ez,"href","/docs/transformers/v4.22.0/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(Cz,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(wz,"href","/docs/transformers/v4.22.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(Az,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(Lz,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(yz,"href","/docs/transformers/v4.22.0/en/model_doc/bloom#transformers.BloomForCausalLM"),c(xz,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertForCausalLM"),c($z,"href","/docs/transformers/v4.22.0/en/model_doc/codegen#transformers.CodeGenForCausalLM"),c(kz,"href","/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(Sz,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(Rz,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraForCausalLM"),c(Pz,"href","/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieForCausalLM"),c(Bz,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(Iz,"href","/docs/transformers/v4.22.0/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(Nz,"href","/docs/transformers/v4.22.0/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(qz,"href","/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(jz,"href","/docs/transformers/v4.22.0/en/model_doc/marian#transformers.MarianForCausalLM"),c(Dz,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartForCausalLM"),c(Gz,"href","/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(Oz,"href","/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpForCausalLM"),c(Vz,"href","/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(Xz,"href","/docs/transformers/v4.22.0/en/model_doc/opt#transformers.OPTForCausalLM"),c(zz,"href","/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(Qz,"href","/docs/transformers/v4.22.0/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(Wz,"href","/docs/transformers/v4.22.0/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(Uz,"href","/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(Hz,"href","/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(Jz,"href","/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(Yz,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(Kz,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(Zz,"href","/docs/transformers/v4.22.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(eQ,"href","/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(oQ,"href","/docs/transformers/v4.22.0/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(rQ,"href","/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(tQ,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(aQ,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(nQ,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(sQ,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(lQ,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(W4,"id","transformers.AutoModelForMaskedLM"),c(W4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(W4,"href","#transformers.AutoModelForMaskedLM"),c(wd,"class","relative group"),c(iQ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dQ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cQ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fQ,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(mQ,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(gQ,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertForMaskedLM"),c(hQ,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(uQ,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(pQ,"href","/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(_Q,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(vQ,"href","/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(bQ,"href","/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(FQ,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(TQ,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(MQ,"href","/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieForMaskedLM"),c(EQ,"href","/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(CQ,"href","/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(wQ,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(AQ,"href","/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(LQ,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(yQ,"href","/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(xQ,"href","/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeForMaskedLM"),c($Q,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(kQ,"href","/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(SQ,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(RQ,"href","/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(PQ,"href","/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(BQ,"href","/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(IQ,"href","/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(NQ,"href","/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(qQ,"href","/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(jQ,"href","/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(DQ,"href","/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(GQ,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(OQ,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(VQ,"href","/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(XQ,"href","/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(zQ,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(QQ,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(WQ,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(UQ,"href","/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ib,"id","transformers.AutoModelForSeq2SeqLM"),c(Ib,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ib,"href","#transformers.AutoModelForSeq2SeqLM"),c(yd,"class","relative group"),c(HQ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JQ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YQ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KQ,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(ZQ,"href","/docs/transformers/v4.22.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(eW,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(oW,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(rW,"href","/docs/transformers/v4.22.0/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(tW,"href","/docs/transformers/v4.22.0/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(aW,"href","/docs/transformers/v4.22.0/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(nW,"href","/docs/transformers/v4.22.0/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(sW,"href","/docs/transformers/v4.22.0/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(lW,"href","/docs/transformers/v4.22.0/en/model_doc/marian#transformers.MarianMTModel"),c(iW,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(dW,"href","/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(cW,"href","/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(fW,"href","/docs/transformers/v4.22.0/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(mW,"href","/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(gW,"href","/docs/transformers/v4.22.0/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),c(hW,"href","/docs/transformers/v4.22.0/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(uW,"href","/docs/transformers/v4.22.0/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(pW,"href","/docs/transformers/v4.22.0/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(_W,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s1,"id","transformers.AutoModelForSequenceClassification"),c(s1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s1,"href","#transformers.AutoModelForSequenceClassification"),c(kd,"class","relative group"),c(vW,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bW,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(FW,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TW,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(MW,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartForSequenceClassification"),c(EW,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertForSequenceClassification"),c(CW,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(wW,"href","/docs/transformers/v4.22.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(AW,"href","/docs/transformers/v4.22.0/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(LW,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(yW,"href","/docs/transformers/v4.22.0/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(xW,"href","/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c($W,"href","/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(kW,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(SW,"href","/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(RW,"href","/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(PW,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(BW,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(IW,"href","/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),c(NW,"href","/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(qW,"href","/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(jW,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(DW,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(GW,"href","/docs/transformers/v4.22.0/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(OW,"href","/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(VW,"href","/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(XW,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(zW,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(QW,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(WW,"href","/docs/transformers/v4.22.0/en/model_doc/led#transformers.LEDForSequenceClassification"),c(UW,"href","/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(HW,"href","/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeForSequenceClassification"),c(JW,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(YW,"href","/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(KW,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(ZW,"href","/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(eU,"href","/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpForSequenceClassification"),c(oU,"href","/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(rU,"href","/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(tU,"href","/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(aU,"href","/docs/transformers/v4.22.0/en/model_doc/opt#transformers.OPTForSequenceClassification"),c(nU,"href","/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(sU,"href","/docs/transformers/v4.22.0/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(lU,"href","/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(iU,"href","/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(dU,"href","/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(cU,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(fU,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(mU,"href","/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(gU,"href","/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(hU,"href","/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(uU,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(pU,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(_U,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(vU,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(bU,"href","/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(d0,"id","transformers.AutoModelForMultipleChoice"),c(d0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d0,"href","#transformers.AutoModelForMultipleChoice"),c(Pd,"class","relative group"),c(FU,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TU,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MU,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EU,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(CU,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertForMultipleChoice"),c(wU,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(AU,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(LU,"href","/docs/transformers/v4.22.0/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(yU,"href","/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(xU,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c($U,"href","/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(kU,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(SU,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(RU,"href","/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),c(PU,"href","/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(BU,"href","/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(IU,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(NU,"href","/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(qU,"href","/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(jU,"href","/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeForMultipleChoice"),c(DU,"href","/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(GU,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(OU,"href","/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(VU,"href","/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(XU,"href","/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(zU,"href","/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(QU,"href","/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(WU,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(UU,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(HU,"href","/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(JU,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(YU,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(KU,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(ZU,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(eH,"href","/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z0,"id","transformers.AutoModelForNextSentencePrediction"),c(z0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z0,"href","#transformers.AutoModelForNextSentencePrediction"),c(Nd,"class","relative group"),c(oH,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rH,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tH,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aH,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(nH,"href","/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),c(sH,"href","/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(lH,"href","/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(iH,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(dH,"href","/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(cH,"href","/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rF,"id","transformers.AutoModelForTokenClassification"),c(rF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(rF,"href","#transformers.AutoModelForTokenClassification"),c(Dd,"class","relative group"),c(fH,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mH,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gH,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hH,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(uH,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertForTokenClassification"),c(pH,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(_H,"href","/docs/transformers/v4.22.0/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(vH,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(bH,"href","/docs/transformers/v4.22.0/en/model_doc/canine#transformers.CanineForTokenClassification"),c(FH,"href","/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(TH,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(MH,"href","/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(EH,"href","/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(CH,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(wH,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(AH,"href","/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieForTokenClassification"),c(LH,"href","/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(yH,"href","/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(xH,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c($H,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(kH,"href","/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(SH,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(RH,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(PH,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(BH,"href","/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(IH,"href","/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeForTokenClassification"),c(NH,"href","/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(qH,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(jH,"href","/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(DH,"href","/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(GH,"href","/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(OH,"href","/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(VH,"href","/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(XH,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(zH,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(QH,"href","/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(WH,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(UH,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(HH,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(JH,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(YH,"href","/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XF,"id","transformers.AutoModelForQuestionAnswering"),c(XF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(XF,"href","#transformers.AutoModelForQuestionAnswering"),c(Vd,"class","relative group"),c(KH,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZH,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eJ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oJ,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(rJ,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(tJ,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(aJ,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(nJ,"href","/docs/transformers/v4.22.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(sJ,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(lJ,"href","/docs/transformers/v4.22.0/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(iJ,"href","/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(dJ,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(cJ,"href","/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(fJ,"href","/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(mJ,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(gJ,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(hJ,"href","/docs/transformers/v4.22.0/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),c(uJ,"href","/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(pJ,"href","/docs/transformers/v4.22.0/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(_J,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(vJ,"href","/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(bJ,"href","/docs/transformers/v4.22.0/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(FJ,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(TJ,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(MJ,"href","/docs/transformers/v4.22.0/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(EJ,"href","/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(CJ,"href","/docs/transformers/v4.22.0/en/model_doc/luke#transformers.LukeForQuestionAnswering"),c(wJ,"href","/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(AJ,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(LJ,"href","/docs/transformers/v4.22.0/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(yJ,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(xJ,"href","/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c($J,"href","/docs/transformers/v4.22.0/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),c(kJ,"href","/docs/transformers/v4.22.0/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(SJ,"href","/docs/transformers/v4.22.0/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(RJ,"href","/docs/transformers/v4.22.0/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(PJ,"href","/docs/transformers/v4.22.0/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(BJ,"href","/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(IJ,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(NJ,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(qJ,"href","/docs/transformers/v4.22.0/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(jJ,"href","/docs/transformers/v4.22.0/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(DJ,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(GJ,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(OJ,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(VJ,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(XJ,"href","/docs/transformers/v4.22.0/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qT,"id","transformers.AutoModelForTableQuestionAnswering"),c(qT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qT,"href","#transformers.AutoModelForTableQuestionAnswering"),c(Qd,"class","relative group"),c(zJ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QJ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WJ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UJ,"href","/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VT,"id","transformers.AutoModelForDocumentQuestionAnswering"),c(VT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(VT,"href","#transformers.AutoModelForDocumentQuestionAnswering"),c(Hd,"class","relative group"),c(HJ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JJ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YJ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KJ,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),c(ZJ,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(eY,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JT,"id","transformers.AutoModelForImageClassification"),c(JT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(JT,"href","#transformers.AutoModelForImageClassification"),c(Zd,"class","relative group"),c(oY,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rY,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tY,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aY,"href","/docs/transformers/v4.22.0/en/model_doc/beit#transformers.BeitForImageClassification"),c(nY,"href","/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(sY,"href","/docs/transformers/v4.22.0/en/model_doc/cvt#transformers.CvtForImageClassification"),c(lY,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(iY,"href","/docs/transformers/v4.22.0/en/model_doc/deit#transformers.DeiTForImageClassification"),c(dY,"href","/docs/transformers/v4.22.0/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(cY,"href","/docs/transformers/v4.22.0/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(fY,"href","/docs/transformers/v4.22.0/en/model_doc/levit#transformers.LevitForImageClassification"),c(mY,"href","/docs/transformers/v4.22.0/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(gY,"href","/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),c(hY,"href","/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(uY,"href","/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(pY,"href","/docs/transformers/v4.22.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(_Y,"href","/docs/transformers/v4.22.0/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(vY,"href","/docs/transformers/v4.22.0/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(bY,"href","/docs/transformers/v4.22.0/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(FY,"href","/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(TY,"href","/docs/transformers/v4.22.0/en/model_doc/swin#transformers.SwinForImageClassification"),c(MY,"href","/docs/transformers/v4.22.0/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),c(EY,"href","/docs/transformers/v4.22.0/en/model_doc/van#transformers.VanForImageClassification"),c(CY,"href","/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTForImageClassification"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hM,"id","transformers.AutoModelForVideoClassification"),c(hM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hM,"href","#transformers.AutoModelForVideoClassification"),c(rc,"class","relative group"),c(wY,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AY,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LY,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yY,"href","/docs/transformers/v4.22.0/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bM,"id","transformers.AutoModelForVision2Seq"),c(bM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bM,"href","#transformers.AutoModelForVision2Seq"),c(nc,"class","relative group"),c(xY,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($Y,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kY,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SY,"href","/docs/transformers/v4.22.0/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CM,"id","transformers.AutoModelForVisualQuestionAnswering"),c(CM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(CM,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(ic,"class","relative group"),c(RY,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PY,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BY,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IY,"href","/docs/transformers/v4.22.0/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xM,"id","transformers.AutoModelForAudioClassification"),c(xM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xM,"href","#transformers.AutoModelForAudioClassification"),c(fc,"class","relative group"),c(NY,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qY,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jY,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DY,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(GY,"href","/docs/transformers/v4.22.0/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(OY,"href","/docs/transformers/v4.22.0/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(VY,"href","/docs/transformers/v4.22.0/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(XY,"href","/docs/transformers/v4.22.0/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(zY,"href","/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(QY,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(WY,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(UY,"href","/docs/transformers/v4.22.0/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OM,"id","transformers.AutoModelForAudioFrameClassification"),c(OM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(OM,"href","#transformers.AutoModelForAudioFrameClassification"),c(hc,"class","relative group"),c(HY,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JY,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YY,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KY,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(ZY,"href","/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(eK,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(oK,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(rK,"href","/docs/transformers/v4.22.0/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YM,"id","transformers.AutoModelForCTC"),c(YM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(YM,"href","#transformers.AutoModelForCTC"),c(_c,"class","relative group"),c(tK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sK,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(lK,"href","/docs/transformers/v4.22.0/en/model_doc/hubert#transformers.HubertForCTC"),c(iK,"href","/docs/transformers/v4.22.0/en/model_doc/mctct#transformers.MCTCTForCTC"),c(dK,"href","/docs/transformers/v4.22.0/en/model_doc/sew#transformers.SEWForCTC"),c(cK,"href","/docs/transformers/v4.22.0/en/model_doc/sew-d#transformers.SEWDForCTC"),c(fK,"href","/docs/transformers/v4.22.0/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(mK,"href","/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(gK,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(hK,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(uK,"href","/docs/transformers/v4.22.0/en/model_doc/wavlm#transformers.WavLMForCTC"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fE,"id","transformers.AutoModelForSpeechSeq2Seq"),c(fE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fE,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Fc,"class","relative group"),c(pK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_K,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bK,"href","/docs/transformers/v4.22.0/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(FK,"href","/docs/transformers/v4.22.0/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_E,"id","transformers.AutoModelForAudioXVector"),c(_E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_E,"href","#transformers.AutoModelForAudioXVector"),c(Ec,"class","relative group"),c(TK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(MK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(EK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CK,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(wK,"href","/docs/transformers/v4.22.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(AK,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(LK,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(yK,"href","/docs/transformers/v4.22.0/en/model_doc/wavlm#transformers.WavLMForXVector"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AE,"id","transformers.AutoModelForMaskedImageModeling"),c(AE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(AE,"href","#transformers.AutoModelForMaskedImageModeling"),c(Ac,"class","relative group"),c(xK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($K,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SK,"href","/docs/transformers/v4.22.0/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(RK,"href","/docs/transformers/v4.22.0/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(PK,"href","/docs/transformers/v4.22.0/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),c(BK,"href","/docs/transformers/v4.22.0/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PE,"id","transformers.AutoModelForObjectDetection"),c(PE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(PE,"href","#transformers.AutoModelForObjectDetection"),c(xc,"class","relative group"),c(IK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jK,"href","/docs/transformers/v4.22.0/en/model_doc/detr#transformers.DetrForObjectDetection"),c(DK,"href","/docs/transformers/v4.22.0/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DE,"id","transformers.AutoModelForImageSegmentation"),c(DE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DE,"href","#transformers.AutoModelForImageSegmentation"),c(Sc,"class","relative group"),c(GK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XK,"href","/docs/transformers/v4.22.0/en/model_doc/detr#transformers.DetrForSegmentation"),c(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zE,"id","transformers.AutoModelForSemanticSegmentation"),c(zE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zE,"href","#transformers.AutoModelForSemanticSegmentation"),c(Bc,"class","relative group"),c(zK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UK,"href","/docs/transformers/v4.22.0/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(HK,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(JK,"href","/docs/transformers/v4.22.0/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(YK,"href","/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),c(KK,"href","/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eC,"id","transformers.AutoModelForInstanceSegmentation"),c(eC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(eC,"href","#transformers.AutoModelForInstanceSegmentation"),c(qc,"class","relative group"),c(ZK,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eZ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oZ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rZ,"href","/docs/transformers/v4.22.0/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nC,"id","transformers.TFAutoModel"),c(nC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(nC,"href","#transformers.TFAutoModel"),c(Gc,"class","relative group"),c(tZ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aZ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nZ,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sZ,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.TFAlbertModel"),c(lZ,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.TFBartModel"),c(iZ,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertModel"),c(dZ,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(cZ,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(fZ,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.TFCamembertModel"),c(mZ,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.TFCLIPModel"),c(gZ,"href","/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.TFConvBertModel"),c(hZ,"href","/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.TFConvNextModel"),c(uZ,"href","/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.TFCTRLModel"),c(pZ,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(_Z,"href","/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.TFDebertaModel"),c(vZ,"href","/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(bZ,"href","/docs/transformers/v4.22.0/en/model_doc/deit#transformers.TFDeiTModel"),c(FZ,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(TZ,"href","/docs/transformers/v4.22.0/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(MZ,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.TFElectraModel"),c(EZ,"href","/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(CZ,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.TFFunnelModel"),c(wZ,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(AZ,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.TFGPT2Model"),c(LZ,"href","/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.TFGPTJModel"),c(yZ,"href","/docs/transformers/v4.22.0/en/model_doc/hubert#transformers.TFHubertModel"),c(xZ,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c($Z,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),c(kZ,"href","/docs/transformers/v4.22.0/en/model_doc/led#transformers.TFLEDModel"),c(SZ,"href","/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.TFLongformerModel"),c(RZ,"href","/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.TFLxmertModel"),c(PZ,"href","/docs/transformers/v4.22.0/en/model_doc/marian#transformers.TFMarianModel"),c(BZ,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.TFMBartModel"),c(IZ,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(NZ,"href","/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.TFMobileViTModel"),c(qZ,"href","/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.TFMPNetModel"),c(jZ,"href","/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.TFMT5Model"),c(DZ,"href","/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(GZ,"href","/docs/transformers/v4.22.0/en/model_doc/opt#transformers.TFOPTModel"),c(OZ,"href","/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.TFPegasusModel"),c(VZ,"href","/docs/transformers/v4.22.0/en/model_doc/regnet#transformers.TFRegNetModel"),c(XZ,"href","/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.TFRemBertModel"),c(zZ,"href","/docs/transformers/v4.22.0/en/model_doc/resnet#transformers.TFResNetModel"),c(QZ,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaModel"),c(WZ,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.TFRoFormerModel"),c(UZ,"href","/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.TFSegformerModel"),c(HZ,"href","/docs/transformers/v4.22.0/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(JZ,"href","/docs/transformers/v4.22.0/en/model_doc/swin#transformers.TFSwinModel"),c(YZ,"href","/docs/transformers/v4.22.0/en/model_doc/t5#transformers.TFT5Model"),c(KZ,"href","/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TFTapasModel"),c(ZZ,"href","/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(eee,"href","/docs/transformers/v4.22.0/en/model_doc/vit#transformers.TFViTModel"),c(oee,"href","/docs/transformers/v4.22.0/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(ree,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(tee,"href","/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.TFXGLMModel"),c(aee,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.TFXLMModel"),c(nee,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(see,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.TFXLNetModel"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l3,"id","transformers.TFAutoModelForPreTraining"),c(l3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l3,"href","#transformers.TFAutoModelForPreTraining"),c(Xc,"class","relative group"),c(lee,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iee,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dee,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cee,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(fee,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(mee,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertForPreTraining"),c(gee,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(hee,"href","/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(uee,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(pee,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(_ee,"href","/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(vee,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(bee,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(Fee,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(Tee,"href","/docs/transformers/v4.22.0/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(Mee,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(Eee,"href","/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(Cee,"href","/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(wee,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(Aee,"href","/docs/transformers/v4.22.0/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Lee,"href","/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(yee,"href","/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(xee,"href","/docs/transformers/v4.22.0/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c($ee,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(kee,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(See,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(R3,"id","transformers.TFAutoModelForCausalLM"),c(R3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R3,"href","#transformers.TFAutoModelForCausalLM"),c(Wc,"class","relative group"),c(Ree,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pee,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Bee,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Iee,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(Nee,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(qee,"href","/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(jee,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(Dee,"href","/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(Gee,"href","/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(Oee,"href","/docs/transformers/v4.22.0/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(Vee,"href","/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(Xee,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(zee,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(Qee,"href","/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(Wee,"href","/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),c(Uee,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(Hee,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(J3,"id","transformers.TFAutoModelForImageClassification"),c(J3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(J3,"href","#transformers.TFAutoModelForImageClassification"),c(Jc,"class","relative group"),c(Jee,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yee,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Kee,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zee,"href","/docs/transformers/v4.22.0/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(eoe,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(ooe,"href","/docs/transformers/v4.22.0/en/model_doc/deit#transformers.TFDeiTForImageClassification"),c(roe,"href","/docs/transformers/v4.22.0/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),c(toe,"href","/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),c(aoe,"href","/docs/transformers/v4.22.0/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),c(noe,"href","/docs/transformers/v4.22.0/en/model_doc/resnet#transformers.TFResNetForImageClassification"),c(soe,"href","/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),c(loe,"href","/docs/transformers/v4.22.0/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(ioe,"href","/docs/transformers/v4.22.0/en/model_doc/vit#transformers.TFViTForImageClassification"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l5,"id","transformers.TFAutoModelForSemanticSegmentation"),c(l5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l5,"href","#transformers.TFAutoModelForSemanticSegmentation"),c(Zc,"class","relative group"),c(doe,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(coe,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(foe,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(moe,"href","/docs/transformers/v4.22.0/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),c(goe,"href","/docs/transformers/v4.22.0/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),c(hoe,"href","/docs/transformers/v4.22.0/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(g5,"id","transformers.TFAutoModelForMaskedLM"),c(g5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(g5,"href","#transformers.TFAutoModelForMaskedLM"),c(tf,"class","relative group"),c(uoe,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(poe,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_oe,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(voe,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(boe,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(Foe,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(Toe,"href","/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(Moe,"href","/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(Eoe,"href","/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(Coe,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(woe,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(Aoe,"href","/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(Loe,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(yoe,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(xoe,"href","/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c($oe,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(koe,"href","/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(Soe,"href","/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(Roe,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(Poe,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(Boe,"href","/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(Ioe,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(Noe,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(I5,"id","transformers.TFAutoModelForSeq2SeqLM"),c(I5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I5,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(sf,"class","relative group"),c(qoe,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(joe,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Doe,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Goe,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(Ooe,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(Voe,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(Xoe,"href","/docs/transformers/v4.22.0/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(zoe,"href","/docs/transformers/v4.22.0/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(Qoe,"href","/docs/transformers/v4.22.0/en/model_doc/marian#transformers.TFMarianMTModel"),c(Woe,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(Uoe,"href","/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(Hoe,"href","/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(Joe,"href","/docs/transformers/v4.22.0/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(H5,"id","transformers.TFAutoModelForSequenceClassification"),c(H5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(H5,"href","#transformers.TFAutoModelForSequenceClassification"),c(cf,"class","relative group"),c(Yoe,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Koe,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Zoe,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ere,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(ore,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(rre,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(tre,"href","/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(are,"href","/docs/transformers/v4.22.0/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(nre,"href","/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(sre,"href","/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(lre,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(ire,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(dre,"href","/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(cre,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(fre,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(mre,"href","/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(gre,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(hre,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),c(ure,"href","/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(pre,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(_re,"href","/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(vre,"href","/docs/transformers/v4.22.0/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(bre,"href","/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(Fre,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(Tre,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(Mre,"href","/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(Ere,"href","/docs/transformers/v4.22.0/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(Cre,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(wre,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(Are,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ww,"id","transformers.TFAutoModelForMultipleChoice"),c(ww,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ww,"href","#transformers.TFAutoModelForMultipleChoice"),c(gf,"class","relative group"),c(Lre,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yre,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xre,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($re,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(kre,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(Sre,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(Rre,"href","/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(Pre,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(Bre,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(Ire,"href","/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(Nre,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(qre,"href","/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(jre,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(Dre,"href","/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(Gre,"href","/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(Ore,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(Vre,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(Xre,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(zre,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(Qre,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zw,"id","transformers.TFAutoModelForNextSentencePrediction"),c(zw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zw,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(pf,"class","relative group"),c(Wre,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ure,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Hre,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jre,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(Yre,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jw,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(Jw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Jw,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(bf,"class","relative group"),c(Kre,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zre,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ete,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ote,"href","/docs/transformers/v4.22.0/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eA,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),c(eA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(eA,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),c(Mf,"class","relative group"),c(rte,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tte,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ate,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nte,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aA,"id","transformers.TFAutoModelForTokenClassification"),c(aA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aA,"href","#transformers.TFAutoModelForTokenClassification"),c(wf,"class","relative group"),c(ste,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lte,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ite,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dte,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(cte,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(fte,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(mte,"href","/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(gte,"href","/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(hte,"href","/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(ute,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(pte,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(_te,"href","/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(vte,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(bte,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(Fte,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),c(Tte,"href","/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(Mte,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(Ete,"href","/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(Cte,"href","/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(wte,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(Ate,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(Lte,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(yte,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(xte,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yA,"id","transformers.TFAutoModelForQuestionAnswering"),c(yA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yA,"href","#transformers.TFAutoModelForQuestionAnswering"),c(yf,"class","relative group"),c($te,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kte,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Ste,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rte,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(Pte,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(Bte,"href","/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(Ite,"href","/docs/transformers/v4.22.0/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(Nte,"href","/docs/transformers/v4.22.0/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(qte,"href","/docs/transformers/v4.22.0/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(jte,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(Dte,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(Gte,"href","/docs/transformers/v4.22.0/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(Ote,"href","/docs/transformers/v4.22.0/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(Vte,"href","/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(Xte,"href","/docs/transformers/v4.22.0/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),c(zte,"href","/docs/transformers/v4.22.0/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(Qte,"href","/docs/transformers/v4.22.0/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(Wte,"href","/docs/transformers/v4.22.0/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(Ute,"href","/docs/transformers/v4.22.0/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(Hte,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(Jte,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(Yte,"href","/docs/transformers/v4.22.0/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(Kte,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(Zte,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KA,"id","transformers.TFAutoModelForVision2Seq"),c(KA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KA,"href","#transformers.TFAutoModelForVision2Seq"),c(kf,"class","relative group"),c(eae,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oae,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rae,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tae,"href","/docs/transformers/v4.22.0/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(r6,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(r6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(r6,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(Pf,"class","relative group"),c(aae,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nae,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sae,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lae,"href","/docs/transformers/v4.22.0/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s6,"id","transformers.FlaxAutoModel"),c(s6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s6,"href","#transformers.FlaxAutoModel"),c(Nf,"class","relative group"),c(iae,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dae,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cae,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fae,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.FlaxAlbertModel"),c(mae,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.FlaxBartModel"),c(gae,"href","/docs/transformers/v4.22.0/en/model_doc/beit#transformers.FlaxBeitModel"),c(hae,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertModel"),c(uae,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(pae,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(_ae,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(vae,"href","/docs/transformers/v4.22.0/en/model_doc/clip#transformers.FlaxCLIPModel"),c(bae,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(Fae,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.FlaxElectraModel"),c(Tae,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(Mae,"href","/docs/transformers/v4.22.0/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(Eae,"href","/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(Cae,"href","/docs/transformers/v4.22.0/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(wae,"href","/docs/transformers/v4.22.0/en/model_doc/marian#transformers.FlaxMarianModel"),c(Aae,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.FlaxMBartModel"),c(Lae,"href","/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.FlaxMT5Model"),c(yae,"href","/docs/transformers/v4.22.0/en/model_doc/opt#transformers.FlaxOPTModel"),c(xae,"href","/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c($ae,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(kae,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(Sae,"href","/docs/transformers/v4.22.0/en/model_doc/t5#transformers.FlaxT5Model"),c(Rae,"href","/docs/transformers/v4.22.0/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(Pae,"href","/docs/transformers/v4.22.0/en/model_doc/vit#transformers.FlaxViTModel"),c(Bae,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(Iae,"href","/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(Nae,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(I6,"id","transformers.FlaxAutoModelForCausalLM"),c(I6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I6,"href","#transformers.FlaxAutoModelForCausalLM"),c(Df,"class","relative group"),c(qae,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jae,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Dae,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gae,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(Oae,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(Vae,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(Xae,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(zae,"href","/docs/transformers/v4.22.0/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(Qae,"href","/docs/transformers/v4.22.0/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(Wae,"href","/docs/transformers/v4.22.0/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(Uae,"href","/docs/transformers/v4.22.0/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(Hae,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(Jae,"href","/docs/transformers/v4.22.0/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(H6,"id","transformers.FlaxAutoModelForPreTraining"),c(H6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(H6,"href","#transformers.FlaxAutoModelForPreTraining"),c(Vf,"class","relative group"),c(Yae,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kae,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Zae,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ene,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(one,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(rne,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(tne,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(ane,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(nne,"href","/docs/transformers/v4.22.0/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(sne,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(lne,"href","/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(ine,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(dne,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(cne,"href","/docs/transformers/v4.22.0/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(fne,"href","/docs/transformers/v4.22.0/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(mne,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f7,"id","transformers.FlaxAutoModelForMaskedLM"),c(f7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f7,"href","#transformers.FlaxAutoModelForMaskedLM"),c(Qf,"class","relative group"),c(gne,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hne,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(une,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pne,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(_ne,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(vne,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(bne,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(Fne,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(Tne,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(Mne,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Ene,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(Cne,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(wne,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C7,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(C7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C7,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(Hf,"class","relative group"),c(Ane,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lne,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yne,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xne,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c($ne,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(kne,"href","/docs/transformers/v4.22.0/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(Sne,"href","/docs/transformers/v4.22.0/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(Rne,"href","/docs/transformers/v4.22.0/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(Pne,"href","/docs/transformers/v4.22.0/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(Bne,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Ine,"href","/docs/transformers/v4.22.0/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(Nne,"href","/docs/transformers/v4.22.0/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(qne,"href","/docs/transformers/v4.22.0/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(N7,"id","transformers.FlaxAutoModelForSequenceClassification"),c(N7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N7,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Kf,"class","relative group"),c(jne,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dne,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Gne,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(One,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(Vne,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(Xne,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(zne,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(Qne,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(Wne,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(Une,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(Hne,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(Jne,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(Yne,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(J7,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(J7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(J7,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(om,"class","relative group"),c(Kne,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zne,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ese,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ose,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(rse,"href","/docs/transformers/v4.22.0/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(tse,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(ase,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(nse,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(sse,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(lse,"href","/docs/transformers/v4.22.0/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(ise,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(dse,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(cse,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dL,"id","transformers.FlaxAutoModelForTokenClassification"),c(dL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dL,"href","#transformers.FlaxAutoModelForTokenClassification"),c(am,"class","relative group"),c(fse,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mse,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gse,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hse,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(use,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(pse,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(_se,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(vse,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(bse,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Fse,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Tse,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FL,"id","transformers.FlaxAutoModelForMultipleChoice"),c(FL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(FL,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(lm,"class","relative group"),c(Mse,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ese,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Cse,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wse,"href","/docs/transformers/v4.22.0/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(Ase,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(Lse,"href","/docs/transformers/v4.22.0/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(yse,"href","/docs/transformers/v4.22.0/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(xse,"href","/docs/transformers/v4.22.0/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c($se,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(kse,"href","/docs/transformers/v4.22.0/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(Sse,"href","/docs/transformers/v4.22.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kL,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(kL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kL,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(cm,"class","relative group"),c(Rse,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pse,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Bse,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ise,"href","/docs/transformers/v4.22.0/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BL,"id","transformers.FlaxAutoModelForImageClassification"),c(BL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BL,"href","#transformers.FlaxAutoModelForImageClassification"),c(gm,"class","relative group"),c(Nse,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qse,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jse,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dse,"href","/docs/transformers/v4.22.0/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(Gse,"href","/docs/transformers/v4.22.0/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DL,"id","transformers.FlaxAutoModelForVision2Seq"),c(DL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DL,"href","#transformers.FlaxAutoModelForVision2Seq"),c(pm,"class","relative group"),c(Ose,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vse,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Xse,"href","/docs/transformers/v4.22.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zse,"href","/docs/transformers/v4.22.0/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,_){e(document.head,g),v(f,b,_),v(f,u,_),e(u,m),e(m,p),M(d,p,null),e(u,h),e(u,yo),e(yo,rd),v(f,Mm,_),v(f,pt,_),e(pt,td),e(pt,ad),e(ad,b9),e(pt,Em),v(f,Ve,_),v(f,He,_),e(He,nd),e(He,Zn),e(Zn,F9),e(He,es),e(He,os),e(os,T9),e(He,sd),e(He,rs),e(rs,M9),e(He,ld),v(f,Cm,_),M(Qa,f,_),v(f,Je,_),v(f,Ae,_),e(Ae,CB),e(Ae,id),e(id,wB),e(Ae,AB),v(f,xo,_),v(f,Wa,_),e(Wa,LB),e(Wa,wm),e(wm,yB),e(Wa,iro),v(f,kYe,_),v(f,dd,_),e(dd,Am),e(Am,Hie),M(E9,Hie,null),e(dd,dro),e(dd,Jie),e(Jie,cro),v(f,SYe,_),v(f,ts,_),e(ts,fro),e(ts,Yie),e(Yie,mro),e(ts,gro),e(ts,Kie),e(Kie,hro),e(ts,uro),v(f,RYe,_),M(C9,f,_),v(f,PYe,_),v(f,xB,_),e(xB,pro),v(f,BYe,_),M(Lm,f,_),v(f,IYe,_),v(f,cd,_),e(cd,ym),e(ym,Zie),M(w9,Zie,null),e(cd,_ro),e(cd,ede),e(ede,vro),v(f,NYe,_),v(f,$o,_),M(A9,$o,null),e($o,bro),e($o,L9),e(L9,Fro),e(L9,$B),e($B,Tro),e(L9,Mro),e($o,Ero),e($o,y9),e(y9,Cro),e(y9,ode),e(ode,wro),e(y9,Aro),e($o,Lro),e($o,Pr),M(x9,Pr,null),e(Pr,yro),e(Pr,rde),e(rde,xro),e(Pr,$ro),e(Pr,fd),e(fd,kro),e(fd,tde),e(tde,Sro),e(fd,Rro),e(fd,ade),e(ade,Pro),e(fd,Bro),e(Pr,Iro),e(Pr,A),e(A,xm),e(xm,nde),e(nde,Nro),e(xm,qro),e(xm,kB),e(kB,jro),e(xm,Dro),e(A,Gro),e(A,$m),e($m,sde),e(sde,Oro),e($m,Vro),e($m,SB),e(SB,Xro),e($m,zro),e(A,Qro),e(A,km),e(km,lde),e(lde,Wro),e(km,Uro),e(km,RB),e(RB,Hro),e(km,Jro),e(A,Yro),e(A,Sm),e(Sm,ide),e(ide,Kro),e(Sm,Zro),e(Sm,PB),e(PB,eto),e(Sm,oto),e(A,rto),e(A,Rm),e(Rm,dde),e(dde,tto),e(Rm,ato),e(Rm,BB),e(BB,nto),e(Rm,sto),e(A,lto),e(A,Pm),e(Pm,cde),e(cde,ito),e(Pm,dto),e(Pm,IB),e(IB,cto),e(Pm,fto),e(A,mto),e(A,Bm),e(Bm,fde),e(fde,gto),e(Bm,hto),e(Bm,NB),e(NB,uto),e(Bm,pto),e(A,_to),e(A,Im),e(Im,mde),e(mde,vto),e(Im,bto),e(Im,qB),e(qB,Fto),e(Im,Tto),e(A,Mto),e(A,Nm),e(Nm,gde),e(gde,Eto),e(Nm,Cto),e(Nm,jB),e(jB,wto),e(Nm,Ato),e(A,Lto),e(A,qm),e(qm,hde),e(hde,yto),e(qm,xto),e(qm,DB),e(DB,$to),e(qm,kto),e(A,Sto),e(A,jm),e(jm,ude),e(ude,Rto),e(jm,Pto),e(jm,GB),e(GB,Bto),e(jm,Ito),e(A,Nto),e(A,Dm),e(Dm,pde),e(pde,qto),e(Dm,jto),e(Dm,OB),e(OB,Dto),e(Dm,Gto),e(A,Oto),e(A,Gm),e(Gm,_de),e(_de,Vto),e(Gm,Xto),e(Gm,VB),e(VB,zto),e(Gm,Qto),e(A,Wto),e(A,Om),e(Om,vde),e(vde,Uto),e(Om,Hto),e(Om,XB),e(XB,Jto),e(Om,Yto),e(A,Kto),e(A,Vm),e(Vm,bde),e(bde,Zto),e(Vm,eao),e(Vm,zB),e(zB,oao),e(Vm,rao),e(A,tao),e(A,Xm),e(Xm,Fde),e(Fde,aao),e(Xm,nao),e(Xm,QB),e(QB,sao),e(Xm,lao),e(A,iao),e(A,zm),e(zm,Tde),e(Tde,dao),e(zm,cao),e(zm,WB),e(WB,fao),e(zm,mao),e(A,gao),e(A,Qm),e(Qm,Mde),e(Mde,hao),e(Qm,uao),e(Qm,UB),e(UB,pao),e(Qm,_ao),e(A,vao),e(A,Wm),e(Wm,Ede),e(Ede,bao),e(Wm,Fao),e(Wm,HB),e(HB,Tao),e(Wm,Mao),e(A,Eao),e(A,Um),e(Um,Cde),e(Cde,Cao),e(Um,wao),e(Um,JB),e(JB,Aao),e(Um,Lao),e(A,yao),e(A,Hm),e(Hm,wde),e(wde,xao),e(Hm,$ao),e(Hm,YB),e(YB,kao),e(Hm,Sao),e(A,Rao),e(A,Jm),e(Jm,Ade),e(Ade,Pao),e(Jm,Bao),e(Jm,KB),e(KB,Iao),e(Jm,Nao),e(A,qao),e(A,Ym),e(Ym,Lde),e(Lde,jao),e(Ym,Dao),e(Ym,ZB),e(ZB,Gao),e(Ym,Oao),e(A,Vao),e(A,Km),e(Km,yde),e(yde,Xao),e(Km,zao),e(Km,eI),e(eI,Qao),e(Km,Wao),e(A,Uao),e(A,Zm),e(Zm,xde),e(xde,Hao),e(Zm,Jao),e(Zm,oI),e(oI,Yao),e(Zm,Kao),e(A,Zao),e(A,eg),e(eg,$de),e($de,eno),e(eg,ono),e(eg,rI),e(rI,rno),e(eg,tno),e(A,ano),e(A,og),e(og,kde),e(kde,nno),e(og,sno),e(og,tI),e(tI,lno),e(og,ino),e(A,dno),e(A,rg),e(rg,Sde),e(Sde,cno),e(rg,fno),e(rg,aI),e(aI,mno),e(rg,gno),e(A,hno),e(A,tg),e(tg,Rde),e(Rde,uno),e(tg,pno),e(tg,nI),e(nI,_no),e(tg,vno),e(A,bno),e(A,ag),e(ag,Pde),e(Pde,Fno),e(ag,Tno),e(ag,sI),e(sI,Mno),e(ag,Eno),e(A,Cno),e(A,ng),e(ng,Bde),e(Bde,wno),e(ng,Ano),e(ng,lI),e(lI,Lno),e(ng,yno),e(A,xno),e(A,sg),e(sg,Ide),e(Ide,$no),e(sg,kno),e(sg,iI),e(iI,Sno),e(sg,Rno),e(A,Pno),e(A,lg),e(lg,Nde),e(Nde,Bno),e(lg,Ino),e(lg,dI),e(dI,Nno),e(lg,qno),e(A,jno),e(A,ig),e(ig,qde),e(qde,Dno),e(ig,Gno),e(ig,cI),e(cI,Ono),e(ig,Vno),e(A,Xno),e(A,dg),e(dg,jde),e(jde,zno),e(dg,Qno),e(dg,fI),e(fI,Wno),e(dg,Uno),e(A,Hno),e(A,cg),e(cg,Dde),e(Dde,Jno),e(cg,Yno),e(cg,mI),e(mI,Kno),e(cg,Zno),e(A,eso),e(A,fg),e(fg,Gde),e(Gde,oso),e(fg,rso),e(fg,gI),e(gI,tso),e(fg,aso),e(A,nso),e(A,mg),e(mg,Ode),e(Ode,sso),e(mg,lso),e(mg,hI),e(hI,iso),e(mg,dso),e(A,cso),e(A,gg),e(gg,Vde),e(Vde,fso),e(gg,mso),e(gg,uI),e(uI,gso),e(gg,hso),e(A,uso),e(A,hg),e(hg,Xde),e(Xde,pso),e(hg,_so),e(hg,pI),e(pI,vso),e(hg,bso),e(A,Fso),e(A,ug),e(ug,zde),e(zde,Tso),e(ug,Mso),e(ug,_I),e(_I,Eso),e(ug,Cso),e(A,wso),e(A,pg),e(pg,Qde),e(Qde,Aso),e(pg,Lso),e(pg,vI),e(vI,yso),e(pg,xso),e(A,$so),e(A,_g),e(_g,Wde),e(Wde,kso),e(_g,Sso),e(_g,bI),e(bI,Rso),e(_g,Pso),e(A,Bso),e(A,vg),e(vg,Ude),e(Ude,Iso),e(vg,Nso),e(vg,FI),e(FI,qso),e(vg,jso),e(A,Dso),e(A,bg),e(bg,Hde),e(Hde,Gso),e(bg,Oso),e(bg,TI),e(TI,Vso),e(bg,Xso),e(A,zso),e(A,Fg),e(Fg,Jde),e(Jde,Qso),e(Fg,Wso),e(Fg,MI),e(MI,Uso),e(Fg,Hso),e(A,Jso),e(A,Tg),e(Tg,Yde),e(Yde,Yso),e(Tg,Kso),e(Tg,EI),e(EI,Zso),e(Tg,elo),e(A,olo),e(A,Mg),e(Mg,Kde),e(Kde,rlo),e(Mg,tlo),e(Mg,CI),e(CI,alo),e(Mg,nlo),e(A,slo),e(A,Eg),e(Eg,Zde),e(Zde,llo),e(Eg,ilo),e(Eg,wI),e(wI,dlo),e(Eg,clo),e(A,flo),e(A,Cg),e(Cg,ece),e(ece,mlo),e(Cg,glo),e(Cg,AI),e(AI,hlo),e(Cg,ulo),e(A,plo),e(A,wg),e(wg,oce),e(oce,_lo),e(wg,vlo),e(wg,LI),e(LI,blo),e(wg,Flo),e(A,Tlo),e(A,Ag),e(Ag,rce),e(rce,Mlo),e(Ag,Elo),e(Ag,yI),e(yI,Clo),e(Ag,wlo),e(A,Alo),e(A,Lg),e(Lg,tce),e(tce,Llo),e(Lg,ylo),e(Lg,xI),e(xI,xlo),e(Lg,$lo),e(A,klo),e(A,yg),e(yg,ace),e(ace,Slo),e(yg,Rlo),e(yg,$I),e($I,Plo),e(yg,Blo),e(A,Ilo),e(A,xg),e(xg,nce),e(nce,Nlo),e(xg,qlo),e(xg,kI),e(kI,jlo),e(xg,Dlo),e(A,Glo),e(A,$g),e($g,sce),e(sce,Olo),e($g,Vlo),e($g,SI),e(SI,Xlo),e($g,zlo),e(A,Qlo),e(A,kg),e(kg,lce),e(lce,Wlo),e(kg,Ulo),e(kg,RI),e(RI,Hlo),e(kg,Jlo),e(A,Ylo),e(A,Sg),e(Sg,ice),e(ice,Klo),e(Sg,Zlo),e(Sg,PI),e(PI,eio),e(Sg,oio),e(A,rio),e(A,Rg),e(Rg,dce),e(dce,tio),e(Rg,aio),e(Rg,BI),e(BI,nio),e(Rg,sio),e(A,lio),e(A,Pg),e(Pg,cce),e(cce,iio),e(Pg,dio),e(Pg,II),e(II,cio),e(Pg,fio),e(A,mio),e(A,Bg),e(Bg,fce),e(fce,gio),e(Bg,hio),e(Bg,NI),e(NI,uio),e(Bg,pio),e(A,_io),e(A,Ig),e(Ig,mce),e(mce,vio),e(Ig,bio),e(Ig,qI),e(qI,Fio),e(Ig,Tio),e(A,Mio),e(A,Ng),e(Ng,gce),e(gce,Eio),e(Ng,Cio),e(Ng,jI),e(jI,wio),e(Ng,Aio),e(A,Lio),e(A,qg),e(qg,hce),e(hce,yio),e(qg,xio),e(qg,DI),e(DI,$io),e(qg,kio),e(A,Sio),e(A,jg),e(jg,uce),e(uce,Rio),e(jg,Pio),e(jg,GI),e(GI,Bio),e(jg,Iio),e(A,Nio),e(A,Dg),e(Dg,pce),e(pce,qio),e(Dg,jio),e(Dg,OI),e(OI,Dio),e(Dg,Gio),e(A,Oio),e(A,Gg),e(Gg,_ce),e(_ce,Vio),e(Gg,Xio),e(Gg,VI),e(VI,zio),e(Gg,Qio),e(A,Wio),e(A,Og),e(Og,vce),e(vce,Uio),e(Og,Hio),e(Og,XI),e(XI,Jio),e(Og,Yio),e(A,Kio),e(A,Vg),e(Vg,bce),e(bce,Zio),e(Vg,edo),e(Vg,zI),e(zI,odo),e(Vg,rdo),e(A,tdo),e(A,Xg),e(Xg,Fce),e(Fce,ado),e(Xg,ndo),e(Xg,QI),e(QI,sdo),e(Xg,ldo),e(A,ido),e(A,zg),e(zg,Tce),e(Tce,ddo),e(zg,cdo),e(zg,WI),e(WI,fdo),e(zg,mdo),e(A,gdo),e(A,Qg),e(Qg,Mce),e(Mce,hdo),e(Qg,udo),e(Qg,UI),e(UI,pdo),e(Qg,_do),e(A,vdo),e(A,Wg),e(Wg,Ece),e(Ece,bdo),e(Wg,Fdo),e(Wg,HI),e(HI,Tdo),e(Wg,Mdo),e(A,Edo),e(A,Ug),e(Ug,Cce),e(Cce,Cdo),e(Ug,wdo),e(Ug,JI),e(JI,Ado),e(Ug,Ldo),e(A,ydo),e(A,Hg),e(Hg,wce),e(wce,xdo),e(Hg,$do),e(Hg,YI),e(YI,kdo),e(Hg,Sdo),e(A,Rdo),e(A,Jg),e(Jg,Ace),e(Ace,Pdo),e(Jg,Bdo),e(Jg,KI),e(KI,Ido),e(Jg,Ndo),e(A,qdo),e(A,Yg),e(Yg,Lce),e(Lce,jdo),e(Yg,Ddo),e(Yg,ZI),e(ZI,Gdo),e(Yg,Odo),e(A,Vdo),e(A,Kg),e(Kg,yce),e(yce,Xdo),e(Kg,zdo),e(Kg,eN),e(eN,Qdo),e(Kg,Wdo),e(A,Udo),e(A,Zg),e(Zg,xce),e(xce,Hdo),e(Zg,Jdo),e(Zg,oN),e(oN,Ydo),e(Zg,Kdo),e(A,Zdo),e(A,eh),e(eh,$ce),e($ce,eco),e(eh,oco),e(eh,rN),e(rN,rco),e(eh,tco),e(A,aco),e(A,oh),e(oh,kce),e(kce,nco),e(oh,sco),e(oh,tN),e(tN,lco),e(oh,ico),e(A,dco),e(A,rh),e(rh,Sce),e(Sce,cco),e(rh,fco),e(rh,aN),e(aN,mco),e(rh,gco),e(A,hco),e(A,th),e(th,Rce),e(Rce,uco),e(th,pco),e(th,nN),e(nN,_co),e(th,vco),e(A,bco),e(A,ah),e(ah,Pce),e(Pce,Fco),e(ah,Tco),e(ah,sN),e(sN,Mco),e(ah,Eco),e(A,Cco),e(A,nh),e(nh,Bce),e(Bce,wco),e(nh,Aco),e(nh,lN),e(lN,Lco),e(nh,yco),e(A,xco),e(A,sh),e(sh,Ice),e(Ice,$co),e(sh,kco),e(sh,iN),e(iN,Sco),e(sh,Rco),e(A,Pco),e(A,lh),e(lh,Nce),e(Nce,Bco),e(lh,Ico),e(lh,dN),e(dN,Nco),e(lh,qco),e(A,jco),e(A,ih),e(ih,qce),e(qce,Dco),e(ih,Gco),e(ih,cN),e(cN,Oco),e(ih,Vco),e(A,Xco),e(A,dh),e(dh,jce),e(jce,zco),e(dh,Qco),e(dh,fN),e(fN,Wco),e(dh,Uco),e(A,Hco),e(A,ch),e(ch,Dce),e(Dce,Jco),e(ch,Yco),e(ch,mN),e(mN,Kco),e(ch,Zco),e(A,efo),e(A,fh),e(fh,Gce),e(Gce,ofo),e(fh,rfo),e(fh,gN),e(gN,tfo),e(fh,afo),e(A,nfo),e(A,mh),e(mh,Oce),e(Oce,sfo),e(mh,lfo),e(mh,hN),e(hN,ifo),e(mh,dfo),e(A,cfo),e(A,gh),e(gh,Vce),e(Vce,ffo),e(gh,mfo),e(gh,uN),e(uN,gfo),e(gh,hfo),e(A,ufo),e(A,hh),e(hh,Xce),e(Xce,pfo),e(hh,_fo),e(hh,pN),e(pN,vfo),e(hh,bfo),e(A,Ffo),e(A,uh),e(uh,zce),e(zce,Tfo),e(uh,Mfo),e(uh,_N),e(_N,Efo),e(uh,Cfo),e(A,wfo),e(A,ph),e(ph,Qce),e(Qce,Afo),e(ph,Lfo),e(ph,vN),e(vN,yfo),e(ph,xfo),e(A,$fo),e(A,_h),e(_h,Wce),e(Wce,kfo),e(_h,Sfo),e(_h,bN),e(bN,Rfo),e(_h,Pfo),e(A,Bfo),e(A,vh),e(vh,Uce),e(Uce,Ifo),e(vh,Nfo),e(vh,FN),e(FN,qfo),e(vh,jfo),e(A,Dfo),e(A,bh),e(bh,Hce),e(Hce,Gfo),e(bh,Ofo),e(bh,TN),e(TN,Vfo),e(bh,Xfo),e(A,zfo),e(A,Fh),e(Fh,Jce),e(Jce,Qfo),e(Fh,Wfo),e(Fh,MN),e(MN,Ufo),e(Fh,Hfo),e(A,Jfo),e(A,Th),e(Th,Yce),e(Yce,Yfo),e(Th,Kfo),e(Th,EN),e(EN,Zfo),e(Th,emo),e(A,omo),e(A,Mh),e(Mh,Kce),e(Kce,rmo),e(Mh,tmo),e(Mh,CN),e(CN,amo),e(Mh,nmo),e(A,smo),e(A,Eh),e(Eh,Zce),e(Zce,lmo),e(Eh,imo),e(Eh,wN),e(wN,dmo),e(Eh,cmo),e(A,fmo),e(A,Ch),e(Ch,efe),e(efe,mmo),e(Ch,gmo),e(Ch,AN),e(AN,hmo),e(Ch,umo),e(A,pmo),e(A,wh),e(wh,ofe),e(ofe,_mo),e(wh,vmo),e(wh,LN),e(LN,bmo),e(wh,Fmo),e(A,Tmo),e(A,Ah),e(Ah,rfe),e(rfe,Mmo),e(Ah,Emo),e(Ah,yN),e(yN,Cmo),e(Ah,wmo),e(A,Amo),e(A,Lh),e(Lh,tfe),e(tfe,Lmo),e(Lh,ymo),e(Lh,xN),e(xN,xmo),e(Lh,$mo),e(A,kmo),e(A,yh),e(yh,afe),e(afe,Smo),e(yh,Rmo),e(yh,$N),e($N,Pmo),e(yh,Bmo),e(A,Imo),e(A,xh),e(xh,nfe),e(nfe,Nmo),e(xh,qmo),e(xh,kN),e(kN,jmo),e(xh,Dmo),e(A,Gmo),e(A,$h),e($h,sfe),e(sfe,Omo),e($h,Vmo),e($h,SN),e(SN,Xmo),e($h,zmo),e(A,Qmo),e(A,kh),e(kh,lfe),e(lfe,Wmo),e(kh,Umo),e(kh,RN),e(RN,Hmo),e(kh,Jmo),e(A,Ymo),e(A,Sh),e(Sh,ife),e(ife,Kmo),e(Sh,Zmo),e(Sh,PN),e(PN,ego),e(Sh,ogo),e(A,rgo),e(A,Rh),e(Rh,dfe),e(dfe,tgo),e(Rh,ago),e(Rh,BN),e(BN,ngo),e(Rh,sgo),e(A,lgo),e(A,Ph),e(Ph,cfe),e(cfe,igo),e(Ph,dgo),e(Ph,IN),e(IN,cgo),e(Ph,fgo),e(A,mgo),e(A,Bh),e(Bh,ffe),e(ffe,ggo),e(Bh,hgo),e(Bh,NN),e(NN,ugo),e(Bh,pgo),e(A,_go),e(A,Ih),e(Ih,mfe),e(mfe,vgo),e(Ih,bgo),e(Ih,qN),e(qN,Fgo),e(Ih,Tgo),e(A,Mgo),e(A,Nh),e(Nh,gfe),e(gfe,Ego),e(Nh,Cgo),e(Nh,jN),e(jN,wgo),e(Nh,Ago),e(A,Lgo),e(A,qh),e(qh,hfe),e(hfe,ygo),e(qh,xgo),e(qh,DN),e(DN,$go),e(qh,kgo),e(A,Sgo),e(A,jh),e(jh,ufe),e(ufe,Rgo),e(jh,Pgo),e(jh,GN),e(GN,Bgo),e(jh,Igo),e(A,Ngo),e(A,Dh),e(Dh,pfe),e(pfe,qgo),e(Dh,jgo),e(Dh,ON),e(ON,Dgo),e(Dh,Ggo),e(A,Ogo),e(A,Gh),e(Gh,_fe),e(_fe,Vgo),e(Gh,Xgo),e(Gh,VN),e(VN,zgo),e(Gh,Qgo),e(A,Wgo),e(A,Oh),e(Oh,vfe),e(vfe,Ugo),e(Oh,Hgo),e(Oh,XN),e(XN,Jgo),e(Oh,Ygo),e(A,Kgo),e(A,Vh),e(Vh,bfe),e(bfe,Zgo),e(Vh,eho),e(Vh,zN),e(zN,oho),e(Vh,rho),e(A,tho),e(A,Xh),e(Xh,Ffe),e(Ffe,aho),e(Xh,nho),e(Xh,QN),e(QN,sho),e(Xh,lho),e(A,iho),e(A,zh),e(zh,Tfe),e(Tfe,dho),e(zh,cho),e(zh,WN),e(WN,fho),e(zh,mho),e(Pr,gho),M(Qh,Pr,null),e($o,hho),e($o,Wh),M($9,Wh,null),e(Wh,uho),e(Wh,Mfe),e(Mfe,pho),v(f,qYe,_),v(f,md,_),e(md,Uh),e(Uh,Efe),M(k9,Efe,null),e(md,_ho),e(md,Cfe),e(Cfe,vho),v(f,jYe,_),v(f,ko,_),M(S9,ko,null),e(ko,bho),e(ko,R9),e(R9,Fho),e(R9,UN),e(UN,Tho),e(R9,Mho),e(ko,Eho),e(ko,P9),e(P9,Cho),e(P9,wfe),e(wfe,who),e(P9,Aho),e(ko,Lho),e(ko,Br),M(B9,Br,null),e(Br,yho),e(Br,Afe),e(Afe,xho),e(Br,$ho),e(Br,Ua),e(Ua,kho),e(Ua,Lfe),e(Lfe,Sho),e(Ua,Rho),e(Ua,yfe),e(yfe,Pho),e(Ua,Bho),e(Ua,xfe),e(xfe,Iho),e(Ua,Nho),e(Br,qho),e(Br,k),e(k,as),e(as,$fe),e($fe,jho),e(as,Dho),e(as,HN),e(HN,Gho),e(as,Oho),e(as,JN),e(JN,Vho),e(as,Xho),e(k,zho),e(k,ns),e(ns,kfe),e(kfe,Qho),e(ns,Who),e(ns,YN),e(YN,Uho),e(ns,Hho),e(ns,KN),e(KN,Jho),e(ns,Yho),e(k,Kho),e(k,ss),e(ss,Sfe),e(Sfe,Zho),e(ss,euo),e(ss,ZN),e(ZN,ouo),e(ss,ruo),e(ss,eq),e(eq,tuo),e(ss,auo),e(k,nuo),e(k,Hh),e(Hh,Rfe),e(Rfe,suo),e(Hh,luo),e(Hh,oq),e(oq,iuo),e(Hh,duo),e(k,cuo),e(k,ls),e(ls,Pfe),e(Pfe,fuo),e(ls,muo),e(ls,rq),e(rq,guo),e(ls,huo),e(ls,tq),e(tq,uuo),e(ls,puo),e(k,_uo),e(k,Jh),e(Jh,Bfe),e(Bfe,vuo),e(Jh,buo),e(Jh,aq),e(aq,Fuo),e(Jh,Tuo),e(k,Muo),e(k,Yh),e(Yh,Ife),e(Ife,Euo),e(Yh,Cuo),e(Yh,nq),e(nq,wuo),e(Yh,Auo),e(k,Luo),e(k,Kh),e(Kh,Nfe),e(Nfe,yuo),e(Kh,xuo),e(Kh,sq),e(sq,$uo),e(Kh,kuo),e(k,Suo),e(k,is),e(is,qfe),e(qfe,Ruo),e(is,Puo),e(is,lq),e(lq,Buo),e(is,Iuo),e(is,iq),e(iq,Nuo),e(is,quo),e(k,juo),e(k,ds),e(ds,jfe),e(jfe,Duo),e(ds,Guo),e(ds,dq),e(dq,Ouo),e(ds,Vuo),e(ds,cq),e(cq,Xuo),e(ds,zuo),e(k,Quo),e(k,cs),e(cs,Dfe),e(Dfe,Wuo),e(cs,Uuo),e(cs,fq),e(fq,Huo),e(cs,Juo),e(cs,mq),e(mq,Yuo),e(cs,Kuo),e(k,Zuo),e(k,Zh),e(Zh,Gfe),e(Gfe,epo),e(Zh,opo),e(Zh,gq),e(gq,rpo),e(Zh,tpo),e(k,apo),e(k,eu),e(eu,Ofe),e(Ofe,npo),e(eu,spo),e(eu,hq),e(hq,lpo),e(eu,ipo),e(k,dpo),e(k,ou),e(ou,Vfe),e(Vfe,cpo),e(ou,fpo),e(ou,uq),e(uq,mpo),e(ou,gpo),e(k,hpo),e(k,fs),e(fs,Xfe),e(Xfe,upo),e(fs,ppo),e(fs,pq),e(pq,_po),e(fs,vpo),e(fs,_q),e(_q,bpo),e(fs,Fpo),e(k,Tpo),e(k,ru),e(ru,zfe),e(zfe,Mpo),e(ru,Epo),e(ru,vq),e(vq,Cpo),e(ru,wpo),e(k,Apo),e(k,ms),e(ms,Qfe),e(Qfe,Lpo),e(ms,ypo),e(ms,bq),e(bq,xpo),e(ms,$po),e(ms,Fq),e(Fq,kpo),e(ms,Spo),e(k,Rpo),e(k,gs),e(gs,Wfe),e(Wfe,Ppo),e(gs,Bpo),e(gs,Tq),e(Tq,Ipo),e(gs,Npo),e(gs,Mq),e(Mq,qpo),e(gs,jpo),e(k,Dpo),e(k,hs),e(hs,Ufe),e(Ufe,Gpo),e(hs,Opo),e(hs,Eq),e(Eq,Vpo),e(hs,Xpo),e(hs,Cq),e(Cq,zpo),e(hs,Qpo),e(k,Wpo),e(k,us),e(us,Hfe),e(Hfe,Upo),e(us,Hpo),e(us,wq),e(wq,Jpo),e(us,Ypo),e(us,Aq),e(Aq,Kpo),e(us,Zpo),e(k,e_o),e(k,tu),e(tu,Jfe),e(Jfe,o_o),e(tu,r_o),e(tu,Lq),e(Lq,t_o),e(tu,a_o),e(k,n_o),e(k,ps),e(ps,Yfe),e(Yfe,s_o),e(ps,l_o),e(ps,yq),e(yq,i_o),e(ps,d_o),e(ps,xq),e(xq,c_o),e(ps,f_o),e(k,m_o),e(k,_s),e(_s,Kfe),e(Kfe,g_o),e(_s,h_o),e(_s,$q),e($q,u_o),e(_s,p_o),e(_s,kq),e(kq,__o),e(_s,v_o),e(k,b_o),e(k,vs),e(vs,Zfe),e(Zfe,F_o),e(vs,T_o),e(vs,Sq),e(Sq,M_o),e(vs,E_o),e(vs,Rq),e(Rq,C_o),e(vs,w_o),e(k,A_o),e(k,bs),e(bs,eme),e(eme,L_o),e(bs,y_o),e(bs,Pq),e(Pq,x_o),e(bs,$_o),e(bs,Bq),e(Bq,k_o),e(bs,S_o),e(k,R_o),e(k,Fs),e(Fs,ome),e(ome,P_o),e(Fs,B_o),e(Fs,Iq),e(Iq,I_o),e(Fs,N_o),e(Fs,Nq),e(Nq,q_o),e(Fs,j_o),e(k,D_o),e(k,Ts),e(Ts,rme),e(rme,G_o),e(Ts,O_o),e(Ts,qq),e(qq,V_o),e(Ts,X_o),e(Ts,jq),e(jq,z_o),e(Ts,Q_o),e(k,W_o),e(k,Ms),e(Ms,tme),e(tme,U_o),e(Ms,H_o),e(Ms,Dq),e(Dq,J_o),e(Ms,Y_o),e(Ms,Gq),e(Gq,K_o),e(Ms,Z_o),e(k,e2o),e(k,au),e(au,ame),e(ame,o2o),e(au,r2o),e(au,Oq),e(Oq,t2o),e(au,a2o),e(k,n2o),e(k,Es),e(Es,nme),e(nme,s2o),e(Es,l2o),e(Es,Vq),e(Vq,i2o),e(Es,d2o),e(Es,Xq),e(Xq,c2o),e(Es,f2o),e(k,m2o),e(k,nu),e(nu,sme),e(sme,g2o),e(nu,h2o),e(nu,zq),e(zq,u2o),e(nu,p2o),e(k,_2o),e(k,Cs),e(Cs,lme),e(lme,v2o),e(Cs,b2o),e(Cs,Qq),e(Qq,F2o),e(Cs,T2o),e(Cs,Wq),e(Wq,M2o),e(Cs,E2o),e(k,C2o),e(k,ws),e(ws,ime),e(ime,w2o),e(ws,A2o),e(ws,Uq),e(Uq,L2o),e(ws,y2o),e(ws,Hq),e(Hq,x2o),e(ws,$2o),e(k,k2o),e(k,As),e(As,dme),e(dme,S2o),e(As,R2o),e(As,Jq),e(Jq,P2o),e(As,B2o),e(As,Yq),e(Yq,I2o),e(As,N2o),e(k,q2o),e(k,su),e(su,cme),e(cme,j2o),e(su,D2o),e(su,Kq),e(Kq,G2o),e(su,O2o),e(k,V2o),e(k,Ls),e(Ls,fme),e(fme,X2o),e(Ls,z2o),e(Ls,Zq),e(Zq,Q2o),e(Ls,W2o),e(Ls,ej),e(ej,U2o),e(Ls,H2o),e(k,J2o),e(k,ys),e(ys,mme),e(mme,Y2o),e(ys,K2o),e(ys,oj),e(oj,Z2o),e(ys,evo),e(ys,rj),e(rj,ovo),e(ys,rvo),e(k,tvo),e(k,xs),e(xs,gme),e(gme,avo),e(xs,nvo),e(xs,tj),e(tj,svo),e(xs,lvo),e(xs,aj),e(aj,ivo),e(xs,dvo),e(k,cvo),e(k,lu),e(lu,hme),e(hme,fvo),e(lu,mvo),e(lu,nj),e(nj,gvo),e(lu,hvo),e(k,uvo),e(k,$s),e($s,ume),e(ume,pvo),e($s,_vo),e($s,sj),e(sj,vvo),e($s,bvo),e($s,lj),e(lj,Fvo),e($s,Tvo),e(k,Mvo),e(k,ks),e(ks,pme),e(pme,Evo),e(ks,Cvo),e(ks,ij),e(ij,wvo),e(ks,Avo),e(ks,dj),e(dj,Lvo),e(ks,yvo),e(k,xvo),e(k,Ss),e(Ss,_me),e(_me,$vo),e(Ss,kvo),e(Ss,cj),e(cj,Svo),e(Ss,Rvo),e(Ss,fj),e(fj,Pvo),e(Ss,Bvo),e(k,Ivo),e(k,Rs),e(Rs,vme),e(vme,Nvo),e(Rs,qvo),e(Rs,mj),e(mj,jvo),e(Rs,Dvo),e(Rs,gj),e(gj,Gvo),e(Rs,Ovo),e(k,Vvo),e(k,Ps),e(Ps,bme),e(bme,Xvo),e(Ps,zvo),e(Ps,hj),e(hj,Qvo),e(Ps,Wvo),e(Ps,uj),e(uj,Uvo),e(Ps,Hvo),e(k,Jvo),e(k,Bs),e(Bs,Fme),e(Fme,Yvo),e(Bs,Kvo),e(Bs,pj),e(pj,Zvo),e(Bs,e4o),e(Bs,_j),e(_j,o4o),e(Bs,r4o),e(k,t4o),e(k,Is),e(Is,Tme),e(Tme,a4o),e(Is,n4o),e(Is,vj),e(vj,s4o),e(Is,l4o),e(Is,bj),e(bj,i4o),e(Is,d4o),e(k,c4o),e(k,Ns),e(Ns,Mme),e(Mme,f4o),e(Ns,m4o),e(Ns,Fj),e(Fj,g4o),e(Ns,h4o),e(Ns,Tj),e(Tj,u4o),e(Ns,p4o),e(k,_4o),e(k,iu),e(iu,Eme),e(Eme,v4o),e(iu,b4o),e(iu,Mj),e(Mj,F4o),e(iu,T4o),e(k,M4o),e(k,qs),e(qs,Cme),e(Cme,E4o),e(qs,C4o),e(qs,Ej),e(Ej,w4o),e(qs,A4o),e(qs,Cj),e(Cj,L4o),e(qs,y4o),e(k,x4o),e(k,du),e(du,wme),e(wme,$4o),e(du,k4o),e(du,wj),e(wj,S4o),e(du,R4o),e(k,P4o),e(k,cu),e(cu,Ame),e(Ame,B4o),e(cu,I4o),e(cu,Aj),e(Aj,N4o),e(cu,q4o),e(k,j4o),e(k,js),e(js,Lme),e(Lme,D4o),e(js,G4o),e(js,Lj),e(Lj,O4o),e(js,V4o),e(js,yj),e(yj,X4o),e(js,z4o),e(k,Q4o),e(k,Ds),e(Ds,yme),e(yme,W4o),e(Ds,U4o),e(Ds,xj),e(xj,H4o),e(Ds,J4o),e(Ds,$j),e($j,Y4o),e(Ds,K4o),e(k,Z4o),e(k,Gs),e(Gs,xme),e(xme,ebo),e(Gs,obo),e(Gs,kj),e(kj,rbo),e(Gs,tbo),e(Gs,Sj),e(Sj,abo),e(Gs,nbo),e(k,sbo),e(k,fu),e(fu,$me),e($me,lbo),e(fu,ibo),e(fu,Rj),e(Rj,dbo),e(fu,cbo),e(k,fbo),e(k,Os),e(Os,kme),e(kme,mbo),e(Os,gbo),e(Os,Pj),e(Pj,hbo),e(Os,ubo),e(Os,Bj),e(Bj,pbo),e(Os,_bo),e(k,vbo),e(k,Vs),e(Vs,Sme),e(Sme,bbo),e(Vs,Fbo),e(Vs,Ij),e(Ij,Tbo),e(Vs,Mbo),e(Vs,Nj),e(Nj,Ebo),e(Vs,Cbo),e(k,wbo),e(k,Xs),e(Xs,Rme),e(Rme,Abo),e(Xs,Lbo),e(Xs,qj),e(qj,ybo),e(Xs,xbo),e(Xs,jj),e(jj,$bo),e(Xs,kbo),e(k,Sbo),e(k,zs),e(zs,Pme),e(Pme,Rbo),e(zs,Pbo),e(zs,Dj),e(Dj,Bbo),e(zs,Ibo),e(zs,Gj),e(Gj,Nbo),e(zs,qbo),e(k,jbo),e(k,Qs),e(Qs,Bme),e(Bme,Dbo),e(Qs,Gbo),e(Qs,Oj),e(Oj,Obo),e(Qs,Vbo),e(Qs,Vj),e(Vj,Xbo),e(Qs,zbo),e(k,Qbo),e(k,Ws),e(Ws,Ime),e(Ime,Wbo),e(Ws,Ubo),e(Ws,Xj),e(Xj,Hbo),e(Ws,Jbo),e(Ws,zj),e(zj,Ybo),e(Ws,Kbo),e(k,Zbo),e(k,Us),e(Us,Nme),e(Nme,e1o),e(Us,o1o),e(Us,Qj),e(Qj,r1o),e(Us,t1o),e(Us,Wj),e(Wj,a1o),e(Us,n1o),e(k,s1o),e(k,Hs),e(Hs,qme),e(qme,l1o),e(Hs,i1o),e(Hs,Uj),e(Uj,d1o),e(Hs,c1o),e(Hs,Hj),e(Hj,f1o),e(Hs,m1o),e(k,g1o),e(k,mu),e(mu,jme),e(jme,h1o),e(mu,u1o),e(mu,Jj),e(Jj,p1o),e(mu,_1o),e(k,v1o),e(k,Js),e(Js,Dme),e(Dme,b1o),e(Js,F1o),e(Js,Yj),e(Yj,T1o),e(Js,M1o),e(Js,Kj),e(Kj,E1o),e(Js,C1o),e(k,w1o),e(k,Ys),e(Ys,Gme),e(Gme,A1o),e(Ys,L1o),e(Ys,Zj),e(Zj,y1o),e(Ys,x1o),e(Ys,eD),e(eD,$1o),e(Ys,k1o),e(k,S1o),e(k,gu),e(gu,Ome),e(Ome,R1o),e(gu,P1o),e(gu,oD),e(oD,B1o),e(gu,I1o),e(k,N1o),e(k,hu),e(hu,Vme),e(Vme,q1o),e(hu,j1o),e(hu,rD),e(rD,D1o),e(hu,G1o),e(k,O1o),e(k,uu),e(uu,Xme),e(Xme,V1o),e(uu,X1o),e(uu,tD),e(tD,z1o),e(uu,Q1o),e(k,W1o),e(k,pu),e(pu,zme),e(zme,U1o),e(pu,H1o),e(pu,aD),e(aD,J1o),e(pu,Y1o),e(k,K1o),e(k,Ks),e(Ks,Qme),e(Qme,Z1o),e(Ks,e0o),e(Ks,nD),e(nD,o0o),e(Ks,r0o),e(Ks,sD),e(sD,t0o),e(Ks,a0o),e(k,n0o),e(k,_u),e(_u,Wme),e(Wme,s0o),e(_u,l0o),e(_u,lD),e(lD,i0o),e(_u,d0o),e(k,c0o),e(k,Zs),e(Zs,Ume),e(Ume,f0o),e(Zs,m0o),e(Zs,iD),e(iD,g0o),e(Zs,h0o),e(Zs,dD),e(dD,u0o),e(Zs,p0o),e(k,_0o),e(k,el),e(el,Hme),e(Hme,v0o),e(el,b0o),e(el,cD),e(cD,F0o),e(el,T0o),e(el,fD),e(fD,M0o),e(el,E0o),e(k,C0o),e(k,ol),e(ol,Jme),e(Jme,w0o),e(ol,A0o),e(ol,mD),e(mD,L0o),e(ol,y0o),e(ol,gD),e(gD,x0o),e(ol,$0o),e(k,k0o),e(k,rl),e(rl,Yme),e(Yme,S0o),e(rl,R0o),e(rl,hD),e(hD,P0o),e(rl,B0o),e(rl,uD),e(uD,I0o),e(rl,N0o),e(k,q0o),e(k,tl),e(tl,Kme),e(Kme,j0o),e(tl,D0o),e(tl,pD),e(pD,G0o),e(tl,O0o),e(tl,_D),e(_D,V0o),e(tl,X0o),e(k,z0o),e(k,al),e(al,Zme),e(Zme,Q0o),e(al,W0o),e(al,vD),e(vD,U0o),e(al,H0o),e(al,bD),e(bD,J0o),e(al,Y0o),e(k,K0o),e(k,vu),e(vu,ege),e(ege,Z0o),e(vu,eFo),e(vu,FD),e(FD,oFo),e(vu,rFo),e(k,tFo),e(k,bu),e(bu,oge),e(oge,aFo),e(bu,nFo),e(bu,TD),e(TD,sFo),e(bu,lFo),e(k,iFo),e(k,nl),e(nl,rge),e(rge,dFo),e(nl,cFo),e(nl,MD),e(MD,fFo),e(nl,mFo),e(nl,ED),e(ED,gFo),e(nl,hFo),e(k,uFo),e(k,sl),e(sl,tge),e(tge,pFo),e(sl,_Fo),e(sl,CD),e(CD,vFo),e(sl,bFo),e(sl,wD),e(wD,FFo),e(sl,TFo),e(k,MFo),e(k,ll),e(ll,age),e(age,EFo),e(ll,CFo),e(ll,AD),e(AD,wFo),e(ll,AFo),e(ll,LD),e(LD,LFo),e(ll,yFo),e(k,xFo),e(k,Fu),e(Fu,nge),e(nge,$Fo),e(Fu,kFo),e(Fu,yD),e(yD,SFo),e(Fu,RFo),e(k,PFo),e(k,Tu),e(Tu,sge),e(sge,BFo),e(Tu,IFo),e(Tu,xD),e(xD,NFo),e(Tu,qFo),e(k,jFo),e(k,Mu),e(Mu,lge),e(lge,DFo),e(Mu,GFo),e(Mu,$D),e($D,OFo),e(Mu,VFo),e(k,XFo),e(k,il),e(il,ige),e(ige,zFo),e(il,QFo),e(il,kD),e(kD,WFo),e(il,UFo),e(il,SD),e(SD,HFo),e(il,JFo),e(k,YFo),e(k,dl),e(dl,dge),e(dge,KFo),e(dl,ZFo),e(dl,RD),e(RD,eTo),e(dl,oTo),e(dl,PD),e(PD,rTo),e(dl,tTo),e(k,aTo),e(k,Eu),e(Eu,cge),e(cge,nTo),e(Eu,sTo),e(Eu,BD),e(BD,lTo),e(Eu,iTo),e(k,dTo),e(k,Cu),e(Cu,fge),e(fge,cTo),e(Cu,fTo),e(Cu,ID),e(ID,mTo),e(Cu,gTo),e(k,hTo),e(k,wu),e(wu,mge),e(mge,uTo),e(wu,pTo),e(wu,ND),e(ND,_To),e(wu,vTo),e(k,bTo),e(k,cl),e(cl,gge),e(gge,FTo),e(cl,TTo),e(cl,qD),e(qD,MTo),e(cl,ETo),e(cl,jD),e(jD,CTo),e(cl,wTo),e(k,ATo),e(k,fl),e(fl,hge),e(hge,LTo),e(fl,yTo),e(fl,DD),e(DD,xTo),e(fl,$To),e(fl,GD),e(GD,kTo),e(fl,STo),e(k,RTo),e(k,Au),e(Au,uge),e(uge,PTo),e(Au,BTo),e(Au,OD),e(OD,ITo),e(Au,NTo),e(k,qTo),e(k,Lu),e(Lu,pge),e(pge,jTo),e(Lu,DTo),e(Lu,VD),e(VD,GTo),e(Lu,OTo),e(k,VTo),e(k,ml),e(ml,_ge),e(_ge,XTo),e(ml,zTo),e(ml,XD),e(XD,QTo),e(ml,WTo),e(ml,zD),e(zD,UTo),e(ml,HTo),e(k,JTo),e(k,gl),e(gl,vge),e(vge,YTo),e(gl,KTo),e(gl,QD),e(QD,ZTo),e(gl,eMo),e(gl,WD),e(WD,oMo),e(gl,rMo),e(k,tMo),e(k,hl),e(hl,bge),e(bge,aMo),e(hl,nMo),e(hl,UD),e(UD,sMo),e(hl,lMo),e(hl,HD),e(HD,iMo),e(hl,dMo),e(k,cMo),e(k,ul),e(ul,Fge),e(Fge,fMo),e(ul,mMo),e(ul,JD),e(JD,gMo),e(ul,hMo),e(ul,YD),e(YD,uMo),e(ul,pMo),e(Br,_Mo),M(yu,Br,null),e(ko,vMo),e(ko,xu),M(I9,xu,null),e(xu,bMo),e(xu,Tge),e(Tge,FMo),v(f,DYe,_),v(f,gd,_),e(gd,$u),e($u,Mge),M(N9,Mge,null),e(gd,TMo),e(gd,Ege),e(Ege,MMo),v(f,GYe,_),v(f,So,_),M(q9,So,null),e(So,EMo),e(So,j9),e(j9,CMo),e(j9,KD),e(KD,wMo),e(j9,AMo),e(So,LMo),e(So,D9),e(D9,yMo),e(D9,Cge),e(Cge,xMo),e(D9,$Mo),e(So,kMo),e(So,Ye),M(G9,Ye,null),e(Ye,SMo),e(Ye,wge),e(wge,RMo),e(Ye,PMo),e(Ye,Ha),e(Ha,BMo),e(Ha,Age),e(Age,IMo),e(Ha,NMo),e(Ha,Lge),e(Lge,qMo),e(Ha,jMo),e(Ha,yge),e(yge,DMo),e(Ha,GMo),e(Ye,OMo),e(Ye,W),e(W,ku),e(ku,xge),e(xge,VMo),e(ku,XMo),e(ku,ZD),e(ZD,zMo),e(ku,QMo),e(W,WMo),e(W,Su),e(Su,$ge),e($ge,UMo),e(Su,HMo),e(Su,eG),e(eG,JMo),e(Su,YMo),e(W,KMo),e(W,Ru),e(Ru,kge),e(kge,ZMo),e(Ru,eEo),e(Ru,oG),e(oG,oEo),e(Ru,rEo),e(W,tEo),e(W,Pu),e(Pu,Sge),e(Sge,aEo),e(Pu,nEo),e(Pu,rG),e(rG,sEo),e(Pu,lEo),e(W,iEo),e(W,Bu),e(Bu,Rge),e(Rge,dEo),e(Bu,cEo),e(Bu,tG),e(tG,fEo),e(Bu,mEo),e(W,gEo),e(W,Iu),e(Iu,Pge),e(Pge,hEo),e(Iu,uEo),e(Iu,aG),e(aG,pEo),e(Iu,_Eo),e(W,vEo),e(W,Nu),e(Nu,Bge),e(Bge,bEo),e(Nu,FEo),e(Nu,nG),e(nG,TEo),e(Nu,MEo),e(W,EEo),e(W,qu),e(qu,Ige),e(Ige,CEo),e(qu,wEo),e(qu,sG),e(sG,AEo),e(qu,LEo),e(W,yEo),e(W,ju),e(ju,Nge),e(Nge,xEo),e(ju,$Eo),e(ju,lG),e(lG,kEo),e(ju,SEo),e(W,REo),e(W,Du),e(Du,qge),e(qge,PEo),e(Du,BEo),e(Du,iG),e(iG,IEo),e(Du,NEo),e(W,qEo),e(W,Gu),e(Gu,jge),e(jge,jEo),e(Gu,DEo),e(Gu,dG),e(dG,GEo),e(Gu,OEo),e(W,VEo),e(W,Ou),e(Ou,Dge),e(Dge,XEo),e(Ou,zEo),e(Ou,cG),e(cG,QEo),e(Ou,WEo),e(W,UEo),e(W,Vu),e(Vu,Gge),e(Gge,HEo),e(Vu,JEo),e(Vu,fG),e(fG,YEo),e(Vu,KEo),e(W,ZEo),e(W,Xu),e(Xu,Oge),e(Oge,eCo),e(Xu,oCo),e(Xu,mG),e(mG,rCo),e(Xu,tCo),e(W,aCo),e(W,zu),e(zu,Vge),e(Vge,nCo),e(zu,sCo),e(zu,gG),e(gG,lCo),e(zu,iCo),e(W,dCo),e(W,Qu),e(Qu,Xge),e(Xge,cCo),e(Qu,fCo),e(Qu,hG),e(hG,mCo),e(Qu,gCo),e(W,hCo),e(W,Wu),e(Wu,zge),e(zge,uCo),e(Wu,pCo),e(Wu,uG),e(uG,_Co),e(Wu,vCo),e(W,bCo),e(W,Uu),e(Uu,Qge),e(Qge,FCo),e(Uu,TCo),e(Uu,pG),e(pG,MCo),e(Uu,ECo),e(W,CCo),e(W,Hu),e(Hu,Wge),e(Wge,wCo),e(Hu,ACo),e(Hu,_G),e(_G,LCo),e(Hu,yCo),e(W,xCo),e(W,Ju),e(Ju,Uge),e(Uge,$Co),e(Ju,kCo),e(Ju,vG),e(vG,SCo),e(Ju,RCo),e(W,PCo),e(W,Yu),e(Yu,Hge),e(Hge,BCo),e(Yu,ICo),e(Yu,bG),e(bG,NCo),e(Yu,qCo),e(W,jCo),e(W,Ku),e(Ku,Jge),e(Jge,DCo),e(Ku,GCo),e(Ku,FG),e(FG,OCo),e(Ku,VCo),e(W,XCo),e(W,Zu),e(Zu,Yge),e(Yge,zCo),e(Zu,QCo),e(Zu,TG),e(TG,WCo),e(Zu,UCo),e(W,HCo),e(W,ep),e(ep,Kge),e(Kge,JCo),e(ep,YCo),e(ep,MG),e(MG,KCo),e(ep,ZCo),e(W,e3o),e(W,op),e(op,Zge),e(Zge,o3o),e(op,r3o),e(op,EG),e(EG,t3o),e(op,a3o),e(W,n3o),e(W,rp),e(rp,ehe),e(ehe,s3o),e(rp,l3o),e(rp,CG),e(CG,i3o),e(rp,d3o),e(W,c3o),e(W,tp),e(tp,ohe),e(ohe,f3o),e(tp,m3o),e(tp,wG),e(wG,g3o),e(tp,h3o),e(W,u3o),e(W,ap),e(ap,rhe),e(rhe,p3o),e(ap,_3o),e(ap,AG),e(AG,v3o),e(ap,b3o),e(W,F3o),e(W,np),e(np,the),e(the,T3o),e(np,M3o),e(np,LG),e(LG,E3o),e(np,C3o),e(W,w3o),e(W,sp),e(sp,ahe),e(ahe,A3o),e(sp,L3o),e(sp,yG),e(yG,y3o),e(sp,x3o),e(W,$3o),e(W,lp),e(lp,nhe),e(nhe,k3o),e(lp,S3o),e(lp,xG),e(xG,R3o),e(lp,P3o),e(W,B3o),e(W,ip),e(ip,she),e(she,I3o),e(ip,N3o),e(ip,$G),e($G,q3o),e(ip,j3o),e(W,D3o),e(W,dp),e(dp,lhe),e(lhe,G3o),e(dp,O3o),e(dp,kG),e(kG,V3o),e(dp,X3o),e(W,z3o),e(W,cp),e(cp,ihe),e(ihe,Q3o),e(cp,W3o),e(cp,SG),e(SG,U3o),e(cp,H3o),e(W,J3o),e(W,fp),e(fp,dhe),e(dhe,Y3o),e(fp,K3o),e(fp,RG),e(RG,Z3o),e(fp,e5o),e(W,o5o),e(W,mp),e(mp,che),e(che,r5o),e(mp,t5o),e(mp,PG),e(PG,a5o),e(mp,n5o),e(W,s5o),e(W,gp),e(gp,fhe),e(fhe,l5o),e(gp,i5o),e(gp,BG),e(BG,d5o),e(gp,c5o),e(W,f5o),e(W,hp),e(hp,mhe),e(mhe,m5o),e(hp,g5o),e(hp,IG),e(IG,h5o),e(hp,u5o),e(W,p5o),e(W,up),e(up,ghe),e(ghe,_5o),e(up,v5o),e(up,NG),e(NG,b5o),e(up,F5o),e(Ye,T5o),M(pp,Ye,null),e(Ye,M5o),M(_p,Ye,null),e(So,E5o),e(So,vp),M(O9,vp,null),e(vp,C5o),e(vp,hhe),e(hhe,w5o),v(f,OYe,_),v(f,hd,_),e(hd,bp),e(bp,uhe),M(V9,uhe,null),e(hd,A5o),e(hd,phe),e(phe,L5o),v(f,VYe,_),v(f,Ro,_),M(X9,Ro,null),e(Ro,y5o),e(Ro,z9),e(z9,x5o),e(z9,qG),e(qG,$5o),e(z9,k5o),e(Ro,S5o),e(Ro,Q9),e(Q9,R5o),e(Q9,_he),e(_he,P5o),e(Q9,B5o),e(Ro,I5o),e(Ro,Ke),M(W9,Ke,null),e(Ke,N5o),e(Ke,vhe),e(vhe,q5o),e(Ke,j5o),e(Ke,ud),e(ud,D5o),e(ud,bhe),e(bhe,G5o),e(ud,O5o),e(ud,Fhe),e(Fhe,V5o),e(ud,X5o),e(Ke,z5o),e(Ke,ie),e(ie,Fp),e(Fp,The),e(The,Q5o),e(Fp,W5o),e(Fp,jG),e(jG,U5o),e(Fp,H5o),e(ie,J5o),e(ie,Tp),e(Tp,Mhe),e(Mhe,Y5o),e(Tp,K5o),e(Tp,DG),e(DG,Z5o),e(Tp,ewo),e(ie,owo),e(ie,Mp),e(Mp,Ehe),e(Ehe,rwo),e(Mp,two),e(Mp,GG),e(GG,awo),e(Mp,nwo),e(ie,swo),e(ie,Ep),e(Ep,Che),e(Che,lwo),e(Ep,iwo),e(Ep,OG),e(OG,dwo),e(Ep,cwo),e(ie,fwo),e(ie,Cp),e(Cp,whe),e(whe,mwo),e(Cp,gwo),e(Cp,VG),e(VG,hwo),e(Cp,uwo),e(ie,pwo),e(ie,wp),e(wp,Ahe),e(Ahe,_wo),e(wp,vwo),e(wp,XG),e(XG,bwo),e(wp,Fwo),e(ie,Two),e(ie,Ap),e(Ap,Lhe),e(Lhe,Mwo),e(Ap,Ewo),e(Ap,zG),e(zG,Cwo),e(Ap,wwo),e(ie,Awo),e(ie,Lp),e(Lp,yhe),e(yhe,Lwo),e(Lp,ywo),e(Lp,QG),e(QG,xwo),e(Lp,$wo),e(ie,kwo),e(ie,yp),e(yp,xhe),e(xhe,Swo),e(yp,Rwo),e(yp,WG),e(WG,Pwo),e(yp,Bwo),e(ie,Iwo),e(ie,xp),e(xp,$he),e($he,Nwo),e(xp,qwo),e(xp,UG),e(UG,jwo),e(xp,Dwo),e(ie,Gwo),e(ie,$p),e($p,khe),e(khe,Owo),e($p,Vwo),e($p,HG),e(HG,Xwo),e($p,zwo),e(ie,Qwo),e(ie,kp),e(kp,She),e(She,Wwo),e(kp,Uwo),e(kp,JG),e(JG,Hwo),e(kp,Jwo),e(ie,Ywo),e(ie,Sp),e(Sp,Rhe),e(Rhe,Kwo),e(Sp,Zwo),e(Sp,YG),e(YG,eAo),e(Sp,oAo),e(ie,rAo),e(ie,Rp),e(Rp,Phe),e(Phe,tAo),e(Rp,aAo),e(Rp,KG),e(KG,nAo),e(Rp,sAo),e(ie,lAo),e(ie,Pp),e(Pp,Bhe),e(Bhe,iAo),e(Pp,dAo),e(Pp,ZG),e(ZG,cAo),e(Pp,fAo),e(ie,mAo),e(ie,Bp),e(Bp,Ihe),e(Ihe,gAo),e(Bp,hAo),e(Bp,eO),e(eO,uAo),e(Bp,pAo),e(ie,_Ao),e(ie,Ip),e(Ip,Nhe),e(Nhe,vAo),e(Ip,bAo),e(Ip,oO),e(oO,FAo),e(Ip,TAo),e(ie,MAo),e(ie,Np),e(Np,qhe),e(qhe,EAo),e(Np,CAo),e(Np,rO),e(rO,wAo),e(Np,AAo),e(ie,LAo),e(ie,qp),e(qp,jhe),e(jhe,yAo),e(qp,xAo),e(qp,tO),e(tO,$Ao),e(qp,kAo),e(ie,SAo),e(ie,jp),e(jp,Dhe),e(Dhe,RAo),e(jp,PAo),e(jp,aO),e(aO,BAo),e(jp,IAo),e(ie,NAo),e(ie,Dp),e(Dp,Ghe),e(Ghe,qAo),e(Dp,jAo),e(Dp,nO),e(nO,DAo),e(Dp,GAo),e(Ke,OAo),M(Gp,Ke,null),e(Ke,VAo),M(Op,Ke,null),e(Ro,XAo),e(Ro,Vp),M(U9,Vp,null),e(Vp,zAo),e(Vp,Ohe),e(Ohe,QAo),v(f,XYe,_),v(f,pd,_),e(pd,Xp),e(Xp,Vhe),M(H9,Vhe,null),e(pd,WAo),e(pd,Xhe),e(Xhe,UAo),v(f,zYe,_),v(f,Po,_),M(J9,Po,null),e(Po,HAo),e(Po,_d),e(_d,JAo),e(_d,sO),e(sO,YAo),e(_d,KAo),e(_d,lO),e(lO,ZAo),e(_d,e6o),e(Po,o6o),e(Po,Y9),e(Y9,r6o),e(Y9,zhe),e(zhe,t6o),e(Y9,a6o),e(Po,n6o),e(Po,_t),M(K9,_t,null),e(_t,s6o),e(_t,Qhe),e(Qhe,l6o),e(_t,i6o),e(_t,vd),e(vd,d6o),e(vd,Whe),e(Whe,c6o),e(vd,f6o),e(vd,iO),e(iO,m6o),e(vd,g6o),e(_t,h6o),M(zp,_t,null),e(Po,u6o),e(Po,Ze),M(Z9,Ze,null),e(Ze,p6o),e(Ze,Uhe),e(Uhe,_6o),e(Ze,v6o),e(Ze,Ja),e(Ja,b6o),e(Ja,Hhe),e(Hhe,F6o),e(Ja,T6o),e(Ja,Jhe),e(Jhe,M6o),e(Ja,E6o),e(Ja,Yhe),e(Yhe,C6o),e(Ja,w6o),e(Ze,A6o),e(Ze,y),e(y,Qp),e(Qp,Khe),e(Khe,L6o),e(Qp,y6o),e(Qp,dO),e(dO,x6o),e(Qp,$6o),e(y,k6o),e(y,Wp),e(Wp,Zhe),e(Zhe,S6o),e(Wp,R6o),e(Wp,cO),e(cO,P6o),e(Wp,B6o),e(y,I6o),e(y,Up),e(Up,eue),e(eue,N6o),e(Up,q6o),e(Up,fO),e(fO,j6o),e(Up,D6o),e(y,G6o),e(y,Hp),e(Hp,oue),e(oue,O6o),e(Hp,V6o),e(Hp,mO),e(mO,X6o),e(Hp,z6o),e(y,Q6o),e(y,Jp),e(Jp,rue),e(rue,W6o),e(Jp,U6o),e(Jp,gO),e(gO,H6o),e(Jp,J6o),e(y,Y6o),e(y,Yp),e(Yp,tue),e(tue,K6o),e(Yp,Z6o),e(Yp,hO),e(hO,e7o),e(Yp,o7o),e(y,r7o),e(y,Kp),e(Kp,aue),e(aue,t7o),e(Kp,a7o),e(Kp,uO),e(uO,n7o),e(Kp,s7o),e(y,l7o),e(y,Zp),e(Zp,nue),e(nue,i7o),e(Zp,d7o),e(Zp,pO),e(pO,c7o),e(Zp,f7o),e(y,m7o),e(y,e_),e(e_,sue),e(sue,g7o),e(e_,h7o),e(e_,_O),e(_O,u7o),e(e_,p7o),e(y,_7o),e(y,o_),e(o_,lue),e(lue,v7o),e(o_,b7o),e(o_,vO),e(vO,F7o),e(o_,T7o),e(y,M7o),e(y,r_),e(r_,iue),e(iue,E7o),e(r_,C7o),e(r_,bO),e(bO,w7o),e(r_,A7o),e(y,L7o),e(y,t_),e(t_,due),e(due,y7o),e(t_,x7o),e(t_,FO),e(FO,$7o),e(t_,k7o),e(y,S7o),e(y,a_),e(a_,cue),e(cue,R7o),e(a_,P7o),e(a_,TO),e(TO,B7o),e(a_,I7o),e(y,N7o),e(y,n_),e(n_,fue),e(fue,q7o),e(n_,j7o),e(n_,MO),e(MO,D7o),e(n_,G7o),e(y,O7o),e(y,s_),e(s_,mue),e(mue,V7o),e(s_,X7o),e(s_,EO),e(EO,z7o),e(s_,Q7o),e(y,W7o),e(y,l_),e(l_,gue),e(gue,U7o),e(l_,H7o),e(l_,CO),e(CO,J7o),e(l_,Y7o),e(y,K7o),e(y,i_),e(i_,hue),e(hue,Z7o),e(i_,eLo),e(i_,wO),e(wO,oLo),e(i_,rLo),e(y,tLo),e(y,d_),e(d_,uue),e(uue,aLo),e(d_,nLo),e(d_,AO),e(AO,sLo),e(d_,lLo),e(y,iLo),e(y,c_),e(c_,pue),e(pue,dLo),e(c_,cLo),e(c_,LO),e(LO,fLo),e(c_,mLo),e(y,gLo),e(y,f_),e(f_,_ue),e(_ue,hLo),e(f_,uLo),e(f_,yO),e(yO,pLo),e(f_,_Lo),e(y,vLo),e(y,m_),e(m_,vue),e(vue,bLo),e(m_,FLo),e(m_,xO),e(xO,TLo),e(m_,MLo),e(y,ELo),e(y,g_),e(g_,bue),e(bue,CLo),e(g_,wLo),e(g_,$O),e($O,ALo),e(g_,LLo),e(y,yLo),e(y,h_),e(h_,Fue),e(Fue,xLo),e(h_,$Lo),e(h_,kO),e(kO,kLo),e(h_,SLo),e(y,RLo),e(y,u_),e(u_,Tue),e(Tue,PLo),e(u_,BLo),e(u_,SO),e(SO,ILo),e(u_,NLo),e(y,qLo),e(y,p_),e(p_,Mue),e(Mue,jLo),e(p_,DLo),e(p_,RO),e(RO,GLo),e(p_,OLo),e(y,VLo),e(y,__),e(__,Eue),e(Eue,XLo),e(__,zLo),e(__,PO),e(PO,QLo),e(__,WLo),e(y,ULo),e(y,v_),e(v_,Cue),e(Cue,HLo),e(v_,JLo),e(v_,BO),e(BO,YLo),e(v_,KLo),e(y,ZLo),e(y,b_),e(b_,wue),e(wue,eyo),e(b_,oyo),e(b_,IO),e(IO,ryo),e(b_,tyo),e(y,ayo),e(y,F_),e(F_,Aue),e(Aue,nyo),e(F_,syo),e(F_,NO),e(NO,lyo),e(F_,iyo),e(y,dyo),e(y,T_),e(T_,Lue),e(Lue,cyo),e(T_,fyo),e(T_,qO),e(qO,myo),e(T_,gyo),e(y,hyo),e(y,M_),e(M_,yue),e(yue,uyo),e(M_,pyo),e(M_,jO),e(jO,_yo),e(M_,vyo),e(y,byo),e(y,E_),e(E_,xue),e(xue,Fyo),e(E_,Tyo),e(E_,DO),e(DO,Myo),e(E_,Eyo),e(y,Cyo),e(y,C_),e(C_,$ue),e($ue,wyo),e(C_,Ayo),e(C_,GO),e(GO,Lyo),e(C_,yyo),e(y,xyo),e(y,w_),e(w_,kue),e(kue,$yo),e(w_,kyo),e(w_,OO),e(OO,Syo),e(w_,Ryo),e(y,Pyo),e(y,A_),e(A_,Sue),e(Sue,Byo),e(A_,Iyo),e(A_,VO),e(VO,Nyo),e(A_,qyo),e(y,jyo),e(y,L_),e(L_,Rue),e(Rue,Dyo),e(L_,Gyo),e(L_,XO),e(XO,Oyo),e(L_,Vyo),e(y,Xyo),e(y,pl),e(pl,Pue),e(Pue,zyo),e(pl,Qyo),e(pl,zO),e(zO,Wyo),e(pl,Uyo),e(pl,QO),e(QO,Hyo),e(pl,Jyo),e(y,Yyo),e(y,y_),e(y_,Bue),e(Bue,Kyo),e(y_,Zyo),e(y_,WO),e(WO,e8o),e(y_,o8o),e(y,r8o),e(y,x_),e(x_,Iue),e(Iue,t8o),e(x_,a8o),e(x_,UO),e(UO,n8o),e(x_,s8o),e(y,l8o),e(y,$_),e($_,Nue),e(Nue,i8o),e($_,d8o),e($_,HO),e(HO,c8o),e($_,f8o),e(y,m8o),e(y,k_),e(k_,que),e(que,g8o),e(k_,h8o),e(k_,JO),e(JO,u8o),e(k_,p8o),e(y,_8o),e(y,S_),e(S_,jue),e(jue,v8o),e(S_,b8o),e(S_,YO),e(YO,F8o),e(S_,T8o),e(y,M8o),e(y,R_),e(R_,Due),e(Due,E8o),e(R_,C8o),e(R_,KO),e(KO,w8o),e(R_,A8o),e(y,L8o),e(y,P_),e(P_,Gue),e(Gue,y8o),e(P_,x8o),e(P_,ZO),e(ZO,$8o),e(P_,k8o),e(y,S8o),e(y,B_),e(B_,Oue),e(Oue,R8o),e(B_,P8o),e(B_,eV),e(eV,B8o),e(B_,I8o),e(y,N8o),e(y,I_),e(I_,Vue),e(Vue,q8o),e(I_,j8o),e(I_,oV),e(oV,D8o),e(I_,G8o),e(y,O8o),e(y,N_),e(N_,Xue),e(Xue,V8o),e(N_,X8o),e(N_,rV),e(rV,z8o),e(N_,Q8o),e(y,W8o),e(y,q_),e(q_,zue),e(zue,U8o),e(q_,H8o),e(q_,tV),e(tV,J8o),e(q_,Y8o),e(y,K8o),e(y,j_),e(j_,Que),e(Que,Z8o),e(j_,e9o),e(j_,aV),e(aV,o9o),e(j_,r9o),e(y,t9o),e(y,D_),e(D_,Wue),e(Wue,a9o),e(D_,n9o),e(D_,nV),e(nV,s9o),e(D_,l9o),e(y,i9o),e(y,G_),e(G_,Uue),e(Uue,d9o),e(G_,c9o),e(G_,sV),e(sV,f9o),e(G_,m9o),e(y,g9o),e(y,O_),e(O_,Hue),e(Hue,h9o),e(O_,u9o),e(O_,lV),e(lV,p9o),e(O_,_9o),e(y,v9o),e(y,V_),e(V_,Jue),e(Jue,b9o),e(V_,F9o),e(V_,iV),e(iV,T9o),e(V_,M9o),e(y,E9o),e(y,X_),e(X_,Yue),e(Yue,C9o),e(X_,w9o),e(X_,dV),e(dV,A9o),e(X_,L9o),e(y,y9o),e(y,z_),e(z_,Kue),e(Kue,x9o),e(z_,$9o),e(z_,cV),e(cV,k9o),e(z_,S9o),e(y,R9o),e(y,Q_),e(Q_,Zue),e(Zue,P9o),e(Q_,B9o),e(Q_,fV),e(fV,I9o),e(Q_,N9o),e(y,q9o),e(y,W_),e(W_,epe),e(epe,j9o),e(W_,D9o),e(W_,mV),e(mV,G9o),e(W_,O9o),e(y,V9o),e(y,U_),e(U_,ope),e(ope,X9o),e(U_,z9o),e(U_,gV),e(gV,Q9o),e(U_,W9o),e(y,U9o),e(y,H_),e(H_,rpe),e(rpe,H9o),e(H_,J9o),e(H_,hV),e(hV,Y9o),e(H_,K9o),e(y,Z9o),e(y,J_),e(J_,tpe),e(tpe,exo),e(J_,oxo),e(J_,uV),e(uV,rxo),e(J_,txo),e(y,axo),e(y,Y_),e(Y_,ape),e(ape,nxo),e(Y_,sxo),e(Y_,pV),e(pV,lxo),e(Y_,ixo),e(y,dxo),e(y,K_),e(K_,npe),e(npe,cxo),e(K_,fxo),e(K_,_V),e(_V,mxo),e(K_,gxo),e(y,hxo),e(y,Z_),e(Z_,spe),e(spe,uxo),e(Z_,pxo),e(Z_,vV),e(vV,_xo),e(Z_,vxo),e(y,bxo),e(y,e2),e(e2,lpe),e(lpe,Fxo),e(e2,Txo),e(e2,bV),e(bV,Mxo),e(e2,Exo),e(y,Cxo),e(y,o2),e(o2,ipe),e(ipe,wxo),e(o2,Axo),e(o2,FV),e(FV,Lxo),e(o2,yxo),e(y,xxo),e(y,r2),e(r2,dpe),e(dpe,$xo),e(r2,kxo),e(r2,TV),e(TV,Sxo),e(r2,Rxo),e(y,Pxo),e(y,t2),e(t2,cpe),e(cpe,Bxo),e(t2,Ixo),e(t2,MV),e(MV,Nxo),e(t2,qxo),e(y,jxo),e(y,a2),e(a2,fpe),e(fpe,Dxo),e(a2,Gxo),e(a2,EV),e(EV,Oxo),e(a2,Vxo),e(y,Xxo),e(y,n2),e(n2,mpe),e(mpe,zxo),e(n2,Qxo),e(n2,CV),e(CV,Wxo),e(n2,Uxo),e(y,Hxo),e(y,s2),e(s2,gpe),e(gpe,Jxo),e(s2,Yxo),e(s2,wV),e(wV,Kxo),e(s2,Zxo),e(y,e$o),e(y,l2),e(l2,hpe),e(hpe,o$o),e(l2,r$o),e(l2,AV),e(AV,t$o),e(l2,a$o),e(y,n$o),e(y,i2),e(i2,upe),e(upe,s$o),e(i2,l$o),e(i2,LV),e(LV,i$o),e(i2,d$o),e(y,c$o),e(y,d2),e(d2,ppe),e(ppe,f$o),e(d2,m$o),e(d2,yV),e(yV,g$o),e(d2,h$o),e(y,u$o),e(y,c2),e(c2,_pe),e(_pe,p$o),e(c2,_$o),e(c2,xV),e(xV,v$o),e(c2,b$o),e(y,F$o),e(y,f2),e(f2,vpe),e(vpe,T$o),e(f2,M$o),e(f2,$V),e($V,E$o),e(f2,C$o),e(y,w$o),e(y,m2),e(m2,bpe),e(bpe,A$o),e(m2,L$o),e(m2,kV),e(kV,y$o),e(m2,x$o),e(y,$$o),e(y,g2),e(g2,Fpe),e(Fpe,k$o),e(g2,S$o),e(g2,SV),e(SV,R$o),e(g2,P$o),e(y,B$o),e(y,h2),e(h2,Tpe),e(Tpe,I$o),e(h2,N$o),e(h2,RV),e(RV,q$o),e(h2,j$o),e(y,D$o),e(y,u2),e(u2,Mpe),e(Mpe,G$o),e(u2,O$o),e(u2,PV),e(PV,V$o),e(u2,X$o),e(y,z$o),e(y,p2),e(p2,Epe),e(Epe,Q$o),e(p2,W$o),e(p2,BV),e(BV,U$o),e(p2,H$o),e(y,J$o),e(y,_2),e(_2,Cpe),e(Cpe,Y$o),e(_2,K$o),e(_2,IV),e(IV,Z$o),e(_2,eko),e(y,oko),e(y,v2),e(v2,wpe),e(wpe,rko),e(v2,tko),e(v2,NV),e(NV,ako),e(v2,nko),e(y,sko),e(y,b2),e(b2,Ape),e(Ape,lko),e(b2,iko),e(b2,qV),e(qV,dko),e(b2,cko),e(y,fko),e(y,F2),e(F2,Lpe),e(Lpe,mko),e(F2,gko),e(F2,jV),e(jV,hko),e(F2,uko),e(y,pko),e(y,T2),e(T2,ype),e(ype,_ko),e(T2,vko),e(T2,DV),e(DV,bko),e(T2,Fko),e(y,Tko),e(y,M2),e(M2,xpe),e(xpe,Mko),e(M2,Eko),e(M2,GV),e(GV,Cko),e(M2,wko),e(y,Ako),e(y,E2),e(E2,$pe),e($pe,Lko),e(E2,yko),e(E2,OV),e(OV,xko),e(E2,$ko),e(y,kko),e(y,C2),e(C2,kpe),e(kpe,Sko),e(C2,Rko),e(C2,VV),e(VV,Pko),e(C2,Bko),e(y,Iko),e(y,w2),e(w2,Spe),e(Spe,Nko),e(w2,qko),e(w2,XV),e(XV,jko),e(w2,Dko),e(y,Gko),e(y,A2),e(A2,Rpe),e(Rpe,Oko),e(A2,Vko),e(A2,zV),e(zV,Xko),e(A2,zko),e(y,Qko),e(y,L2),e(L2,Ppe),e(Ppe,Wko),e(L2,Uko),e(L2,QV),e(QV,Hko),e(L2,Jko),e(y,Yko),e(y,y2),e(y2,Bpe),e(Bpe,Kko),e(y2,Zko),e(y2,WV),e(WV,eSo),e(y2,oSo),e(y,rSo),e(y,x2),e(x2,Ipe),e(Ipe,tSo),e(x2,aSo),e(x2,UV),e(UV,nSo),e(x2,sSo),e(y,lSo),e(y,$2),e($2,Npe),e(Npe,iSo),e($2,dSo),e($2,HV),e(HV,cSo),e($2,fSo),e(y,mSo),e(y,k2),e(k2,qpe),e(qpe,gSo),e(k2,hSo),e(k2,JV),e(JV,uSo),e(k2,pSo),e(y,_So),e(y,S2),e(S2,jpe),e(jpe,vSo),e(S2,bSo),e(S2,YV),e(YV,FSo),e(S2,TSo),e(y,MSo),e(y,R2),e(R2,Dpe),e(Dpe,ESo),e(R2,CSo),e(R2,KV),e(KV,wSo),e(R2,ASo),e(y,LSo),e(y,P2),e(P2,Gpe),e(Gpe,ySo),e(P2,xSo),e(P2,ZV),e(ZV,$So),e(P2,kSo),e(y,SSo),e(y,B2),e(B2,Ope),e(Ope,RSo),e(B2,PSo),e(B2,eX),e(eX,BSo),e(B2,ISo),e(y,NSo),e(y,I2),e(I2,Vpe),e(Vpe,qSo),e(I2,jSo),e(I2,oX),e(oX,DSo),e(I2,GSo),e(y,OSo),e(y,N2),e(N2,Xpe),e(Xpe,VSo),e(N2,XSo),e(N2,rX),e(rX,zSo),e(N2,QSo),e(y,WSo),e(y,q2),e(q2,zpe),e(zpe,USo),e(q2,HSo),e(q2,tX),e(tX,JSo),e(q2,YSo),e(y,KSo),e(y,j2),e(j2,Qpe),e(Qpe,ZSo),e(j2,eRo),e(j2,aX),e(aX,oRo),e(j2,rRo),e(y,tRo),e(y,D2),e(D2,Wpe),e(Wpe,aRo),e(D2,nRo),e(D2,nX),e(nX,sRo),e(D2,lRo),e(y,iRo),e(y,G2),e(G2,Upe),e(Upe,dRo),e(G2,cRo),e(G2,sX),e(sX,fRo),e(G2,mRo),e(y,gRo),e(y,O2),e(O2,Hpe),e(Hpe,hRo),e(O2,uRo),e(O2,lX),e(lX,pRo),e(O2,_Ro),e(y,vRo),e(y,V2),e(V2,Jpe),e(Jpe,bRo),e(V2,FRo),e(V2,iX),e(iX,TRo),e(V2,MRo),e(y,ERo),e(y,X2),e(X2,Ype),e(Ype,CRo),e(X2,wRo),e(X2,dX),e(dX,ARo),e(X2,LRo),e(y,yRo),e(y,z2),e(z2,Kpe),e(Kpe,xRo),e(z2,$Ro),e(z2,cX),e(cX,kRo),e(z2,SRo),e(y,RRo),e(y,Q2),e(Q2,Zpe),e(Zpe,PRo),e(Q2,BRo),e(Q2,fX),e(fX,IRo),e(Q2,NRo),e(y,qRo),e(y,W2),e(W2,e_e),e(e_e,jRo),e(W2,DRo),e(W2,mX),e(mX,GRo),e(W2,ORo),e(y,VRo),e(y,U2),e(U2,o_e),e(o_e,XRo),e(U2,zRo),e(U2,gX),e(gX,QRo),e(U2,WRo),e(y,URo),e(y,H2),e(H2,r_e),e(r_e,HRo),e(H2,JRo),e(H2,hX),e(hX,YRo),e(H2,KRo),e(y,ZRo),e(y,J2),e(J2,t_e),e(t_e,ePo),e(J2,oPo),e(J2,uX),e(uX,rPo),e(J2,tPo),e(y,aPo),e(y,Y2),e(Y2,a_e),e(a_e,nPo),e(Y2,sPo),e(Y2,pX),e(pX,lPo),e(Y2,iPo),e(y,dPo),e(y,K2),e(K2,n_e),e(n_e,cPo),e(K2,fPo),e(K2,_X),e(_X,mPo),e(K2,gPo),e(y,hPo),e(y,Z2),e(Z2,s_e),e(s_e,uPo),e(Z2,pPo),e(Z2,vX),e(vX,_Po),e(Z2,vPo),e(y,bPo),e(y,ev),e(ev,l_e),e(l_e,FPo),e(ev,TPo),e(ev,bX),e(bX,MPo),e(ev,EPo),e(y,CPo),e(y,ov),e(ov,i_e),e(i_e,wPo),e(ov,APo),e(ov,FX),e(FX,LPo),e(ov,yPo),e(Ze,xPo),e(Ze,rv),e(rv,$Po),e(rv,d_e),e(d_e,kPo),e(rv,SPo),e(rv,c_e),e(c_e,RPo),e(Ze,PPo),M(tv,Ze,null),v(f,QYe,_),v(f,bd,_),e(bd,av),e(av,f_e),M(ex,f_e,null),e(bd,BPo),e(bd,m_e),e(m_e,IPo),v(f,WYe,_),v(f,Bo,_),M(ox,Bo,null),e(Bo,NPo),e(Bo,Fd),e(Fd,qPo),e(Fd,TX),e(TX,jPo),e(Fd,DPo),e(Fd,MX),e(MX,GPo),e(Fd,OPo),e(Bo,VPo),e(Bo,rx),e(rx,XPo),e(rx,g_e),e(g_e,zPo),e(rx,QPo),e(Bo,WPo),e(Bo,vt),M(tx,vt,null),e(vt,UPo),e(vt,h_e),e(h_e,HPo),e(vt,JPo),e(vt,Td),e(Td,YPo),e(Td,u_e),e(u_e,KPo),e(Td,ZPo),e(Td,EX),e(EX,eBo),e(Td,oBo),e(vt,rBo),M(nv,vt,null),e(Bo,tBo),e(Bo,eo),M(ax,eo,null),e(eo,aBo),e(eo,p_e),e(p_e,nBo),e(eo,sBo),e(eo,Ya),e(Ya,lBo),e(Ya,__e),e(__e,iBo),e(Ya,dBo),e(Ya,v_e),e(v_e,cBo),e(Ya,fBo),e(Ya,b_e),e(b_e,mBo),e(Ya,gBo),e(eo,hBo),e(eo,G),e(G,sv),e(sv,F_e),e(F_e,uBo),e(sv,pBo),e(sv,CX),e(CX,_Bo),e(sv,vBo),e(G,bBo),e(G,lv),e(lv,T_e),e(T_e,FBo),e(lv,TBo),e(lv,wX),e(wX,MBo),e(lv,EBo),e(G,CBo),e(G,iv),e(iv,M_e),e(M_e,wBo),e(iv,ABo),e(iv,AX),e(AX,LBo),e(iv,yBo),e(G,xBo),e(G,dv),e(dv,E_e),e(E_e,$Bo),e(dv,kBo),e(dv,LX),e(LX,SBo),e(dv,RBo),e(G,PBo),e(G,cv),e(cv,C_e),e(C_e,BBo),e(cv,IBo),e(cv,yX),e(yX,NBo),e(cv,qBo),e(G,jBo),e(G,fv),e(fv,w_e),e(w_e,DBo),e(fv,GBo),e(fv,xX),e(xX,OBo),e(fv,VBo),e(G,XBo),e(G,mv),e(mv,A_e),e(A_e,zBo),e(mv,QBo),e(mv,$X),e($X,WBo),e(mv,UBo),e(G,HBo),e(G,gv),e(gv,L_e),e(L_e,JBo),e(gv,YBo),e(gv,kX),e(kX,KBo),e(gv,ZBo),e(G,eIo),e(G,hv),e(hv,y_e),e(y_e,oIo),e(hv,rIo),e(hv,SX),e(SX,tIo),e(hv,aIo),e(G,nIo),e(G,uv),e(uv,x_e),e(x_e,sIo),e(uv,lIo),e(uv,RX),e(RX,iIo),e(uv,dIo),e(G,cIo),e(G,pv),e(pv,$_e),e($_e,fIo),e(pv,mIo),e(pv,PX),e(PX,gIo),e(pv,hIo),e(G,uIo),e(G,_v),e(_v,k_e),e(k_e,pIo),e(_v,_Io),e(_v,BX),e(BX,vIo),e(_v,bIo),e(G,FIo),e(G,vv),e(vv,S_e),e(S_e,TIo),e(vv,MIo),e(vv,IX),e(IX,EIo),e(vv,CIo),e(G,wIo),e(G,bv),e(bv,R_e),e(R_e,AIo),e(bv,LIo),e(bv,NX),e(NX,yIo),e(bv,xIo),e(G,$Io),e(G,Fv),e(Fv,P_e),e(P_e,kIo),e(Fv,SIo),e(Fv,qX),e(qX,RIo),e(Fv,PIo),e(G,BIo),e(G,Tv),e(Tv,B_e),e(B_e,IIo),e(Tv,NIo),e(Tv,jX),e(jX,qIo),e(Tv,jIo),e(G,DIo),e(G,Mv),e(Mv,I_e),e(I_e,GIo),e(Mv,OIo),e(Mv,DX),e(DX,VIo),e(Mv,XIo),e(G,zIo),e(G,Ev),e(Ev,N_e),e(N_e,QIo),e(Ev,WIo),e(Ev,GX),e(GX,UIo),e(Ev,HIo),e(G,JIo),e(G,Cv),e(Cv,q_e),e(q_e,YIo),e(Cv,KIo),e(Cv,OX),e(OX,ZIo),e(Cv,eNo),e(G,oNo),e(G,wv),e(wv,j_e),e(j_e,rNo),e(wv,tNo),e(wv,VX),e(VX,aNo),e(wv,nNo),e(G,sNo),e(G,Av),e(Av,D_e),e(D_e,lNo),e(Av,iNo),e(Av,XX),e(XX,dNo),e(Av,cNo),e(G,fNo),e(G,Lv),e(Lv,G_e),e(G_e,mNo),e(Lv,gNo),e(Lv,zX),e(zX,hNo),e(Lv,uNo),e(G,pNo),e(G,yv),e(yv,O_e),e(O_e,_No),e(yv,vNo),e(yv,QX),e(QX,bNo),e(yv,FNo),e(G,TNo),e(G,xv),e(xv,V_e),e(V_e,MNo),e(xv,ENo),e(xv,WX),e(WX,CNo),e(xv,wNo),e(G,ANo),e(G,$v),e($v,X_e),e(X_e,LNo),e($v,yNo),e($v,UX),e(UX,xNo),e($v,$No),e(G,kNo),e(G,kv),e(kv,z_e),e(z_e,SNo),e(kv,RNo),e(kv,HX),e(HX,PNo),e(kv,BNo),e(G,INo),e(G,Sv),e(Sv,Q_e),e(Q_e,NNo),e(Sv,qNo),e(Sv,JX),e(JX,jNo),e(Sv,DNo),e(G,GNo),e(G,Rv),e(Rv,W_e),e(W_e,ONo),e(Rv,VNo),e(Rv,YX),e(YX,XNo),e(Rv,zNo),e(G,QNo),e(G,Pv),e(Pv,U_e),e(U_e,WNo),e(Pv,UNo),e(Pv,KX),e(KX,HNo),e(Pv,JNo),e(G,YNo),e(G,Bv),e(Bv,H_e),e(H_e,KNo),e(Bv,ZNo),e(Bv,ZX),e(ZX,eqo),e(Bv,oqo),e(G,rqo),e(G,Iv),e(Iv,J_e),e(J_e,tqo),e(Iv,aqo),e(Iv,ez),e(ez,nqo),e(Iv,sqo),e(G,lqo),e(G,Nv),e(Nv,Y_e),e(Y_e,iqo),e(Nv,dqo),e(Nv,oz),e(oz,cqo),e(Nv,fqo),e(G,mqo),e(G,qv),e(qv,K_e),e(K_e,gqo),e(qv,hqo),e(qv,rz),e(rz,uqo),e(qv,pqo),e(G,_qo),e(G,jv),e(jv,Z_e),e(Z_e,vqo),e(jv,bqo),e(jv,tz),e(tz,Fqo),e(jv,Tqo),e(G,Mqo),e(G,Dv),e(Dv,e2e),e(e2e,Eqo),e(Dv,Cqo),e(Dv,az),e(az,wqo),e(Dv,Aqo),e(G,Lqo),e(G,Gv),e(Gv,o2e),e(o2e,yqo),e(Gv,xqo),e(Gv,nz),e(nz,$qo),e(Gv,kqo),e(G,Sqo),e(G,Ov),e(Ov,r2e),e(r2e,Rqo),e(Ov,Pqo),e(Ov,sz),e(sz,Bqo),e(Ov,Iqo),e(G,Nqo),e(G,Vv),e(Vv,t2e),e(t2e,qqo),e(Vv,jqo),e(Vv,lz),e(lz,Dqo),e(Vv,Gqo),e(G,Oqo),e(G,Xv),e(Xv,a2e),e(a2e,Vqo),e(Xv,Xqo),e(Xv,iz),e(iz,zqo),e(Xv,Qqo),e(G,Wqo),e(G,zv),e(zv,n2e),e(n2e,Uqo),e(zv,Hqo),e(zv,dz),e(dz,Jqo),e(zv,Yqo),e(G,Kqo),e(G,Qv),e(Qv,s2e),e(s2e,Zqo),e(Qv,ejo),e(Qv,cz),e(cz,ojo),e(Qv,rjo),e(G,tjo),e(G,Wv),e(Wv,l2e),e(l2e,ajo),e(Wv,njo),e(Wv,fz),e(fz,sjo),e(Wv,ljo),e(G,ijo),e(G,Uv),e(Uv,i2e),e(i2e,djo),e(Uv,cjo),e(Uv,mz),e(mz,fjo),e(Uv,mjo),e(G,gjo),e(G,Hv),e(Hv,d2e),e(d2e,hjo),e(Hv,ujo),e(Hv,gz),e(gz,pjo),e(Hv,_jo),e(G,vjo),e(G,Jv),e(Jv,c2e),e(c2e,bjo),e(Jv,Fjo),e(Jv,hz),e(hz,Tjo),e(Jv,Mjo),e(G,Ejo),e(G,Yv),e(Yv,f2e),e(f2e,Cjo),e(Yv,wjo),e(Yv,uz),e(uz,Ajo),e(Yv,Ljo),e(G,yjo),e(G,Kv),e(Kv,m2e),e(m2e,xjo),e(Kv,$jo),e(Kv,pz),e(pz,kjo),e(Kv,Sjo),e(G,Rjo),e(G,Zv),e(Zv,g2e),e(g2e,Pjo),e(Zv,Bjo),e(Zv,_z),e(_z,Ijo),e(Zv,Njo),e(eo,qjo),e(eo,e4),e(e4,jjo),e(e4,h2e),e(h2e,Djo),e(e4,Gjo),e(e4,u2e),e(u2e,Ojo),e(eo,Vjo),M(o4,eo,null),v(f,UYe,_),v(f,Md,_),e(Md,r4),e(r4,p2e),M(nx,p2e,null),e(Md,Xjo),e(Md,_2e),e(_2e,zjo),v(f,HYe,_),v(f,Io,_),M(sx,Io,null),e(Io,Qjo),e(Io,Ed),e(Ed,Wjo),e(Ed,vz),e(vz,Ujo),e(Ed,Hjo),e(Ed,bz),e(bz,Jjo),e(Ed,Yjo),e(Io,Kjo),e(Io,lx),e(lx,Zjo),e(lx,v2e),e(v2e,eDo),e(lx,oDo),e(Io,rDo),e(Io,bt),M(ix,bt,null),e(bt,tDo),e(bt,b2e),e(b2e,aDo),e(bt,nDo),e(bt,Cd),e(Cd,sDo),e(Cd,F2e),e(F2e,lDo),e(Cd,iDo),e(Cd,Fz),e(Fz,dDo),e(Cd,cDo),e(bt,fDo),M(t4,bt,null),e(Io,mDo),e(Io,oo),M(dx,oo,null),e(oo,gDo),e(oo,T2e),e(T2e,hDo),e(oo,uDo),e(oo,Ka),e(Ka,pDo),e(Ka,M2e),e(M2e,_Do),e(Ka,vDo),e(Ka,E2e),e(E2e,bDo),e(Ka,FDo),e(Ka,C2e),e(C2e,TDo),e(Ka,MDo),e(oo,EDo),e(oo,z),e(z,a4),e(a4,w2e),e(w2e,CDo),e(a4,wDo),e(a4,Tz),e(Tz,ADo),e(a4,LDo),e(z,yDo),e(z,n4),e(n4,A2e),e(A2e,xDo),e(n4,$Do),e(n4,Mz),e(Mz,kDo),e(n4,SDo),e(z,RDo),e(z,s4),e(s4,L2e),e(L2e,PDo),e(s4,BDo),e(s4,Ez),e(Ez,IDo),e(s4,NDo),e(z,qDo),e(z,l4),e(l4,y2e),e(y2e,jDo),e(l4,DDo),e(l4,Cz),e(Cz,GDo),e(l4,ODo),e(z,VDo),e(z,i4),e(i4,x2e),e(x2e,XDo),e(i4,zDo),e(i4,wz),e(wz,QDo),e(i4,WDo),e(z,UDo),e(z,d4),e(d4,$2e),e($2e,HDo),e(d4,JDo),e(d4,Az),e(Az,YDo),e(d4,KDo),e(z,ZDo),e(z,c4),e(c4,k2e),e(k2e,eGo),e(c4,oGo),e(c4,Lz),e(Lz,rGo),e(c4,tGo),e(z,aGo),e(z,f4),e(f4,S2e),e(S2e,nGo),e(f4,sGo),e(f4,yz),e(yz,lGo),e(f4,iGo),e(z,dGo),e(z,m4),e(m4,R2e),e(R2e,cGo),e(m4,fGo),e(m4,xz),e(xz,mGo),e(m4,gGo),e(z,hGo),e(z,g4),e(g4,P2e),e(P2e,uGo),e(g4,pGo),e(g4,$z),e($z,_Go),e(g4,vGo),e(z,bGo),e(z,h4),e(h4,B2e),e(B2e,FGo),e(h4,TGo),e(h4,kz),e(kz,MGo),e(h4,EGo),e(z,CGo),e(z,u4),e(u4,I2e),e(I2e,wGo),e(u4,AGo),e(u4,Sz),e(Sz,LGo),e(u4,yGo),e(z,xGo),e(z,p4),e(p4,N2e),e(N2e,$Go),e(p4,kGo),e(p4,Rz),e(Rz,SGo),e(p4,RGo),e(z,PGo),e(z,_4),e(_4,q2e),e(q2e,BGo),e(_4,IGo),e(_4,Pz),e(Pz,NGo),e(_4,qGo),e(z,jGo),e(z,v4),e(v4,j2e),e(j2e,DGo),e(v4,GGo),e(v4,Bz),e(Bz,OGo),e(v4,VGo),e(z,XGo),e(z,b4),e(b4,D2e),e(D2e,zGo),e(b4,QGo),e(b4,Iz),e(Iz,WGo),e(b4,UGo),e(z,HGo),e(z,F4),e(F4,G2e),e(G2e,JGo),e(F4,YGo),e(F4,Nz),e(Nz,KGo),e(F4,ZGo),e(z,eOo),e(z,T4),e(T4,O2e),e(O2e,oOo),e(T4,rOo),e(T4,qz),e(qz,tOo),e(T4,aOo),e(z,nOo),e(z,M4),e(M4,V2e),e(V2e,sOo),e(M4,lOo),e(M4,jz),e(jz,iOo),e(M4,dOo),e(z,cOo),e(z,E4),e(E4,X2e),e(X2e,fOo),e(E4,mOo),e(E4,Dz),e(Dz,gOo),e(E4,hOo),e(z,uOo),e(z,C4),e(C4,z2e),e(z2e,pOo),e(C4,_Oo),e(C4,Gz),e(Gz,vOo),e(C4,bOo),e(z,FOo),e(z,w4),e(w4,Q2e),e(Q2e,TOo),e(w4,MOo),e(w4,Oz),e(Oz,EOo),e(w4,COo),e(z,wOo),e(z,A4),e(A4,W2e),e(W2e,AOo),e(A4,LOo),e(A4,Vz),e(Vz,yOo),e(A4,xOo),e(z,$Oo),e(z,L4),e(L4,U2e),e(U2e,kOo),e(L4,SOo),e(L4,Xz),e(Xz,ROo),e(L4,POo),e(z,BOo),e(z,y4),e(y4,H2e),e(H2e,IOo),e(y4,NOo),e(y4,zz),e(zz,qOo),e(y4,jOo),e(z,DOo),e(z,x4),e(x4,J2e),e(J2e,GOo),e(x4,OOo),e(x4,Qz),e(Qz,VOo),e(x4,XOo),e(z,zOo),e(z,$4),e($4,Y2e),e(Y2e,QOo),e($4,WOo),e($4,Wz),e(Wz,UOo),e($4,HOo),e(z,JOo),e(z,k4),e(k4,K2e),e(K2e,YOo),e(k4,KOo),e(k4,Uz),e(Uz,ZOo),e(k4,eVo),e(z,oVo),e(z,S4),e(S4,Z2e),e(Z2e,rVo),e(S4,tVo),e(S4,Hz),e(Hz,aVo),e(S4,nVo),e(z,sVo),e(z,R4),e(R4,eve),e(eve,lVo),e(R4,iVo),e(R4,Jz),e(Jz,dVo),e(R4,cVo),e(z,fVo),e(z,P4),e(P4,ove),e(ove,mVo),e(P4,gVo),e(P4,Yz),e(Yz,hVo),e(P4,uVo),e(z,pVo),e(z,B4),e(B4,rve),e(rve,_Vo),e(B4,vVo),e(B4,Kz),e(Kz,bVo),e(B4,FVo),e(z,TVo),e(z,I4),e(I4,tve),e(tve,MVo),e(I4,EVo),e(I4,Zz),e(Zz,CVo),e(I4,wVo),e(z,AVo),e(z,N4),e(N4,ave),e(ave,LVo),e(N4,yVo),e(N4,eQ),e(eQ,xVo),e(N4,$Vo),e(z,kVo),e(z,q4),e(q4,nve),e(nve,SVo),e(q4,RVo),e(q4,oQ),e(oQ,PVo),e(q4,BVo),e(z,IVo),e(z,j4),e(j4,sve),e(sve,NVo),e(j4,qVo),e(j4,rQ),e(rQ,jVo),e(j4,DVo),e(z,GVo),e(z,D4),e(D4,lve),e(lve,OVo),e(D4,VVo),e(D4,tQ),e(tQ,XVo),e(D4,zVo),e(z,QVo),e(z,G4),e(G4,ive),e(ive,WVo),e(G4,UVo),e(G4,aQ),e(aQ,HVo),e(G4,JVo),e(z,YVo),e(z,O4),e(O4,dve),e(dve,KVo),e(O4,ZVo),e(O4,nQ),e(nQ,eXo),e(O4,oXo),e(z,rXo),e(z,V4),e(V4,cve),e(cve,tXo),e(V4,aXo),e(V4,sQ),e(sQ,nXo),e(V4,sXo),e(z,lXo),e(z,X4),e(X4,fve),e(fve,iXo),e(X4,dXo),e(X4,lQ),e(lQ,cXo),e(X4,fXo),e(oo,mXo),e(oo,z4),e(z4,gXo),e(z4,mve),e(mve,hXo),e(z4,uXo),e(z4,gve),e(gve,pXo),e(oo,_Xo),M(Q4,oo,null),v(f,JYe,_),v(f,wd,_),e(wd,W4),e(W4,hve),M(cx,hve,null),e(wd,vXo),e(wd,uve),e(uve,bXo),v(f,YYe,_),v(f,No,_),M(fx,No,null),e(No,FXo),e(No,Ad),e(Ad,TXo),e(Ad,iQ),e(iQ,MXo),e(Ad,EXo),e(Ad,dQ),e(dQ,CXo),e(Ad,wXo),e(No,AXo),e(No,mx),e(mx,LXo),e(mx,pve),e(pve,yXo),e(mx,xXo),e(No,$Xo),e(No,Ft),M(gx,Ft,null),e(Ft,kXo),e(Ft,_ve),e(_ve,SXo),e(Ft,RXo),e(Ft,Ld),e(Ld,PXo),e(Ld,vve),e(vve,BXo),e(Ld,IXo),e(Ld,cQ),e(cQ,NXo),e(Ld,qXo),e(Ft,jXo),M(U4,Ft,null),e(No,DXo),e(No,ro),M(hx,ro,null),e(ro,GXo),e(ro,bve),e(bve,OXo),e(ro,VXo),e(ro,Za),e(Za,XXo),e(Za,Fve),e(Fve,zXo),e(Za,QXo),e(Za,Tve),e(Tve,WXo),e(Za,UXo),e(Za,Mve),e(Mve,HXo),e(Za,JXo),e(ro,YXo),e(ro,U),e(U,H4),e(H4,Eve),e(Eve,KXo),e(H4,ZXo),e(H4,fQ),e(fQ,ezo),e(H4,ozo),e(U,rzo),e(U,J4),e(J4,Cve),e(Cve,tzo),e(J4,azo),e(J4,mQ),e(mQ,nzo),e(J4,szo),e(U,lzo),e(U,Y4),e(Y4,wve),e(wve,izo),e(Y4,dzo),e(Y4,gQ),e(gQ,czo),e(Y4,fzo),e(U,mzo),e(U,K4),e(K4,Ave),e(Ave,gzo),e(K4,hzo),e(K4,hQ),e(hQ,uzo),e(K4,pzo),e(U,_zo),e(U,Z4),e(Z4,Lve),e(Lve,vzo),e(Z4,bzo),e(Z4,uQ),e(uQ,Fzo),e(Z4,Tzo),e(U,Mzo),e(U,eb),e(eb,yve),e(yve,Ezo),e(eb,Czo),e(eb,pQ),e(pQ,wzo),e(eb,Azo),e(U,Lzo),e(U,ob),e(ob,xve),e(xve,yzo),e(ob,xzo),e(ob,_Q),e(_Q,$zo),e(ob,kzo),e(U,Szo),e(U,rb),e(rb,$ve),e($ve,Rzo),e(rb,Pzo),e(rb,vQ),e(vQ,Bzo),e(rb,Izo),e(U,Nzo),e(U,tb),e(tb,kve),e(kve,qzo),e(tb,jzo),e(tb,bQ),e(bQ,Dzo),e(tb,Gzo),e(U,Ozo),e(U,ab),e(ab,Sve),e(Sve,Vzo),e(ab,Xzo),e(ab,FQ),e(FQ,zzo),e(ab,Qzo),e(U,Wzo),e(U,nb),e(nb,Rve),e(Rve,Uzo),e(nb,Hzo),e(nb,TQ),e(TQ,Jzo),e(nb,Yzo),e(U,Kzo),e(U,sb),e(sb,Pve),e(Pve,Zzo),e(sb,eQo),e(sb,MQ),e(MQ,oQo),e(sb,rQo),e(U,tQo),e(U,lb),e(lb,Bve),e(Bve,aQo),e(lb,nQo),e(lb,EQ),e(EQ,sQo),e(lb,lQo),e(U,iQo),e(U,ib),e(ib,Ive),e(Ive,dQo),e(ib,cQo),e(ib,CQ),e(CQ,fQo),e(ib,mQo),e(U,gQo),e(U,db),e(db,Nve),e(Nve,hQo),e(db,uQo),e(db,wQ),e(wQ,pQo),e(db,_Qo),e(U,vQo),e(U,cb),e(cb,qve),e(qve,bQo),e(cb,FQo),e(cb,AQ),e(AQ,TQo),e(cb,MQo),e(U,EQo),e(U,fb),e(fb,jve),e(jve,CQo),e(fb,wQo),e(fb,LQ),e(LQ,AQo),e(fb,LQo),e(U,yQo),e(U,mb),e(mb,Dve),e(Dve,xQo),e(mb,$Qo),e(mb,yQ),e(yQ,kQo),e(mb,SQo),e(U,RQo),e(U,gb),e(gb,Gve),e(Gve,PQo),e(gb,BQo),e(gb,xQ),e(xQ,IQo),e(gb,NQo),e(U,qQo),e(U,hb),e(hb,Ove),e(Ove,jQo),e(hb,DQo),e(hb,$Q),e($Q,GQo),e(hb,OQo),e(U,VQo),e(U,ub),e(ub,Vve),e(Vve,XQo),e(ub,zQo),e(ub,kQ),e(kQ,QQo),e(ub,WQo),e(U,UQo),e(U,pb),e(pb,Xve),e(Xve,HQo),e(pb,JQo),e(pb,SQ),e(SQ,YQo),e(pb,KQo),e(U,ZQo),e(U,_b),e(_b,zve),e(zve,eWo),e(_b,oWo),e(_b,RQ),e(RQ,rWo),e(_b,tWo),e(U,aWo),e(U,vb),e(vb,Qve),e(Qve,nWo),e(vb,sWo),e(vb,PQ),e(PQ,lWo),e(vb,iWo),e(U,dWo),e(U,bb),e(bb,Wve),e(Wve,cWo),e(bb,fWo),e(bb,BQ),e(BQ,mWo),e(bb,gWo),e(U,hWo),e(U,Fb),e(Fb,Uve),e(Uve,uWo),e(Fb,pWo),e(Fb,IQ),e(IQ,_Wo),e(Fb,vWo),e(U,bWo),e(U,Tb),e(Tb,Hve),e(Hve,FWo),e(Tb,TWo),e(Tb,NQ),e(NQ,MWo),e(Tb,EWo),e(U,CWo),e(U,Mb),e(Mb,Jve),e(Jve,wWo),e(Mb,AWo),e(Mb,qQ),e(qQ,LWo),e(Mb,yWo),e(U,xWo),e(U,Eb),e(Eb,Yve),e(Yve,$Wo),e(Eb,kWo),e(Eb,jQ),e(jQ,SWo),e(Eb,RWo),e(U,PWo),e(U,Cb),e(Cb,Kve),e(Kve,BWo),e(Cb,IWo),e(Cb,DQ),e(DQ,NWo),e(Cb,qWo),e(U,jWo),e(U,wb),e(wb,Zve),e(Zve,DWo),e(wb,GWo),e(wb,GQ),e(GQ,OWo),e(wb,VWo),e(U,XWo),e(U,Ab),e(Ab,e4e),e(e4e,zWo),e(Ab,QWo),e(Ab,OQ),e(OQ,WWo),e(Ab,UWo),e(U,HWo),e(U,Lb),e(Lb,o4e),e(o4e,JWo),e(Lb,YWo),e(Lb,VQ),e(VQ,KWo),e(Lb,ZWo),e(U,eUo),e(U,yb),e(yb,r4e),e(r4e,oUo),e(yb,rUo),e(yb,XQ),e(XQ,tUo),e(yb,aUo),e(U,nUo),e(U,xb),e(xb,t4e),e(t4e,sUo),e(xb,lUo),e(xb,a4e),e(a4e,iUo),e(xb,dUo),e(U,cUo),e(U,$b),e($b,n4e),e(n4e,fUo),e($b,mUo),e($b,zQ),e(zQ,gUo),e($b,hUo),e(U,uUo),e(U,kb),e(kb,s4e),e(s4e,pUo),e(kb,_Uo),e(kb,QQ),e(QQ,vUo),e(kb,bUo),e(U,FUo),e(U,Sb),e(Sb,l4e),e(l4e,TUo),e(Sb,MUo),e(Sb,WQ),e(WQ,EUo),e(Sb,CUo),e(U,wUo),e(U,Rb),e(Rb,i4e),e(i4e,AUo),e(Rb,LUo),e(Rb,UQ),e(UQ,yUo),e(Rb,xUo),e(ro,$Uo),e(ro,Pb),e(Pb,kUo),e(Pb,d4e),e(d4e,SUo),e(Pb,RUo),e(Pb,c4e),e(c4e,PUo),e(ro,BUo),M(Bb,ro,null),v(f,KYe,_),v(f,yd,_),e(yd,Ib),e(Ib,f4e),M(ux,f4e,null),e(yd,IUo),e(yd,m4e),e(m4e,NUo),v(f,ZYe,_),v(f,qo,_),M(px,qo,null),e(qo,qUo),e(qo,xd),e(xd,jUo),e(xd,HQ),e(HQ,DUo),e(xd,GUo),e(xd,JQ),e(JQ,OUo),e(xd,VUo),e(qo,XUo),e(qo,_x),e(_x,zUo),e(_x,g4e),e(g4e,QUo),e(_x,WUo),e(qo,UUo),e(qo,Tt),M(vx,Tt,null),e(Tt,HUo),e(Tt,h4e),e(h4e,JUo),e(Tt,YUo),e(Tt,$d),e($d,KUo),e($d,u4e),e(u4e,ZUo),e($d,eHo),e($d,YQ),e(YQ,oHo),e($d,rHo),e(Tt,tHo),M(Nb,Tt,null),e(qo,aHo),e(qo,to),M(bx,to,null),e(to,nHo),e(to,p4e),e(p4e,sHo),e(to,lHo),e(to,en),e(en,iHo),e(en,_4e),e(_4e,dHo),e(en,cHo),e(en,v4e),e(v4e,fHo),e(en,mHo),e(en,b4e),e(b4e,gHo),e(en,hHo),e(to,uHo),e(to,fe),e(fe,qb),e(qb,F4e),e(F4e,pHo),e(qb,_Ho),e(qb,KQ),e(KQ,vHo),e(qb,bHo),e(fe,FHo),e(fe,jb),e(jb,T4e),e(T4e,THo),e(jb,MHo),e(jb,ZQ),e(ZQ,EHo),e(jb,CHo),e(fe,wHo),e(fe,Db),e(Db,M4e),e(M4e,AHo),e(Db,LHo),e(Db,eW),e(eW,yHo),e(Db,xHo),e(fe,$Ho),e(fe,Gb),e(Gb,E4e),e(E4e,kHo),e(Gb,SHo),e(Gb,oW),e(oW,RHo),e(Gb,PHo),e(fe,BHo),e(fe,Ob),e(Ob,C4e),e(C4e,IHo),e(Ob,NHo),e(Ob,rW),e(rW,qHo),e(Ob,jHo),e(fe,DHo),e(fe,Vb),e(Vb,w4e),e(w4e,GHo),e(Vb,OHo),e(Vb,tW),e(tW,VHo),e(Vb,XHo),e(fe,zHo),e(fe,Xb),e(Xb,A4e),e(A4e,QHo),e(Xb,WHo),e(Xb,aW),e(aW,UHo),e(Xb,HHo),e(fe,JHo),e(fe,zb),e(zb,L4e),e(L4e,YHo),e(zb,KHo),e(zb,nW),e(nW,ZHo),e(zb,eJo),e(fe,oJo),e(fe,Qb),e(Qb,y4e),e(y4e,rJo),e(Qb,tJo),e(Qb,sW),e(sW,aJo),e(Qb,nJo),e(fe,sJo),e(fe,Wb),e(Wb,x4e),e(x4e,lJo),e(Wb,iJo),e(Wb,lW),e(lW,dJo),e(Wb,cJo),e(fe,fJo),e(fe,Ub),e(Ub,$4e),e($4e,mJo),e(Ub,gJo),e(Ub,iW),e(iW,hJo),e(Ub,uJo),e(fe,pJo),e(fe,Hb),e(Hb,k4e),e(k4e,_Jo),e(Hb,vJo),e(Hb,dW),e(dW,bJo),e(Hb,FJo),e(fe,TJo),e(fe,Jb),e(Jb,S4e),e(S4e,MJo),e(Jb,EJo),e(Jb,cW),e(cW,CJo),e(Jb,wJo),e(fe,AJo),e(fe,Yb),e(Yb,R4e),e(R4e,LJo),e(Yb,yJo),e(Yb,fW),e(fW,xJo),e(Yb,$Jo),e(fe,kJo),e(fe,Kb),e(Kb,P4e),e(P4e,SJo),e(Kb,RJo),e(Kb,mW),e(mW,PJo),e(Kb,BJo),e(fe,IJo),e(fe,Zb),e(Zb,B4e),e(B4e,NJo),e(Zb,qJo),e(Zb,gW),e(gW,jJo),e(Zb,DJo),e(fe,GJo),e(fe,e1),e(e1,I4e),e(I4e,OJo),e(e1,VJo),e(e1,hW),e(hW,XJo),e(e1,zJo),e(fe,QJo),e(fe,o1),e(o1,N4e),e(N4e,WJo),e(o1,UJo),e(o1,uW),e(uW,HJo),e(o1,JJo),e(fe,YJo),e(fe,r1),e(r1,q4e),e(q4e,KJo),e(r1,ZJo),e(r1,pW),e(pW,eYo),e(r1,oYo),e(fe,rYo),e(fe,t1),e(t1,j4e),e(j4e,tYo),e(t1,aYo),e(t1,_W),e(_W,nYo),e(t1,sYo),e(to,lYo),e(to,a1),e(a1,iYo),e(a1,D4e),e(D4e,dYo),e(a1,cYo),e(a1,G4e),e(G4e,fYo),e(to,mYo),M(n1,to,null),v(f,eKe,_),v(f,kd,_),e(kd,s1),e(s1,O4e),M(Fx,O4e,null),e(kd,gYo),e(kd,V4e),e(V4e,hYo),v(f,oKe,_),v(f,jo,_),M(Tx,jo,null),e(jo,uYo),e(jo,Sd),e(Sd,pYo),e(Sd,vW),e(vW,_Yo),e(Sd,vYo),e(Sd,bW),e(bW,bYo),e(Sd,FYo),e(jo,TYo),e(jo,Mx),e(Mx,MYo),e(Mx,X4e),e(X4e,EYo),e(Mx,CYo),e(jo,wYo),e(jo,Mt),M(Ex,Mt,null),e(Mt,AYo),e(Mt,z4e),e(z4e,LYo),e(Mt,yYo),e(Mt,Rd),e(Rd,xYo),e(Rd,Q4e),e(Q4e,$Yo),e(Rd,kYo),e(Rd,FW),e(FW,SYo),e(Rd,RYo),e(Mt,PYo),M(l1,Mt,null),e(jo,BYo),e(jo,ao),M(Cx,ao,null),e(ao,IYo),e(ao,W4e),e(W4e,NYo),e(ao,qYo),e(ao,on),e(on,jYo),e(on,U4e),e(U4e,DYo),e(on,GYo),e(on,H4e),e(H4e,OYo),e(on,VYo),e(on,J4e),e(J4e,XYo),e(on,zYo),e(ao,QYo),e(ao,q),e(q,i1),e(i1,Y4e),e(Y4e,WYo),e(i1,UYo),e(i1,TW),e(TW,HYo),e(i1,JYo),e(q,YYo),e(q,d1),e(d1,K4e),e(K4e,KYo),e(d1,ZYo),e(d1,MW),e(MW,eKo),e(d1,oKo),e(q,rKo),e(q,c1),e(c1,Z4e),e(Z4e,tKo),e(c1,aKo),e(c1,EW),e(EW,nKo),e(c1,sKo),e(q,lKo),e(q,f1),e(f1,ebe),e(ebe,iKo),e(f1,dKo),e(f1,CW),e(CW,cKo),e(f1,fKo),e(q,mKo),e(q,m1),e(m1,obe),e(obe,gKo),e(m1,hKo),e(m1,wW),e(wW,uKo),e(m1,pKo),e(q,_Ko),e(q,g1),e(g1,rbe),e(rbe,vKo),e(g1,bKo),e(g1,AW),e(AW,FKo),e(g1,TKo),e(q,MKo),e(q,h1),e(h1,tbe),e(tbe,EKo),e(h1,CKo),e(h1,LW),e(LW,wKo),e(h1,AKo),e(q,LKo),e(q,u1),e(u1,abe),e(abe,yKo),e(u1,xKo),e(u1,yW),e(yW,$Ko),e(u1,kKo),e(q,SKo),e(q,p1),e(p1,nbe),e(nbe,RKo),e(p1,PKo),e(p1,xW),e(xW,BKo),e(p1,IKo),e(q,NKo),e(q,_1),e(_1,sbe),e(sbe,qKo),e(_1,jKo),e(_1,$W),e($W,DKo),e(_1,GKo),e(q,OKo),e(q,v1),e(v1,lbe),e(lbe,VKo),e(v1,XKo),e(v1,kW),e(kW,zKo),e(v1,QKo),e(q,WKo),e(q,b1),e(b1,ibe),e(ibe,UKo),e(b1,HKo),e(b1,SW),e(SW,JKo),e(b1,YKo),e(q,KKo),e(q,F1),e(F1,dbe),e(dbe,ZKo),e(F1,eZo),e(F1,RW),e(RW,oZo),e(F1,rZo),e(q,tZo),e(q,T1),e(T1,cbe),e(cbe,aZo),e(T1,nZo),e(T1,PW),e(PW,sZo),e(T1,lZo),e(q,iZo),e(q,M1),e(M1,fbe),e(fbe,dZo),e(M1,cZo),e(M1,BW),e(BW,fZo),e(M1,mZo),e(q,gZo),e(q,E1),e(E1,mbe),e(mbe,hZo),e(E1,uZo),e(E1,IW),e(IW,pZo),e(E1,_Zo),e(q,vZo),e(q,C1),e(C1,gbe),e(gbe,bZo),e(C1,FZo),e(C1,NW),e(NW,TZo),e(C1,MZo),e(q,EZo),e(q,w1),e(w1,hbe),e(hbe,CZo),e(w1,wZo),e(w1,qW),e(qW,AZo),e(w1,LZo),e(q,yZo),e(q,A1),e(A1,ube),e(ube,xZo),e(A1,$Zo),e(A1,jW),e(jW,kZo),e(A1,SZo),e(q,RZo),e(q,L1),e(L1,pbe),e(pbe,PZo),e(L1,BZo),e(L1,DW),e(DW,IZo),e(L1,NZo),e(q,qZo),e(q,y1),e(y1,_be),e(_be,jZo),e(y1,DZo),e(y1,GW),e(GW,GZo),e(y1,OZo),e(q,VZo),e(q,x1),e(x1,vbe),e(vbe,XZo),e(x1,zZo),e(x1,OW),e(OW,QZo),e(x1,WZo),e(q,UZo),e(q,$1),e($1,bbe),e(bbe,HZo),e($1,JZo),e($1,VW),e(VW,YZo),e($1,KZo),e(q,ZZo),e(q,k1),e(k1,Fbe),e(Fbe,eer),e(k1,oer),e(k1,XW),e(XW,rer),e(k1,ter),e(q,aer),e(q,S1),e(S1,Tbe),e(Tbe,ner),e(S1,ser),e(S1,zW),e(zW,ler),e(S1,ier),e(q,der),e(q,R1),e(R1,Mbe),e(Mbe,cer),e(R1,fer),e(R1,QW),e(QW,mer),e(R1,ger),e(q,her),e(q,P1),e(P1,Ebe),e(Ebe,uer),e(P1,per),e(P1,WW),e(WW,_er),e(P1,ver),e(q,ber),e(q,B1),e(B1,Cbe),e(Cbe,Fer),e(B1,Ter),e(B1,UW),e(UW,Mer),e(B1,Eer),e(q,Cer),e(q,I1),e(I1,wbe),e(wbe,wer),e(I1,Aer),e(I1,HW),e(HW,Ler),e(I1,yer),e(q,xer),e(q,N1),e(N1,Abe),e(Abe,$er),e(N1,ker),e(N1,JW),e(JW,Ser),e(N1,Rer),e(q,Per),e(q,q1),e(q1,Lbe),e(Lbe,Ber),e(q1,Ier),e(q1,YW),e(YW,Ner),e(q1,qer),e(q,jer),e(q,j1),e(j1,ybe),e(ybe,Der),e(j1,Ger),e(j1,KW),e(KW,Oer),e(j1,Ver),e(q,Xer),e(q,D1),e(D1,xbe),e(xbe,zer),e(D1,Qer),e(D1,ZW),e(ZW,Wer),e(D1,Uer),e(q,Her),e(q,G1),e(G1,$be),e($be,Jer),e(G1,Yer),e(G1,eU),e(eU,Ker),e(G1,Zer),e(q,eor),e(q,O1),e(O1,kbe),e(kbe,oor),e(O1,ror),e(O1,oU),e(oU,tor),e(O1,aor),e(q,nor),e(q,V1),e(V1,Sbe),e(Sbe,sor),e(V1,lor),e(V1,rU),e(rU,ior),e(V1,dor),e(q,cor),e(q,X1),e(X1,Rbe),e(Rbe,mor),e(X1,gor),e(X1,tU),e(tU,hor),e(X1,uor),e(q,por),e(q,z1),e(z1,Pbe),e(Pbe,_or),e(z1,vor),e(z1,aU),e(aU,bor),e(z1,For),e(q,Tor),e(q,Q1),e(Q1,Bbe),e(Bbe,Mor),e(Q1,Eor),e(Q1,nU),e(nU,Cor),e(Q1,wor),e(q,Aor),e(q,W1),e(W1,Ibe),e(Ibe,Lor),e(W1,yor),e(W1,sU),e(sU,xor),e(W1,$or),e(q,kor),e(q,U1),e(U1,Nbe),e(Nbe,Sor),e(U1,Ror),e(U1,lU),e(lU,Por),e(U1,Bor),e(q,Ior),e(q,H1),e(H1,qbe),e(qbe,Nor),e(H1,qor),e(H1,iU),e(iU,jor),e(H1,Dor),e(q,Gor),e(q,J1),e(J1,jbe),e(jbe,Oor),e(J1,Vor),e(J1,dU),e(dU,Xor),e(J1,zor),e(q,Qor),e(q,Y1),e(Y1,Dbe),e(Dbe,Wor),e(Y1,Uor),e(Y1,cU),e(cU,Hor),e(Y1,Jor),e(q,Yor),e(q,K1),e(K1,Gbe),e(Gbe,Kor),e(K1,Zor),e(K1,fU),e(fU,err),e(K1,orr),e(q,rrr),e(q,Z1),e(Z1,Obe),e(Obe,trr),e(Z1,arr),e(Z1,mU),e(mU,nrr),e(Z1,srr),e(q,lrr),e(q,e0),e(e0,Vbe),e(Vbe,irr),e(e0,drr),e(e0,gU),e(gU,crr),e(e0,frr),e(q,mrr),e(q,o0),e(o0,Xbe),e(Xbe,grr),e(o0,hrr),e(o0,hU),e(hU,urr),e(o0,prr),e(q,_rr),e(q,r0),e(r0,zbe),e(zbe,vrr),e(r0,brr),e(r0,uU),e(uU,Frr),e(r0,Trr),e(q,Mrr),e(q,t0),e(t0,Qbe),e(Qbe,Err),e(t0,Crr),e(t0,pU),e(pU,wrr),e(t0,Arr),e(q,Lrr),e(q,a0),e(a0,Wbe),e(Wbe,yrr),e(a0,xrr),e(a0,_U),e(_U,$rr),e(a0,krr),e(q,Srr),e(q,n0),e(n0,Ube),e(Ube,Rrr),e(n0,Prr),e(n0,vU),e(vU,Brr),e(n0,Irr),e(q,Nrr),e(q,s0),e(s0,Hbe),e(Hbe,qrr),e(s0,jrr),e(s0,bU),e(bU,Drr),e(s0,Grr),e(ao,Orr),e(ao,l0),e(l0,Vrr),e(l0,Jbe),e(Jbe,Xrr),e(l0,zrr),e(l0,Ybe),e(Ybe,Qrr),e(ao,Wrr),M(i0,ao,null),v(f,rKe,_),v(f,Pd,_),e(Pd,d0),e(d0,Kbe),M(wx,Kbe,null),e(Pd,Urr),e(Pd,Zbe),e(Zbe,Hrr),v(f,tKe,_),v(f,Do,_),M(Ax,Do,null),e(Do,Jrr),e(Do,Bd),e(Bd,Yrr),e(Bd,FU),e(FU,Krr),e(Bd,Zrr),e(Bd,TU),e(TU,etr),e(Bd,otr),e(Do,rtr),e(Do,Lx),e(Lx,ttr),e(Lx,e1e),e(e1e,atr),e(Lx,ntr),e(Do,str),e(Do,Et),M(yx,Et,null),e(Et,ltr),e(Et,o1e),e(o1e,itr),e(Et,dtr),e(Et,Id),e(Id,ctr),e(Id,r1e),e(r1e,ftr),e(Id,mtr),e(Id,MU),e(MU,gtr),e(Id,htr),e(Et,utr),M(c0,Et,null),e(Do,ptr),e(Do,no),M(xx,no,null),e(no,_tr),e(no,t1e),e(t1e,vtr),e(no,btr),e(no,rn),e(rn,Ftr),e(rn,a1e),e(a1e,Ttr),e(rn,Mtr),e(rn,n1e),e(n1e,Etr),e(rn,Ctr),e(rn,s1e),e(s1e,wtr),e(rn,Atr),e(no,Ltr),e(no,Z),e(Z,f0),e(f0,l1e),e(l1e,ytr),e(f0,xtr),e(f0,EU),e(EU,$tr),e(f0,ktr),e(Z,Str),e(Z,m0),e(m0,i1e),e(i1e,Rtr),e(m0,Ptr),e(m0,CU),e(CU,Btr),e(m0,Itr),e(Z,Ntr),e(Z,g0),e(g0,d1e),e(d1e,qtr),e(g0,jtr),e(g0,wU),e(wU,Dtr),e(g0,Gtr),e(Z,Otr),e(Z,h0),e(h0,c1e),e(c1e,Vtr),e(h0,Xtr),e(h0,AU),e(AU,ztr),e(h0,Qtr),e(Z,Wtr),e(Z,u0),e(u0,f1e),e(f1e,Utr),e(u0,Htr),e(u0,LU),e(LU,Jtr),e(u0,Ytr),e(Z,Ktr),e(Z,p0),e(p0,m1e),e(m1e,Ztr),e(p0,ear),e(p0,yU),e(yU,oar),e(p0,rar),e(Z,tar),e(Z,_0),e(_0,g1e),e(g1e,aar),e(_0,nar),e(_0,xU),e(xU,sar),e(_0,lar),e(Z,iar),e(Z,v0),e(v0,h1e),e(h1e,dar),e(v0,car),e(v0,$U),e($U,far),e(v0,mar),e(Z,gar),e(Z,b0),e(b0,u1e),e(u1e,har),e(b0,uar),e(b0,kU),e(kU,par),e(b0,_ar),e(Z,bar),e(Z,F0),e(F0,p1e),e(p1e,Far),e(F0,Tar),e(F0,SU),e(SU,Mar),e(F0,Ear),e(Z,Car),e(Z,T0),e(T0,_1e),e(_1e,war),e(T0,Aar),e(T0,RU),e(RU,Lar),e(T0,yar),e(Z,xar),e(Z,M0),e(M0,v1e),e(v1e,$ar),e(M0,kar),e(M0,PU),e(PU,Sar),e(M0,Rar),e(Z,Par),e(Z,E0),e(E0,b1e),e(b1e,Bar),e(E0,Iar),e(E0,BU),e(BU,Nar),e(E0,qar),e(Z,jar),e(Z,C0),e(C0,F1e),e(F1e,Dar),e(C0,Gar),e(C0,IU),e(IU,Oar),e(C0,Var),e(Z,Xar),e(Z,w0),e(w0,T1e),e(T1e,zar),e(w0,Qar),e(w0,NU),e(NU,War),e(w0,Uar),e(Z,Har),e(Z,A0),e(A0,M1e),e(M1e,Jar),e(A0,Yar),e(A0,qU),e(qU,Kar),e(A0,Zar),e(Z,enr),e(Z,L0),e(L0,E1e),e(E1e,onr),e(L0,rnr),e(L0,jU),e(jU,tnr),e(L0,anr),e(Z,nnr),e(Z,y0),e(y0,C1e),e(C1e,snr),e(y0,lnr),e(y0,DU),e(DU,inr),e(y0,dnr),e(Z,cnr),e(Z,x0),e(x0,w1e),e(w1e,fnr),e(x0,mnr),e(x0,GU),e(GU,gnr),e(x0,hnr),e(Z,unr),e(Z,$0),e($0,A1e),e(A1e,pnr),e($0,_nr),e($0,OU),e(OU,vnr),e($0,bnr),e(Z,Fnr),e(Z,k0),e(k0,L1e),e(L1e,Tnr),e(k0,Mnr),e(k0,VU),e(VU,Enr),e(k0,Cnr),e(Z,wnr),e(Z,S0),e(S0,y1e),e(y1e,Anr),e(S0,Lnr),e(S0,XU),e(XU,ynr),e(S0,xnr),e(Z,$nr),e(Z,R0),e(R0,x1e),e(x1e,knr),e(R0,Snr),e(R0,zU),e(zU,Rnr),e(R0,Pnr),e(Z,Bnr),e(Z,P0),e(P0,$1e),e($1e,Inr),e(P0,Nnr),e(P0,QU),e(QU,qnr),e(P0,jnr),e(Z,Dnr),e(Z,B0),e(B0,k1e),e(k1e,Gnr),e(B0,Onr),e(B0,WU),e(WU,Vnr),e(B0,Xnr),e(Z,znr),e(Z,I0),e(I0,S1e),e(S1e,Qnr),e(I0,Wnr),e(I0,UU),e(UU,Unr),e(I0,Hnr),e(Z,Jnr),e(Z,N0),e(N0,R1e),e(R1e,Ynr),e(N0,Knr),e(N0,HU),e(HU,Znr),e(N0,esr),e(Z,osr),e(Z,q0),e(q0,P1e),e(P1e,rsr),e(q0,tsr),e(q0,JU),e(JU,asr),e(q0,nsr),e(Z,ssr),e(Z,j0),e(j0,B1e),e(B1e,lsr),e(j0,isr),e(j0,YU),e(YU,dsr),e(j0,csr),e(Z,fsr),e(Z,D0),e(D0,I1e),e(I1e,msr),e(D0,gsr),e(D0,KU),e(KU,hsr),e(D0,usr),e(Z,psr),e(Z,G0),e(G0,N1e),e(N1e,_sr),e(G0,vsr),e(G0,ZU),e(ZU,bsr),e(G0,Fsr),e(Z,Tsr),e(Z,O0),e(O0,q1e),e(q1e,Msr),e(O0,Esr),e(O0,eH),e(eH,Csr),e(O0,wsr),e(no,Asr),e(no,V0),e(V0,Lsr),e(V0,j1e),e(j1e,ysr),e(V0,xsr),e(V0,D1e),e(D1e,$sr),e(no,ksr),M(X0,no,null),v(f,aKe,_),v(f,Nd,_),e(Nd,z0),e(z0,G1e),M($x,G1e,null),e(Nd,Ssr),e(Nd,O1e),e(O1e,Rsr),v(f,nKe,_),v(f,Go,_),M(kx,Go,null),e(Go,Psr),e(Go,qd),e(qd,Bsr),e(qd,oH),e(oH,Isr),e(qd,Nsr),e(qd,rH),e(rH,qsr),e(qd,jsr),e(Go,Dsr),e(Go,Sx),e(Sx,Gsr),e(Sx,V1e),e(V1e,Osr),e(Sx,Vsr),e(Go,Xsr),e(Go,Ct),M(Rx,Ct,null),e(Ct,zsr),e(Ct,X1e),e(X1e,Qsr),e(Ct,Wsr),e(Ct,jd),e(jd,Usr),e(jd,z1e),e(z1e,Hsr),e(jd,Jsr),e(jd,tH),e(tH,Ysr),e(jd,Ksr),e(Ct,Zsr),M(Q0,Ct,null),e(Go,elr),e(Go,so),M(Px,so,null),e(so,olr),e(so,Q1e),e(Q1e,rlr),e(so,tlr),e(so,tn),e(tn,alr),e(tn,W1e),e(W1e,nlr),e(tn,slr),e(tn,U1e),e(U1e,llr),e(tn,ilr),e(tn,H1e),e(H1e,dlr),e(tn,clr),e(so,flr),e(so,Ue),e(Ue,W0),e(W0,J1e),e(J1e,mlr),e(W0,glr),e(W0,aH),e(aH,hlr),e(W0,ulr),e(Ue,plr),e(Ue,U0),e(U0,Y1e),e(Y1e,_lr),e(U0,vlr),e(U0,nH),e(nH,blr),e(U0,Flr),e(Ue,Tlr),e(Ue,H0),e(H0,K1e),e(K1e,Mlr),e(H0,Elr),e(H0,sH),e(sH,Clr),e(H0,wlr),e(Ue,Alr),e(Ue,J0),e(J0,Z1e),e(Z1e,Llr),e(J0,ylr),e(J0,lH),e(lH,xlr),e(J0,$lr),e(Ue,klr),e(Ue,Y0),e(Y0,e0e),e(e0e,Slr),e(Y0,Rlr),e(Y0,iH),e(iH,Plr),e(Y0,Blr),e(Ue,Ilr),e(Ue,K0),e(K0,o0e),e(o0e,Nlr),e(K0,qlr),e(K0,dH),e(dH,jlr),e(K0,Dlr),e(Ue,Glr),e(Ue,Z0),e(Z0,r0e),e(r0e,Olr),e(Z0,Vlr),e(Z0,cH),e(cH,Xlr),e(Z0,zlr),e(so,Qlr),e(so,eF),e(eF,Wlr),e(eF,t0e),e(t0e,Ulr),e(eF,Hlr),e(eF,a0e),e(a0e,Jlr),e(so,Ylr),M(oF,so,null),v(f,sKe,_),v(f,Dd,_),e(Dd,rF),e(rF,n0e),M(Bx,n0e,null),e(Dd,Klr),e(Dd,s0e),e(s0e,Zlr),v(f,lKe,_),v(f,Oo,_),M(Ix,Oo,null),e(Oo,eir),e(Oo,Gd),e(Gd,oir),e(Gd,fH),e(fH,rir),e(Gd,tir),e(Gd,mH),e(mH,air),e(Gd,nir),e(Oo,sir),e(Oo,Nx),e(Nx,lir),e(Nx,l0e),e(l0e,iir),e(Nx,dir),e(Oo,cir),e(Oo,wt),M(qx,wt,null),e(wt,fir),e(wt,i0e),e(i0e,mir),e(wt,gir),e(wt,Od),e(Od,hir),e(Od,d0e),e(d0e,uir),e(Od,pir),e(Od,gH),e(gH,_ir),e(Od,vir),e(wt,bir),M(tF,wt,null),e(Oo,Fir),e(Oo,lo),M(jx,lo,null),e(lo,Tir),e(lo,c0e),e(c0e,Mir),e(lo,Eir),e(lo,an),e(an,Cir),e(an,f0e),e(f0e,wir),e(an,Air),e(an,m0e),e(m0e,Lir),e(an,yir),e(an,g0e),e(g0e,xir),e(an,$ir),e(lo,kir),e(lo,H),e(H,aF),e(aF,h0e),e(h0e,Sir),e(aF,Rir),e(aF,hH),e(hH,Pir),e(aF,Bir),e(H,Iir),e(H,nF),e(nF,u0e),e(u0e,Nir),e(nF,qir),e(nF,uH),e(uH,jir),e(nF,Dir),e(H,Gir),e(H,sF),e(sF,p0e),e(p0e,Oir),e(sF,Vir),e(sF,pH),e(pH,Xir),e(sF,zir),e(H,Qir),e(H,lF),e(lF,_0e),e(_0e,Wir),e(lF,Uir),e(lF,_H),e(_H,Hir),e(lF,Jir),e(H,Yir),e(H,iF),e(iF,v0e),e(v0e,Kir),e(iF,Zir),e(iF,vH),e(vH,edr),e(iF,odr),e(H,rdr),e(H,dF),e(dF,b0e),e(b0e,tdr),e(dF,adr),e(dF,bH),e(bH,ndr),e(dF,sdr),e(H,ldr),e(H,cF),e(cF,F0e),e(F0e,idr),e(cF,ddr),e(cF,FH),e(FH,cdr),e(cF,fdr),e(H,mdr),e(H,fF),e(fF,T0e),e(T0e,gdr),e(fF,hdr),e(fF,TH),e(TH,udr),e(fF,pdr),e(H,_dr),e(H,mF),e(mF,M0e),e(M0e,vdr),e(mF,bdr),e(mF,MH),e(MH,Fdr),e(mF,Tdr),e(H,Mdr),e(H,gF),e(gF,E0e),e(E0e,Edr),e(gF,Cdr),e(gF,EH),e(EH,wdr),e(gF,Adr),e(H,Ldr),e(H,hF),e(hF,C0e),e(C0e,ydr),e(hF,xdr),e(hF,CH),e(CH,$dr),e(hF,kdr),e(H,Sdr),e(H,uF),e(uF,w0e),e(w0e,Rdr),e(uF,Pdr),e(uF,wH),e(wH,Bdr),e(uF,Idr),e(H,Ndr),e(H,pF),e(pF,A0e),e(A0e,qdr),e(pF,jdr),e(pF,AH),e(AH,Ddr),e(pF,Gdr),e(H,Odr),e(H,_F),e(_F,L0e),e(L0e,Vdr),e(_F,Xdr),e(_F,LH),e(LH,zdr),e(_F,Qdr),e(H,Wdr),e(H,vF),e(vF,y0e),e(y0e,Udr),e(vF,Hdr),e(vF,yH),e(yH,Jdr),e(vF,Ydr),e(H,Kdr),e(H,bF),e(bF,x0e),e(x0e,Zdr),e(bF,ecr),e(bF,xH),e(xH,ocr),e(bF,rcr),e(H,tcr),e(H,FF),e(FF,$0e),e($0e,acr),e(FF,ncr),e(FF,$H),e($H,scr),e(FF,lcr),e(H,icr),e(H,TF),e(TF,k0e),e(k0e,dcr),e(TF,ccr),e(TF,kH),e(kH,fcr),e(TF,mcr),e(H,gcr),e(H,MF),e(MF,S0e),e(S0e,hcr),e(MF,ucr),e(MF,SH),e(SH,pcr),e(MF,_cr),e(H,vcr),e(H,EF),e(EF,R0e),e(R0e,bcr),e(EF,Fcr),e(EF,RH),e(RH,Tcr),e(EF,Mcr),e(H,Ecr),e(H,CF),e(CF,P0e),e(P0e,Ccr),e(CF,wcr),e(CF,PH),e(PH,Acr),e(CF,Lcr),e(H,ycr),e(H,wF),e(wF,B0e),e(B0e,xcr),e(wF,$cr),e(wF,BH),e(BH,kcr),e(wF,Scr),e(H,Rcr),e(H,AF),e(AF,I0e),e(I0e,Pcr),e(AF,Bcr),e(AF,IH),e(IH,Icr),e(AF,Ncr),e(H,qcr),e(H,LF),e(LF,N0e),e(N0e,jcr),e(LF,Dcr),e(LF,NH),e(NH,Gcr),e(LF,Ocr),e(H,Vcr),e(H,yF),e(yF,q0e),e(q0e,Xcr),e(yF,zcr),e(yF,qH),e(qH,Qcr),e(yF,Wcr),e(H,Ucr),e(H,xF),e(xF,j0e),e(j0e,Hcr),e(xF,Jcr),e(xF,jH),e(jH,Ycr),e(xF,Kcr),e(H,Zcr),e(H,$F),e($F,D0e),e(D0e,efr),e($F,ofr),e($F,DH),e(DH,rfr),e($F,tfr),e(H,afr),e(H,kF),e(kF,G0e),e(G0e,nfr),e(kF,sfr),e(kF,GH),e(GH,lfr),e(kF,ifr),e(H,dfr),e(H,SF),e(SF,O0e),e(O0e,cfr),e(SF,ffr),e(SF,OH),e(OH,mfr),e(SF,gfr),e(H,hfr),e(H,RF),e(RF,V0e),e(V0e,ufr),e(RF,pfr),e(RF,VH),e(VH,_fr),e(RF,vfr),e(H,bfr),e(H,PF),e(PF,X0e),e(X0e,Ffr),e(PF,Tfr),e(PF,XH),e(XH,Mfr),e(PF,Efr),e(H,Cfr),e(H,BF),e(BF,z0e),e(z0e,wfr),e(BF,Afr),e(BF,zH),e(zH,Lfr),e(BF,yfr),e(H,xfr),e(H,IF),e(IF,Q0e),e(Q0e,$fr),e(IF,kfr),e(IF,QH),e(QH,Sfr),e(IF,Rfr),e(H,Pfr),e(H,NF),e(NF,W0e),e(W0e,Bfr),e(NF,Ifr),e(NF,WH),e(WH,Nfr),e(NF,qfr),e(H,jfr),e(H,qF),e(qF,U0e),e(U0e,Dfr),e(qF,Gfr),e(qF,UH),e(UH,Ofr),e(qF,Vfr),e(H,Xfr),e(H,jF),e(jF,H0e),e(H0e,zfr),e(jF,Qfr),e(jF,HH),e(HH,Wfr),e(jF,Ufr),e(H,Hfr),e(H,DF),e(DF,J0e),e(J0e,Jfr),e(DF,Yfr),e(DF,JH),e(JH,Kfr),e(DF,Zfr),e(H,emr),e(H,GF),e(GF,Y0e),e(Y0e,omr),e(GF,rmr),e(GF,YH),e(YH,tmr),e(GF,amr),e(lo,nmr),e(lo,OF),e(OF,smr),e(OF,K0e),e(K0e,lmr),e(OF,imr),e(OF,Z0e),e(Z0e,dmr),e(lo,cmr),M(VF,lo,null),v(f,iKe,_),v(f,Vd,_),e(Vd,XF),e(XF,eFe),M(Dx,eFe,null),e(Vd,fmr),e(Vd,oFe),e(oFe,mmr),v(f,dKe,_),v(f,Vo,_),M(Gx,Vo,null),e(Vo,gmr),e(Vo,Xd),e(Xd,hmr),e(Xd,KH),e(KH,umr),e(Xd,pmr),e(Xd,ZH),e(ZH,_mr),e(Xd,vmr),e(Vo,bmr),e(Vo,Ox),e(Ox,Fmr),e(Ox,rFe),e(rFe,Tmr),e(Ox,Mmr),e(Vo,Emr),e(Vo,At),M(Vx,At,null),e(At,Cmr),e(At,tFe),e(tFe,wmr),e(At,Amr),e(At,zd),e(zd,Lmr),e(zd,aFe),e(aFe,ymr),e(zd,xmr),e(zd,eJ),e(eJ,$mr),e(zd,kmr),e(At,Smr),M(zF,At,null),e(Vo,Rmr),e(Vo,io),M(Xx,io,null),e(io,Pmr),e(io,nFe),e(nFe,Bmr),e(io,Imr),e(io,nn),e(nn,Nmr),e(nn,sFe),e(sFe,qmr),e(nn,jmr),e(nn,lFe),e(lFe,Dmr),e(nn,Gmr),e(nn,iFe),e(iFe,Omr),e(nn,Vmr),e(io,Xmr),e(io,V),e(V,QF),e(QF,dFe),e(dFe,zmr),e(QF,Qmr),e(QF,oJ),e(oJ,Wmr),e(QF,Umr),e(V,Hmr),e(V,WF),e(WF,cFe),e(cFe,Jmr),e(WF,Ymr),e(WF,rJ),e(rJ,Kmr),e(WF,Zmr),e(V,egr),e(V,UF),e(UF,fFe),e(fFe,ogr),e(UF,rgr),e(UF,tJ),e(tJ,tgr),e(UF,agr),e(V,ngr),e(V,HF),e(HF,mFe),e(mFe,sgr),e(HF,lgr),e(HF,aJ),e(aJ,igr),e(HF,dgr),e(V,cgr),e(V,JF),e(JF,gFe),e(gFe,fgr),e(JF,mgr),e(JF,nJ),e(nJ,ggr),e(JF,hgr),e(V,ugr),e(V,YF),e(YF,hFe),e(hFe,pgr),e(YF,_gr),e(YF,sJ),e(sJ,vgr),e(YF,bgr),e(V,Fgr),e(V,KF),e(KF,uFe),e(uFe,Tgr),e(KF,Mgr),e(KF,lJ),e(lJ,Egr),e(KF,Cgr),e(V,wgr),e(V,ZF),e(ZF,pFe),e(pFe,Agr),e(ZF,Lgr),e(ZF,iJ),e(iJ,ygr),e(ZF,xgr),e(V,$gr),e(V,eT),e(eT,_Fe),e(_Fe,kgr),e(eT,Sgr),e(eT,dJ),e(dJ,Rgr),e(eT,Pgr),e(V,Bgr),e(V,oT),e(oT,vFe),e(vFe,Igr),e(oT,Ngr),e(oT,cJ),e(cJ,qgr),e(oT,jgr),e(V,Dgr),e(V,rT),e(rT,bFe),e(bFe,Ggr),e(rT,Ogr),e(rT,fJ),e(fJ,Vgr),e(rT,Xgr),e(V,zgr),e(V,tT),e(tT,FFe),e(FFe,Qgr),e(tT,Wgr),e(tT,mJ),e(mJ,Ugr),e(tT,Hgr),e(V,Jgr),e(V,aT),e(aT,TFe),e(TFe,Ygr),e(aT,Kgr),e(aT,gJ),e(gJ,Zgr),e(aT,ehr),e(V,ohr),e(V,nT),e(nT,MFe),e(MFe,rhr),e(nT,thr),e(nT,hJ),e(hJ,ahr),e(nT,nhr),e(V,shr),e(V,sT),e(sT,EFe),e(EFe,lhr),e(sT,ihr),e(sT,uJ),e(uJ,dhr),e(sT,chr),e(V,fhr),e(V,lT),e(lT,CFe),e(CFe,mhr),e(lT,ghr),e(lT,pJ),e(pJ,hhr),e(lT,uhr),e(V,phr),e(V,iT),e(iT,wFe),e(wFe,_hr),e(iT,vhr),e(iT,_J),e(_J,bhr),e(iT,Fhr),e(V,Thr),e(V,dT),e(dT,AFe),e(AFe,Mhr),e(dT,Ehr),e(dT,vJ),e(vJ,Chr),e(dT,whr),e(V,Ahr),e(V,cT),e(cT,LFe),e(LFe,Lhr),e(cT,yhr),e(cT,bJ),e(bJ,xhr),e(cT,$hr),e(V,khr),e(V,fT),e(fT,yFe),e(yFe,Shr),e(fT,Rhr),e(fT,FJ),e(FJ,Phr),e(fT,Bhr),e(V,Ihr),e(V,mT),e(mT,xFe),e(xFe,Nhr),e(mT,qhr),e(mT,TJ),e(TJ,jhr),e(mT,Dhr),e(V,Ghr),e(V,gT),e(gT,$Fe),e($Fe,Ohr),e(gT,Vhr),e(gT,MJ),e(MJ,Xhr),e(gT,zhr),e(V,Qhr),e(V,hT),e(hT,kFe),e(kFe,Whr),e(hT,Uhr),e(hT,EJ),e(EJ,Hhr),e(hT,Jhr),e(V,Yhr),e(V,uT),e(uT,SFe),e(SFe,Khr),e(uT,Zhr),e(uT,CJ),e(CJ,eur),e(uT,our),e(V,rur),e(V,pT),e(pT,RFe),e(RFe,tur),e(pT,aur),e(pT,wJ),e(wJ,nur),e(pT,sur),e(V,lur),e(V,_T),e(_T,PFe),e(PFe,iur),e(_T,dur),e(_T,AJ),e(AJ,cur),e(_T,fur),e(V,mur),e(V,vT),e(vT,BFe),e(BFe,gur),e(vT,hur),e(vT,LJ),e(LJ,uur),e(vT,pur),e(V,_ur),e(V,bT),e(bT,IFe),e(IFe,vur),e(bT,bur),e(bT,yJ),e(yJ,Fur),e(bT,Tur),e(V,Mur),e(V,FT),e(FT,NFe),e(NFe,Eur),e(FT,Cur),e(FT,xJ),e(xJ,wur),e(FT,Aur),e(V,Lur),e(V,TT),e(TT,qFe),e(qFe,yur),e(TT,xur),e(TT,$J),e($J,$ur),e(TT,kur),e(V,Sur),e(V,MT),e(MT,jFe),e(jFe,Rur),e(MT,Pur),e(MT,kJ),e(kJ,Bur),e(MT,Iur),e(V,Nur),e(V,ET),e(ET,DFe),e(DFe,qur),e(ET,jur),e(ET,SJ),e(SJ,Dur),e(ET,Gur),e(V,Our),e(V,CT),e(CT,GFe),e(GFe,Vur),e(CT,Xur),e(CT,RJ),e(RJ,zur),e(CT,Qur),e(V,Wur),e(V,wT),e(wT,OFe),e(OFe,Uur),e(wT,Hur),e(wT,PJ),e(PJ,Jur),e(wT,Yur),e(V,Kur),e(V,AT),e(AT,VFe),e(VFe,Zur),e(AT,epr),e(AT,BJ),e(BJ,opr),e(AT,rpr),e(V,tpr),e(V,LT),e(LT,XFe),e(XFe,apr),e(LT,npr),e(LT,IJ),e(IJ,spr),e(LT,lpr),e(V,ipr),e(V,yT),e(yT,zFe),e(zFe,dpr),e(yT,cpr),e(yT,NJ),e(NJ,fpr),e(yT,mpr),e(V,gpr),e(V,xT),e(xT,QFe),e(QFe,hpr),e(xT,upr),e(xT,qJ),e(qJ,ppr),e(xT,_pr),e(V,vpr),e(V,$T),e($T,WFe),e(WFe,bpr),e($T,Fpr),e($T,jJ),e(jJ,Tpr),e($T,Mpr),e(V,Epr),e(V,kT),e(kT,UFe),e(UFe,Cpr),e(kT,wpr),e(kT,DJ),e(DJ,Apr),e(kT,Lpr),e(V,ypr),e(V,ST),e(ST,HFe),e(HFe,xpr),e(ST,$pr),e(ST,GJ),e(GJ,kpr),e(ST,Spr),e(V,Rpr),e(V,RT),e(RT,JFe),e(JFe,Ppr),e(RT,Bpr),e(RT,OJ),e(OJ,Ipr),e(RT,Npr),e(V,qpr),e(V,PT),e(PT,YFe),e(YFe,jpr),e(PT,Dpr),e(PT,VJ),e(VJ,Gpr),e(PT,Opr),e(V,Vpr),e(V,BT),e(BT,KFe),e(KFe,Xpr),e(BT,zpr),e(BT,XJ),e(XJ,Qpr),e(BT,Wpr),e(io,Upr),e(io,IT),e(IT,Hpr),e(IT,ZFe),e(ZFe,Jpr),e(IT,Ypr),e(IT,eTe),e(eTe,Kpr),e(io,Zpr),M(NT,io,null),v(f,cKe,_),v(f,Qd,_),e(Qd,qT),e(qT,oTe),M(zx,oTe,null),e(Qd,e_r),e(Qd,rTe),e(rTe,o_r),v(f,fKe,_),v(f,Xo,_),M(Qx,Xo,null),e(Xo,r_r),e(Xo,Wd),e(Wd,t_r),e(Wd,zJ),e(zJ,a_r),e(Wd,n_r),e(Wd,QJ),e(QJ,s_r),e(Wd,l_r),e(Xo,i_r),e(Xo,Wx),e(Wx,d_r),e(Wx,tTe),e(tTe,c_r),e(Wx,f_r),e(Xo,m_r),e(Xo,Lt),M(Ux,Lt,null),e(Lt,g_r),e(Lt,aTe),e(aTe,h_r),e(Lt,u_r),e(Lt,Ud),e(Ud,p_r),e(Ud,nTe),e(nTe,__r),e(Ud,v_r),e(Ud,WJ),e(WJ,b_r),e(Ud,F_r),e(Lt,T_r),M(jT,Lt,null),e(Xo,M_r),e(Xo,co),M(Hx,co,null),e(co,E_r),e(co,sTe),e(sTe,C_r),e(co,w_r),e(co,sn),e(sn,A_r),e(sn,lTe),e(lTe,L_r),e(sn,y_r),e(sn,iTe),e(iTe,x_r),e(sn,$_r),e(sn,dTe),e(dTe,k_r),e(sn,S_r),e(co,R_r),e(co,cTe),e(cTe,DT),e(DT,fTe),e(fTe,P_r),e(DT,B_r),e(DT,UJ),e(UJ,I_r),e(DT,N_r),e(co,q_r),e(co,GT),e(GT,j_r),e(GT,mTe),e(mTe,D_r),e(GT,G_r),e(GT,gTe),e(gTe,O_r),e(co,V_r),M(OT,co,null),v(f,mKe,_),v(f,Hd,_),e(Hd,VT),e(VT,hTe),M(Jx,hTe,null),e(Hd,X_r),e(Hd,uTe),e(uTe,z_r),v(f,gKe,_),v(f,zo,_),M(Yx,zo,null),e(zo,Q_r),e(zo,Jd),e(Jd,W_r),e(Jd,HJ),e(HJ,U_r),e(Jd,H_r),e(Jd,JJ),e(JJ,J_r),e(Jd,Y_r),e(zo,K_r),e(zo,Kx),e(Kx,Z_r),e(Kx,pTe),e(pTe,e2r),e(Kx,o2r),e(zo,r2r),e(zo,yt),M(Zx,yt,null),e(yt,t2r),e(yt,_Te),e(_Te,a2r),e(yt,n2r),e(yt,Yd),e(Yd,s2r),e(Yd,vTe),e(vTe,l2r),e(Yd,i2r),e(Yd,YJ),e(YJ,d2r),e(Yd,c2r),e(yt,f2r),M(XT,yt,null),e(zo,m2r),e(zo,fo),M(e$,fo,null),e(fo,g2r),e(fo,bTe),e(bTe,h2r),e(fo,u2r),e(fo,ln),e(ln,p2r),e(ln,FTe),e(FTe,_2r),e(ln,v2r),e(ln,TTe),e(TTe,b2r),e(ln,F2r),e(ln,MTe),e(MTe,T2r),e(ln,M2r),e(fo,E2r),e(fo,Kd),e(Kd,zT),e(zT,ETe),e(ETe,C2r),e(zT,w2r),e(zT,KJ),e(KJ,A2r),e(zT,L2r),e(Kd,y2r),e(Kd,QT),e(QT,CTe),e(CTe,x2r),e(QT,$2r),e(QT,ZJ),e(ZJ,k2r),e(QT,S2r),e(Kd,R2r),e(Kd,WT),e(WT,wTe),e(wTe,P2r),e(WT,B2r),e(WT,eY),e(eY,I2r),e(WT,N2r),e(fo,q2r),e(fo,UT),e(UT,j2r),e(UT,ATe),e(ATe,D2r),e(UT,G2r),e(UT,LTe),e(LTe,O2r),e(fo,V2r),M(HT,fo,null),v(f,hKe,_),v(f,Zd,_),e(Zd,JT),e(JT,yTe),M(o$,yTe,null),e(Zd,X2r),e(Zd,xTe),e(xTe,z2r),v(f,uKe,_),v(f,Qo,_),M(r$,Qo,null),e(Qo,Q2r),e(Qo,ec),e(ec,W2r),e(ec,oY),e(oY,U2r),e(ec,H2r),e(ec,rY),e(rY,J2r),e(ec,Y2r),e(Qo,K2r),e(Qo,t$),e(t$,Z2r),e(t$,$Te),e($Te,evr),e(t$,ovr),e(Qo,rvr),e(Qo,xt),M(a$,xt,null),e(xt,tvr),e(xt,kTe),e(kTe,avr),e(xt,nvr),e(xt,oc),e(oc,svr),e(oc,STe),e(STe,lvr),e(oc,ivr),e(oc,tY),e(tY,dvr),e(oc,cvr),e(xt,fvr),M(YT,xt,null),e(Qo,mvr),e(Qo,mo),M(n$,mo,null),e(mo,gvr),e(mo,RTe),e(RTe,hvr),e(mo,uvr),e(mo,dn),e(dn,pvr),e(dn,PTe),e(PTe,_vr),e(dn,vvr),e(dn,BTe),e(BTe,bvr),e(dn,Fvr),e(dn,ITe),e(ITe,Tvr),e(dn,Mvr),e(mo,Evr),e(mo,ve),e(ve,KT),e(KT,NTe),e(NTe,Cvr),e(KT,wvr),e(KT,aY),e(aY,Avr),e(KT,Lvr),e(ve,yvr),e(ve,ZT),e(ZT,qTe),e(qTe,xvr),e(ZT,$vr),e(ZT,nY),e(nY,kvr),e(ZT,Svr),e(ve,Rvr),e(ve,eM),e(eM,jTe),e(jTe,Pvr),e(eM,Bvr),e(eM,sY),e(sY,Ivr),e(eM,Nvr),e(ve,qvr),e(ve,oM),e(oM,DTe),e(DTe,jvr),e(oM,Dvr),e(oM,lY),e(lY,Gvr),e(oM,Ovr),e(ve,Vvr),e(ve,_l),e(_l,GTe),e(GTe,Xvr),e(_l,zvr),e(_l,iY),e(iY,Qvr),e(_l,Wvr),e(_l,dY),e(dY,Uvr),e(_l,Hvr),e(ve,Jvr),e(ve,rM),e(rM,OTe),e(OTe,Yvr),e(rM,Kvr),e(rM,cY),e(cY,Zvr),e(rM,e4r),e(ve,o4r),e(ve,vl),e(vl,VTe),e(VTe,r4r),e(vl,t4r),e(vl,fY),e(fY,a4r),e(vl,n4r),e(vl,mY),e(mY,s4r),e(vl,l4r),e(ve,i4r),e(ve,tM),e(tM,XTe),e(XTe,d4r),e(tM,c4r),e(tM,gY),e(gY,f4r),e(tM,m4r),e(ve,g4r),e(ve,$t),e($t,zTe),e(zTe,h4r),e($t,u4r),e($t,hY),e(hY,p4r),e($t,_4r),e($t,uY),e(uY,v4r),e($t,b4r),e($t,pY),e(pY,F4r),e($t,T4r),e(ve,M4r),e(ve,aM),e(aM,QTe),e(QTe,E4r),e(aM,C4r),e(aM,_Y),e(_Y,w4r),e(aM,A4r),e(ve,L4r),e(ve,nM),e(nM,WTe),e(WTe,y4r),e(nM,x4r),e(nM,vY),e(vY,$4r),e(nM,k4r),e(ve,S4r),e(ve,sM),e(sM,UTe),e(UTe,R4r),e(sM,P4r),e(sM,bY),e(bY,B4r),e(sM,I4r),e(ve,N4r),e(ve,lM),e(lM,HTe),e(HTe,q4r),e(lM,j4r),e(lM,FY),e(FY,D4r),e(lM,G4r),e(ve,O4r),e(ve,iM),e(iM,JTe),e(JTe,V4r),e(iM,X4r),e(iM,TY),e(TY,z4r),e(iM,Q4r),e(ve,W4r),e(ve,dM),e(dM,YTe),e(YTe,U4r),e(dM,H4r),e(dM,MY),e(MY,J4r),e(dM,Y4r),e(ve,K4r),e(ve,cM),e(cM,KTe),e(KTe,Z4r),e(cM,ebr),e(cM,EY),e(EY,obr),e(cM,rbr),e(ve,tbr),e(ve,fM),e(fM,ZTe),e(ZTe,abr),e(fM,nbr),e(fM,CY),e(CY,sbr),e(fM,lbr),e(mo,ibr),e(mo,mM),e(mM,dbr),e(mM,eMe),e(eMe,cbr),e(mM,fbr),e(mM,oMe),e(oMe,mbr),e(mo,gbr),M(gM,mo,null),v(f,pKe,_),v(f,rc,_),e(rc,hM),e(hM,rMe),M(s$,rMe,null),e(rc,hbr),e(rc,tMe),e(tMe,ubr),v(f,_Ke,_),v(f,Wo,_),M(l$,Wo,null),e(Wo,pbr),e(Wo,tc),e(tc,_br),e(tc,wY),e(wY,vbr),e(tc,bbr),e(tc,AY),e(AY,Fbr),e(tc,Tbr),e(Wo,Mbr),e(Wo,i$),e(i$,Ebr),e(i$,aMe),e(aMe,Cbr),e(i$,wbr),e(Wo,Abr),e(Wo,kt),M(d$,kt,null),e(kt,Lbr),e(kt,nMe),e(nMe,ybr),e(kt,xbr),e(kt,ac),e(ac,$br),e(ac,sMe),e(sMe,kbr),e(ac,Sbr),e(ac,LY),e(LY,Rbr),e(ac,Pbr),e(kt,Bbr),M(uM,kt,null),e(Wo,Ibr),e(Wo,go),M(c$,go,null),e(go,Nbr),e(go,lMe),e(lMe,qbr),e(go,jbr),e(go,cn),e(cn,Dbr),e(cn,iMe),e(iMe,Gbr),e(cn,Obr),e(cn,dMe),e(dMe,Vbr),e(cn,Xbr),e(cn,cMe),e(cMe,zbr),e(cn,Qbr),e(go,Wbr),e(go,fMe),e(fMe,pM),e(pM,mMe),e(mMe,Ubr),e(pM,Hbr),e(pM,yY),e(yY,Jbr),e(pM,Ybr),e(go,Kbr),e(go,_M),e(_M,Zbr),e(_M,gMe),e(gMe,e1r),e(_M,o1r),e(_M,hMe),e(hMe,r1r),e(go,t1r),M(vM,go,null),v(f,vKe,_),v(f,nc,_),e(nc,bM),e(bM,uMe),M(f$,uMe,null),e(nc,a1r),e(nc,pMe),e(pMe,n1r),v(f,bKe,_),v(f,Uo,_),M(m$,Uo,null),e(Uo,s1r),e(Uo,sc),e(sc,l1r),e(sc,xY),e(xY,i1r),e(sc,d1r),e(sc,$Y),e($Y,c1r),e(sc,f1r),e(Uo,m1r),e(Uo,g$),e(g$,g1r),e(g$,_Me),e(_Me,h1r),e(g$,u1r),e(Uo,p1r),e(Uo,St),M(h$,St,null),e(St,_1r),e(St,vMe),e(vMe,v1r),e(St,b1r),e(St,lc),e(lc,F1r),e(lc,bMe),e(bMe,T1r),e(lc,M1r),e(lc,kY),e(kY,E1r),e(lc,C1r),e(St,w1r),M(FM,St,null),e(Uo,A1r),e(Uo,ho),M(u$,ho,null),e(ho,L1r),e(ho,FMe),e(FMe,y1r),e(ho,x1r),e(ho,fn),e(fn,$1r),e(fn,TMe),e(TMe,k1r),e(fn,S1r),e(fn,MMe),e(MMe,R1r),e(fn,P1r),e(fn,EMe),e(EMe,B1r),e(fn,I1r),e(ho,N1r),e(ho,CMe),e(CMe,TM),e(TM,wMe),e(wMe,q1r),e(TM,j1r),e(TM,SY),e(SY,D1r),e(TM,G1r),e(ho,O1r),e(ho,MM),e(MM,V1r),e(MM,AMe),e(AMe,X1r),e(MM,z1r),e(MM,LMe),e(LMe,Q1r),e(ho,W1r),M(EM,ho,null),v(f,FKe,_),v(f,ic,_),e(ic,CM),e(CM,yMe),M(p$,yMe,null),e(ic,U1r),e(ic,xMe),e(xMe,H1r),v(f,TKe,_),v(f,Ho,_),M(_$,Ho,null),e(Ho,J1r),e(Ho,dc),e(dc,Y1r),e(dc,RY),e(RY,K1r),e(dc,Z1r),e(dc,PY),e(PY,e0r),e(dc,o0r),e(Ho,r0r),e(Ho,v$),e(v$,t0r),e(v$,$Me),e($Me,a0r),e(v$,n0r),e(Ho,s0r),e(Ho,Rt),M(b$,Rt,null),e(Rt,l0r),e(Rt,kMe),e(kMe,i0r),e(Rt,d0r),e(Rt,cc),e(cc,c0r),e(cc,SMe),e(SMe,f0r),e(cc,m0r),e(cc,BY),e(BY,g0r),e(cc,h0r),e(Rt,u0r),M(wM,Rt,null),e(Ho,p0r),e(Ho,uo),M(F$,uo,null),e(uo,_0r),e(uo,RMe),e(RMe,v0r),e(uo,b0r),e(uo,mn),e(mn,F0r),e(mn,PMe),e(PMe,T0r),e(mn,M0r),e(mn,BMe),e(BMe,E0r),e(mn,C0r),e(mn,IMe),e(IMe,w0r),e(mn,A0r),e(uo,L0r),e(uo,NMe),e(NMe,AM),e(AM,qMe),e(qMe,y0r),e(AM,x0r),e(AM,IY),e(IY,$0r),e(AM,k0r),e(uo,S0r),e(uo,LM),e(LM,R0r),e(LM,jMe),e(jMe,P0r),e(LM,B0r),e(LM,DMe),e(DMe,I0r),e(uo,N0r),M(yM,uo,null),v(f,MKe,_),v(f,fc,_),e(fc,xM),e(xM,GMe),M(T$,GMe,null),e(fc,q0r),e(fc,OMe),e(OMe,j0r),v(f,EKe,_),v(f,Jo,_),M(M$,Jo,null),e(Jo,D0r),e(Jo,mc),e(mc,G0r),e(mc,NY),e(NY,O0r),e(mc,V0r),e(mc,qY),e(qY,X0r),e(mc,z0r),e(Jo,Q0r),e(Jo,E$),e(E$,W0r),e(E$,VMe),e(VMe,U0r),e(E$,H0r),e(Jo,J0r),e(Jo,Pt),M(C$,Pt,null),e(Pt,Y0r),e(Pt,XMe),e(XMe,K0r),e(Pt,Z0r),e(Pt,gc),e(gc,eFr),e(gc,zMe),e(zMe,oFr),e(gc,rFr),e(gc,jY),e(jY,tFr),e(gc,aFr),e(Pt,nFr),M($M,Pt,null),e(Jo,sFr),e(Jo,po),M(w$,po,null),e(po,lFr),e(po,QMe),e(QMe,iFr),e(po,dFr),e(po,gn),e(gn,cFr),e(gn,WMe),e(WMe,fFr),e(gn,mFr),e(gn,UMe),e(UMe,gFr),e(gn,hFr),e(gn,HMe),e(HMe,uFr),e(gn,pFr),e(po,_Fr),e(po,Pe),e(Pe,kM),e(kM,JMe),e(JMe,vFr),e(kM,bFr),e(kM,DY),e(DY,FFr),e(kM,TFr),e(Pe,MFr),e(Pe,SM),e(SM,YMe),e(YMe,EFr),e(SM,CFr),e(SM,GY),e(GY,wFr),e(SM,AFr),e(Pe,LFr),e(Pe,RM),e(RM,KMe),e(KMe,yFr),e(RM,xFr),e(RM,OY),e(OY,$Fr),e(RM,kFr),e(Pe,SFr),e(Pe,PM),e(PM,ZMe),e(ZMe,RFr),e(PM,PFr),e(PM,VY),e(VY,BFr),e(PM,IFr),e(Pe,NFr),e(Pe,BM),e(BM,eEe),e(eEe,qFr),e(BM,jFr),e(BM,XY),e(XY,DFr),e(BM,GFr),e(Pe,OFr),e(Pe,IM),e(IM,oEe),e(oEe,VFr),e(IM,XFr),e(IM,zY),e(zY,zFr),e(IM,QFr),e(Pe,WFr),e(Pe,NM),e(NM,rEe),e(rEe,UFr),e(NM,HFr),e(NM,QY),e(QY,JFr),e(NM,YFr),e(Pe,KFr),e(Pe,qM),e(qM,tEe),e(tEe,ZFr),e(qM,eTr),e(qM,WY),e(WY,oTr),e(qM,rTr),e(Pe,tTr),e(Pe,jM),e(jM,aEe),e(aEe,aTr),e(jM,nTr),e(jM,UY),e(UY,sTr),e(jM,lTr),e(po,iTr),e(po,DM),e(DM,dTr),e(DM,nEe),e(nEe,cTr),e(DM,fTr),e(DM,sEe),e(sEe,mTr),e(po,gTr),M(GM,po,null),v(f,CKe,_),v(f,hc,_),e(hc,OM),e(OM,lEe),M(A$,lEe,null),e(hc,hTr),e(hc,iEe),e(iEe,uTr),v(f,wKe,_),v(f,Yo,_),M(L$,Yo,null),e(Yo,pTr),e(Yo,uc),e(uc,_Tr),e(uc,HY),e(HY,vTr),e(uc,bTr),e(uc,JY),e(JY,FTr),e(uc,TTr),e(Yo,MTr),e(Yo,y$),e(y$,ETr),e(y$,dEe),e(dEe,CTr),e(y$,wTr),e(Yo,ATr),e(Yo,Bt),M(x$,Bt,null),e(Bt,LTr),e(Bt,cEe),e(cEe,yTr),e(Bt,xTr),e(Bt,pc),e(pc,$Tr),e(pc,fEe),e(fEe,kTr),e(pc,STr),e(pc,YY),e(YY,RTr),e(pc,PTr),e(Bt,BTr),M(VM,Bt,null),e(Yo,ITr),e(Yo,_o),M($$,_o,null),e(_o,NTr),e(_o,mEe),e(mEe,qTr),e(_o,jTr),e(_o,hn),e(hn,DTr),e(hn,gEe),e(gEe,GTr),e(hn,OTr),e(hn,hEe),e(hEe,VTr),e(hn,XTr),e(hn,uEe),e(uEe,zTr),e(hn,QTr),e(_o,WTr),e(_o,ft),e(ft,XM),e(XM,pEe),e(pEe,UTr),e(XM,HTr),e(XM,KY),e(KY,JTr),e(XM,YTr),e(ft,KTr),e(ft,zM),e(zM,_Ee),e(_Ee,ZTr),e(zM,eMr),e(zM,ZY),e(ZY,oMr),e(zM,rMr),e(ft,tMr),e(ft,QM),e(QM,vEe),e(vEe,aMr),e(QM,nMr),e(QM,eK),e(eK,sMr),e(QM,lMr),e(ft,iMr),e(ft,WM),e(WM,bEe),e(bEe,dMr),e(WM,cMr),e(WM,oK),e(oK,fMr),e(WM,mMr),e(ft,gMr),e(ft,UM),e(UM,FEe),e(FEe,hMr),e(UM,uMr),e(UM,rK),e(rK,pMr),e(UM,_Mr),e(_o,vMr),e(_o,HM),e(HM,bMr),e(HM,TEe),e(TEe,FMr),e(HM,TMr),e(HM,MEe),e(MEe,MMr),e(_o,EMr),M(JM,_o,null),v(f,AKe,_),v(f,_c,_),e(_c,YM),e(YM,EEe),M(k$,EEe,null),e(_c,CMr),e(_c,CEe),e(CEe,wMr),v(f,LKe,_),v(f,Ko,_),M(S$,Ko,null),e(Ko,AMr),e(Ko,vc),e(vc,LMr),e(vc,tK),e(tK,yMr),e(vc,xMr),e(vc,aK),e(aK,$Mr),e(vc,kMr),e(Ko,SMr),e(Ko,R$),e(R$,RMr),e(R$,wEe),e(wEe,PMr),e(R$,BMr),e(Ko,IMr),e(Ko,It),M(P$,It,null),e(It,NMr),e(It,AEe),e(AEe,qMr),e(It,jMr),e(It,bc),e(bc,DMr),e(bc,LEe),e(LEe,GMr),e(bc,OMr),e(bc,nK),e(nK,VMr),e(bc,XMr),e(It,zMr),M(KM,It,null),e(Ko,QMr),e(Ko,vo),M(B$,vo,null),e(vo,WMr),e(vo,yEe),e(yEe,UMr),e(vo,HMr),e(vo,un),e(un,JMr),e(un,xEe),e(xEe,YMr),e(un,KMr),e(un,$Ee),e($Ee,ZMr),e(un,eEr),e(un,kEe),e(kEe,oEr),e(un,rEr),e(vo,tEr),e(vo,Le),e(Le,ZM),e(ZM,SEe),e(SEe,aEr),e(ZM,nEr),e(ZM,sK),e(sK,sEr),e(ZM,lEr),e(Le,iEr),e(Le,eE),e(eE,REe),e(REe,dEr),e(eE,cEr),e(eE,lK),e(lK,fEr),e(eE,mEr),e(Le,gEr),e(Le,oE),e(oE,PEe),e(PEe,hEr),e(oE,uEr),e(oE,iK),e(iK,pEr),e(oE,_Er),e(Le,vEr),e(Le,rE),e(rE,BEe),e(BEe,bEr),e(rE,FEr),e(rE,dK),e(dK,TEr),e(rE,MEr),e(Le,EEr),e(Le,tE),e(tE,IEe),e(IEe,CEr),e(tE,wEr),e(tE,cK),e(cK,AEr),e(tE,LEr),e(Le,yEr),e(Le,aE),e(aE,NEe),e(NEe,xEr),e(aE,$Er),e(aE,fK),e(fK,kEr),e(aE,SEr),e(Le,REr),e(Le,nE),e(nE,qEe),e(qEe,PEr),e(nE,BEr),e(nE,mK),e(mK,IEr),e(nE,NEr),e(Le,qEr),e(Le,sE),e(sE,jEe),e(jEe,jEr),e(sE,DEr),e(sE,gK),e(gK,GEr),e(sE,OEr),e(Le,VEr),e(Le,lE),e(lE,DEe),e(DEe,XEr),e(lE,zEr),e(lE,hK),e(hK,QEr),e(lE,WEr),e(Le,UEr),e(Le,iE),e(iE,GEe),e(GEe,HEr),e(iE,JEr),e(iE,uK),e(uK,YEr),e(iE,KEr),e(vo,ZEr),e(vo,dE),e(dE,eCr),e(dE,OEe),e(OEe,oCr),e(dE,rCr),e(dE,VEe),e(VEe,tCr),e(vo,aCr),M(cE,vo,null),v(f,yKe,_),v(f,Fc,_),e(Fc,fE),e(fE,XEe),M(I$,XEe,null),e(Fc,nCr),e(Fc,zEe),e(zEe,sCr),v(f,xKe,_),v(f,Zo,_),M(N$,Zo,null),e(Zo,lCr),e(Zo,Tc),e(Tc,iCr),e(Tc,pK),e(pK,dCr),e(Tc,cCr),e(Tc,_K),e(_K,fCr),e(Tc,mCr),e(Zo,gCr),e(Zo,q$),e(q$,hCr),e(q$,QEe),e(QEe,uCr),e(q$,pCr),e(Zo,_Cr),e(Zo,Nt),M(j$,Nt,null),e(Nt,vCr),e(Nt,WEe),e(WEe,bCr),e(Nt,FCr),e(Nt,Mc),e(Mc,TCr),e(Mc,UEe),e(UEe,MCr),e(Mc,ECr),e(Mc,vK),e(vK,CCr),e(Mc,wCr),e(Nt,ACr),M(mE,Nt,null),e(Zo,LCr),e(Zo,bo),M(D$,bo,null),e(bo,yCr),e(bo,HEe),e(HEe,xCr),e(bo,$Cr),e(bo,pn),e(pn,kCr),e(pn,JEe),e(JEe,SCr),e(pn,RCr),e(pn,YEe),e(YEe,PCr),e(pn,BCr),e(pn,KEe),e(KEe,ICr),e(pn,NCr),e(bo,qCr),e(bo,G$),e(G$,gE),e(gE,ZEe),e(ZEe,jCr),e(gE,DCr),e(gE,bK),e(bK,GCr),e(gE,OCr),e(G$,VCr),e(G$,hE),e(hE,eCe),e(eCe,XCr),e(hE,zCr),e(hE,FK),e(FK,QCr),e(hE,WCr),e(bo,UCr),e(bo,uE),e(uE,HCr),e(uE,oCe),e(oCe,JCr),e(uE,YCr),e(uE,rCe),e(rCe,KCr),e(bo,ZCr),M(pE,bo,null),v(f,$Ke,_),v(f,Ec,_),e(Ec,_E),e(_E,tCe),M(O$,tCe,null),e(Ec,e3r),e(Ec,aCe),e(aCe,o3r),v(f,kKe,_),v(f,er,_),M(V$,er,null),e(er,r3r),e(er,Cc),e(Cc,t3r),e(Cc,TK),e(TK,a3r),e(Cc,n3r),e(Cc,MK),e(MK,s3r),e(Cc,l3r),e(er,i3r),e(er,X$),e(X$,d3r),e(X$,nCe),e(nCe,c3r),e(X$,f3r),e(er,m3r),e(er,qt),M(z$,qt,null),e(qt,g3r),e(qt,sCe),e(sCe,h3r),e(qt,u3r),e(qt,wc),e(wc,p3r),e(wc,lCe),e(lCe,_3r),e(wc,v3r),e(wc,EK),e(EK,b3r),e(wc,F3r),e(qt,T3r),M(vE,qt,null),e(er,M3r),e(er,Fo),M(Q$,Fo,null),e(Fo,E3r),e(Fo,iCe),e(iCe,C3r),e(Fo,w3r),e(Fo,_n),e(_n,A3r),e(_n,dCe),e(dCe,L3r),e(_n,y3r),e(_n,cCe),e(cCe,x3r),e(_n,$3r),e(_n,fCe),e(fCe,k3r),e(_n,S3r),e(Fo,R3r),e(Fo,mt),e(mt,bE),e(bE,mCe),e(mCe,P3r),e(bE,B3r),e(bE,CK),e(CK,I3r),e(bE,N3r),e(mt,q3r),e(mt,FE),e(FE,gCe),e(gCe,j3r),e(FE,D3r),e(FE,wK),e(wK,G3r),e(FE,O3r),e(mt,V3r),e(mt,TE),e(TE,hCe),e(hCe,X3r),e(TE,z3r),e(TE,AK),e(AK,Q3r),e(TE,W3r),e(mt,U3r),e(mt,ME),e(ME,uCe),e(uCe,H3r),e(ME,J3r),e(ME,LK),e(LK,Y3r),e(ME,K3r),e(mt,Z3r),e(mt,EE),e(EE,pCe),e(pCe,e5r),e(EE,o5r),e(EE,yK),e(yK,r5r),e(EE,t5r),e(Fo,a5r),e(Fo,CE),e(CE,n5r),e(CE,_Ce),e(_Ce,s5r),e(CE,l5r),e(CE,vCe),e(vCe,i5r),e(Fo,d5r),M(wE,Fo,null),v(f,SKe,_),v(f,Ac,_),e(Ac,AE),e(AE,bCe),M(W$,bCe,null),e(Ac,c5r),e(Ac,FCe),e(FCe,f5r),v(f,RKe,_),v(f,or,_),M(U$,or,null),e(or,m5r),e(or,Lc),e(Lc,g5r),e(Lc,xK),e(xK,h5r),e(Lc,u5r),e(Lc,$K),e($K,p5r),e(Lc,_5r),e(or,v5r),e(or,H$),e(H$,b5r),e(H$,TCe),e(TCe,F5r),e(H$,T5r),e(or,M5r),e(or,jt),M(J$,jt,null),e(jt,E5r),e(jt,MCe),e(MCe,C5r),e(jt,w5r),e(jt,yc),e(yc,A5r),e(yc,ECe),e(ECe,L5r),e(yc,y5r),e(yc,kK),e(kK,x5r),e(yc,$5r),e(jt,k5r),M(LE,jt,null),e(or,S5r),e(or,To),M(Y$,To,null),e(To,R5r),e(To,CCe),e(CCe,P5r),e(To,B5r),e(To,vn),e(vn,I5r),e(vn,wCe),e(wCe,N5r),e(vn,q5r),e(vn,ACe),e(ACe,j5r),e(vn,D5r),e(vn,LCe),e(LCe,G5r),e(vn,O5r),e(To,V5r),e(To,bn),e(bn,yE),e(yE,yCe),e(yCe,X5r),e(yE,z5r),e(yE,SK),e(SK,Q5r),e(yE,W5r),e(bn,U5r),e(bn,xE),e(xE,xCe),e(xCe,H5r),e(xE,J5r),e(xE,RK),e(RK,Y5r),e(xE,K5r),e(bn,Z5r),e(bn,$E),e($E,$Ce),e($Ce,ewr),e($E,owr),e($E,PK),e(PK,rwr),e($E,twr),e(bn,awr),e(bn,kE),e(kE,kCe),e(kCe,nwr),e(kE,swr),e(kE,BK),e(BK,lwr),e(kE,iwr),e(To,dwr),e(To,SE),e(SE,cwr),e(SE,SCe),e(SCe,fwr),e(SE,mwr),e(SE,RCe),e(RCe,gwr),e(To,hwr),M(RE,To,null),v(f,PKe,_),v(f,xc,_),e(xc,PE),e(PE,PCe),M(K$,PCe,null),e(xc,uwr),e(xc,BCe),e(BCe,pwr),v(f,BKe,_),v(f,rr,_),M(Z$,rr,null),e(rr,_wr),e(rr,$c),e($c,vwr),e($c,IK),e(IK,bwr),e($c,Fwr),e($c,NK),e(NK,Twr),e($c,Mwr),e(rr,Ewr),e(rr,ek),e(ek,Cwr),e(ek,ICe),e(ICe,wwr),e(ek,Awr),e(rr,Lwr),e(rr,Dt),M(ok,Dt,null),e(Dt,ywr),e(Dt,NCe),e(NCe,xwr),e(Dt,$wr),e(Dt,kc),e(kc,kwr),e(kc,qCe),e(qCe,Swr),e(kc,Rwr),e(kc,qK),e(qK,Pwr),e(kc,Bwr),e(Dt,Iwr),M(BE,Dt,null),e(rr,Nwr),e(rr,Mo),M(rk,Mo,null),e(Mo,qwr),e(Mo,jCe),e(jCe,jwr),e(Mo,Dwr),e(Mo,Fn),e(Fn,Gwr),e(Fn,DCe),e(DCe,Owr),e(Fn,Vwr),e(Fn,GCe),e(GCe,Xwr),e(Fn,zwr),e(Fn,OCe),e(OCe,Qwr),e(Fn,Wwr),e(Mo,Uwr),e(Mo,tk),e(tk,IE),e(IE,VCe),e(VCe,Hwr),e(IE,Jwr),e(IE,jK),e(jK,Ywr),e(IE,Kwr),e(tk,Zwr),e(tk,NE),e(NE,XCe),e(XCe,eAr),e(NE,oAr),e(NE,DK),e(DK,rAr),e(NE,tAr),e(Mo,aAr),e(Mo,qE),e(qE,nAr),e(qE,zCe),e(zCe,sAr),e(qE,lAr),e(qE,QCe),e(QCe,iAr),e(Mo,dAr),M(jE,Mo,null),v(f,IKe,_),v(f,Sc,_),e(Sc,DE),e(DE,WCe),M(ak,WCe,null),e(Sc,cAr),e(Sc,UCe),e(UCe,fAr),v(f,NKe,_),v(f,tr,_),M(nk,tr,null),e(tr,mAr),e(tr,Rc),e(Rc,gAr),e(Rc,GK),e(GK,hAr),e(Rc,uAr),e(Rc,OK),e(OK,pAr),e(Rc,_Ar),e(tr,vAr),e(tr,sk),e(sk,bAr),e(sk,HCe),e(HCe,FAr),e(sk,TAr),e(tr,MAr),e(tr,Gt),M(lk,Gt,null),e(Gt,EAr),e(Gt,JCe),e(JCe,CAr),e(Gt,wAr),e(Gt,Pc),e(Pc,AAr),e(Pc,YCe),e(YCe,LAr),e(Pc,yAr),e(Pc,VK),e(VK,xAr),e(Pc,$Ar),e(Gt,kAr),M(GE,Gt,null),e(tr,SAr),e(tr,Eo),M(ik,Eo,null),e(Eo,RAr),e(Eo,KCe),e(KCe,PAr),e(Eo,BAr),e(Eo,Tn),e(Tn,IAr),e(Tn,ZCe),e(ZCe,NAr),e(Tn,qAr),e(Tn,e3e),e(e3e,jAr),e(Tn,DAr),e(Tn,o3e),e(o3e,GAr),e(Tn,OAr),e(Eo,VAr),e(Eo,r3e),e(r3e,OE),e(OE,t3e),e(t3e,XAr),e(OE,zAr),e(OE,XK),e(XK,QAr),e(OE,WAr),e(Eo,UAr),e(Eo,VE),e(VE,HAr),e(VE,a3e),e(a3e,JAr),e(VE,YAr),e(VE,n3e),e(n3e,KAr),e(Eo,ZAr),M(XE,Eo,null),v(f,qKe,_),v(f,Bc,_),e(Bc,zE),e(zE,s3e),M(dk,s3e,null),e(Bc,e6r),e(Bc,l3e),e(l3e,o6r),v(f,jKe,_),v(f,ar,_),M(ck,ar,null),e(ar,r6r),e(ar,Ic),e(Ic,t6r),e(Ic,zK),e(zK,a6r),e(Ic,n6r),e(Ic,QK),e(QK,s6r),e(Ic,l6r),e(ar,i6r),e(ar,fk),e(fk,d6r),e(fk,i3e),e(i3e,c6r),e(fk,f6r),e(ar,m6r),e(ar,Ot),M(mk,Ot,null),e(Ot,g6r),e(Ot,d3e),e(d3e,h6r),e(Ot,u6r),e(Ot,Nc),e(Nc,p6r),e(Nc,c3e),e(c3e,_6r),e(Nc,v6r),e(Nc,WK),e(WK,b6r),e(Nc,F6r),e(Ot,T6r),M(QE,Ot,null),e(ar,M6r),e(ar,Co),M(gk,Co,null),e(Co,E6r),e(Co,f3e),e(f3e,C6r),e(Co,w6r),e(Co,Mn),e(Mn,A6r),e(Mn,m3e),e(m3e,L6r),e(Mn,y6r),e(Mn,g3e),e(g3e,x6r),e(Mn,$6r),e(Mn,h3e),e(h3e,k6r),e(Mn,S6r),e(Co,R6r),e(Co,gt),e(gt,WE),e(WE,u3e),e(u3e,P6r),e(WE,B6r),e(WE,UK),e(UK,I6r),e(WE,N6r),e(gt,q6r),e(gt,UE),e(UE,p3e),e(p3e,j6r),e(UE,D6r),e(UE,HK),e(HK,G6r),e(UE,O6r),e(gt,V6r),e(gt,HE),e(HE,_3e),e(_3e,X6r),e(HE,z6r),e(HE,JK),e(JK,Q6r),e(HE,W6r),e(gt,U6r),e(gt,JE),e(JE,v3e),e(v3e,H6r),e(JE,J6r),e(JE,YK),e(YK,Y6r),e(JE,K6r),e(gt,Z6r),e(gt,YE),e(YE,b3e),e(b3e,e7r),e(YE,o7r),e(YE,KK),e(KK,r7r),e(YE,t7r),e(Co,a7r),e(Co,KE),e(KE,n7r),e(KE,F3e),e(F3e,s7r),e(KE,l7r),e(KE,T3e),e(T3e,i7r),e(Co,d7r),M(ZE,Co,null),v(f,DKe,_),v(f,qc,_),e(qc,eC),e(eC,M3e),M(hk,M3e,null),e(qc,c7r),e(qc,E3e),e(E3e,f7r),v(f,GKe,_),v(f,nr,_),M(uk,nr,null),e(nr,m7r),e(nr,jc),e(jc,g7r),e(jc,ZK),e(ZK,h7r),e(jc,u7r),e(jc,eZ),e(eZ,p7r),e(jc,_7r),e(nr,v7r),e(nr,pk),e(pk,b7r),e(pk,C3e),e(C3e,F7r),e(pk,T7r),e(nr,M7r),e(nr,Vt),M(_k,Vt,null),e(Vt,E7r),e(Vt,w3e),e(w3e,C7r),e(Vt,w7r),e(Vt,Dc),e(Dc,A7r),e(Dc,A3e),e(A3e,L7r),e(Dc,y7r),e(Dc,oZ),e(oZ,x7r),e(Dc,$7r),e(Vt,k7r),M(oC,Vt,null),e(nr,S7r),e(nr,wo),M(vk,wo,null),e(wo,R7r),e(wo,L3e),e(L3e,P7r),e(wo,B7r),e(wo,En),e(En,I7r),e(En,y3e),e(y3e,N7r),e(En,q7r),e(En,x3e),e(x3e,j7r),e(En,D7r),e(En,$3e),e($3e,G7r),e(En,O7r),e(wo,V7r),e(wo,k3e),e(k3e,rC),e(rC,S3e),e(S3e,X7r),e(rC,z7r),e(rC,rZ),e(rZ,Q7r),e(rC,W7r),e(wo,U7r),e(wo,tC),e(tC,H7r),e(tC,R3e),e(R3e,J7r),e(tC,Y7r),e(tC,P3e),e(P3e,K7r),e(wo,Z7r),M(aC,wo,null),v(f,OKe,_),v(f,Gc,_),e(Gc,nC),e(nC,B3e),M(bk,B3e,null),e(Gc,eLr),e(Gc,I3e),e(I3e,oLr),v(f,VKe,_),v(f,sr,_),M(Fk,sr,null),e(sr,rLr),e(sr,Oc),e(Oc,tLr),e(Oc,tZ),e(tZ,aLr),e(Oc,nLr),e(Oc,aZ),e(aZ,sLr),e(Oc,lLr),e(sr,iLr),e(sr,Tk),e(Tk,dLr),e(Tk,N3e),e(N3e,cLr),e(Tk,fLr),e(sr,mLr),e(sr,Xt),M(Mk,Xt,null),e(Xt,gLr),e(Xt,q3e),e(q3e,hLr),e(Xt,uLr),e(Xt,Vc),e(Vc,pLr),e(Vc,j3e),e(j3e,_Lr),e(Vc,vLr),e(Vc,nZ),e(nZ,bLr),e(Vc,FLr),e(Xt,TLr),M(sC,Xt,null),e(sr,MLr),e(sr,Ir),M(Ek,Ir,null),e(Ir,ELr),e(Ir,D3e),e(D3e,CLr),e(Ir,wLr),e(Ir,Cn),e(Cn,ALr),e(Cn,G3e),e(G3e,LLr),e(Cn,yLr),e(Cn,O3e),e(O3e,xLr),e(Cn,$Lr),e(Cn,V3e),e(V3e,kLr),e(Cn,SLr),e(Ir,RLr),e(Ir,N),e(N,lC),e(lC,X3e),e(X3e,PLr),e(lC,BLr),e(lC,sZ),e(sZ,ILr),e(lC,NLr),e(N,qLr),e(N,iC),e(iC,z3e),e(z3e,jLr),e(iC,DLr),e(iC,lZ),e(lZ,GLr),e(iC,OLr),e(N,VLr),e(N,dC),e(dC,Q3e),e(Q3e,XLr),e(dC,zLr),e(dC,iZ),e(iZ,QLr),e(dC,WLr),e(N,ULr),e(N,cC),e(cC,W3e),e(W3e,HLr),e(cC,JLr),e(cC,dZ),e(dZ,YLr),e(cC,KLr),e(N,ZLr),e(N,fC),e(fC,U3e),e(U3e,eyr),e(fC,oyr),e(fC,cZ),e(cZ,ryr),e(fC,tyr),e(N,ayr),e(N,mC),e(mC,H3e),e(H3e,nyr),e(mC,syr),e(mC,fZ),e(fZ,lyr),e(mC,iyr),e(N,dyr),e(N,gC),e(gC,J3e),e(J3e,cyr),e(gC,fyr),e(gC,mZ),e(mZ,myr),e(gC,gyr),e(N,hyr),e(N,hC),e(hC,Y3e),e(Y3e,uyr),e(hC,pyr),e(hC,gZ),e(gZ,_yr),e(hC,vyr),e(N,byr),e(N,uC),e(uC,K3e),e(K3e,Fyr),e(uC,Tyr),e(uC,hZ),e(hZ,Myr),e(uC,Eyr),e(N,Cyr),e(N,pC),e(pC,Z3e),e(Z3e,wyr),e(pC,Ayr),e(pC,uZ),e(uZ,Lyr),e(pC,yyr),e(N,xyr),e(N,_C),e(_C,e5e),e(e5e,$yr),e(_C,kyr),e(_C,pZ),e(pZ,Syr),e(_C,Ryr),e(N,Pyr),e(N,vC),e(vC,o5e),e(o5e,Byr),e(vC,Iyr),e(vC,_Z),e(_Z,Nyr),e(vC,qyr),e(N,jyr),e(N,bC),e(bC,r5e),e(r5e,Dyr),e(bC,Gyr),e(bC,vZ),e(vZ,Oyr),e(bC,Vyr),e(N,Xyr),e(N,FC),e(FC,t5e),e(t5e,zyr),e(FC,Qyr),e(FC,bZ),e(bZ,Wyr),e(FC,Uyr),e(N,Hyr),e(N,TC),e(TC,a5e),e(a5e,Jyr),e(TC,Yyr),e(TC,FZ),e(FZ,Kyr),e(TC,Zyr),e(N,e8r),e(N,MC),e(MC,n5e),e(n5e,o8r),e(MC,r8r),e(MC,TZ),e(TZ,t8r),e(MC,a8r),e(N,n8r),e(N,EC),e(EC,s5e),e(s5e,s8r),e(EC,l8r),e(EC,MZ),e(MZ,i8r),e(EC,d8r),e(N,c8r),e(N,CC),e(CC,l5e),e(l5e,f8r),e(CC,m8r),e(CC,EZ),e(EZ,g8r),e(CC,h8r),e(N,u8r),e(N,bl),e(bl,i5e),e(i5e,p8r),e(bl,_8r),e(bl,CZ),e(CZ,v8r),e(bl,b8r),e(bl,wZ),e(wZ,F8r),e(bl,T8r),e(N,M8r),e(N,wC),e(wC,d5e),e(d5e,E8r),e(wC,C8r),e(wC,AZ),e(AZ,w8r),e(wC,A8r),e(N,L8r),e(N,AC),e(AC,c5e),e(c5e,y8r),e(AC,x8r),e(AC,LZ),e(LZ,$8r),e(AC,k8r),e(N,S8r),e(N,LC),e(LC,f5e),e(f5e,R8r),e(LC,P8r),e(LC,yZ),e(yZ,B8r),e(LC,I8r),e(N,N8r),e(N,yC),e(yC,m5e),e(m5e,q8r),e(yC,j8r),e(yC,xZ),e(xZ,D8r),e(yC,G8r),e(N,O8r),e(N,xC),e(xC,g5e),e(g5e,V8r),e(xC,X8r),e(xC,$Z),e($Z,z8r),e(xC,Q8r),e(N,W8r),e(N,$C),e($C,h5e),e(h5e,U8r),e($C,H8r),e($C,kZ),e(kZ,J8r),e($C,Y8r),e(N,K8r),e(N,kC),e(kC,u5e),e(u5e,Z8r),e(kC,e9r),e(kC,SZ),e(SZ,o9r),e(kC,r9r),e(N,t9r),e(N,SC),e(SC,p5e),e(p5e,a9r),e(SC,n9r),e(SC,RZ),e(RZ,s9r),e(SC,l9r),e(N,i9r),e(N,RC),e(RC,_5e),e(_5e,d9r),e(RC,c9r),e(RC,PZ),e(PZ,f9r),e(RC,m9r),e(N,g9r),e(N,PC),e(PC,v5e),e(v5e,h9r),e(PC,u9r),e(PC,BZ),e(BZ,p9r),e(PC,_9r),e(N,v9r),e(N,BC),e(BC,b5e),e(b5e,b9r),e(BC,F9r),e(BC,IZ),e(IZ,T9r),e(BC,M9r),e(N,E9r),e(N,IC),e(IC,F5e),e(F5e,C9r),e(IC,w9r),e(IC,NZ),e(NZ,A9r),e(IC,L9r),e(N,y9r),e(N,NC),e(NC,T5e),e(T5e,x9r),e(NC,$9r),e(NC,qZ),e(qZ,k9r),e(NC,S9r),e(N,R9r),e(N,qC),e(qC,M5e),e(M5e,P9r),e(qC,B9r),e(qC,jZ),e(jZ,I9r),e(qC,N9r),e(N,q9r),e(N,jC),e(jC,E5e),e(E5e,j9r),e(jC,D9r),e(jC,DZ),e(DZ,G9r),e(jC,O9r),e(N,V9r),e(N,DC),e(DC,C5e),e(C5e,X9r),e(DC,z9r),e(DC,GZ),e(GZ,Q9r),e(DC,W9r),e(N,U9r),e(N,GC),e(GC,w5e),e(w5e,H9r),e(GC,J9r),e(GC,OZ),e(OZ,Y9r),e(GC,K9r),e(N,Z9r),e(N,OC),e(OC,A5e),e(A5e,exr),e(OC,oxr),e(OC,VZ),e(VZ,rxr),e(OC,txr),e(N,axr),e(N,VC),e(VC,L5e),e(L5e,nxr),e(VC,sxr),e(VC,XZ),e(XZ,lxr),e(VC,ixr),e(N,dxr),e(N,XC),e(XC,y5e),e(y5e,cxr),e(XC,fxr),e(XC,zZ),e(zZ,mxr),e(XC,gxr),e(N,hxr),e(N,zC),e(zC,x5e),e(x5e,uxr),e(zC,pxr),e(zC,QZ),e(QZ,_xr),e(zC,vxr),e(N,bxr),e(N,QC),e(QC,$5e),e($5e,Fxr),e(QC,Txr),e(QC,WZ),e(WZ,Mxr),e(QC,Exr),e(N,Cxr),e(N,WC),e(WC,k5e),e(k5e,wxr),e(WC,Axr),e(WC,UZ),e(UZ,Lxr),e(WC,yxr),e(N,xxr),e(N,UC),e(UC,S5e),e(S5e,$xr),e(UC,kxr),e(UC,HZ),e(HZ,Sxr),e(UC,Rxr),e(N,Pxr),e(N,HC),e(HC,R5e),e(R5e,Bxr),e(HC,Ixr),e(HC,JZ),e(JZ,Nxr),e(HC,qxr),e(N,jxr),e(N,JC),e(JC,P5e),e(P5e,Dxr),e(JC,Gxr),e(JC,YZ),e(YZ,Oxr),e(JC,Vxr),e(N,Xxr),e(N,YC),e(YC,B5e),e(B5e,zxr),e(YC,Qxr),e(YC,KZ),e(KZ,Wxr),e(YC,Uxr),e(N,Hxr),e(N,KC),e(KC,I5e),e(I5e,Jxr),e(KC,Yxr),e(KC,ZZ),e(ZZ,Kxr),e(KC,Zxr),e(N,e$r),e(N,ZC),e(ZC,N5e),e(N5e,o$r),e(ZC,r$r),e(ZC,eee),e(eee,t$r),e(ZC,a$r),e(N,n$r),e(N,e3),e(e3,q5e),e(q5e,s$r),e(e3,l$r),e(e3,oee),e(oee,i$r),e(e3,d$r),e(N,c$r),e(N,o3),e(o3,j5e),e(j5e,f$r),e(o3,m$r),e(o3,ree),e(ree,g$r),e(o3,h$r),e(N,u$r),e(N,r3),e(r3,D5e),e(D5e,p$r),e(r3,_$r),e(r3,tee),e(tee,v$r),e(r3,b$r),e(N,F$r),e(N,t3),e(t3,G5e),e(G5e,T$r),e(t3,M$r),e(t3,aee),e(aee,E$r),e(t3,C$r),e(N,w$r),e(N,a3),e(a3,O5e),e(O5e,A$r),e(a3,L$r),e(a3,nee),e(nee,y$r),e(a3,x$r),e(N,$$r),e(N,n3),e(n3,V5e),e(V5e,k$r),e(n3,S$r),e(n3,see),e(see,R$r),e(n3,P$r),e(Ir,B$r),M(s3,Ir,null),v(f,XKe,_),v(f,Xc,_),e(Xc,l3),e(l3,X5e),M(Ck,X5e,null),e(Xc,I$r),e(Xc,z5e),e(z5e,N$r),v(f,zKe,_),v(f,lr,_),M(wk,lr,null),e(lr,q$r),e(lr,zc),e(zc,j$r),e(zc,lee),e(lee,D$r),e(zc,G$r),e(zc,iee),e(iee,O$r),e(zc,V$r),e(lr,X$r),e(lr,Ak),e(Ak,z$r),e(Ak,Q5e),e(Q5e,Q$r),e(Ak,W$r),e(lr,U$r),e(lr,zt),M(Lk,zt,null),e(zt,H$r),e(zt,W5e),e(W5e,J$r),e(zt,Y$r),e(zt,Qc),e(Qc,K$r),e(Qc,U5e),e(U5e,Z$r),e(Qc,ekr),e(Qc,dee),e(dee,okr),e(Qc,rkr),e(zt,tkr),M(i3,zt,null),e(lr,akr),e(lr,Nr),M(yk,Nr,null),e(Nr,nkr),e(Nr,H5e),e(H5e,skr),e(Nr,lkr),e(Nr,wn),e(wn,ikr),e(wn,J5e),e(J5e,dkr),e(wn,ckr),e(wn,Y5e),e(Y5e,fkr),e(wn,mkr),e(wn,K5e),e(K5e,gkr),e(wn,hkr),e(Nr,ukr),e(Nr,se),e(se,d3),e(d3,Z5e),e(Z5e,pkr),e(d3,_kr),e(d3,cee),e(cee,vkr),e(d3,bkr),e(se,Fkr),e(se,c3),e(c3,ewe),e(ewe,Tkr),e(c3,Mkr),e(c3,fee),e(fee,Ekr),e(c3,Ckr),e(se,wkr),e(se,f3),e(f3,owe),e(owe,Akr),e(f3,Lkr),e(f3,mee),e(mee,ykr),e(f3,xkr),e(se,$kr),e(se,m3),e(m3,rwe),e(rwe,kkr),e(m3,Skr),e(m3,gee),e(gee,Rkr),e(m3,Pkr),e(se,Bkr),e(se,g3),e(g3,twe),e(twe,Ikr),e(g3,Nkr),e(g3,hee),e(hee,qkr),e(g3,jkr),e(se,Dkr),e(se,h3),e(h3,awe),e(awe,Gkr),e(h3,Okr),e(h3,uee),e(uee,Vkr),e(h3,Xkr),e(se,zkr),e(se,u3),e(u3,nwe),e(nwe,Qkr),e(u3,Wkr),e(u3,pee),e(pee,Ukr),e(u3,Hkr),e(se,Jkr),e(se,p3),e(p3,swe),e(swe,Ykr),e(p3,Kkr),e(p3,_ee),e(_ee,Zkr),e(p3,eSr),e(se,oSr),e(se,_3),e(_3,lwe),e(lwe,rSr),e(_3,tSr),e(_3,vee),e(vee,aSr),e(_3,nSr),e(se,sSr),e(se,v3),e(v3,iwe),e(iwe,lSr),e(v3,iSr),e(v3,bee),e(bee,dSr),e(v3,cSr),e(se,fSr),e(se,b3),e(b3,dwe),e(dwe,mSr),e(b3,gSr),e(b3,Fee),e(Fee,hSr),e(b3,uSr),e(se,pSr),e(se,F3),e(F3,cwe),e(cwe,_Sr),e(F3,vSr),e(F3,Tee),e(Tee,bSr),e(F3,FSr),e(se,TSr),e(se,T3),e(T3,fwe),e(fwe,MSr),e(T3,ESr),e(T3,Mee),e(Mee,CSr),e(T3,wSr),e(se,ASr),e(se,M3),e(M3,mwe),e(mwe,LSr),e(M3,ySr),e(M3,Eee),e(Eee,xSr),e(M3,$Sr),e(se,kSr),e(se,E3),e(E3,gwe),e(gwe,SSr),e(E3,RSr),e(E3,Cee),e(Cee,PSr),e(E3,BSr),e(se,ISr),e(se,C3),e(C3,hwe),e(hwe,NSr),e(C3,qSr),e(C3,wee),e(wee,jSr),e(C3,DSr),e(se,GSr),e(se,w3),e(w3,uwe),e(uwe,OSr),e(w3,VSr),e(w3,Aee),e(Aee,XSr),e(w3,zSr),e(se,QSr),e(se,A3),e(A3,pwe),e(pwe,WSr),e(A3,USr),e(A3,Lee),e(Lee,HSr),e(A3,JSr),e(se,YSr),e(se,L3),e(L3,_we),e(_we,KSr),e(L3,ZSr),e(L3,yee),e(yee,eRr),e(L3,oRr),e(se,rRr),e(se,y3),e(y3,vwe),e(vwe,tRr),e(y3,aRr),e(y3,xee),e(xee,nRr),e(y3,sRr),e(se,lRr),e(se,x3),e(x3,bwe),e(bwe,iRr),e(x3,dRr),e(x3,$ee),e($ee,cRr),e(x3,fRr),e(se,mRr),e(se,$3),e($3,Fwe),e(Fwe,gRr),e($3,hRr),e($3,kee),e(kee,uRr),e($3,pRr),e(se,_Rr),e(se,k3),e(k3,Twe),e(Twe,vRr),e(k3,bRr),e(k3,See),e(See,FRr),e(k3,TRr),e(Nr,MRr),M(S3,Nr,null),v(f,QKe,_),v(f,Wc,_),e(Wc,R3),e(R3,Mwe),M(xk,Mwe,null),e(Wc,ERr),e(Wc,Ewe),e(Ewe,CRr),v(f,WKe,_),v(f,ir,_),M($k,ir,null),e(ir,wRr),e(ir,Uc),e(Uc,ARr),e(Uc,Ree),e(Ree,LRr),e(Uc,yRr),e(Uc,Pee),e(Pee,xRr),e(Uc,$Rr),e(ir,kRr),e(ir,kk),e(kk,SRr),e(kk,Cwe),e(Cwe,RRr),e(kk,PRr),e(ir,BRr),e(ir,Qt),M(Sk,Qt,null),e(Qt,IRr),e(Qt,wwe),e(wwe,NRr),e(Qt,qRr),e(Qt,Hc),e(Hc,jRr),e(Hc,Awe),e(Awe,DRr),e(Hc,GRr),e(Hc,Bee),e(Bee,ORr),e(Hc,VRr),e(Qt,XRr),M(P3,Qt,null),e(ir,zRr),e(ir,qr),M(Rk,qr,null),e(qr,QRr),e(qr,Lwe),e(Lwe,WRr),e(qr,URr),e(qr,An),e(An,HRr),e(An,ywe),e(ywe,JRr),e(An,YRr),e(An,xwe),e(xwe,KRr),e(An,ZRr),e(An,$we),e($we,ePr),e(An,oPr),e(qr,rPr),e(qr,Me),e(Me,B3),e(B3,kwe),e(kwe,tPr),e(B3,aPr),e(B3,Iee),e(Iee,nPr),e(B3,sPr),e(Me,lPr),e(Me,I3),e(I3,Swe),e(Swe,iPr),e(I3,dPr),e(I3,Nee),e(Nee,cPr),e(I3,fPr),e(Me,mPr),e(Me,N3),e(N3,Rwe),e(Rwe,gPr),e(N3,hPr),e(N3,qee),e(qee,uPr),e(N3,pPr),e(Me,_Pr),e(Me,q3),e(q3,Pwe),e(Pwe,vPr),e(q3,bPr),e(q3,jee),e(jee,FPr),e(q3,TPr),e(Me,MPr),e(Me,j3),e(j3,Bwe),e(Bwe,EPr),e(j3,CPr),e(j3,Dee),e(Dee,wPr),e(j3,APr),e(Me,LPr),e(Me,D3),e(D3,Iwe),e(Iwe,yPr),e(D3,xPr),e(D3,Gee),e(Gee,$Pr),e(D3,kPr),e(Me,SPr),e(Me,G3),e(G3,Nwe),e(Nwe,RPr),e(G3,PPr),e(G3,Oee),e(Oee,BPr),e(G3,IPr),e(Me,NPr),e(Me,O3),e(O3,qwe),e(qwe,qPr),e(O3,jPr),e(O3,Vee),e(Vee,DPr),e(O3,GPr),e(Me,OPr),e(Me,V3),e(V3,jwe),e(jwe,VPr),e(V3,XPr),e(V3,Xee),e(Xee,zPr),e(V3,QPr),e(Me,WPr),e(Me,X3),e(X3,Dwe),e(Dwe,UPr),e(X3,HPr),e(X3,zee),e(zee,JPr),e(X3,YPr),e(Me,KPr),e(Me,z3),e(z3,Gwe),e(Gwe,ZPr),e(z3,eBr),e(z3,Qee),e(Qee,oBr),e(z3,rBr),e(Me,tBr),e(Me,Q3),e(Q3,Owe),e(Owe,aBr),e(Q3,nBr),e(Q3,Wee),e(Wee,sBr),e(Q3,lBr),e(Me,iBr),e(Me,W3),e(W3,Vwe),e(Vwe,dBr),e(W3,cBr),e(W3,Uee),e(Uee,fBr),e(W3,mBr),e(Me,gBr),e(Me,U3),e(U3,Xwe),e(Xwe,hBr),e(U3,uBr),e(U3,Hee),e(Hee,pBr),e(U3,_Br),e(qr,vBr),M(H3,qr,null),v(f,UKe,_),v(f,Jc,_),e(Jc,J3),e(J3,zwe),M(Pk,zwe,null),e(Jc,bBr),e(Jc,Qwe),e(Qwe,FBr),v(f,HKe,_),v(f,dr,_),M(Bk,dr,null),e(dr,TBr),e(dr,Yc),e(Yc,MBr),e(Yc,Jee),e(Jee,EBr),e(Yc,CBr),e(Yc,Yee),e(Yee,wBr),e(Yc,ABr),e(dr,LBr),e(dr,Ik),e(Ik,yBr),e(Ik,Wwe),e(Wwe,xBr),e(Ik,$Br),e(dr,kBr),e(dr,Wt),M(Nk,Wt,null),e(Wt,SBr),e(Wt,Uwe),e(Uwe,RBr),e(Wt,PBr),e(Wt,Kc),e(Kc,BBr),e(Kc,Hwe),e(Hwe,IBr),e(Kc,NBr),e(Kc,Kee),e(Kee,qBr),e(Kc,jBr),e(Wt,DBr),M(Y3,Wt,null),e(dr,GBr),e(dr,jr),M(qk,jr,null),e(jr,OBr),e(jr,Jwe),e(Jwe,VBr),e(jr,XBr),e(jr,Ln),e(Ln,zBr),e(Ln,Ywe),e(Ywe,QBr),e(Ln,WBr),e(Ln,Kwe),e(Kwe,UBr),e(Ln,HBr),e(Ln,Zwe),e(Zwe,JBr),e(Ln,YBr),e(jr,KBr),e(jr,Be),e(Be,K3),e(K3,eAe),e(eAe,ZBr),e(K3,eIr),e(K3,Zee),e(Zee,oIr),e(K3,rIr),e(Be,tIr),e(Be,Z3),e(Z3,oAe),e(oAe,aIr),e(Z3,nIr),e(Z3,eoe),e(eoe,sIr),e(Z3,lIr),e(Be,iIr),e(Be,Fl),e(Fl,rAe),e(rAe,dIr),e(Fl,cIr),e(Fl,ooe),e(ooe,fIr),e(Fl,mIr),e(Fl,roe),e(roe,gIr),e(Fl,hIr),e(Be,uIr),e(Be,e5),e(e5,tAe),e(tAe,pIr),e(e5,_Ir),e(e5,toe),e(toe,vIr),e(e5,bIr),e(Be,FIr),e(Be,o5),e(o5,aAe),e(aAe,TIr),e(o5,MIr),e(o5,aoe),e(aoe,EIr),e(o5,CIr),e(Be,wIr),e(Be,r5),e(r5,nAe),e(nAe,AIr),e(r5,LIr),e(r5,noe),e(noe,yIr),e(r5,xIr),e(Be,$Ir),e(Be,t5),e(t5,sAe),e(sAe,kIr),e(t5,SIr),e(t5,soe),e(soe,RIr),e(t5,PIr),e(Be,BIr),e(Be,a5),e(a5,lAe),e(lAe,IIr),e(a5,NIr),e(a5,loe),e(loe,qIr),e(a5,jIr),e(Be,DIr),e(Be,n5),e(n5,iAe),e(iAe,GIr),e(n5,OIr),e(n5,ioe),e(ioe,VIr),e(n5,XIr),e(jr,zIr),M(s5,jr,null),v(f,JKe,_),v(f,Zc,_),e(Zc,l5),e(l5,dAe),M(jk,dAe,null),e(Zc,QIr),e(Zc,cAe),e(cAe,WIr),v(f,YKe,_),v(f,cr,_),M(Dk,cr,null),e(cr,UIr),e(cr,ef),e(ef,HIr),e(ef,doe),e(doe,JIr),e(ef,YIr),e(ef,coe),e(coe,KIr),e(ef,ZIr),e(cr,eNr),e(cr,Gk),e(Gk,oNr),e(Gk,fAe),e(fAe,rNr),e(Gk,tNr),e(cr,aNr),e(cr,Ut),M(Ok,Ut,null),e(Ut,nNr),e(Ut,mAe),e(mAe,sNr),e(Ut,lNr),e(Ut,of),e(of,iNr),e(of,gAe),e(gAe,dNr),e(of,cNr),e(of,foe),e(foe,fNr),e(of,mNr),e(Ut,gNr),M(i5,Ut,null),e(cr,hNr),e(cr,Dr),M(Vk,Dr,null),e(Dr,uNr),e(Dr,hAe),e(hAe,pNr),e(Dr,_Nr),e(Dr,yn),e(yn,vNr),e(yn,uAe),e(uAe,bNr),e(yn,FNr),e(yn,pAe),e(pAe,TNr),e(yn,MNr),e(yn,_Ae),e(_Ae,ENr),e(yn,CNr),e(Dr,wNr),e(Dr,rf),e(rf,d5),e(d5,vAe),e(vAe,ANr),e(d5,LNr),e(d5,moe),e(moe,yNr),e(d5,xNr),e(rf,$Nr),e(rf,c5),e(c5,bAe),e(bAe,kNr),e(c5,SNr),e(c5,goe),e(goe,RNr),e(c5,PNr),e(rf,BNr),e(rf,f5),e(f5,FAe),e(FAe,INr),e(f5,NNr),e(f5,hoe),e(hoe,qNr),e(f5,jNr),e(Dr,DNr),M(m5,Dr,null),v(f,KKe,_),v(f,tf,_),e(tf,g5),e(g5,TAe),M(Xk,TAe,null),e(tf,GNr),e(tf,MAe),e(MAe,ONr),v(f,ZKe,_),v(f,fr,_),M(zk,fr,null),e(fr,VNr),e(fr,af),e(af,XNr),e(af,uoe),e(uoe,zNr),e(af,QNr),e(af,poe),e(poe,WNr),e(af,UNr),e(fr,HNr),e(fr,Qk),e(Qk,JNr),e(Qk,EAe),e(EAe,YNr),e(Qk,KNr),e(fr,ZNr),e(fr,Ht),M(Wk,Ht,null),e(Ht,eqr),e(Ht,CAe),e(CAe,oqr),e(Ht,rqr),e(Ht,nf),e(nf,tqr),e(nf,wAe),e(wAe,aqr),e(nf,nqr),e(nf,_oe),e(_oe,sqr),e(nf,lqr),e(Ht,iqr),M(h5,Ht,null),e(fr,dqr),e(fr,Gr),M(Uk,Gr,null),e(Gr,cqr),e(Gr,AAe),e(AAe,fqr),e(Gr,mqr),e(Gr,xn),e(xn,gqr),e(xn,LAe),e(LAe,hqr),e(xn,uqr),e(xn,yAe),e(yAe,pqr),e(xn,_qr),e(xn,xAe),e(xAe,vqr),e(xn,bqr),e(Gr,Fqr),e(Gr,me),e(me,u5),e(u5,$Ae),e($Ae,Tqr),e(u5,Mqr),e(u5,voe),e(voe,Eqr),e(u5,Cqr),e(me,wqr),e(me,p5),e(p5,kAe),e(kAe,Aqr),e(p5,Lqr),e(p5,boe),e(boe,yqr),e(p5,xqr),e(me,$qr),e(me,_5),e(_5,SAe),e(SAe,kqr),e(_5,Sqr),e(_5,Foe),e(Foe,Rqr),e(_5,Pqr),e(me,Bqr),e(me,v5),e(v5,RAe),e(RAe,Iqr),e(v5,Nqr),e(v5,Toe),e(Toe,qqr),e(v5,jqr),e(me,Dqr),e(me,b5),e(b5,PAe),e(PAe,Gqr),e(b5,Oqr),e(b5,Moe),e(Moe,Vqr),e(b5,Xqr),e(me,zqr),e(me,F5),e(F5,BAe),e(BAe,Qqr),e(F5,Wqr),e(F5,Eoe),e(Eoe,Uqr),e(F5,Hqr),e(me,Jqr),e(me,T5),e(T5,IAe),e(IAe,Yqr),e(T5,Kqr),e(T5,Coe),e(Coe,Zqr),e(T5,ejr),e(me,ojr),e(me,M5),e(M5,NAe),e(NAe,rjr),e(M5,tjr),e(M5,woe),e(woe,ajr),e(M5,njr),e(me,sjr),e(me,E5),e(E5,qAe),e(qAe,ljr),e(E5,ijr),e(E5,Aoe),e(Aoe,djr),e(E5,cjr),e(me,fjr),e(me,C5),e(C5,jAe),e(jAe,mjr),e(C5,gjr),e(C5,Loe),e(Loe,hjr),e(C5,ujr),e(me,pjr),e(me,w5),e(w5,DAe),e(DAe,_jr),e(w5,vjr),e(w5,yoe),e(yoe,bjr),e(w5,Fjr),e(me,Tjr),e(me,A5),e(A5,GAe),e(GAe,Mjr),e(A5,Ejr),e(A5,xoe),e(xoe,Cjr),e(A5,wjr),e(me,Ajr),e(me,L5),e(L5,OAe),e(OAe,Ljr),e(L5,yjr),e(L5,$oe),e($oe,xjr),e(L5,$jr),e(me,kjr),e(me,y5),e(y5,VAe),e(VAe,Sjr),e(y5,Rjr),e(y5,koe),e(koe,Pjr),e(y5,Bjr),e(me,Ijr),e(me,x5),e(x5,XAe),e(XAe,Njr),e(x5,qjr),e(x5,Soe),e(Soe,jjr),e(x5,Djr),e(me,Gjr),e(me,$5),e($5,zAe),e(zAe,Ojr),e($5,Vjr),e($5,Roe),e(Roe,Xjr),e($5,zjr),e(me,Qjr),e(me,k5),e(k5,QAe),e(QAe,Wjr),e(k5,Ujr),e(k5,Poe),e(Poe,Hjr),e(k5,Jjr),e(me,Yjr),e(me,S5),e(S5,WAe),e(WAe,Kjr),e(S5,Zjr),e(S5,Boe),e(Boe,eDr),e(S5,oDr),e(me,rDr),e(me,R5),e(R5,UAe),e(UAe,tDr),e(R5,aDr),e(R5,Ioe),e(Ioe,nDr),e(R5,sDr),e(me,lDr),e(me,P5),e(P5,HAe),e(HAe,iDr),e(P5,dDr),e(P5,Noe),e(Noe,cDr),e(P5,fDr),e(Gr,mDr),M(B5,Gr,null),v(f,eZe,_),v(f,sf,_),e(sf,I5),e(I5,JAe),M(Hk,JAe,null),e(sf,gDr),e(sf,YAe),e(YAe,hDr),v(f,oZe,_),v(f,mr,_),M(Jk,mr,null),e(mr,uDr),e(mr,lf),e(lf,pDr),e(lf,qoe),e(qoe,_Dr),e(lf,vDr),e(lf,joe),e(joe,bDr),e(lf,FDr),e(mr,TDr),e(mr,Yk),e(Yk,MDr),e(Yk,KAe),e(KAe,EDr),e(Yk,CDr),e(mr,wDr),e(mr,Jt),M(Kk,Jt,null),e(Jt,ADr),e(Jt,ZAe),e(ZAe,LDr),e(Jt,yDr),e(Jt,df),e(df,xDr),e(df,e6e),e(e6e,$Dr),e(df,kDr),e(df,Doe),e(Doe,SDr),e(df,RDr),e(Jt,PDr),M(N5,Jt,null),e(mr,BDr),e(mr,Or),M(Zk,Or,null),e(Or,IDr),e(Or,o6e),e(o6e,NDr),e(Or,qDr),e(Or,$n),e($n,jDr),e($n,r6e),e(r6e,DDr),e($n,GDr),e($n,t6e),e(t6e,ODr),e($n,VDr),e($n,a6e),e(a6e,XDr),e($n,zDr),e(Or,QDr),e(Or,ye),e(ye,q5),e(q5,n6e),e(n6e,WDr),e(q5,UDr),e(q5,Goe),e(Goe,HDr),e(q5,JDr),e(ye,YDr),e(ye,j5),e(j5,s6e),e(s6e,KDr),e(j5,ZDr),e(j5,Ooe),e(Ooe,eGr),e(j5,oGr),e(ye,rGr),e(ye,D5),e(D5,l6e),e(l6e,tGr),e(D5,aGr),e(D5,Voe),e(Voe,nGr),e(D5,sGr),e(ye,lGr),e(ye,G5),e(G5,i6e),e(i6e,iGr),e(G5,dGr),e(G5,Xoe),e(Xoe,cGr),e(G5,fGr),e(ye,mGr),e(ye,O5),e(O5,d6e),e(d6e,gGr),e(O5,hGr),e(O5,zoe),e(zoe,uGr),e(O5,pGr),e(ye,_Gr),e(ye,V5),e(V5,c6e),e(c6e,vGr),e(V5,bGr),e(V5,Qoe),e(Qoe,FGr),e(V5,TGr),e(ye,MGr),e(ye,X5),e(X5,f6e),e(f6e,EGr),e(X5,CGr),e(X5,Woe),e(Woe,wGr),e(X5,AGr),e(ye,LGr),e(ye,z5),e(z5,m6e),e(m6e,yGr),e(z5,xGr),e(z5,Uoe),e(Uoe,$Gr),e(z5,kGr),e(ye,SGr),e(ye,Q5),e(Q5,g6e),e(g6e,RGr),e(Q5,PGr),e(Q5,Hoe),e(Hoe,BGr),e(Q5,IGr),e(ye,NGr),e(ye,W5),e(W5,h6e),e(h6e,qGr),e(W5,jGr),e(W5,Joe),e(Joe,DGr),e(W5,GGr),e(Or,OGr),M(U5,Or,null),v(f,rZe,_),v(f,cf,_),e(cf,H5),e(H5,u6e),M(eS,u6e,null),e(cf,VGr),e(cf,p6e),e(p6e,XGr),v(f,tZe,_),v(f,gr,_),M(oS,gr,null),e(gr,zGr),e(gr,ff),e(ff,QGr),e(ff,Yoe),e(Yoe,WGr),e(ff,UGr),e(ff,Koe),e(Koe,HGr),e(ff,JGr),e(gr,YGr),e(gr,rS),e(rS,KGr),e(rS,_6e),e(_6e,ZGr),e(rS,eOr),e(gr,oOr),e(gr,Yt),M(tS,Yt,null),e(Yt,rOr),e(Yt,v6e),e(v6e,tOr),e(Yt,aOr),e(Yt,mf),e(mf,nOr),e(mf,b6e),e(b6e,sOr),e(mf,lOr),e(mf,Zoe),e(Zoe,iOr),e(mf,dOr),e(Yt,cOr),M(J5,Yt,null),e(gr,fOr),e(gr,Vr),M(aS,Vr,null),e(Vr,mOr),e(Vr,F6e),e(F6e,gOr),e(Vr,hOr),e(Vr,kn),e(kn,uOr),e(kn,T6e),e(T6e,pOr),e(kn,_Or),e(kn,M6e),e(M6e,vOr),e(kn,bOr),e(kn,E6e),e(E6e,FOr),e(kn,TOr),e(Vr,MOr),e(Vr,re),e(re,Y5),e(Y5,C6e),e(C6e,EOr),e(Y5,COr),e(Y5,ere),e(ere,wOr),e(Y5,AOr),e(re,LOr),e(re,K5),e(K5,w6e),e(w6e,yOr),e(K5,xOr),e(K5,ore),e(ore,$Or),e(K5,kOr),e(re,SOr),e(re,Z5),e(Z5,A6e),e(A6e,ROr),e(Z5,POr),e(Z5,rre),e(rre,BOr),e(Z5,IOr),e(re,NOr),e(re,ew),e(ew,L6e),e(L6e,qOr),e(ew,jOr),e(ew,tre),e(tre,DOr),e(ew,GOr),e(re,OOr),e(re,ow),e(ow,y6e),e(y6e,VOr),e(ow,XOr),e(ow,are),e(are,zOr),e(ow,QOr),e(re,WOr),e(re,rw),e(rw,x6e),e(x6e,UOr),e(rw,HOr),e(rw,nre),e(nre,JOr),e(rw,YOr),e(re,KOr),e(re,tw),e(tw,$6e),e($6e,ZOr),e(tw,eVr),e(tw,sre),e(sre,oVr),e(tw,rVr),e(re,tVr),e(re,aw),e(aw,k6e),e(k6e,aVr),e(aw,nVr),e(aw,lre),e(lre,sVr),e(aw,lVr),e(re,iVr),e(re,nw),e(nw,S6e),e(S6e,dVr),e(nw,cVr),e(nw,ire),e(ire,fVr),e(nw,mVr),e(re,gVr),e(re,sw),e(sw,R6e),e(R6e,hVr),e(sw,uVr),e(sw,dre),e(dre,pVr),e(sw,_Vr),e(re,vVr),e(re,lw),e(lw,P6e),e(P6e,bVr),e(lw,FVr),e(lw,cre),e(cre,TVr),e(lw,MVr),e(re,EVr),e(re,iw),e(iw,B6e),e(B6e,CVr),e(iw,wVr),e(iw,fre),e(fre,AVr),e(iw,LVr),e(re,yVr),e(re,dw),e(dw,I6e),e(I6e,xVr),e(dw,$Vr),e(dw,mre),e(mre,kVr),e(dw,SVr),e(re,RVr),e(re,cw),e(cw,N6e),e(N6e,PVr),e(cw,BVr),e(cw,gre),e(gre,IVr),e(cw,NVr),e(re,qVr),e(re,fw),e(fw,q6e),e(q6e,jVr),e(fw,DVr),e(fw,hre),e(hre,GVr),e(fw,OVr),e(re,VVr),e(re,mw),e(mw,j6e),e(j6e,XVr),e(mw,zVr),e(mw,ure),e(ure,QVr),e(mw,WVr),e(re,UVr),e(re,gw),e(gw,D6e),e(D6e,HVr),e(gw,JVr),e(gw,pre),e(pre,YVr),e(gw,KVr),e(re,ZVr),e(re,hw),e(hw,G6e),e(G6e,eXr),e(hw,oXr),e(hw,_re),e(_re,rXr),e(hw,tXr),e(re,aXr),e(re,uw),e(uw,O6e),e(O6e,nXr),e(uw,sXr),e(uw,vre),e(vre,lXr),e(uw,iXr),e(re,dXr),e(re,pw),e(pw,V6e),e(V6e,cXr),e(pw,fXr),e(pw,bre),e(bre,mXr),e(pw,gXr),e(re,hXr),e(re,_w),e(_w,X6e),e(X6e,uXr),e(_w,pXr),e(_w,Fre),e(Fre,_Xr),e(_w,vXr),e(re,bXr),e(re,vw),e(vw,z6e),e(z6e,FXr),e(vw,TXr),e(vw,Tre),e(Tre,MXr),e(vw,EXr),e(re,CXr),e(re,bw),e(bw,Q6e),e(Q6e,wXr),e(bw,AXr),e(bw,Mre),e(Mre,LXr),e(bw,yXr),e(re,xXr),e(re,Fw),e(Fw,W6e),e(W6e,$Xr),e(Fw,kXr),e(Fw,Ere),e(Ere,SXr),e(Fw,RXr),e(re,PXr),e(re,Tw),e(Tw,U6e),e(U6e,BXr),e(Tw,IXr),e(Tw,Cre),e(Cre,NXr),e(Tw,qXr),e(re,jXr),e(re,Mw),e(Mw,H6e),e(H6e,DXr),e(Mw,GXr),e(Mw,wre),e(wre,OXr),e(Mw,VXr),e(re,XXr),e(re,Ew),e(Ew,J6e),e(J6e,zXr),e(Ew,QXr),e(Ew,Are),e(Are,WXr),e(Ew,UXr),e(Vr,HXr),M(Cw,Vr,null),v(f,aZe,_),v(f,gf,_),e(gf,ww),e(ww,Y6e),M(nS,Y6e,null),e(gf,JXr),e(gf,K6e),e(K6e,YXr),v(f,nZe,_),v(f,hr,_),M(sS,hr,null),e(hr,KXr),e(hr,hf),e(hf,ZXr),e(hf,Lre),e(Lre,ezr),e(hf,ozr),e(hf,yre),e(yre,rzr),e(hf,tzr),e(hr,azr),e(hr,lS),e(lS,nzr),e(lS,Z6e),e(Z6e,szr),e(lS,lzr),e(hr,izr),e(hr,Kt),M(iS,Kt,null),e(Kt,dzr),e(Kt,e7e),e(e7e,czr),e(Kt,fzr),e(Kt,uf),e(uf,mzr),e(uf,o7e),e(o7e,gzr),e(uf,hzr),e(uf,xre),e(xre,uzr),e(uf,pzr),e(Kt,_zr),M(Aw,Kt,null),e(hr,vzr),e(hr,Xr),M(dS,Xr,null),e(Xr,bzr),e(Xr,r7e),e(r7e,Fzr),e(Xr,Tzr),e(Xr,Sn),e(Sn,Mzr),e(Sn,t7e),e(t7e,Ezr),e(Sn,Czr),e(Sn,a7e),e(a7e,wzr),e(Sn,Azr),e(Sn,n7e),e(n7e,Lzr),e(Sn,yzr),e(Xr,xzr),e(Xr,be),e(be,Lw),e(Lw,s7e),e(s7e,$zr),e(Lw,kzr),e(Lw,$re),e($re,Szr),e(Lw,Rzr),e(be,Pzr),e(be,yw),e(yw,l7e),e(l7e,Bzr),e(yw,Izr),e(yw,kre),e(kre,Nzr),e(yw,qzr),e(be,jzr),e(be,xw),e(xw,i7e),e(i7e,Dzr),e(xw,Gzr),e(xw,Sre),e(Sre,Ozr),e(xw,Vzr),e(be,Xzr),e(be,$w),e($w,d7e),e(d7e,zzr),e($w,Qzr),e($w,Rre),e(Rre,Wzr),e($w,Uzr),e(be,Hzr),e(be,kw),e(kw,c7e),e(c7e,Jzr),e(kw,Yzr),e(kw,Pre),e(Pre,Kzr),e(kw,Zzr),e(be,eQr),e(be,Sw),e(Sw,f7e),e(f7e,oQr),e(Sw,rQr),e(Sw,Bre),e(Bre,tQr),e(Sw,aQr),e(be,nQr),e(be,Rw),e(Rw,m7e),e(m7e,sQr),e(Rw,lQr),e(Rw,Ire),e(Ire,iQr),e(Rw,dQr),e(be,cQr),e(be,Pw),e(Pw,g7e),e(g7e,fQr),e(Pw,mQr),e(Pw,Nre),e(Nre,gQr),e(Pw,hQr),e(be,uQr),e(be,Bw),e(Bw,h7e),e(h7e,pQr),e(Bw,_Qr),e(Bw,qre),e(qre,vQr),e(Bw,bQr),e(be,FQr),e(be,Iw),e(Iw,u7e),e(u7e,TQr),e(Iw,MQr),e(Iw,jre),e(jre,EQr),e(Iw,CQr),e(be,wQr),e(be,Nw),e(Nw,p7e),e(p7e,AQr),e(Nw,LQr),e(Nw,Dre),e(Dre,yQr),e(Nw,xQr),e(be,$Qr),e(be,qw),e(qw,_7e),e(_7e,kQr),e(qw,SQr),e(qw,Gre),e(Gre,RQr),e(qw,PQr),e(be,BQr),e(be,jw),e(jw,v7e),e(v7e,IQr),e(jw,NQr),e(jw,Ore),e(Ore,qQr),e(jw,jQr),e(be,DQr),e(be,Dw),e(Dw,b7e),e(b7e,GQr),e(Dw,OQr),e(Dw,Vre),e(Vre,VQr),e(Dw,XQr),e(be,zQr),e(be,Gw),e(Gw,F7e),e(F7e,QQr),e(Gw,WQr),e(Gw,Xre),e(Xre,UQr),e(Gw,HQr),e(be,JQr),e(be,Ow),e(Ow,T7e),e(T7e,YQr),e(Ow,KQr),e(Ow,zre),e(zre,ZQr),e(Ow,eWr),e(be,oWr),e(be,Vw),e(Vw,M7e),e(M7e,rWr),e(Vw,tWr),e(Vw,Qre),e(Qre,aWr),e(Vw,nWr),e(Xr,sWr),M(Xw,Xr,null),v(f,sZe,_),v(f,pf,_),e(pf,zw),e(zw,E7e),M(cS,E7e,null),e(pf,lWr),e(pf,C7e),e(C7e,iWr),v(f,lZe,_),v(f,ur,_),M(fS,ur,null),e(ur,dWr),e(ur,_f),e(_f,cWr),e(_f,Wre),e(Wre,fWr),e(_f,mWr),e(_f,Ure),e(Ure,gWr),e(_f,hWr),e(ur,uWr),e(ur,mS),e(mS,pWr),e(mS,w7e),e(w7e,_Wr),e(mS,vWr),e(ur,bWr),e(ur,Zt),M(gS,Zt,null),e(Zt,FWr),e(Zt,A7e),e(A7e,TWr),e(Zt,MWr),e(Zt,vf),e(vf,EWr),e(vf,L7e),e(L7e,CWr),e(vf,wWr),e(vf,Hre),e(Hre,AWr),e(vf,LWr),e(Zt,yWr),M(Qw,Zt,null),e(ur,xWr),e(ur,zr),M(hS,zr,null),e(zr,$Wr),e(zr,y7e),e(y7e,kWr),e(zr,SWr),e(zr,Rn),e(Rn,RWr),e(Rn,x7e),e(x7e,PWr),e(Rn,BWr),e(Rn,$7e),e($7e,IWr),e(Rn,NWr),e(Rn,k7e),e(k7e,qWr),e(Rn,jWr),e(zr,DWr),e(zr,uS),e(uS,Ww),e(Ww,S7e),e(S7e,GWr),e(Ww,OWr),e(Ww,Jre),e(Jre,VWr),e(Ww,XWr),e(uS,zWr),e(uS,Uw),e(Uw,R7e),e(R7e,QWr),e(Uw,WWr),e(Uw,Yre),e(Yre,UWr),e(Uw,HWr),e(zr,JWr),M(Hw,zr,null),v(f,iZe,_),v(f,bf,_),e(bf,Jw),e(Jw,P7e),M(pS,P7e,null),e(bf,YWr),e(bf,B7e),e(B7e,KWr),v(f,dZe,_),v(f,pr,_),M(_S,pr,null),e(pr,ZWr),e(pr,Ff),e(Ff,eUr),e(Ff,Kre),e(Kre,oUr),e(Ff,rUr),e(Ff,Zre),e(Zre,tUr),e(Ff,aUr),e(pr,nUr),e(pr,vS),e(vS,sUr),e(vS,I7e),e(I7e,lUr),e(vS,iUr),e(pr,dUr),e(pr,ea),M(bS,ea,null),e(ea,cUr),e(ea,N7e),e(N7e,fUr),e(ea,mUr),e(ea,Tf),e(Tf,gUr),e(Tf,q7e),e(q7e,hUr),e(Tf,uUr),e(Tf,ete),e(ete,pUr),e(Tf,_Ur),e(ea,vUr),M(Yw,ea,null),e(pr,bUr),e(pr,Qr),M(FS,Qr,null),e(Qr,FUr),e(Qr,j7e),e(j7e,TUr),e(Qr,MUr),e(Qr,Pn),e(Pn,EUr),e(Pn,D7e),e(D7e,CUr),e(Pn,wUr),e(Pn,G7e),e(G7e,AUr),e(Pn,LUr),e(Pn,O7e),e(O7e,yUr),e(Pn,xUr),e(Qr,$Ur),e(Qr,V7e),e(V7e,Kw),e(Kw,X7e),e(X7e,kUr),e(Kw,SUr),e(Kw,ote),e(ote,RUr),e(Kw,PUr),e(Qr,BUr),M(Zw,Qr,null),v(f,cZe,_),v(f,Mf,_),e(Mf,eA),e(eA,z7e),M(TS,z7e,null),e(Mf,IUr),e(Mf,Q7e),e(Q7e,NUr),v(f,fZe,_),v(f,_r,_),M(MS,_r,null),e(_r,qUr),e(_r,Ef),e(Ef,jUr),e(Ef,rte),e(rte,DUr),e(Ef,GUr),e(Ef,tte),e(tte,OUr),e(Ef,VUr),e(_r,XUr),e(_r,ES),e(ES,zUr),e(ES,W7e),e(W7e,QUr),e(ES,WUr),e(_r,UUr),e(_r,oa),M(CS,oa,null),e(oa,HUr),e(oa,U7e),e(U7e,JUr),e(oa,YUr),e(oa,Cf),e(Cf,KUr),e(Cf,H7e),e(H7e,ZUr),e(Cf,eHr),e(Cf,ate),e(ate,oHr),e(Cf,rHr),e(oa,tHr),M(oA,oa,null),e(_r,aHr),e(_r,Wr),M(wS,Wr,null),e(Wr,nHr),e(Wr,J7e),e(J7e,sHr),e(Wr,lHr),e(Wr,Bn),e(Bn,iHr),e(Bn,Y7e),e(Y7e,dHr),e(Bn,cHr),e(Bn,K7e),e(K7e,fHr),e(Bn,mHr),e(Bn,Z7e),e(Z7e,gHr),e(Bn,hHr),e(Wr,uHr),e(Wr,eLe),e(eLe,rA),e(rA,oLe),e(oLe,pHr),e(rA,_Hr),e(rA,nte),e(nte,vHr),e(rA,bHr),e(Wr,FHr),M(tA,Wr,null),v(f,mZe,_),v(f,wf,_),e(wf,aA),e(aA,rLe),M(AS,rLe,null),e(wf,THr),e(wf,tLe),e(tLe,MHr),v(f,gZe,_),v(f,vr,_),M(LS,vr,null),e(vr,EHr),e(vr,Af),e(Af,CHr),e(Af,ste),e(ste,wHr),e(Af,AHr),e(Af,lte),e(lte,LHr),e(Af,yHr),e(vr,xHr),e(vr,yS),e(yS,$Hr),e(yS,aLe),e(aLe,kHr),e(yS,SHr),e(vr,RHr),e(vr,ra),M(xS,ra,null),e(ra,PHr),e(ra,nLe),e(nLe,BHr),e(ra,IHr),e(ra,Lf),e(Lf,NHr),e(Lf,sLe),e(sLe,qHr),e(Lf,jHr),e(Lf,ite),e(ite,DHr),e(Lf,GHr),e(ra,OHr),M(nA,ra,null),e(vr,VHr),e(vr,Ur),M($S,Ur,null),e(Ur,XHr),e(Ur,lLe),e(lLe,zHr),e(Ur,QHr),e(Ur,In),e(In,WHr),e(In,iLe),e(iLe,UHr),e(In,HHr),e(In,dLe),e(dLe,JHr),e(In,YHr),e(In,cLe),e(cLe,KHr),e(In,ZHr),e(Ur,eJr),e(Ur,de),e(de,sA),e(sA,fLe),e(fLe,oJr),e(sA,rJr),e(sA,dte),e(dte,tJr),e(sA,aJr),e(de,nJr),e(de,lA),e(lA,mLe),e(mLe,sJr),e(lA,lJr),e(lA,cte),e(cte,iJr),e(lA,dJr),e(de,cJr),e(de,iA),e(iA,gLe),e(gLe,fJr),e(iA,mJr),e(iA,fte),e(fte,gJr),e(iA,hJr),e(de,uJr),e(de,dA),e(dA,hLe),e(hLe,pJr),e(dA,_Jr),e(dA,mte),e(mte,vJr),e(dA,bJr),e(de,FJr),e(de,cA),e(cA,uLe),e(uLe,TJr),e(cA,MJr),e(cA,gte),e(gte,EJr),e(cA,CJr),e(de,wJr),e(de,fA),e(fA,pLe),e(pLe,AJr),e(fA,LJr),e(fA,hte),e(hte,yJr),e(fA,xJr),e(de,$Jr),e(de,mA),e(mA,_Le),e(_Le,kJr),e(mA,SJr),e(mA,ute),e(ute,RJr),e(mA,PJr),e(de,BJr),e(de,gA),e(gA,vLe),e(vLe,IJr),e(gA,NJr),e(gA,pte),e(pte,qJr),e(gA,jJr),e(de,DJr),e(de,hA),e(hA,bLe),e(bLe,GJr),e(hA,OJr),e(hA,_te),e(_te,VJr),e(hA,XJr),e(de,zJr),e(de,uA),e(uA,FLe),e(FLe,QJr),e(uA,WJr),e(uA,vte),e(vte,UJr),e(uA,HJr),e(de,JJr),e(de,pA),e(pA,TLe),e(TLe,YJr),e(pA,KJr),e(pA,bte),e(bte,ZJr),e(pA,eYr),e(de,oYr),e(de,_A),e(_A,MLe),e(MLe,rYr),e(_A,tYr),e(_A,Fte),e(Fte,aYr),e(_A,nYr),e(de,sYr),e(de,vA),e(vA,ELe),e(ELe,lYr),e(vA,iYr),e(vA,Tte),e(Tte,dYr),e(vA,cYr),e(de,fYr),e(de,bA),e(bA,CLe),e(CLe,mYr),e(bA,gYr),e(bA,Mte),e(Mte,hYr),e(bA,uYr),e(de,pYr),e(de,FA),e(FA,wLe),e(wLe,_Yr),e(FA,vYr),e(FA,Ete),e(Ete,bYr),e(FA,FYr),e(de,TYr),e(de,TA),e(TA,ALe),e(ALe,MYr),e(TA,EYr),e(TA,Cte),e(Cte,CYr),e(TA,wYr),e(de,AYr),e(de,MA),e(MA,LLe),e(LLe,LYr),e(MA,yYr),e(MA,wte),e(wte,xYr),e(MA,$Yr),e(de,kYr),e(de,EA),e(EA,yLe),e(yLe,SYr),e(EA,RYr),e(EA,Ate),e(Ate,PYr),e(EA,BYr),e(de,IYr),e(de,CA),e(CA,xLe),e(xLe,NYr),e(CA,qYr),e(CA,Lte),e(Lte,jYr),e(CA,DYr),e(de,GYr),e(de,wA),e(wA,$Le),e($Le,OYr),e(wA,VYr),e(wA,yte),e(yte,XYr),e(wA,zYr),e(de,QYr),e(de,AA),e(AA,kLe),e(kLe,WYr),e(AA,UYr),e(AA,xte),e(xte,HYr),e(AA,JYr),e(Ur,YYr),M(LA,Ur,null),v(f,hZe,_),v(f,yf,_),e(yf,yA),e(yA,SLe),M(kS,SLe,null),e(yf,KYr),e(yf,RLe),e(RLe,ZYr),v(f,uZe,_),v(f,br,_),M(SS,br,null),e(br,eKr),e(br,xf),e(xf,oKr),e(xf,$te),e($te,rKr),e(xf,tKr),e(xf,kte),e(kte,aKr),e(xf,nKr),e(br,sKr),e(br,RS),e(RS,lKr),e(RS,PLe),e(PLe,iKr),e(RS,dKr),e(br,cKr),e(br,ta),M(PS,ta,null),e(ta,fKr),e(ta,BLe),e(BLe,mKr),e(ta,gKr),e(ta,$f),e($f,hKr),e($f,ILe),e(ILe,uKr),e($f,pKr),e($f,Ste),e(Ste,_Kr),e($f,vKr),e(ta,bKr),M(xA,ta,null),e(br,FKr),e(br,Hr),M(BS,Hr,null),e(Hr,TKr),e(Hr,NLe),e(NLe,MKr),e(Hr,EKr),e(Hr,Nn),e(Nn,CKr),e(Nn,qLe),e(qLe,wKr),e(Nn,AKr),e(Nn,jLe),e(jLe,LKr),e(Nn,yKr),e(Nn,DLe),e(DLe,xKr),e(Nn,$Kr),e(Hr,kKr),e(Hr,ce),e(ce,$A),e($A,GLe),e(GLe,SKr),e($A,RKr),e($A,Rte),e(Rte,PKr),e($A,BKr),e(ce,IKr),e(ce,kA),e(kA,OLe),e(OLe,NKr),e(kA,qKr),e(kA,Pte),e(Pte,jKr),e(kA,DKr),e(ce,GKr),e(ce,SA),e(SA,VLe),e(VLe,OKr),e(SA,VKr),e(SA,Bte),e(Bte,XKr),e(SA,zKr),e(ce,QKr),e(ce,RA),e(RA,XLe),e(XLe,WKr),e(RA,UKr),e(RA,Ite),e(Ite,HKr),e(RA,JKr),e(ce,YKr),e(ce,PA),e(PA,zLe),e(zLe,KKr),e(PA,ZKr),e(PA,Nte),e(Nte,eZr),e(PA,oZr),e(ce,rZr),e(ce,BA),e(BA,QLe),e(QLe,tZr),e(BA,aZr),e(BA,qte),e(qte,nZr),e(BA,sZr),e(ce,lZr),e(ce,IA),e(IA,WLe),e(WLe,iZr),e(IA,dZr),e(IA,jte),e(jte,cZr),e(IA,fZr),e(ce,mZr),e(ce,NA),e(NA,ULe),e(ULe,gZr),e(NA,hZr),e(NA,Dte),e(Dte,uZr),e(NA,pZr),e(ce,_Zr),e(ce,qA),e(qA,HLe),e(HLe,vZr),e(qA,bZr),e(qA,Gte),e(Gte,FZr),e(qA,TZr),e(ce,MZr),e(ce,jA),e(jA,JLe),e(JLe,EZr),e(jA,CZr),e(jA,Ote),e(Ote,wZr),e(jA,AZr),e(ce,LZr),e(ce,DA),e(DA,YLe),e(YLe,yZr),e(DA,xZr),e(DA,Vte),e(Vte,$Zr),e(DA,kZr),e(ce,SZr),e(ce,GA),e(GA,KLe),e(KLe,RZr),e(GA,PZr),e(GA,Xte),e(Xte,BZr),e(GA,IZr),e(ce,NZr),e(ce,OA),e(OA,ZLe),e(ZLe,qZr),e(OA,jZr),e(OA,zte),e(zte,DZr),e(OA,GZr),e(ce,OZr),e(ce,VA),e(VA,eye),e(eye,VZr),e(VA,XZr),e(VA,Qte),e(Qte,zZr),e(VA,QZr),e(ce,WZr),e(ce,XA),e(XA,oye),e(oye,UZr),e(XA,HZr),e(XA,Wte),e(Wte,JZr),e(XA,YZr),e(ce,KZr),e(ce,zA),e(zA,rye),e(rye,ZZr),e(zA,eet),e(zA,Ute),e(Ute,oet),e(zA,ret),e(ce,tet),e(ce,QA),e(QA,tye),e(tye,aet),e(QA,net),e(QA,Hte),e(Hte,set),e(QA,iet),e(ce,det),e(ce,WA),e(WA,aye),e(aye,cet),e(WA,fet),e(WA,Jte),e(Jte,met),e(WA,get),e(ce,het),e(ce,UA),e(UA,nye),e(nye,uet),e(UA,pet),e(UA,Yte),e(Yte,_et),e(UA,vet),e(ce,bet),e(ce,HA),e(HA,sye),e(sye,Fet),e(HA,Tet),e(HA,Kte),e(Kte,Met),e(HA,Eet),e(ce,Cet),e(ce,JA),e(JA,lye),e(lye,wet),e(JA,Aet),e(JA,Zte),e(Zte,Let),e(JA,yet),e(Hr,xet),M(YA,Hr,null),v(f,pZe,_),v(f,kf,_),e(kf,KA),e(KA,iye),M(IS,iye,null),e(kf,$et),e(kf,dye),e(dye,ket),v(f,_Ze,_),v(f,Fr,_),M(NS,Fr,null),e(Fr,Set),e(Fr,Sf),e(Sf,Ret),e(Sf,eae),e(eae,Pet),e(Sf,Bet),e(Sf,oae),e(oae,Iet),e(Sf,Net),e(Fr,qet),e(Fr,qS),e(qS,jet),e(qS,cye),e(cye,Det),e(qS,Get),e(Fr,Oet),e(Fr,aa),M(jS,aa,null),e(aa,Vet),e(aa,fye),e(fye,Xet),e(aa,zet),e(aa,Rf),e(Rf,Qet),e(Rf,mye),e(mye,Wet),e(Rf,Uet),e(Rf,rae),e(rae,Het),e(Rf,Jet),e(aa,Yet),M(ZA,aa,null),e(Fr,Ket),e(Fr,Jr),M(DS,Jr,null),e(Jr,Zet),e(Jr,gye),e(gye,eot),e(Jr,oot),e(Jr,qn),e(qn,rot),e(qn,hye),e(hye,tot),e(qn,aot),e(qn,uye),e(uye,not),e(qn,sot),e(qn,pye),e(pye,lot),e(qn,iot),e(Jr,dot),e(Jr,_ye),e(_ye,e6),e(e6,vye),e(vye,cot),e(e6,fot),e(e6,tae),e(tae,mot),e(e6,got),e(Jr,hot),M(o6,Jr,null),v(f,vZe,_),v(f,Pf,_),e(Pf,r6),e(r6,bye),M(GS,bye,null),e(Pf,uot),e(Pf,Fye),e(Fye,pot),v(f,bZe,_),v(f,Tr,_),M(OS,Tr,null),e(Tr,_ot),e(Tr,Bf),e(Bf,vot),e(Bf,aae),e(aae,bot),e(Bf,Fot),e(Bf,nae),e(nae,Tot),e(Bf,Mot),e(Tr,Eot),e(Tr,VS),e(VS,Cot),e(VS,Tye),e(Tye,wot),e(VS,Aot),e(Tr,Lot),e(Tr,na),M(XS,na,null),e(na,yot),e(na,Mye),e(Mye,xot),e(na,$ot),e(na,If),e(If,kot),e(If,Eye),e(Eye,Sot),e(If,Rot),e(If,sae),e(sae,Pot),e(If,Bot),e(na,Iot),M(t6,na,null),e(Tr,Not),e(Tr,Yr),M(zS,Yr,null),e(Yr,qot),e(Yr,Cye),e(Cye,jot),e(Yr,Dot),e(Yr,jn),e(jn,Got),e(jn,wye),e(wye,Oot),e(jn,Vot),e(jn,Aye),e(Aye,Xot),e(jn,zot),e(jn,Lye),e(Lye,Qot),e(jn,Wot),e(Yr,Uot),e(Yr,yye),e(yye,a6),e(a6,xye),e(xye,Hot),e(a6,Jot),e(a6,lae),e(lae,Yot),e(a6,Kot),e(Yr,Zot),M(n6,Yr,null),v(f,FZe,_),v(f,Nf,_),e(Nf,s6),e(s6,$ye),M(QS,$ye,null),e(Nf,ert),e(Nf,kye),e(kye,ort),v(f,TZe,_),v(f,Mr,_),M(WS,Mr,null),e(Mr,rrt),e(Mr,qf),e(qf,trt),e(qf,iae),e(iae,art),e(qf,nrt),e(qf,dae),e(dae,srt),e(qf,lrt),e(Mr,irt),e(Mr,US),e(US,drt),e(US,Sye),e(Sye,crt),e(US,frt),e(Mr,mrt),e(Mr,sa),M(HS,sa,null),e(sa,grt),e(sa,Rye),e(Rye,hrt),e(sa,urt),e(sa,jf),e(jf,prt),e(jf,Pye),e(Pye,_rt),e(jf,vrt),e(jf,cae),e(cae,brt),e(jf,Frt),e(sa,Trt),M(l6,sa,null),e(Mr,Mrt),e(Mr,Kr),M(JS,Kr,null),e(Kr,Ert),e(Kr,Bye),e(Bye,Crt),e(Kr,wrt),e(Kr,Dn),e(Dn,Art),e(Dn,Iye),e(Iye,Lrt),e(Dn,yrt),e(Dn,Nye),e(Nye,xrt),e(Dn,$rt),e(Dn,qye),e(qye,krt),e(Dn,Srt),e(Kr,Rrt),e(Kr,te),e(te,i6),e(i6,jye),e(jye,Prt),e(i6,Brt),e(i6,fae),e(fae,Irt),e(i6,Nrt),e(te,qrt),e(te,d6),e(d6,Dye),e(Dye,jrt),e(d6,Drt),e(d6,mae),e(mae,Grt),e(d6,Ort),e(te,Vrt),e(te,c6),e(c6,Gye),e(Gye,Xrt),e(c6,zrt),e(c6,gae),e(gae,Qrt),e(c6,Wrt),e(te,Urt),e(te,f6),e(f6,Oye),e(Oye,Hrt),e(f6,Jrt),e(f6,hae),e(hae,Yrt),e(f6,Krt),e(te,Zrt),e(te,m6),e(m6,Vye),e(Vye,ett),e(m6,ott),e(m6,uae),e(uae,rtt),e(m6,ttt),e(te,att),e(te,g6),e(g6,Xye),e(Xye,ntt),e(g6,stt),e(g6,pae),e(pae,ltt),e(g6,itt),e(te,dtt),e(te,h6),e(h6,zye),e(zye,ctt),e(h6,ftt),e(h6,_ae),e(_ae,mtt),e(h6,gtt),e(te,htt),e(te,u6),e(u6,Qye),e(Qye,utt),e(u6,ptt),e(u6,vae),e(vae,_tt),e(u6,vtt),e(te,btt),e(te,p6),e(p6,Wye),e(Wye,Ftt),e(p6,Ttt),e(p6,bae),e(bae,Mtt),e(p6,Ett),e(te,Ctt),e(te,_6),e(_6,Uye),e(Uye,wtt),e(_6,Att),e(_6,Fae),e(Fae,Ltt),e(_6,ytt),e(te,xtt),e(te,v6),e(v6,Hye),e(Hye,$tt),e(v6,ktt),e(v6,Tae),e(Tae,Stt),e(v6,Rtt),e(te,Ptt),e(te,b6),e(b6,Jye),e(Jye,Btt),e(b6,Itt),e(b6,Mae),e(Mae,Ntt),e(b6,qtt),e(te,jtt),e(te,F6),e(F6,Yye),e(Yye,Dtt),e(F6,Gtt),e(F6,Eae),e(Eae,Ott),e(F6,Vtt),e(te,Xtt),e(te,T6),e(T6,Kye),e(Kye,ztt),e(T6,Qtt),e(T6,Cae),e(Cae,Wtt),e(T6,Utt),e(te,Htt),e(te,M6),e(M6,Zye),e(Zye,Jtt),e(M6,Ytt),e(M6,wae),e(wae,Ktt),e(M6,Ztt),e(te,eat),e(te,E6),e(E6,e8e),e(e8e,oat),e(E6,rat),e(E6,Aae),e(Aae,tat),e(E6,aat),e(te,nat),e(te,C6),e(C6,o8e),e(o8e,sat),e(C6,lat),e(C6,Lae),e(Lae,iat),e(C6,dat),e(te,cat),e(te,w6),e(w6,r8e),e(r8e,fat),e(w6,mat),e(w6,yae),e(yae,gat),e(w6,hat),e(te,uat),e(te,A6),e(A6,t8e),e(t8e,pat),e(A6,_at),e(A6,xae),e(xae,vat),e(A6,bat),e(te,Fat),e(te,L6),e(L6,a8e),e(a8e,Tat),e(L6,Mat),e(L6,$ae),e($ae,Eat),e(L6,Cat),e(te,wat),e(te,y6),e(y6,n8e),e(n8e,Aat),e(y6,Lat),e(y6,kae),e(kae,yat),e(y6,xat),e(te,$at),e(te,x6),e(x6,s8e),e(s8e,kat),e(x6,Sat),e(x6,Sae),e(Sae,Rat),e(x6,Pat),e(te,Bat),e(te,$6),e($6,l8e),e(l8e,Iat),e($6,Nat),e($6,Rae),e(Rae,qat),e($6,jat),e(te,Dat),e(te,k6),e(k6,i8e),e(i8e,Gat),e(k6,Oat),e(k6,Pae),e(Pae,Vat),e(k6,Xat),e(te,zat),e(te,S6),e(S6,d8e),e(d8e,Qat),e(S6,Wat),e(S6,Bae),e(Bae,Uat),e(S6,Hat),e(te,Jat),e(te,R6),e(R6,c8e),e(c8e,Yat),e(R6,Kat),e(R6,Iae),e(Iae,Zat),e(R6,ent),e(te,ont),e(te,P6),e(P6,f8e),e(f8e,rnt),e(P6,tnt),e(P6,Nae),e(Nae,ant),e(P6,nnt),e(Kr,snt),M(B6,Kr,null),v(f,MZe,_),v(f,Df,_),e(Df,I6),e(I6,m8e),M(YS,m8e,null),e(Df,lnt),e(Df,g8e),e(g8e,int),v(f,EZe,_),v(f,Er,_),M(KS,Er,null),e(Er,dnt),e(Er,Gf),e(Gf,cnt),e(Gf,qae),e(qae,fnt),e(Gf,mnt),e(Gf,jae),e(jae,gnt),e(Gf,hnt),e(Er,unt),e(Er,ZS),e(ZS,pnt),e(ZS,h8e),e(h8e,_nt),e(ZS,vnt),e(Er,bnt),e(Er,la),M(eR,la,null),e(la,Fnt),e(la,u8e),e(u8e,Tnt),e(la,Mnt),e(la,Of),e(Of,Ent),e(Of,p8e),e(p8e,Cnt),e(Of,wnt),e(Of,Dae),e(Dae,Ant),e(Of,Lnt),e(la,ynt),M(N6,la,null),e(Er,xnt),e(Er,Zr),M(oR,Zr,null),e(Zr,$nt),e(Zr,_8e),e(_8e,knt),e(Zr,Snt),e(Zr,Gn),e(Gn,Rnt),e(Gn,v8e),e(v8e,Pnt),e(Gn,Bnt),e(Gn,b8e),e(b8e,Int),e(Gn,Nnt),e(Gn,F8e),e(F8e,qnt),e(Gn,jnt),e(Zr,Dnt),e(Zr,xe),e(xe,q6),e(q6,T8e),e(T8e,Gnt),e(q6,Ont),e(q6,Gae),e(Gae,Vnt),e(q6,Xnt),e(xe,znt),e(xe,j6),e(j6,M8e),e(M8e,Qnt),e(j6,Wnt),e(j6,Oae),e(Oae,Unt),e(j6,Hnt),e(xe,Jnt),e(xe,D6),e(D6,E8e),e(E8e,Ynt),e(D6,Knt),e(D6,Vae),e(Vae,Znt),e(D6,est),e(xe,ost),e(xe,G6),e(G6,C8e),e(C8e,rst),e(G6,tst),e(G6,Xae),e(Xae,ast),e(G6,nst),e(xe,sst),e(xe,O6),e(O6,w8e),e(w8e,lst),e(O6,ist),e(O6,zae),e(zae,dst),e(O6,cst),e(xe,fst),e(xe,V6),e(V6,A8e),e(A8e,mst),e(V6,gst),e(V6,Qae),e(Qae,hst),e(V6,ust),e(xe,pst),e(xe,X6),e(X6,L8e),e(L8e,_st),e(X6,vst),e(X6,Wae),e(Wae,bst),e(X6,Fst),e(xe,Tst),e(xe,z6),e(z6,y8e),e(y8e,Mst),e(z6,Est),e(z6,Uae),e(Uae,Cst),e(z6,wst),e(xe,Ast),e(xe,Q6),e(Q6,x8e),e(x8e,Lst),e(Q6,yst),e(Q6,Hae),e(Hae,xst),e(Q6,$st),e(xe,kst),e(xe,W6),e(W6,$8e),e($8e,Sst),e(W6,Rst),e(W6,Jae),e(Jae,Pst),e(W6,Bst),e(Zr,Ist),M(U6,Zr,null),v(f,CZe,_),v(f,Vf,_),e(Vf,H6),e(H6,k8e),M(rR,k8e,null),e(Vf,Nst),e(Vf,S8e),e(S8e,qst),v(f,wZe,_),v(f,Cr,_),M(tR,Cr,null),e(Cr,jst),e(Cr,Xf),e(Xf,Dst),e(Xf,Yae),e(Yae,Gst),e(Xf,Ost),e(Xf,Kae),e(Kae,Vst),e(Xf,Xst),e(Cr,zst),e(Cr,aR),e(aR,Qst),e(aR,R8e),e(R8e,Wst),e(aR,Ust),e(Cr,Hst),e(Cr,ia),M(nR,ia,null),e(ia,Jst),e(ia,P8e),e(P8e,Yst),e(ia,Kst),e(ia,zf),e(zf,Zst),e(zf,B8e),e(B8e,elt),e(zf,olt),e(zf,Zae),e(Zae,rlt),e(zf,tlt),e(ia,alt),M(J6,ia,null),e(Cr,nlt),e(Cr,et),M(sR,et,null),e(et,slt),e(et,I8e),e(I8e,llt),e(et,ilt),e(et,On),e(On,dlt),e(On,N8e),e(N8e,clt),e(On,flt),e(On,q8e),e(q8e,mlt),e(On,glt),e(On,j8e),e(j8e,hlt),e(On,ult),e(et,plt),e(et,Ee),e(Ee,Y6),e(Y6,D8e),e(D8e,_lt),e(Y6,vlt),e(Y6,ene),e(ene,blt),e(Y6,Flt),e(Ee,Tlt),e(Ee,K6),e(K6,G8e),e(G8e,Mlt),e(K6,Elt),e(K6,one),e(one,Clt),e(K6,wlt),e(Ee,Alt),e(Ee,Z6),e(Z6,O8e),e(O8e,Llt),e(Z6,ylt),e(Z6,rne),e(rne,xlt),e(Z6,$lt),e(Ee,klt),e(Ee,e7),e(e7,V8e),e(V8e,Slt),e(e7,Rlt),e(e7,tne),e(tne,Plt),e(e7,Blt),e(Ee,Ilt),e(Ee,o7),e(o7,X8e),e(X8e,Nlt),e(o7,qlt),e(o7,ane),e(ane,jlt),e(o7,Dlt),e(Ee,Glt),e(Ee,r7),e(r7,z8e),e(z8e,Olt),e(r7,Vlt),e(r7,nne),e(nne,Xlt),e(r7,zlt),e(Ee,Qlt),e(Ee,t7),e(t7,Q8e),e(Q8e,Wlt),e(t7,Ult),e(t7,sne),e(sne,Hlt),e(t7,Jlt),e(Ee,Ylt),e(Ee,a7),e(a7,W8e),e(W8e,Klt),e(a7,Zlt),e(a7,lne),e(lne,eit),e(a7,oit),e(Ee,rit),e(Ee,n7),e(n7,U8e),e(U8e,tit),e(n7,ait),e(n7,ine),e(ine,nit),e(n7,sit),e(Ee,lit),e(Ee,s7),e(s7,H8e),e(H8e,iit),e(s7,dit),e(s7,dne),e(dne,cit),e(s7,fit),e(Ee,mit),e(Ee,l7),e(l7,J8e),e(J8e,git),e(l7,hit),e(l7,cne),e(cne,uit),e(l7,pit),e(Ee,_it),e(Ee,i7),e(i7,Y8e),e(Y8e,vit),e(i7,bit),e(i7,fne),e(fne,Fit),e(i7,Tit),e(Ee,Mit),e(Ee,d7),e(d7,K8e),e(K8e,Eit),e(d7,Cit),e(d7,mne),e(mne,wit),e(d7,Ait),e(et,Lit),M(c7,et,null),v(f,AZe,_),v(f,Qf,_),e(Qf,f7),e(f7,Z8e),M(lR,Z8e,null),e(Qf,yit),e(Qf,e9e),e(e9e,xit),v(f,LZe,_),v(f,wr,_),M(iR,wr,null),e(wr,$it),e(wr,Wf),e(Wf,kit),e(Wf,gne),e(gne,Sit),e(Wf,Rit),e(Wf,hne),e(hne,Pit),e(Wf,Bit),e(wr,Iit),e(wr,dR),e(dR,Nit),e(dR,o9e),e(o9e,qit),e(dR,jit),e(wr,Dit),e(wr,da),M(cR,da,null),e(da,Git),e(da,r9e),e(r9e,Oit),e(da,Vit),e(da,Uf),e(Uf,Xit),e(Uf,t9e),e(t9e,zit),e(Uf,Qit),e(Uf,une),e(une,Wit),e(Uf,Uit),e(da,Hit),M(m7,da,null),e(wr,Jit),e(wr,ot),M(fR,ot,null),e(ot,Yit),e(ot,a9e),e(a9e,Kit),e(ot,Zit),e(ot,Vn),e(Vn,edt),e(Vn,n9e),e(n9e,odt),e(Vn,rdt),e(Vn,s9e),e(s9e,tdt),e(Vn,adt),e(Vn,l9e),e(l9e,ndt),e(Vn,sdt),e(ot,ldt),e(ot,$e),e($e,g7),e(g7,i9e),e(i9e,idt),e(g7,ddt),e(g7,pne),e(pne,cdt),e(g7,fdt),e($e,mdt),e($e,h7),e(h7,d9e),e(d9e,gdt),e(h7,hdt),e(h7,_ne),e(_ne,udt),e(h7,pdt),e($e,_dt),e($e,u7),e(u7,c9e),e(c9e,vdt),e(u7,bdt),e(u7,vne),e(vne,Fdt),e(u7,Tdt),e($e,Mdt),e($e,p7),e(p7,f9e),e(f9e,Edt),e(p7,Cdt),e(p7,bne),e(bne,wdt),e(p7,Adt),e($e,Ldt),e($e,_7),e(_7,m9e),e(m9e,ydt),e(_7,xdt),e(_7,Fne),e(Fne,$dt),e(_7,kdt),e($e,Sdt),e($e,v7),e(v7,g9e),e(g9e,Rdt),e(v7,Pdt),e(v7,Tne),e(Tne,Bdt),e(v7,Idt),e($e,Ndt),e($e,b7),e(b7,h9e),e(h9e,qdt),e(b7,jdt),e(b7,Mne),e(Mne,Ddt),e(b7,Gdt),e($e,Odt),e($e,F7),e(F7,u9e),e(u9e,Vdt),e(F7,Xdt),e(F7,Ene),e(Ene,zdt),e(F7,Qdt),e($e,Wdt),e($e,T7),e(T7,p9e),e(p9e,Udt),e(T7,Hdt),e(T7,Cne),e(Cne,Jdt),e(T7,Ydt),e($e,Kdt),e($e,M7),e(M7,_9e),e(_9e,Zdt),e(M7,ect),e(M7,wne),e(wne,oct),e(M7,rct),e(ot,tct),M(E7,ot,null),v(f,yZe,_),v(f,Hf,_),e(Hf,C7),e(C7,v9e),M(mR,v9e,null),e(Hf,act),e(Hf,b9e),e(b9e,nct),v(f,xZe,_),v(f,Ar,_),M(gR,Ar,null),e(Ar,sct),e(Ar,Jf),e(Jf,lct),e(Jf,Ane),e(Ane,ict),e(Jf,dct),e(Jf,Lne),e(Lne,cct),e(Jf,fct),e(Ar,mct),e(Ar,hR),e(hR,gct),e(hR,F9e),e(F9e,hct),e(hR,uct),e(Ar,pct),e(Ar,ca),M(uR,ca,null),e(ca,_ct),e(ca,T9e),e(T9e,vct),e(ca,bct),e(ca,Yf),e(Yf,Fct),e(Yf,M9e),e(M9e,Tct),e(Yf,Mct),e(Yf,yne),e(yne,Ect),e(Yf,Cct),e(ca,wct),M(w7,ca,null),e(Ar,Act),e(Ar,rt),M(pR,rt,null),e(rt,Lct),e(rt,E9e),e(E9e,yct),e(rt,xct),e(rt,Xn),e(Xn,$ct),e(Xn,C9e),e(C9e,kct),e(Xn,Sct),e(Xn,w9e),e(w9e,Rct),e(Xn,Pct),e(Xn,A9e),e(A9e,Bct),e(Xn,Ict),e(rt,Nct),e(rt,ke),e(ke,A7),e(A7,L9e),e(L9e,qct),e(A7,jct),e(A7,xne),e(xne,Dct),e(A7,Gct),e(ke,Oct),e(ke,L7),e(L7,y9e),e(y9e,Vct),e(L7,Xct),e(L7,$ne),e($ne,zct),e(L7,Qct),e(ke,Wct),e(ke,y7),e(y7,x9e),e(x9e,Uct),e(y7,Hct),e(y7,kne),e(kne,Jct),e(y7,Yct),e(ke,Kct),e(ke,x7),e(x7,$9e),e($9e,Zct),e(x7,eft),e(x7,Sne),e(Sne,oft),e(x7,rft),e(ke,tft),e(ke,$7),e($7,k9e),e(k9e,aft),e($7,nft),e($7,Rne),e(Rne,sft),e($7,lft),e(ke,ift),e(ke,k7),e(k7,S9e),e(S9e,dft),e(k7,cft),e(k7,Pne),e(Pne,fft),e(k7,mft),e(ke,gft),e(ke,S7),e(S7,R9e),e(R9e,hft),e(S7,uft),e(S7,Bne),e(Bne,pft),e(S7,_ft),e(ke,vft),e(ke,R7),e(R7,P9e),e(P9e,bft),e(R7,Fft),e(R7,Ine),e(Ine,Tft),e(R7,Mft),e(ke,Eft),e(ke,P7),e(P7,B9e),e(B9e,Cft),e(P7,wft),e(P7,Nne),e(Nne,Aft),e(P7,Lft),e(ke,yft),e(ke,B7),e(B7,I9e),e(I9e,xft),e(B7,$ft),e(B7,qne),e(qne,kft),e(B7,Sft),e(rt,Rft),M(I7,rt,null),v(f,$Ze,_),v(f,Kf,_),e(Kf,N7),e(N7,N9e),M(_R,N9e,null),e(Kf,Pft),e(Kf,q9e),e(q9e,Bft),v(f,kZe,_),v(f,Lr,_),M(vR,Lr,null),e(Lr,Ift),e(Lr,Zf),e(Zf,Nft),e(Zf,jne),e(jne,qft),e(Zf,jft),e(Zf,Dne),e(Dne,Dft),e(Zf,Gft),e(Lr,Oft),e(Lr,bR),e(bR,Vft),e(bR,j9e),e(j9e,Xft),e(bR,zft),e(Lr,Qft),e(Lr,fa),M(FR,fa,null),e(fa,Wft),e(fa,D9e),e(D9e,Uft),e(fa,Hft),e(fa,em),e(em,Jft),e(em,G9e),e(G9e,Yft),e(em,Kft),e(em,Gne),e(Gne,Zft),e(em,emt),e(fa,omt),M(q7,fa,null),e(Lr,rmt),e(Lr,tt),M(TR,tt,null),e(tt,tmt),e(tt,O9e),e(O9e,amt),e(tt,nmt),e(tt,zn),e(zn,smt),e(zn,V9e),e(V9e,lmt),e(zn,imt),e(zn,X9e),e(X9e,dmt),e(zn,cmt),e(zn,z9e),e(z9e,fmt),e(zn,mmt),e(tt,gmt),e(tt,Se),e(Se,j7),e(j7,Q9e),e(Q9e,hmt),e(j7,umt),e(j7,One),e(One,pmt),e(j7,_mt),e(Se,vmt),e(Se,D7),e(D7,W9e),e(W9e,bmt),e(D7,Fmt),e(D7,Vne),e(Vne,Tmt),e(D7,Mmt),e(Se,Emt),e(Se,G7),e(G7,U9e),e(U9e,Cmt),e(G7,wmt),e(G7,Xne),e(Xne,Amt),e(G7,Lmt),e(Se,ymt),e(Se,O7),e(O7,H9e),e(H9e,xmt),e(O7,$mt),e(O7,zne),e(zne,kmt),e(O7,Smt),e(Se,Rmt),e(Se,V7),e(V7,J9e),e(J9e,Pmt),e(V7,Bmt),e(V7,Qne),e(Qne,Imt),e(V7,Nmt),e(Se,qmt),e(Se,X7),e(X7,Y9e),e(Y9e,jmt),e(X7,Dmt),e(X7,Wne),e(Wne,Gmt),e(X7,Omt),e(Se,Vmt),e(Se,z7),e(z7,K9e),e(K9e,Xmt),e(z7,zmt),e(z7,Une),e(Une,Qmt),e(z7,Wmt),e(Se,Umt),e(Se,Q7),e(Q7,Z9e),e(Z9e,Hmt),e(Q7,Jmt),e(Q7,Hne),e(Hne,Ymt),e(Q7,Kmt),e(Se,Zmt),e(Se,W7),e(W7,exe),e(exe,egt),e(W7,ogt),e(W7,Jne),e(Jne,rgt),e(W7,tgt),e(Se,agt),e(Se,U7),e(U7,oxe),e(oxe,ngt),e(U7,sgt),e(U7,Yne),e(Yne,lgt),e(U7,igt),e(tt,dgt),M(H7,tt,null),v(f,SZe,_),v(f,om,_),e(om,J7),e(J7,rxe),M(MR,rxe,null),e(om,cgt),e(om,txe),e(txe,fgt),v(f,RZe,_),v(f,yr,_),M(ER,yr,null),e(yr,mgt),e(yr,rm),e(rm,ggt),e(rm,Kne),e(Kne,hgt),e(rm,ugt),e(rm,Zne),e(Zne,pgt),e(rm,_gt),e(yr,vgt),e(yr,CR),e(CR,bgt),e(CR,axe),e(axe,Fgt),e(CR,Tgt),e(yr,Mgt),e(yr,ma),M(wR,ma,null),e(ma,Egt),e(ma,nxe),e(nxe,Cgt),e(ma,wgt),e(ma,tm),e(tm,Agt),e(tm,sxe),e(sxe,Lgt),e(tm,ygt),e(tm,ese),e(ese,xgt),e(tm,$gt),e(ma,kgt),M(Y7,ma,null),e(yr,Sgt),e(yr,at),M(AR,at,null),e(at,Rgt),e(at,lxe),e(lxe,Pgt),e(at,Bgt),e(at,Qn),e(Qn,Igt),e(Qn,ixe),e(ixe,Ngt),e(Qn,qgt),e(Qn,dxe),e(dxe,jgt),e(Qn,Dgt),e(Qn,cxe),e(cxe,Ggt),e(Qn,Ogt),e(at,Vgt),e(at,Re),e(Re,K7),e(K7,fxe),e(fxe,Xgt),e(K7,zgt),e(K7,ose),e(ose,Qgt),e(K7,Wgt),e(Re,Ugt),e(Re,Z7),e(Z7,mxe),e(mxe,Hgt),e(Z7,Jgt),e(Z7,rse),e(rse,Ygt),e(Z7,Kgt),e(Re,Zgt),e(Re,eL),e(eL,gxe),e(gxe,eht),e(eL,oht),e(eL,tse),e(tse,rht),e(eL,tht),e(Re,aht),e(Re,oL),e(oL,hxe),e(hxe,nht),e(oL,sht),e(oL,ase),e(ase,lht),e(oL,iht),e(Re,dht),e(Re,rL),e(rL,uxe),e(uxe,cht),e(rL,fht),e(rL,nse),e(nse,mht),e(rL,ght),e(Re,hht),e(Re,tL),e(tL,pxe),e(pxe,uht),e(tL,pht),e(tL,sse),e(sse,_ht),e(tL,vht),e(Re,bht),e(Re,aL),e(aL,_xe),e(_xe,Fht),e(aL,Tht),e(aL,lse),e(lse,Mht),e(aL,Eht),e(Re,Cht),e(Re,nL),e(nL,vxe),e(vxe,wht),e(nL,Aht),e(nL,ise),e(ise,Lht),e(nL,yht),e(Re,xht),e(Re,sL),e(sL,bxe),e(bxe,$ht),e(sL,kht),e(sL,dse),e(dse,Sht),e(sL,Rht),e(Re,Pht),e(Re,lL),e(lL,Fxe),e(Fxe,Bht),e(lL,Iht),e(lL,cse),e(cse,Nht),e(lL,qht),e(at,jht),M(iL,at,null),v(f,PZe,_),v(f,am,_),e(am,dL),e(dL,Txe),M(LR,Txe,null),e(am,Dht),e(am,Mxe),e(Mxe,Ght),v(f,BZe,_),v(f,xr,_),M(yR,xr,null),e(xr,Oht),e(xr,nm),e(nm,Vht),e(nm,fse),e(fse,Xht),e(nm,zht),e(nm,mse),e(mse,Qht),e(nm,Wht),e(xr,Uht),e(xr,xR),e(xR,Hht),e(xR,Exe),e(Exe,Jht),e(xR,Yht),e(xr,Kht),e(xr,ga),M($R,ga,null),e(ga,Zht),e(ga,Cxe),e(Cxe,eut),e(ga,out),e(ga,sm),e(sm,rut),e(sm,wxe),e(wxe,tut),e(sm,aut),e(sm,gse),e(gse,nut),e(sm,sut),e(ga,lut),M(cL,ga,null),e(xr,iut),e(xr,nt),M(kR,nt,null),e(nt,dut),e(nt,Axe),e(Axe,cut),e(nt,fut),e(nt,Wn),e(Wn,mut),e(Wn,Lxe),e(Lxe,gut),e(Wn,hut),e(Wn,yxe),e(yxe,uut),e(Wn,put),e(Wn,xxe),e(xxe,_ut),e(Wn,vut),e(nt,but),e(nt,Xe),e(Xe,fL),e(fL,$xe),e($xe,Fut),e(fL,Tut),e(fL,hse),e(hse,Mut),e(fL,Eut),e(Xe,Cut),e(Xe,mL),e(mL,kxe),e(kxe,wut),e(mL,Aut),e(mL,use),e(use,Lut),e(mL,yut),e(Xe,xut),e(Xe,gL),e(gL,Sxe),e(Sxe,$ut),e(gL,kut),e(gL,pse),e(pse,Sut),e(gL,Rut),e(Xe,Put),e(Xe,hL),e(hL,Rxe),e(Rxe,But),e(hL,Iut),e(hL,_se),e(_se,Nut),e(hL,qut),e(Xe,jut),e(Xe,uL),e(uL,Pxe),e(Pxe,Dut),e(uL,Gut),e(uL,vse),e(vse,Out),e(uL,Vut),e(Xe,Xut),e(Xe,pL),e(pL,Bxe),e(Bxe,zut),e(pL,Qut),e(pL,bse),e(bse,Wut),e(pL,Uut),e(Xe,Hut),e(Xe,_L),e(_L,Ixe),e(Ixe,Jut),e(_L,Yut),e(_L,Fse),e(Fse,Kut),e(_L,Zut),e(Xe,ept),e(Xe,vL),e(vL,Nxe),e(Nxe,opt),e(vL,rpt),e(vL,Tse),e(Tse,tpt),e(vL,apt),e(nt,npt),M(bL,nt,null),v(f,IZe,_),v(f,lm,_),e(lm,FL),e(FL,qxe),M(SR,qxe,null),e(lm,spt),e(lm,jxe),e(jxe,lpt),v(f,NZe,_),v(f,$r,_),M(RR,$r,null),e($r,ipt),e($r,im),e(im,dpt),e(im,Mse),e(Mse,cpt),e(im,fpt),e(im,Ese),e(Ese,mpt),e(im,gpt),e($r,hpt),e($r,PR),e(PR,upt),e(PR,Dxe),e(Dxe,ppt),e(PR,_pt),e($r,vpt),e($r,ha),M(BR,ha,null),e(ha,bpt),e(ha,Gxe),e(Gxe,Fpt),e(ha,Tpt),e(ha,dm),e(dm,Mpt),e(dm,Oxe),e(Oxe,Ept),e(dm,Cpt),e(dm,Cse),e(Cse,wpt),e(dm,Apt),e(ha,Lpt),M(TL,ha,null),e($r,ypt),e($r,st),M(IR,st,null),e(st,xpt),e(st,Vxe),e(Vxe,$pt),e(st,kpt),e(st,Un),e(Un,Spt),e(Un,Xxe),e(Xxe,Rpt),e(Un,Ppt),e(Un,zxe),e(zxe,Bpt),e(Un,Ipt),e(Un,Qxe),e(Qxe,Npt),e(Un,qpt),e(st,jpt),e(st,ze),e(ze,ML),e(ML,Wxe),e(Wxe,Dpt),e(ML,Gpt),e(ML,wse),e(wse,Opt),e(ML,Vpt),e(ze,Xpt),e(ze,EL),e(EL,Uxe),e(Uxe,zpt),e(EL,Qpt),e(EL,Ase),e(Ase,Wpt),e(EL,Upt),e(ze,Hpt),e(ze,CL),e(CL,Hxe),e(Hxe,Jpt),e(CL,Ypt),e(CL,Lse),e(Lse,Kpt),e(CL,Zpt),e(ze,e_t),e(ze,wL),e(wL,Jxe),e(Jxe,o_t),e(wL,r_t),e(wL,yse),e(yse,t_t),e(wL,a_t),e(ze,n_t),e(ze,AL),e(AL,Yxe),e(Yxe,s_t),e(AL,l_t),e(AL,xse),e(xse,i_t),e(AL,d_t),e(ze,c_t),e(ze,LL),e(LL,Kxe),e(Kxe,f_t),e(LL,m_t),e(LL,$se),e($se,g_t),e(LL,h_t),e(ze,u_t),e(ze,yL),e(yL,Zxe),e(Zxe,p_t),e(yL,__t),e(yL,kse),e(kse,v_t),e(yL,b_t),e(ze,F_t),e(ze,xL),e(xL,e$e),e(e$e,T_t),e(xL,M_t),e(xL,Sse),e(Sse,E_t),e(xL,C_t),e(st,w_t),M($L,st,null),v(f,qZe,_),v(f,cm,_),e(cm,kL),e(kL,o$e),M(NR,o$e,null),e(cm,A_t),e(cm,r$e),e(r$e,L_t),v(f,jZe,_),v(f,kr,_),M(qR,kr,null),e(kr,y_t),e(kr,fm),e(fm,x_t),e(fm,Rse),e(Rse,$_t),e(fm,k_t),e(fm,Pse),e(Pse,S_t),e(fm,R_t),e(kr,P_t),e(kr,jR),e(jR,B_t),e(jR,t$e),e(t$e,I_t),e(jR,N_t),e(kr,q_t),e(kr,ua),M(DR,ua,null),e(ua,j_t),e(ua,a$e),e(a$e,D_t),e(ua,G_t),e(ua,mm),e(mm,O_t),e(mm,n$e),e(n$e,V_t),e(mm,X_t),e(mm,Bse),e(Bse,z_t),e(mm,Q_t),e(ua,W_t),M(SL,ua,null),e(kr,U_t),e(kr,lt),M(GR,lt,null),e(lt,H_t),e(lt,s$e),e(s$e,J_t),e(lt,Y_t),e(lt,Hn),e(Hn,K_t),e(Hn,l$e),e(l$e,Z_t),e(Hn,e2t),e(Hn,i$e),e(i$e,o2t),e(Hn,r2t),e(Hn,d$e),e(d$e,t2t),e(Hn,a2t),e(lt,n2t),e(lt,c$e),e(c$e,RL),e(RL,f$e),e(f$e,s2t),e(RL,l2t),e(RL,Ise),e(Ise,i2t),e(RL,d2t),e(lt,c2t),M(PL,lt,null),v(f,DZe,_),v(f,gm,_),e(gm,BL),e(BL,m$e),M(OR,m$e,null),e(gm,f2t),e(gm,g$e),e(g$e,m2t),v(f,GZe,_),v(f,Sr,_),M(VR,Sr,null),e(Sr,g2t),e(Sr,hm),e(hm,h2t),e(hm,Nse),e(Nse,u2t),e(hm,p2t),e(hm,qse),e(qse,_2t),e(hm,v2t),e(Sr,b2t),e(Sr,XR),e(XR,F2t),e(XR,h$e),e(h$e,T2t),e(XR,M2t),e(Sr,E2t),e(Sr,pa),M(zR,pa,null),e(pa,C2t),e(pa,u$e),e(u$e,w2t),e(pa,A2t),e(pa,um),e(um,L2t),e(um,p$e),e(p$e,y2t),e(um,x2t),e(um,jse),e(jse,$2t),e(um,k2t),e(pa,S2t),M(IL,pa,null),e(Sr,R2t),e(Sr,it),M(QR,it,null),e(it,P2t),e(it,_$e),e(_$e,B2t),e(it,I2t),e(it,Jn),e(Jn,N2t),e(Jn,v$e),e(v$e,q2t),e(Jn,j2t),e(Jn,b$e),e(b$e,D2t),e(Jn,G2t),e(Jn,F$e),e(F$e,O2t),e(Jn,V2t),e(it,X2t),e(it,WR),e(WR,NL),e(NL,T$e),e(T$e,z2t),e(NL,Q2t),e(NL,Dse),e(Dse,W2t),e(NL,U2t),e(WR,H2t),e(WR,qL),e(qL,M$e),e(M$e,J2t),e(qL,Y2t),e(qL,Gse),e(Gse,K2t),e(qL,Z2t),e(it,evt),M(jL,it,null),v(f,OZe,_),v(f,pm,_),e(pm,DL),e(DL,E$e),M(UR,E$e,null),e(pm,ovt),e(pm,C$e),e(C$e,rvt),v(f,VZe,_),v(f,Rr,_),M(HR,Rr,null),e(Rr,tvt),e(Rr,_m),e(_m,avt),e(_m,Ose),e(Ose,nvt),e(_m,svt),e(_m,Vse),e(Vse,lvt),e(_m,ivt),e(Rr,dvt),e(Rr,JR),e(JR,cvt),e(JR,w$e),e(w$e,fvt),e(JR,mvt),e(Rr,gvt),e(Rr,_a),M(YR,_a,null),e(_a,hvt),e(_a,A$e),e(A$e,uvt),e(_a,pvt),e(_a,vm),e(vm,_vt),e(vm,L$e),e(L$e,vvt),e(vm,bvt),e(vm,Xse),e(Xse,Fvt),e(vm,Tvt),e(_a,Mvt),M(GL,_a,null),e(Rr,Evt),e(Rr,dt),M(KR,dt,null),e(dt,Cvt),e(dt,y$e),e(y$e,wvt),e(dt,Avt),e(dt,Yn),e(Yn,Lvt),e(Yn,x$e),e(x$e,yvt),e(Yn,xvt),e(Yn,$$e),e($$e,$vt),e(Yn,kvt),e(Yn,k$e),e(k$e,Svt),e(Yn,Rvt),e(dt,Pvt),e(dt,S$e),e(S$e,OL),e(OL,R$e),e(R$e,Bvt),e(OL,Ivt),e(OL,zse),e(zse,Nvt),e(OL,qvt),e(dt,jvt),M(VL,dt,null),XZe=!0},p(f,[_]){const ZR={};_&2&&(ZR.$$scope={dirty:_,ctx:f}),Lm.$set(ZR);const P$e={};_&2&&(P$e.$$scope={dirty:_,ctx:f}),Qh.$set(P$e);const B$e={};_&2&&(B$e.$$scope={dirty:_,ctx:f}),yu.$set(B$e);const I$e={};_&2&&(I$e.$$scope={dirty:_,ctx:f}),pp.$set(I$e);const eP={};_&2&&(eP.$$scope={dirty:_,ctx:f}),_p.$set(eP);const N$e={};_&2&&(N$e.$$scope={dirty:_,ctx:f}),Gp.$set(N$e);const Kn={};_&2&&(Kn.$$scope={dirty:_,ctx:f}),Op.$set(Kn);const q$e={};_&2&&(q$e.$$scope={dirty:_,ctx:f}),zp.$set(q$e);const j$e={};_&2&&(j$e.$$scope={dirty:_,ctx:f}),tv.$set(j$e);const D$e={};_&2&&(D$e.$$scope={dirty:_,ctx:f}),nv.$set(D$e);const oP={};_&2&&(oP.$$scope={dirty:_,ctx:f}),o4.$set(oP);const G$e={};_&2&&(G$e.$$scope={dirty:_,ctx:f}),t4.$set(G$e);const rP={};_&2&&(rP.$$scope={dirty:_,ctx:f}),Q4.$set(rP);const O$e={};_&2&&(O$e.$$scope={dirty:_,ctx:f}),U4.$set(O$e);const tP={};_&2&&(tP.$$scope={dirty:_,ctx:f}),Bb.$set(tP);const V$e={};_&2&&(V$e.$$scope={dirty:_,ctx:f}),Nb.$set(V$e);const X$e={};_&2&&(X$e.$$scope={dirty:_,ctx:f}),n1.$set(X$e);const z$e={};_&2&&(z$e.$$scope={dirty:_,ctx:f}),l1.$set(z$e);const bm={};_&2&&(bm.$$scope={dirty:_,ctx:f}),i0.$set(bm);const Q$e={};_&2&&(Q$e.$$scope={dirty:_,ctx:f}),c0.$set(Q$e);const W$e={};_&2&&(W$e.$$scope={dirty:_,ctx:f}),X0.$set(W$e);const U$e={};_&2&&(U$e.$$scope={dirty:_,ctx:f}),Q0.$set(U$e);const aP={};_&2&&(aP.$$scope={dirty:_,ctx:f}),oF.$set(aP);const H$e={};_&2&&(H$e.$$scope={dirty:_,ctx:f}),tF.$set(H$e);const J$e={};_&2&&(J$e.$$scope={dirty:_,ctx:f}),VF.$set(J$e);const Y$e={};_&2&&(Y$e.$$scope={dirty:_,ctx:f}),zF.$set(Y$e);const ht={};_&2&&(ht.$$scope={dirty:_,ctx:f}),NT.$set(ht);const nP={};_&2&&(nP.$$scope={dirty:_,ctx:f}),jT.$set(nP);const K$e={};_&2&&(K$e.$$scope={dirty:_,ctx:f}),OT.$set(K$e);const sP={};_&2&&(sP.$$scope={dirty:_,ctx:f}),XT.$set(sP);const Z$e={};_&2&&(Z$e.$$scope={dirty:_,ctx:f}),HT.$set(Z$e);const ut={};_&2&&(ut.$$scope={dirty:_,ctx:f}),YT.$set(ut);const eke={};_&2&&(eke.$$scope={dirty:_,ctx:f}),gM.$set(eke);const Fm={};_&2&&(Fm.$$scope={dirty:_,ctx:f}),uM.$set(Fm);const oke={};_&2&&(oke.$$scope={dirty:_,ctx:f}),vM.$set(oke);const rke={};_&2&&(rke.$$scope={dirty:_,ctx:f}),FM.$set(rke);const L={};_&2&&(L.$$scope={dirty:_,ctx:f}),EM.$set(L);const XL={};_&2&&(XL.$$scope={dirty:_,ctx:f}),wM.$set(XL);const tke={};_&2&&(tke.$$scope={dirty:_,ctx:f}),yM.$set(tke);const ake={};_&2&&(ake.$$scope={dirty:_,ctx:f}),$M.$set(ake);const zL={};_&2&&(zL.$$scope={dirty:_,ctx:f}),GM.$set(zL);const nke={};_&2&&(nke.$$scope={dirty:_,ctx:f}),VM.$set(nke);const ske={};_&2&&(ske.$$scope={dirty:_,ctx:f}),JM.$set(ske);const QL={};_&2&&(QL.$$scope={dirty:_,ctx:f}),KM.$set(QL);const lke={};_&2&&(lke.$$scope={dirty:_,ctx:f}),cE.$set(lke);const ike={};_&2&&(ike.$$scope={dirty:_,ctx:f}),mE.$set(ike);const WL={};_&2&&(WL.$$scope={dirty:_,ctx:f}),pE.$set(WL);const dke={};_&2&&(dke.$$scope={dirty:_,ctx:f}),vE.$set(dke);const cke={};_&2&&(cke.$$scope={dirty:_,ctx:f}),wE.$set(cke);const UL={};_&2&&(UL.$$scope={dirty:_,ctx:f}),LE.$set(UL);const fke={};_&2&&(fke.$$scope={dirty:_,ctx:f}),RE.$set(fke);const mke={};_&2&&(mke.$$scope={dirty:_,ctx:f}),BE.$set(mke);const HL={};_&2&&(HL.$$scope={dirty:_,ctx:f}),jE.$set(HL);const gke={};_&2&&(gke.$$scope={dirty:_,ctx:f}),GE.$set(gke);const hke={};_&2&&(hke.$$scope={dirty:_,ctx:f}),XE.$set(hke);const JL={};_&2&&(JL.$$scope={dirty:_,ctx:f}),QE.$set(JL);const uke={};_&2&&(uke.$$scope={dirty:_,ctx:f}),ZE.$set(uke);const pke={};_&2&&(pke.$$scope={dirty:_,ctx:f}),oC.$set(pke);const YL={};_&2&&(YL.$$scope={dirty:_,ctx:f}),aC.$set(YL);const _ke={};_&2&&(_ke.$$scope={dirty:_,ctx:f}),sC.$set(_ke);const vke={};_&2&&(vke.$$scope={dirty:_,ctx:f}),s3.$set(vke);const KL={};_&2&&(KL.$$scope={dirty:_,ctx:f}),i3.$set(KL);const bke={};_&2&&(bke.$$scope={dirty:_,ctx:f}),S3.$set(bke);const Fke={};_&2&&(Fke.$$scope={dirty:_,ctx:f}),P3.$set(Fke);const ZL={};_&2&&(ZL.$$scope={dirty:_,ctx:f}),H3.$set(ZL);const Tke={};_&2&&(Tke.$$scope={dirty:_,ctx:f}),Y3.$set(Tke);const Mke={};_&2&&(Mke.$$scope={dirty:_,ctx:f}),s5.$set(Mke);const ey={};_&2&&(ey.$$scope={dirty:_,ctx:f}),i5.$set(ey);const Eke={};_&2&&(Eke.$$scope={dirty:_,ctx:f}),m5.$set(Eke);const Cke={};_&2&&(Cke.$$scope={dirty:_,ctx:f}),h5.$set(Cke);const oy={};_&2&&(oy.$$scope={dirty:_,ctx:f}),B5.$set(oy);const wke={};_&2&&(wke.$$scope={dirty:_,ctx:f}),N5.$set(wke);const Ake={};_&2&&(Ake.$$scope={dirty:_,ctx:f}),U5.$set(Ake);const ry={};_&2&&(ry.$$scope={dirty:_,ctx:f}),J5.$set(ry);const Lke={};_&2&&(Lke.$$scope={dirty:_,ctx:f}),Cw.$set(Lke);const yke={};_&2&&(yke.$$scope={dirty:_,ctx:f}),Aw.$set(yke);const ty={};_&2&&(ty.$$scope={dirty:_,ctx:f}),Xw.$set(ty);const xke={};_&2&&(xke.$$scope={dirty:_,ctx:f}),Qw.$set(xke);const $ke={};_&2&&($ke.$$scope={dirty:_,ctx:f}),Hw.$set($ke);const ay={};_&2&&(ay.$$scope={dirty:_,ctx:f}),Yw.$set(ay);const kke={};_&2&&(kke.$$scope={dirty:_,ctx:f}),Zw.$set(kke);const Ske={};_&2&&(Ske.$$scope={dirty:_,ctx:f}),oA.$set(Ske);const ny={};_&2&&(ny.$$scope={dirty:_,ctx:f}),tA.$set(ny);const Rke={};_&2&&(Rke.$$scope={dirty:_,ctx:f}),nA.$set(Rke);const Pke={};_&2&&(Pke.$$scope={dirty:_,ctx:f}),LA.$set(Pke);const sy={};_&2&&(sy.$$scope={dirty:_,ctx:f}),xA.$set(sy);const Bke={};_&2&&(Bke.$$scope={dirty:_,ctx:f}),YA.$set(Bke);const Ike={};_&2&&(Ike.$$scope={dirty:_,ctx:f}),ZA.$set(Ike);const ly={};_&2&&(ly.$$scope={dirty:_,ctx:f}),o6.$set(ly);const Nke={};_&2&&(Nke.$$scope={dirty:_,ctx:f}),t6.$set(Nke);const qke={};_&2&&(qke.$$scope={dirty:_,ctx:f}),n6.$set(qke);const iy={};_&2&&(iy.$$scope={dirty:_,ctx:f}),l6.$set(iy);const jke={};_&2&&(jke.$$scope={dirty:_,ctx:f}),B6.$set(jke);const Dke={};_&2&&(Dke.$$scope={dirty:_,ctx:f}),N6.$set(Dke);const dy={};_&2&&(dy.$$scope={dirty:_,ctx:f}),U6.$set(dy);const Gke={};_&2&&(Gke.$$scope={dirty:_,ctx:f}),J6.$set(Gke);const Oke={};_&2&&(Oke.$$scope={dirty:_,ctx:f}),c7.$set(Oke);const cy={};_&2&&(cy.$$scope={dirty:_,ctx:f}),m7.$set(cy);const Vke={};_&2&&(Vke.$$scope={dirty:_,ctx:f}),E7.$set(Vke);const Xke={};_&2&&(Xke.$$scope={dirty:_,ctx:f}),w7.$set(Xke);const fy={};_&2&&(fy.$$scope={dirty:_,ctx:f}),I7.$set(fy);const zke={};_&2&&(zke.$$scope={dirty:_,ctx:f}),q7.$set(zke);const Qke={};_&2&&(Qke.$$scope={dirty:_,ctx:f}),H7.$set(Qke);const my={};_&2&&(my.$$scope={dirty:_,ctx:f}),Y7.$set(my);const Wke={};_&2&&(Wke.$$scope={dirty:_,ctx:f}),iL.$set(Wke);const Uke={};_&2&&(Uke.$$scope={dirty:_,ctx:f}),cL.$set(Uke);const gy={};_&2&&(gy.$$scope={dirty:_,ctx:f}),bL.$set(gy);const Hke={};_&2&&(Hke.$$scope={dirty:_,ctx:f}),TL.$set(Hke);const Jke={};_&2&&(Jke.$$scope={dirty:_,ctx:f}),$L.$set(Jke);const hy={};_&2&&(hy.$$scope={dirty:_,ctx:f}),SL.$set(hy);const Yke={};_&2&&(Yke.$$scope={dirty:_,ctx:f}),PL.$set(Yke);const Kke={};_&2&&(Kke.$$scope={dirty:_,ctx:f}),IL.$set(Kke);const uy={};_&2&&(uy.$$scope={dirty:_,ctx:f}),jL.$set(uy);const Zke={};_&2&&(Zke.$$scope={dirty:_,ctx:f}),GL.$set(Zke);const eSe={};_&2&&(eSe.$$scope={dirty:_,ctx:f}),VL.$set(eSe)},i(f){XZe||(E(d.$$.fragment,f),E(Qa.$$.fragment,f),E(E9.$$.fragment,f),E(C9.$$.fragment,f),E(Lm.$$.fragment,f),E(w9.$$.fragment,f),E(A9.$$.fragment,f),E(x9.$$.fragment,f),E(Qh.$$.fragment,f),E($9.$$.fragment,f),E(k9.$$.fragment,f),E(S9.$$.fragment,f),E(B9.$$.fragment,f),E(yu.$$.fragment,f),E(I9.$$.fragment,f),E(N9.$$.fragment,f),E(q9.$$.fragment,f),E(G9.$$.fragment,f),E(pp.$$.fragment,f),E(_p.$$.fragment,f),E(O9.$$.fragment,f),E(V9.$$.fragment,f),E(X9.$$.fragment,f),E(W9.$$.fragment,f),E(Gp.$$.fragment,f),E(Op.$$.fragment,f),E(U9.$$.fragment,f),E(H9.$$.fragment,f),E(J9.$$.fragment,f),E(K9.$$.fragment,f),E(zp.$$.fragment,f),E(Z9.$$.fragment,f),E(tv.$$.fragment,f),E(ex.$$.fragment,f),E(ox.$$.fragment,f),E(tx.$$.fragment,f),E(nv.$$.fragment,f),E(ax.$$.fragment,f),E(o4.$$.fragment,f),E(nx.$$.fragment,f),E(sx.$$.fragment,f),E(ix.$$.fragment,f),E(t4.$$.fragment,f),E(dx.$$.fragment,f),E(Q4.$$.fragment,f),E(cx.$$.fragment,f),E(fx.$$.fragment,f),E(gx.$$.fragment,f),E(U4.$$.fragment,f),E(hx.$$.fragment,f),E(Bb.$$.fragment,f),E(ux.$$.fragment,f),E(px.$$.fragment,f),E(vx.$$.fragment,f),E(Nb.$$.fragment,f),E(bx.$$.fragment,f),E(n1.$$.fragment,f),E(Fx.$$.fragment,f),E(Tx.$$.fragment,f),E(Ex.$$.fragment,f),E(l1.$$.fragment,f),E(Cx.$$.fragment,f),E(i0.$$.fragment,f),E(wx.$$.fragment,f),E(Ax.$$.fragment,f),E(yx.$$.fragment,f),E(c0.$$.fragment,f),E(xx.$$.fragment,f),E(X0.$$.fragment,f),E($x.$$.fragment,f),E(kx.$$.fragment,f),E(Rx.$$.fragment,f),E(Q0.$$.fragment,f),E(Px.$$.fragment,f),E(oF.$$.fragment,f),E(Bx.$$.fragment,f),E(Ix.$$.fragment,f),E(qx.$$.fragment,f),E(tF.$$.fragment,f),E(jx.$$.fragment,f),E(VF.$$.fragment,f),E(Dx.$$.fragment,f),E(Gx.$$.fragment,f),E(Vx.$$.fragment,f),E(zF.$$.fragment,f),E(Xx.$$.fragment,f),E(NT.$$.fragment,f),E(zx.$$.fragment,f),E(Qx.$$.fragment,f),E(Ux.$$.fragment,f),E(jT.$$.fragment,f),E(Hx.$$.fragment,f),E(OT.$$.fragment,f),E(Jx.$$.fragment,f),E(Yx.$$.fragment,f),E(Zx.$$.fragment,f),E(XT.$$.fragment,f),E(e$.$$.fragment,f),E(HT.$$.fragment,f),E(o$.$$.fragment,f),E(r$.$$.fragment,f),E(a$.$$.fragment,f),E(YT.$$.fragment,f),E(n$.$$.fragment,f),E(gM.$$.fragment,f),E(s$.$$.fragment,f),E(l$.$$.fragment,f),E(d$.$$.fragment,f),E(uM.$$.fragment,f),E(c$.$$.fragment,f),E(vM.$$.fragment,f),E(f$.$$.fragment,f),E(m$.$$.fragment,f),E(h$.$$.fragment,f),E(FM.$$.fragment,f),E(u$.$$.fragment,f),E(EM.$$.fragment,f),E(p$.$$.fragment,f),E(_$.$$.fragment,f),E(b$.$$.fragment,f),E(wM.$$.fragment,f),E(F$.$$.fragment,f),E(yM.$$.fragment,f),E(T$.$$.fragment,f),E(M$.$$.fragment,f),E(C$.$$.fragment,f),E($M.$$.fragment,f),E(w$.$$.fragment,f),E(GM.$$.fragment,f),E(A$.$$.fragment,f),E(L$.$$.fragment,f),E(x$.$$.fragment,f),E(VM.$$.fragment,f),E($$.$$.fragment,f),E(JM.$$.fragment,f),E(k$.$$.fragment,f),E(S$.$$.fragment,f),E(P$.$$.fragment,f),E(KM.$$.fragment,f),E(B$.$$.fragment,f),E(cE.$$.fragment,f),E(I$.$$.fragment,f),E(N$.$$.fragment,f),E(j$.$$.fragment,f),E(mE.$$.fragment,f),E(D$.$$.fragment,f),E(pE.$$.fragment,f),E(O$.$$.fragment,f),E(V$.$$.fragment,f),E(z$.$$.fragment,f),E(vE.$$.fragment,f),E(Q$.$$.fragment,f),E(wE.$$.fragment,f),E(W$.$$.fragment,f),E(U$.$$.fragment,f),E(J$.$$.fragment,f),E(LE.$$.fragment,f),E(Y$.$$.fragment,f),E(RE.$$.fragment,f),E(K$.$$.fragment,f),E(Z$.$$.fragment,f),E(ok.$$.fragment,f),E(BE.$$.fragment,f),E(rk.$$.fragment,f),E(jE.$$.fragment,f),E(ak.$$.fragment,f),E(nk.$$.fragment,f),E(lk.$$.fragment,f),E(GE.$$.fragment,f),E(ik.$$.fragment,f),E(XE.$$.fragment,f),E(dk.$$.fragment,f),E(ck.$$.fragment,f),E(mk.$$.fragment,f),E(QE.$$.fragment,f),E(gk.$$.fragment,f),E(ZE.$$.fragment,f),E(hk.$$.fragment,f),E(uk.$$.fragment,f),E(_k.$$.fragment,f),E(oC.$$.fragment,f),E(vk.$$.fragment,f),E(aC.$$.fragment,f),E(bk.$$.fragment,f),E(Fk.$$.fragment,f),E(Mk.$$.fragment,f),E(sC.$$.fragment,f),E(Ek.$$.fragment,f),E(s3.$$.fragment,f),E(Ck.$$.fragment,f),E(wk.$$.fragment,f),E(Lk.$$.fragment,f),E(i3.$$.fragment,f),E(yk.$$.fragment,f),E(S3.$$.fragment,f),E(xk.$$.fragment,f),E($k.$$.fragment,f),E(Sk.$$.fragment,f),E(P3.$$.fragment,f),E(Rk.$$.fragment,f),E(H3.$$.fragment,f),E(Pk.$$.fragment,f),E(Bk.$$.fragment,f),E(Nk.$$.fragment,f),E(Y3.$$.fragment,f),E(qk.$$.fragment,f),E(s5.$$.fragment,f),E(jk.$$.fragment,f),E(Dk.$$.fragment,f),E(Ok.$$.fragment,f),E(i5.$$.fragment,f),E(Vk.$$.fragment,f),E(m5.$$.fragment,f),E(Xk.$$.fragment,f),E(zk.$$.fragment,f),E(Wk.$$.fragment,f),E(h5.$$.fragment,f),E(Uk.$$.fragment,f),E(B5.$$.fragment,f),E(Hk.$$.fragment,f),E(Jk.$$.fragment,f),E(Kk.$$.fragment,f),E(N5.$$.fragment,f),E(Zk.$$.fragment,f),E(U5.$$.fragment,f),E(eS.$$.fragment,f),E(oS.$$.fragment,f),E(tS.$$.fragment,f),E(J5.$$.fragment,f),E(aS.$$.fragment,f),E(Cw.$$.fragment,f),E(nS.$$.fragment,f),E(sS.$$.fragment,f),E(iS.$$.fragment,f),E(Aw.$$.fragment,f),E(dS.$$.fragment,f),E(Xw.$$.fragment,f),E(cS.$$.fragment,f),E(fS.$$.fragment,f),E(gS.$$.fragment,f),E(Qw.$$.fragment,f),E(hS.$$.fragment,f),E(Hw.$$.fragment,f),E(pS.$$.fragment,f),E(_S.$$.fragment,f),E(bS.$$.fragment,f),E(Yw.$$.fragment,f),E(FS.$$.fragment,f),E(Zw.$$.fragment,f),E(TS.$$.fragment,f),E(MS.$$.fragment,f),E(CS.$$.fragment,f),E(oA.$$.fragment,f),E(wS.$$.fragment,f),E(tA.$$.fragment,f),E(AS.$$.fragment,f),E(LS.$$.fragment,f),E(xS.$$.fragment,f),E(nA.$$.fragment,f),E($S.$$.fragment,f),E(LA.$$.fragment,f),E(kS.$$.fragment,f),E(SS.$$.fragment,f),E(PS.$$.fragment,f),E(xA.$$.fragment,f),E(BS.$$.fragment,f),E(YA.$$.fragment,f),E(IS.$$.fragment,f),E(NS.$$.fragment,f),E(jS.$$.fragment,f),E(ZA.$$.fragment,f),E(DS.$$.fragment,f),E(o6.$$.fragment,f),E(GS.$$.fragment,f),E(OS.$$.fragment,f),E(XS.$$.fragment,f),E(t6.$$.fragment,f),E(zS.$$.fragment,f),E(n6.$$.fragment,f),E(QS.$$.fragment,f),E(WS.$$.fragment,f),E(HS.$$.fragment,f),E(l6.$$.fragment,f),E(JS.$$.fragment,f),E(B6.$$.fragment,f),E(YS.$$.fragment,f),E(KS.$$.fragment,f),E(eR.$$.fragment,f),E(N6.$$.fragment,f),E(oR.$$.fragment,f),E(U6.$$.fragment,f),E(rR.$$.fragment,f),E(tR.$$.fragment,f),E(nR.$$.fragment,f),E(J6.$$.fragment,f),E(sR.$$.fragment,f),E(c7.$$.fragment,f),E(lR.$$.fragment,f),E(iR.$$.fragment,f),E(cR.$$.fragment,f),E(m7.$$.fragment,f),E(fR.$$.fragment,f),E(E7.$$.fragment,f),E(mR.$$.fragment,f),E(gR.$$.fragment,f),E(uR.$$.fragment,f),E(w7.$$.fragment,f),E(pR.$$.fragment,f),E(I7.$$.fragment,f),E(_R.$$.fragment,f),E(vR.$$.fragment,f),E(FR.$$.fragment,f),E(q7.$$.fragment,f),E(TR.$$.fragment,f),E(H7.$$.fragment,f),E(MR.$$.fragment,f),E(ER.$$.fragment,f),E(wR.$$.fragment,f),E(Y7.$$.fragment,f),E(AR.$$.fragment,f),E(iL.$$.fragment,f),E(LR.$$.fragment,f),E(yR.$$.fragment,f),E($R.$$.fragment,f),E(cL.$$.fragment,f),E(kR.$$.fragment,f),E(bL.$$.fragment,f),E(SR.$$.fragment,f),E(RR.$$.fragment,f),E(BR.$$.fragment,f),E(TL.$$.fragment,f),E(IR.$$.fragment,f),E($L.$$.fragment,f),E(NR.$$.fragment,f),E(qR.$$.fragment,f),E(DR.$$.fragment,f),E(SL.$$.fragment,f),E(GR.$$.fragment,f),E(PL.$$.fragment,f),E(OR.$$.fragment,f),E(VR.$$.fragment,f),E(zR.$$.fragment,f),E(IL.$$.fragment,f),E(QR.$$.fragment,f),E(jL.$$.fragment,f),E(UR.$$.fragment,f),E(HR.$$.fragment,f),E(YR.$$.fragment,f),E(GL.$$.fragment,f),E(KR.$$.fragment,f),E(VL.$$.fragment,f),XZe=!0)},o(f){C(d.$$.fragment,f),C(Qa.$$.fragment,f),C(E9.$$.fragment,f),C(C9.$$.fragment,f),C(Lm.$$.fragment,f),C(w9.$$.fragment,f),C(A9.$$.fragment,f),C(x9.$$.fragment,f),C(Qh.$$.fragment,f),C($9.$$.fragment,f),C(k9.$$.fragment,f),C(S9.$$.fragment,f),C(B9.$$.fragment,f),C(yu.$$.fragment,f),C(I9.$$.fragment,f),C(N9.$$.fragment,f),C(q9.$$.fragment,f),C(G9.$$.fragment,f),C(pp.$$.fragment,f),C(_p.$$.fragment,f),C(O9.$$.fragment,f),C(V9.$$.fragment,f),C(X9.$$.fragment,f),C(W9.$$.fragment,f),C(Gp.$$.fragment,f),C(Op.$$.fragment,f),C(U9.$$.fragment,f),C(H9.$$.fragment,f),C(J9.$$.fragment,f),C(K9.$$.fragment,f),C(zp.$$.fragment,f),C(Z9.$$.fragment,f),C(tv.$$.fragment,f),C(ex.$$.fragment,f),C(ox.$$.fragment,f),C(tx.$$.fragment,f),C(nv.$$.fragment,f),C(ax.$$.fragment,f),C(o4.$$.fragment,f),C(nx.$$.fragment,f),C(sx.$$.fragment,f),C(ix.$$.fragment,f),C(t4.$$.fragment,f),C(dx.$$.fragment,f),C(Q4.$$.fragment,f),C(cx.$$.fragment,f),C(fx.$$.fragment,f),C(gx.$$.fragment,f),C(U4.$$.fragment,f),C(hx.$$.fragment,f),C(Bb.$$.fragment,f),C(ux.$$.fragment,f),C(px.$$.fragment,f),C(vx.$$.fragment,f),C(Nb.$$.fragment,f),C(bx.$$.fragment,f),C(n1.$$.fragment,f),C(Fx.$$.fragment,f),C(Tx.$$.fragment,f),C(Ex.$$.fragment,f),C(l1.$$.fragment,f),C(Cx.$$.fragment,f),C(i0.$$.fragment,f),C(wx.$$.fragment,f),C(Ax.$$.fragment,f),C(yx.$$.fragment,f),C(c0.$$.fragment,f),C(xx.$$.fragment,f),C(X0.$$.fragment,f),C($x.$$.fragment,f),C(kx.$$.fragment,f),C(Rx.$$.fragment,f),C(Q0.$$.fragment,f),C(Px.$$.fragment,f),C(oF.$$.fragment,f),C(Bx.$$.fragment,f),C(Ix.$$.fragment,f),C(qx.$$.fragment,f),C(tF.$$.fragment,f),C(jx.$$.fragment,f),C(VF.$$.fragment,f),C(Dx.$$.fragment,f),C(Gx.$$.fragment,f),C(Vx.$$.fragment,f),C(zF.$$.fragment,f),C(Xx.$$.fragment,f),C(NT.$$.fragment,f),C(zx.$$.fragment,f),C(Qx.$$.fragment,f),C(Ux.$$.fragment,f),C(jT.$$.fragment,f),C(Hx.$$.fragment,f),C(OT.$$.fragment,f),C(Jx.$$.fragment,f),C(Yx.$$.fragment,f),C(Zx.$$.fragment,f),C(XT.$$.fragment,f),C(e$.$$.fragment,f),C(HT.$$.fragment,f),C(o$.$$.fragment,f),C(r$.$$.fragment,f),C(a$.$$.fragment,f),C(YT.$$.fragment,f),C(n$.$$.fragment,f),C(gM.$$.fragment,f),C(s$.$$.fragment,f),C(l$.$$.fragment,f),C(d$.$$.fragment,f),C(uM.$$.fragment,f),C(c$.$$.fragment,f),C(vM.$$.fragment,f),C(f$.$$.fragment,f),C(m$.$$.fragment,f),C(h$.$$.fragment,f),C(FM.$$.fragment,f),C(u$.$$.fragment,f),C(EM.$$.fragment,f),C(p$.$$.fragment,f),C(_$.$$.fragment,f),C(b$.$$.fragment,f),C(wM.$$.fragment,f),C(F$.$$.fragment,f),C(yM.$$.fragment,f),C(T$.$$.fragment,f),C(M$.$$.fragment,f),C(C$.$$.fragment,f),C($M.$$.fragment,f),C(w$.$$.fragment,f),C(GM.$$.fragment,f),C(A$.$$.fragment,f),C(L$.$$.fragment,f),C(x$.$$.fragment,f),C(VM.$$.fragment,f),C($$.$$.fragment,f),C(JM.$$.fragment,f),C(k$.$$.fragment,f),C(S$.$$.fragment,f),C(P$.$$.fragment,f),C(KM.$$.fragment,f),C(B$.$$.fragment,f),C(cE.$$.fragment,f),C(I$.$$.fragment,f),C(N$.$$.fragment,f),C(j$.$$.fragment,f),C(mE.$$.fragment,f),C(D$.$$.fragment,f),C(pE.$$.fragment,f),C(O$.$$.fragment,f),C(V$.$$.fragment,f),C(z$.$$.fragment,f),C(vE.$$.fragment,f),C(Q$.$$.fragment,f),C(wE.$$.fragment,f),C(W$.$$.fragment,f),C(U$.$$.fragment,f),C(J$.$$.fragment,f),C(LE.$$.fragment,f),C(Y$.$$.fragment,f),C(RE.$$.fragment,f),C(K$.$$.fragment,f),C(Z$.$$.fragment,f),C(ok.$$.fragment,f),C(BE.$$.fragment,f),C(rk.$$.fragment,f),C(jE.$$.fragment,f),C(ak.$$.fragment,f),C(nk.$$.fragment,f),C(lk.$$.fragment,f),C(GE.$$.fragment,f),C(ik.$$.fragment,f),C(XE.$$.fragment,f),C(dk.$$.fragment,f),C(ck.$$.fragment,f),C(mk.$$.fragment,f),C(QE.$$.fragment,f),C(gk.$$.fragment,f),C(ZE.$$.fragment,f),C(hk.$$.fragment,f),C(uk.$$.fragment,f),C(_k.$$.fragment,f),C(oC.$$.fragment,f),C(vk.$$.fragment,f),C(aC.$$.fragment,f),C(bk.$$.fragment,f),C(Fk.$$.fragment,f),C(Mk.$$.fragment,f),C(sC.$$.fragment,f),C(Ek.$$.fragment,f),C(s3.$$.fragment,f),C(Ck.$$.fragment,f),C(wk.$$.fragment,f),C(Lk.$$.fragment,f),C(i3.$$.fragment,f),C(yk.$$.fragment,f),C(S3.$$.fragment,f),C(xk.$$.fragment,f),C($k.$$.fragment,f),C(Sk.$$.fragment,f),C(P3.$$.fragment,f),C(Rk.$$.fragment,f),C(H3.$$.fragment,f),C(Pk.$$.fragment,f),C(Bk.$$.fragment,f),C(Nk.$$.fragment,f),C(Y3.$$.fragment,f),C(qk.$$.fragment,f),C(s5.$$.fragment,f),C(jk.$$.fragment,f),C(Dk.$$.fragment,f),C(Ok.$$.fragment,f),C(i5.$$.fragment,f),C(Vk.$$.fragment,f),C(m5.$$.fragment,f),C(Xk.$$.fragment,f),C(zk.$$.fragment,f),C(Wk.$$.fragment,f),C(h5.$$.fragment,f),C(Uk.$$.fragment,f),C(B5.$$.fragment,f),C(Hk.$$.fragment,f),C(Jk.$$.fragment,f),C(Kk.$$.fragment,f),C(N5.$$.fragment,f),C(Zk.$$.fragment,f),C(U5.$$.fragment,f),C(eS.$$.fragment,f),C(oS.$$.fragment,f),C(tS.$$.fragment,f),C(J5.$$.fragment,f),C(aS.$$.fragment,f),C(Cw.$$.fragment,f),C(nS.$$.fragment,f),C(sS.$$.fragment,f),C(iS.$$.fragment,f),C(Aw.$$.fragment,f),C(dS.$$.fragment,f),C(Xw.$$.fragment,f),C(cS.$$.fragment,f),C(fS.$$.fragment,f),C(gS.$$.fragment,f),C(Qw.$$.fragment,f),C(hS.$$.fragment,f),C(Hw.$$.fragment,f),C(pS.$$.fragment,f),C(_S.$$.fragment,f),C(bS.$$.fragment,f),C(Yw.$$.fragment,f),C(FS.$$.fragment,f),C(Zw.$$.fragment,f),C(TS.$$.fragment,f),C(MS.$$.fragment,f),C(CS.$$.fragment,f),C(oA.$$.fragment,f),C(wS.$$.fragment,f),C(tA.$$.fragment,f),C(AS.$$.fragment,f),C(LS.$$.fragment,f),C(xS.$$.fragment,f),C(nA.$$.fragment,f),C($S.$$.fragment,f),C(LA.$$.fragment,f),C(kS.$$.fragment,f),C(SS.$$.fragment,f),C(PS.$$.fragment,f),C(xA.$$.fragment,f),C(BS.$$.fragment,f),C(YA.$$.fragment,f),C(IS.$$.fragment,f),C(NS.$$.fragment,f),C(jS.$$.fragment,f),C(ZA.$$.fragment,f),C(DS.$$.fragment,f),C(o6.$$.fragment,f),C(GS.$$.fragment,f),C(OS.$$.fragment,f),C(XS.$$.fragment,f),C(t6.$$.fragment,f),C(zS.$$.fragment,f),C(n6.$$.fragment,f),C(QS.$$.fragment,f),C(WS.$$.fragment,f),C(HS.$$.fragment,f),C(l6.$$.fragment,f),C(JS.$$.fragment,f),C(B6.$$.fragment,f),C(YS.$$.fragment,f),C(KS.$$.fragment,f),C(eR.$$.fragment,f),C(N6.$$.fragment,f),C(oR.$$.fragment,f),C(U6.$$.fragment,f),C(rR.$$.fragment,f),C(tR.$$.fragment,f),C(nR.$$.fragment,f),C(J6.$$.fragment,f),C(sR.$$.fragment,f),C(c7.$$.fragment,f),C(lR.$$.fragment,f),C(iR.$$.fragment,f),C(cR.$$.fragment,f),C(m7.$$.fragment,f),C(fR.$$.fragment,f),C(E7.$$.fragment,f),C(mR.$$.fragment,f),C(gR.$$.fragment,f),C(uR.$$.fragment,f),C(w7.$$.fragment,f),C(pR.$$.fragment,f),C(I7.$$.fragment,f),C(_R.$$.fragment,f),C(vR.$$.fragment,f),C(FR.$$.fragment,f),C(q7.$$.fragment,f),C(TR.$$.fragment,f),C(H7.$$.fragment,f),C(MR.$$.fragment,f),C(ER.$$.fragment,f),C(wR.$$.fragment,f),C(Y7.$$.fragment,f),C(AR.$$.fragment,f),C(iL.$$.fragment,f),C(LR.$$.fragment,f),C(yR.$$.fragment,f),C($R.$$.fragment,f),C(cL.$$.fragment,f),C(kR.$$.fragment,f),C(bL.$$.fragment,f),C(SR.$$.fragment,f),C(RR.$$.fragment,f),C(BR.$$.fragment,f),C(TL.$$.fragment,f),C(IR.$$.fragment,f),C($L.$$.fragment,f),C(NR.$$.fragment,f),C(qR.$$.fragment,f),C(DR.$$.fragment,f),C(SL.$$.fragment,f),C(GR.$$.fragment,f),C(PL.$$.fragment,f),C(OR.$$.fragment,f),C(VR.$$.fragment,f),C(zR.$$.fragment,f),C(IL.$$.fragment,f),C(QR.$$.fragment,f),C(jL.$$.fragment,f),C(UR.$$.fragment,f),C(HR.$$.fragment,f),C(YR.$$.fragment,f),C(GL.$$.fragment,f),C(KR.$$.fragment,f),C(VL.$$.fragment,f),XZe=!1},d(f){t(g),f&&t(b),f&&t(u),w(d),f&&t(Mm),f&&t(pt),f&&t(Ve),f&&t(He),f&&t(Cm),w(Qa,f),f&&t(Je),f&&t(Ae),f&&t(xo),f&&t(Wa),f&&t(kYe),f&&t(dd),w(E9),f&&t(SYe),f&&t(ts),f&&t(RYe),w(C9,f),f&&t(PYe),f&&t(xB),f&&t(BYe),w(Lm,f),f&&t(IYe),f&&t(cd),w(w9),f&&t(NYe),f&&t($o),w(A9),w(x9),w(Qh),w($9),f&&t(qYe),f&&t(md),w(k9),f&&t(jYe),f&&t(ko),w(S9),w(B9),w(yu),w(I9),f&&t(DYe),f&&t(gd),w(N9),f&&t(GYe),f&&t(So),w(q9),w(G9),w(pp),w(_p),w(O9),f&&t(OYe),f&&t(hd),w(V9),f&&t(VYe),f&&t(Ro),w(X9),w(W9),w(Gp),w(Op),w(U9),f&&t(XYe),f&&t(pd),w(H9),f&&t(zYe),f&&t(Po),w(J9),w(K9),w(zp),w(Z9),w(tv),f&&t(QYe),f&&t(bd),w(ex),f&&t(WYe),f&&t(Bo),w(ox),w(tx),w(nv),w(ax),w(o4),f&&t(UYe),f&&t(Md),w(nx),f&&t(HYe),f&&t(Io),w(sx),w(ix),w(t4),w(dx),w(Q4),f&&t(JYe),f&&t(wd),w(cx),f&&t(YYe),f&&t(No),w(fx),w(gx),w(U4),w(hx),w(Bb),f&&t(KYe),f&&t(yd),w(ux),f&&t(ZYe),f&&t(qo),w(px),w(vx),w(Nb),w(bx),w(n1),f&&t(eKe),f&&t(kd),w(Fx),f&&t(oKe),f&&t(jo),w(Tx),w(Ex),w(l1),w(Cx),w(i0),f&&t(rKe),f&&t(Pd),w(wx),f&&t(tKe),f&&t(Do),w(Ax),w(yx),w(c0),w(xx),w(X0),f&&t(aKe),f&&t(Nd),w($x),f&&t(nKe),f&&t(Go),w(kx),w(Rx),w(Q0),w(Px),w(oF),f&&t(sKe),f&&t(Dd),w(Bx),f&&t(lKe),f&&t(Oo),w(Ix),w(qx),w(tF),w(jx),w(VF),f&&t(iKe),f&&t(Vd),w(Dx),f&&t(dKe),f&&t(Vo),w(Gx),w(Vx),w(zF),w(Xx),w(NT),f&&t(cKe),f&&t(Qd),w(zx),f&&t(fKe),f&&t(Xo),w(Qx),w(Ux),w(jT),w(Hx),w(OT),f&&t(mKe),f&&t(Hd),w(Jx),f&&t(gKe),f&&t(zo),w(Yx),w(Zx),w(XT),w(e$),w(HT),f&&t(hKe),f&&t(Zd),w(o$),f&&t(uKe),f&&t(Qo),w(r$),w(a$),w(YT),w(n$),w(gM),f&&t(pKe),f&&t(rc),w(s$),f&&t(_Ke),f&&t(Wo),w(l$),w(d$),w(uM),w(c$),w(vM),f&&t(vKe),f&&t(nc),w(f$),f&&t(bKe),f&&t(Uo),w(m$),w(h$),w(FM),w(u$),w(EM),f&&t(FKe),f&&t(ic),w(p$),f&&t(TKe),f&&t(Ho),w(_$),w(b$),w(wM),w(F$),w(yM),f&&t(MKe),f&&t(fc),w(T$),f&&t(EKe),f&&t(Jo),w(M$),w(C$),w($M),w(w$),w(GM),f&&t(CKe),f&&t(hc),w(A$),f&&t(wKe),f&&t(Yo),w(L$),w(x$),w(VM),w($$),w(JM),f&&t(AKe),f&&t(_c),w(k$),f&&t(LKe),f&&t(Ko),w(S$),w(P$),w(KM),w(B$),w(cE),f&&t(yKe),f&&t(Fc),w(I$),f&&t(xKe),f&&t(Zo),w(N$),w(j$),w(mE),w(D$),w(pE),f&&t($Ke),f&&t(Ec),w(O$),f&&t(kKe),f&&t(er),w(V$),w(z$),w(vE),w(Q$),w(wE),f&&t(SKe),f&&t(Ac),w(W$),f&&t(RKe),f&&t(or),w(U$),w(J$),w(LE),w(Y$),w(RE),f&&t(PKe),f&&t(xc),w(K$),f&&t(BKe),f&&t(rr),w(Z$),w(ok),w(BE),w(rk),w(jE),f&&t(IKe),f&&t(Sc),w(ak),f&&t(NKe),f&&t(tr),w(nk),w(lk),w(GE),w(ik),w(XE),f&&t(qKe),f&&t(Bc),w(dk),f&&t(jKe),f&&t(ar),w(ck),w(mk),w(QE),w(gk),w(ZE),f&&t(DKe),f&&t(qc),w(hk),f&&t(GKe),f&&t(nr),w(uk),w(_k),w(oC),w(vk),w(aC),f&&t(OKe),f&&t(Gc),w(bk),f&&t(VKe),f&&t(sr),w(Fk),w(Mk),w(sC),w(Ek),w(s3),f&&t(XKe),f&&t(Xc),w(Ck),f&&t(zKe),f&&t(lr),w(wk),w(Lk),w(i3),w(yk),w(S3),f&&t(QKe),f&&t(Wc),w(xk),f&&t(WKe),f&&t(ir),w($k),w(Sk),w(P3),w(Rk),w(H3),f&&t(UKe),f&&t(Jc),w(Pk),f&&t(HKe),f&&t(dr),w(Bk),w(Nk),w(Y3),w(qk),w(s5),f&&t(JKe),f&&t(Zc),w(jk),f&&t(YKe),f&&t(cr),w(Dk),w(Ok),w(i5),w(Vk),w(m5),f&&t(KKe),f&&t(tf),w(Xk),f&&t(ZKe),f&&t(fr),w(zk),w(Wk),w(h5),w(Uk),w(B5),f&&t(eZe),f&&t(sf),w(Hk),f&&t(oZe),f&&t(mr),w(Jk),w(Kk),w(N5),w(Zk),w(U5),f&&t(rZe),f&&t(cf),w(eS),f&&t(tZe),f&&t(gr),w(oS),w(tS),w(J5),w(aS),w(Cw),f&&t(aZe),f&&t(gf),w(nS),f&&t(nZe),f&&t(hr),w(sS),w(iS),w(Aw),w(dS),w(Xw),f&&t(sZe),f&&t(pf),w(cS),f&&t(lZe),f&&t(ur),w(fS),w(gS),w(Qw),w(hS),w(Hw),f&&t(iZe),f&&t(bf),w(pS),f&&t(dZe),f&&t(pr),w(_S),w(bS),w(Yw),w(FS),w(Zw),f&&t(cZe),f&&t(Mf),w(TS),f&&t(fZe),f&&t(_r),w(MS),w(CS),w(oA),w(wS),w(tA),f&&t(mZe),f&&t(wf),w(AS),f&&t(gZe),f&&t(vr),w(LS),w(xS),w(nA),w($S),w(LA),f&&t(hZe),f&&t(yf),w(kS),f&&t(uZe),f&&t(br),w(SS),w(PS),w(xA),w(BS),w(YA),f&&t(pZe),f&&t(kf),w(IS),f&&t(_Ze),f&&t(Fr),w(NS),w(jS),w(ZA),w(DS),w(o6),f&&t(vZe),f&&t(Pf),w(GS),f&&t(bZe),f&&t(Tr),w(OS),w(XS),w(t6),w(zS),w(n6),f&&t(FZe),f&&t(Nf),w(QS),f&&t(TZe),f&&t(Mr),w(WS),w(HS),w(l6),w(JS),w(B6),f&&t(MZe),f&&t(Df),w(YS),f&&t(EZe),f&&t(Er),w(KS),w(eR),w(N6),w(oR),w(U6),f&&t(CZe),f&&t(Vf),w(rR),f&&t(wZe),f&&t(Cr),w(tR),w(nR),w(J6),w(sR),w(c7),f&&t(AZe),f&&t(Qf),w(lR),f&&t(LZe),f&&t(wr),w(iR),w(cR),w(m7),w(fR),w(E7),f&&t(yZe),f&&t(Hf),w(mR),f&&t(xZe),f&&t(Ar),w(gR),w(uR),w(w7),w(pR),w(I7),f&&t($Ze),f&&t(Kf),w(_R),f&&t(kZe),f&&t(Lr),w(vR),w(FR),w(q7),w(TR),w(H7),f&&t(SZe),f&&t(om),w(MR),f&&t(RZe),f&&t(yr),w(ER),w(wR),w(Y7),w(AR),w(iL),f&&t(PZe),f&&t(am),w(LR),f&&t(BZe),f&&t(xr),w(yR),w($R),w(cL),w(kR),w(bL),f&&t(IZe),f&&t(lm),w(SR),f&&t(NZe),f&&t($r),w(RR),w(BR),w(TL),w(IR),w($L),f&&t(qZe),f&&t(cm),w(NR),f&&t(jZe),f&&t(kr),w(qR),w(DR),w(SL),w(GR),w(PL),f&&t(DZe),f&&t(gm),w(OR),f&&t(GZe),f&&t(Sr),w(VR),w(zR),w(IL),w(QR),w(jL),f&&t(OZe),f&&t(pm),w(UR),f&&t(VZe),f&&t(Rr),w(HR),w(YR),w(GL),w(KR),w(VL)}}}const Hha={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function Jha($){return Dma(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class tua extends Ima{constructor(g){super();Nma(this,g,Jha,Uha,qma,{})}}export{tua as default,Hha as metadata};
