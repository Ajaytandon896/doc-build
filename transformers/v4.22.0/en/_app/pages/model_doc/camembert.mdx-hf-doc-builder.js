import{S as Lg,i as Ag,s as Rg,e as a,k as d,w as L,t as o,M as zg,c as s,d as t,m,a as n,x as A,h as r,b as h,G as e,g as c,y as R,q as z,o as q,B as x,v as qg}from"../../chunks/vendor-hf-doc-builder.js";import{T as va}from"../../chunks/Tip-hf-doc-builder.js";import{D as Qe}from"../../chunks/Docstring-hf-doc-builder.js";import{I as Ve}from"../../chunks/IconCopyLink-hf-doc-builder.js";function xg(tt){let v,me,$,te,le,W,w,S,be,he,F,oe,X,f,ke,U,we,ce,M,ye,ae,K,Te,fe,I,Ee,pe,O,de,Ce,Z,_,y,ue,B,se,$e,N,Fe,Pe,k,ee,j,ne,Me,H,ie,De,C,ge,P,re,J,b,Le,T,Ae,_e;return{c(){v=a("p"),me=o("TensorFlow models and layers in "),$=a("code"),te=o("transformers"),le=o(" accept two formats as input:"),W=d(),w=a("ul"),S=a("li"),be=o("having all inputs as keyword arguments (like PyTorch models), or"),he=d(),F=a("li"),oe=o("having all inputs as a list, tuple or dict in the first positional argument."),X=d(),f=a("p"),ke=o(`The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
and layers. Because of this support, when using methods like `),U=a("code"),we=o("model.fit()"),ce=o(` things should \u201Cjust work\u201D for you - just
pass your inputs and labels in any format that `),M=a("code"),ye=o("model.fit()"),ae=o(` supports! If, however, you want to use the second
format outside of Keras methods like `),K=a("code"),Te=o("fit()"),fe=o(" and "),I=a("code"),Ee=o("predict()"),pe=o(`, such as when creating your own layers or models with
the Keras `),O=a("code"),de=o("Functional"),Ce=o(` API, there are three possibilities you can use to gather all the input Tensors in the first
positional argument:`),Z=d(),_=a("ul"),y=a("li"),ue=o("a single Tensor with "),B=a("code"),se=o("input_ids"),$e=o(" only and nothing else: "),N=a("code"),Fe=o("model(input_ids)"),Pe=d(),k=a("li"),ee=o(`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),j=a("code"),ne=o("model([input_ids, attention_mask])"),Me=o(" or "),H=a("code"),ie=o("model([input_ids, attention_mask, token_type_ids])"),De=d(),C=a("li"),ge=o(`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),P=a("code"),re=o('model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),J=d(),b=a("p"),Le=o(`Note that when creating models and layers with
`),T=a("a"),Ae=o("subclassing"),_e=o(` then you don\u2019t need to worry
about any of this, as you can just pass inputs like you would to any other Python function!`),this.h()},l(l){v=s(l,"P",{});var p=n(v);me=r(p,"TensorFlow models and layers in "),$=s(p,"CODE",{});var Be=n($);te=r(Be,"transformers"),Be.forEach(t),le=r(p," accept two formats as input:"),p.forEach(t),W=m(l),w=s(l,"UL",{});var V=n(w);S=s(V,"LI",{});var Ne=n(S);be=r(Ne,"having all inputs as keyword arguments (like PyTorch models), or"),Ne.forEach(t),he=m(V),F=s(V,"LI",{});var qe=n(F);oe=r(qe,"having all inputs as a list, tuple or dict in the first positional argument."),qe.forEach(t),V.forEach(t),X=m(l),f=s(l,"P",{});var g=n(f);ke=r(g,`The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
and layers. Because of this support, when using methods like `),U=s(g,"CODE",{});var Se=n(U);we=r(Se,"model.fit()"),Se.forEach(t),ce=r(g,` things should \u201Cjust work\u201D for you - just
pass your inputs and labels in any format that `),M=s(g,"CODE",{});var Re=n(M);ye=r(Re,"model.fit()"),Re.forEach(t),ae=r(g,` supports! If, however, you want to use the second
format outside of Keras methods like `),K=s(g,"CODE",{});var Ue=n(K);Te=r(Ue,"fit()"),Ue.forEach(t),fe=r(g," and "),I=s(g,"CODE",{});var Ke=n(I);Ee=r(Ke,"predict()"),Ke.forEach(t),pe=r(g,`, such as when creating your own layers or models with
the Keras `),O=s(g,"CODE",{});var Oe=n(O);de=r(Oe,"Functional"),Oe.forEach(t),Ce=r(g,` API, there are three possibilities you can use to gather all the input Tensors in the first
positional argument:`),g.forEach(t),Z=m(l),_=s(l,"UL",{});var E=n(_);y=s(E,"LI",{});var D=n(y);ue=r(D,"a single Tensor with "),B=s(D,"CODE",{});var xe=n(B);se=r(xe,"input_ids"),xe.forEach(t),$e=r(D," only and nothing else: "),N=s(D,"CODE",{});var ze=n(N);Fe=r(ze,"model(input_ids)"),ze.forEach(t),D.forEach(t),Pe=m(E),k=s(E,"LI",{});var Q=n(k);ee=r(Q,`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),j=s(Q,"CODE",{});var Ie=n(j);ne=r(Ie,"model([input_ids, attention_mask])"),Ie.forEach(t),Me=r(Q," or "),H=s(Q,"CODE",{});var je=n(H);ie=r(je,"model([input_ids, attention_mask, token_type_ids])"),je.forEach(t),Q.forEach(t),De=m(E),C=s(E,"LI",{});var ve=n(C);ge=r(ve,`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),P=s(ve,"CODE",{});var Y=n(P);re=r(Y,'model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),Y.forEach(t),ve.forEach(t),E.forEach(t),J=m(l),b=s(l,"P",{});var G=n(b);Le=r(G,`Note that when creating models and layers with
`),T=s(G,"A",{href:!0,rel:!0});var He=n(T);Ae=r(He,"subclassing"),He.forEach(t),_e=r(G,` then you don\u2019t need to worry
about any of this, as you can just pass inputs like you would to any other Python function!`),G.forEach(t),this.h()},h(){h(T,"href","https://keras.io/guides/making_new_layers_and_models_via_subclassing/"),h(T,"rel","nofollow")},m(l,p){c(l,v,p),e(v,me),e(v,$),e($,te),e(v,le),c(l,W,p),c(l,w,p),e(w,S),e(S,be),e(w,he),e(w,F),e(F,oe),c(l,X,p),c(l,f,p),e(f,ke),e(f,U),e(U,we),e(f,ce),e(f,M),e(M,ye),e(f,ae),e(f,K),e(K,Te),e(f,fe),e(f,I),e(I,Ee),e(f,pe),e(f,O),e(O,de),e(f,Ce),c(l,Z,p),c(l,_,p),e(_,y),e(y,ue),e(y,B),e(B,se),e(y,$e),e(y,N),e(N,Fe),e(_,Pe),e(_,k),e(k,ee),e(k,j),e(j,ne),e(k,Me),e(k,H),e(H,ie),e(_,De),e(_,C),e(C,ge),e(C,P),e(P,re),c(l,J,p),c(l,b,p),e(b,Le),e(b,T),e(T,Ae),e(b,_e)},d(l){l&&t(v),l&&t(W),l&&t(w),l&&t(X),l&&t(f),l&&t(Z),l&&t(_),l&&t(J),l&&t(b)}}}function Ig(tt){let v,me,$,te,le,W,w,S,be,he,F,oe,X,f,ke,U,we,ce,M,ye,ae,K,Te,fe,I,Ee,pe,O,de,Ce,Z,_,y,ue,B,se,$e,N,Fe,Pe,k,ee,j,ne,Me,H,ie,De,C,ge,P,re,J,b,Le,T,Ae,_e;return{c(){v=a("p"),me=o("TensorFlow models and layers in "),$=a("code"),te=o("transformers"),le=o(" accept two formats as input:"),W=d(),w=a("ul"),S=a("li"),be=o("having all inputs as keyword arguments (like PyTorch models), or"),he=d(),F=a("li"),oe=o("having all inputs as a list, tuple or dict in the first positional argument."),X=d(),f=a("p"),ke=o(`The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
and layers. Because of this support, when using methods like `),U=a("code"),we=o("model.fit()"),ce=o(` things should \u201Cjust work\u201D for you - just
pass your inputs and labels in any format that `),M=a("code"),ye=o("model.fit()"),ae=o(` supports! If, however, you want to use the second
format outside of Keras methods like `),K=a("code"),Te=o("fit()"),fe=o(" and "),I=a("code"),Ee=o("predict()"),pe=o(`, such as when creating your own layers or models with
the Keras `),O=a("code"),de=o("Functional"),Ce=o(` API, there are three possibilities you can use to gather all the input Tensors in the first
positional argument:`),Z=d(),_=a("ul"),y=a("li"),ue=o("a single Tensor with "),B=a("code"),se=o("input_ids"),$e=o(" only and nothing else: "),N=a("code"),Fe=o("model(input_ids)"),Pe=d(),k=a("li"),ee=o(`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),j=a("code"),ne=o("model([input_ids, attention_mask])"),Me=o(" or "),H=a("code"),ie=o("model([input_ids, attention_mask, token_type_ids])"),De=d(),C=a("li"),ge=o(`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),P=a("code"),re=o('model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),J=d(),b=a("p"),Le=o(`Note that when creating models and layers with
`),T=a("a"),Ae=o("subclassing"),_e=o(` then you don\u2019t need to worry
about any of this, as you can just pass inputs like you would to any other Python function!`),this.h()},l(l){v=s(l,"P",{});var p=n(v);me=r(p,"TensorFlow models and layers in "),$=s(p,"CODE",{});var Be=n($);te=r(Be,"transformers"),Be.forEach(t),le=r(p," accept two formats as input:"),p.forEach(t),W=m(l),w=s(l,"UL",{});var V=n(w);S=s(V,"LI",{});var Ne=n(S);be=r(Ne,"having all inputs as keyword arguments (like PyTorch models), or"),Ne.forEach(t),he=m(V),F=s(V,"LI",{});var qe=n(F);oe=r(qe,"having all inputs as a list, tuple or dict in the first positional argument."),qe.forEach(t),V.forEach(t),X=m(l),f=s(l,"P",{});var g=n(f);ke=r(g,`The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
and layers. Because of this support, when using methods like `),U=s(g,"CODE",{});var Se=n(U);we=r(Se,"model.fit()"),Se.forEach(t),ce=r(g,` things should \u201Cjust work\u201D for you - just
pass your inputs and labels in any format that `),M=s(g,"CODE",{});var Re=n(M);ye=r(Re,"model.fit()"),Re.forEach(t),ae=r(g,` supports! If, however, you want to use the second
format outside of Keras methods like `),K=s(g,"CODE",{});var Ue=n(K);Te=r(Ue,"fit()"),Ue.forEach(t),fe=r(g," and "),I=s(g,"CODE",{});var Ke=n(I);Ee=r(Ke,"predict()"),Ke.forEach(t),pe=r(g,`, such as when creating your own layers or models with
the Keras `),O=s(g,"CODE",{});var Oe=n(O);de=r(Oe,"Functional"),Oe.forEach(t),Ce=r(g,` API, there are three possibilities you can use to gather all the input Tensors in the first
positional argument:`),g.forEach(t),Z=m(l),_=s(l,"UL",{});var E=n(_);y=s(E,"LI",{});var D=n(y);ue=r(D,"a single Tensor with "),B=s(D,"CODE",{});var xe=n(B);se=r(xe,"input_ids"),xe.forEach(t),$e=r(D," only and nothing else: "),N=s(D,"CODE",{});var ze=n(N);Fe=r(ze,"model(input_ids)"),ze.forEach(t),D.forEach(t),Pe=m(E),k=s(E,"LI",{});var Q=n(k);ee=r(Q,`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),j=s(Q,"CODE",{});var Ie=n(j);ne=r(Ie,"model([input_ids, attention_mask])"),Ie.forEach(t),Me=r(Q," or "),H=s(Q,"CODE",{});var je=n(H);ie=r(je,"model([input_ids, attention_mask, token_type_ids])"),je.forEach(t),Q.forEach(t),De=m(E),C=s(E,"LI",{});var ve=n(C);ge=r(ve,`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),P=s(ve,"CODE",{});var Y=n(P);re=r(Y,'model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),Y.forEach(t),ve.forEach(t),E.forEach(t),J=m(l),b=s(l,"P",{});var G=n(b);Le=r(G,`Note that when creating models and layers with
`),T=s(G,"A",{href:!0,rel:!0});var He=n(T);Ae=r(He,"subclassing"),He.forEach(t),_e=r(G,` then you don\u2019t need to worry
about any of this, as you can just pass inputs like you would to any other Python function!`),G.forEach(t),this.h()},h(){h(T,"href","https://keras.io/guides/making_new_layers_and_models_via_subclassing/"),h(T,"rel","nofollow")},m(l,p){c(l,v,p),e(v,me),e(v,$),e($,te),e(v,le),c(l,W,p),c(l,w,p),e(w,S),e(S,be),e(w,he),e(w,F),e(F,oe),c(l,X,p),c(l,f,p),e(f,ke),e(f,U),e(U,we),e(f,ce),e(f,M),e(M,ye),e(f,ae),e(f,K),e(K,Te),e(f,fe),e(f,I),e(I,Ee),e(f,pe),e(f,O),e(O,de),e(f,Ce),c(l,Z,p),c(l,_,p),e(_,y),e(y,ue),e(y,B),e(B,se),e(y,$e),e(y,N),e(N,Fe),e(_,Pe),e(_,k),e(k,ee),e(k,j),e(j,ne),e(k,Me),e(k,H),e(H,ie),e(_,De),e(_,C),e(C,ge),e(C,P),e(P,re),c(l,J,p),c(l,b,p),e(b,Le),e(b,T),e(T,Ae),e(b,_e)},d(l){l&&t(v),l&&t(W),l&&t(w),l&&t(X),l&&t(f),l&&t(Z),l&&t(_),l&&t(J),l&&t(b)}}}function Og(tt){let v,me,$,te,le,W,w,S,be,he,F,oe,X,f,ke,U,we,ce,M,ye,ae,K,Te,fe,I,Ee,pe,O,de,Ce,Z,_,y,ue,B,se,$e,N,Fe,Pe,k,ee,j,ne,Me,H,ie,De,C,ge,P,re,J,b,Le,T,Ae,_e;return{c(){v=a("p"),me=o("TensorFlow models and layers in "),$=a("code"),te=o("transformers"),le=o(" accept two formats as input:"),W=d(),w=a("ul"),S=a("li"),be=o("having all inputs as keyword arguments (like PyTorch models), or"),he=d(),F=a("li"),oe=o("having all inputs as a list, tuple or dict in the first positional argument."),X=d(),f=a("p"),ke=o(`The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
and layers. Because of this support, when using methods like `),U=a("code"),we=o("model.fit()"),ce=o(` things should \u201Cjust work\u201D for you - just
pass your inputs and labels in any format that `),M=a("code"),ye=o("model.fit()"),ae=o(` supports! If, however, you want to use the second
format outside of Keras methods like `),K=a("code"),Te=o("fit()"),fe=o(" and "),I=a("code"),Ee=o("predict()"),pe=o(`, such as when creating your own layers or models with
the Keras `),O=a("code"),de=o("Functional"),Ce=o(` API, there are three possibilities you can use to gather all the input Tensors in the first
positional argument:`),Z=d(),_=a("ul"),y=a("li"),ue=o("a single Tensor with "),B=a("code"),se=o("input_ids"),$e=o(" only and nothing else: "),N=a("code"),Fe=o("model(input_ids)"),Pe=d(),k=a("li"),ee=o(`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),j=a("code"),ne=o("model([input_ids, attention_mask])"),Me=o(" or "),H=a("code"),ie=o("model([input_ids, attention_mask, token_type_ids])"),De=d(),C=a("li"),ge=o(`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),P=a("code"),re=o('model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),J=d(),b=a("p"),Le=o(`Note that when creating models and layers with
`),T=a("a"),Ae=o("subclassing"),_e=o(` then you don\u2019t need to worry
about any of this, as you can just pass inputs like you would to any other Python function!`),this.h()},l(l){v=s(l,"P",{});var p=n(v);me=r(p,"TensorFlow models and layers in "),$=s(p,"CODE",{});var Be=n($);te=r(Be,"transformers"),Be.forEach(t),le=r(p," accept two formats as input:"),p.forEach(t),W=m(l),w=s(l,"UL",{});var V=n(w);S=s(V,"LI",{});var Ne=n(S);be=r(Ne,"having all inputs as keyword arguments (like PyTorch models), or"),Ne.forEach(t),he=m(V),F=s(V,"LI",{});var qe=n(F);oe=r(qe,"having all inputs as a list, tuple or dict in the first positional argument."),qe.forEach(t),V.forEach(t),X=m(l),f=s(l,"P",{});var g=n(f);ke=r(g,`The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
and layers. Because of this support, when using methods like `),U=s(g,"CODE",{});var Se=n(U);we=r(Se,"model.fit()"),Se.forEach(t),ce=r(g,` things should \u201Cjust work\u201D for you - just
pass your inputs and labels in any format that `),M=s(g,"CODE",{});var Re=n(M);ye=r(Re,"model.fit()"),Re.forEach(t),ae=r(g,` supports! If, however, you want to use the second
format outside of Keras methods like `),K=s(g,"CODE",{});var Ue=n(K);Te=r(Ue,"fit()"),Ue.forEach(t),fe=r(g," and "),I=s(g,"CODE",{});var Ke=n(I);Ee=r(Ke,"predict()"),Ke.forEach(t),pe=r(g,`, such as when creating your own layers or models with
the Keras `),O=s(g,"CODE",{});var Oe=n(O);de=r(Oe,"Functional"),Oe.forEach(t),Ce=r(g,` API, there are three possibilities you can use to gather all the input Tensors in the first
positional argument:`),g.forEach(t),Z=m(l),_=s(l,"UL",{});var E=n(_);y=s(E,"LI",{});var D=n(y);ue=r(D,"a single Tensor with "),B=s(D,"CODE",{});var xe=n(B);se=r(xe,"input_ids"),xe.forEach(t),$e=r(D," only and nothing else: "),N=s(D,"CODE",{});var ze=n(N);Fe=r(ze,"model(input_ids)"),ze.forEach(t),D.forEach(t),Pe=m(E),k=s(E,"LI",{});var Q=n(k);ee=r(Q,`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),j=s(Q,"CODE",{});var Ie=n(j);ne=r(Ie,"model([input_ids, attention_mask])"),Ie.forEach(t),Me=r(Q," or "),H=s(Q,"CODE",{});var je=n(H);ie=r(je,"model([input_ids, attention_mask, token_type_ids])"),je.forEach(t),Q.forEach(t),De=m(E),C=s(E,"LI",{});var ve=n(C);ge=r(ve,`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),P=s(ve,"CODE",{});var Y=n(P);re=r(Y,'model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),Y.forEach(t),ve.forEach(t),E.forEach(t),J=m(l),b=s(l,"P",{});var G=n(b);Le=r(G,`Note that when creating models and layers with
`),T=s(G,"A",{href:!0,rel:!0});var He=n(T);Ae=r(He,"subclassing"),He.forEach(t),_e=r(G,` then you don\u2019t need to worry
about any of this, as you can just pass inputs like you would to any other Python function!`),G.forEach(t),this.h()},h(){h(T,"href","https://keras.io/guides/making_new_layers_and_models_via_subclassing/"),h(T,"rel","nofollow")},m(l,p){c(l,v,p),e(v,me),e(v,$),e($,te),e(v,le),c(l,W,p),c(l,w,p),e(w,S),e(S,be),e(w,he),e(w,F),e(F,oe),c(l,X,p),c(l,f,p),e(f,ke),e(f,U),e(U,we),e(f,ce),e(f,M),e(M,ye),e(f,ae),e(f,K),e(K,Te),e(f,fe),e(f,I),e(I,Ee),e(f,pe),e(f,O),e(O,de),e(f,Ce),c(l,Z,p),c(l,_,p),e(_,y),e(y,ue),e(y,B),e(B,se),e(y,$e),e(y,N),e(N,Fe),e(_,Pe),e(_,k),e(k,ee),e(k,j),e(j,ne),e(k,Me),e(k,H),e(H,ie),e(_,De),e(_,C),e(C,ge),e(C,P),e(P,re),c(l,J,p),c(l,b,p),e(b,Le),e(b,T),e(T,Ae),e(b,_e)},d(l){l&&t(v),l&&t(W),l&&t(w),l&&t(X),l&&t(f),l&&t(Z),l&&t(_),l&&t(J),l&&t(b)}}}function Bg(tt){let v,me,$,te,le,W,w,S,be,he,F,oe,X,f,ke,U,we,ce,M,ye,ae,K,Te,fe,I,Ee,pe,O,de,Ce,Z,_,y,ue,B,se,$e,N,Fe,Pe,k,ee,j,ne,Me,H,ie,De,C,ge,P,re,J,b,Le,T,Ae,_e;return{c(){v=a("p"),me=o("TensorFlow models and layers in "),$=a("code"),te=o("transformers"),le=o(" accept two formats as input:"),W=d(),w=a("ul"),S=a("li"),be=o("having all inputs as keyword arguments (like PyTorch models), or"),he=d(),F=a("li"),oe=o("having all inputs as a list, tuple or dict in the first positional argument."),X=d(),f=a("p"),ke=o(`The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
and layers. Because of this support, when using methods like `),U=a("code"),we=o("model.fit()"),ce=o(` things should \u201Cjust work\u201D for you - just
pass your inputs and labels in any format that `),M=a("code"),ye=o("model.fit()"),ae=o(` supports! If, however, you want to use the second
format outside of Keras methods like `),K=a("code"),Te=o("fit()"),fe=o(" and "),I=a("code"),Ee=o("predict()"),pe=o(`, such as when creating your own layers or models with
the Keras `),O=a("code"),de=o("Functional"),Ce=o(` API, there are three possibilities you can use to gather all the input Tensors in the first
positional argument:`),Z=d(),_=a("ul"),y=a("li"),ue=o("a single Tensor with "),B=a("code"),se=o("input_ids"),$e=o(" only and nothing else: "),N=a("code"),Fe=o("model(input_ids)"),Pe=d(),k=a("li"),ee=o(`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),j=a("code"),ne=o("model([input_ids, attention_mask])"),Me=o(" or "),H=a("code"),ie=o("model([input_ids, attention_mask, token_type_ids])"),De=d(),C=a("li"),ge=o(`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),P=a("code"),re=o('model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),J=d(),b=a("p"),Le=o(`Note that when creating models and layers with
`),T=a("a"),Ae=o("subclassing"),_e=o(` then you don\u2019t need to worry
about any of this, as you can just pass inputs like you would to any other Python function!`),this.h()},l(l){v=s(l,"P",{});var p=n(v);me=r(p,"TensorFlow models and layers in "),$=s(p,"CODE",{});var Be=n($);te=r(Be,"transformers"),Be.forEach(t),le=r(p," accept two formats as input:"),p.forEach(t),W=m(l),w=s(l,"UL",{});var V=n(w);S=s(V,"LI",{});var Ne=n(S);be=r(Ne,"having all inputs as keyword arguments (like PyTorch models), or"),Ne.forEach(t),he=m(V),F=s(V,"LI",{});var qe=n(F);oe=r(qe,"having all inputs as a list, tuple or dict in the first positional argument."),qe.forEach(t),V.forEach(t),X=m(l),f=s(l,"P",{});var g=n(f);ke=r(g,`The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
and layers. Because of this support, when using methods like `),U=s(g,"CODE",{});var Se=n(U);we=r(Se,"model.fit()"),Se.forEach(t),ce=r(g,` things should \u201Cjust work\u201D for you - just
pass your inputs and labels in any format that `),M=s(g,"CODE",{});var Re=n(M);ye=r(Re,"model.fit()"),Re.forEach(t),ae=r(g,` supports! If, however, you want to use the second
format outside of Keras methods like `),K=s(g,"CODE",{});var Ue=n(K);Te=r(Ue,"fit()"),Ue.forEach(t),fe=r(g," and "),I=s(g,"CODE",{});var Ke=n(I);Ee=r(Ke,"predict()"),Ke.forEach(t),pe=r(g,`, such as when creating your own layers or models with
the Keras `),O=s(g,"CODE",{});var Oe=n(O);de=r(Oe,"Functional"),Oe.forEach(t),Ce=r(g,` API, there are three possibilities you can use to gather all the input Tensors in the first
positional argument:`),g.forEach(t),Z=m(l),_=s(l,"UL",{});var E=n(_);y=s(E,"LI",{});var D=n(y);ue=r(D,"a single Tensor with "),B=s(D,"CODE",{});var xe=n(B);se=r(xe,"input_ids"),xe.forEach(t),$e=r(D," only and nothing else: "),N=s(D,"CODE",{});var ze=n(N);Fe=r(ze,"model(input_ids)"),ze.forEach(t),D.forEach(t),Pe=m(E),k=s(E,"LI",{});var Q=n(k);ee=r(Q,`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),j=s(Q,"CODE",{});var Ie=n(j);ne=r(Ie,"model([input_ids, attention_mask])"),Ie.forEach(t),Me=r(Q," or "),H=s(Q,"CODE",{});var je=n(H);ie=r(je,"model([input_ids, attention_mask, token_type_ids])"),je.forEach(t),Q.forEach(t),De=m(E),C=s(E,"LI",{});var ve=n(C);ge=r(ve,`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),P=s(ve,"CODE",{});var Y=n(P);re=r(Y,'model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),Y.forEach(t),ve.forEach(t),E.forEach(t),J=m(l),b=s(l,"P",{});var G=n(b);Le=r(G,`Note that when creating models and layers with
`),T=s(G,"A",{href:!0,rel:!0});var He=n(T);Ae=r(He,"subclassing"),He.forEach(t),_e=r(G,` then you don\u2019t need to worry
about any of this, as you can just pass inputs like you would to any other Python function!`),G.forEach(t),this.h()},h(){h(T,"href","https://keras.io/guides/making_new_layers_and_models_via_subclassing/"),h(T,"rel","nofollow")},m(l,p){c(l,v,p),e(v,me),e(v,$),e($,te),e(v,le),c(l,W,p),c(l,w,p),e(w,S),e(S,be),e(w,he),e(w,F),e(F,oe),c(l,X,p),c(l,f,p),e(f,ke),e(f,U),e(U,we),e(f,ce),e(f,M),e(M,ye),e(f,ae),e(f,K),e(K,Te),e(f,fe),e(f,I),e(I,Ee),e(f,pe),e(f,O),e(O,de),e(f,Ce),c(l,Z,p),c(l,_,p),e(_,y),e(y,ue),e(y,B),e(B,se),e(y,$e),e(y,N),e(N,Fe),e(_,Pe),e(_,k),e(k,ee),e(k,j),e(j,ne),e(k,Me),e(k,H),e(H,ie),e(_,De),e(_,C),e(C,ge),e(C,P),e(P,re),c(l,J,p),c(l,b,p),e(b,Le),e(b,T),e(T,Ae),e(b,_e)},d(l){l&&t(v),l&&t(W),l&&t(w),l&&t(X),l&&t(f),l&&t(Z),l&&t(_),l&&t(J),l&&t(b)}}}function Ng(tt){let v,me,$,te,le,W,w,S,be,he,F,oe,X,f,ke,U,we,ce,M,ye,ae,K,Te,fe,I,Ee,pe,O,de,Ce,Z,_,y,ue,B,se,$e,N,Fe,Pe,k,ee,j,ne,Me,H,ie,De,C,ge,P,re,J,b,Le,T,Ae,_e;return{c(){v=a("p"),me=o("TensorFlow models and layers in "),$=a("code"),te=o("transformers"),le=o(" accept two formats as input:"),W=d(),w=a("ul"),S=a("li"),be=o("having all inputs as keyword arguments (like PyTorch models), or"),he=d(),F=a("li"),oe=o("having all inputs as a list, tuple or dict in the first positional argument."),X=d(),f=a("p"),ke=o(`The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
and layers. Because of this support, when using methods like `),U=a("code"),we=o("model.fit()"),ce=o(` things should \u201Cjust work\u201D for you - just
pass your inputs and labels in any format that `),M=a("code"),ye=o("model.fit()"),ae=o(` supports! If, however, you want to use the second
format outside of Keras methods like `),K=a("code"),Te=o("fit()"),fe=o(" and "),I=a("code"),Ee=o("predict()"),pe=o(`, such as when creating your own layers or models with
the Keras `),O=a("code"),de=o("Functional"),Ce=o(` API, there are three possibilities you can use to gather all the input Tensors in the first
positional argument:`),Z=d(),_=a("ul"),y=a("li"),ue=o("a single Tensor with "),B=a("code"),se=o("input_ids"),$e=o(" only and nothing else: "),N=a("code"),Fe=o("model(input_ids)"),Pe=d(),k=a("li"),ee=o(`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),j=a("code"),ne=o("model([input_ids, attention_mask])"),Me=o(" or "),H=a("code"),ie=o("model([input_ids, attention_mask, token_type_ids])"),De=d(),C=a("li"),ge=o(`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),P=a("code"),re=o('model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),J=d(),b=a("p"),Le=o(`Note that when creating models and layers with
`),T=a("a"),Ae=o("subclassing"),_e=o(` then you don\u2019t need to worry
about any of this, as you can just pass inputs like you would to any other Python function!`),this.h()},l(l){v=s(l,"P",{});var p=n(v);me=r(p,"TensorFlow models and layers in "),$=s(p,"CODE",{});var Be=n($);te=r(Be,"transformers"),Be.forEach(t),le=r(p," accept two formats as input:"),p.forEach(t),W=m(l),w=s(l,"UL",{});var V=n(w);S=s(V,"LI",{});var Ne=n(S);be=r(Ne,"having all inputs as keyword arguments (like PyTorch models), or"),Ne.forEach(t),he=m(V),F=s(V,"LI",{});var qe=n(F);oe=r(qe,"having all inputs as a list, tuple or dict in the first positional argument."),qe.forEach(t),V.forEach(t),X=m(l),f=s(l,"P",{});var g=n(f);ke=r(g,`The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
and layers. Because of this support, when using methods like `),U=s(g,"CODE",{});var Se=n(U);we=r(Se,"model.fit()"),Se.forEach(t),ce=r(g,` things should \u201Cjust work\u201D for you - just
pass your inputs and labels in any format that `),M=s(g,"CODE",{});var Re=n(M);ye=r(Re,"model.fit()"),Re.forEach(t),ae=r(g,` supports! If, however, you want to use the second
format outside of Keras methods like `),K=s(g,"CODE",{});var Ue=n(K);Te=r(Ue,"fit()"),Ue.forEach(t),fe=r(g," and "),I=s(g,"CODE",{});var Ke=n(I);Ee=r(Ke,"predict()"),Ke.forEach(t),pe=r(g,`, such as when creating your own layers or models with
the Keras `),O=s(g,"CODE",{});var Oe=n(O);de=r(Oe,"Functional"),Oe.forEach(t),Ce=r(g,` API, there are three possibilities you can use to gather all the input Tensors in the first
positional argument:`),g.forEach(t),Z=m(l),_=s(l,"UL",{});var E=n(_);y=s(E,"LI",{});var D=n(y);ue=r(D,"a single Tensor with "),B=s(D,"CODE",{});var xe=n(B);se=r(xe,"input_ids"),xe.forEach(t),$e=r(D," only and nothing else: "),N=s(D,"CODE",{});var ze=n(N);Fe=r(ze,"model(input_ids)"),ze.forEach(t),D.forEach(t),Pe=m(E),k=s(E,"LI",{});var Q=n(k);ee=r(Q,`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),j=s(Q,"CODE",{});var Ie=n(j);ne=r(Ie,"model([input_ids, attention_mask])"),Ie.forEach(t),Me=r(Q," or "),H=s(Q,"CODE",{});var je=n(H);ie=r(je,"model([input_ids, attention_mask, token_type_ids])"),je.forEach(t),Q.forEach(t),De=m(E),C=s(E,"LI",{});var ve=n(C);ge=r(ve,`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),P=s(ve,"CODE",{});var Y=n(P);re=r(Y,'model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),Y.forEach(t),ve.forEach(t),E.forEach(t),J=m(l),b=s(l,"P",{});var G=n(b);Le=r(G,`Note that when creating models and layers with
`),T=s(G,"A",{href:!0,rel:!0});var He=n(T);Ae=r(He,"subclassing"),He.forEach(t),_e=r(G,` then you don\u2019t need to worry
about any of this, as you can just pass inputs like you would to any other Python function!`),G.forEach(t),this.h()},h(){h(T,"href","https://keras.io/guides/making_new_layers_and_models_via_subclassing/"),h(T,"rel","nofollow")},m(l,p){c(l,v,p),e(v,me),e(v,$),e($,te),e(v,le),c(l,W,p),c(l,w,p),e(w,S),e(S,be),e(w,he),e(w,F),e(F,oe),c(l,X,p),c(l,f,p),e(f,ke),e(f,U),e(U,we),e(f,ce),e(f,M),e(M,ye),e(f,ae),e(f,K),e(K,Te),e(f,fe),e(f,I),e(I,Ee),e(f,pe),e(f,O),e(O,de),e(f,Ce),c(l,Z,p),c(l,_,p),e(_,y),e(y,ue),e(y,B),e(B,se),e(y,$e),e(y,N),e(N,Fe),e(_,Pe),e(_,k),e(k,ee),e(k,j),e(j,ne),e(k,Me),e(k,H),e(H,ie),e(_,De),e(_,C),e(C,ge),e(C,P),e(P,re),c(l,J,p),c(l,b,p),e(b,Le),e(b,T),e(T,Ae),e(b,_e)},d(l){l&&t(v),l&&t(W),l&&t(w),l&&t(X),l&&t(f),l&&t(Z),l&&t(_),l&&t(J),l&&t(b)}}}function Sg(tt){let v,me,$,te,le,W,w,S,be,he,F,oe,X,f,ke,U,we,ce,M,ye,ae,K,Te,fe,I,Ee,pe,O,de,Ce,Z,_,y,ue,B,se,$e,N,Fe,Pe,k,ee,j,ne,Me,H,ie,De,C,ge,P,re,J,b,Le,T,Ae,_e;return{c(){v=a("p"),me=o("TensorFlow models and layers in "),$=a("code"),te=o("transformers"),le=o(" accept two formats as input:"),W=d(),w=a("ul"),S=a("li"),be=o("having all inputs as keyword arguments (like PyTorch models), or"),he=d(),F=a("li"),oe=o("having all inputs as a list, tuple or dict in the first positional argument."),X=d(),f=a("p"),ke=o(`The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
and layers. Because of this support, when using methods like `),U=a("code"),we=o("model.fit()"),ce=o(` things should \u201Cjust work\u201D for you - just
pass your inputs and labels in any format that `),M=a("code"),ye=o("model.fit()"),ae=o(` supports! If, however, you want to use the second
format outside of Keras methods like `),K=a("code"),Te=o("fit()"),fe=o(" and "),I=a("code"),Ee=o("predict()"),pe=o(`, such as when creating your own layers or models with
the Keras `),O=a("code"),de=o("Functional"),Ce=o(` API, there are three possibilities you can use to gather all the input Tensors in the first
positional argument:`),Z=d(),_=a("ul"),y=a("li"),ue=o("a single Tensor with "),B=a("code"),se=o("input_ids"),$e=o(" only and nothing else: "),N=a("code"),Fe=o("model(input_ids)"),Pe=d(),k=a("li"),ee=o(`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),j=a("code"),ne=o("model([input_ids, attention_mask])"),Me=o(" or "),H=a("code"),ie=o("model([input_ids, attention_mask, token_type_ids])"),De=d(),C=a("li"),ge=o(`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),P=a("code"),re=o('model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),J=d(),b=a("p"),Le=o(`Note that when creating models and layers with
`),T=a("a"),Ae=o("subclassing"),_e=o(` then you don\u2019t need to worry
about any of this, as you can just pass inputs like you would to any other Python function!`),this.h()},l(l){v=s(l,"P",{});var p=n(v);me=r(p,"TensorFlow models and layers in "),$=s(p,"CODE",{});var Be=n($);te=r(Be,"transformers"),Be.forEach(t),le=r(p," accept two formats as input:"),p.forEach(t),W=m(l),w=s(l,"UL",{});var V=n(w);S=s(V,"LI",{});var Ne=n(S);be=r(Ne,"having all inputs as keyword arguments (like PyTorch models), or"),Ne.forEach(t),he=m(V),F=s(V,"LI",{});var qe=n(F);oe=r(qe,"having all inputs as a list, tuple or dict in the first positional argument."),qe.forEach(t),V.forEach(t),X=m(l),f=s(l,"P",{});var g=n(f);ke=r(g,`The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
and layers. Because of this support, when using methods like `),U=s(g,"CODE",{});var Se=n(U);we=r(Se,"model.fit()"),Se.forEach(t),ce=r(g,` things should \u201Cjust work\u201D for you - just
pass your inputs and labels in any format that `),M=s(g,"CODE",{});var Re=n(M);ye=r(Re,"model.fit()"),Re.forEach(t),ae=r(g,` supports! If, however, you want to use the second
format outside of Keras methods like `),K=s(g,"CODE",{});var Ue=n(K);Te=r(Ue,"fit()"),Ue.forEach(t),fe=r(g," and "),I=s(g,"CODE",{});var Ke=n(I);Ee=r(Ke,"predict()"),Ke.forEach(t),pe=r(g,`, such as when creating your own layers or models with
the Keras `),O=s(g,"CODE",{});var Oe=n(O);de=r(Oe,"Functional"),Oe.forEach(t),Ce=r(g,` API, there are three possibilities you can use to gather all the input Tensors in the first
positional argument:`),g.forEach(t),Z=m(l),_=s(l,"UL",{});var E=n(_);y=s(E,"LI",{});var D=n(y);ue=r(D,"a single Tensor with "),B=s(D,"CODE",{});var xe=n(B);se=r(xe,"input_ids"),xe.forEach(t),$e=r(D," only and nothing else: "),N=s(D,"CODE",{});var ze=n(N);Fe=r(ze,"model(input_ids)"),ze.forEach(t),D.forEach(t),Pe=m(E),k=s(E,"LI",{});var Q=n(k);ee=r(Q,`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),j=s(Q,"CODE",{});var Ie=n(j);ne=r(Ie,"model([input_ids, attention_mask])"),Ie.forEach(t),Me=r(Q," or "),H=s(Q,"CODE",{});var je=n(H);ie=r(je,"model([input_ids, attention_mask, token_type_ids])"),je.forEach(t),Q.forEach(t),De=m(E),C=s(E,"LI",{});var ve=n(C);ge=r(ve,`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),P=s(ve,"CODE",{});var Y=n(P);re=r(Y,'model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),Y.forEach(t),ve.forEach(t),E.forEach(t),J=m(l),b=s(l,"P",{});var G=n(b);Le=r(G,`Note that when creating models and layers with
`),T=s(G,"A",{href:!0,rel:!0});var He=n(T);Ae=r(He,"subclassing"),He.forEach(t),_e=r(G,` then you don\u2019t need to worry
about any of this, as you can just pass inputs like you would to any other Python function!`),G.forEach(t),this.h()},h(){h(T,"href","https://keras.io/guides/making_new_layers_and_models_via_subclassing/"),h(T,"rel","nofollow")},m(l,p){c(l,v,p),e(v,me),e(v,$),e($,te),e(v,le),c(l,W,p),c(l,w,p),e(w,S),e(S,be),e(w,he),e(w,F),e(F,oe),c(l,X,p),c(l,f,p),e(f,ke),e(f,U),e(U,we),e(f,ce),e(f,M),e(M,ye),e(f,ae),e(f,K),e(K,Te),e(f,fe),e(f,I),e(I,Ee),e(f,pe),e(f,O),e(O,de),e(f,Ce),c(l,Z,p),c(l,_,p),e(_,y),e(y,ue),e(y,B),e(B,se),e(y,$e),e(y,N),e(N,Fe),e(_,Pe),e(_,k),e(k,ee),e(k,j),e(j,ne),e(k,Me),e(k,H),e(H,ie),e(_,De),e(_,C),e(C,ge),e(C,P),e(P,re),c(l,J,p),c(l,b,p),e(b,Le),e(b,T),e(T,Ae),e(b,_e)},d(l){l&&t(v),l&&t(W),l&&t(w),l&&t(X),l&&t(f),l&&t(Z),l&&t(_),l&&t(J),l&&t(b)}}}function Ug(tt){let v,me,$,te,le,W,w,S,be,he,F,oe,X,f,ke,U,we,ce,M,ye,ae,K,Te,fe,I,Ee,pe,O,de,Ce,Z,_,y,ue,B,se,$e,N,Fe,Pe,k,ee,j,ne,Me,H,ie,De,C,ge,P,re,J,b,Le,T,Ae,_e;return{c(){v=a("p"),me=o("TensorFlow models and layers in "),$=a("code"),te=o("transformers"),le=o(" accept two formats as input:"),W=d(),w=a("ul"),S=a("li"),be=o("having all inputs as keyword arguments (like PyTorch models), or"),he=d(),F=a("li"),oe=o("having all inputs as a list, tuple or dict in the first positional argument."),X=d(),f=a("p"),ke=o(`The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
and layers. Because of this support, when using methods like `),U=a("code"),we=o("model.fit()"),ce=o(` things should \u201Cjust work\u201D for you - just
pass your inputs and labels in any format that `),M=a("code"),ye=o("model.fit()"),ae=o(` supports! If, however, you want to use the second
format outside of Keras methods like `),K=a("code"),Te=o("fit()"),fe=o(" and "),I=a("code"),Ee=o("predict()"),pe=o(`, such as when creating your own layers or models with
the Keras `),O=a("code"),de=o("Functional"),Ce=o(` API, there are three possibilities you can use to gather all the input Tensors in the first
positional argument:`),Z=d(),_=a("ul"),y=a("li"),ue=o("a single Tensor with "),B=a("code"),se=o("input_ids"),$e=o(" only and nothing else: "),N=a("code"),Fe=o("model(input_ids)"),Pe=d(),k=a("li"),ee=o(`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),j=a("code"),ne=o("model([input_ids, attention_mask])"),Me=o(" or "),H=a("code"),ie=o("model([input_ids, attention_mask, token_type_ids])"),De=d(),C=a("li"),ge=o(`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),P=a("code"),re=o('model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),J=d(),b=a("p"),Le=o(`Note that when creating models and layers with
`),T=a("a"),Ae=o("subclassing"),_e=o(` then you don\u2019t need to worry
about any of this, as you can just pass inputs like you would to any other Python function!`),this.h()},l(l){v=s(l,"P",{});var p=n(v);me=r(p,"TensorFlow models and layers in "),$=s(p,"CODE",{});var Be=n($);te=r(Be,"transformers"),Be.forEach(t),le=r(p," accept two formats as input:"),p.forEach(t),W=m(l),w=s(l,"UL",{});var V=n(w);S=s(V,"LI",{});var Ne=n(S);be=r(Ne,"having all inputs as keyword arguments (like PyTorch models), or"),Ne.forEach(t),he=m(V),F=s(V,"LI",{});var qe=n(F);oe=r(qe,"having all inputs as a list, tuple or dict in the first positional argument."),qe.forEach(t),V.forEach(t),X=m(l),f=s(l,"P",{});var g=n(f);ke=r(g,`The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
and layers. Because of this support, when using methods like `),U=s(g,"CODE",{});var Se=n(U);we=r(Se,"model.fit()"),Se.forEach(t),ce=r(g,` things should \u201Cjust work\u201D for you - just
pass your inputs and labels in any format that `),M=s(g,"CODE",{});var Re=n(M);ye=r(Re,"model.fit()"),Re.forEach(t),ae=r(g,` supports! If, however, you want to use the second
format outside of Keras methods like `),K=s(g,"CODE",{});var Ue=n(K);Te=r(Ue,"fit()"),Ue.forEach(t),fe=r(g," and "),I=s(g,"CODE",{});var Ke=n(I);Ee=r(Ke,"predict()"),Ke.forEach(t),pe=r(g,`, such as when creating your own layers or models with
the Keras `),O=s(g,"CODE",{});var Oe=n(O);de=r(Oe,"Functional"),Oe.forEach(t),Ce=r(g,` API, there are three possibilities you can use to gather all the input Tensors in the first
positional argument:`),g.forEach(t),Z=m(l),_=s(l,"UL",{});var E=n(_);y=s(E,"LI",{});var D=n(y);ue=r(D,"a single Tensor with "),B=s(D,"CODE",{});var xe=n(B);se=r(xe,"input_ids"),xe.forEach(t),$e=r(D," only and nothing else: "),N=s(D,"CODE",{});var ze=n(N);Fe=r(ze,"model(input_ids)"),ze.forEach(t),D.forEach(t),Pe=m(E),k=s(E,"LI",{});var Q=n(k);ee=r(Q,`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),j=s(Q,"CODE",{});var Ie=n(j);ne=r(Ie,"model([input_ids, attention_mask])"),Ie.forEach(t),Me=r(Q," or "),H=s(Q,"CODE",{});var je=n(H);ie=r(je,"model([input_ids, attention_mask, token_type_ids])"),je.forEach(t),Q.forEach(t),De=m(E),C=s(E,"LI",{});var ve=n(C);ge=r(ve,`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),P=s(ve,"CODE",{});var Y=n(P);re=r(Y,'model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),Y.forEach(t),ve.forEach(t),E.forEach(t),J=m(l),b=s(l,"P",{});var G=n(b);Le=r(G,`Note that when creating models and layers with
`),T=s(G,"A",{href:!0,rel:!0});var He=n(T);Ae=r(He,"subclassing"),He.forEach(t),_e=r(G,` then you don\u2019t need to worry
about any of this, as you can just pass inputs like you would to any other Python function!`),G.forEach(t),this.h()},h(){h(T,"href","https://keras.io/guides/making_new_layers_and_models_via_subclassing/"),h(T,"rel","nofollow")},m(l,p){c(l,v,p),e(v,me),e(v,$),e($,te),e(v,le),c(l,W,p),c(l,w,p),e(w,S),e(S,be),e(w,he),e(w,F),e(F,oe),c(l,X,p),c(l,f,p),e(f,ke),e(f,U),e(U,we),e(f,ce),e(f,M),e(M,ye),e(f,ae),e(f,K),e(K,Te),e(f,fe),e(f,I),e(I,Ee),e(f,pe),e(f,O),e(O,de),e(f,Ce),c(l,Z,p),c(l,_,p),e(_,y),e(y,ue),e(y,B),e(B,se),e(y,$e),e(y,N),e(N,Fe),e(_,Pe),e(_,k),e(k,ee),e(k,j),e(j,ne),e(k,Me),e(k,H),e(H,ie),e(_,De),e(_,C),e(C,ge),e(C,P),e(P,re),c(l,J,p),c(l,b,p),e(b,Le),e(b,T),e(T,Ae),e(b,_e)},d(l){l&&t(v),l&&t(W),l&&t(w),l&&t(X),l&&t(f),l&&t(Z),l&&t(_),l&&t(J),l&&t(b)}}}function Kg(tt){let v,me,$,te,le,W,w,S,be,he,F,oe,X,f,ke,U,we,ce,M,ye,ae,K,Te,fe,I,Ee,pe,O,de,Ce,Z,_,y,ue,B,se,$e,N,Fe,Pe,k,ee,j,ne,Me,H,ie,De,C,ge,P,re,J,b,Le,T,Ae,_e,l,p,Be,V,Ne,qe,g,Se,Re,Ue,Ke,Oe,E,D,xe,ze,Q,Ie,je,ve,Y,G,He,bt,ul,ba,gl,_l,ka,vl,bl,wo,kl,wl,yl,yo,Tl,wa,El,Cl,$l,kt,To,Fl,ds,Pl,Ml,Eo,ya,Dl,ms,Ll,Al,Ta,Rl,hs,zl,ql,Vt,Co,xl,$o,Il,cs,Ol,Bl,Nl,Wt,Fo,Sl,fs,Ul,Kl,Ea,Po,vn,Lt,Gt,ps,Mo,jl,us,Hl,bn,ot,Do,Ql,ht,Vl,gs,Wl,Gl,Ca,Xl,Jl,$a,Yl,Zl,Lo,ed,td,od,Ao,rd,Fa,ad,sd,nd,wt,Ro,id,_s,ld,dd,zo,Pa,md,vs,hd,cd,Ma,fd,bs,pd,ud,Xt,qo,gd,ks,_d,kn,At,Jt,ws,xo,vd,ys,bd,wn,rt,Io,kd,Ts,wd,yd,Oo,Td,Da,Ed,Cd,$d,Bo,Fd,No,Pd,Md,Dd,So,Ld,La,Ad,Rd,yn,Rt,Yt,Es,Uo,zd,Cs,qd,Tn,at,Ko,xd,jo,Id,$s,Od,Bd,Nd,Ho,Sd,Aa,Ud,Kd,jd,Qo,Hd,Vo,Qd,Vd,Wd,Wo,Gd,Ra,Xd,Jd,En,zt,Zt,Fs,Go,Yd,Ps,Zd,Cn,st,Xo,em,Jo,tm,Ms,om,rm,am,Yo,sm,za,nm,im,lm,Zo,dm,er,mm,hm,cm,tr,fm,qa,pm,um,$n,qt,eo,Ds,or,gm,Ls,_m,Fn,nt,rr,vm,As,bm,km,ar,wm,xa,ym,Tm,Em,sr,Cm,nr,$m,Fm,Pm,ir,Mm,Ia,Dm,Lm,Pn,xt,to,Rs,lr,Am,zs,Rm,Mn,it,dr,zm,qs,qm,xm,mr,Im,Oa,Om,Bm,Nm,hr,Sm,cr,Um,Km,jm,fr,Hm,Ba,Qm,Vm,Dn,It,oo,xs,pr,Wm,Is,Gm,Ln,lt,ur,Xm,Os,Jm,Ym,gr,Zm,Na,eh,th,oh,_r,rh,vr,ah,sh,nh,br,ih,Sa,lh,dh,An,Ot,ro,Bs,kr,mh,Ns,hh,Rn,dt,wr,ch,ao,fh,Ss,ph,uh,Us,gh,_h,yr,vh,Ua,bh,kh,wh,Tr,yh,Er,Th,Eh,Ch,Cr,$h,Ka,Fh,Ph,zn,Bt,so,Ks,$r,Mh,js,Dh,qn,We,Fr,Lh,Hs,Ah,Rh,Pr,zh,ja,qh,xh,Ih,Mr,Oh,Dr,Bh,Nh,Sh,no,Uh,Lr,Kh,Ha,jh,Hh,xn,Nt,io,Qs,Ar,Qh,Vs,Vh,In,Ge,Rr,Wh,zr,Gh,Ws,Xh,Jh,Yh,qr,Zh,Qa,ec,tc,oc,xr,rc,Ir,ac,sc,nc,lo,ic,Or,lc,Va,dc,mc,On,St,mo,Gs,Br,hc,Xs,cc,Bn,Xe,Nr,fc,Sr,pc,Js,uc,gc,_c,Ur,vc,Wa,bc,kc,wc,Kr,yc,jr,Tc,Ec,Cc,ho,$c,Hr,Fc,Ga,Pc,Mc,Nn,Ut,co,Ys,Qr,Dc,Zs,Lc,Sn,Je,Vr,Ac,en,Rc,zc,Wr,qc,Xa,xc,Ic,Oc,Gr,Bc,Xr,Nc,Sc,Uc,fo,Kc,Jr,jc,Ja,Hc,Qc,Un,Kt,po,tn,Yr,Vc,on,Wc,Kn,Ye,Zr,Gc,rn,Xc,Jc,ea,Yc,Ya,Zc,ef,tf,ta,of,oa,rf,af,sf,uo,nf,ra,lf,Za,df,mf,jn,jt,go,an,aa,hf,sn,cf,Hn,Ze,sa,ff,nn,pf,uf,na,gf,es,_f,vf,bf,ia,kf,la,wf,yf,Tf,_o,Ef,da,Cf,ts,$f,Ff,Qn,Ht,vo,ln,ma,Pf,dn,Mf,Vn,et,ha,Df,Qt,Lf,mn,Af,Rf,hn,zf,qf,xf,ca,If,os,Of,Bf,Nf,fa,Sf,pa,Uf,Kf,jf,bo,Hf,ua,Qf,rs,Vf,Wf,Wn;return W=new Ve({}),f=new Ve({}),b=new Ve({}),p=new Qe({props:{name:"class transformers.CamembertConfig",anchor:"transformers.CamembertConfig",parameters:[{name:"pad_token_id",val:" = 1"},{name:"bos_token_id",val:" = 0"},{name:"eos_token_id",val:" = 2"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/configuration_camembert.py#L39"}}),ze=new Ve({}),G=new Qe({props:{name:"class transformers.CamembertTokenizer",anchor:"transformers.CamembertTokenizer",parameters:[{name:"vocab_file",val:""},{name:"bos_token",val:" = '<s>'"},{name:"eos_token",val:" = '</s>'"},{name:"sep_token",val:" = '</s>'"},{name:"cls_token",val:" = '<s>'"},{name:"unk_token",val:" = '<unk>'"},{name:"pad_token",val:" = '<pad>'"},{name:"mask_token",val:" = '<mask>'"},{name:"additional_special_tokens",val:" = ['<s>NOTUSED', '</s>NOTUSED']"},{name:"sp_model_kwargs",val:": typing.Union[typing.Dict[str, typing.Any], NoneType] = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.CamembertTokenizer.vocab_file",description:`<strong>vocab_file</strong> (<code>str</code>) &#x2014;
<a href="https://github.com/google/sentencepiece" rel="nofollow">SentencePiece</a> file (generally has a <em>.spm</em> extension) that
contains the vocabulary necessary to instantiate a tokenizer.`,name:"vocab_file"},{anchor:"transformers.CamembertTokenizer.bos_token",description:`<strong>bos_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;s&gt;&quot;</code>) &#x2014;
The beginning of sequence token that was used during pretraining. Can be used a sequence classifier token.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>When building a sequence using special tokens, this is not the token that is used for the beginning of
sequence. The token used is the <code>cls_token</code>.</p>

					</div>`,name:"bos_token"},{anchor:"transformers.CamembertTokenizer.eos_token",description:`<strong>eos_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;/s&gt;&quot;</code>) &#x2014;
The end of sequence token.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>When building a sequence using special tokens, this is not the token that is used for the end of sequence.
The token used is the <code>sep_token</code>.</p>

					</div>`,name:"eos_token"},{anchor:"transformers.CamembertTokenizer.sep_token",description:`<strong>sep_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;/s&gt;&quot;</code>) &#x2014;
The separator token, which is used when building a sequence from multiple sequences, e.g. two sequences for
sequence classification or for a text and a question for question answering. It is also used as the last
token of a sequence built with special tokens.`,name:"sep_token"},{anchor:"transformers.CamembertTokenizer.cls_token",description:`<strong>cls_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;s&gt;&quot;</code>) &#x2014;
The classifier token which is used when doing sequence classification (classification of the whole sequence
instead of per-token classification). It is the first token of the sequence when built with special tokens.`,name:"cls_token"},{anchor:"transformers.CamembertTokenizer.unk_token",description:`<strong>unk_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;unk&gt;&quot;</code>) &#x2014;
The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this
token instead.`,name:"unk_token"},{anchor:"transformers.CamembertTokenizer.pad_token",description:`<strong>pad_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;pad&gt;&quot;</code>) &#x2014;
The token used for padding, for example when batching sequences of different lengths.`,name:"pad_token"},{anchor:"transformers.CamembertTokenizer.mask_token",description:`<strong>mask_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;mask&gt;&quot;</code>) &#x2014;
The token used for masking values. This is the token used when training this model with masked language
modeling. This is the token which the model will try to predict.`,name:"mask_token"},{anchor:"transformers.CamembertTokenizer.additional_special_tokens",description:`<strong>additional_special_tokens</strong> (<code>List[str]</code>, <em>optional</em>, defaults to <code>[&quot;&lt;s&gt;NOTUSED&quot;, &quot;&lt;/s&gt;NOTUSED&quot;]</code>) &#x2014;
Additional special tokens used by the tokenizer.`,name:"additional_special_tokens"},{anchor:"transformers.CamembertTokenizer.sp_model_kwargs",description:`<strong>sp_model_kwargs</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Will be passed to the <code>SentencePieceProcessor.__init__()</code> method. The <a href="https://github.com/google/sentencepiece/tree/master/python" rel="nofollow">Python wrapper for
SentencePiece</a> can be used, among other things,
to set:</p>
<ul>
<li>
<p><code>enable_sampling</code>: Enable subword regularization.</p>
</li>
<li>
<p><code>nbest_size</code>: Sampling parameters for unigram. Invalid for BPE-Dropout.</p>
<ul>
<li><code>nbest_size = {0,1}</code>: No sampling is performed.</li>
<li><code>nbest_size &gt; 1</code>: samples from the nbest_size results.</li>
<li><code>nbest_size &lt; 0</code>: assuming that nbest_size is infinite and samples from the all hypothesis (lattice)
using forward-filtering-and-backward-sampling algorithm.</li>
</ul>
</li>
<li>
<p><code>alpha</code>: Smoothing parameter for unigram sampling, and dropout probability of merge operations for
BPE-dropout.</p>
</li>
</ul>`,name:"sp_model_kwargs"},{anchor:"transformers.CamembertTokenizer.sp_model",description:`<strong>sp_model</strong> (<code>SentencePieceProcessor</code>) &#x2014;
The <em>SentencePiece</em> processor that is used for every conversion (string, tokens and IDs).`,name:"sp_model"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/tokenization_camembert.py#L45"}}),To=new Qe({props:{name:"build_inputs_with_special_tokens",anchor:"transformers.CamembertTokenizer.build_inputs_with_special_tokens",parameters:[{name:"token_ids_0",val:": typing.List[int]"},{name:"token_ids_1",val:": typing.Optional[typing.List[int]] = None"}],parametersDescription:[{anchor:"transformers.CamembertTokenizer.build_inputs_with_special_tokens.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs to which the special tokens will be added.`,name:"token_ids_0"},{anchor:"transformers.CamembertTokenizer.build_inputs_with_special_tokens.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/tokenization_camembert.py#L161",returnDescription:`
<p>List of <a href="../glossary#input-ids">input IDs</a> with the appropriate special tokens.</p>
`,returnType:`
<p><code>List[int]</code></p>
`}}),Co=new Qe({props:{name:"get_special_tokens_mask",anchor:"transformers.CamembertTokenizer.get_special_tokens_mask",parameters:[{name:"token_ids_0",val:": typing.List[int]"},{name:"token_ids_1",val:": typing.Optional[typing.List[int]] = None"},{name:"already_has_special_tokens",val:": bool = False"}],parametersDescription:[{anchor:"transformers.CamembertTokenizer.get_special_tokens_mask.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs.`,name:"token_ids_0"},{anchor:"transformers.CamembertTokenizer.get_special_tokens_mask.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"},{anchor:"transformers.CamembertTokenizer.get_special_tokens_mask.already_has_special_tokens",description:`<strong>already_has_special_tokens</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the token list is already formatted with special tokens for the model.`,name:"already_has_special_tokens"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/tokenization_camembert.py#L187",returnDescription:`
<p>A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.</p>
`,returnType:`
<p><code>List[int]</code></p>
`}}),Fo=new Qe({props:{name:"create_token_type_ids_from_sequences",anchor:"transformers.CamembertTokenizer.create_token_type_ids_from_sequences",parameters:[{name:"token_ids_0",val:": typing.List[int]"},{name:"token_ids_1",val:": typing.Optional[typing.List[int]] = None"}],parametersDescription:[{anchor:"transformers.CamembertTokenizer.create_token_type_ids_from_sequences.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs.`,name:"token_ids_0"},{anchor:"transformers.CamembertTokenizer.create_token_type_ids_from_sequences.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/tokenization_camembert.py#L214",returnDescription:`
<p>List of zeros.</p>
`,returnType:`
<p><code>List[int]</code></p>
`}}),Po=new Qe({props:{name:"save_vocabulary",anchor:"transformers.CamembertTokenizer.save_vocabulary",parameters:[{name:"save_directory",val:": str"},{name:"filename_prefix",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/tokenization_camembert.py#L283"}}),Mo=new Ve({}),Do=new Qe({props:{name:"class transformers.CamembertTokenizerFast",anchor:"transformers.CamembertTokenizerFast",parameters:[{name:"vocab_file",val:" = None"},{name:"tokenizer_file",val:" = None"},{name:"bos_token",val:" = '<s>'"},{name:"eos_token",val:" = '</s>'"},{name:"sep_token",val:" = '</s>'"},{name:"cls_token",val:" = '<s>'"},{name:"unk_token",val:" = '<unk>'"},{name:"pad_token",val:" = '<pad>'"},{name:"mask_token",val:" = '<mask>'"},{name:"additional_special_tokens",val:" = ['<s>NOTUSED', '</s>NOTUSED']"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.CamembertTokenizerFast.vocab_file",description:`<strong>vocab_file</strong> (<code>str</code>) &#x2014;
<a href="https://github.com/google/sentencepiece" rel="nofollow">SentencePiece</a> file (generally has a <em>.spm</em> extension) that
contains the vocabulary necessary to instantiate a tokenizer.`,name:"vocab_file"},{anchor:"transformers.CamembertTokenizerFast.bos_token",description:`<strong>bos_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;s&gt;&quot;</code>) &#x2014;
The beginning of sequence token that was used during pretraining. Can be used a sequence classifier token.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>When building a sequence using special tokens, this is not the token that is used for the beginning of
sequence. The token used is the <code>cls_token</code>.</p>

					</div>`,name:"bos_token"},{anchor:"transformers.CamembertTokenizerFast.eos_token",description:`<strong>eos_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;/s&gt;&quot;</code>) &#x2014;
The end of sequence token.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>When building a sequence using special tokens, this is not the token that is used for the end of sequence.
The token used is the <code>sep_token</code>.</p>

					</div>`,name:"eos_token"},{anchor:"transformers.CamembertTokenizerFast.sep_token",description:`<strong>sep_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;/s&gt;&quot;</code>) &#x2014;
The separator token, which is used when building a sequence from multiple sequences, e.g. two sequences for
sequence classification or for a text and a question for question answering. It is also used as the last
token of a sequence built with special tokens.`,name:"sep_token"},{anchor:"transformers.CamembertTokenizerFast.cls_token",description:`<strong>cls_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;s&gt;&quot;</code>) &#x2014;
The classifier token which is used when doing sequence classification (classification of the whole sequence
instead of per-token classification). It is the first token of the sequence when built with special tokens.`,name:"cls_token"},{anchor:"transformers.CamembertTokenizerFast.unk_token",description:`<strong>unk_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;unk&gt;&quot;</code>) &#x2014;
The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this
token instead.`,name:"unk_token"},{anchor:"transformers.CamembertTokenizerFast.pad_token",description:`<strong>pad_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;pad&gt;&quot;</code>) &#x2014;
The token used for padding, for example when batching sequences of different lengths.`,name:"pad_token"},{anchor:"transformers.CamembertTokenizerFast.mask_token",description:`<strong>mask_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;mask&gt;&quot;</code>) &#x2014;
The token used for masking values. This is the token used when training this model with masked language
modeling. This is the token which the model will try to predict.`,name:"mask_token"},{anchor:"transformers.CamembertTokenizerFast.additional_special_tokens",description:`<strong>additional_special_tokens</strong> (<code>List[str]</code>, <em>optional</em>, defaults to <code>[&quot;&lt;s&gt;NOTUSED&quot;, &quot;&lt;/s&gt;NOTUSED&quot;]</code>) &#x2014;
Additional special tokens used by the tokenizer.`,name:"additional_special_tokens"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/tokenization_camembert_fast.py#L53"}}),Ro=new Qe({props:{name:"build_inputs_with_special_tokens",anchor:"transformers.CamembertTokenizerFast.build_inputs_with_special_tokens",parameters:[{name:"token_ids_0",val:": typing.List[int]"},{name:"token_ids_1",val:": typing.Optional[typing.List[int]] = None"}],parametersDescription:[{anchor:"transformers.CamembertTokenizerFast.build_inputs_with_special_tokens.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs to which the special tokens will be added.`,name:"token_ids_0"},{anchor:"transformers.CamembertTokenizerFast.build_inputs_with_special_tokens.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/tokenization_camembert_fast.py#L145",returnDescription:`
<p>List of <a href="../glossary#input-ids">input IDs</a> with the appropriate special tokens.</p>
`,returnType:`
<p><code>List[int]</code></p>
`}}),qo=new Qe({props:{name:"create_token_type_ids_from_sequences",anchor:"transformers.CamembertTokenizerFast.create_token_type_ids_from_sequences",parameters:[{name:"token_ids_0",val:": typing.List[int]"},{name:"token_ids_1",val:": typing.Optional[typing.List[int]] = None"}],parametersDescription:[{anchor:"transformers.CamembertTokenizerFast.create_token_type_ids_from_sequences.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs.`,name:"token_ids_0"},{anchor:"transformers.CamembertTokenizerFast.create_token_type_ids_from_sequences.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/tokenization_camembert_fast.py#L171",returnDescription:`
<p>List of zeros.</p>
`,returnType:`
<p><code>List[int]</code></p>
`}}),xo=new Ve({}),Io=new Qe({props:{name:"class transformers.CamembertModel",anchor:"transformers.CamembertModel",parameters:[{name:"config",val:""},{name:"add_pooling_layer",val:" = True"}],parametersDescription:[{anchor:"transformers.CamembertModel.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a>) &#x2014; Model configuration class with all the parameters of the
model. Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/modeling_camembert.py#L63"}}),Uo=new Ve({}),Ko=new Qe({props:{name:"class transformers.CamembertForCausalLM",anchor:"transformers.CamembertForCausalLM",parameters:[{name:"config",val:""}],parametersDescription:[{anchor:"transformers.CamembertForCausalLM.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a>) &#x2014; Model configuration class with all the parameters of the
model. Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/modeling_camembert.py#L152"}}),Go=new Ve({}),Xo=new Qe({props:{name:"class transformers.CamembertForMaskedLM",anchor:"transformers.CamembertForMaskedLM",parameters:[{name:"config",val:""}],parametersDescription:[{anchor:"transformers.CamembertForMaskedLM.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a>) &#x2014; Model configuration class with all the parameters of the
model. Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/modeling_camembert.py#L76"}}),or=new Ve({}),rr=new Qe({props:{name:"class transformers.CamembertForSequenceClassification",anchor:"transformers.CamembertForSequenceClassification",parameters:[{name:"config",val:""}],parametersDescription:[{anchor:"transformers.CamembertForSequenceClassification.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a>) &#x2014; Model configuration class with all the parameters of the
model. Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/modeling_camembert.py#L92"}}),lr=new Ve({}),dr=new Qe({props:{name:"class transformers.CamembertForMultipleChoice",anchor:"transformers.CamembertForMultipleChoice",parameters:[{name:"config",val:""}],parametersDescription:[{anchor:"transformers.CamembertForMultipleChoice.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a>) &#x2014; Model configuration class with all the parameters of the
model. Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/modeling_camembert.py#L108"}}),pr=new Ve({}),ur=new Qe({props:{name:"class transformers.CamembertForTokenClassification",anchor:"transformers.CamembertForTokenClassification",parameters:[{name:"config",val:""}],parametersDescription:[{anchor:"transformers.CamembertForTokenClassification.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a>) &#x2014; Model configuration class with all the parameters of the
model. Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/modeling_camembert.py#L124"}}),kr=new Ve({}),wr=new Qe({props:{name:"class transformers.CamembertForQuestionAnswering",anchor:"transformers.CamembertForQuestionAnswering",parameters:[{name:"config",val:""}],parametersDescription:[{anchor:"transformers.CamembertForQuestionAnswering.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a>) &#x2014; Model configuration class with all the parameters of the
model. Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/modeling_camembert.py#L140"}}),$r=new Ve({}),Fr=new Qe({props:{name:"class transformers.TFCamembertModel",anchor:"transformers.TFCamembertModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFCamembertModel.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a>) &#x2014; Model configuration class with all the parameters of the
model. Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/modeling_tf_camembert.py#L85"}}),no=new va({props:{$$slots:{default:[xg]},$$scope:{ctx:tt}}}),Ar=new Ve({}),Rr=new Qe({props:{name:"class transformers.TFCamembertForCausalLM",anchor:"transformers.TFCamembertForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFCamembertForCausalLM.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a>) &#x2014; Model configuration class with all the parameters of the
model. Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/modeling_tf_camembert.py#L174"}}),lo=new va({props:{$$slots:{default:[Ig]},$$scope:{ctx:tt}}}),Br=new Ve({}),Nr=new Qe({props:{name:"class transformers.TFCamembertForMaskedLM",anchor:"transformers.TFCamembertForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFCamembertForMaskedLM.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a>) &#x2014; Model configuration class with all the parameters of the
model. Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/modeling_tf_camembert.py#L98"}}),ho=new va({props:{$$slots:{default:[Og]},$$scope:{ctx:tt}}}),Qr=new Ve({}),Vr=new Qe({props:{name:"class transformers.TFCamembertForSequenceClassification",anchor:"transformers.TFCamembertForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFCamembertForSequenceClassification.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a>) &#x2014; Model configuration class with all the parameters of the
model. Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/modeling_tf_camembert.py#L114"}}),fo=new va({props:{$$slots:{default:[Bg]},$$scope:{ctx:tt}}}),Yr=new Ve({}),Zr=new Qe({props:{name:"class transformers.TFCamembertForMultipleChoice",anchor:"transformers.TFCamembertForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFCamembertForMultipleChoice.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a>) &#x2014; Model configuration class with all the parameters of the
model. Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/modeling_tf_camembert.py#L146"}}),uo=new va({props:{$$slots:{default:[Ng]},$$scope:{ctx:tt}}}),aa=new Ve({}),sa=new Qe({props:{name:"class transformers.TFCamembertForTokenClassification",anchor:"transformers.TFCamembertForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFCamembertForTokenClassification.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a>) &#x2014; Model configuration class with all the parameters of the
model. Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/modeling_tf_camembert.py#L130"}}),_o=new va({props:{$$slots:{default:[Sg]},$$scope:{ctx:tt}}}),ma=new Ve({}),ha=new Qe({props:{name:"class transformers.TFCamembertForQuestionAnswering",anchor:"transformers.TFCamembertForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFCamembertForQuestionAnswering.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a>) &#x2014; Model configuration class with all the parameters of the
model. Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.0/src/transformers/models/camembert/modeling_tf_camembert.py#L162"}}),bo=new va({props:{$$slots:{default:[Ug]},$$scope:{ctx:tt}}}),{c(){v=a("meta"),me=d(),$=a("h1"),te=a("a"),le=a("span"),L(W.$$.fragment),w=d(),S=a("span"),be=o("CamemBERT"),he=d(),F=a("h2"),oe=a("a"),X=a("span"),L(f.$$.fragment),ke=d(),U=a("span"),we=o("Overview"),ce=d(),M=a("p"),ye=o("The CamemBERT model was proposed in "),ae=a("a"),K=o("CamemBERT: a Tasty French Language Model"),Te=o(` by
Louis Martin, Benjamin Muller, Pedro Javier Ortiz Su\xE1rez, Yoann Dupont, Laurent Romary, \xC9ric Villemonte de la
Clergerie, Djam\xE9 Seddah, and Beno\xEEt Sagot. It is based on Facebook\u2019s RoBERTa model released in 2019. It is a model
trained on 138GB of French text.`),fe=d(),I=a("p"),Ee=o("The abstract from the paper is the following:"),pe=d(),O=a("p"),de=a("em"),Ce=o(`Pretrained language models are now ubiquitous in Natural Language Processing. Despite their success, most available
models have either been trained on English data or on the concatenation of data in multiple languages. This makes
practical use of such models \u2014in all languages except English\u2014 very limited. Aiming to address this issue for French,
we release CamemBERT, a French version of the Bi-directional Encoders for Transformers (BERT). We measure the
performance of CamemBERT compared to multilingual models in multiple downstream tasks, namely part-of-speech tagging,
dependency parsing, named-entity recognition, and natural language inference. CamemBERT improves the state of the art
for most of the tasks considered. We release the pretrained model for CamemBERT hoping to foster research and
downstream applications for French NLP.`),Z=d(),_=a("p"),y=o("Tips:"),ue=d(),B=a("ul"),se=a("li"),$e=o("This implementation is the same as RoBERTa. Refer to the "),N=a("a"),Fe=o("documentation of RoBERTa"),Pe=o(` for usage examples
as well as the information relative to the inputs and outputs.`),k=d(),ee=a("p"),j=o("This model was contributed by "),ne=a("a"),Me=o("camembert"),H=o(". The original code can be found "),ie=a("a"),De=o("here"),C=o("."),ge=d(),P=a("h2"),re=a("a"),J=a("span"),L(b.$$.fragment),Le=d(),T=a("span"),Ae=o("CamembertConfig"),_e=d(),l=a("div"),L(p.$$.fragment),Be=d(),V=a("p"),Ne=o("This class overrides "),qe=a("a"),g=o("RobertaConfig"),Se=o(`. Please check the superclass for the appropriate documentation alongside
usage examples. Instantiating a configuration with the defaults will yield a similar configuration to that of the
Camembert `),Re=a("a"),Ue=o("camembert-base"),Ke=o(" architecture."),Oe=d(),E=a("h2"),D=a("a"),xe=a("span"),L(ze.$$.fragment),Q=d(),Ie=a("span"),je=o("CamembertTokenizer"),ve=d(),Y=a("div"),L(G.$$.fragment),He=d(),bt=a("p"),ul=o("Adapted from "),ba=a("a"),gl=o("RobertaTokenizer"),_l=o(" and "),ka=a("a"),vl=o("XLNetTokenizer"),bl=o(`. Construct a CamemBERT tokenizer. Based on
`),wo=a("a"),kl=o("SentencePiece"),wl=o("."),yl=d(),yo=a("p"),Tl=o("This tokenizer inherits from "),wa=a("a"),El=o("PreTrainedTokenizer"),Cl=o(` which contains most of the main methods. Users should refer to
this superclass for more information regarding those methods.`),$l=d(),kt=a("div"),L(To.$$.fragment),Fl=d(),ds=a("p"),Pl=o(`Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
adding special tokens. An CamemBERT sequence has the following format:`),Ml=d(),Eo=a("ul"),ya=a("li"),Dl=o("single sequence: "),ms=a("code"),Ll=o("<s> X </s>"),Al=d(),Ta=a("li"),Rl=o("pair of sequences: "),hs=a("code"),zl=o("<s> A </s></s> B </s>"),ql=d(),Vt=a("div"),L(Co.$$.fragment),xl=d(),$o=a("p"),Il=o(`Retrieve sequence ids from a token list that has no special tokens added. This method is called when adding
special tokens using the tokenizer `),cs=a("code"),Ol=o("prepare_for_model"),Bl=o(" method."),Nl=d(),Wt=a("div"),L(Fo.$$.fragment),Sl=d(),fs=a("p"),Ul=o(`Create a mask from the two sequences passed to be used in a sequence-pair classification task. CamemBERT, like
RoBERTa, does not make use of token type ids, therefore a list of zeros is returned.`),Kl=d(),Ea=a("div"),L(Po.$$.fragment),vn=d(),Lt=a("h2"),Gt=a("a"),ps=a("span"),L(Mo.$$.fragment),jl=d(),us=a("span"),Hl=o("CamembertTokenizerFast"),bn=d(),ot=a("div"),L(Do.$$.fragment),Ql=d(),ht=a("p"),Vl=o("Construct a \u201Cfast\u201D CamemBERT tokenizer (backed by HuggingFace\u2019s "),gs=a("em"),Wl=o("tokenizers"),Gl=o(` library). Adapted from
`),Ca=a("a"),Xl=o("RobertaTokenizer"),Jl=o(" and "),$a=a("a"),Yl=o("XLNetTokenizer"),Zl=o(`. Based on
`),Lo=a("a"),ed=o("BPE"),td=o("."),od=d(),Ao=a("p"),rd=o("This tokenizer inherits from "),Fa=a("a"),ad=o("PreTrainedTokenizerFast"),sd=o(` which contains most of the main methods. Users should
refer to this superclass for more information regarding those methods.`),nd=d(),wt=a("div"),L(Ro.$$.fragment),id=d(),_s=a("p"),ld=o(`Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
adding special tokens. An CamemBERT sequence has the following format:`),dd=d(),zo=a("ul"),Pa=a("li"),md=o("single sequence: "),vs=a("code"),hd=o("<s> X </s>"),cd=d(),Ma=a("li"),fd=o("pair of sequences: "),bs=a("code"),pd=o("<s> A </s></s> B </s>"),ud=d(),Xt=a("div"),L(qo.$$.fragment),gd=d(),ks=a("p"),_d=o(`Create a mask from the two sequences passed to be used in a sequence-pair classification task. CamemBERT, like
RoBERTa, does not make use of token type ids, therefore a list of zeros is returned.`),kn=d(),At=a("h2"),Jt=a("a"),ws=a("span"),L(xo.$$.fragment),vd=d(),ys=a("span"),bd=o("CamembertModel"),wn=d(),rt=a("div"),L(Io.$$.fragment),kd=d(),Ts=a("p"),wd=o("The bare CamemBERT Model transformer outputting raw hidden-states without any specific head on top."),yd=d(),Oo=a("p"),Td=o("This model inherits from "),Da=a("a"),Ed=o("PreTrainedModel"),Cd=o(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),$d=d(),Bo=a("p"),Fd=o("This model is also a PyTorch "),No=a("a"),Pd=o("torch.nn.Module"),Md=o(` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),Dd=d(),So=a("p"),Ld=o("This class overrides "),La=a("a"),Ad=o("RobertaModel"),Rd=o(`. Please check the superclass for the appropriate documentation alongside
usage examples.`),yn=d(),Rt=a("h2"),Yt=a("a"),Es=a("span"),L(Uo.$$.fragment),zd=d(),Cs=a("span"),qd=o("CamembertForCausalLM"),Tn=d(),at=a("div"),L(Ko.$$.fragment),xd=d(),jo=a("p"),Id=o("CamemBERT Model with a "),$s=a("code"),Od=o("language modeling"),Bd=o(" head on top for CLM fine-tuning."),Nd=d(),Ho=a("p"),Sd=o("This model inherits from "),Aa=a("a"),Ud=o("PreTrainedModel"),Kd=o(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),jd=d(),Qo=a("p"),Hd=o("This model is also a PyTorch "),Vo=a("a"),Qd=o("torch.nn.Module"),Vd=o(` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),Wd=d(),Wo=a("p"),Gd=o("This class overrides "),Ra=a("a"),Xd=o("RobertaForCausalLM"),Jd=o(`. Please check the superclass for the appropriate documentation
alongside usage examples.`),En=d(),zt=a("h2"),Zt=a("a"),Fs=a("span"),L(Go.$$.fragment),Yd=d(),Ps=a("span"),Zd=o("CamembertForMaskedLM"),Cn=d(),st=a("div"),L(Xo.$$.fragment),em=d(),Jo=a("p"),tm=o("CamemBERT Model with a "),Ms=a("code"),om=o("language modeling"),rm=o(" head on top."),am=d(),Yo=a("p"),sm=o("This model inherits from "),za=a("a"),nm=o("PreTrainedModel"),im=o(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),lm=d(),Zo=a("p"),dm=o("This model is also a PyTorch "),er=a("a"),mm=o("torch.nn.Module"),hm=o(` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),cm=d(),tr=a("p"),fm=o("This class overrides "),qa=a("a"),pm=o("RobertaForMaskedLM"),um=o(`. Please check the superclass for the appropriate documentation
alongside usage examples.`),$n=d(),qt=a("h2"),eo=a("a"),Ds=a("span"),L(or.$$.fragment),gm=d(),Ls=a("span"),_m=o("CamembertForSequenceClassification"),Fn=d(),nt=a("div"),L(rr.$$.fragment),vm=d(),As=a("p"),bm=o(`CamemBERT Model transformer with a sequence classification/regression head on top (a linear layer on top of the
pooled output) e.g. for GLUE tasks.`),km=d(),ar=a("p"),wm=o("This model inherits from "),xa=a("a"),ym=o("PreTrainedModel"),Tm=o(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Em=d(),sr=a("p"),Cm=o("This model is also a PyTorch "),nr=a("a"),$m=o("torch.nn.Module"),Fm=o(` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),Pm=d(),ir=a("p"),Mm=o("This class overrides "),Ia=a("a"),Dm=o("RobertaForSequenceClassification"),Lm=o(`. Please check the superclass for the appropriate
documentation alongside usage examples.`),Pn=d(),xt=a("h2"),to=a("a"),Rs=a("span"),L(lr.$$.fragment),Am=d(),zs=a("span"),Rm=o("CamembertForMultipleChoice"),Mn=d(),it=a("div"),L(dr.$$.fragment),zm=d(),qs=a("p"),qm=o(`CamemBERT Model with a multiple choice classification head on top (a linear layer on top of the pooled output and a
softmax) e.g. for RocStories/SWAG tasks.`),xm=d(),mr=a("p"),Im=o("This model inherits from "),Oa=a("a"),Om=o("PreTrainedModel"),Bm=o(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Nm=d(),hr=a("p"),Sm=o("This model is also a PyTorch "),cr=a("a"),Um=o("torch.nn.Module"),Km=o(` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),jm=d(),fr=a("p"),Hm=o("This class overrides "),Ba=a("a"),Qm=o("RobertaForMultipleChoice"),Vm=o(`. Please check the superclass for the appropriate documentation
alongside usage examples.`),Dn=d(),It=a("h2"),oo=a("a"),xs=a("span"),L(pr.$$.fragment),Wm=d(),Is=a("span"),Gm=o("CamembertForTokenClassification"),Ln=d(),lt=a("div"),L(ur.$$.fragment),Xm=d(),Os=a("p"),Jm=o(`CamemBERT Model with a token classification head on top (a linear layer on top of the hidden-states output) e.g.
for Named-Entity-Recognition (NER) tasks.`),Ym=d(),gr=a("p"),Zm=o("This model inherits from "),Na=a("a"),eh=o("PreTrainedModel"),th=o(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),oh=d(),_r=a("p"),rh=o("This model is also a PyTorch "),vr=a("a"),ah=o("torch.nn.Module"),sh=o(` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),nh=d(),br=a("p"),ih=o("This class overrides "),Sa=a("a"),lh=o("RobertaForTokenClassification"),dh=o(`. Please check the superclass for the appropriate
documentation alongside usage examples.`),An=d(),Ot=a("h2"),ro=a("a"),Bs=a("span"),L(kr.$$.fragment),mh=d(),Ns=a("span"),hh=o("CamembertForQuestionAnswering"),Rn=d(),dt=a("div"),L(wr.$$.fragment),ch=d(),ao=a("p"),fh=o(`CamemBERT Model with a span classification head on top for extractive question-answering tasks like SQuAD (a linear
layers on top of the hidden-states output to compute `),Ss=a("code"),ph=o("span start logits"),uh=o(" and "),Us=a("code"),gh=o("span end logits"),_h=d(),yr=a("p"),vh=o("This model inherits from "),Ua=a("a"),bh=o("PreTrainedModel"),kh=o(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),wh=d(),Tr=a("p"),yh=o("This model is also a PyTorch "),Er=a("a"),Th=o("torch.nn.Module"),Eh=o(` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),Ch=d(),Cr=a("p"),$h=o("This class overrides "),Ka=a("a"),Fh=o("RobertaForQuestionAnswering"),Ph=o(`. Please check the superclass for the appropriate documentation
alongside usage examples.`),zn=d(),Bt=a("h2"),so=a("a"),Ks=a("span"),L($r.$$.fragment),Mh=d(),js=a("span"),Dh=o("TFCamembertModel"),qn=d(),We=a("div"),L(Fr.$$.fragment),Lh=d(),Hs=a("p"),Ah=o("The bare CamemBERT Model transformer outputting raw hidden-states without any specific head on top."),Rh=d(),Pr=a("p"),zh=o("This model inherits from "),ja=a("a"),qh=o("TFPreTrainedModel"),xh=o(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Ih=d(),Mr=a("p"),Oh=o("This model is also a "),Dr=a("a"),Bh=o("tf.keras.Model"),Nh=o(` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),Sh=d(),L(no.$$.fragment),Uh=d(),Lr=a("p"),Kh=o("This class overrides "),Ha=a("a"),jh=o("TFRobertaModel"),Hh=o(`. Please check the superclass for the appropriate documentation alongside
usage examples.`),xn=d(),Nt=a("h2"),io=a("a"),Qs=a("span"),L(Ar.$$.fragment),Qh=d(),Vs=a("span"),Vh=o("TFCamembertForCasualLM"),In=d(),Ge=a("div"),L(Rr.$$.fragment),Wh=d(),zr=a("p"),Gh=o("CamemBERT Model with a "),Ws=a("code"),Xh=o("language modeling"),Jh=o(" head on top for CLM fine-tuning."),Yh=d(),qr=a("p"),Zh=o("This model inherits from "),Qa=a("a"),ec=o("TFPreTrainedModel"),tc=o(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),oc=d(),xr=a("p"),rc=o("This model is also a "),Ir=a("a"),ac=o("tf.keras.Model"),sc=o(` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),nc=d(),L(lo.$$.fragment),ic=d(),Or=a("p"),lc=o("This class overrides "),Va=a("a"),dc=o("TFRobertaForCausalLM"),mc=o(`. Please check the superclass for the appropriate documentation
alongside usage examples.`),On=d(),St=a("h2"),mo=a("a"),Gs=a("span"),L(Br.$$.fragment),hc=d(),Xs=a("span"),cc=o("TFCamembertForMaskedLM"),Bn=d(),Xe=a("div"),L(Nr.$$.fragment),fc=d(),Sr=a("p"),pc=o("CamemBERT Model with a "),Js=a("code"),uc=o("language modeling"),gc=o(" head on top."),_c=d(),Ur=a("p"),vc=o("This model inherits from "),Wa=a("a"),bc=o("TFPreTrainedModel"),kc=o(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),wc=d(),Kr=a("p"),yc=o("This model is also a "),jr=a("a"),Tc=o("tf.keras.Model"),Ec=o(` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),Cc=d(),L(ho.$$.fragment),$c=d(),Hr=a("p"),Fc=o("This class overrides "),Ga=a("a"),Pc=o("TFRobertaForMaskedLM"),Mc=o(`. Please check the superclass for the appropriate documentation
alongside usage examples.`),Nn=d(),Ut=a("h2"),co=a("a"),Ys=a("span"),L(Qr.$$.fragment),Dc=d(),Zs=a("span"),Lc=o("TFCamembertForSequenceClassification"),Sn=d(),Je=a("div"),L(Vr.$$.fragment),Ac=d(),en=a("p"),Rc=o(`CamemBERT Model transformer with a sequence classification/regression head on top (a linear layer on top of the
pooled output) e.g. for GLUE tasks.`),zc=d(),Wr=a("p"),qc=o("This model inherits from "),Xa=a("a"),xc=o("TFPreTrainedModel"),Ic=o(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Oc=d(),Gr=a("p"),Bc=o("This model is also a "),Xr=a("a"),Nc=o("tf.keras.Model"),Sc=o(` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),Uc=d(),L(fo.$$.fragment),Kc=d(),Jr=a("p"),jc=o("This class overrides "),Ja=a("a"),Hc=o("TFRobertaForSequenceClassification"),Qc=o(`. Please check the superclass for the appropriate
documentation alongside usage examples.`),Un=d(),Kt=a("h2"),po=a("a"),tn=a("span"),L(Yr.$$.fragment),Vc=d(),on=a("span"),Wc=o("TFCamembertForMultipleChoice"),Kn=d(),Ye=a("div"),L(Zr.$$.fragment),Gc=d(),rn=a("p"),Xc=o(`CamemBERT Model with a multiple choice classification head on top (a linear layer on top of the pooled output and a
softmax) e.g. for RocStories/SWAG tasks.`),Jc=d(),ea=a("p"),Yc=o("This model inherits from "),Ya=a("a"),Zc=o("TFPreTrainedModel"),ef=o(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),tf=d(),ta=a("p"),of=o("This model is also a "),oa=a("a"),rf=o("tf.keras.Model"),af=o(` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),sf=d(),L(uo.$$.fragment),nf=d(),ra=a("p"),lf=o("This class overrides "),Za=a("a"),df=o("TFRobertaForMultipleChoice"),mf=o(`. Please check the superclass for the appropriate documentation
alongside usage examples.`),jn=d(),jt=a("h2"),go=a("a"),an=a("span"),L(aa.$$.fragment),hf=d(),sn=a("span"),cf=o("TFCamembertForTokenClassification"),Hn=d(),Ze=a("div"),L(sa.$$.fragment),ff=d(),nn=a("p"),pf=o(`CamemBERT Model with a token classification head on top (a linear layer on top of the hidden-states output) e.g.
for Named-Entity-Recognition (NER) tasks.`),uf=d(),na=a("p"),gf=o("This model inherits from "),es=a("a"),_f=o("TFPreTrainedModel"),vf=o(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),bf=d(),ia=a("p"),kf=o("This model is also a "),la=a("a"),wf=o("tf.keras.Model"),yf=o(` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),Tf=d(),L(_o.$$.fragment),Ef=d(),da=a("p"),Cf=o("This class overrides "),ts=a("a"),$f=o("TFRobertaForTokenClassification"),Ff=o(`. Please check the superclass for the appropriate
documentation alongside usage examples.`),Qn=d(),Ht=a("h2"),vo=a("a"),ln=a("span"),L(ma.$$.fragment),Pf=d(),dn=a("span"),Mf=o("TFCamembertForQuestionAnswering"),Vn=d(),et=a("div"),L(ha.$$.fragment),Df=d(),Qt=a("p"),Lf=o(`CamemBERT Model with a span classification head on top for extractive question-answering tasks like SQuAD (a linear
layers on top of the hidden-states output to compute `),mn=a("code"),Af=o("span start logits"),Rf=o(" and "),hn=a("code"),zf=o("span end logits"),qf=o(")."),xf=d(),ca=a("p"),If=o("This model inherits from "),os=a("a"),Of=o("TFPreTrainedModel"),Bf=o(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Nf=d(),fa=a("p"),Sf=o("This model is also a "),pa=a("a"),Uf=o("tf.keras.Model"),Kf=o(` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),jf=d(),L(bo.$$.fragment),Hf=d(),ua=a("p"),Qf=o("This class overrides "),rs=a("a"),Vf=o("TFRobertaForQuestionAnswering"),Wf=o(`. Please check the superclass for the appropriate
documentation alongside usage examples.`),this.h()},l(i){const u=zg('[data-svelte="svelte-1phssyn"]',document.head);v=s(u,"META",{name:!0,content:!0}),u.forEach(t),me=m(i),$=s(i,"H1",{class:!0});var ga=n($);te=s(ga,"A",{id:!0,class:!0,href:!0});var cn=n(te);le=s(cn,"SPAN",{});var fn=n(le);A(W.$$.fragment,fn),fn.forEach(t),cn.forEach(t),w=m(ga),S=s(ga,"SPAN",{});var pn=n(S);be=r(pn,"CamemBERT"),pn.forEach(t),ga.forEach(t),he=m(i),F=s(i,"H2",{class:!0});var _a=n(F);oe=s(_a,"A",{id:!0,class:!0,href:!0});var un=n(oe);X=s(un,"SPAN",{});var gn=n(X);A(f.$$.fragment,gn),gn.forEach(t),un.forEach(t),ke=m(_a),U=s(_a,"SPAN",{});var Zf=n(U);we=r(Zf,"Overview"),Zf.forEach(t),_a.forEach(t),ce=m(i),M=s(i,"P",{});var Gn=n(M);ye=r(Gn,"The CamemBERT model was proposed in "),ae=s(Gn,"A",{href:!0,rel:!0});var ep=n(ae);K=r(ep,"CamemBERT: a Tasty French Language Model"),ep.forEach(t),Te=r(Gn,` by
Louis Martin, Benjamin Muller, Pedro Javier Ortiz Su\xE1rez, Yoann Dupont, Laurent Romary, \xC9ric Villemonte de la
Clergerie, Djam\xE9 Seddah, and Beno\xEEt Sagot. It is based on Facebook\u2019s RoBERTa model released in 2019. It is a model
trained on 138GB of French text.`),Gn.forEach(t),fe=m(i),I=s(i,"P",{});var tp=n(I);Ee=r(tp,"The abstract from the paper is the following:"),tp.forEach(t),pe=m(i),O=s(i,"P",{});var op=n(O);de=s(op,"EM",{});var rp=n(de);Ce=r(rp,`Pretrained language models are now ubiquitous in Natural Language Processing. Despite their success, most available
models have either been trained on English data or on the concatenation of data in multiple languages. This makes
practical use of such models \u2014in all languages except English\u2014 very limited. Aiming to address this issue for French,
we release CamemBERT, a French version of the Bi-directional Encoders for Transformers (BERT). We measure the
performance of CamemBERT compared to multilingual models in multiple downstream tasks, namely part-of-speech tagging,
dependency parsing, named-entity recognition, and natural language inference. CamemBERT improves the state of the art
for most of the tasks considered. We release the pretrained model for CamemBERT hoping to foster research and
downstream applications for French NLP.`),rp.forEach(t),op.forEach(t),Z=m(i),_=s(i,"P",{});var ap=n(_);y=r(ap,"Tips:"),ap.forEach(t),ue=m(i),B=s(i,"UL",{});var sp=n(B);se=s(sp,"LI",{});var Xn=n(se);$e=r(Xn,"This implementation is the same as RoBERTa. Refer to the "),N=s(Xn,"A",{href:!0});var np=n(N);Fe=r(np,"documentation of RoBERTa"),np.forEach(t),Pe=r(Xn,` for usage examples
as well as the information relative to the inputs and outputs.`),Xn.forEach(t),sp.forEach(t),k=m(i),ee=s(i,"P",{});var as=n(ee);j=r(as,"This model was contributed by "),ne=s(as,"A",{href:!0,rel:!0});var ip=n(ne);Me=r(ip,"camembert"),ip.forEach(t),H=r(as,". The original code can be found "),ie=s(as,"A",{href:!0,rel:!0});var lp=n(ie);De=r(lp,"here"),lp.forEach(t),C=r(as,"."),as.forEach(t),ge=m(i),P=s(i,"H2",{class:!0});var Jn=n(P);re=s(Jn,"A",{id:!0,class:!0,href:!0});var dp=n(re);J=s(dp,"SPAN",{});var mp=n(J);A(b.$$.fragment,mp),mp.forEach(t),dp.forEach(t),Le=m(Jn),T=s(Jn,"SPAN",{});var hp=n(T);Ae=r(hp,"CamembertConfig"),hp.forEach(t),Jn.forEach(t),_e=m(i),l=s(i,"DIV",{class:!0});var Yn=n(l);A(p.$$.fragment,Yn),Be=m(Yn),V=s(Yn,"P",{});var ss=n(V);Ne=r(ss,"This class overrides "),qe=s(ss,"A",{href:!0});var cp=n(qe);g=r(cp,"RobertaConfig"),cp.forEach(t),Se=r(ss,`. Please check the superclass for the appropriate documentation alongside
usage examples. Instantiating a configuration with the defaults will yield a similar configuration to that of the
Camembert `),Re=s(ss,"A",{href:!0,rel:!0});var fp=n(Re);Ue=r(fp,"camembert-base"),fp.forEach(t),Ke=r(ss," architecture."),ss.forEach(t),Yn.forEach(t),Oe=m(i),E=s(i,"H2",{class:!0});var Zn=n(E);D=s(Zn,"A",{id:!0,class:!0,href:!0});var pp=n(D);xe=s(pp,"SPAN",{});var up=n(xe);A(ze.$$.fragment,up),up.forEach(t),pp.forEach(t),Q=m(Zn),Ie=s(Zn,"SPAN",{});var gp=n(Ie);je=r(gp,"CamembertTokenizer"),gp.forEach(t),Zn.forEach(t),ve=m(i),Y=s(i,"DIV",{class:!0});var mt=n(Y);A(G.$$.fragment,mt),He=m(mt),bt=s(mt,"P",{});var ko=n(bt);ul=r(ko,"Adapted from "),ba=s(ko,"A",{href:!0});var _p=n(ba);gl=r(_p,"RobertaTokenizer"),_p.forEach(t),_l=r(ko," and "),ka=s(ko,"A",{href:!0});var vp=n(ka);vl=r(vp,"XLNetTokenizer"),vp.forEach(t),bl=r(ko,`. Construct a CamemBERT tokenizer. Based on
`),wo=s(ko,"A",{href:!0,rel:!0});var bp=n(wo);kl=r(bp,"SentencePiece"),bp.forEach(t),wl=r(ko,"."),ko.forEach(t),yl=m(mt),yo=s(mt,"P",{});var ei=n(yo);Tl=r(ei,"This tokenizer inherits from "),wa=s(ei,"A",{href:!0});var kp=n(wa);El=r(kp,"PreTrainedTokenizer"),kp.forEach(t),Cl=r(ei,` which contains most of the main methods. Users should refer to
this superclass for more information regarding those methods.`),ei.forEach(t),$l=m(mt),kt=s(mt,"DIV",{class:!0});var ns=n(kt);A(To.$$.fragment,ns),Fl=m(ns),ds=s(ns,"P",{});var wp=n(ds);Pl=r(wp,`Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
adding special tokens. An CamemBERT sequence has the following format:`),wp.forEach(t),Ml=m(ns),Eo=s(ns,"UL",{});var ti=n(Eo);ya=s(ti,"LI",{});var Gf=n(ya);Dl=r(Gf,"single sequence: "),ms=s(Gf,"CODE",{});var yp=n(ms);Ll=r(yp,"<s> X </s>"),yp.forEach(t),Gf.forEach(t),Al=m(ti),Ta=s(ti,"LI",{});var Xf=n(Ta);Rl=r(Xf,"pair of sequences: "),hs=s(Xf,"CODE",{});var Tp=n(hs);zl=r(Tp,"<s> A </s></s> B </s>"),Tp.forEach(t),Xf.forEach(t),ti.forEach(t),ns.forEach(t),ql=m(mt),Vt=s(mt,"DIV",{class:!0});var oi=n(Vt);A(Co.$$.fragment,oi),xl=m(oi),$o=s(oi,"P",{});var ri=n($o);Il=r(ri,`Retrieve sequence ids from a token list that has no special tokens added. This method is called when adding
special tokens using the tokenizer `),cs=s(ri,"CODE",{});var Ep=n(cs);Ol=r(Ep,"prepare_for_model"),Ep.forEach(t),Bl=r(ri," method."),ri.forEach(t),oi.forEach(t),Nl=m(mt),Wt=s(mt,"DIV",{class:!0});var ai=n(Wt);A(Fo.$$.fragment,ai),Sl=m(ai),fs=s(ai,"P",{});var Cp=n(fs);Ul=r(Cp,`Create a mask from the two sequences passed to be used in a sequence-pair classification task. CamemBERT, like
RoBERTa, does not make use of token type ids, therefore a list of zeros is returned.`),Cp.forEach(t),ai.forEach(t),Kl=m(mt),Ea=s(mt,"DIV",{class:!0});var $p=n(Ea);A(Po.$$.fragment,$p),$p.forEach(t),mt.forEach(t),vn=m(i),Lt=s(i,"H2",{class:!0});var si=n(Lt);Gt=s(si,"A",{id:!0,class:!0,href:!0});var Fp=n(Gt);ps=s(Fp,"SPAN",{});var Pp=n(ps);A(Mo.$$.fragment,Pp),Pp.forEach(t),Fp.forEach(t),jl=m(si),us=s(si,"SPAN",{});var Mp=n(us);Hl=r(Mp,"CamembertTokenizerFast"),Mp.forEach(t),si.forEach(t),bn=m(i),ot=s(i,"DIV",{class:!0});var yt=n(ot);A(Do.$$.fragment,yt),Ql=m(yt),ht=s(yt,"P",{});var Tt=n(ht);Vl=r(Tt,"Construct a \u201Cfast\u201D CamemBERT tokenizer (backed by HuggingFace\u2019s "),gs=s(Tt,"EM",{});var Dp=n(gs);Wl=r(Dp,"tokenizers"),Dp.forEach(t),Gl=r(Tt,` library). Adapted from
`),Ca=s(Tt,"A",{href:!0});var Lp=n(Ca);Xl=r(Lp,"RobertaTokenizer"),Lp.forEach(t),Jl=r(Tt," and "),$a=s(Tt,"A",{href:!0});var Ap=n($a);Yl=r(Ap,"XLNetTokenizer"),Ap.forEach(t),Zl=r(Tt,`. Based on
`),Lo=s(Tt,"A",{href:!0,rel:!0});var Rp=n(Lo);ed=r(Rp,"BPE"),Rp.forEach(t),td=r(Tt,"."),Tt.forEach(t),od=m(yt),Ao=s(yt,"P",{});var ni=n(Ao);rd=r(ni,"This tokenizer inherits from "),Fa=s(ni,"A",{href:!0});var zp=n(Fa);ad=r(zp,"PreTrainedTokenizerFast"),zp.forEach(t),sd=r(ni,` which contains most of the main methods. Users should
refer to this superclass for more information regarding those methods.`),ni.forEach(t),nd=m(yt),wt=s(yt,"DIV",{class:!0});var is=n(wt);A(Ro.$$.fragment,is),id=m(is),_s=s(is,"P",{});var qp=n(_s);ld=r(qp,`Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
adding special tokens. An CamemBERT sequence has the following format:`),qp.forEach(t),dd=m(is),zo=s(is,"UL",{});var ii=n(zo);Pa=s(ii,"LI",{});var Jf=n(Pa);md=r(Jf,"single sequence: "),vs=s(Jf,"CODE",{});var xp=n(vs);hd=r(xp,"<s> X </s>"),xp.forEach(t),Jf.forEach(t),cd=m(ii),Ma=s(ii,"LI",{});var Yf=n(Ma);fd=r(Yf,"pair of sequences: "),bs=s(Yf,"CODE",{});var Ip=n(bs);pd=r(Ip,"<s> A </s></s> B </s>"),Ip.forEach(t),Yf.forEach(t),ii.forEach(t),is.forEach(t),ud=m(yt),Xt=s(yt,"DIV",{class:!0});var li=n(Xt);A(qo.$$.fragment,li),gd=m(li),ks=s(li,"P",{});var Op=n(ks);_d=r(Op,`Create a mask from the two sequences passed to be used in a sequence-pair classification task. CamemBERT, like
RoBERTa, does not make use of token type ids, therefore a list of zeros is returned.`),Op.forEach(t),li.forEach(t),yt.forEach(t),kn=m(i),At=s(i,"H2",{class:!0});var di=n(At);Jt=s(di,"A",{id:!0,class:!0,href:!0});var Bp=n(Jt);ws=s(Bp,"SPAN",{});var Np=n(ws);A(xo.$$.fragment,Np),Np.forEach(t),Bp.forEach(t),vd=m(di),ys=s(di,"SPAN",{});var Sp=n(ys);bd=r(Sp,"CamembertModel"),Sp.forEach(t),di.forEach(t),wn=m(i),rt=s(i,"DIV",{class:!0});var Et=n(rt);A(Io.$$.fragment,Et),kd=m(Et),Ts=s(Et,"P",{});var Up=n(Ts);wd=r(Up,"The bare CamemBERT Model transformer outputting raw hidden-states without any specific head on top."),Up.forEach(t),yd=m(Et),Oo=s(Et,"P",{});var mi=n(Oo);Td=r(mi,"This model inherits from "),Da=s(mi,"A",{href:!0});var Kp=n(Da);Ed=r(Kp,"PreTrainedModel"),Kp.forEach(t),Cd=r(mi,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),mi.forEach(t),$d=m(Et),Bo=s(Et,"P",{});var hi=n(Bo);Fd=r(hi,"This model is also a PyTorch "),No=s(hi,"A",{href:!0,rel:!0});var jp=n(No);Pd=r(jp,"torch.nn.Module"),jp.forEach(t),Md=r(hi,` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),hi.forEach(t),Dd=m(Et),So=s(Et,"P",{});var ci=n(So);Ld=r(ci,"This class overrides "),La=s(ci,"A",{href:!0});var Hp=n(La);Ad=r(Hp,"RobertaModel"),Hp.forEach(t),Rd=r(ci,`. Please check the superclass for the appropriate documentation alongside
usage examples.`),ci.forEach(t),Et.forEach(t),yn=m(i),Rt=s(i,"H2",{class:!0});var fi=n(Rt);Yt=s(fi,"A",{id:!0,class:!0,href:!0});var Qp=n(Yt);Es=s(Qp,"SPAN",{});var Vp=n(Es);A(Uo.$$.fragment,Vp),Vp.forEach(t),Qp.forEach(t),zd=m(fi),Cs=s(fi,"SPAN",{});var Wp=n(Cs);qd=r(Wp,"CamembertForCausalLM"),Wp.forEach(t),fi.forEach(t),Tn=m(i),at=s(i,"DIV",{class:!0});var Ct=n(at);A(Ko.$$.fragment,Ct),xd=m(Ct),jo=s(Ct,"P",{});var pi=n(jo);Id=r(pi,"CamemBERT Model with a "),$s=s(pi,"CODE",{});var Gp=n($s);Od=r(Gp,"language modeling"),Gp.forEach(t),Bd=r(pi," head on top for CLM fine-tuning."),pi.forEach(t),Nd=m(Ct),Ho=s(Ct,"P",{});var ui=n(Ho);Sd=r(ui,"This model inherits from "),Aa=s(ui,"A",{href:!0});var Xp=n(Aa);Ud=r(Xp,"PreTrainedModel"),Xp.forEach(t),Kd=r(ui,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),ui.forEach(t),jd=m(Ct),Qo=s(Ct,"P",{});var gi=n(Qo);Hd=r(gi,"This model is also a PyTorch "),Vo=s(gi,"A",{href:!0,rel:!0});var Jp=n(Vo);Qd=r(Jp,"torch.nn.Module"),Jp.forEach(t),Vd=r(gi,` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),gi.forEach(t),Wd=m(Ct),Wo=s(Ct,"P",{});var _i=n(Wo);Gd=r(_i,"This class overrides "),Ra=s(_i,"A",{href:!0});var Yp=n(Ra);Xd=r(Yp,"RobertaForCausalLM"),Yp.forEach(t),Jd=r(_i,`. Please check the superclass for the appropriate documentation
alongside usage examples.`),_i.forEach(t),Ct.forEach(t),En=m(i),zt=s(i,"H2",{class:!0});var vi=n(zt);Zt=s(vi,"A",{id:!0,class:!0,href:!0});var Zp=n(Zt);Fs=s(Zp,"SPAN",{});var eu=n(Fs);A(Go.$$.fragment,eu),eu.forEach(t),Zp.forEach(t),Yd=m(vi),Ps=s(vi,"SPAN",{});var tu=n(Ps);Zd=r(tu,"CamembertForMaskedLM"),tu.forEach(t),vi.forEach(t),Cn=m(i),st=s(i,"DIV",{class:!0});var $t=n(st);A(Xo.$$.fragment,$t),em=m($t),Jo=s($t,"P",{});var bi=n(Jo);tm=r(bi,"CamemBERT Model with a "),Ms=s(bi,"CODE",{});var ou=n(Ms);om=r(ou,"language modeling"),ou.forEach(t),rm=r(bi," head on top."),bi.forEach(t),am=m($t),Yo=s($t,"P",{});var ki=n(Yo);sm=r(ki,"This model inherits from "),za=s(ki,"A",{href:!0});var ru=n(za);nm=r(ru,"PreTrainedModel"),ru.forEach(t),im=r(ki,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),ki.forEach(t),lm=m($t),Zo=s($t,"P",{});var wi=n(Zo);dm=r(wi,"This model is also a PyTorch "),er=s(wi,"A",{href:!0,rel:!0});var au=n(er);mm=r(au,"torch.nn.Module"),au.forEach(t),hm=r(wi,` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),wi.forEach(t),cm=m($t),tr=s($t,"P",{});var yi=n(tr);fm=r(yi,"This class overrides "),qa=s(yi,"A",{href:!0});var su=n(qa);pm=r(su,"RobertaForMaskedLM"),su.forEach(t),um=r(yi,`. Please check the superclass for the appropriate documentation
alongside usage examples.`),yi.forEach(t),$t.forEach(t),$n=m(i),qt=s(i,"H2",{class:!0});var Ti=n(qt);eo=s(Ti,"A",{id:!0,class:!0,href:!0});var nu=n(eo);Ds=s(nu,"SPAN",{});var iu=n(Ds);A(or.$$.fragment,iu),iu.forEach(t),nu.forEach(t),gm=m(Ti),Ls=s(Ti,"SPAN",{});var lu=n(Ls);_m=r(lu,"CamembertForSequenceClassification"),lu.forEach(t),Ti.forEach(t),Fn=m(i),nt=s(i,"DIV",{class:!0});var Ft=n(nt);A(rr.$$.fragment,Ft),vm=m(Ft),As=s(Ft,"P",{});var du=n(As);bm=r(du,`CamemBERT Model transformer with a sequence classification/regression head on top (a linear layer on top of the
pooled output) e.g. for GLUE tasks.`),du.forEach(t),km=m(Ft),ar=s(Ft,"P",{});var Ei=n(ar);wm=r(Ei,"This model inherits from "),xa=s(Ei,"A",{href:!0});var mu=n(xa);ym=r(mu,"PreTrainedModel"),mu.forEach(t),Tm=r(Ei,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Ei.forEach(t),Em=m(Ft),sr=s(Ft,"P",{});var Ci=n(sr);Cm=r(Ci,"This model is also a PyTorch "),nr=s(Ci,"A",{href:!0,rel:!0});var hu=n(nr);$m=r(hu,"torch.nn.Module"),hu.forEach(t),Fm=r(Ci,` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),Ci.forEach(t),Pm=m(Ft),ir=s(Ft,"P",{});var $i=n(ir);Mm=r($i,"This class overrides "),Ia=s($i,"A",{href:!0});var cu=n(Ia);Dm=r(cu,"RobertaForSequenceClassification"),cu.forEach(t),Lm=r($i,`. Please check the superclass for the appropriate
documentation alongside usage examples.`),$i.forEach(t),Ft.forEach(t),Pn=m(i),xt=s(i,"H2",{class:!0});var Fi=n(xt);to=s(Fi,"A",{id:!0,class:!0,href:!0});var fu=n(to);Rs=s(fu,"SPAN",{});var pu=n(Rs);A(lr.$$.fragment,pu),pu.forEach(t),fu.forEach(t),Am=m(Fi),zs=s(Fi,"SPAN",{});var uu=n(zs);Rm=r(uu,"CamembertForMultipleChoice"),uu.forEach(t),Fi.forEach(t),Mn=m(i),it=s(i,"DIV",{class:!0});var Pt=n(it);A(dr.$$.fragment,Pt),zm=m(Pt),qs=s(Pt,"P",{});var gu=n(qs);qm=r(gu,`CamemBERT Model with a multiple choice classification head on top (a linear layer on top of the pooled output and a
softmax) e.g. for RocStories/SWAG tasks.`),gu.forEach(t),xm=m(Pt),mr=s(Pt,"P",{});var Pi=n(mr);Im=r(Pi,"This model inherits from "),Oa=s(Pi,"A",{href:!0});var _u=n(Oa);Om=r(_u,"PreTrainedModel"),_u.forEach(t),Bm=r(Pi,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Pi.forEach(t),Nm=m(Pt),hr=s(Pt,"P",{});var Mi=n(hr);Sm=r(Mi,"This model is also a PyTorch "),cr=s(Mi,"A",{href:!0,rel:!0});var vu=n(cr);Um=r(vu,"torch.nn.Module"),vu.forEach(t),Km=r(Mi,` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),Mi.forEach(t),jm=m(Pt),fr=s(Pt,"P",{});var Di=n(fr);Hm=r(Di,"This class overrides "),Ba=s(Di,"A",{href:!0});var bu=n(Ba);Qm=r(bu,"RobertaForMultipleChoice"),bu.forEach(t),Vm=r(Di,`. Please check the superclass for the appropriate documentation
alongside usage examples.`),Di.forEach(t),Pt.forEach(t),Dn=m(i),It=s(i,"H2",{class:!0});var Li=n(It);oo=s(Li,"A",{id:!0,class:!0,href:!0});var ku=n(oo);xs=s(ku,"SPAN",{});var wu=n(xs);A(pr.$$.fragment,wu),wu.forEach(t),ku.forEach(t),Wm=m(Li),Is=s(Li,"SPAN",{});var yu=n(Is);Gm=r(yu,"CamembertForTokenClassification"),yu.forEach(t),Li.forEach(t),Ln=m(i),lt=s(i,"DIV",{class:!0});var Mt=n(lt);A(ur.$$.fragment,Mt),Xm=m(Mt),Os=s(Mt,"P",{});var Tu=n(Os);Jm=r(Tu,`CamemBERT Model with a token classification head on top (a linear layer on top of the hidden-states output) e.g.
for Named-Entity-Recognition (NER) tasks.`),Tu.forEach(t),Ym=m(Mt),gr=s(Mt,"P",{});var Ai=n(gr);Zm=r(Ai,"This model inherits from "),Na=s(Ai,"A",{href:!0});var Eu=n(Na);eh=r(Eu,"PreTrainedModel"),Eu.forEach(t),th=r(Ai,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Ai.forEach(t),oh=m(Mt),_r=s(Mt,"P",{});var Ri=n(_r);rh=r(Ri,"This model is also a PyTorch "),vr=s(Ri,"A",{href:!0,rel:!0});var Cu=n(vr);ah=r(Cu,"torch.nn.Module"),Cu.forEach(t),sh=r(Ri,` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),Ri.forEach(t),nh=m(Mt),br=s(Mt,"P",{});var zi=n(br);ih=r(zi,"This class overrides "),Sa=s(zi,"A",{href:!0});var $u=n(Sa);lh=r($u,"RobertaForTokenClassification"),$u.forEach(t),dh=r(zi,`. Please check the superclass for the appropriate
documentation alongside usage examples.`),zi.forEach(t),Mt.forEach(t),An=m(i),Ot=s(i,"H2",{class:!0});var qi=n(Ot);ro=s(qi,"A",{id:!0,class:!0,href:!0});var Fu=n(ro);Bs=s(Fu,"SPAN",{});var Pu=n(Bs);A(kr.$$.fragment,Pu),Pu.forEach(t),Fu.forEach(t),mh=m(qi),Ns=s(qi,"SPAN",{});var Mu=n(Ns);hh=r(Mu,"CamembertForQuestionAnswering"),Mu.forEach(t),qi.forEach(t),Rn=m(i),dt=s(i,"DIV",{class:!0});var Dt=n(dt);A(wr.$$.fragment,Dt),ch=m(Dt),ao=s(Dt,"P",{});var _n=n(ao);fh=r(_n,`CamemBERT Model with a span classification head on top for extractive question-answering tasks like SQuAD (a linear
layers on top of the hidden-states output to compute `),Ss=s(_n,"CODE",{});var Du=n(Ss);ph=r(Du,"span start logits"),Du.forEach(t),uh=r(_n," and "),Us=s(_n,"CODE",{});var Lu=n(Us);gh=r(Lu,"span end logits"),Lu.forEach(t),_n.forEach(t),_h=m(Dt),yr=s(Dt,"P",{});var xi=n(yr);vh=r(xi,"This model inherits from "),Ua=s(xi,"A",{href:!0});var Au=n(Ua);bh=r(Au,"PreTrainedModel"),Au.forEach(t),kh=r(xi,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),xi.forEach(t),wh=m(Dt),Tr=s(Dt,"P",{});var Ii=n(Tr);yh=r(Ii,"This model is also a PyTorch "),Er=s(Ii,"A",{href:!0,rel:!0});var Ru=n(Er);Th=r(Ru,"torch.nn.Module"),Ru.forEach(t),Eh=r(Ii,` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),Ii.forEach(t),Ch=m(Dt),Cr=s(Dt,"P",{});var Oi=n(Cr);$h=r(Oi,"This class overrides "),Ka=s(Oi,"A",{href:!0});var zu=n(Ka);Fh=r(zu,"RobertaForQuestionAnswering"),zu.forEach(t),Ph=r(Oi,`. Please check the superclass for the appropriate documentation
alongside usage examples.`),Oi.forEach(t),Dt.forEach(t),zn=m(i),Bt=s(i,"H2",{class:!0});var Bi=n(Bt);so=s(Bi,"A",{id:!0,class:!0,href:!0});var qu=n(so);Ks=s(qu,"SPAN",{});var xu=n(Ks);A($r.$$.fragment,xu),xu.forEach(t),qu.forEach(t),Mh=m(Bi),js=s(Bi,"SPAN",{});var Iu=n(js);Dh=r(Iu,"TFCamembertModel"),Iu.forEach(t),Bi.forEach(t),qn=m(i),We=s(i,"DIV",{class:!0});var ct=n(We);A(Fr.$$.fragment,ct),Lh=m(ct),Hs=s(ct,"P",{});var Ou=n(Hs);Ah=r(Ou,"The bare CamemBERT Model transformer outputting raw hidden-states without any specific head on top."),Ou.forEach(t),Rh=m(ct),Pr=s(ct,"P",{});var Ni=n(Pr);zh=r(Ni,"This model inherits from "),ja=s(Ni,"A",{href:!0});var Bu=n(ja);qh=r(Bu,"TFPreTrainedModel"),Bu.forEach(t),xh=r(Ni,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Ni.forEach(t),Ih=m(ct),Mr=s(ct,"P",{});var Si=n(Mr);Oh=r(Si,"This model is also a "),Dr=s(Si,"A",{href:!0,rel:!0});var Nu=n(Dr);Bh=r(Nu,"tf.keras.Model"),Nu.forEach(t),Nh=r(Si,` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),Si.forEach(t),Sh=m(ct),A(no.$$.fragment,ct),Uh=m(ct),Lr=s(ct,"P",{});var Ui=n(Lr);Kh=r(Ui,"This class overrides "),Ha=s(Ui,"A",{href:!0});var Su=n(Ha);jh=r(Su,"TFRobertaModel"),Su.forEach(t),Hh=r(Ui,`. Please check the superclass for the appropriate documentation alongside
usage examples.`),Ui.forEach(t),ct.forEach(t),xn=m(i),Nt=s(i,"H2",{class:!0});var Ki=n(Nt);io=s(Ki,"A",{id:!0,class:!0,href:!0});var Uu=n(io);Qs=s(Uu,"SPAN",{});var Ku=n(Qs);A(Ar.$$.fragment,Ku),Ku.forEach(t),Uu.forEach(t),Qh=m(Ki),Vs=s(Ki,"SPAN",{});var ju=n(Vs);Vh=r(ju,"TFCamembertForCasualLM"),ju.forEach(t),Ki.forEach(t),In=m(i),Ge=s(i,"DIV",{class:!0});var ft=n(Ge);A(Rr.$$.fragment,ft),Wh=m(ft),zr=s(ft,"P",{});var ji=n(zr);Gh=r(ji,"CamemBERT Model with a "),Ws=s(ji,"CODE",{});var Hu=n(Ws);Xh=r(Hu,"language modeling"),Hu.forEach(t),Jh=r(ji," head on top for CLM fine-tuning."),ji.forEach(t),Yh=m(ft),qr=s(ft,"P",{});var Hi=n(qr);Zh=r(Hi,"This model inherits from "),Qa=s(Hi,"A",{href:!0});var Qu=n(Qa);ec=r(Qu,"TFPreTrainedModel"),Qu.forEach(t),tc=r(Hi,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Hi.forEach(t),oc=m(ft),xr=s(ft,"P",{});var Qi=n(xr);rc=r(Qi,"This model is also a "),Ir=s(Qi,"A",{href:!0,rel:!0});var Vu=n(Ir);ac=r(Vu,"tf.keras.Model"),Vu.forEach(t),sc=r(Qi,` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),Qi.forEach(t),nc=m(ft),A(lo.$$.fragment,ft),ic=m(ft),Or=s(ft,"P",{});var Vi=n(Or);lc=r(Vi,"This class overrides "),Va=s(Vi,"A",{href:!0});var Wu=n(Va);dc=r(Wu,"TFRobertaForCausalLM"),Wu.forEach(t),mc=r(Vi,`. Please check the superclass for the appropriate documentation
alongside usage examples.`),Vi.forEach(t),ft.forEach(t),On=m(i),St=s(i,"H2",{class:!0});var Wi=n(St);mo=s(Wi,"A",{id:!0,class:!0,href:!0});var Gu=n(mo);Gs=s(Gu,"SPAN",{});var Xu=n(Gs);A(Br.$$.fragment,Xu),Xu.forEach(t),Gu.forEach(t),hc=m(Wi),Xs=s(Wi,"SPAN",{});var Ju=n(Xs);cc=r(Ju,"TFCamembertForMaskedLM"),Ju.forEach(t),Wi.forEach(t),Bn=m(i),Xe=s(i,"DIV",{class:!0});var pt=n(Xe);A(Nr.$$.fragment,pt),fc=m(pt),Sr=s(pt,"P",{});var Gi=n(Sr);pc=r(Gi,"CamemBERT Model with a "),Js=s(Gi,"CODE",{});var Yu=n(Js);uc=r(Yu,"language modeling"),Yu.forEach(t),gc=r(Gi," head on top."),Gi.forEach(t),_c=m(pt),Ur=s(pt,"P",{});var Xi=n(Ur);vc=r(Xi,"This model inherits from "),Wa=s(Xi,"A",{href:!0});var Zu=n(Wa);bc=r(Zu,"TFPreTrainedModel"),Zu.forEach(t),kc=r(Xi,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Xi.forEach(t),wc=m(pt),Kr=s(pt,"P",{});var Ji=n(Kr);yc=r(Ji,"This model is also a "),jr=s(Ji,"A",{href:!0,rel:!0});var eg=n(jr);Tc=r(eg,"tf.keras.Model"),eg.forEach(t),Ec=r(Ji,` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),Ji.forEach(t),Cc=m(pt),A(ho.$$.fragment,pt),$c=m(pt),Hr=s(pt,"P",{});var Yi=n(Hr);Fc=r(Yi,"This class overrides "),Ga=s(Yi,"A",{href:!0});var tg=n(Ga);Pc=r(tg,"TFRobertaForMaskedLM"),tg.forEach(t),Mc=r(Yi,`. Please check the superclass for the appropriate documentation
alongside usage examples.`),Yi.forEach(t),pt.forEach(t),Nn=m(i),Ut=s(i,"H2",{class:!0});var Zi=n(Ut);co=s(Zi,"A",{id:!0,class:!0,href:!0});var og=n(co);Ys=s(og,"SPAN",{});var rg=n(Ys);A(Qr.$$.fragment,rg),rg.forEach(t),og.forEach(t),Dc=m(Zi),Zs=s(Zi,"SPAN",{});var ag=n(Zs);Lc=r(ag,"TFCamembertForSequenceClassification"),ag.forEach(t),Zi.forEach(t),Sn=m(i),Je=s(i,"DIV",{class:!0});var ut=n(Je);A(Vr.$$.fragment,ut),Ac=m(ut),en=s(ut,"P",{});var sg=n(en);Rc=r(sg,`CamemBERT Model transformer with a sequence classification/regression head on top (a linear layer on top of the
pooled output) e.g. for GLUE tasks.`),sg.forEach(t),zc=m(ut),Wr=s(ut,"P",{});var el=n(Wr);qc=r(el,"This model inherits from "),Xa=s(el,"A",{href:!0});var ng=n(Xa);xc=r(ng,"TFPreTrainedModel"),ng.forEach(t),Ic=r(el,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),el.forEach(t),Oc=m(ut),Gr=s(ut,"P",{});var tl=n(Gr);Bc=r(tl,"This model is also a "),Xr=s(tl,"A",{href:!0,rel:!0});var ig=n(Xr);Nc=r(ig,"tf.keras.Model"),ig.forEach(t),Sc=r(tl,` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),tl.forEach(t),Uc=m(ut),A(fo.$$.fragment,ut),Kc=m(ut),Jr=s(ut,"P",{});var ol=n(Jr);jc=r(ol,"This class overrides "),Ja=s(ol,"A",{href:!0});var lg=n(Ja);Hc=r(lg,"TFRobertaForSequenceClassification"),lg.forEach(t),Qc=r(ol,`. Please check the superclass for the appropriate
documentation alongside usage examples.`),ol.forEach(t),ut.forEach(t),Un=m(i),Kt=s(i,"H2",{class:!0});var rl=n(Kt);po=s(rl,"A",{id:!0,class:!0,href:!0});var dg=n(po);tn=s(dg,"SPAN",{});var mg=n(tn);A(Yr.$$.fragment,mg),mg.forEach(t),dg.forEach(t),Vc=m(rl),on=s(rl,"SPAN",{});var hg=n(on);Wc=r(hg,"TFCamembertForMultipleChoice"),hg.forEach(t),rl.forEach(t),Kn=m(i),Ye=s(i,"DIV",{class:!0});var gt=n(Ye);A(Zr.$$.fragment,gt),Gc=m(gt),rn=s(gt,"P",{});var cg=n(rn);Xc=r(cg,`CamemBERT Model with a multiple choice classification head on top (a linear layer on top of the pooled output and a
softmax) e.g. for RocStories/SWAG tasks.`),cg.forEach(t),Jc=m(gt),ea=s(gt,"P",{});var al=n(ea);Yc=r(al,"This model inherits from "),Ya=s(al,"A",{href:!0});var fg=n(Ya);Zc=r(fg,"TFPreTrainedModel"),fg.forEach(t),ef=r(al,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),al.forEach(t),tf=m(gt),ta=s(gt,"P",{});var sl=n(ta);of=r(sl,"This model is also a "),oa=s(sl,"A",{href:!0,rel:!0});var pg=n(oa);rf=r(pg,"tf.keras.Model"),pg.forEach(t),af=r(sl,` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),sl.forEach(t),sf=m(gt),A(uo.$$.fragment,gt),nf=m(gt),ra=s(gt,"P",{});var nl=n(ra);lf=r(nl,"This class overrides "),Za=s(nl,"A",{href:!0});var ug=n(Za);df=r(ug,"TFRobertaForMultipleChoice"),ug.forEach(t),mf=r(nl,`. Please check the superclass for the appropriate documentation
alongside usage examples.`),nl.forEach(t),gt.forEach(t),jn=m(i),jt=s(i,"H2",{class:!0});var il=n(jt);go=s(il,"A",{id:!0,class:!0,href:!0});var gg=n(go);an=s(gg,"SPAN",{});var _g=n(an);A(aa.$$.fragment,_g),_g.forEach(t),gg.forEach(t),hf=m(il),sn=s(il,"SPAN",{});var vg=n(sn);cf=r(vg,"TFCamembertForTokenClassification"),vg.forEach(t),il.forEach(t),Hn=m(i),Ze=s(i,"DIV",{class:!0});var _t=n(Ze);A(sa.$$.fragment,_t),ff=m(_t),nn=s(_t,"P",{});var bg=n(nn);pf=r(bg,`CamemBERT Model with a token classification head on top (a linear layer on top of the hidden-states output) e.g.
for Named-Entity-Recognition (NER) tasks.`),bg.forEach(t),uf=m(_t),na=s(_t,"P",{});var ll=n(na);gf=r(ll,"This model inherits from "),es=s(ll,"A",{href:!0});var kg=n(es);_f=r(kg,"TFPreTrainedModel"),kg.forEach(t),vf=r(ll,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),ll.forEach(t),bf=m(_t),ia=s(_t,"P",{});var dl=n(ia);kf=r(dl,"This model is also a "),la=s(dl,"A",{href:!0,rel:!0});var wg=n(la);wf=r(wg,"tf.keras.Model"),wg.forEach(t),yf=r(dl,` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),dl.forEach(t),Tf=m(_t),A(_o.$$.fragment,_t),Ef=m(_t),da=s(_t,"P",{});var ml=n(da);Cf=r(ml,"This class overrides "),ts=s(ml,"A",{href:!0});var yg=n(ts);$f=r(yg,"TFRobertaForTokenClassification"),yg.forEach(t),Ff=r(ml,`. Please check the superclass for the appropriate
documentation alongside usage examples.`),ml.forEach(t),_t.forEach(t),Qn=m(i),Ht=s(i,"H2",{class:!0});var hl=n(Ht);vo=s(hl,"A",{id:!0,class:!0,href:!0});var Tg=n(vo);ln=s(Tg,"SPAN",{});var Eg=n(ln);A(ma.$$.fragment,Eg),Eg.forEach(t),Tg.forEach(t),Pf=m(hl),dn=s(hl,"SPAN",{});var Cg=n(dn);Mf=r(Cg,"TFCamembertForQuestionAnswering"),Cg.forEach(t),hl.forEach(t),Vn=m(i),et=s(i,"DIV",{class:!0});var vt=n(et);A(ha.$$.fragment,vt),Df=m(vt),Qt=s(vt,"P",{});var ls=n(Qt);Lf=r(ls,`CamemBERT Model with a span classification head on top for extractive question-answering tasks like SQuAD (a linear
layers on top of the hidden-states output to compute `),mn=s(ls,"CODE",{});var $g=n(mn);Af=r($g,"span start logits"),$g.forEach(t),Rf=r(ls," and "),hn=s(ls,"CODE",{});var Fg=n(hn);zf=r(Fg,"span end logits"),Fg.forEach(t),qf=r(ls,")."),ls.forEach(t),xf=m(vt),ca=s(vt,"P",{});var cl=n(ca);If=r(cl,"This model inherits from "),os=s(cl,"A",{href:!0});var Pg=n(os);Of=r(Pg,"TFPreTrainedModel"),Pg.forEach(t),Bf=r(cl,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),cl.forEach(t),Nf=m(vt),fa=s(vt,"P",{});var fl=n(fa);Sf=r(fl,"This model is also a "),pa=s(fl,"A",{href:!0,rel:!0});var Mg=n(pa);Uf=r(Mg,"tf.keras.Model"),Mg.forEach(t),Kf=r(fl,` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),fl.forEach(t),jf=m(vt),A(bo.$$.fragment,vt),Hf=m(vt),ua=s(vt,"P",{});var pl=n(ua);Qf=r(pl,"This class overrides "),rs=s(pl,"A",{href:!0});var Dg=n(rs);Vf=r(Dg,"TFRobertaForQuestionAnswering"),Dg.forEach(t),Wf=r(pl,`. Please check the superclass for the appropriate
documentation alongside usage examples.`),pl.forEach(t),vt.forEach(t),this.h()},h(){h(v,"name","hf:doc:metadata"),h(v,"content",JSON.stringify(jg)),h(te,"id","camembert"),h(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(te,"href","#camembert"),h($,"class","relative group"),h(oe,"id","overview"),h(oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(oe,"href","#overview"),h(F,"class","relative group"),h(ae,"href","https://arxiv.org/abs/1911.03894"),h(ae,"rel","nofollow"),h(N,"href","roberta"),h(ne,"href","https://huggingface.co/camembert"),h(ne,"rel","nofollow"),h(ie,"href","https://camembert-model.fr/"),h(ie,"rel","nofollow"),h(re,"id","transformers.CamembertConfig"),h(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(re,"href","#transformers.CamembertConfig"),h(P,"class","relative group"),h(qe,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaConfig"),h(Re,"href","https://huggingface.co/camembert-base"),h(Re,"rel","nofollow"),h(l,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(D,"id","transformers.CamembertTokenizer"),h(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(D,"href","#transformers.CamembertTokenizer"),h(E,"class","relative group"),h(ba,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaTokenizer"),h(ka,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetTokenizer"),h(wo,"href","https://github.com/google/sentencepiece"),h(wo,"rel","nofollow"),h(wa,"href","/docs/transformers/v4.22.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizer"),h(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(Ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(Gt,"id","transformers.CamembertTokenizerFast"),h(Gt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Gt,"href","#transformers.CamembertTokenizerFast"),h(Lt,"class","relative group"),h(Ca,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaTokenizer"),h($a,"href","/docs/transformers/v4.22.0/en/model_doc/xlnet#transformers.XLNetTokenizer"),h(Lo,"href","https://huggingface.co/docs/tokenizers/python/latest/components.html?highlight=BPE#models"),h(Lo,"rel","nofollow"),h(Fa,"href","/docs/transformers/v4.22.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast"),h(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(Jt,"id","transformers.CamembertModel"),h(Jt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Jt,"href","#transformers.CamembertModel"),h(At,"class","relative group"),h(Da,"href","/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel"),h(No,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),h(No,"rel","nofollow"),h(La,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaModel"),h(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(Yt,"id","transformers.CamembertForCausalLM"),h(Yt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Yt,"href","#transformers.CamembertForCausalLM"),h(Rt,"class","relative group"),h(Aa,"href","/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel"),h(Vo,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),h(Vo,"rel","nofollow"),h(Ra,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForCausalLM"),h(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(Zt,"id","transformers.CamembertForMaskedLM"),h(Zt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Zt,"href","#transformers.CamembertForMaskedLM"),h(zt,"class","relative group"),h(za,"href","/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel"),h(er,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),h(er,"rel","nofollow"),h(qa,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForMaskedLM"),h(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(eo,"id","transformers.CamembertForSequenceClassification"),h(eo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(eo,"href","#transformers.CamembertForSequenceClassification"),h(qt,"class","relative group"),h(xa,"href","/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel"),h(nr,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),h(nr,"rel","nofollow"),h(Ia,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),h(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(to,"id","transformers.CamembertForMultipleChoice"),h(to,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(to,"href","#transformers.CamembertForMultipleChoice"),h(xt,"class","relative group"),h(Oa,"href","/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel"),h(cr,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),h(cr,"rel","nofollow"),h(Ba,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),h(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(oo,"id","transformers.CamembertForTokenClassification"),h(oo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(oo,"href","#transformers.CamembertForTokenClassification"),h(It,"class","relative group"),h(Na,"href","/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel"),h(vr,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),h(vr,"rel","nofollow"),h(Sa,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForTokenClassification"),h(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(ro,"id","transformers.CamembertForQuestionAnswering"),h(ro,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ro,"href","#transformers.CamembertForQuestionAnswering"),h(Ot,"class","relative group"),h(Ua,"href","/docs/transformers/v4.22.0/en/main_classes/model#transformers.PreTrainedModel"),h(Er,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),h(Er,"rel","nofollow"),h(Ka,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),h(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(so,"id","transformers.TFCamembertModel"),h(so,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(so,"href","#transformers.TFCamembertModel"),h(Bt,"class","relative group"),h(ja,"href","/docs/transformers/v4.22.0/en/main_classes/model#transformers.TFPreTrainedModel"),h(Dr,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),h(Dr,"rel","nofollow"),h(Ha,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaModel"),h(We,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(io,"id","transformers.TFCamembertForCausalLM"),h(io,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(io,"href","#transformers.TFCamembertForCausalLM"),h(Nt,"class","relative group"),h(Qa,"href","/docs/transformers/v4.22.0/en/main_classes/model#transformers.TFPreTrainedModel"),h(Ir,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),h(Ir,"rel","nofollow"),h(Va,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),h(Ge,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(mo,"id","transformers.TFCamembertForMaskedLM"),h(mo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(mo,"href","#transformers.TFCamembertForMaskedLM"),h(St,"class","relative group"),h(Wa,"href","/docs/transformers/v4.22.0/en/main_classes/model#transformers.TFPreTrainedModel"),h(jr,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),h(jr,"rel","nofollow"),h(Ga,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),h(Xe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(co,"id","transformers.TFCamembertForSequenceClassification"),h(co,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(co,"href","#transformers.TFCamembertForSequenceClassification"),h(Ut,"class","relative group"),h(Xa,"href","/docs/transformers/v4.22.0/en/main_classes/model#transformers.TFPreTrainedModel"),h(Xr,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),h(Xr,"rel","nofollow"),h(Ja,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),h(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(po,"id","transformers.TFCamembertForMultipleChoice"),h(po,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(po,"href","#transformers.TFCamembertForMultipleChoice"),h(Kt,"class","relative group"),h(Ya,"href","/docs/transformers/v4.22.0/en/main_classes/model#transformers.TFPreTrainedModel"),h(oa,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),h(oa,"rel","nofollow"),h(Za,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),h(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(go,"id","transformers.TFCamembertForTokenClassification"),h(go,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(go,"href","#transformers.TFCamembertForTokenClassification"),h(jt,"class","relative group"),h(es,"href","/docs/transformers/v4.22.0/en/main_classes/model#transformers.TFPreTrainedModel"),h(la,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),h(la,"rel","nofollow"),h(ts,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),h(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(vo,"id","transformers.TFCamembertForQuestionAnswering"),h(vo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(vo,"href","#transformers.TFCamembertForQuestionAnswering"),h(Ht,"class","relative group"),h(os,"href","/docs/transformers/v4.22.0/en/main_classes/model#transformers.TFPreTrainedModel"),h(pa,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),h(pa,"rel","nofollow"),h(rs,"href","/docs/transformers/v4.22.0/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),h(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(i,u){e(document.head,v),c(i,me,u),c(i,$,u),e($,te),e(te,le),R(W,le,null),e($,w),e($,S),e(S,be),c(i,he,u),c(i,F,u),e(F,oe),e(oe,X),R(f,X,null),e(F,ke),e(F,U),e(U,we),c(i,ce,u),c(i,M,u),e(M,ye),e(M,ae),e(ae,K),e(M,Te),c(i,fe,u),c(i,I,u),e(I,Ee),c(i,pe,u),c(i,O,u),e(O,de),e(de,Ce),c(i,Z,u),c(i,_,u),e(_,y),c(i,ue,u),c(i,B,u),e(B,se),e(se,$e),e(se,N),e(N,Fe),e(se,Pe),c(i,k,u),c(i,ee,u),e(ee,j),e(ee,ne),e(ne,Me),e(ee,H),e(ee,ie),e(ie,De),e(ee,C),c(i,ge,u),c(i,P,u),e(P,re),e(re,J),R(b,J,null),e(P,Le),e(P,T),e(T,Ae),c(i,_e,u),c(i,l,u),R(p,l,null),e(l,Be),e(l,V),e(V,Ne),e(V,qe),e(qe,g),e(V,Se),e(V,Re),e(Re,Ue),e(V,Ke),c(i,Oe,u),c(i,E,u),e(E,D),e(D,xe),R(ze,xe,null),e(E,Q),e(E,Ie),e(Ie,je),c(i,ve,u),c(i,Y,u),R(G,Y,null),e(Y,He),e(Y,bt),e(bt,ul),e(bt,ba),e(ba,gl),e(bt,_l),e(bt,ka),e(ka,vl),e(bt,bl),e(bt,wo),e(wo,kl),e(bt,wl),e(Y,yl),e(Y,yo),e(yo,Tl),e(yo,wa),e(wa,El),e(yo,Cl),e(Y,$l),e(Y,kt),R(To,kt,null),e(kt,Fl),e(kt,ds),e(ds,Pl),e(kt,Ml),e(kt,Eo),e(Eo,ya),e(ya,Dl),e(ya,ms),e(ms,Ll),e(Eo,Al),e(Eo,Ta),e(Ta,Rl),e(Ta,hs),e(hs,zl),e(Y,ql),e(Y,Vt),R(Co,Vt,null),e(Vt,xl),e(Vt,$o),e($o,Il),e($o,cs),e(cs,Ol),e($o,Bl),e(Y,Nl),e(Y,Wt),R(Fo,Wt,null),e(Wt,Sl),e(Wt,fs),e(fs,Ul),e(Y,Kl),e(Y,Ea),R(Po,Ea,null),c(i,vn,u),c(i,Lt,u),e(Lt,Gt),e(Gt,ps),R(Mo,ps,null),e(Lt,jl),e(Lt,us),e(us,Hl),c(i,bn,u),c(i,ot,u),R(Do,ot,null),e(ot,Ql),e(ot,ht),e(ht,Vl),e(ht,gs),e(gs,Wl),e(ht,Gl),e(ht,Ca),e(Ca,Xl),e(ht,Jl),e(ht,$a),e($a,Yl),e(ht,Zl),e(ht,Lo),e(Lo,ed),e(ht,td),e(ot,od),e(ot,Ao),e(Ao,rd),e(Ao,Fa),e(Fa,ad),e(Ao,sd),e(ot,nd),e(ot,wt),R(Ro,wt,null),e(wt,id),e(wt,_s),e(_s,ld),e(wt,dd),e(wt,zo),e(zo,Pa),e(Pa,md),e(Pa,vs),e(vs,hd),e(zo,cd),e(zo,Ma),e(Ma,fd),e(Ma,bs),e(bs,pd),e(ot,ud),e(ot,Xt),R(qo,Xt,null),e(Xt,gd),e(Xt,ks),e(ks,_d),c(i,kn,u),c(i,At,u),e(At,Jt),e(Jt,ws),R(xo,ws,null),e(At,vd),e(At,ys),e(ys,bd),c(i,wn,u),c(i,rt,u),R(Io,rt,null),e(rt,kd),e(rt,Ts),e(Ts,wd),e(rt,yd),e(rt,Oo),e(Oo,Td),e(Oo,Da),e(Da,Ed),e(Oo,Cd),e(rt,$d),e(rt,Bo),e(Bo,Fd),e(Bo,No),e(No,Pd),e(Bo,Md),e(rt,Dd),e(rt,So),e(So,Ld),e(So,La),e(La,Ad),e(So,Rd),c(i,yn,u),c(i,Rt,u),e(Rt,Yt),e(Yt,Es),R(Uo,Es,null),e(Rt,zd),e(Rt,Cs),e(Cs,qd),c(i,Tn,u),c(i,at,u),R(Ko,at,null),e(at,xd),e(at,jo),e(jo,Id),e(jo,$s),e($s,Od),e(jo,Bd),e(at,Nd),e(at,Ho),e(Ho,Sd),e(Ho,Aa),e(Aa,Ud),e(Ho,Kd),e(at,jd),e(at,Qo),e(Qo,Hd),e(Qo,Vo),e(Vo,Qd),e(Qo,Vd),e(at,Wd),e(at,Wo),e(Wo,Gd),e(Wo,Ra),e(Ra,Xd),e(Wo,Jd),c(i,En,u),c(i,zt,u),e(zt,Zt),e(Zt,Fs),R(Go,Fs,null),e(zt,Yd),e(zt,Ps),e(Ps,Zd),c(i,Cn,u),c(i,st,u),R(Xo,st,null),e(st,em),e(st,Jo),e(Jo,tm),e(Jo,Ms),e(Ms,om),e(Jo,rm),e(st,am),e(st,Yo),e(Yo,sm),e(Yo,za),e(za,nm),e(Yo,im),e(st,lm),e(st,Zo),e(Zo,dm),e(Zo,er),e(er,mm),e(Zo,hm),e(st,cm),e(st,tr),e(tr,fm),e(tr,qa),e(qa,pm),e(tr,um),c(i,$n,u),c(i,qt,u),e(qt,eo),e(eo,Ds),R(or,Ds,null),e(qt,gm),e(qt,Ls),e(Ls,_m),c(i,Fn,u),c(i,nt,u),R(rr,nt,null),e(nt,vm),e(nt,As),e(As,bm),e(nt,km),e(nt,ar),e(ar,wm),e(ar,xa),e(xa,ym),e(ar,Tm),e(nt,Em),e(nt,sr),e(sr,Cm),e(sr,nr),e(nr,$m),e(sr,Fm),e(nt,Pm),e(nt,ir),e(ir,Mm),e(ir,Ia),e(Ia,Dm),e(ir,Lm),c(i,Pn,u),c(i,xt,u),e(xt,to),e(to,Rs),R(lr,Rs,null),e(xt,Am),e(xt,zs),e(zs,Rm),c(i,Mn,u),c(i,it,u),R(dr,it,null),e(it,zm),e(it,qs),e(qs,qm),e(it,xm),e(it,mr),e(mr,Im),e(mr,Oa),e(Oa,Om),e(mr,Bm),e(it,Nm),e(it,hr),e(hr,Sm),e(hr,cr),e(cr,Um),e(hr,Km),e(it,jm),e(it,fr),e(fr,Hm),e(fr,Ba),e(Ba,Qm),e(fr,Vm),c(i,Dn,u),c(i,It,u),e(It,oo),e(oo,xs),R(pr,xs,null),e(It,Wm),e(It,Is),e(Is,Gm),c(i,Ln,u),c(i,lt,u),R(ur,lt,null),e(lt,Xm),e(lt,Os),e(Os,Jm),e(lt,Ym),e(lt,gr),e(gr,Zm),e(gr,Na),e(Na,eh),e(gr,th),e(lt,oh),e(lt,_r),e(_r,rh),e(_r,vr),e(vr,ah),e(_r,sh),e(lt,nh),e(lt,br),e(br,ih),e(br,Sa),e(Sa,lh),e(br,dh),c(i,An,u),c(i,Ot,u),e(Ot,ro),e(ro,Bs),R(kr,Bs,null),e(Ot,mh),e(Ot,Ns),e(Ns,hh),c(i,Rn,u),c(i,dt,u),R(wr,dt,null),e(dt,ch),e(dt,ao),e(ao,fh),e(ao,Ss),e(Ss,ph),e(ao,uh),e(ao,Us),e(Us,gh),e(dt,_h),e(dt,yr),e(yr,vh),e(yr,Ua),e(Ua,bh),e(yr,kh),e(dt,wh),e(dt,Tr),e(Tr,yh),e(Tr,Er),e(Er,Th),e(Tr,Eh),e(dt,Ch),e(dt,Cr),e(Cr,$h),e(Cr,Ka),e(Ka,Fh),e(Cr,Ph),c(i,zn,u),c(i,Bt,u),e(Bt,so),e(so,Ks),R($r,Ks,null),e(Bt,Mh),e(Bt,js),e(js,Dh),c(i,qn,u),c(i,We,u),R(Fr,We,null),e(We,Lh),e(We,Hs),e(Hs,Ah),e(We,Rh),e(We,Pr),e(Pr,zh),e(Pr,ja),e(ja,qh),e(Pr,xh),e(We,Ih),e(We,Mr),e(Mr,Oh),e(Mr,Dr),e(Dr,Bh),e(Mr,Nh),e(We,Sh),R(no,We,null),e(We,Uh),e(We,Lr),e(Lr,Kh),e(Lr,Ha),e(Ha,jh),e(Lr,Hh),c(i,xn,u),c(i,Nt,u),e(Nt,io),e(io,Qs),R(Ar,Qs,null),e(Nt,Qh),e(Nt,Vs),e(Vs,Vh),c(i,In,u),c(i,Ge,u),R(Rr,Ge,null),e(Ge,Wh),e(Ge,zr),e(zr,Gh),e(zr,Ws),e(Ws,Xh),e(zr,Jh),e(Ge,Yh),e(Ge,qr),e(qr,Zh),e(qr,Qa),e(Qa,ec),e(qr,tc),e(Ge,oc),e(Ge,xr),e(xr,rc),e(xr,Ir),e(Ir,ac),e(xr,sc),e(Ge,nc),R(lo,Ge,null),e(Ge,ic),e(Ge,Or),e(Or,lc),e(Or,Va),e(Va,dc),e(Or,mc),c(i,On,u),c(i,St,u),e(St,mo),e(mo,Gs),R(Br,Gs,null),e(St,hc),e(St,Xs),e(Xs,cc),c(i,Bn,u),c(i,Xe,u),R(Nr,Xe,null),e(Xe,fc),e(Xe,Sr),e(Sr,pc),e(Sr,Js),e(Js,uc),e(Sr,gc),e(Xe,_c),e(Xe,Ur),e(Ur,vc),e(Ur,Wa),e(Wa,bc),e(Ur,kc),e(Xe,wc),e(Xe,Kr),e(Kr,yc),e(Kr,jr),e(jr,Tc),e(Kr,Ec),e(Xe,Cc),R(ho,Xe,null),e(Xe,$c),e(Xe,Hr),e(Hr,Fc),e(Hr,Ga),e(Ga,Pc),e(Hr,Mc),c(i,Nn,u),c(i,Ut,u),e(Ut,co),e(co,Ys),R(Qr,Ys,null),e(Ut,Dc),e(Ut,Zs),e(Zs,Lc),c(i,Sn,u),c(i,Je,u),R(Vr,Je,null),e(Je,Ac),e(Je,en),e(en,Rc),e(Je,zc),e(Je,Wr),e(Wr,qc),e(Wr,Xa),e(Xa,xc),e(Wr,Ic),e(Je,Oc),e(Je,Gr),e(Gr,Bc),e(Gr,Xr),e(Xr,Nc),e(Gr,Sc),e(Je,Uc),R(fo,Je,null),e(Je,Kc),e(Je,Jr),e(Jr,jc),e(Jr,Ja),e(Ja,Hc),e(Jr,Qc),c(i,Un,u),c(i,Kt,u),e(Kt,po),e(po,tn),R(Yr,tn,null),e(Kt,Vc),e(Kt,on),e(on,Wc),c(i,Kn,u),c(i,Ye,u),R(Zr,Ye,null),e(Ye,Gc),e(Ye,rn),e(rn,Xc),e(Ye,Jc),e(Ye,ea),e(ea,Yc),e(ea,Ya),e(Ya,Zc),e(ea,ef),e(Ye,tf),e(Ye,ta),e(ta,of),e(ta,oa),e(oa,rf),e(ta,af),e(Ye,sf),R(uo,Ye,null),e(Ye,nf),e(Ye,ra),e(ra,lf),e(ra,Za),e(Za,df),e(ra,mf),c(i,jn,u),c(i,jt,u),e(jt,go),e(go,an),R(aa,an,null),e(jt,hf),e(jt,sn),e(sn,cf),c(i,Hn,u),c(i,Ze,u),R(sa,Ze,null),e(Ze,ff),e(Ze,nn),e(nn,pf),e(Ze,uf),e(Ze,na),e(na,gf),e(na,es),e(es,_f),e(na,vf),e(Ze,bf),e(Ze,ia),e(ia,kf),e(ia,la),e(la,wf),e(ia,yf),e(Ze,Tf),R(_o,Ze,null),e(Ze,Ef),e(Ze,da),e(da,Cf),e(da,ts),e(ts,$f),e(da,Ff),c(i,Qn,u),c(i,Ht,u),e(Ht,vo),e(vo,ln),R(ma,ln,null),e(Ht,Pf),e(Ht,dn),e(dn,Mf),c(i,Vn,u),c(i,et,u),R(ha,et,null),e(et,Df),e(et,Qt),e(Qt,Lf),e(Qt,mn),e(mn,Af),e(Qt,Rf),e(Qt,hn),e(hn,zf),e(Qt,qf),e(et,xf),e(et,ca),e(ca,If),e(ca,os),e(os,Of),e(ca,Bf),e(et,Nf),e(et,fa),e(fa,Sf),e(fa,pa),e(pa,Uf),e(fa,Kf),e(et,jf),R(bo,et,null),e(et,Hf),e(et,ua),e(ua,Qf),e(ua,rs),e(rs,Vf),e(ua,Wf),Wn=!0},p(i,[u]){const ga={};u&2&&(ga.$$scope={dirty:u,ctx:i}),no.$set(ga);const cn={};u&2&&(cn.$$scope={dirty:u,ctx:i}),lo.$set(cn);const fn={};u&2&&(fn.$$scope={dirty:u,ctx:i}),ho.$set(fn);const pn={};u&2&&(pn.$$scope={dirty:u,ctx:i}),fo.$set(pn);const _a={};u&2&&(_a.$$scope={dirty:u,ctx:i}),uo.$set(_a);const un={};u&2&&(un.$$scope={dirty:u,ctx:i}),_o.$set(un);const gn={};u&2&&(gn.$$scope={dirty:u,ctx:i}),bo.$set(gn)},i(i){Wn||(z(W.$$.fragment,i),z(f.$$.fragment,i),z(b.$$.fragment,i),z(p.$$.fragment,i),z(ze.$$.fragment,i),z(G.$$.fragment,i),z(To.$$.fragment,i),z(Co.$$.fragment,i),z(Fo.$$.fragment,i),z(Po.$$.fragment,i),z(Mo.$$.fragment,i),z(Do.$$.fragment,i),z(Ro.$$.fragment,i),z(qo.$$.fragment,i),z(xo.$$.fragment,i),z(Io.$$.fragment,i),z(Uo.$$.fragment,i),z(Ko.$$.fragment,i),z(Go.$$.fragment,i),z(Xo.$$.fragment,i),z(or.$$.fragment,i),z(rr.$$.fragment,i),z(lr.$$.fragment,i),z(dr.$$.fragment,i),z(pr.$$.fragment,i),z(ur.$$.fragment,i),z(kr.$$.fragment,i),z(wr.$$.fragment,i),z($r.$$.fragment,i),z(Fr.$$.fragment,i),z(no.$$.fragment,i),z(Ar.$$.fragment,i),z(Rr.$$.fragment,i),z(lo.$$.fragment,i),z(Br.$$.fragment,i),z(Nr.$$.fragment,i),z(ho.$$.fragment,i),z(Qr.$$.fragment,i),z(Vr.$$.fragment,i),z(fo.$$.fragment,i),z(Yr.$$.fragment,i),z(Zr.$$.fragment,i),z(uo.$$.fragment,i),z(aa.$$.fragment,i),z(sa.$$.fragment,i),z(_o.$$.fragment,i),z(ma.$$.fragment,i),z(ha.$$.fragment,i),z(bo.$$.fragment,i),Wn=!0)},o(i){q(W.$$.fragment,i),q(f.$$.fragment,i),q(b.$$.fragment,i),q(p.$$.fragment,i),q(ze.$$.fragment,i),q(G.$$.fragment,i),q(To.$$.fragment,i),q(Co.$$.fragment,i),q(Fo.$$.fragment,i),q(Po.$$.fragment,i),q(Mo.$$.fragment,i),q(Do.$$.fragment,i),q(Ro.$$.fragment,i),q(qo.$$.fragment,i),q(xo.$$.fragment,i),q(Io.$$.fragment,i),q(Uo.$$.fragment,i),q(Ko.$$.fragment,i),q(Go.$$.fragment,i),q(Xo.$$.fragment,i),q(or.$$.fragment,i),q(rr.$$.fragment,i),q(lr.$$.fragment,i),q(dr.$$.fragment,i),q(pr.$$.fragment,i),q(ur.$$.fragment,i),q(kr.$$.fragment,i),q(wr.$$.fragment,i),q($r.$$.fragment,i),q(Fr.$$.fragment,i),q(no.$$.fragment,i),q(Ar.$$.fragment,i),q(Rr.$$.fragment,i),q(lo.$$.fragment,i),q(Br.$$.fragment,i),q(Nr.$$.fragment,i),q(ho.$$.fragment,i),q(Qr.$$.fragment,i),q(Vr.$$.fragment,i),q(fo.$$.fragment,i),q(Yr.$$.fragment,i),q(Zr.$$.fragment,i),q(uo.$$.fragment,i),q(aa.$$.fragment,i),q(sa.$$.fragment,i),q(_o.$$.fragment,i),q(ma.$$.fragment,i),q(ha.$$.fragment,i),q(bo.$$.fragment,i),Wn=!1},d(i){t(v),i&&t(me),i&&t($),x(W),i&&t(he),i&&t(F),x(f),i&&t(ce),i&&t(M),i&&t(fe),i&&t(I),i&&t(pe),i&&t(O),i&&t(Z),i&&t(_),i&&t(ue),i&&t(B),i&&t(k),i&&t(ee),i&&t(ge),i&&t(P),x(b),i&&t(_e),i&&t(l),x(p),i&&t(Oe),i&&t(E),x(ze),i&&t(ve),i&&t(Y),x(G),x(To),x(Co),x(Fo),x(Po),i&&t(vn),i&&t(Lt),x(Mo),i&&t(bn),i&&t(ot),x(Do),x(Ro),x(qo),i&&t(kn),i&&t(At),x(xo),i&&t(wn),i&&t(rt),x(Io),i&&t(yn),i&&t(Rt),x(Uo),i&&t(Tn),i&&t(at),x(Ko),i&&t(En),i&&t(zt),x(Go),i&&t(Cn),i&&t(st),x(Xo),i&&t($n),i&&t(qt),x(or),i&&t(Fn),i&&t(nt),x(rr),i&&t(Pn),i&&t(xt),x(lr),i&&t(Mn),i&&t(it),x(dr),i&&t(Dn),i&&t(It),x(pr),i&&t(Ln),i&&t(lt),x(ur),i&&t(An),i&&t(Ot),x(kr),i&&t(Rn),i&&t(dt),x(wr),i&&t(zn),i&&t(Bt),x($r),i&&t(qn),i&&t(We),x(Fr),x(no),i&&t(xn),i&&t(Nt),x(Ar),i&&t(In),i&&t(Ge),x(Rr),x(lo),i&&t(On),i&&t(St),x(Br),i&&t(Bn),i&&t(Xe),x(Nr),x(ho),i&&t(Nn),i&&t(Ut),x(Qr),i&&t(Sn),i&&t(Je),x(Vr),x(fo),i&&t(Un),i&&t(Kt),x(Yr),i&&t(Kn),i&&t(Ye),x(Zr),x(uo),i&&t(jn),i&&t(jt),x(aa),i&&t(Hn),i&&t(Ze),x(sa),x(_o),i&&t(Qn),i&&t(Ht),x(ma),i&&t(Vn),i&&t(et),x(ha),x(bo)}}}const jg={local:"camembert",sections:[{local:"overview",title:"Overview"},{local:"transformers.CamembertConfig",title:"CamembertConfig"},{local:"transformers.CamembertTokenizer",title:"CamembertTokenizer"},{local:"transformers.CamembertTokenizerFast",title:"CamembertTokenizerFast"},{local:"transformers.CamembertModel",title:"CamembertModel"},{local:"transformers.CamembertForCausalLM",title:"CamembertForCausalLM"},{local:"transformers.CamembertForMaskedLM",title:"CamembertForMaskedLM"},{local:"transformers.CamembertForSequenceClassification",title:"CamembertForSequenceClassification"},{local:"transformers.CamembertForMultipleChoice",title:"CamembertForMultipleChoice"},{local:"transformers.CamembertForTokenClassification",title:"CamembertForTokenClassification"},{local:"transformers.CamembertForQuestionAnswering",title:"CamembertForQuestionAnswering"},{local:"transformers.TFCamembertModel",title:"TFCamembertModel"},{local:"transformers.TFCamembertForCausalLM",title:"TFCamembertForCasualLM"},{local:"transformers.TFCamembertForMaskedLM",title:"TFCamembertForMaskedLM"},{local:"transformers.TFCamembertForSequenceClassification",title:"TFCamembertForSequenceClassification"},{local:"transformers.TFCamembertForMultipleChoice",title:"TFCamembertForMultipleChoice"},{local:"transformers.TFCamembertForTokenClassification",title:"TFCamembertForTokenClassification"},{local:"transformers.TFCamembertForQuestionAnswering",title:"TFCamembertForQuestionAnswering"}],title:"CamemBERT"};function Hg(tt){return qg(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Xg extends Lg{constructor(v){super();Ag(this,v,Hg,Kg,Rg,{})}}export{Xg as default,jg as metadata};
